title,company,location,link,description,skills,details
Data Engineer H/F,Inetum,"St.-Ouen, √éle-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-h-f-at-inetum-3843966639?position=2&pageNum=0&refId=%2Bft0CQksufPV00p2d83arQ%3D%3D&trackingId=nTrOCXlFWzhFa1Udx1L9Wg%3D%3D&trk=public_jobs_jserp-result_search-card,"D√©tail de l'offre
Informations g√©n√©rales
Entit√© de rattachement
Inetum est un leader europ√©en des services num√©riques. Pour les entreprises, les acteurs publics et la soci√©t√© dans son ensemble, les 28 000 consultants et sp√©cialistes du groupe visent chaque jour l'impact digital des solutions qui contribuent √† la performance, √† l'innovation et au bien commun.
Pr√©sent dans 19 pays au plus pr√®s des territoires, et avec ses grands partenaires √©diteurs de logiciels, Inetum r√©pond aux enjeux de la transformation digitale avec proximit√© et flexibilit√©.
Port√© par son ambition de croissance et d'industrialisation, Inetum a g√©n√©r√© en 2023 un chiffre d'affaires de 2,5 milliards d'‚Ç¨.
Pour r√©pondre √† un march√© en croissance continue depuis plus de 30ans, Inetum a fait le choix d√©lib√©r√© de se recentrer sur 4 m√©tiers afin de gagner en puissance et proposer des solutions sur mesure, adapt√©es aux besoins sp√©cifiques de ses clients le conseil (Inetum Consulting), la gestion des infrastructures et applications √† fa√ßon (Inetum Technologies), l'impl√©mentation de progiciels (Inetum Solutions) et sa propre activit√© d'√©diteur de logiciels (Inetum Software). Inetum a conclu des partenariats strat√©giques avec 4 grands √©diteurs mondiaux - Salesforce, ServiceNow, Microsoft et SAP et poursuit une strat√©gie d'acquisitions d√©di√©e afin d'entrer dans le top 5 europ√©en sur ces technologies et proposer la meilleure expertise √† ses clients.
Tous nos postes sont ouverts aux personnes en situation de handicap.
Description du poste
M√©tier
Applications Delivery - Software Development
Intitul√© du poste
Data Engineer H/F
Contrat
CDI
Description De La Mission
Le p√¥le BFA de la branche Application Services du groupe INETUM, recherche plusieurs Data Engineers afin d'intervenir aupr√®s de clients grands comptes au sein des march√©s bancaires et de l'assurance.
Au sein de l'√©quipe Data, en tant que Data Engineer, vous participez √† la r√©alisation de divers projets et vos missions sont
Apporter votre connaissance en Big Data permettant la manipulation des donn√©es
Concevoir les plateformes permettant de traiter des volumes de donn√©es importants
Mettre en place des bases de donn√©es
Pr√©parer le pipeline de donn√©es pour que les donn√©es d√©ploy√©es soient s√©curis√©es et claires afin d'√™tre analys√©es et transform√©es.
Profil
De formation ing√©nieure en informatique Bac + 5 informatique ou scientifique
Bonne communication orale et √©crite en fran√ßais et niveau d‚Äôanglais professionnel
Savoir- √™tre Bon esprit d'analyse et de synth√®se, sens de l'organisation et de la qualit√©, force de proposition, rigueur, travail en √©quipe, adaptabilit√©.
Si vous vous reconnaissez, n'h√©sitez pas √† postuler !
Localisation du poste
Localisation du poste
France
Ville
Saint-Ouen
Crit√®res candidat
Niveau d'√©tudes min. requis
Bac+5
Niveau d'exp√©rience min. requis
Plus de 2 ans
Comp√©tences
SQL
Show more
Show less","{'ProgLanguage': ['R'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git'], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Big Data'], 'FrSoftSkills': ['Communication', 'Adaptabilit√©', 'Organisation', 'Flexibilit√©'], 'EnSoftSkils': ['Communication']}","{'JobDetail': [], 'TypeContract': ['CDI'], 'Salary': [], 'Level': ['Bac+5'], 'Experience': ['a', 'n', 's', '30', '30', '30']}"
Data Engineer (F/H),Thales,"V√©lizy-Villacoublay, √éle-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-f-h-at-thales-3908228180?position=3&pageNum=0&refId=%2Bft0CQksufPV00p2d83arQ%3D%3D&trackingId=HD%2FQ70zSF8JIOs1yoDNnNA%3D%3D&trk=public_jobs_jserp-result_search-card,"QUI SOMMES-NOUS ?
Thales est un leader mondial des hautes technologies comptant plus de 81 000 collaborateurs pr√©sents sur tous les continents. Le Groupe investit dans les innovations du num√©rique et de la ¬´ deep tech ¬ª ‚Äì big data, intelligence artificielle, connectivit√©, cybers√©curit√© et quantique ‚Äì pour construire un avenir de confiance, essentiel au d√©veloppement de nos soci√©t√©s, en pla√ßant l‚Äôhumain au c≈ìur des d√©cisions.
Thales propose des solutions, services et produits qui aident ses clients ‚Äì entreprises, organisations, Etats ‚Äì dans cinq grands march√©s vitaux pour le fonctionnement de nos soci√©t√©s : identit√© et s√©curit√© num√©riques, d√©fense, a√©ronautique, espace, et transport.
QUI ETES-VOUS ?
Dipl√¥m√© d‚Äôun Bac+5 en √©cole d‚Äôing√©nieur ou √©quivalent universitaire avec une sp√©cialisation en informatique, vous avez au moins 3 ans d'exp√©rience dans les technologies Big Data.
CE QUE NOUS POUVONS ACCOMPLIR ENSEMBLE :
En tant que Data Engineer, vous jouerez un r√¥le cl√© dans la conception, le d√©veloppement et la maintenance de notre infrastructure de donn√©es, ainsi que dans la transformation et la gestion des flux de donn√©es.
VOS MISSIONS :
‚Ä¢ Concevoir, d√©velopper et d√©ployer des solutions Big Data en utilisant les technologies Hadoop.
‚Ä¢ Mettre en place des pipelines de donn√©es performants pour l'ingestion, le traitement et le stockage des donn√©es massives.
‚Ä¢ Collaborer √©troitement avec les √©quipes m√©tier pour comprendre leurs besoins en mati√®re d'analyse de donn√©es et proposer des solutions adapt√©es.
‚Ä¢ Optimiser les performances des clusters Hadoop pour garantir une exploitation efficace des donn√©es.
‚Ä¢ Assurer la qualit√© et la fiabilit√© des donn√©es trait√©es, en mettant en place des processus de validation et de nettoyage.
‚Ä¢ Identifier et r√©soudre les probl√®mes li√©s √† l'infrastructure Big Data et proposer des am√©liorations.
‚Ä¢ Travailler en √©troite collaboration avec les Data Scientists et les Data Analysts pour fournir des insights pertinents √† partir des donn√©es.
Innovation, passion, ambition : rejoignez Thales et cr√©ez le monde de demain, d√®s aujourd‚Äôhui.
Show more
Show less","{'ProgLanguage': ['R'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': ['Hadoop'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Big Data'], 'FrSoftSkills': ['Collaboration', 'Organisation'], 'EnSoftSkils': ['Collaboration']}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': ['Bac+5'], 'Experience': ['a', 'n', 's', '3', '3', '3']}"
Data Engineer,digiRocks recrute ‚úÖ,"Paris, √éle-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-at-digirocks-recrute-%E2%9C%85-3903481080?position=4&pageNum=0&refId=%2Bft0CQksufPV00p2d83arQ%3D%3D&trackingId=aC4LOsoZqyxXsKs%2Fx4aYZQ%3D%3D&trk=public_jobs_jserp-result_search-card,"üòé Envie d'accompagner des organisations dans leurs strat√©gies, Fan de data?
Rejoins un jeune cabinet de conseil en strat√©gie sp√©cialis√© en data. Le cabinet a √©t√© cr√©√© il y a 4 ans pas des anciens de grands cabinets de conseil en strat√©gie qui ne se reconnaissaient plus dans ce qu'est devenu le ""consulting"". Cependant ils n'ont pas perdu espoir de pouvoir apporter du conseil √† haute valeur ajout√©e dans une ambiance friendly, fa√ßon start-up, sans sacrifier l'excellence.
Jean-Patrick recrute un(e) Consultant Data Engineer √† Paris en CDI
‚úÖ MISSION :
Vous serez responsable de la mise en ≈ìuvre de bout en bout de la pile de donn√©es, de la collecte au reporting, avec un accent sur l'infrastructure et les processus techniques. Vous travaillerez avec des Consultants en Strat√©gie & Data et les soutiendrez dans la r√©solution des d√©fis li√©s aux donn√©es de leurs clients. Vous contribuerez √† la d√©finition des strat√©gies de donn√©es, √† la mise en ≈ìuvre des syst√®mes de donn√©es et vous soutiendrez l'exploitation des donn√©es dans des projets transformationnels. En g√©n√©ral, vous serez responsable de comprendre intimement les probl√®mes, de concevoir une strat√©gie technique pour les adresser et de faciliter une ex√©cution technique de haute qualit√©.
‚úÖ R√âSULTATS ATTENDUS :
üöÄ R√©sultat 1: Unificateur de Donn√©es : Architecturer, assembler, assimiler, nettoyer et conformer de grands ensembles de donn√©es complexes pour livrer des insights commerciaux et alimenter les exp√©riences de produits de donn√©es.
üöÄ R√©sultat 2: Agent de S√©curit√© des Donn√©es : Concevoir et construire une infrastructure de donn√©es fiable et √©volutive avec les techniques de confidentialit√© et de s√©curit√© de pointe pour prot√©ger les donn√©es.
üöÄ R√©sultat 3: DataOps : Poss√©der la pile de donn√©es de bout en bout, y compris la collecte d'√©v√©nements, la gouvernance des donn√©es, les int√©grations de donn√©es et la mod√©lisation.
üöÄ R√©sultat 4: Gardien des Donn√©es : Assurer la coh√©rence et la qualit√© de l'environnement technique et de la structure des donn√©es √† travers des m√©triques, de la documentation, des processus, des tests de donn√©es et de la formation.
Requirements
‚úÖ PROFIL RECHERCH√â :
Dipl√¥m√© d'une Grande Ecole de Commerce ou d'ing√©nieur, avec une premi√®re exp√©rience r√©ussie comme Data Engineer, id√©alement dans un contexte similaire au Conseil,
Connaissance des services de Data Warehouses Cloud. Exp√©rience avec Google BigQuery, Snowflake, AWS Redshift/Athena, Looker, Azure SQL DWH, ou Azure Databricks est tr√®s souhaitable.
Connaissance des architectures de donn√©es relationnelles et de grandes donn√©es, de l'entreposage de donn√©es, de l'int√©gration de donn√©es, de la mod√©lisation de donn√©es, de l'optimisation de donn√©es et des techniques d'analyse de donn√©es.
Exp√©rience dans la construction de pipelines de donn√©es de bout en bout en utilisant des plateformes de donn√©es sur site ou bas√©es sur le cloud.
Exp√©rience pratique dans la livraison de solutions comprenant des bases de donn√©es, SQL avanc√© et d√©veloppement logiciel dans des langues telles que Python.
Int√©ress√© et connaissant les technologies Big Data et les technologies de l'√©cosyst√®me Apache telles que Beam, Spark, Kafka, Airflow, bases de donn√©es, int√©gration, gestion des donn√©es de r√©f√©rence, assurance qualit√©, manipulation de donn√©es et technologies de gouvernance des donn√©es.
Exp√©rience avec les plateformes cloud publiques et l'infrastructure cloud qui est essentielle.
Expos√© aux outils ETL/ELT et de gouvernance.
Int√©ress√© par les technologies et principes IA et ML.
Show more
Show less","{'ProgLanguage': ['Python', 'R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': ['Spark', 'Databricks'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': ['AWS', 'Azure'], 'DevTools': [], 'Os': [], 'DBMS': ['Snowflake', 'Snowflake', 'BigQuery'], 'SoftBigDataProcessing': [], 'Automation': ['Airflow'], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Big Data', 'ML', 'Cloud'], 'FrSoftSkills': ['Organisation'], 'EnSoftSkils': []}","{'JobDetail': [], 'TypeContract': ['CDI'], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's', '4', '4', '4']}"
Data Engineer,EarthDaily Agro,"Balma, Occitanie, France",https://fr.linkedin.com/jobs/view/data-engineer-at-earthdaily-agro-3883708013?position=5&pageNum=0&refId=%2Bft0CQksufPV00p2d83arQ%3D%3D&trackingId=myqOfZs5UWTalWgXlrRLjA%3D%3D&trk=public_jobs_jserp-result_search-card,"About Us
EarthDaily Agro provides space age data and analytics to the organizations and people who feed the planet!
With 35 years of industry experience, EarthDaily Agro provides customers with the data, analysis and knowledge they need to make more efficient and effective decisions. B2B services range from global risk management and monitoring of agricultural commodities to the marketing of inputs and precision agriculture consulting, using the latest research in agronomy, information technologies and remote sensing.
EarthDaily Agro also develops highly customized business solutions for agricultural lenders, insurers, input suppliers and food companies, with easy-to-use analytics, that help reduce the daily risks of agriculture.
EarthDaily Agro is headquartered in Minneapolis, MN, USA, with offices in France, Brazil, Australia and Switzerland and is a division of EarthDaily Analytics Corp.
EarthDaily Analytics Corp., a vertically-integrated data processing and analytics company, is launching a new constellation of earth observation satellites. The EarthDaily satellite constellation will significantly enhance geospatial analytics capabilities in agriculture, forestry, environment, financial services, and intelligence, among many other verticals.
Main Job Tasks And Responsibilities
As a EarthDailyAgro Data Engineer, your primary responsibility will be to design, develop, and manage data pipelines and infrastructure specialized for geospatial and remote sensing applications. You will work closely with data scientists, geospatial analysts, remote sensing experts, software engineers, and DevOps teams to ensure the successful deployment and scaling of data pipeline to feed geospatial data machine learning models. Your role will be crucial in optimizing the geospatial machine learning ecosystem and ensuring the seamless integration of AI-driven geospatial solutions into real-world applications.
Your Responsibilities Include
Cloud-based data pipeline Conceptualization, Development and Scaling: Build up pipeline to ingest large volumes of geospatial data, pre-process them and meet data scientists‚Äô requirements, in terms of accessibility, speed, format, quality.
Automation and CI/CD: Industrialization of pipeline deployment, orchestration, workflows, and versioning.
Cost & Speed Optimization: Collaborate with infrastructure team to develop, optimize, and fine-tune pipeline.
Cloud and Containerization: Experience with cloud platforms (e.g., AWS, Azure, GCP) and containerization tools.
Infrastructure Management: Utilize containerization technologies and cloud-based services to set up and manage infrastructure, enabling seamless deployment and scalability.
Monitoring and Anomaly Detection: Implement monitoring systems to track pipeline performance and identify anomalies.
Version Control and Data Version Control: Proficient with version control systems like Git and DVC.
Security and Compliance: Ensure the security and privacy of geospatial data, adhering to relevant data protection regulations and industry best practices.
Collaboration and Communication: Collaborate with interdisciplinary teams to integrate data pipeline into existing applications or develop new geospatial products.
Issue Resolution and Troubleshooting: Identify and resolve promptly technical issues related to geospatial data processing, performance, or infrastructure.
Education, Knowledge And Abilities
Requirements
Education: Master's degree in Computer Science, specialisation in Geomatics and/or Remote sensing would be a plus.
Experience: 3+ years experiences with data pipeline processes and deployment is a must-have. Proven hands-on experience in setting up pipelines and data processes with opensource tools (e.g., MLFlow, Argo, Kubeflow) is desirable.
Programming Skills: Proficiency in Python and with data manipulation frameworks (e.g., dataframe, numpy, pandas, xarray, rasterio) and librairies (e.g., Dask).
Problem-Solving Skills: Autonomous, and strong analytical and problem-solving abilities to address complex geospatial data and analysis challenges.
Communication Skills: Excellent communication and interpersonal skills to collaborate effectively with cross-functional teams and stakeholders.
French mandatory (job based in France). Fluent in English (oral and written):‚ÄØmeetings with internal are mostly in‚ÄØEnglish.
Preferred Additional Skills
Experience with Earth Observation (EO) data analysis and processing.
Experience with geospatial data formats (e.g., GeoTIFF, Shapefile, NetCDF).
Spatial Analysis Techniques: Understanding of spatial analysis techniques and algorithms commonly used in geospatial data manipulation.
Remote Sensing Integration: Knowledge of remote sensing data sources (e.g., STAC catalog, satellite imagery, LiDAR, SAR) integration into data pipelines for accurate and up-to-date geospatial analysis.
CONDITIONS
Full time job based in Balma, near Toulouse, France.
Fixed + Bonuses
TR / ""Family"" insurance / CSE
Powered by JazzHR
WrfSXQ5YJg
Show more
Show less","{'ProgLanguage': ['Python', 'Scala', 'R', 'Go'], 'DataBase': [], 'DataAnalytics': ['Pandas', 'NumPy', 'R'], 'BigData': [], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': ['AWS', 'Azure'], 'DevTools': ['Git'], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': ['Teams'], 'Other': ['DevOps', 'ML', 'Machine Learning', 'Cloud', 'CI/CD'], 'FrSoftSkills': ['Communication', 'Collaboration'], 'EnSoftSkils': ['Communication', 'Collaboration', 'Organization', 'Interpersonal Skills']}","{'JobDetail': ['Remote', 'Full'], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's']}"
Data Engineer (H/F),ternair,Greater Lille Metropolitan Area,https://fr.linkedin.com/jobs/view/data-engineer-h-f-at-ternair-3915757963?position=6&pageNum=0&refId=%2Bft0CQksufPV00p2d83arQ%3D%3D&trackingId=iPNIhGXIotrpwSQr1vaCtA%3D%3D&trk=public_jobs_jserp-result_search-card,"üë®‚ÄçüöÄ MISSION : üë©‚ÄçüöÄ
En coh√©rence avec la strat√©gie d‚Äôentreprise et la roadmap data, vous aurez pour principales missions de :
En lien avec l‚Äô√©quipe DevOps, construire, maintenir et faire √©voluer la plateforme de donn√©es;
D√©finir et piloter la coh√©rence de la collecte, la gestion et l‚Äôalimentation des donn√©es internes et externes, en diff√©rents modes : batch, streaming, API (architecture micro-services);
Pr√©parer et mettre en qualit√© les donn√©es pour les rendre disponibles dans les diff√©rents environnements de travail (datalake, datawarehouse, datamart);
V√©rifier la qualit√© des donn√©es, de leur bonne et r√©guli√®re ex√©cution ainsi que de leur utilisation ad√©quate (gestion des co√ªts);
Travailler en √©troite collaboration avec les data analysts, scientists et data stewards et business de l‚Äôentreprise ;
En lien avec l‚ÄôIT et la s√©curit√©, veiller aux r√®gles d'int√©grit√© et de s√©curit√© des donn√©es;
Veille technologique.
üßÆ Les outils :
Plateforme data : Google Cloud Platform (Big Query, Airflow)
D√©veloppement : Github/GitLab, Docker, Terraform, Python
Analytiques : Qlik
Gestion de projet s: Jira, Confluence, Miro, Drive, Docs, Sheets, Slides
ü§© Profil recherch√© : ü§©
Exp√©rience d'au moins 4-5 ans (apr√®s √©tudes) en data ing√©nierie (flux, mod√©lisation, run)
A l‚Äôaise avec l‚Äôenvironnement Cloud et les infrastructures digitales
Communiquant, p√©dagogue et fortes capacit√©s relationnelles
Anglais (√† l‚Äô√©crit)
R√©mun√©ration : 42-60 k‚Ç¨ en package selon exp√©rience
Show more
Show less","{'ProgLanguage': ['Python', 'R', 'Go'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': ['Google Cloud Platform'], 'DevTools': ['Git', 'Docker'], 'Os': [], 'DBMS': ['Big Query'], 'SoftBigDataProcessing': [], 'Automation': ['Airflow'], 'InfrastructureAsCode': ['Terraform'], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': ['Docker'], 'Collaboration': ['JIRA', 'Confluence'], 'Other': ['DevOps', 'Cloud'], 'FrSoftSkills': ['Collaboration'], 'EnSoftSkils': ['Collaboration']}","{'JobDetail': [], 'TypeContract': [], 'Salary': ['Package'], 'Level': [], 'Experience': ['a', 'n', 's', '5', '5', '5']}"
DATA ENGINEER (H/F),SFR,"Paris, √éle-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-h-f-at-sfr-3879318123?position=7&pageNum=0&refId=%2Bft0CQksufPV00p2d83arQ%3D%3D&trackingId=y1mAPo3%2B5hAo763%2B7x%2FWTg%3D%3D&trk=public_jobs_jserp-result_search-card,"En tant que Data Ing√©nieur exp√©riment√©, vous occuperez un r√¥le essentiel dans notre √©quipe Data Science.
Vous serez responsable de la conception, du d√©veloppement et de la maintenance des pipelines de donn√©es ainsi que de l'int√©gration de sources de donn√©es multiples.
Votre expertise sera cruciale pour garantir une gestion efficace des flux de donn√©es, ainsi que pour faciliter l'analyse et la visualisation des donn√©es en plus du support aux data scientists vos missions seront les suivantes :
Architecture projet des donn√©es
: Concevoir et d√©velopper des architectures projet de donn√©es robustes, √©volutives et performantes pour int√©grer et g√©rer de grandes quantit√©s de donn√©es provenant de sources multiples. Assurer la fiabilit√©, l'√©volutivit√© et la s√©curit√© des flux de donn√©es entrant d‚Äôun projet Data Science.
Int√©gration des donn√©es
: √âlaborer des pipelines de donn√©es efficaces pour l'extraction, la transformation et le chargement des donn√©es (via notre Framework ELT/ETL interne) provenant de diff√©rentes sources. Mettre en place des processus d'int√©gration automatis√©s et veiller √† la qualit√© des donn√©es.
Gestion des bases de donn√©es
: Concevoir et optimiser des bases de donn√©es pour r√©pondre aux besoins analytiques et de reporting. Assurer la performance, la disponibilit√© et la s√©curit√© des bases de donn√©es, ainsi que la gestion efficace des requ√™tes.
Collaboration interfonctionnelle
: Support des Data Scientists, vous travaillerez avec les √©quipes business pour comprendre leurs besoins et fournir des conseils et des recommandations bas√©s sur les donn√©es.
Optimisation des performances
: Surveiller et optimiser les performances des pipelines de donn√©es, des bases de donn√©es et des requ√™tes. Identifier les goulots d'√©tranglement et les points d'optimisation, et proposer des am√©liorations pour garantir des performances optimales.
S√©curit√© et conformit√©
: Veiller √† ce que les donn√©es soient trait√©es et stock√©es conform√©ment aux normes de s√©curit√© et de confidentialit√©. Mettre en place des m√©canismes de s√©curit√© pour prot√©ger les donn√©es sensibles et garantir la conformit√© aux r√©glementations en vigueur.
Votre profil :
Vous avez un
Dipl√¥me universitaire en informatique, en g√©nie logiciel, en science des donn√©es ou dans un domaine connexe et vous avez √† minima 5 ans d'exp√©rience en tant que Data Ing√©nieur.
Vous poss√©dez √©galement une solide ma√Ætrise des technologies et des outils suivants :
Hadoop, Spark, SQL, Kafka, GCP BigQuery,
De plus vous avez une bonne compr√©hension des architectures, des mod√®les et des concepts de base de donn√©s avec une exp√©rience avanc√©e dans la mise en ≈ìuvre de pipelines ETL et dans la gestion de bases de donn√©es.
Vos connaissances en mati√®re de s√©curit√© des donn√©es, de conformit√© aux r√©glementations ainsi que vos comp√©tences en programmation scripting et en d√©veloppement logiciel seront un plus.
Vos excellentes comp√©tences en communication seront des qualit√©s appr√©ci√©es et
un niveau d'anglais (appliqu√©e au domaine technique) est un plus.
Show more
Show less","{'ProgLanguage': ['R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': ['Hadoop', 'Spark'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'DBMS': ['BigQuery'], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': [], 'FrSoftSkills': ['Communication', 'Collaboration'], 'EnSoftSkils': ['Communication', 'Collaboration']}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's', '5', '5', '5']}"
Data engineer - F / H,United Robotics Group,"Paris, √éle-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-f-h-at-united-robotics-group-3891680780?position=8&pageNum=0&refId=%2Bft0CQksufPV00p2d83arQ%3D%3D&trackingId=o85f1mh3uictmPWka3k2%2FQ%3D%3D&trk=public_jobs_jserp-result_search-card,"Bienvenue chez
Aldebaran
, leader europ√©en de la robotique
au sein du groupe
United Robotics Group
.
Nous concevons et industrialisons des robots innovants avec une vision soci√©tale ambitieuse pour fa√ßonner un monde plus humain. Depuis 2005, nous sommes √† l'avant-garde de l'interaction homme-robot avec des produits embl√©matiques tels que NAO et Pepper.
Notre dernier-n√©,
Plato
,
incarne notre engagement envers la technologie de pointe et la s√©curit√©,
fabriqu√© en France avec des composants europ√©ens.
Rejoignez nos √©quipes multiculturelles et dynamiques pour √™tre au c≈ìur de la r√©volution de la robotique.
Si vous √™tes passionn√©.e par la robotique et l'intelligence artificielle, et que vous souhaitez contribuer √† fa√ßonner l'avenir, nous vous offrons une exp√©rience enrichissante et stimulante.
En tant que membre de notre √©quipe, vous b√©n√©ficierez d'une culture d'entreprise ax√©e sur le sens de ce que nous faisons et valorisant la responsabilit√© sociale et environnementale.
Chez Aldebaran, nous valorisons l'innovation, la diversit√© et l'√©galit√© et encourageons chacun.e √† √™tre ouvert.e, authentique, courageux.se, responsable et engag√©.e.
Finalit√© du poste
Au sein de l'√©quipe Cloud-Online Services, le Data engineer int√©grera l'√©quipe Data, responsable du d√©veloppement des produits destin√©s √† la collecte, aux process et √† l'exploitation des donn√©es de nos robots.
Il aura pour r√¥le de d√©finir et d'impl√©menter des services data, sur une infrastructure Cloud AWS, supportant des services en ligne qui g√®rent les robots du groupe.
Missions principales
Le Data engineer aura pour responsabilit√©s de :
√©valuer les choix d'architecture et de solutions techniques lors de la mise en place de PoC,
concevoir et d√©velopper des services Data en respectant la sp√©cification fonctionnelle et la m√©thodologie agile,
agr√©ger et stocker de grandes quantit√©s de donn√©es,
mettre en place des solutions de data processing,
int√©grer/d√©velopper des outils de visualisation de donn√©es et analyser les KPI,
d√©velopper, tester, s√©lectionner et mettre en production des algorithmes qui permettent de r√©pondre aux besoins,
r√©aliser des analyses de donn√©es,
mettre en place des tests de charge et fonctionnels pour les solutions Data,
investiguer et corriger les bugs remont√©s par les utilisateurs,
contribuer √† la mise en place de l'infrastructure et outil de d√©ploiement (CI/CD)
Rejoignez-nous pour faire partie d'une aventure passionnante o√π Pepper, NAO, Plato et leurs futurs successeurs attendent votre contribution pour repousser les limites de la technologie robotique !
Requirements
Pour la bonne ex√©cution des missions confi√©es, vous t√©moignez d'au moins 6 ans d'exp√©rience en tant que d√©veloppeur sur des projets data en Cloud en Python et Spark et avec comme Cloud provider AWS.
Comp√©tences demand√©es :
Bonne compr√©hension des technologies d'infrastructure et de d√©ploiement,
Comp√©tences techniques sur les services AWS : IOT core , Glue, lambda, Kinesis, S3, RDS,
Bonne compr√©hension technique dans la mise en place et l'automatisation de tests de charge et fonctionnels,
Bonne maitrise d'outils BI ou de dashboarding (POWER BI, TABLEAU, QUICKSIGHT)
Bonne connaissance et une exp√©rience pratique de Scrum\Scrumban et des m√©thodes agiles,
Une certification AWS sera appr√©ci√©e,
Un niveau de fran√ßais et d'anglais courant est indispensable,
Des exp√©riences dans des environnements fortement internationaux sont un plus
Benefits
Nos principaux avantages :
Une culture du bien-√™tre en entreprise qui a fait ses preuves (budget c√©l√©bration et moments de convivialit√© par √©quipes et directions, restauration collective de qualit√©, environnement de travail agr√©able)
Un engagement fort en mati√®re de responsabilit√© sociale et environnementale (promotion de l'√©galit√© professionnelle, performance de notre plan diversit√© et inclusion, r√©f√©rent handicap, fresque du num√©rique)
Une culture du t√©l√©travail encadr√©e de mani√®re appropri√©e !
Tous nos postes sont ouverts aux personnes en situation de handicap.
Show more
Show less","{'ProgLanguage': ['Python', 'R', 'Go'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': ['Spark'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': ['Tableau', 'Power BI'], 'Statistics': [], 'CloudComputing': ['AWS'], 'DevTools': [], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Cloud', 'CI/CD'], 'FrSoftSkills': [], 'EnSoftSkils': []}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's', '6', '6', '6']}"
Data Engineer H/F,Thales,"Lyon, Auvergne-Rh√¥ne-Alpes, France",https://fr.linkedin.com/jobs/view/data-engineer-h-f-at-thales-3903089036?position=9&pageNum=0&refId=%2Bft0CQksufPV00p2d83arQ%3D%3D&trackingId=o7a3Ej%2Fj5vAgLZ73Mk3WMg%3D%3D&trk=public_jobs_jserp-result_search-card,"üì¢ Nous recherchons un(e) Data Engineer, bas√©(e) √† Lyon
üëâQuelques mots sur les activit√©s num√©riques de Thales Lyon :
Les activit√©s num√©riques repr√©sentent une entit√© rattach√©e au groupe Thales, sp√©cialis√©e dans l‚ÄôIT et pr√©sente au national.
L‚Äôagence de Lyon adresse divers sujets d‚Äôexpertise : ing√©nierie logiciels, cybers√©curit√©, infog√©rance des infrastructures et transformation digitale.
üéØ
Votre r√¥le et missions
En nous rejoignant, vous int√©grerez le centre de comp√©tences
Augmented data
,
sp√©cialis√© dans la conception, le d√©veloppement et l‚Äô√©volution d‚Äôapplications data centr√©es. Vous y boosterez votre carri√®re en travaillant sur des technologies telles que
Spark, Elasticsearch, Kube ...
le plus souvent dans un environnement
Agile
.
Dans le cadre des projets que nous op√©rons aujourd‚Äôhui :
- Vous contribuerez √† la conception, au maintien, √† la scalabilit√© des plateformes d‚Äôanalyse de donn√©es au travers de votre expertise sur les sujets data (base de donn√©es, gestion de flux, ETL ‚Ä¶)
- Vous contribuerez √† la conception et √† la mise en production des pipelines d‚Äôanalyses et de transformations de donn√©es en veillant √† leur bonne adaptation aux besoins m√©tiers et aux contraintes techniques du client
- Vous pourrez intervenir sur des sujets de visualisations, dans le but de notamment accompagn√©es nos clients sur la conception de Dashboard m√©tier intelligent ‚Ä¶
- Vous serez √©galement amen√©es √† √©changer directement avec des DevOps/Datascientist pour la mise en place, l‚Äôint√©gration des pipelines et l‚Äô√©laboration des algorithmes de traitements de donn√©es.
- A l‚Äô√©chelle du d√©partement, Vous serez un acteur majeur du d√©veloppement de notre activit√© et du lancement de nouveaux projets de valorisation de donn√©es.
üôã‚Äç‚ôÄÔ∏è üôã‚Äç‚ôÇÔ∏è
Votre profil
De formation Bac +5 en informatique (√©cole d‚Äôing√©nieur, Master ou √©quivalent), vous justifiez d‚Äôune premi√®re exp√©rience r√©ussie sur un projet data ? Vous souhaitez participer √† la conception et intervenir sur des solutions de r√©cup√©ration et d‚Äôexploitation de donn√©es m√©tiers dans des contextes critiques et hautement s√©curis√©s ?
Autonome, dynamique, organis√©(e) et proactif(ve), vous souhaitez √©voluer au sein d‚Äô√©quipes passionn√©es par l‚Äôexploration et l‚Äôint√©gration des technologies nouvelles au service des m√©tiers de nos clients ?
Vous avez des comp√©tences qui couvrent les domaines suivants :
Mise en place et gestion de base de donn√©es (SQL, Elasticsearch, Clickhouse ...)
Langages de programmations (Java, Python)
Gestion de flux (Kafka, flink, logstash ‚Ä¶)
Environnements big Data (Spark/hadoop )
Principes et outils de type ETL
Vous √™tes de plus int√©ress√©(e):
Par les environnements containeris√©s (docker, kubernetes, helm ...)
Les concepts DevOps (Ansible, CI/CD...)
Les sujets de Datavisualisation (Vega, Kibana, python librairies...)
Vous aimez travailler en √©quipe ? Vous √™tes reconnu(e) pour vos qualit√©s relationnelles et vos capacit√©s de vulgarisation ?
Alors notre poste d‚ÄôIng√©nieur(e) Data(H/F) est fait pour vous !
üôå
Votre carri√®re chez Thales
Diff√©rentes opportunit√©s vous permettront de d√©couvrir d'autres domaines ou sites. Vous pourrez √©voluer et d√©velopper vos comp√©tences dans diff√©rents domaines.
Explorez un espace attentif au d√©veloppement personnel.
D√©veloppez vos talents dans un autre domaine du groupe Thales, en d√©couvrant de nouveaux produits, de nouveaux clients, un nouveau pays ou en vous orientant vers une solution plus complexe.
Choisissez entre une expertise technique ou un parcours de leadership.
Vous travaillerez dans une entreprise r√©solument humaine avec des valeurs fortes comme la s√©curit√© au travail, l‚Äô√©galit√© Homme/Femme et l‚Äô√©quilibre vie personnelle/professionnelle (Accord T√©l√©travail).
Rattach√©(e) √† la Convention m√©tallurgie, vous b√©n√©ficierez aussi de ses multiples avantages (‚Ä¶)
Vous souhaitez en savoir plus ?
N‚Äôh√©sitez pas √† contacter notre √©quipe de recrutement ou nos √©quipes directement.
Show more
Show less","{'ProgLanguage': ['Python', 'Java', 'Scala', 'R', 'Go'], 'DataBase': ['SQL', 'Elasticsearch'], 'DataAnalytics': ['R'], 'BigData': ['Hadoop', 'Spark', 'Flink'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git', 'Docker'], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': ['Ansible', 'Kubernetes'], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': ['Docker', 'Kubernetes'], 'Collaboration': [], 'Other': ['DevOps', 'Big Data', 'CI/CD'], 'FrSoftSkills': ['Leadership'], 'EnSoftSkils': ['Leadership']}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's']}"
Data Engineer - Mod√©lisation SQL - F/H,Orange Business,Greater Lille Metropolitan Area,https://fr.linkedin.com/jobs/view/data-engineer-mod%C3%A9lisation-sql-f-h-at-orange-business-3916551577?position=10&pageNum=0&refId=%2Bft0CQksufPV00p2d83arQ%3D%3D&trackingId=aPXCR7ZAmAmtcmlXkv%2FYRA%3D%3D&trk=public_jobs_jserp-result_search-card,"Et si Business & Decision et Orange Business conjuguaient leurs forces pour devenir l‚Äôun des leaders europ√©ens de la Data transformation ?
Nous l‚Äôavons fait ! Notre alchimie nous positionne comme un acteur unique intervenant sur toutes les √©tapes du voyage de la donn√©e.
Depuis 30 ans, Business & Decision, entit√© de Digital Services s'est impos√©e comme un partenaire strat√©gique pour la transformation Data de nombreux clients, dans des secteurs tr√®s vari√©s. Digital Services est aujourd‚Äôhui l‚ÄôESN d‚ÄôOrange Business alliant les expertises historiques Cloud et Digital d‚ÄôOrange ainsi que le c≈ìur de m√©tier Data/IA de Business & Decision. Son but est d‚Äôaccompagner les entreprises et les acteurs publics dans leur transformation gr√¢ce aux 4000 experts pr√©sents dans plusieurs grandes villes fran√ßaises comme Montpellier, Niort, Lyon, Bordeaux, Lille et Toulouse ‚Ä¶
Description du poste
Orange Business, recherche pour son site de Lille, son futur Data Engineer pour rejoindre sa team Data.
Votre quotidien ?
En int√©grant Orange Business, vous pouvez participer √† une grande diversit√© d‚Äôactivit√©s dans la Data. En voici un aper√ßu :
Au d√©marrage du projet :
Recueillir et analyser les besoins du client
R√©diger les sp√©cifications fonctionnelles et techniques
Estimer les charges
Pendant la phase de r√©alisation :
Mod√©liser des datawarehouses et datamart (int√©gration de flux et consolidation des donn√©es)
D√©velopper les proc√©dures d‚Äôalimentation (ETL)
D√©velopper en SQL / PLSQL / Shell
Garantir la qualit√© des donn√©es et leur disponibilit√©
R√©aliser la recette et les tests
Suivre et mettre en production
En fonction de votre √©volution et de nos enjeux, vous pouvez aussi √©voluer sur des missions transverses (conseil, coaching, avant-vente, formation, audit, etc.). La prise d‚Äôinitiative est toujours la bienvenue !
Qualifications
Vous poss√©dez 5 ans d'exp√©rience ou plus dans la mise en ≈ìuvre de projets d√©cisionnels et en mod√©lisation.
Vous avez de s
olides comp√©tences en d√©veloppement SQL
(job, scripting, d√©ploiement) ainsi que sur Python.
Envie d‚Äôapprendre de nouvelles technos ? Vous souhaitez partager vos comp√©tences et b√©n√©ficier des expertises de la Team Orange Business ?
Outre l‚Äôaspect technique, c‚Äôest une personnalit√© qui est recherch√©e !
Show more
Show less","{'ProgLanguage': ['Python', 'R'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': ['Orange'], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git'], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Cloud'], 'FrSoftSkills': [], 'EnSoftSkils': ['Initiative']}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's', '30', '30', '30']}"
Data Engineer / MLOps (H/F),DC CONSULTANTS,"Paris, √éle-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-mlops-h-f-at-dc-consultants-3904597462?position=11&pageNum=0&refId=%2Bft0CQksufPV00p2d83arQ%3D%3D&trackingId=%2BhGtpWiBTPpEhfm1ou2QJg%3D%3D&trk=public_jobs_jserp-result_search-card,"Cette offre d‚Äôemploi est fournie par P√¥le emploi
Description
Le data engineer est celui qui b√¢tit d'√©normes r√©servoirs de donn√©es pour les stocker et les tester. Ensuite, son principal travail consiste √† g√©rer des syst√®mes de traitement et des bases de donn√©es √† grande √©chelle et de s'assurer que tout fonctionne. Vous savez traiter des donn√©es en vous appuyant sur la data visualisation et des mod√®les ML, vous savez √©galement d√©velopper des fonctionnalit√©s n√©cessaires et les d√©ployer sur le cloud. Vos responsabilit√©s : Intervenir aupr√®s des √©quipes de nos clients pour d√©livrer des services DATA Vous √™tes impliqu√©(e) dans l'engagement de l'√©quipe au quotidien et faites tout pour l'aider pour d√©livrer des fonctionnalit√©s en continue. Vous travaillez en √©troite relation avec les autres membres de l'√©quipe pour aider √† la cr√©ation des algorithmes de machine learning n√©cessaires pour les cas d'usages d√©velopp√©s pour les √©quipes m√©tier. Vous √©changerez de mani√®re continue avec les m√©tiers car nous pensons que la proximit√© avec le m√©tier est la clef pour toucher le bon besoin business. Vous savez d√©velopper et d√©ployer des solutions IT Vous participez √† mettre en place les nouveaux flux d'entr√©e et de sortie au sein de la plateforme data, et irez jusqu'au modeling et √† l'activation de la donn√©e.
PROFIL SOUHAIT√â
Exp√©rience
D√©butant accept√©
Savoirs et savoir-faire
Data engineer
D√©velopper une application en lien avec une base de donn√©es
Superviser et coordonner les r√©alisations, √©tudes ou d√©veloppements informatiques (collaborateurs, sous-traitants)
Concevoir et d√©velopper une solution digitale
V√©rifier la compatibilit√© des d√©veloppements produits avec les sp√©cifications
Savoir-√™tre professionnels
Faire preuve d'autonomie
Faire preuve de cr√©ativit√©, d'inventivit√©
Faire preuve de rigueur et de pr√©cision
Formations
Bac+5 et plus ou √©quivalents
Langue
Anglais
Fran√ßais
Source: Pole emploi (https://www.pole-emploi.fr)
Show more
Show less","{'ProgLanguage': ['R', 'Go'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git'], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['ML', 'Machine Learning', 'Cloud'], 'FrSoftSkills': ['Cr√©ativit√©'], 'EnSoftSkils': []}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': ['Bac+5'], 'Experience': ['a', 'n', 's']}"
Data Engineer EMEA (F/M/D),Flowdesk,"Paris, √éle-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-emea-f-m-d-at-flowdesk-3860942388?position=12&pageNum=0&refId=%2Bft0CQksufPV00p2d83arQ%3D%3D&trackingId=zlwZGVqGt82geU3XWImMvw%3D%3D&trk=public_jobs_jserp-result_search-card,"Flowdesk is seeking a highly motivated Data Engineer to join the team and managed by the Quentin, the Lead Data!
The data engineer will be an integral part of the growing data team, working closely with our trading and quantitative departments to provide a platform and tools to answer their analytical needs. The data platform revolves around Dagster deployed on Kubernetes for the orchestration, dbt on BigQuery for the transformations, and Looker for the visualization.
Among our current challenges, we are currently focusing on the real-time ingestion and processing of terabytes of market data.
Responsibilities
Design, build, and maintain efficient, scalable, and reliable batch and streaming data pipelines to support Flowdesk's trading infrastructure.
Develop and maintain data warehouses, data lakes, and other data management systems with a strong focus on logical and physical modeling.
Contribute early on to the definition of the data team's data products to maximize ease of access, data quality, and related documentation.
Collaborate with the software engineering team to integrate data-related functionality into Flowdesk's trading infrastructure and other applications.
Leverage cutting-edge data engineering technologies to continually improve the speed, reliability, and scalability of Flowdesk's data processing capabilities.
Develop and maintain strong processes and procedures for data quality control, data validation, data documentation and, data integration.
Collaborate with cross-functional teams including traders, developers, and compliance officers to ensure that all data used by Flowdesk is accurate, timely, and compliant with relevant regulations and requirements.
Requirements
Bachelor's or Master's degree in Computer Science, Engineering, or related field.
3+ years of experience in data engineering or related field.
Awareness of software, data, and analytics engineering best practices (e.g. programming standards, data modelization, code idempotency....)
General understanding of systems architecture and concepts (distributed computing, lake-house architecture, ci/cd workflows...)
Experience optimizing modern data warehousing platforms (BigQuery is a plus).
Strong communication skills and ability to work collaboratively in a fast-paced international environment.
Knowledge of the data engineering ecosystem (contribution to open source projects is a plus).
Strong analytical and problem-solving skills with a keen attention to detail.
Benefits
üåç International environment (English is the main language)
üöÉ 50% of transportation costs & a sustainable mobility agreement
üçî Swile lunch voucher (‚Ç¨9.25 per day, 60% covered)
üè• 100% Alan Blue covered for you and your children
üíª Top of the range equipment{{:}} Macbook, keyboard, laptop stand, 4K monitor & headphones
üéâ Team events and offsites
üîú Coming soon {{:}} gym memberships, international mobility & lot of other cool benefits !
Recruitment process
üëÄ Are you interested in this job but feel you haven't ticked all the boxes? Don't hesitate to apply and tell us in the cover letter section why we should meet!
üìù Here's what you can expect if you apply{{:}}
HR interview (30')
Technical test
Technical interview (60')
Chat with the Head of People (30') and the Head of Department (30')
On the agenda{{:}} discussions rather than trick questions! These moments of exchange will allow you to understand how Flowdesk works and its values. But they are also (and above all) an opportunity for you to present your career path and your expectations for your next job!
Show more
Show less","{'ProgLanguage': ['Scala', 'R'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'DBMS': ['BigQuery'], 'SoftBigDataProcessing': [], 'Automation': ['Kubernetes'], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': ['Kubernetes'], 'Collaboration': ['Teams'], 'Other': ['CI/CD'], 'FrSoftSkills': ['Communication'], 'EnSoftSkils': ['Communication']}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's']}"
Data Engineer (H/F),Web Transition,"Lille, Hauts-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-h-f-at-web-transition-3909147172?position=13&pageNum=0&refId=%2Bft0CQksufPV00p2d83arQ%3D%3D&trackingId=OUbzPye8cZqH4%2FhOKRyQPg%3D%3D&trk=public_jobs_jserp-result_search-card,"Web Transition, c‚Äôest qui ?
Fond√©e en 2011,
Web transition
est une entreprise de services num√©riques op√©rant sur le march√© de l‚ÄôIT/Digital !
Constituant une part essentielle de
MoOngy Digital Lab
, Web Transition accompagne ses clients grands comptes sur leurs projets de Webmarketing, de Design, Gestion de projet et √©galement en Data !
Notre objectif : nous implanter comme un acteur principal sur le march√© de la Transformation Digitale en accompagnant et valorisant les comp√©tences de nos collaborateurs !
Nous sommes convaincus que le succ√®s de MoOngy Digital Lab r√©side dans la somme des potentiels de nos √©quipes ü§ù
Ton √©quipe : La tribu Data
Parce qu‚Äôil est indispensable que tu puisses partager tes connaissances mais aussi en acqu√©rir de nouvelles, tu feras partie de l‚Äôune de nos tribus : celle de la Data. De plus, cela te permettra d‚Äô√™tre acteur dans le d√©veloppement et la strat√©gie de Web Transition. Ce syst√®me de co-r√©flexion et co-construction est un fondement essentiel chez nous !
Dans cette aventure, tu :
T‚Äôassures
de la ma√Ætrise de la donn√©e et est garant de la qualit√© de son utilisation (r√©f√©rencement, normalisation, et qualification)
Travailles
√† la compr√©hension et l'int√©gration des donn√©es en provenance des diff√©rents formats
des interfaces de flux
√©galement √† la d√©finition de la politique de la donn√©e et √† la structuration de son cycle de vie dans le respect des r√©glementations en vigueur
la supervision et l'int√©gration des donn√©es de diverse nature qui proviennent de ces sources multiples et v√©rifie la qualit√© des donn√©es qui entrent dans le Data Lake
Garantis
l'acc√®s qualitatif aux sources de donn√©es
Facilites
l‚Äôacc√®s aux donn√©es pour tes coll√®gues (data scientists, data analysts‚Ä¶)
Assistes
les autres √©quipes dans l'acc√®s et la compr√©hension des donn√©es des socles.
Rejoins-nous si tu as :
Exp√©rience d‚Äôau-moins 4 ans dans la Data
App√©tence √† la qualit√© des donn√©es.
Connaissance famili√®re des Datawarehouses.
Maitrise de Python, Oracle SQL, GCP/Power BI
Aisance avec les indicateurs, tu as une bonne capacit√© d'analyse et de r√©daction.
Ton savoir-√™tre :
Ouvert d‚Äôesprit
Rigoureux
Autonome
Respectueux des diff√©rences de chacun
Curieux
Proactif
Agile
Par o√π on commence ?
Un premier entretien RH d‚Äô1h pour comprendre ton parcours et tes aspirations
Un second entretien de 45 minutes avec l‚Äôun de nos Business Manager afin de valider tes comp√©tences et qu‚Äôil se projette sur l‚Äôune des missions qu‚Äôil pourrait te proposer
Un troisi√®me entretien de quelques minutes avec notre responsable d‚Äôagence pour te proposer d‚Äôint√©grer notre superbe Team Web !
3 entretiens en peu de temps, si ton profil correspond tu int√®greras tr√®s vite nos √©quipes üòâ
Pr√™t pour embarquer dans notre grande aventure humaine ? Deviens notre futur Weber en postulant √† cette offre ! Voici les avantages qui t‚Äôattendent en tant que Weber :
ü§© Des coll√®gues incroyables
üèÜ Certifi√©e Great Place to Work
üéÆ Des bureaux sympas (o√π vous serez toujours les bienvenus)
üéâ Des teambuilding et √©vents tous les mois
üíª Des tributs m√©tiers pour √©changer entre Weber du m√™me m√©tier
Des missions chez le client qui sont accompagn√©es et coach√©es par ton manager
Un accompagnement dans ton plan de carri√®re et tes envies de re skilling
ü§ì Un catalogue de formations certifiantes ouvert √† tous les salari√©s
üçΩÔ∏è Une carte tickets restaurant MyEdenred
‚ù§Ô∏è Une mutuelle GrasSavoye
üöé Une prise en charge des frais de transport √† 100%
Show more
Show less","{'ProgLanguage': ['Python', 'R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': ['Power BI'], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git'], 'Os': [], 'DBMS': ['Oracle'], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': [], 'FrSoftSkills': [], 'EnSoftSkils': []}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's', '4', '4', '4']}"
Data Engineer (H/F),Scalian,"Valbonne, Provence-Alpes-C√¥te d'Azur, France",https://fr.linkedin.com/jobs/view/data-engineer-h-f-at-scalian-3819563847?position=14&pageNum=0&refId=%2Bft0CQksufPV00p2d83arQ%3D%3D&trackingId=IXSu1ivtXv89J9PqmYqQ4Q%3D%3D&trk=public_jobs_jserp-result_search-card,"Ing√©nieur DATA / Data engineer (H/F)
Valbonne/Sophia-Antipolis
Type : CDI
Lieu : Locaux Scalian Sophia-Antipolis
T√©l√©travail : En fonction des possibilit√©s
Date de prise de poste : imm√©diatement ou en fonction de votre pr√©avis
Salaire : en fonction du profil - entre 40 et 48K Brut annuels (hors avantages Scalian)
Avantages Scalian : Accord d'entreprise t√©l√©travail, Tickets restaurants, Mutuelle groupe, accord am√©nagement temps de travail, compte √©pargne temps, accord de participation et int√©ressement groupe, programme cooptation et apports d'affaires, accompagnement parentalit√©, avantages CSE
Vous √™tes data engineer ou vous souhaitez le devenir !
Quel sera votre r√¥le ?
La port√©e de la mission comprend (sans toutefois s'y limiter) :
Science des donn√©es
Ing√©nierie des donn√©es
Analyse des donn√©es
G√©nie logiciel
Ce que cette exp√©rience va vous apporter
Vous √™tes autonome, vous avez le sens du service et de l‚Äôanalyse, vous √™tes impliqu√©, nous vous offrons une ouverture sur des projets complexes et une rapide √©volution de carri√®re. Vous rejoignez notre business unit √† Sophia Antipolis compos√©e d'environ 50 consultants, avec possibilit√© de t√©l√©travail en fonction des sujets.
Nous co-construisons votre trajectoire professionnelle et assurons votre mont√©e en comp√©tences.
Nous nous inscrivons ensemble dans la dur√©e, nous assurons votre mont√©e en comp√©tences et disposons d'une vari√©t√© de sujets passionnants.
Ce que nous recherchons chez vous
De formation sup√©rieure (Bac+5, √©cole ou universit√©), vous poss√©dez id√©alement une premi√®re exp√©rience r√©ussie dans ce domaine (d√©butants accept√©s), vous aimez le travail en √©quipe.
Comp√©tences requises
:
Etape d‚Äôanalyse : Comprendre l‚Äôarchitecture technique, les sources de donn√©es, les objectifs fonctionnels.
Etape de conception : Solution de conception avec un fort centrage sur les pipelines de donn√©es et les mod√®les ML et l‚Äôexposition des KPI via API
Mise en ≈ìuvre : Apr√®s les phases d‚Äôanalyse et de conception, proc√©der √† a mise en ≈ìuvre dans des technologies s√©lectionn√©es (Java,Scala,Python,Spark)
Cr√©er un code test√© et document√©
Techno : Linux, Shell, Hadoop, Scrum, Python, Spark, Scala
Pourquoi feriez-vous le grand saut ?
Parce que Scalian vous accompagne dans le d√©veloppement de votre carri√®re :
Programme d'onboarding complet sur 1 an avec votre manager et votre RH
Programme de formation (Scalian Academy, e-learning, webinaires et formations externes)
Communaut√©s techniques (Squads, Practices) afin de valoriser et d√©velopper votre expertise
√âv√©nements internes (Afterworks, Awards Dinner, Kick Off, Live Event du COMEX, Stand Up) et externes (participation √† des salons et forums sp√©cialis√©s dans nos domaines d‚Äôactivit√©s‚Ä¶)
Dispositif d‚Äôacc√©l√©ration d‚Äôacc√®s √† la mobilit√© interne et √† des √©changes internationaux type Erasmus
Parce que Scalian favorise la Qualit√© de Vie au Travail :
Certifications Great Place to Work¬Æ et Best Workplaces for Women¬Æ
Prime de cooptation, prime vacances, prise en charge par l‚Äôemployeur de 60% des titres-restaurant, Accord t√©l√©travail (jusqu‚Äô√† 2,5 jours par semaine indemnis√©s), RTT (dont une partie mon√©tisable), CSE (activit√©s ludiques, ch√®ques-cadeaux, ch√®ques vacances)
Berceaux en cr√®ches inter-entreprises
Don ou r√©ception de jours de cong√©s en cas de difficult√©s personnelles
Parce que Scalian d√©veloppe une politique RSE concr√®te et ambitieuse :
Mobilit√© durable (indemnit√© kilom√©trique v√©lo, leasing de v√©los √† assistance √©lectrique)
Actions environnementales (Fresque du Climat, Reforest'Action, Clean Up Day, m√©c√©nat ONF)
Postes ouverts aux personnes en situation de Handicap
Diverses politiques de diversit√©, d‚Äôinclusion et d‚Äôint√©gration mises en place
Scalian c‚Äôest aussi :
Une entreprise en tr√®s forte croissance qui, cr√©√©e en 1989, compte aujourd‚Äôhui plus de 5500 personnes
Des r√©f√©rences clients √† forte valeur ajout√©e aupr√®s de grands industriels fran√ßais (du CAC40) et internationaux
Un terrain de jeu o√π l‚Äôexpertise se conjugue avec audace, libert√© d‚Äôentreprendre et convivialit√©
Si vous aspirez √† un environnement de travail qui valorise autant votre bien-√™tre que votre d√©veloppement professionnel,
rejoignez-nous et exprimez pleinement votre talent !
Envie d'√©largir le cadre ?
Je suis Liza Djehel, Talent Acquisition Officer.
Si votre CV est retenu, je vous contacte pour un premier √©change t√©l√©phonique de 15 √† 20 minutes.
Nous d√©terminons ensemble si ce poste est en ad√©quation avec vos comp√©tences et surtout, avec vos attentes.
L'√©change est positif ? Nous convenons d'un entretien de 1h (en pr√©sentiel ou en visio) avec Lucas Daunar, Business Manager √† Sophia-Antipolis. Cet √©change permet de revenir en d√©tail sur vos comp√©tences, vos attentes, de vous pr√©senter le poste plus en d√©tail, et d'√©voquer d'autres opportunit√©s.
Nous pr√©voyons ensuite un rendez-vous technique de 1h (en pr√©sentiel ou en visio) avec un de nos responsable technique.
Enfin, nous vous pr√©sentons notre proposition d'embauche.
Notre processus de recrutement dure entre 15 et 30 jours
Show more
Show less","{'ProgLanguage': ['Python', 'Java', 'Scala', 'R'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': ['Hadoop', 'Spark'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': [], 'Os': ['Linux'], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['ML'], 'FrSoftSkills': [], 'EnSoftSkils': []}","{'JobDetail': [], 'TypeContract': ['CDI'], 'Salary': ['40'], 'Level': ['Bac+5'], 'Experience': ['a', 'n', 's']}"
Data Engineer,Thales,"Ollioules, Provence-Alpes-C√¥te d'Azur, France",https://fr.linkedin.com/jobs/view/data-engineer-at-thales-3902424527?position=15&pageNum=0&refId=%2Bft0CQksufPV00p2d83arQ%3D%3D&trackingId=e8Q2eToI0AsxE8EqsICG9Q%3D%3D&trk=public_jobs_jserp-result_search-card,"QUI SOMMES-NOUS ?
Thales est un leader mondial des hautes technologies comptant plus de 81 000 collaborateurs pr√©sents sur tous les continents. Le Groupe investit dans les innovations du num√©rique et de la ¬´ deep tech ¬ª ‚Äì big data, intelligence artificielle, connectivit√©, cybers√©curit√© et quantique ‚Äì pour construire un avenir de confiance, essentiel au d√©veloppement de nos soci√©t√©s, en pla√ßant l‚Äôhumain au c≈ìur des d√©cisions.
Thales propose des solutions, services et produits qui aident ses clients ‚Äì entreprises, organisations, Etats ‚Äì dans cinq grands march√©s vitaux pour le fonctionnement de nos soci√©t√©s : identit√© et s√©curit√© num√©riques, d√©fense, a√©ronautique, espace, et transport.
QUI ETES-VOUS ?
Dipl√¥m√© d‚Äôun Bac+5 en √©cole d‚Äôing√©nieur ou √©quivalent universitaire avec une sp√©cialisation en informatique, vous avez a
u moins 3 ans d'exp√©rience
dans les technologies Big Data.
Passionn√© par le
secteur de la D√©fense et du Naval.
CE QUE NOUS POUVONS ACCOMPLIR ENSEMBLE :
En tant que
Data Engineer,
vous jouerez un r√¥le cl√© dans la conception, le d√©veloppement et la maintenance de notre infrastructure de donn√©es, ainsi que dans la transformation et la gestion des flux de donn√©es.
VOS MISSIONS :
‚Ä¢ Concevoir, d√©velopper et d√©ployer des solutions Big Data en utilisant les technologies
Hadoop, Spark, Scala
.
‚Ä¢ Mettre en place des pipelines de donn√©es performants pour l'ingestion, le traitement et le stockage des donn√©es massives.
‚Ä¢ Collaborer √©troitement avec les √©quipes m√©tier pour comprendre leurs besoins en mati√®re d'analyse de donn√©es et proposer des solutions adapt√©es.
‚Ä¢ Optimiser les performances des clusters Hadoop pour garantir une exploitation efficace des donn√©es.
‚Ä¢ Assurer la qualit√© et la fiabilit√© des donn√©es trait√©es, en mettant en place des processus de validation et de nettoyage.
‚Ä¢ Identifier et r√©soudre les probl√®mes li√©s √† l'infrastructure Big Data et proposer des am√©liorations.
Innovation, passion, ambition : rejoignez Thales et cr√©ez le monde de demain, d√®s aujourd‚Äôhui.
Show more
Show less","{'ProgLanguage': ['Scala', 'R'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': ['Hadoop', 'Spark'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Big Data'], 'FrSoftSkills': ['Organisation'], 'EnSoftSkils': []}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': ['Bac+5'], 'Experience': ['a', 'n', 's', '3', '3', '3']}"
Data Engineer (H/F) | POEI,DataScientest.com,"Puteaux, √éle-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-h-f-poei-at-datascientest-com-3909358387?position=16&pageNum=0&refId=%2Bft0CQksufPV00p2d83arQ%3D%3D&trackingId=vFkLd0Q1fxKwro6mqN23Gg%3D%3D&trk=public_jobs_jserp-result_search-card,"Data Engineer (H/F) | POEI
Puteaux
CDI
Postuler
Retour
Datascientest Is Hiring!
Data Engineer (H/F) | POEI
√Ä propos
Vous √™tes demandeur d'emploi et vivement int√©ress√©(e) par les m√©tiers de la Data ?
Rejoignez DataScientest en int√©grant une formation 100% financ√©e par P√¥le Emploi afin d‚Äôacqu√©rir les comp√©tences cl√©s qui vous permettront de booster votre carri√®re en tant que Data Engineer Cloud, un m√©tier en tension et en plein essor.
Cette formation est certifi√©e par l'Ecole des Mines ParisTech, et inclut le passage de certifications √©diteurs (AWS, Microsoft Azure ou encore GCP) qui garantissent votre employabilit√©.
Apr√®s avoir suivi notre formation de Cloud Data Engineer, vous rejoindrez, en CDI , notre entreprise partenaire.
Les candidats retenus b√©n√©ficieront d‚Äôune formation intensive, enti√®rement prise en charge par le dispositif POEI (Pr√©paration Op√©rationnelle √† l‚ÄôEmploi Individuel) avec P√¥le-Emploi.
Descriptif du poste
En Tant Que Cloud Data Engineer, Vous Aurez Pour Missions De Proposer Les Meilleures Solutions Aux Entreprises Afin D'optimiser Leur Activit√©, √† Travers Les Missions Suivantes
D√©veloppement de solutions permettant de traiter des volumes importants de donn√©es,
Conception, collection et fabrication des donn√©es brutes,
Cr√©ation d'outils et algorithmes pour le traitement des donn√©es,
Pr√©paration des donn√©es pour le Data Analyst,
S√©curisation des Pipelines donn√©es pour les Data Analysts et Data Scientists,
Organisation de l'architecture du cloud
Profil recherch√©
Ce Que Nous Vous Offrons
Une certification de l'Ecole des Mines ParisTech
Un CDI aupr√®s d'un de nos partenaires, expert europ√©en dans le traitement et l'exploitation des donn√©es
Un salaire attractif √† la cl√© : 35 000‚Ç¨ √† 48 000‚Ç¨ selon le profil
**Votre profil : **
Issu(e) d‚Äôune fili√®re scientifique ou informatique vous disposez d'un bac+5 ou d‚Äôun dipl√¥me d‚Äôing√©nieur,
Vous disposez id√©alement d‚Äôune exp√©rience significative en d√©veloppement informatique, en architecture r√©seaux ou dans la Data,
Vous ma√Ætrisez un langage objet type Java, Python, C++, etc.
Vous √™tes inscrit(e) √† P√¥le Emploi
Informations compl√©mentaires
Type de contrat : CDI
Date de d√©but : 01 septembre 2023
Lieu : Puteaux
Niveau d'√©tudes : Bac +5 / Master
Exp√©rience : > 1 an
T√©l√©travail ponctuel autoris√©
Salaire : entre 35000‚Ç¨ et 48000‚Ç¨ / an
Vous √™tes int√©ress√© par cette offre ?
Postuler
Show more
Show less","{'ProgLanguage': ['Python', 'Java', 'C++', 'R', 'Go'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': ['AWS', 'Azure'], 'DevTools': [], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Cloud'], 'FrSoftSkills': ['Organisation'], 'EnSoftSkils': []}","{'JobDetail': [], 'TypeContract': ['CDI'], 'Salary': ['35'], 'Level': ['Bac+5'], 'Experience': ['a', 'n', 's']}"
Data Engineer (H/F),Technology & Strategy,"Lyon, Auvergne-Rh√¥ne-Alpes, France",https://fr.linkedin.com/jobs/view/data-engineer-h-f-at-technology-strategy-3881556102?position=17&pageNum=0&refId=%2Bft0CQksufPV00p2d83arQ%3D%3D&trackingId=keR%2B0XbNnomK7Eq890KL2Q%3D%3D&trk=public_jobs_jserp-result_search-card,"D√©couvrez Novencia
:
Expert en Data et Intelligence Artificielle, nous aidons nos clients √† exploiter et √† valoriser leurs donn√©es sous toutes ses formes en les accompagnant sur des projets de Data Analyse, Data Gourvernance, Data Architecture, Data Science, et Data Engineering‚Ä¶
Vous avez une solide exp√©rience de minimum 2 ans dans l'ing√©nierie des donn√©es et vous √™tes √† la recherche de nouveaux d√©fis ? Bouclez votre ceinture, la suite est pour vous !
Type de contrat : CDI
Lieu : Lyon
En qualit√© de Data Engineer (H/F), votre r√¥le sera :
Concevoir et proposer les solutions de d√©veloppement r√©pondant aux besoins fonctionnels et techniques des projets big data.
Tu participes √† la conception de solutions permettant le traitement de volumes importants de pipelines donn√©es.
R√©aliser ces solutions par l‚Äô√©criture de code, en respectant les m√©thodes et proc√©dures qualit√©s d√©finies au sein du d√©partement Technique.
Mise √† disposition s√©curis√© et lisible de la data.
S‚Äôassurer de la conformit√© fonctionnelle et technique de ces r√©alisations en effectuant les tests automatis√©s n√©cessaire et la mise en place de monitoring (syst√®me et qualit√©).
Assurer la maintenance des applicatifs / plateforme data science
Assurer une veille technologique
Vous disposez des comp√©tences suivantes :
Maitrise des plateformes Cloud (AWS, GCP ou Azure), de Scala et de SQL.
Un.e touche √† tout : poss√©dant des comp√©tences en langage Python/Spark, de bonnes capacit√©s de mod√©lisation, une forte app√©tence pour le Big Data
Fin.e connaisseur.euse : Data Engineer convaincu, tr√®s peu de secrets pour les clusters et pour les calculs parall√®les
Explorateur.trice : d√©couvre de nouvelles technos gr√¢ce √† une veille r√©guli√®re
D√©brouillard.e : rel√®ve de nouveaux d√©fis
Notre objectif commun est de co-construire votre carri√®re en fonction de vos aspirations et de vos comp√©tences.
Contactez-moi en message priv√© ou par mail √† s.ziki@technologyandstrategy.com !
Let's make it possible #together
*Nos postes sont ouverts aux personnes b√©n√©ficiant d‚Äôune Reconnaissance de la Qualit√© de Travailleur Handicap√© (RQTH). T&S Groupe encourage la diversit√© et l‚Äô√©galit√© sur le lieu de travail. Tous les candidats qualifi√©s H/F/* sont pris en consid√©ration pour un emploi sur un m√™me pied d'√©galit√©.
Show more
Show less","{'ProgLanguage': ['Python', 'Scala', 'R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': ['Spark'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': ['AWS', 'Azure'], 'DevTools': [], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Big Data', 'Cloud'], 'FrSoftSkills': [], 'EnSoftSkils': []}","{'JobDetail': [], 'TypeContract': ['CDI'], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's', '2', '2', '2']}"
Data Engineer (H/F),iPepperGroup,"Valbonne, Provence-Alpes-C√¥te d'Azur, France",https://fr.linkedin.com/jobs/view/data-engineer-h-f-at-ipeppergroup-3894091360?position=18&pageNum=0&refId=%2Bft0CQksufPV00p2d83arQ%3D%3D&trackingId=At5X5FDWn%2FtZtWcoeDpt6w%3D%3D&trk=public_jobs_jserp-result_search-card,"iPepper recrute pour l'un de ses clients une PME √©diteur de logiciel dans le domaine du voyage, un
Data Engineer (H/F)
passionn√©(e) et exp√©riment√©(e) pour rejoindre une √©quipe dynamique.
En tant qu'Ing√©nieur(e) Data, vous serez en charge d'extraire et de transformer des donn√©es, de construire et d'optimiser des pipelines de donn√©es, ainsi que de concevoir des visualisations de donn√©es intuitives et informatives.
Responsabilit√©s :
Concevoir, construire et maintenir des pipelines de donn√©es √©volutifs et efficaces pour transf√©rer des donn√©es entre des bases de donn√©es SQL et NoSQL.
D√©velopper et mettre en ≈ìuvre des processus ETL pour extraire, transformer et charger des donn√©es √† partir de diff√©rentes sources dans notre entrep√¥t de donn√©es.
Collaborer avec des √©quipes pluridisciplinaires pour comprendre les besoins en donn√©es et garantir la fourniture r√©ussie de solutions de donn√©es.
Optimiser et ajuster les pipelines de donn√©es existants pour la performance et la fiabilit√©.
Concevoir et d√©velopper des visualisations de donn√©es et des tableaux de bord pour fournir des insights exploitables aux parties prenantes.
Surveiller et r√©soudre les probl√®mes de pipelines de donn√©es, en veillant √† la qualit√© et √† l'int√©grit√© des donn√©es.
Profil recherch√© :
Dipl√¥me universitaire en informatique, en ing√©nierie ou dans un domaine connexe.
Exp√©rience av√©r√©e en tant que Data Engineer ou dans un r√¥le similaire, avec un accent particulier sur la construction de pipelines de donn√©es et de processus ETL.
Compr√©hension solide des bases de donn√©es
SQL
et
NoSQL
, y compris la mod√©lisation des donn√©es et la conception de sch√©mas.
Ma√Ætrise des langages de programmation tels que
Python, Java ou Scala.
Exp√©rience avec des outils de visualisation de donn√©es tels que
Tableau, Power BI.
Solides comp√©tences en analyse et en r√©solution de probl√®mes, avec la capacit√© de traduire des donn√©es complexes en insights exploitables.
Excellentes comp√©tences en communication et en collaboration, avec la capacit√© de travailler efficacement dans un environnement d'√©quipe pluridisciplinaire.
Show more
Show less","{'ProgLanguage': ['Python', 'Java', 'Scala', 'R'], 'DataBase': ['SQL', 'NoSQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': ['Tableau', 'Power BI'], 'Statistics': [], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': [], 'FrSoftSkills': ['Communication', 'R√©solution de probl√®mes', 'Collaboration'], 'EnSoftSkils': ['Communication', 'Collaboration']}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's']}"
Data Engineer (H/F),MP DATA,"Toulouse, Occitanie, France",https://fr.linkedin.com/jobs/view/data-engineer-h-f-at-mp-data-3908719610?position=19&pageNum=0&refId=%2Bft0CQksufPV00p2d83arQ%3D%3D&trackingId=sNdPCof08QHf2fGw%2BLf2Ug%3D%3D&trk=public_jobs_jserp-result_search-card,"MP DATA est une soci√©t√© sp√©cialis√©e dans l‚Äôacquisition, le traitement, et la valorisation des donn√©es.
Depuis sa cr√©ation en 2015, MP DATA accompagne ses clients, majoritairement industriels, dans le management de leur performance et l‚Äôexploitation de leurs donn√©es.
Les collaborateurs, tous issus de grandes √©coles, incarnent au quotidien les valeurs d‚ÄôExcellence, de Partage et d‚ÄôEngagement.
Ils associent savoir-faire technique, m√©thodologie et passion et mettent leurs comp√©tences au service de missions et projets au sein de grands groupes fran√ßais.
MP DATA accompagne ses clients sur toute la chaine au travers de 3 p√¥les d‚Äôexpertise : Conseil et Strat√©gie, Infrastructure & CloudOPS, Data Science.
Chez MP DATA, les √©quipes commerciales cherchent des missions en fonction des envies des collaborateurs et non pas l‚Äôinverse. Les consultants sont accompagn√©s dans tous leurs projets, de la mobilit√© g√©ographique, au changement de secteur d‚Äôactivit√© en passant par le d√©veloppement de nouvelles comp√©tences.
Rejoindre MP DATA, c‚Äôest la garantie de travailler sur des sujets passionnants avec un cadre technique fort.
Descriptif du poste :
Nous recherchons un Data Engineer exp√©riment√© pour rejoindre notre √©quipe.
En tant que Data Engineer, vous serez responsable de la conception, du d√©veloppement et de la mise en ≈ìuvre de pipelines de traitement de donn√©es en temps r√©el √† grande √©chelle.
Vous travaillerez avec des technologies telles que Kafka, Flink, Kinesis et vous utiliserez les services du cloud AWS pour stocker et traiter les donn√©es.
Vos responsabilit√©s :
Utiliser Kafka pour le traitement de flux de donn√©es en temps r√©el √† grande √©chelle, en travaillant avec les producteurs, les consommateurs et les topics.
Mettre en ≈ìuvre des pipelines de traitement de donn√©es en streaming avec Flink, en appliquant des transformations complexes et en g√©rant les √©tats.
√âcrire du code efficace et maintenable en Java / Python pour manipuler et analyser les donn√©es en temps r√©el.
Utiliser Kubernetes pour d√©ployer et g√©rer des applications conteneuris√©es √† grande √©chelle, en assurant la r√©silience et l‚Äô√©volutivit√© des services.
Utiliser les services AWS tels que Amazon S3, AWS Lambda, Elastic Kubernetes Service (EKS), Elastic Container Service (ECS) et Elastic Compute Cloud (EC2) pour le stockage, le traitement et le calcul des donn√©es en temps r√©el.
Suivre les meilleures pratiques pour une utilisation efficace du cloud, en assurant la gestion des co√ªts, la s√©curit√© des donn√©es et la disponibilit√© des services.
Collaborer avec l‚Äô√©quipe de d√©veloppement logiciel et la gestion de projets pour assurer un flux de d√©veloppement fluide et une livraison efficace des fonctionnalit√©s.
Bon √† savoir :
CDI / ASAP / Toulouse
Profil recherch√©:
Nous recherchons un candidat dipl√¥m√© d'une grande √©cole d'Ing√©nieur avec une premi√®re exp√©rience.
Comp√©tences n√©cessaires :
Exp√©rience significative dans un environnement industriel en mode DevOps, avec des outils tels que CICD, gitlab, Jenkins, Sonar, Nexus, XLdeploy, Camunda, etc.
Ma√Ætrise des langages de programmation tels que Python, Java et expertise dans l‚Äô√©criture et l‚Äôoptimisation du code SQL
Ma√Ætrise du fran√ßais et bonne maitrise de l‚Äôanglais.
Capacit√© √† travailler en √©quipe et esprit d‚Äô√©quipe.
Le processus de recrutement se d√©roule en 3 entretiens :
Prise de contact
1er entretien : Pr√©sentation et projet du candidat + pr√©sentation MP DATA
2√®me entretien : Entretien de qualification technique
3√®me entretien : Rencontre avec les √©quipes dans les locaux MP DATA + Proposition de collaboration
Show more
Show less","{'ProgLanguage': ['Python', 'Java', 'R'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': ['Flink'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': ['AWS'], 'DevTools': ['Git', 'Jenkins'], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': ['Kubernetes'], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': ['Kubernetes'], 'Collaboration': [], 'Other': ['DevOps', 'Cloud'], 'FrSoftSkills': ['Collaboration'], 'EnSoftSkils': ['Collaboration']}","{'JobDetail': [], 'TypeContract': ['CDI'], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's']}"
Data Engineer / Ops H/F,Chantelle,"Cachan, √éle-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-ops-h-f-at-chantelle-3909858815?position=20&pageNum=0&refId=%2Bft0CQksufPV00p2d83arQ%3D%3D&trackingId=C4lYKI4iYuo8FJXqkCQS6g%3D%3D&trk=public_jobs_jserp-result_search-card,"La Direction des Syst√®mes d'Information et du Digital du groupe Chantelle recherche son/sa futur.e Data Engineer / Ops H/F, pour le lancement du grand chantier de r√©novation de l'architecture Data : la bascule de l'int√©gralit√© de son Data Warehouse vers Google Big Query.
Vos Missions Sont Les Suivantes
Vous concevez et mettez en ≈ìuvre une infrastructure autour de Google Cloud Platform permettant de collecter, transformer, charger et historiser les donn√©es g√©n√©r√©es par l'entreprise.
Vous travaillez en √©troite proximit√© avec le lead data engineer de l'√©quipe, l'√©quipe
int√©gration en charge du d√©veloppement des interfaces, avec notre √©quipe de Data Analysts qui sont en charge d'exposer cette donn√©e au reste de l'entreprise ainsi qu'avec l'√©quipe technique en charge des infrastructures transverses.
Vous collaborez avec l'ensemble des domaines fonctionnels de la DSI (MasterData, Supply Chain, Manufacturing, B2B, et B2C, Finance ...) dans le cadre des projets men√©s par le Groupe.
Vous apportez l'assertivit√© technique sur tous les sujets d'architecture data, et √™tes force de proposition, par exemple choix de mise en place de pipeline temps r√©els ou au contraire de flux de donn√©es en mode batch, ou bien encore stockage sur Big Query / Big Table en fonction des cas d'usage.
Vous d√©finissez ces √©l√©ments structurants, en justifiant vos choix, et les
mettez en ≈ìuvre.
Les enjeux sont forts et les use cases nombreux √† l'√©chelle du groupe : am√©lioration du pilotage de nos stocks en dimensionnant mieux nos quantit√©s √† produire et nos assortiments, par magasin, meilleure ad√©quation des achats mati√®res premi√®res vs objectifs de stocks, produits finis, personnalisation de nos sites e-commerce en temps r√©el en fonction de nos profils client, refonte de nos flux / Apisation, ...
Show more
Show less","{'ProgLanguage': ['R', 'Go'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': ['Google Cloud Platform'], 'DevTools': ['Git'], 'Os': [], 'DBMS': ['Big Query'], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Cloud'], 'FrSoftSkills': [], 'EnSoftSkils': []}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's']}"
Data Engineer,AFD Technologies,"Lille, Hauts-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-at-afd-technologies-3899625641?position=21&pageNum=0&refId=%2Bft0CQksufPV00p2d83arQ%3D%3D&trackingId=M4UbKAdnXPl6W5s4N3NyEw%3D%3D&trk=public_jobs_jserp-result_search-card,"AFD.TECH part of Accenture
est le sp√©cialiste du conseil en transformation digitale des grandes entreprises üöÄ.
A ce jour, le Groupe est compos√© de 2.000 talents r√©partis dans 3 pays (France, Belgique & Maroc) üåé pour un chiffre d‚Äôaffaires annuel de 125M‚Ç¨ !
Nos Talents d‚Äôabord üòé:
Les Talents d‚ÄôAFD.TECH part of Accenture sont au c≈ìur de la strat√©gie du Groupe et il est primordial pour nous que chaque collaborateur trouve du sens dans son travail.
Au-del√† de proposer une carri√®re ambitieuse et personnalis√©e √† nos Talents, nous avons √† c≈ìur de leur offrir un environnement de travail flexible (remote), inclusif et √©panouissant dans tous nos bureaux (Paris, Bruxelles, Rabat, Lyon, Strasbourg, Lille, Nantes, Toulouse, Marseille, Bordeaux et Rennes)üåç.
Avec 20% de croissance par an et plus de 20 ans d‚Äôexistence, AFD.TECH part of Accenture est devenu l‚Äôacteur incontournable du march√© des infrastructures informatiques, r√©seaux et t√©l√©coms.
Notre proposition de valeur ? Intervenir sur l‚Äôensemble du cycle de vie de projets complexes, pour des clients grands comptes, venant de secteurs tels que la banque, le ferroviaire, les m√©dias, t√©l√©coms, etc (comme la Soci√©t√© G√©n√©rale, Bouygues Telecom, Orange, Thales et bien d‚Äôautres encore !)üë©üèª‚Äçüíª.
Nous rejoindre est une formidable aventure humaine : nous vous proposons un poste un poste de
Data Engineer en CDI
, au sein de notre agence Lilloise.
Vos missions ‚úÖ:
En tant que Data Engineer pour l'un de nos clients grands comptes, votre r√¥le s‚Äôarticulera autour de diff√©rents axes :
Appr√©hender le contexte et les enjeux m√©tier du client.
Collaborer avec les √©quipes m√©tier pour comprendre les exigences en mati√®re de donn√©es.
D√©finir des architectures data.
Concevoir et mettre en place des pipelines de donn√©es.
Construire des flux de donn√©es complexes.
Vous travaillerez dans une mission √† forte valeur ajout√©e et de longue dur√©e (minimum 1 an et demi).
Votre profil‚úÖ:
Vous ma√Ætrisez le langage SQL, les ETL et les ELT.
Vous aimez automatiser, mettre en place vos data pipelines et ma√Ætriser les technologies: CI/CD, Terraform, Github, Python, Kafka.
Vous poss√©dez des comp√©tences en data visualisation : Business Objects, Qlikview, Qlik Sense, PowerBI ou Data Studio.
Vous connaissez Google Cloud Platform (GCS, BigQuery).
Vous √™tes dipl√¥m√©(e) d‚Äôune formation BAC + 5.
Vous avez une premi√®re exp√©rience significative dans la data engineering (
minimum 3 ans
).
Vous projetez votre carri√®re dans un cabinet de conseil exigent et successful, qui vous permettra de d√©velopper votre esprit entrepreneurial et de r√©pondre √† vos ambitions.
Ce que nous offrons chez AFD.TECH part of Accenture ü§ó:
Une politique de flexibilit√© dans votre organisation et un bon √©quilibre de vie üèÉ‚Äç‚ôÇÔ∏è.
Des avantages plus que comp√©titifs üí∞.
Un accompagnement et un suivi r√©gulier durant tout votre parcours chez AFD.TECH (Launchpad, Linkers, rookies, etc‚Ä¶).
Un √©tat d‚Äôesprit familial et de la proximit√© entre tous üë®‚Äçüë©‚Äçüëß‚Äçüë¶.
Des moments de convivialit√© toute l‚Äôann√©e üçæ (√©vent en √©quipe, s√©minaire annuel, sports collectifs etc.).
Un parcours d‚Äô√©volution sur mesure üîº.
A tr√®s bient√¥t chez AFD.TECH part of Accenture!
Show more
Show less","{'ProgLanguage': ['Python', 'R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': ['Orange'], 'DataSerialization': [], 'DataVisualization': ['PowerBI'], 'Statistics': [], 'CloudComputing': ['Google Cloud Platform'], 'DevTools': ['Git'], 'Os': [], 'DBMS': ['BigQuery'], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': ['Terraform'], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Cloud', 'CI/CD'], 'FrSoftSkills': ['Organisation', 'Flexibilit√©'], 'EnSoftSkils': []}","{'JobDetail': ['Remote'], 'TypeContract': ['CDI'], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's', '20', '20', '20']}"
Data Engineer F/H,Valeuriad,"Nantes, Pays de la Loire, France",https://fr.linkedin.com/jobs/view/data-engineer-f-h-at-valeuriad-3741223009?position=22&pageNum=0&refId=%2Bft0CQksufPV00p2d83arQ%3D%3D&trackingId=0lhldG7Vz9FqhdswL%2Fpfww%3D%3D&trk=public_jobs_jserp-result_search-card,"Rejoins la
Team Data
cr√©√©e par
Nicolas Greffard,
Docteur en Intelligence Artificielle
, d√©j√† compos√©e de
20
Data Engineers
et
Datascientists
talentueux üòç
Nous recherchons de
nouvelles p√©pites
pour rejoindre notre √©quipe de choc et r√©pondre aux
multiples probl√©matiques Big Data
de nos
clients nantais
mais √©galement
contribuer √† nos projets de R&D
et travailler sur des
conf√©rences incroyables
(DevFest, Salon de la Data)
ü§©
Ta future mission si tu l'acceptes
üòâ
Nous te proposons d'intervenir au sein de nos
grandes DSI clientes
, sur des sujets de
collecte
, d
'alimentation
et de
transformation de donn√©es
sur un environnement
Big Data
Apache
(
Hadoop, Spark, Ambari, Hive
) sur les technologies suivantes :
Hadoop, Apache Ambari, RabbitMQ, Java, Scala, YarnApplication, Teradata, Squoop, Kudu, Hue, Hive, Impala, Dataiku, Flink, Kafka, Spark, Kibana, Oozie, Git, GitLabCI, Jenkins
,
AWS.
Le job en d√©tail
ü§©
√âtude, conception et r√©alisation de traitements Big Data ;
√âchange avec les architectes, les PO et PPO, les d√©veloppeurs et la gouvernance de donn√©es ;
Exploration des donn√©es et des usages des utilisateurs avec Impala ;
Import de donn√©es (SFTP, Kafka, RabbitMQ) ;
Alimentation du cluster Hadoop via des composants d√©velopp√© en Java avec le Framework Spark sur IntelliJ ;
Utilisation d‚ÄôApache Ambari pour g√©rer et surveiller un cluster Hadoop, visualisation des jobs en cours via YarnApplication et des flux Oozie ;
Collecte des donn√©es depuis Teradata via l‚Äôoutil Sqoop dans une base de donn√©es Hive ;
Transformation des donn√©es avec Spark (HDFS, Hive, Kafka, Hbase, Phoenix) ;
Utilisation de Apache Kudu afin d'optimiser les requ√™tes utilisateurs sur les donn√©es chaudes ;
Exposition de donn√©es sur Dataiku pour la cr√©ation de mod√®le de DataScience ;
R√©alisation en Java ‚Äì Flink pour g√©rer les traitements complexe et volumineux ;
Gestion de configuration sous Git avec GitLab ;
Int√©gration continue avec Jenkins et Sonar ;
Lecture de fichier parquet depuis un r√©pertoire S3 sous AWS ;
Requ√™tage de bases de donn√©e depuis l'outil Athena d'AWS ;
Transformation des donn√©es et calcul d'indicateurs sous Hive ;
Utilisation de Oozie pour l‚Äôordonnancement de flux ;
Utilisation de Kibana pour visualiser et mesurer la volum√©trie de traitements quotidien et en streaming.
Pourquoi choisir Valeuriad ?
üòä
En plus d‚Äô√™tre aujourd‚Äôhui un acteur nantais reconnu de l‚Äôexpertise IT, nous nous inscrivons depuis notre cr√©ation dans une d√©marche d'entreprise
Opale
et
Holacratique
, o√π l'ensemble de nos prises de d√©cisions et projets sont r√©alis√©s par et avec l'ensemble de nos
119 co√©quipiers
üí™
Rejoindre Valeuriad, c'est
pouvoir s'investir dans la co-construction de l'entreprise
:
Par un r√¥le, avec une fiche de poste et un temps d√©di√© (gestionnaire des Ci‚Äôs, porteur des partenariats √©coles, organisateur d‚Äô√©v√©nements, PO des projets internes, gestion de l'Acad√©mie Valeuriad‚Ä¶).
Par les projets strat√©giques (200 jours mis √† disposition pour les co√©quipiers chaque ann√©e) pour cr√©er et faire grandir des projets structurants (cr√©ation de nouveaux avantages √† l'anciennet√©, cr√©ation d'indicateurs mensuels pour √™tre toujours plus transparents, m√©c√©nat de comp√©tences pour des associations caritatives...).
Par les projets cagnottes (150‚Ç¨ par co√©quipiers et par an) pour r√©aliser des projets collaboratifs qui te tiennent √† c≈ìur avec d'autres Valeurieux (d√©couverte du c√©cifoot, challenge √©cologique, challenges sportifs pour des dons √† des associations humanitaires, borne photo...).
Par les ateliers collaboratifs, chaque mois des brainstorming et ateliers de travail sont propos√©s par les diff√©rents porteurs de projets et sont ouverts √† tous les volontaires.
Mais avant-tout nous sommes une
√©quipe soud√©e
, des coll√®gues qui appr√©cient
passer du temps ensemble
lors de nos
soir√©es hebdomadaires
et se cr√©er des
souvenirs inoubliables
ü§© C'est pour √ßa que chez Valeuriad, le plus important pour nous reste le
savoir-√™tre
:
des passionn√©s, du dynamisme, des sourires, de l'√©coute et le sens de la f√™te
üòâ
Show more
Show less","{'ProgLanguage': ['Java', 'Scala', 'R', 'Go'], 'DataBase': ['HBase'], 'DataAnalytics': ['R'], 'BigData': ['Hadoop', 'Spark', 'Flink'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': ['AWS'], 'DevTools': ['Git', 'Jenkins'], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': ['HBase'], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Big Data'], 'FrSoftSkills': [], 'EnSoftSkils': []}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's']}"
Data Engineer H/F,Chantelle,"Cachan, √éle-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-h-f-at-chantelle-3909775663?position=23&pageNum=0&refId=%2Bft0CQksufPV00p2d83arQ%3D%3D&trackingId=AQs2yfAiZE8LJEpoOklfow%3D%3D&trk=public_jobs_jserp-result_search-card,"La Direction des Syst√®mes d'Information et du Digital du groupe Chantelle recherche son/sa futur.e Data Engineer H/F, pour le lancement du grand chantier de r√©novation de l'architecture Data : la bascule de l'int√©gralit√© de son Data Warehouse vers Google Big Query.
Nous souhaitons recruter un Data Engineer H/F confirm√©.e, charg√©.e de contribuer √† la d√©finition de la feuille de route de la Chantelle Data Plaform. En tant que Data Engineer vous travaillerez au sein de l'√©quipe Data Int√©gration en charge de la Chantelle Data Platform.
Vos Missions :
- Mettre en ≈ìuvre une infrastructure autour de Google Cloud Platform permettant de collecter (airbyte, API, ...) , transformer (dataform, Bigquery ...), exposer (dataviz, API, applications, ...) et historiser les donn√©es g√©n√©r√©es par l'entreprise.
- Travailler en √©troite proximit√© avec les responsables des diff√©rents domaines fonctionnels (R√©f√©rentiels, Supply Chain, Manufacturing, B2B, Retail & e-commerce, Finance, ...), avec notre √©quipe de Data Analysts ainsi qu'avec l'√©quipe technique en charge des infrastructures transverses
- √ätre force de proposition sur tous les sujets d'architecture et de mod√©lisation (choix de mise en place de pipeline temps r√©els ou au contraire de flux de donn√©es en mode batch, ou bien encore stockage sur Big Query / Big Table en fonction des cas d'usage).
- D√©finir les √©l√©ments structurants, en justifiant vos choix, et les mettre en ≈ìuvre.
- Rationaliser et moderniser notre architecture d'int√©gration inter-applicative; se projeter sur la cr√©ation d'un mod√®le de donn√©es de type Datamesh.
- Faire la refonte de la BI de nombreux use cases tels que le pilotage de nos stocks, personnalisation de nos sites e-commerce en temps r√©el en fonction de nos profils client, etc‚Ä¶
Stack technique : Google Cloud Platform, BigQuery, DataForm, DataFlow, PubSub, Airbyte, Github ...
Bonne ma√Ætrise des langages Python et SQL
Pourquoi travailler chez Chantelle ?
Une flexibilit√© dans votre lieu de travail, selon la politique de t√©l√©travail de l'entreprise.
11 jours de RTT/an ainsi qu'un 13√®me mois.
Une culture d'entreprise familiale bas√©e sur des valeurs de respect, de cr√©ativit√©, de durabilit√© et de transparence
Une aventure dans laquelle vous pourrez vous √©panouir, apprendre et entreprendre, avec une grande vari√©t√© de missions et beaucoup d'autonomie
Des √©quipes ressources humaines et des managers √† votre √©coute pour vous accompagner dans votre parcours professionnel
Des r√©ductions sur nos produits et des ventes au personnel
Des avantages dans votre qualit√© de vie au travail : une conciergerie compl√®te proposant un large panel de services, des activit√©s en interne, un CSE.
Vous souhaitez rejoindre un Groupe familial, innovant, engag√© et leader dans son secteur en France comme √† l'international et vous souhaitez apporter votre expertise et authenticit√© pour guider votre √©quipe vers le succ√®s : postulez et rejoignez le Groupe Chantelle !
Show more
Show less","{'ProgLanguage': ['Python', 'R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': ['Google Cloud Platform'], 'DevTools': ['Git'], 'Os': [], 'DBMS': ['BigQuery', 'Big Query'], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Cloud'], 'FrSoftSkills': ['Cr√©ativit√©', 'Flexibilit√©'], 'EnSoftSkils': []}","{'JobDetail': ['Confirm√©'], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's']}"
Data Engineer,eXalt Value,"√éle-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-at-exalt-value-3897767649?position=24&pageNum=0&refId=%2Bft0CQksufPV00p2d83arQ%3D%3D&trackingId=vBl1py5prZu9FMqxtE%2Fmag%3D%3D&trk=public_jobs_jserp-result_search-card,"eXalt
est un cabinet de conseil IT
Pure player Data
& IA bas√© √† Paris.
Notre offre s‚Äôarticule autour de 4 piliers r√©unis au sein d‚Äôune m√™me communaut√© pour un accompagnement √† 360¬∞ alliant une expertise technique et m√©thodologique √† une approche conseil m√©tier:
Data Gouvernance & Project
Data Engineering & Big Data
Data Performance & Analytics
Data Science & IA
Filiale du groupe eXalt, cr√©√© en 2018,
regroupant plus de
950 collaborateurs en France
(Paris, Lyon, Bordeaux, Lille, Nantes, Marseille)
et √† l‚Äôinternational
(Colombie, Etats-Unis, Espagne, Belgique),
eXalt Value
apporte une
expertise approfondie
dans le domaine de la Data & IA et conseille les entreprises dans le d√©ploiement de leurs strat√©gies data-driven.
B√©n√©ficiant du support du groupe eXalt
(1er dans la cat√©gorie Conseil & Audit au classement des Champions de la Croissance 2024), eXalt Value
est en pleine croissance et regroupe aujourd‚Äôhui une communaut√© d‚Äôexpertise de plus de 60 collaborateurs en r√©gion parisienne.
Nos consultants interviennent sur d
es projets d‚Äôenvergure
dans divers secteurs d‚Äôactivit√©,
Banque & Assurance, M√©dias, Transports, Retail, Tourisme, etc.
Nous recherchons un
Data Engineer Confirm√© H/F (minimum 4 ans d'exp√©rience dans la fonction)
pour rejoindre notre communaut√© sur le
pilier Data Engineering & Big Data.
Vos missions:
Concevoir et d√©velopper des pipelines et des flux de donn√©es.
Int√©grer et transformer des donn√©es provenant de diff√©rentes sources.
D√©velopper et mettre en ≈ìuvre des algorithmes de traitement de donn√©es avanc√©s.
Collaborer √©troitement avec les √©quipes clients pour comprendre leurs besoins et fournir des solutions adapt√©es.
Assurer la qualit√© et la fiabilit√© des solutions d√©velopp√©es.
Conseiller les √©quipes clients sur les solutions √† mettre en place.
Les Pr√©requis :
Titulaire d'un Bac+5, Ecole d'Ing√©nieur
Ma√Ætrise d'un ou plusieurs langages de programmation (
Python, Scala, Spark, etc
.).
Exp√©rience approfondie des technologies
Big Data (Hadoop, Spark, Kafka, Talend, etc.)
Exp√©rience av√©r√©e
en
environnement Cloud (AWS, GCP, ou Azure)
.
Solides comp√©tences en conception et en optimisation de pipelines de donn√©es.
Exp√©rience de travail en
m√©thode Agile
Capacit√© √† travailler de mani√®re autonome et en √©quipe.
Excellentes comp√©tences en communication et en r√©solution de probl√®mes.
Ma√Ætrise de l‚Äôanglais (oral & √©crit dans un contexte international professionnel).
Votre environnement eXalt√©:
Un environnement de travail Collaboratif
favorisant les initiatives et projets transverses √† la Practice Data & IA (Lab IA, Data Hub, etc.).
Un collectif de consultants passionn√©s,
s‚Äôint√©ressant aux tendances innovantes du secteur.
Une Practice de proximit√©,
privil√©giant la mont√©e en comp√©tence de ses collaborateurs (formations, coachings, mentorats, etc.)
Un suivi individualis√© et de proximit√©
par un.e Data Sales Manager r√©f√©rent du compte client, un.e Charg√©.e RH et un.e Practice Manager
Une √©quipe ouverte et dynamique,
qui privil√©gie les moments de partage et de convivialit√© (s√©minaires, eXaltemps, meet-up, d√©jeuners d‚Äô√©quipe, etc.)
Notre processus de recrutement :
Un entretien RH avec Estelle,
√† la suite duquel vous saurez tout (ou presque) d‚ÄôeXalt Value,
Un entretien technique avec un Manager assorti d‚Äôun test technique,
lors duquel vous aurez l‚Äôoccasion de d√©montrer vos talents mais aussi d‚Äôapprendre avant m√™me de dire oui,
Un entretien final avec la Directrice Associ√©e ou le Directeur Op√©rationnel,
pour finir de vous convaincre de nous rejoindre üòä
Nous avons h√¢te de recevoir vos CV, et de faire votre connaissance!
Show more
Show less","{'ProgLanguage': ['Python', 'Scala', 'R', 'Go'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': ['Hadoop', 'Spark'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': ['AWS', 'Azure'], 'DevTools': [], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Big Data', 'Cloud'], 'FrSoftSkills': ['Communication', 'R√©solution de probl√®mes'], 'EnSoftSkils': ['Communication', 'Initiative']}","{'JobDetail': ['Confirm√©'], 'TypeContract': [], 'Salary': [], 'Level': ['Bac+5'], 'Experience': ['a', 'n', 's', '4', '4', '4']}"
Data Engineer,ADVANCED Schema,"Paris, √éle-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-at-advanced-schema-3886398270?position=25&pageNum=0&refId=%2Bft0CQksufPV00p2d83arQ%3D%3D&trackingId=vow2%2BMVl04SYWB2CWmFDCg%3D%3D&trk=public_jobs_jserp-result_search-card,"En tant que Data Engineer, vous aurez les missions suivantes :
Concevoir
des modeÃÅlisations physiques
Construire
des mappings techniques et r√©daction de sp√©cifications d‚Äôalimentation.
D√©velopper
des flux des donn√©es
Contribuer
au pilotage de projets, de proof of concepts
Participer
aÃÄ des missions d‚Äôexpertise
Comp√©tences professionnelles & niveau d'√©tudes requis :
Vous √™tes titulaire d'un dipl√¥me
Bac +3
minimum dans le domaine de la
data
Vous poss√©dez minimum
1 an d'exp√©rience
dans le m√©tier
√ätre
enthousiaste
√† l'id√©e
d'apprendre de nouvelles technologies
Exp√©rience de la m√©thodologie
Agile / Scrum
Capacit√© √†
planifier et √† prioriser
les
t√¢ches
et les
activit√©s confi√©es
en autonomie
Ma√Ætrise
de l‚Äôanglais oral et technique obligatoire
ExpeÃÅrience
av√©r√©e dans l'√©criture de code propre avec 2 ou plusieurs des technologies suivantes :
BASH, SQL, Java, Python, NoSQL
Show more
Show less","{'ProgLanguage': ['Python', 'Java', 'R', 'Bash'], 'DataBase': ['SQL', 'NoSQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': [], 'FrSoftSkills': [], 'EnSoftSkils': []}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's']}"
Data Engineer GCP (H/F),SQLI,Greater Paris Metropolitan Region,https://fr.linkedin.com/jobs/view/data-engineer-gcp-h-f-at-sqli-3849296046?position=26&pageNum=0&refId=%2Bft0CQksufPV00p2d83arQ%3D%3D&trackingId=EMktKmtfYfhxvsEgTN19Jg%3D%3D&trk=public_jobs_jserp-result_search-card,"Rejoignez
SQLI
et faites partie de l'√©quipe Data, au sein d‚Äôune soci√©t√© √† taille humaine, mais avec de grandes ambitions. Nous sommes plus de 2200 talents sur 13 pays et 3 continents.‚Äã
Votre futur √©cosyst√®me :
Au sein du p√¥le Data de SQLI
, pour rejoindre une √©quipe dynamique de +40 passionn√©s.
Des projets digitaux pour des clients grands comptes
: notamment dans les secteurs des services financiers, de l'industrie et du retail.
Une organisation orient√©e delivery
: vous travaillerez au sein de nos locaux ou en √©quipe int√©gr√©e chez nos clients en mode 100% agile, en mode projet.
Possibilit√© de t√©l√©travail jusqu'√† 3 jours par semaine
Des communaut√©s d‚ÄôExperts
, pour vous aider √† progresser‚Äã, avec des workshops et ateliers techniques favorisant le partage de connaissances.‚Äã
Des Managers de carri√®re
, pour √™tre suivi par l'un de vos pairs sur l'entit√© Data, avec un
accompagnement dans l‚Äôexpression de vos talents
(certifications et formations notamment via le partenariat Solutions de Microsoft, participation aux √©v√®nements/salons, publications dans la presse...).
Description du poste :
Un poste de
Data Engineer GCP (H/F)
est ouvert √†
PARIS ou ROUEN
(selon votre localisation)
, pour faire partie de l‚Äô√©quipe Data chez SQLI et vous investir dans un environnement technique innovant.
Vos missions seront :
L'analyse et la compr√©hension des besoins m√©tiers.
La participation √† la d√©finition et √† la conception de l‚Äôarchitecture.
La r√©alisation des pr√©sentations, d√©monstrations, POC ou Pilotes pour mettre en lumi√®re les recommandations technologiques.
Les d√©veloppements de jobs d‚Äôalimentation (pr√©paration, ingestion, traitement et contr√¥le qualit√©) et l'automatisation des flux d‚Äôalimentation du Data Lake et du Datawarehouse
Les tests de charge, tests unitaires‚Ä¶
La maintenabilit√© de la solution Big Data/BI : optimisation et performance des traitements.
Qualifications :
Ing√©nieur(e) de formation, avec minimum
3 ans d‚Äôexp√©rience sur des projets Google Cloud Platform (BigQuery, Dataflow, ...)
Toujours en veille, √† l‚Äôaffut des nouveaut√©s technologiques et vous aimez √©changer (Events, conf√©rences, meetups, etc‚Ä¶).
Force de proposition, vous vous sentez libre d‚Äôoser et de vous surpassez en partageant vos id√©es.
Comp√©tences techniques requises :
Ma√Ætrise d'un langage de programmation
(Python, Java, R, Spark, Scala).
Ma√Ætrise de
SQL.
Une exp√©rience sur au moins un ETL/ELT
(Talend, DBT).
Bonne connaissance des outils et framework d‚Äôindustrialisation
CI/CD
et/ou gestion de version (Gitlab).
Serait un plus : une exp√©rience sur Power BI, TIBCO EBX et/ou BO DS + la gestion de Conteners et Kubernetes (GKE).
Vous pensez que ce poste est fait pour vous ? Transmettez-nous votre profil !
Tous nos postes sont ouverts aux personnes en situation de handicap.
Des questions sur vos donn√©es personnelles ? Retrouvez notre politique de confidentialit√© concernant les candidats :
https://www.sqli.com/sites/default/files/2024-01/SQLI-PRIV-Politique-Confidentialite-Candidats-C0-29012024.pdf
Show more
Show less","{'ProgLanguage': ['Python', 'Java', 'Scala', 'R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': ['Spark'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': ['Power BI'], 'Statistics': [], 'CloudComputing': ['Google Cloud Platform'], 'DevTools': ['Git'], 'Os': [], 'DBMS': ['BigQuery'], 'SoftBigDataProcessing': [], 'Automation': ['Kubernetes'], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': ['Kubernetes'], 'Collaboration': [], 'Other': ['Big Data', 'Cloud', 'CI/CD'], 'FrSoftSkills': ['Organisation'], 'EnSoftSkils': []}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's', '3', '3', '3']}"
Data Engineer,Ramify,Greater Paris Metropolitan Region,https://fr.linkedin.com/jobs/view/data-engineer-at-ramify-3896146641?position=27&pageNum=0&refId=%2Bft0CQksufPV00p2d83arQ%3D%3D&trackingId=OyTZ5Wg2QZ80gah92GQKkQ%3D%3D&trk=public_jobs_jserp-result_search-card,"ABOUT
Ramify‚Äôs mission is to help people achieve financial freedom, no matter who they are and how much they have. We are revolutionizing the private wealth management industry by making smart and affordable financial products for everyone.
No more standardized solutions, hidden fees and complicated words, Ramify enables everyone to become a smart investor. The team combines elements of its research with technology to design customized investment portfolios composed of world-class financial products.
The team comprises around 15 talented individuals. Ramify is looking for talented people in all sectors, who want to have a huge impact, move fast and deliver.
JOB DESCRIPTION
The Quantitative Investment Solutions (QIS) Team is dedicated to designing innovative investment portfolio models and developing cutting-edge investment features within our product suite. Moreover, the QIS Team is at the forefront of driving AI-based solutions for Ramify. This involves conceptualizing and implementing transformative AI solutions tailored to meet the diverse needs of various teams within Ramify.
As a Data Engineer on our QIS Team, you will play a pivotal role in shaping the future of investment strategies through data-driven insights and AI-based solutions. Collaborating closely with our talented team of quantitative researchers, and investment experts, your responsibilities will encompass architecting and implementing robust data pipelines. These pipelines will facilitate the seamless integration of diverse data sources, empowering Ramify teams to make informed decision-making.
Key Responsibilities:
Design, build and launch data pipelines at scale to move data across Ramify platform with SQL technologies.
Design and implement processes and tools for data onboarding and quality, helping to deliver an industry best-practice solution for managing the data lifecycle.
Produce stand-alone tools that can be used by other teams to automate data quality and discover faults.
Build analytical tools that provide insight into business metrics across Ramify.
Architect and lead the implementation of AI based solutions within Ramify
PREFERRED EXPERIENCE
We're looking for people who:
Want to make a difference. We are a small team effectively reshaping how people look at the industry. We need people who 'get it' and want to play an integral part in helping us accomplish this mission and are persistent in getting the job done.
Skills we're looking for:
Master‚Äôs or upper-year undergraduate-level coursework in either Computer Science, Management Information Systems, Business Information Systems, Mathematics or Finance related field.
2+ years of professional experience in data engineering.
2+ years of experience with one or more coding languages such as Python (is a must), Java.
Experience with data modeling and ETL design, implementation and maintenance.
Demonstrable mastery of industry best practices in the data lifecycle, including data quality automation and tooling.
Excellent written and verbal communication skills with ability to communicate complex designs and solutions to non-technical and highly technical audiences alike.
Good attention to detail.
Strong analytics and strategic thinking skills
Nice-to-haves :
Understanding of ML/ Generative AI technologies and their applications.
Possess a passion, curiosity, and energy for finance + investing. You understand the ins and outs of the wealth management, trading, and more importantly - know how to explain these concepts simply
Show more
Show less","{'ProgLanguage': ['Python', 'Java', 'R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': ['Teams'], 'Other': ['ML'], 'FrSoftSkills': ['Communication'], 'EnSoftSkils': ['Communication']}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's']}"
Data Engineer (F/H),Aubay,"√éle-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-f-h-at-aubay-3573871076?position=28&pageNum=0&refId=%2Bft0CQksufPV00p2d83arQ%3D%3D&trackingId=XZpHkW4Cb1vXWOPaeoHFcg%3D%3D&trk=public_jobs_jserp-result_search-card,"Passionn√© par la Data, tu souhaites rejoindre une communaut√© d‚Äôexperts dans le domaine afin de d√©velopper tes comp√©tences en Data Engineering. Aubay renforce ses √©quipes Data et recherche des Data Engineers pour int√©grer des dispositifs de projets pointus et vari√©s.
Ton quotidien en tant que Data Engineer chez Aubay, :
D√©finition de la strat√©gie de stockage et mise en ≈ìuvre des technologie appropri√©es (base de donn√©es SQL, NoSQL, stockage distribu√©,‚Ä¶)
Ingestion des donn√©es (structur√©es, semi-structur√©es ou non-structur√©es) selon diff√©rentes fr√©quences : batch, micro-batch ou temps r√©el
Conception et mise en ≈ìuvre de pipelines de donn√©es afin de fournir des donn√©es pr√™tes √† l‚Äôemploi aux consommateurs : uniformisation, mise en qualit√©, enrichissement, calcul d‚Äôindicateurs,‚Ä¶
Conception et d√©veloppement d‚ÄôAPI pour exposer les donn√©es aupr√®s d‚Äôapplications tierces
Appui aux Data Scientists pour industrialiser et optimiser les algorithmes de Machine Learning
Pr√©paration et animation d‚Äôateliers de travail avec des interlocuteurs vari√©s : recueil/approfondissement des besoins m√©tiers, avancement/restitution des travaux, transfert de comp√©tences,‚Ä¶
Ton profil :
Tu dispose d‚Äôune formation niveau BAC+5 (Master 2 ou √©cole d‚Äôing√©nieur) sp√©cialis√©e en informatique
Tu as d√©j√† une premi√®re exp√©rience significative (a minima 2 ans) en Data Engineering sur des technologies Big Data
Les technologies telles que Hadoop, Spark ou Kafka sont tes technologies de pr√©dilection
La programmation n‚Äôa plus de secret pour toi et tu maitrise parfaitement un ou plusieurs langages de programmation suivants : Java, Scala et Python
Tu ma√Ætrises les tenants et aboutissants de la philosophie DevOps et des outils orient√©s CI/CD
Tu es soucieux de la qualit√© et de la performance de tes d√©veloppements et tu t'int√©resse √† l‚Äôinnovation frugale
Tu es un expert technique dans ton domaine sans pour autant oublier l‚Äôimportance d‚Äôune communication orale et √©crite de qualit√© et adapt√©e √† chacun de tes interlocuteurs
Tu travaille au quotidien en mode agile et tu en maitrise les fondements
Ce qui nous caract√©rise :
Des missions et projets dans le domaine du Data Engineering en nombre et dans des secteurs vari√©s (Banque, Assurance, Telecom, Industrie,‚Ä¶) qui permettent √† nos collaborateurs de monter en comp√©tences et de devenir des experts Data reconnus
De l‚Äôapprentissage en continu avec des formations et des certifications sur les technologies Data d‚Äôaujourd‚Äôhui et de demain
Des experts Data mobilisables pour accompagner et soutenir techniquement les collaborateurs sur leurs projets
Des communaut√©s de savoir-faire Data proposant de mani√®re r√©guli√®re aux collaborateurs d‚ÄôAubay du contenu et des √©v√®nements de partage (webinar, meetup/afterwork, BBL,‚Ä¶) sur les th√©matiques suivantes : Data Engineering, Data Viz, Data Science/IA, Data Platform & Architecture,‚Ä¶
Aubay encourage la diversit√© sous toutes ses formes et garantit l'√©galit√© des chances √† tous les candidats. Tous nos postes sont ouverts aux personnes en situation de handicap et nous proposons tous les am√©nagements n√©cessaires.
Ta carri√®re chez Aubay :
Tu auras la possibilit√© de d√©velopper et certifier tes comp√©tences sur les derni√®res technologies Data avec un focus fort sur les plateformes Data Cloud telles qu‚ÄôAzure Synapse Analytics, Google Cloud Platform, Snowflake et Databricks
Tu pourras rejoindre la BU d‚Äôexcellence Data et √©voluer au sein d‚Äôun environnement humain et professionnel de haut niveau. Tu profiteras d‚Äôun management sur-mesure pour t'accompagner dans ta trajectoire de carri√®re
Au sein de la BU d‚Äôexcellence, de multiples perspectives s‚Äôoffriront √† toi :
R√¥le de ¬´ Lead ¬ª : Vous pourrez gagner en responsabilit√© sur le plan technologique et devenir un r√©f√©rent aupr√®s de nos clients et des collaborateurs de la communaut√© Data Engineering
R√¥le de ¬´ Champion ¬ª : Vous repr√©senterez Aubay aupr√®s d‚Äôun ou plusieurs de nos partenaires √©diteurs strat√©giques et vous participerez activement √† l‚Äôanimation de la relation sur le plan technologique
R√¥le de ¬´ Head ¬ª : Vous pourrez prendre la responsabilit√© du savoir-faire Data Engineering et de ses offres et en assurer le d√©veloppement au sens large (d√©veloppement business, recrutement, management de collaborateurs, d√©finition de la strat√©gie et animation de la communaut√© au sein du groupe Aubay,‚Ä¶)
Besoin d‚Äôen savoir plus sur le processus de recrutement ?
Un √©change macro au niveau RH avec Doriane
Un entretien technique avec Marius ou Peter, deux de nos r√©f√©rents techniques
Un √©change manag√©rial avec le Directeur de la BU Modern BI & Data
A savoir que l‚Äôordre des √©tapes peut varier selon tes envies (ex : √©change manag√©rial avec l‚Äô√©change technique)
Aubay encourage la diversit√© sous toutes ses formes et garantit l'√©galit√© des chances √† tous les candidats. Tous nos postes sont ouverts aux personnes en situation de handicap et nous proposons tous les am√©nagements n√©cessaires.
Show more
Show less","{'ProgLanguage': ['Python', 'Java', 'Scala', 'R', 'Go'], 'DataBase': ['SQL', 'NoSQL'], 'DataAnalytics': ['R'], 'BigData': ['Hadoop', 'Spark', 'Databricks'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': ['Azure', 'Google Cloud Platform'], 'DevTools': [], 'Os': [], 'DBMS': ['Snowflake', 'Snowflake'], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['DevOps', 'Big Data', 'Machine Learning', 'Cloud', 'CI/CD'], 'FrSoftSkills': ['Communication'], 'EnSoftSkils': ['Communication']}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': ['Bac+5'], 'Experience': ['a', 'n', 's', '2', '2', '2']}"
Data Engineer (F/H) √† Nantes,Siderlog Conseil,"Nantes, Pays de la Loire, France",https://fr.linkedin.com/jobs/view/data-engineer-f-h-%C3%A0-nantes-at-siderlog-conseil-3858540683?position=29&pageNum=0&refId=%2Bft0CQksufPV00p2d83arQ%3D%3D&trackingId=HCbwQ5WQuIbfa%2FN9RitVJw%3D%3D&trk=public_jobs_jserp-result_search-card,"Rejoignez une Aventure Passionnante chez Nous !
üöÄ
Si vous recherchez une entreprise en pleine croissance o√π votre potentiel peut s'√©panouir pleinement, vous √™tes au bon endroit !
Chez nous, l'humain est au c≈ìur de notre culture d'entreprise. Nous croyons en l'autonomie, la confiance et le partage comme des valeurs essentielles qui guident chacune de nos actions.
Ne perdez plus de temps, rencontrons-nous d√®s maintenant !
En tant que membre de notre √©quipe de consultants Siderlog, vous travaillerez en √©troite collaboration avec nos clients. Voici un aper√ßu des missions qui vous attend :
Contribution √† la fabrication de produits dans un environnement Cloudera üõ†Ô∏è
Accompagnement sur la fabrication des mod√®les de Machine Learning sur des donn√©es √©nerg√©tiques et plus largement ESG. ü§ñ
Attendu :
Contribuer au sein d'une √©quipe agile √† r√©pondre aux besoins des Caisses r√©gionales.. üåê
D√©finir les architectures des solutions avec le reste de l‚Äô√©quipe üèóÔ∏è
Fabriquer et tester les solutions üß™
D√©ployer dans les diff√©rents environnements üöÄ
Garantir le bon fonctionnement en production üíº
Accompagner l‚Äô√©volution des pratiques de l‚Äô√©quipe dans une logique d‚Äôam√©lioration continue de la qualit√© du code üìà
Entrainer et tester des mod√®les de Machine Learning üß†
Profil :
Une exp√©rience entre 4 √† 7 ans
Lieu : Nantes
D√©but : D√®s que possible
Show more
Show less","{'ProgLanguage': ['R'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Machine Learning', 'Cloud'], 'FrSoftSkills': ['Collaboration'], 'EnSoftSkils': ['Collaboration']}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's', '7', '7', '7']}"
Data Engineer / D√©veloppeur Big Data # H/F,Air France,"Provence-Alpes-C√¥te d'Azur, France",https://fr.linkedin.com/jobs/view/data-engineer-d%C3%A9veloppeur-big-data-%23-h-f-at-air-france-3900080172?position=30&pageNum=0&refId=%2Bft0CQksufPV00p2d83arQ%3D%3D&trackingId=85QU4wBfckhPMLhY6Q4HmA%3D%3D&trk=public_jobs_jserp-result_search-card,"Description du poste
Intitul√© du poste
Data Engineer / D√©veloppeur Big Data # H/F
M√©tier
Syst√®mes d'informations - D√©veloppement
Cat√©gorie socio-professionnelle
Cadre
Pr√©sentation du contexte
Vous avez peut-√™tre d√©j√† voyag√© avec nous, mais que connaissez-vous de nos m√©tiers et de la richesse des donn√©es qu‚Äôils g√©n√®rent au quotidien ? Comment le traitement et l‚Äôexploitation de ces donn√©es peut contribuer √† notre strat√©gie de Revenue Management, ou encore aux multiples op√©rations √† r√©aliser pour permettre √† un vol de partir √† l‚Äôheure ?
Air France-KLM fait r√™ver 104 millions de passagers par an, en les emmenant vers plus de 250 destinations, gr√¢ce √† une flotte de plus de 500 appareils. Le Groupe emploie 80 000 collaborateurs partout dans le monde :les opportunit√©s sont vastes pour mettre √† profit ses comp√©tences, apprendre et se d√©velopper !
Le d√©partement de d√©veloppement DATA, OR & AI d‚ÄôAir France, au sein de la direction des Syst√®mes d‚ÄôInformation, intervient dans toute la cha√Æne de captation et de traitement des donn√©es du groupe pour d√©livrer √† nos m√©tiers des solutions applicatives cl√©s en main.
Le d√©partement est √©galement en charge de l‚Äôensemble des outils techniques (ETL, DataLakes, DataWarehouses, Data visualisation) et du d√©veloppement des talents et comp√©tences de Data Engineering.
Notre mission ? Transformer la donn√©e brute en d√©cision intelligente, pour mieux optimiser les m√©tiers d‚ÄôAir France ‚Äì KLM !
Pour cela, nous avons chacun un r√¥le essentiel √† jouer, pourquoi le v√¥tre ne serait pas celui de Data Engineer et de d√©veloppeur Big Data ?
Description de la mission
Au sein de notre d√©partement, vous travaillerez main dans la main avec d‚Äôautres Data Engineers et d√©veloppeurs Big Data ainsi qu‚Äôavec des sp√©cialistes des m√©tiers.
Int√©gr√© au sein d‚Äôune product team agile passionn√©e et dynamique :
Vous participez √† l‚Äôanalyse des besoins m√©tiers du commercial, des op√©rations a√©riennes, de l‚Äôexploitation sol en a√©roport, de la maintenance a√©ronautique ou encore du Cargo.
Vous contribuez √† la d√©finition, au d√©veloppement, √† l‚Äôindustrialisation et √† la maintenance d‚Äôapplications Big Data ou en Business Intelligence
Vous pr√©sentez la restitution de vos travaux et accompagnez les utilisateurs d‚Äôun point de vue fonctionnel ou m√©thodologique
Vous serez en contact avec les directions m√©tier du groupe Air France KLM.
Nous attachons beaucoup d'importance au d√©veloppement des comp√©tences de nos collaborateurs ainsi qu‚Äô√† leur offrir des conditions de travail favorables √† l‚Äôautonomie et aux missions √† forte valeur ajout√©e. L'ouverture, le respect, la bienveillance et le partage sont des valeurs humaines port√©es par l'entreprise.
Profil recherch√©
Vous √™tes dipl√¥m√© de niveau Master ou Ing√©nieur dans les domaines informatiques, vous avez acquis une exp√©rience professionnelle dans le d√©veloppement d‚Äôapplications.
Vous disposez d‚Äôune exp√©rience du d√©veloppement indispensable en Backend / Java
Vous ma√Ætrisez les bases de donn√©es relationnelles et le langage SQL
En Compl√©ment, Vous Avez Une Connaissance Ou Une Exp√©rience Dans Tout Ou Partie Des Concepts Ou Outils Suivants
Environnement Big Data (Spark, Hadoop, Elasticsearch, Kafka, ...)
Base de donn√©es noSQL (MongoDB, HBase, REDIS) ou Data Warehouse Teradata
Outil de Datavisualisation (Spotfire, PowerBI, Qlik ou Kibana)
Solutions de Cloud (GCP) et hybride (GCP / AZURE)
(Ces comp√©tences compl√©mentaires ou manquantes pouvant aussi s'acqu√©rir √† travers un parcours de reskilling et de formations aux outils du data engineering dispens√© en interne).
Vous avez particip√© √† des projets organis√©s en Scrum ou Kanban, et avez peut-√™tre m√™me ≈ìuvr√© comme Scrum-Master, ce qui vous permettra de vous int√©grer ais√©ment au sein d‚Äôune Product Team. Votre esprit de synth√®se, votre force de conviction et votre ma√Ætrise de la communication facilitent les d√©cisions avec l‚Äôensemble des collaborateurs de l‚Äô√©quipe, √©ventuellement en langue anglaise, √† l‚Äô√©crit comme √† l‚Äôoral.
Vous √™tes autonome, rigoureux(se), responsable et curieux(se), vous aimez travailler en √©quipe. Vous poss√©dez de bonnes capacit√©s d'√©coute, d'analyse, de synth√®se et de communication.
Et bien s√ªr, vous √™tes passionn√©(e), enthousiaste et ing√©nieux(se)
Ce que nous vous offrons
De la cr√©ation de valeur pour l‚Äôensemble des m√©tiers d‚ÄôAir France KLM
Des challenges et probl√©matiques complexes √† r√©soudre
L‚Äôopportunit√© de d√©ployer des solutions Data industrielles √† l‚Äô√©chelle !
Une grande part de responsabilit√© dans une structure hi√©rarchique horizontale
Un important degr√© de libert√© pour apprendre et d√©velopper son expertise au sein de l‚Äô√©quipe
On vous attend le plus rapidement possible ! Et pour une dur√©e ind√©termin√©e ;)
Type de contrat
CDI
Temps partiel possible
Non
Type d'horaires
Administratif
Profil candidat
Niveau d'√©tudes min. requis
Bac + 5 et plus
Langue
Anglais (4 - Confirm√© / C1)
Localisation du poste
Localisation du poste
France, Provence-Alpes-C√¥te d'Azur, Alpes Maritimes (06)
Site
Valbonne
Show more
Show less","{'ProgLanguage': ['Java', 'R', 'Go'], 'DataBase': ['SQL', 'NoSQL', 'HBase', 'Elasticsearch'], 'DataAnalytics': ['R'], 'BigData': ['Hadoop', 'Spark'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': ['PowerBI'], 'Statistics': [], 'CloudComputing': ['Azure'], 'DevTools': [], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': ['HBase'], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Big Data', 'Cloud'], 'FrSoftSkills': ['Communication'], 'EnSoftSkils': ['Communication']}","{'JobDetail': ['Hybride', 'Confirm√©'], 'TypeContract': ['CDI'], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's']}"
Data Engineer GCP (F/H),Apside,"Paris, √éle-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-gcp-f-h-at-apside-2859485219?position=31&pageNum=0&refId=%2Bft0CQksufPV00p2d83arQ%3D%3D&trackingId=S4frMrZwFddt0qzttg5Npw%3D%3D&trk=public_jobs_jserp-result_search-card,"Envie de rejoindre une entreprise apprenante ? Engag√©e pour t‚Äôaccompagner dans ton √©volution professionnelle et dans tes projets personnels ?
Rejoins Apside Paris pour travailler sur nos projets de demain !
Le poste :
Tu seras amen√© √† participer √† la migration des donn√©es et le traitements Big Data depuis un cluster Hadoop interne vers l'infrastructure Google Cloud Platform.
Dans ce sens, tes missions seront les suivantes :
Participation aux chantiers de cadrage de la migration
Contribution √† la mise en place des environnements et outils de d√©ploiement automatis√©s
Accompagnement et formation des √©quipes √† l‚Äôoutil GCP
...
Environnement technique :
Jira Big data
Cloud GCP
Hadoop
Kubernetes
Spark, Kafka, Python
Toi ?
Tu as d√©j√† particip√© √† un projet de
migration Google Cloud Platform (GCP)
?
Tu es
rigoureux
,
bon communiquant
?
Tu souhaites participer √† un
projet d‚Äôenvergure associant cloud et Big Data
?
Alors ce poste de
Data Engineer GCP
est fait pour toi !
Et la suite ?
Tu rencontres d‚Äôabord l‚Äô√©quipe RH pour parler de tes attentes, ton projet, ton futur !
Puis les managers pour parler concret : missions, projets, parcours de carri√®re, et bien s√ªr salaire et avantages :)
Et tu discutes avec un de nos Tech Leads, pour √©valuer tes comp√©tences et te challenger.
Tu souhaites donner un nouvel √©lan √† ta carri√®re ? Rejoins la vie Apsidienne !
Pour en savoir plus √† www.apside.com
Show more
Show less","{'ProgLanguage': ['Python', 'R', 'Go'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': ['Hadoop', 'Spark'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': ['Google Cloud Platform'], 'DevTools': [], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': ['Kubernetes'], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': ['Kubernetes'], 'Collaboration': ['JIRA'], 'Other': ['Big Data', 'Cloud'], 'FrSoftSkills': [], 'EnSoftSkils': []}","{'JobDetail': [], 'TypeContract': [], 'Salary': ['Salaire'], 'Level': [], 'Experience': ['a', 'n', 's']}"
Data Engineer confirm√© (H/F),BforBank,Greater Paris Metropolitan Region,https://fr.linkedin.com/jobs/view/data-engineer-confirm%C3%A9-h-f-at-bforbank-3918327555?position=32&pageNum=0&refId=%2Bft0CQksufPV00p2d83arQ%3D%3D&trackingId=eLpDaRizmJq6UlkVJPOsew%3D%3D&trk=public_jobs_jserp-result_search-card,"Sur le mod√®le d'une
""Tech company"",
BforBank place
l'humain et le digital
au c≈ìur de sa transformation. Notre mission,
offrir √† nos clients une exp√©rience bancaire incomparable
pour r√©pondre √† leurs besoins et usages mobile. üåü üì±
Rejoindre BforBank c‚Äôest
rejoindre une √©quipe engag√©e
dans un
grand projet de d√©veloppement strat√©gique en France et en Europe.
Nous sommes aujourd‚Äôhui 350 passionn√©(e)s et
recherchons nos talents pour construire la banque de demain
. üöÄ
Nous croyons en la force du collectif, chaque jour rassembl√©s autour de nos valeurs, de simplicit√©, d'optimisme et d‚Äôengagement, encourageant chacun √† oser, essayer et accepter d‚Äô√©chouer.
üéØ Au sein de la Direction Technologie, la Data Factory a pour objectifs de piloter, d√©finir, d√©ployer et op√©rer les meilleures solutions technologiques r√©pondant aux cas d‚Äôusage data et d‚Äôautomatisations de processus de la banque au travers de plateformes. √âgalement, la Data Factory contribue au d√©veloppement des produits, √† la cristallisation et √† la diffusion des pratiques au sein des Squads BforBank sur les usages data dans la banque.
Tu rejoindras une squad en charge de r√©soudre des probl√©matiques m√©tiers en cr√©ant des solutions applicatives utilisant les donn√©es, des data products, avec pour finalit√©s la prise de d√©cision via des moteurs de calcul ou des dashboards, la cr√©ation de flux r√©glementaires, la cr√©ation de data layer ou de reportings.
üöÄ Tes missions principales sont les suivantes :
¬∑ Participer aux analyses, √©tudes d‚Äôimpacts et cadrage techniques
¬∑ Concevoir des solutions en respectant les bonnes pratiques d‚Äôarchitecture data et d√©veloppement
¬∑ R√©aliser le d√©veloppement de nouveaux data products et assurer la maintenance √©volutive et corrective des data products existants
¬∑ R√©diger la documentation technique des data products
¬∑ Assurer un support aux testeurs
¬∑ Reporter de ton activit√© √† ta Squad et travailler dans une d√©marche d‚Äôefficacit√© collective
Concr√®tement tu seras amen√©(e) √† produire les livrables suivants :
¬∑ R√©aliser du code applicatif √† l‚Äô√©tat de l‚Äôart sur notre nouvelle Data Platform
¬∑ Cr√©er des data layer et des rapports sur notre outil de Data Visualisation
¬∑ R√©diger les documentations techniques li√©es √† ta solution, incluant le mod√®le de donn√©es, les proc√©dures, l‚Äôordonnancement
Ce que tu ma√Ætrises :
¬∑ Maitrise des services manag√©s de GCP (BigQuery, dataproc, dataflow, CloudSQL ‚Ä¶)
¬∑ Maitrise du langage Python, Pandas, Spark
¬∑ Maitrise de la mod√©lisation de base de donn√©es et du langage SQL
¬∑ Maitrise d‚Äôune chaine CI/CD (GitLab‚Ä¶)
¬∑ Bonne connaissance de Kafka
¬∑ Bonne connaissance d‚Äôun outil d‚Äôint√©gration de donn√©es type ETL (Informatica‚Ä¶)
¬∑ Connaissance de l‚Äôinfra as code (Terraform)
¬∑ Connaissance d‚Äôun outil de reporting (Looker, BO‚Ä¶)
ü§ù Ce poste est fait pour toi si :
¬∑ Tu es passionn√©(e) par la Data et leurs usages
¬∑ Tu es orient√© r√©solution de probl√®me, est curieux(se) et force de proposition
¬∑ Tu appr√©cies le travail en √©quipe
¬∑ Tu as un bon relationnel et est rigoureux(se)
¬∑ Tu as une bonne capacit√© d‚Äôanalyse et r√©dactionnelle
¬∑ Tu t‚Äôadaptes rapidement aux changements
üéì
Formation :
Tu es dipl√¥m√©(e) d‚Äôun master en √©cole de commerce, √©cole d‚Äôing√©nieur ou √©quivalent.
Chez BforBank nous recherchons avant tout des comp√©tences. Tu ne disposes pas du dipl√¥me requis mais as des exp√©riences √©quivalentes ? N'h√©site pas √† postuler !
üíº
Exp√©rience :
Exp√©rience confirm√©e de 3 ans en tant que Data Engineer.
En rejoignant BforBank tu trouveras‚Ä¶
¬∑ Un projet ambitieux de transformation digitale et culturelle √† l‚Äô√©chelon europ√©en, terrain d‚Äôinnovation et d‚Äôouverture d‚Äôesprit
¬∑ Une organisation apprenante, proposant un large choix de formations toute l‚Äôann√©e, et qui favorise l‚Äô√©change avec les autres marques du Groupe
¬∑ Une promo RSE multi-m√©tiers qui fait √©voluer en continu les actions de BforBank vers une banque plus responsable
¬∑ Une organisation du travail en mode Agile, impliquant un degr√© √©lev√© de collaboration et d'autonomie tout en travaillant avec un groupe de pairs diversifi√©s.
¬∑ Une Direction Technologie en pleine expansion, porteuse de nombreux d√©fis strat√©giques
Mais aussi‚Ä¶
De 2 jours √† 5 jours de t√©l√©travail modulables par semaine, dans la limite de 84 jours par an (frais de fonctionnement pris en charge)
25 jours de cong√©s + 16 jours de RTT
80% du co√ªt de la mutuelle d‚Äôentreprise pris en charge / couvert
Avantages collaborateurs Cr√©dit Agricole : taux et tarifs pr√©f√©rentiels
Des frais de transports rembours√©s √† 75%
Un restaurant d‚Äôentreprise
Des douches pour les sportifs et un tarif avantageux aupr√®s d‚Äôune salle de sport toute proche
üìç Le poste est bas√© √† La D√©fense, dans des locaux flambant neufs !
BforBank s'engage √† garantir l'√©galit√© des chances aux candidats car nous sommes convaincus de la richesse apport√©e par la diversit√© et l'inclusion dans nos √©quipes.
Rencontrons-nous !
Le processus de recrutement se d√©roule en 4 √©tapes :
üßëüèº‚Äçüíª
Call de 30 minutes avec notre √©quipe Talent Acquisition
Echange avec le Data Factory Manager et notre √©quipe Talent Acquisition (pr√©sentiel)
Echange avec une personne de l‚Äô√©quipe avec qui tu seras amen√© √† travailler (visio)
Echange avec le CTO (visio ou pr√©sentiel)
Notre processus de recrutement dure en moyenne 3 semaines et l‚Äô√©quipe Talent Acquisition se tiendra √† ta disposition pour te donner un maximum de visibilit√© sur l‚Äôavanc√©e du process.
Show more
Show less","{'ProgLanguage': ['Python', 'R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['Pandas', 'R'], 'BigData': ['Spark'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git'], 'Os': [], 'DBMS': ['BigQuery'], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': ['Terraform'], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Cloud', 'CI/CD'], 'FrSoftSkills': ['Collaboration', 'Organisation'], 'EnSoftSkils': ['Collaboration']}","{'JobDetail': ['Confirm√©'], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's', '3', '3', '3']}"
Data Engineer ‚Äì Grenoble,Capgemini,"Grenoble, Auvergne-Rh√¥ne-Alpes, France",https://fr.linkedin.com/jobs/view/data-engineer-%E2%80%93-grenoble-at-capgemini-3905836212?position=33&pageNum=0&refId=%2Bft0CQksufPV00p2d83arQ%3D%3D&trackingId=eHTfZ6LD16GsONOWvJIvvA%3D%3D&trk=public_jobs_jserp-result_search-card,"Choisir Capgemini, c'est choisir une entreprise o√π vous serez en mesure de fa√ßonner votre carri√®re selon vos aspirations. Avec le soutien et l'inspiration d'une communaut√© d‚Äôexperts dans le monde entier, vous pourrez r√©√©crire votre futur. Rejoignez-nous pour red√©finir les limites de ce qui est possible, contribuer √† lib√©rer la valeur de la technologie pour les plus grandes organisations et participer √† la construction d‚Äôun monde plus durable et inclusif.
Vos missions :
En tant que Data Engineer au sein d'une √©quipe multidisciplinaire, vos responsabilit√©s principales seront les suivantes :
Intervenir sur les diff√©rentes phases d'un projet dans un environnement Cloud et Agile.
Contribuer √† la gestion de la qualit√© des donn√©es et extraction et analyse de celle-ci, ainsi qu‚Äô√† la pr√©sentation des donn√©es dans leur forme raffin√©e.
Proposer des nouvelles lectures de donn√©es via un travail de fouille sur les gisements d‚Äôinformation, notamment client.
Adopter une posture de consultant : proposer de nouvelles solutions et accompagner le client dans ses choix.
Votre profil :
Titulaire d'un Bac+5 en √©cole d‚Äôing√©nieur ou en universit√©.
Connaissances approfondies des ETL (Talend, Informatica ou SSIS), du traitement de donn√©es (Spark, Python, Scala) ainsi que des bases de donn√©es (Oracle, SQL Server, Postgres).
Facult√© pour se montrer curieux, autonome et proactif dans la r√©alisation de ses t√¢ches.
Capacit√© √† faire preuve de rigueur et √† travailler en √©quipe.
Bon niveau d‚Äôanglais (B2 minimum).
3 raisons de nous rejoindre :
Qualit√© de vie au travail
: accord de t√©l√©travail en France et √† l‚Äôinternational, accord sur l‚Äô√©galit√© professionnelle, la parentalit√©, l‚Äô√©quilibre des temps et la mobilit√© durable.
Apprentissage en continu
: certifications et formations en libre acc√®s, accompagnement sur mesure avec votre career manager, parcours d‚Äôint√©gration sur 9 mois.
Avantages groupe & CSE
: plan actionnariat, tarif pr√©f√©rentiels, remboursement partiel vacances, remboursement de votre abonnement sportif ou culturel.
Nos engagements et priorit√©s
:
Le groupe Capgemini encourage une culture inclusive dans un cadre multiculturel et handi-accueillant. En nous rejoignant, vous int√©grez un collectif qui valorise la diversit√©, d√©veloppe le potentiel de ses talents, s‚Äôengage dans des initiatives solidaires avec ses partenaires, et se mobilise pour r√©duire son impact environnemental sur tous ses sites et aupr√®s de ses clients.
√Ä propos de Capgemini :
Capgemini est un leader mondial, responsable et multiculturel, regroupant pr√®s de 350 000 personnes dans plus de 50 pays. Fort de 55 ans d‚Äôexp√©rience, nous sommes un partenaire strat√©gique des entreprises pour la transformation de leurs activit√©s en tirant profit de toute la puissance de la technologie et des innovations dans les domaines en perp√©tuelle √©volution tels que le cloud, la data, l‚ÄôIntelligence Artificielle, la connectivit√©, les logiciels, l‚Äôing√©nierie digitale ou les plateformes.
Get The Future You Want* | www.capgemini.com/fr-fr
*Capgemini, le futur que vous voulez
Show more
Show less","{'ProgLanguage': ['Python', 'Scala', 'R'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': ['Spark'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git'], 'Os': [], 'DBMS': ['Oracle', 'SQL Server'], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Cloud'], 'FrSoftSkills': ['Organisation'], 'EnSoftSkils': ['Initiative']}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': ['Bac+5'], 'Experience': ['a', 'n', 's', '55', '55', '55']}"
Data engineer H/F,Extia,"Paris, √éle-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-h-f-at-extia-3599188121?position=34&pageNum=0&refId=%2Bft0CQksufPV00p2d83arQ%3D%3D&trackingId=fmbgssK3ynUQOA5iMd9QYg%3D%3D&trk=public_jobs_jserp-result_search-card,"Vous souhaitez rejoindre une entreprise qui place l‚Äôhumain au c≈ìur de ses pr√©occupations ? On vous attend chez
Extia
!
Soci√©t√© de conseil sp√©cialis√©e dans les m√©tiers de l‚ÄôIT, de l‚Äôing√©nierie et du digital, Extia privil√©gie depuis sa cr√©ation en 2007 une approche qui allie performance et bien-√™tre au travail. Une vision de l‚Äôentreprise partag√©e aujourd‚Äôhui par plus de 2 500 Extiens en France et √† l'international et r√©compens√©e par le label Great Place to Work¬Æ depuis 13 ans, notamment en
2024 o√π les Extiens se hissent √† la premi√®re place du palmar√®s Best Workplaces France
!
Chez Extia, c‚Äôest ¬´ D‚Äôabord qui, ensuite quoi ¬ª alors, allons-y !
D'abord qui
Vous √™tes habitu√© √† travailler aussi bien avec des m√©ta-donn√©es qu‚Äôavec des donn√©es non-structur√©es. A cet effet vous maitrisez un ou plusieurs des concepts comme l‚ÄôETL, le Data mining le Machine learning, les Big data ou encore la Th√©orie des graphes par exemple,
Vous maitrisez les bases de l‚Äôanalyse statistique,
Vous √™tes apte √† r√©diger des scripts en Python et/ou R, et une connaissance d'autres langages de programmation comme Java, Scala ou SAS est un plus,
Vous maitrisez Spark et Hadoop
Vous √™tes familiaris√© avec l‚Äôenvironnement Linux,
Une exp√©rience avec les outils de Stockage de fichiers volumineux (HDFS, Data Lake, S3, stockage Blob), la connaissance des infrastructures cloud AWS ou GCP et des bases en streaming temps r√©el seront aussi de r√©els atouts.
Ensuite quoi
Vous aurez le r√¥le de support technique aux √©quipes d‚Äôanalyse : structurer les donn√©es, r√©aliser des analyses ¬´ statistiques ¬ª ou ¬´ techniques ¬ª sur les donn√©es, d√©velopper des outils d‚Äôanalyse‚Ä¶
Vous m√®nerez des √©tudes afin d‚Äô√©valuer les nouvelles technologies dans le domaine du Big Data, Data Mining ou Machine Learning afin d‚Äôidentifier les solutions les plus pertinentes.
Vous serez en charge de :
Participer √† la d√©finition des besoins et √† la r√©daction des User Stories,
Collaborer avec les Data Scientists au d√©veloppement des modules d‚Äôanalyse de donn√©e,
Concevoir et construire des architectures de donn√©es,
Int√©grer des sources de donn√©es,
Vous assurez que les donn√©es sont facilement accessibles et que leur exploitation fonctionne comme demand√©, m√™me dans des circonstances hautement √©volutives,
Ex√©cuter des processus ETL (extraire / transformer / charger) √† partir d'ensembles de donn√©es complexes et / ou volumineux
Show more
Show less","{'ProgLanguage': ['Python', 'Java', 'Scala', 'R'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': ['Hadoop', 'Spark'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': ['Statistiques'], 'CloudComputing': ['AWS'], 'DevTools': ['Git'], 'Os': ['Linux'], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Big Data', 'Machine Learning', 'Statistiques', 'Cloud'], 'FrSoftSkills': [], 'EnSoftSkils': []}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's', '13', '13', '13']}"
Data Engineer,ALFI : Financial Markets Consultancy Services,"Paris, √éle-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-at-alfi-financial-markets-consultancy-services-3916552424?position=35&pageNum=0&refId=%2Bft0CQksufPV00p2d83arQ%3D%3D&trackingId=NSA4f6Emvv9w8DZZCS0%2Bww%3D%3D&trk=public_jobs_jserp-result_search-card,"Le Data Engineer intervient au sein de l‚Äô√©quipe Engineering Open Big Data du D√©partement Guilde Data, qui regroupe l‚Äôensemble des expertises technologiques li√©es √† l‚Äôing√©nierie de la donn√©e, de l‚Äôautomatisation et √† l‚Äôexploitation des mod√®les de Machine Learning.
Votre r√¥le et vos missions :
Vous aurez pour missions principales de d√©velopper les projets Big Data demand√©s par le m√©tier, et notamment :
Passer de la donn√©e brute √† de la donn√©e exploitable, expos√©e sous forme de tables requ√™tables dans le Datalake
Consolider ces donn√©es au fur et √† mesure de leur alimentation r√©currente dans le Datalake
Les exploiter pour atteindre la finalit√© business (exposition de Business View, r√©int√©gration des r√©sultats dans le SI, service de scoring, ‚Ä¶)
De mettre en place et de garantir le respect dans la dur√©e d'un processus qualit√© sur l'ensemble du cycle de DEV (documents, tests unitaires / int√©gration / fonctionnels, commentaires, versionning, etc.)
Accompagner les Data Engineers sur son p√©rim√®tre pour garantier la qualit√© des livrables
Expertise souhait√©e
Comp√©tences techniques :
Expertise en SPARK et PySpark
Expertise sur Databricks
Une exp√©rience sur un cloud provider public comme Azure (id√©alement), AWS, ou GCP
Connaissances avanc√©es d'outils de BI comme PowerBI (id√©alement) ou Spotfire
Comp√©tences transverses :
Capacit√© √† interagir avec des parties prenantes diverses : Business analyst, Architectes, M√©tier
Exp√©rience en mode de Delivery Agile (Scrum, Kanban, etc.‚Ä¶)
Etre expert dans les pratiques du Software Craftsmanship (Test Driven Development, Behavior Driven Development, Clean Code, Code Reviews, etc.)
Et :
Des Connaissances sur Azure DevOps, Azure Pipeline, GIT
Maitrise des Traitements Big Data en mode Streaming
Maitrise des Bases de donn√©es relationnelles et NoSQL
Une exp√©rience professionnelle avec des outils comme Azure Databricks, Azure Data Lake Storage ou encore Azure Data Factory
Conform√©ment √† la r√®glementation, et √† notre politique d‚Äô√©galit√© professionnelle, tous nos postes sont ouverts aux personnes en situation de handicap.
Show more
Show less","{'ProgLanguage': ['R'], 'DataBase': ['SQL', 'NoSQL'], 'DataAnalytics': ['R'], 'BigData': ['Spark', 'Databricks'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': ['PowerBI'], 'Statistics': [], 'CloudComputing': ['AWS', 'Azure'], 'DevTools': ['Git'], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['DevOps', 'Big Data', 'Machine Learning', 'Cloud'], 'FrSoftSkills': [], 'EnSoftSkils': []}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's']}"
Data Engineer,PROXIAD,Greater Nice Metropolitan Area,https://fr.linkedin.com/jobs/view/data-engineer-at-proxiad-3901014428?position=36&pageNum=0&refId=%2Bft0CQksufPV00p2d83arQ%3D%3D&trackingId=DHnpe%2BF2ldIK4miABMTptQ%3D%3D&trk=public_jobs_jserp-result_search-card,"Contexte
En tant que Data Engineer, votre r√¥le consistera √† r√©aliser la conception, le d√©veloppement, les tests unitaires, la qualification, l'int√©gration continue et la mise en production d'√©volutions sur les projets du p√¥le produits scoring.
Ces projets Big Data GCP ont pour objet de d√©velopper des traitements de croisement de donn√©es, exploration data en mode agile (scrum et Safe), industriel (respect de normes), sur l'environnement Google Cloud Platform.
1 : Conception
Sp√©cification et conception d'une solution se basant sur les d√©veloppements existants.
Mettre en question les choix techniques dans le but de concevoir un logiciel r√©pondant au mieux √† la demande au moindre co√ªt et avec la qualit√© demand√©e.
Conception de l'expression de besoins, de la r√©ponse √† l'expression de besoins √† l'aide des besoins m√©tiers remont√©s par le Product Owner.
2 : R√©alisation
D√©veloppement de nouvelles fonctionnalit√©s sur les composants des applications du p√¥le produits scoring en environnement GCP (DataProc, GCS, BigQuery, Airflow...)
Tests des d√©veloppements r√©alis√©s
Revue de code des d√©veloppements des autres d√©veloppeurs
Mise en production via CICD des d√©veloppements
3 : Suivi du RUN applicatif
Prendre en charge avec les autres membres de l'√©quipe le RUN des applications du p√¥le produits scoring. Cela inclus les t√¢ches de rapport quotidien, la gestion des probl√®mes applicatifs, le soutien aux utilisateurs.
Comp√©tences attendues
Ma√Ætrise op√©rationnelle :
Confluence
Impl√©mentation de l‚Äôint√©gration continue (Utilisation de la chaine CI/CD existante )
Connaissance des principes DevOps
Jira
Anglais (lu, √©crit)
Ma√Ætrise avanc√©e :
Elaborer un cahier de recette
Big Query
Sp√©cifications technique et documentation
D√©veloppement :Python, SQL, Scala, Javascript, GitLab
Expertise
GCP : Exp√©rience significative en tant que Data Engineer Cloud. Mise en pratique des produits GCP et en particulier Dataproc, Big Query, composer, workflow, PubSub
D√©veloppement : Java
Compr√©hension g√©n√©rale des travaux BigData et du profiling
Informations compl√©mentaires :
T√©l√©travail 2 jours par semaines
R√©mun√©ration aux alentours des 45K‚Ç¨
Exp√©rience requise : 6 ans
Localisation : Mougins
Show more
Show less","{'ProgLanguage': ['Python', 'Java', 'Scala', 'R', 'Go', 'JavaScript'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': ['Google Cloud Platform'], 'DevTools': ['Git'], 'Os': [], 'DBMS': ['BigQuery', 'Big Query'], 'SoftBigDataProcessing': [], 'Automation': ['Airflow'], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': ['JIRA', 'Confluence'], 'Other': ['DevOps', 'Big Data', 'Cloud', 'CI/CD'], 'FrSoftSkills': [], 'EnSoftSkils': []}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's', '6', '6', '6']}"
Data Engineer,Digital Waffle,"Paris, √éle-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-at-digital-waffle-3913824888?position=37&pageNum=0&refId=%2Bft0CQksufPV00p2d83arQ%3D%3D&trackingId=FvfLgObEC8BcUbz8bVbiyA%3D%3D&trk=public_jobs_jserp-result_search-card,"Digital Waffle is proud to have partnered with an innovative tech startup in Paris, who are looking for a talented Data Engineer to join their growing team!
They are made up of a powerhouse of experts, combining
data engineers, business process gurus, and Project managers
who leverage the most advanced solutions available; utilising process mining, automation tools, and smart execution systems.
Looking for an experienced Data Engineer (3-5 years)
What You'll Do:
This is a full-time,
hybrid role (Paris-based)
where you'll wear many hats: data exploration, system integration, data prep, data modeling, and implementing data solutions.
Experience:
Expertise in data engineering, data modeling, and ETL (Extract, Transform, Load) processes
Data warehousing and data analytics skills
Experience handling large, complex datasets
Proficiency in SQL and programming languages like Python or Java
Stellar problem-solving and analytical skills
Top-notch communication and collaboration abilities
Bachelor's or Master's in Computer Science, Information Systems, or a similar field (a plus for process mining or intelligent process automation experience)
If you are an experienced and driven Data Engineer, please apply here!
Show more
Show less","{'ProgLanguage': ['Python', 'Java', 'R'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git'], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': [], 'FrSoftSkills': ['Communication', 'Collaboration'], 'EnSoftSkils': ['Communication', 'Collaboration']}","{'JobDetail': ['Full'], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's']}"
Data Engineer F/H,Mobilize Financial Services ‚Äì France,"Noisy-le-Grand, √éle-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-f-h-at-mobilize-financial-services-%E2%80%93-france-3869637982?position=38&pageNum=0&refId=%2Bft0CQksufPV00p2d83arQ%3D%3D&trackingId=odZjcZQrXE2PiZNJFUCL7w%3D%3D&trk=public_jobs_jserp-result_search-card,"üöó En route vers Mobilize !
A l‚Äô√©coute de tous nos clients, nous cr√©ons des services financiers innovants pour construire une mobilit√© durable pour tous.
Rejoindre Mobilize Financial Services,
c‚Äôest d‚Äôabord choisir d‚Äôint√©grer un groupe international
, filiale de Renault Group, une banque de financement solide, partenaire des constructeurs Renault‚ÄìNissan‚ÄìMitsubishi. Nos 4 000 collaborateurs pr√©sents dans 35 pays, agissent ensemble au service de nos clients.
Nous proposons √† nos clients - particuliers comme professionnels - les financements et les services les plus adapt√©s pour les v√©hicules neufs et d'occasion.
Nous finan√ßons √©galement l'activit√© des r√©seaux de concessionnaires des marques de l'Alliance Renault-Nissan-Mitsubishi et nous veillons √† faciliter leur gestion au quotidien pour leur permettre de d√©velopper leurs ventes et assurer leur p√©rennit√© financi√®re.
Notre entreprise se ""MOBILIZE"" en faveur de la diversit√© culturelle, l'√©galit√© hommes-femmes et l'int√©gration de personnes en situation de Handicap. Nous favorisons un environnement de travail o√π les diff√©rences individuelles sont reconnues, appr√©ci√©es, respect√©es et valoris√©es, de fa√ßon √† mettre √† profit les talents et les forces de chacun.
üöòPrenez le volant ! Pas de routine, tous nos itin√©raires sont diff√©rents !
Au sein de la DSI
,
votre
futur m√©tier consistera √† :
Accompagner l‚Äô√©quipe dans la transformation du domaine d√©cisionnel construit sur une architecture type DWH et le porter sur la solution GCP (Google Cloud Platform) de Mobilize FS
Participer √† la construction du projet de transformation vers GCP
Participer aux projets d‚Äô√©volution de notre plateforme Suite Elastic (ELK - Kibana)
Piloter des projets en √©troite collaboration avec les directions m√©tier et en accord avec le TBA (Tableau de Bord des Actions).
Assurer la gestion du budget, du planning, de la tenue des jalons et du respect des engagements sur les projets en responsabilit√©
Assurer la qualit√© et le bon fonctionnement du chargement des donn√©es.
Assurer la mise √† disposition des donn√©es et des outils de reportings √† toutes les directions clientes dans le respect des contrats de service
V√©ritable tout-terrain, vous nous int√©ressez !
L‚Äôesprit d‚Äô√©quipe et le sens du service client pour atteindre ensemble les diff√©rents objectifs ambitieux et satisfaire les diff√©rentes parties avec un haut niveau de qualit√©.
Vous avez un bon relationnel, de l‚Äô√©coute et une excellente communication afin d‚Äôinteragir avec des interlocuteurs de diff√©rents niveaux (direction technique et m√©tier) et de travailler en transverse.
Le sens de l‚Äôanalyse et de bonnes capacit√©s d‚Äôanticipation pour d√©celer les probl√®mes avant la naissance de ces derniers.
Force de proposition : avec vous il n'y a pas de probl√®mes, que des solutions
Vous avez un niveau d‚Äôanglais vous permettant de lire et de comprendre de la documentation technique
üíªüñ± Environnement technique :
Maitrise des langages Python - SQL / NoSQL
Exp√©rience significative sur Python
Exp√©rience avec Git
Une exp√©rience avec les outils Nifi, Airflow et GCP (BigQuery / Cloud Function / Cloud Storage ‚Ä¶) serait un plus
Gestion de projet, maintenance, √©volution, support
App√©tence pour les sujets techniques et fonctionnels : outils de mod√©lisation, exploration de donn√©es, IA, machine learning
Pourquoi nous rejoindre ?
Votre Pack confort
est compos√© de nombreux avantages üòÄ :
Rejoindre Mobilize Financial Services c‚Äôest int√©grer un grand groupe international qui offre des opportunit√©s de carri√®re
.
Un environnement de travail moderne et convivial
: locaux agr√©ables, salle de sport, terrasse, restaurant d‚Äôentreprise, parking avec un CSE dynamique avec de nombreuses offres voyages, sport, famille,
Nous sommes mobilis√©s pour d√©velopper la qualit√© de vie au travail de nos collaborateurs en faisant √©voluer nos fa√ßons de travailler (m√©thodes, outils, organisation du travail‚Ä¶) et nous sommes fiers d‚Äô√™tre certifi√©s ‚≠ê
Great Place To Work ‚≠ê
Possibilit√© de t√©l√©travailler 2 jours par semaine
Nous proposons une
r√©mun√©ration selon profil + Participation + Int√©ressement
Locaux situ√©s au pied du RER A ‚Äì Noisy le Grand Mont d‚ÄôEst
‚ùó Mobilize Financial Services d√©m√©nage ‚ùó Les postes √† pourvoir en r√©gion parisienne seront bas√©s √† Boulogne Billancourt √† horizon 2026
Pour en savoir plus sur notre entreprise,
suivez-nous sur LinkedIn !
La route du recrutement ?
üìû Un rapide entretien t√©l√©phonique,
üõë
un premier √©change
avec Marie DE CARLI, Responsable du d√©partement DATA
‚Ü™ et un dernier virage avec Agathe GROSBOIS, Responsale des Ressources Humaines
L‚Äô√©quipe Mobilize FS a h√¢te de vous recevoir !
Show more
Show less","{'ProgLanguage': ['Python', 'R', 'Go'], 'DataBase': ['SQL', 'NoSQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': ['Tableau'], 'Statistics': [], 'CloudComputing': ['Google Cloud Platform'], 'DevTools': ['Git'], 'Os': [], 'DBMS': ['BigQuery'], 'SoftBigDataProcessing': [], 'Automation': ['Airflow'], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Machine Learning', 'Cloud'], 'FrSoftSkills': ['Communication', 'Collaboration', 'Organisation'], 'EnSoftSkils': ['Communication', 'Collaboration']}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's']}"
Data Engineer H/F,Neosoft,"Lille, Hauts-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-h-f-at-neosoft-3877878521?position=39&pageNum=0&refId=%2Bft0CQksufPV00p2d83arQ%3D%3D&trackingId=BL0jwnxp9GaGWe%2Bvrjzvaw%3D%3D&trk=public_jobs_jserp-result_search-card,"Tous nos postes sont ouverts au t√©l√©travail
Groupe ind√©pendant de conseil en transformation digitale de pr√®s de 1800 collaborateurs, N√©osoft s‚Äôest construit, depuis 2005, sur un mod√®le qui place l‚Äôexcellence, le d√©passement de soi et la RSE au c≈ìur de sa strat√©gie.
En nous rejoignant, vous int√©grez des communaut√©s d‚Äôexperts et de talents qui vous permettent de d√©velopper vos comp√©tences et d‚Äôoffrir √† nos clients le meilleur accompagnement possible.
Notre savoir-faire s‚Äôarticule autour de nos 6 domaines d‚Äôexpertise :
Conseil & Agilit√©
Cybers√©curit√©
Data
DevOps
Infrastructures & Cloud
Software Engineering
Nous recherchons pour int√©grer notre
agence lilloise
un(e)
Data Engineer confirm√©(e)
.
Nous aimerions vous voir rayonner au sein de notre communaut√© DATA (+100 collaborateurs) anim√©e par Nicolas Huche, son practice leader et Thibaud Blanchard son Technical Officer. Vous aiderez les clients √† consolider un patrimoine Data responsable.
üéØ
Vos missions :
Apr√®s une p√©riode d‚Äôint√©gration, en tant que
Data Engineer
, voici √† quoi ressembleront vos activit√©s dans des contextes clients Retail ou Banque / Assurance / Finance :
Analyser et s'approprier les cas d'usages
Analyser et valoriser les donn√©es du patrimoine
Mettre en place des flux de transformation de donn√©es
R√©aliser les tests permettant de s'assurer la qualit√© du delivery
Continuer la mise au point de frameworks data
Cr√©er et d√©velopper des modules de d√©ploiement des solutions
Assurer l'industrialisation de moteurs bas√©s sur l'IA
Assurer le niveau de performance des pipelines
Impl√©menter les outils de monitoring du socles de donn√©es
üìù
Votre profil :
Nous vous imaginons avec au moins 4 ans d‚Äôexp√©riences sur des projets autour de la
Data
, une ma√Ætrise des
bases de donn√©es (SQL)
, des outils de transformation de la donn√©e
(Talend, BigQuery, Airflow)
, et un socle de comp√©tences solides autours des langages
Python, Spark, Scala, Hadoop, Java.
üëâ
Votre carri√®re chez N√©osoft
Depuis sa cr√©ation, N√©osoft place ses collaborateurs au c≈ìur de sa strat√©gie. Notre culture pourrait se r√©sumer en un mot : le collectif.
Nos communaut√©s d‚Äôexperts vous donnent la possibilit√© d‚Äôapprendre, mais aussi de transmettre et de partager vos savoirs pour faire progresser les autres.
Nous veillons √† ce que chacun b√©n√©ficie d‚Äôun accompagnement de proximit√© et d‚Äôun suivi de carri√®re personnalis√© aupr√®s de votre manager d√©di√© :
1 bilan d‚Äôactivit√© trimestriel pour suivre le d√©veloppement de vos comp√©tences
1 entretien d‚Äô√©valuation qui a lieu chaque ann√©e pour √©valuer votre performance et d√©terminer vos nouveaux objectifs
1 entretien annuel aupr√®s de votre RH dans le but de cartographier vos nouvelles comp√©tences pour √©changer sur vos projets professionnels et souhaits de formations
üëâ
Vos avantages
Formations et d√©veloppement de l‚Äôexpertise :
Vous disposez de temps allou√© et r√©mun√©r√© en contribuant au d√©veloppement de votre expertise technique et de celle du groupe (Participations √† des Tech days, animation d‚Äôune conf√©rence √† l‚Äôinterne ou √† l‚Äôexterne, r√©daction d‚Äôarticles, rencontres avec nos candidats en processus de recrutement‚Ä¶)
Un abonnement illimit√© LinkedIn Learning offert
Bien-√™tre au travail :
Un accord de t√©l√©travail flexible jusqu‚Äô√† 100% de t√©l√©travail et personnalisable
Un partenariat avec Gymlib qui favorise le sport en entreprise
Des initiatives locales (afterworks, d√©fis sportifs, team buildings, ‚Ä¶)
Et bien plus encore :
Parce que les meilleurs cooptent les meilleurs, une politique de cooptation attractive r√©mun√©r√©e d√®s l‚Äôarriv√©e du collaborateur
En plus de votre salaire : participation, compte √©pargne temps, actionnariat...
üëâ
Votre parcours candidat
Notre processus de recrutement se compose de deux √©tapes cl√©s :
Un entretien de recrutement RH avec un Talent Acquisition Sp√©cialiste pour dresser un bilan de votre parcours professionnel et identifier les trajectoires de carri√®re possibles au sein de notre groupe
Un entretien d‚Äô√©valuation technique pour r√©aliser un diagnostic de vos comp√©tences techniques et identifier les comp√©tences sur lesquels poursuivre votre √©volution
Vous aurez √©galement la possibilit√© de rencontrer pour compl√©ter votre processus un acteur de notre p√¥le Business ou un pair de votre m√©tier pour √©changer sur son exp√©rience collaborateur.
Nous avons h√¢te de vous rencontrer !
A bient√¥t,
L‚Äô√©quipe N√©osoft üñê
Show more
Show less","{'ProgLanguage': ['Python', 'Java', 'Scala', 'R'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': ['Hadoop', 'Spark'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git'], 'Os': [], 'DBMS': ['BigQuery'], 'SoftBigDataProcessing': [], 'Automation': ['Airflow'], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['DevOps', 'ML', 'Cloud'], 'FrSoftSkills': [], 'EnSoftSkils': ['Initiative']}","{'JobDetail': ['Confirm√©'], 'TypeContract': [], 'Salary': ['Salaire'], 'Level': [], 'Experience': ['a', 'n', 's', '4', '4', '4']}"
Data Engineer,StackEase,"Marseille, Provence-Alpes-C√¥te d'Azur, France",https://fr.linkedin.com/jobs/view/data-engineer-at-stackease-3906618983?position=40&pageNum=0&refId=%2Bft0CQksufPV00p2d83arQ%3D%3D&trackingId=uhMR0GNQBelnu2jlW49URA%3D%3D&trk=public_jobs_jserp-result_search-card,"Context :
It is challenging in many ways to develop a net zero electricity grid. Adding renewable energies means more need for storage and for grid balancing. Grid-scale batteries handle these issues but their operation is not quite simple.
A battery has access to many different revenue streams, each being specific. No revenue alone is enough to make it economically viable. All revenues stacked and optimized together ensure profitability in the long run and a fast deployment.
StackEase‚Äôs ambition is to develop optimization and trading algorithms that merge the battery revenue streams and ensure their sustainable development. The final tool will be an autopilot that makes the best decisions in real time, controls the battery accordingly and sends the corresponding orders to¬† the market.
About StackEase:
StackEase is a deeptech spinoff from the INRIA (French Institute for Research in Computer Science). It was created in August 2023 and secured its first fundings. Members are located in Marseille and Paris.
Our values are innovation, customer satisfaction, merit and sustainability. The company's purpose is to leverage Machine Learning and Mathematical Optimization to accelerate the energy transition.
Missions :
Define and develop the backend architecture of StackEase
Set up databases and data pipelines collecting battery and market data
Deploy and maintain optimisation algorithms and forecasts
Develop a robust and scalable SaaS platform for 24/7 battery management with high cyber standards
Participate in the UI/UX product definition
Skills Wishlist :
Scientific BS/MS/PhD with 2+ years of experience in software engineering
Experience with the common backend tools: Python, Git, Kubernetes, SQL/NoSQL ‚Ä¶ Knowledge of the AWS environment is a plus
Enthusiastic, rigorous, autonomous and willing to be involved in major technical decisions
Knowledge/Interest in the energy sector and ancillary services
Compensation :
45k‚Ç¨ - 60k‚Ç¨ salary range (incl. healthcare, unemployment rate, vacations, ‚Ä¶)
Flexible remote work policies
You do not need to meet 100% of the requirements to apply, we will study all applications: please send your resume to jobs@stackease.fr. References and a cover letter are also welcome but not mandatory.
Show more
Show less","{'ProgLanguage': ['Python', 'Scala', 'R', 'Go'], 'DataBase': ['SQL', 'NoSQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': ['AWS'], 'DevTools': ['Git'], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': ['Kubernetes'], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': ['Kubernetes'], 'Collaboration': [], 'Other': ['Machine Learning'], 'FrSoftSkills': [], 'EnSoftSkils': []}","{'JobDetail': ['Remote'], 'TypeContract': [], 'Salary': ['100'], 'Level': [], 'Experience': ['a', 'n', 's']}"
Data Engineer - Profils exp√©riment√©s H/F,LCL,"Villejuif, √éle-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-profils-exp%C3%A9riment%C3%A9s-h-f-at-lcl-3888403052?position=41&pageNum=0&refId=%2Bft0CQksufPV00p2d83arQ%3D%3D&trackingId=wJZsutTuxjKjugEIdlzF5Q%3D%3D&trk=public_jobs_jserp-result_search-card,"üè¶ LCL, c‚Äôest LA banque urbaine du Groupe Cr√©dit Agricole - avec nous, accompagnez la transformation, le d√©veloppement et le maintien technologiques de nos outils avec une vision business et de satisfaction de nos 6 millions de clients.
En tant qu‚Äôacteur majeur de la banque de d√©tail, nous nous adaptons chaque jour aux nouveaux modes de consommation et les projets de nos de clients internes et externes tout en garantissant le besoin de s√©curit√© et de d√©veloppement technologique qu‚Äôimpliquent nos activit√©s.
üí°Organis√©es en mode Agile, les 8 squads de la tribu DATA (6 squads M√©tier et 2 squads transverses) ≈ìuvrent au quotidien pour r√©pondre √† un enjeu majeur pour la banque : la collecte, le stockage, la gestion et l‚Äôusage de la donn√©e. En interaction permanente avec les autres tribus IT et les m√©tiers, elles √©tudient et proposent les solutions et architectures √† d√©ployer pour r√©pondre au mieux aux strat√©gies de d√©veloppement et de pilotage de l‚Äôensemble des m√©tiers de la banque.
Rejoignez-nous si vous souhaitez participer aux r√©flexions et au d√©veloppement de la trajectoire technique et DataCentric du SI LCL et plus largement du Groupe CA. Vous c√¥toierez et serez au c≈ìur de l‚Äôimpl√©mentation de technologies vari√©es telles que les plateformes Teradata, les solutions d‚Äôarchitecture applicative des technologies BigData ou IA, des environnements analytiques ou encore des solutions de datavisualisation. Vous assurerez le traitement de donn√©es en temps r√©el ou en batch et exposerez les donn√©es sous diff√©rentes formes.
Que vous souhaitiez devenir expert sur les socles technologiques ou relever le challenge de la gestion de projets M√©tier, nous vous aiderons √† atteindre vos propres objectifs.
Vous rejoindrez une √©quipe pluridisciplinaire, clairement orient√©e vers le d√©veloppement de ses collaborateurs √† de nouvelles technologies !
üéØ En tant que Data Engineer :
¬∑ Vous aimez analyser les besoins avec les m√©tiers, challenger, identifier les sources de donn√©es dans les diff√©rents univers technologiques, industrialiser des algorithmes, concevoir et d√©velopper des Datalab ou des Datamart sur les plateformes ? Vous saurez relever les challenges propos√©s par les squads m√©tier !
¬∑ Vous pr√©f√©rez travailler √† l‚Äôarchitecture et au d√©ploiement de nouvelles plateformes, √† la lev√©e de la dette technologique ou encore r√©aliser de la veille au service de notre trajectoire ? La squad Socles Data est faite pour vous !
¬∑ Au-del√† des projets que vous g√©rerez, garant du bon fonctionnement de votre parc applicatif, vous attacherez une grande attention √† la mise en ≈ìuvre de solutions optimis√©es.
¬∑ La rigueur, la communication, l‚Äôesprit d‚Äô√©quipe mais aussi la curiosit√© et la cr√©ativit√© font partie de vos soft skills ! ils vous permettront de r√©pondre aux enjeux de s√©curit√©, de qualit√©, de transmission de la connaissance et contribueront √† l‚Äôatteinte des objectifs de l‚ÄôIT et plus largement de LCL, au service de ses clients.
üíª Voici les principales technologies utilis√©es au sein de la tribu, si certaines vous sont famili√®res, nous vous aiderons √† monter en comp√©tence sur d‚Äôautres !
Langages utilis√©s : SQL, Python, Scala
SGBD : Teradata et utilitaires (TPT, BTEQ, ‚Ä¶)
Streaming : Kafka
Search : ElasticSearch, SolR
Environnement : Unix
Solutions Big Data : Hadoop Cloudera, DataIku, HDFS, Hive, Impala,
Devops : GitLab, Jenkins, Nexus
Outils de visualisation : MS BI (SSIS, SSAS, SSRS) Qlik Sens, BO
Mod√©lisation : MEGA
Outils collaboratifs : GIT, Jira, Confluence, Teams
‚ö°Si les nouveaux enjeux bancaires vous int√©ressent, que vous souhaitez int√©grer une √©quipe Agile au service des m√©tiers dans laquelle vous serez force de proposition et que vous aimez travailler dans un environnement motivant et dynamique, rejoignez-nous, cette offre est faite pour vous !
üî• Les + de notre entreprise :
Acc√®s au Plan d‚Äô√©pargne Groupe, int√©ressement et participation aux b√©n√©fices de l‚Äôentreprise + abondement
Prix pr√©f√©rentiels bancaires et avantages CSE
Parcours √©volutif dans l‚Äôentreprise et/ou dans le Groupe CA.S.A
T√©l√©travail (jusqu'√† 2 jours de t√©l√©travail par semaine)
De multiples commodit√©s sur le campus (restaurants d'entreprise, salle de sport, cr√®che, centre m√©dical, m√©diath√®que...)
Forfait et avantages pratiques ¬´ mobilit√© durable ¬ª pour les velotafeurs
Des √©quipes aussi diversifi√©es que structur√©es dans une dynamique de transformation
LCL s‚Äôengage en faveur de la diversit√© et nous encourageons tout(e) candidat(e) ayant l‚Äôexp√©rience requise √† postuler √† nos offres. Tous nos postes sont ouverts aux personnes en situation de handicap.
Nous avons encore de nombreuses raisons √† vous pr√©senter pour vous convaincre de nous rejoindre mais pour cela, il faudra postuler ici !
Show more
Show less","{'ProgLanguage': ['Python', 'Scala', 'R', 'Go'], 'DataBase': ['SQL', 'Elasticsearch'], 'DataAnalytics': ['R'], 'BigData': ['Hadoop'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git', 'Jenkins'], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': ['JIRA', 'Confluence', 'Teams'], 'Other': ['DevOps', 'Big Data', 'Cloud'], 'FrSoftSkills': ['Communication', 'Cr√©ativit√©'], 'EnSoftSkils': ['Communication']}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's']}"
Data Analyst H/F,Valeuriad,"Nantes, Pays de la Loire, France",https://fr.linkedin.com/jobs/view/data-analyst-h-f-at-valeuriad-3741219622?position=42&pageNum=0&refId=%2Bft0CQksufPV00p2d83arQ%3D%3D&trackingId=HI6lY%2BwJjv1zWoqxN78hvQ%3D%3D&trk=public_jobs_jserp-result_search-card,"Rejoins la Team Data
cr√©√©e par Nicolas Greffard,
Docteur en Intelligence Artificielle
, d√©j√† compos√©e de 20 Data Scientists et Data Engineer talentueux üòç
Nous recherchons de nouvelles p√©pites pour rejoindre notre √©quipe de choc et r√©pondre aux multiples probl√©matiques Data science de nos clients nantais mais √©galement contribuer √† nos projets de R&D et travailler sur des conf√©rences incroyables (DevFest, Salon de la Data) ü§©
Ta future mission si tu l'acceptes üòâ
Nous te proposons d'intervenir au sein de nos grandes DSI clientes, sur des sujets de collecte, d'alimentation et de transformation de donn√©es autour de l‚Äôintelligence artificielle.
Le job en d√©tail ü§©
Toutes Les Missions Ne Sont Pas Identiques, Mais Voici Des Exemples De Choses Sur Lesquelles Nos Data Analyst Sont Intervenus
Mettre en oeuvre des outils informatiques, des techniques et des m√©thodes statistiques pour permettre d'organiser, synth√©tiser et traduire efficacement des donn√©es ;
Fournir un appui analytique √† la conduite d'exploration et √† l'analyse complexe de donn√©es ;
Cr√©er des algorithmes de recherche de donn√©es qui permettent d'explorer les donn√©es utiles ;
Proc√©der √† l'industrialisation du proc√©d√© pour les donn√©es les plus int√©ressantes. Et organiser, synth√©tiser et traduire les informations pour faciliter la prise de d√©cision ;
G√©rer les op√©rations et l'administration, la mod√©lisation et l'architecture des sources de donn√©es. Et s'assurer que les bases de donn√©es existantes soient op√©rationnelles et int√®gres ;
Donner un sens aux donn√©es √† l'aide de ses connaissances analytiques (SQL, analytics/BI, statistiques basiques) ;
D‚Äôint√©grer de nouveaux jeux de donn√©es (Open Data, crowd sourcing, API, fichiers, etc.).
Nous intervenons sur
des donn√©es Big Data
(Hadoop, Hive, Spark, etc...), NoSQL (Neo4j, Redis Graph, Redis, mongo) avec toujours quelques bases de donn√©es Oracle ind√©boulonnables. Mais aussi r√©guli√®rement sur des environnements
Cloud
(principalement AWS et GCP). C√¥t√© outillage et ETL, les missions r√©centes √©taient principalement sur Informatica, Dataiku et Dig Dash. A retenir : nous faisons de tout !
Pourquoi choisir Valeuriad ? üòä
En plus d‚Äô√™tre aujourd‚Äôhui un acteur nantais reconnu de l‚Äôexpertise IT, nous nous inscrivons depuis notre cr√©ation dans une d√©marche d'entreprise
Opale
et
Holacratique
, o√π l'ensemble de nos prises de d√©cisions et projets sont r√©alis√©s par et avec l'ensemble de nos 120 co√©quipiers üí™
Rejoindre Valeuriad, c'est
pouvoir s'investir dans la co-construction
de l'entreprise :
Par un r√¥le, avec une fiche de poste et un temps d√©di√© (gestionnaire des Ci‚Äôs, porteur des partenariats √©coles, organisateur d‚Äô√©v√©nements, PO des projets internes, gestion de l'Acad√©mie Valeuriad‚Ä¶).
Par les projets strat√©giques (200 jours mis √† disposition pour les co√©quipiers chaque ann√©e) pour cr√©er et faire grandir des projets structurants (cr√©ation de nouveaux avantages √† l'anciennet√©, cr√©ation d'indicateurs mensuels pour √™tre toujours plus transparents, m√©c√©nat de comp√©tences pour des associations caritatives...).
Par les projets cagnottes (150‚Ç¨ par co√©quipiers et par an) pour r√©aliser des projets collaboratifs qui te tiennent √† c≈ìur avec d'autres Valeurieux (d√©couverte du c√©cifoot, challenge √©cologique, challenges sportifs pour des dons √† des associations humanitaires, borne photo...).
Par les ateliers collaboratifs, chaque mois des brainstorming et ateliers de travail sont propos√©s par les diff√©rents porteurs de projets et sont ouverts √† tous les volontaires.
Mais avant-tout nous sommes une
√©quipe soud√©e
, des coll√®gues qui appr√©cient passer du temps ensemble lors de nos soir√©es hebdomadaires et se cr√©er des souvenirs inoubliables ü§© C'est pour √ßa que chez Valeuriad, le plus important pour nous reste le savoir-√™tre : des passionn√©s, du dynamisme, des sourires, de l'√©coute et le sens de la f√™te üòâ
Show more
Show less","{'ProgLanguage': ['R', 'Go'], 'DataBase': ['SQL', 'NoSQL', 'Neo4j'], 'DataAnalytics': ['R'], 'BigData': ['Hadoop', 'Spark'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': ['Statistiques'], 'CloudComputing': ['AWS'], 'DevTools': [], 'Os': [], 'DBMS': ['Oracle'], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Big Data', 'Statistiques', 'Cloud'], 'FrSoftSkills': [], 'EnSoftSkils': []}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's']}"
Data engineer python,FINAXYS,"Paris, √éle-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-python-at-finaxys-3887107285?position=43&pageNum=0&refId=%2Bft0CQksufPV00p2d83arQ%3D%3D&trackingId=pet4csm3yy%2BSqrH7Ty2jFw%3D%3D&trk=public_jobs_jserp-result_search-card,"LE CONTEXTE
Leader en
IT
, dans les domaines Banque
,
Finance
et
Assurance
,
Finaxys
est un cabinet de
conseil
cr√©√© en 2008. Nous accompagnons au quotidien les plus grandes banques du pays sur leur
transformation digitale
(BNP Paribas, Soci√©t√© G√©n√©rale, Cr√©dit Agricole, Natixis, etc.)
Nos clients bancaires travaillent √©galement dans des contextes Big Data sur des applications centrales rattach√©es aux Datalakes.
LES MISSIONS
D√©veloppement et traitements sur des applications Big Data (Python)
√ätre force de proposition sur les choix techniques les plus pertinents
Maintenir la qualit√© des solutions, mesure de cette qualit√©, alerte sur les non-conformit√©s et validation des solutions d√©finitives.
Analyser des risques li√©s aux solutions envisag√©es et proposition des actions de rem√©diation.
Apporter des solutions IT r√©pondant au mieux aux besoins du business port√© par la/le Product Owner (M√©tiers/Fonctions) en cherchant toujours la maximisation de la valeur g√©n√©r√©e
Accompagner les √©quipes dans les migrations Cloud
ENVIRONNEMENT TECHNIQUE
Python
Pandas
Scirpting Big Data
Culture DevOps (Jenkins, Maven, Ansible)
PROFIL
Comp√©tences Techniques et Fonctionnelles requises
Maitrise obligatoire de l‚Äôanglais
Show more
Show less","{'ProgLanguage': ['Python', 'R'], 'DataBase': [], 'DataAnalytics': ['Pandas', 'R'], 'BigData': [], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git', 'Jenkins'], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': ['Ansible'], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['DevOps', 'Big Data', 'Cloud'], 'FrSoftSkills': [], 'EnSoftSkils': []}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's']}"
Data Engineer (H/F),Beelix,"Antibes, Provence-Alpes-C√¥te d'Azur, France",https://fr.linkedin.com/jobs/view/data-engineer-h-f-at-beelix-3838611420?position=44&pageNum=0&refId=%2Bft0CQksufPV00p2d83arQ%3D%3D&trackingId=eOrYiQxT73dlk566%2Bib1PQ%3D%3D&trk=public_jobs_jserp-result_search-card,"Qui sommes-nous ?
Depuis 2016, nous accompagnons nos clients sur des probl√©matiques de Product Management, Data et Design Thinking. Beelix contribue √† fa√ßonner le monde de demain en participant aux grandes avanc√©es des secteurs suivants :
üöóAutomobile
‚ö°Energie
üì°M√©dias & T√©l√©coms
üëóLuxe & Retail
üí∂ Banque, Finance & Assurance
‚úàÔ∏èD√©fense
Aujourd‚Äôhui, Beelix compte plus de 200 collaborateurs motiv√©s et dynamiques. Lab√©lis√©e Great Place To work en 2023, Beelix est aussi une entreprise engag√©e o√π il fait bon vivre.
Dans le cadre de notre d√©veloppement, nous recherchons un Data Engineer (H/F) pour l'un de nos clients.
Quelles missions au quotidien ?
√ätre le leader de la brique Datalakehouse
D√©velopper les scripts de transformations de donn√©es et les pipelines d‚Äôalimentation
Proposer des √©volutions architecturales ou de fonctionnalit√©s pour am√©liorer le socle technique
√ätre le back-up du leader technique sur la partie reporting (Power BI)
Orientation satisfaction client et r√©sultat final forte mais √©galement sensibilit√© au ¬´ comment ¬ª
Innovation et proposition de nouvelles pratiques pour am√©liorer l‚Äôenvironnement et les conditions de travail des √©quipes
A propos de vous ?
5 + ann√©es d'exp√©rience en tant que Data Engineer
Ma√Ætrise des technologies suivantes : Microsoft Azure, Microsoft Azure Synapse Analytics (Spark / Python / Pipeline / Serverless), fichiers parquet / delta, Microsoft Power BI, Microsoft SQL Server, langage SQL, Datawarehousing / Mod√©lisation de donn√©es
Analyses et export de donn√©es
Connaissance de l‚Äôensemble du processus depuis la collecte jusqu‚Äô√† la mise √† disposition des donn√©es en ayant comme point fort la maitrise de sa transformation et mise en forme
Vous avez un bon niveau d‚Äôanglais
Localisation : Biot et/ou Carros
Show more
Show less","{'ProgLanguage': ['Python', 'R'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': ['Spark'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': ['Power BI'], 'Statistics': [], 'CloudComputing': ['Azure'], 'DevTools': [], 'Os': [], 'DBMS': ['SQL Server'], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': [], 'FrSoftSkills': [], 'EnSoftSkils': []}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's']}"
Data Engineer | Python - Azure | IA & Machine Learning  | Paris ou Remote Partiel,Octopus IT - Expert du recrutement tech,"Paris, √éle-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-python-azure-ia-machine-learning-paris-ou-remote-partiel-at-octopus-it-expert-du-recrutement-tech-3664568765?position=45&pageNum=0&refId=%2Bft0CQksufPV00p2d83arQ%3D%3D&trackingId=%2Bl2frS%2B7pgf7pnDBijx4%2FA%3D%3D&trk=public_jobs_jserp-result_search-card,"La soci√©t√©
Cr√©√©e il y a plus de 2 ans, cette startup est la premi√®re base de connaissance intelligente d√©di√©e aux services clients. Leur mission ? En finir avec la frustration lorsque l'on contact un Help Desk.
Pour cela, elle propose aux entreprises la possibilit√© de d√©livrer une exp√©rience client d'exception : rapide et de qualit√©. Gr√¢ce √† leur moteur de recherche intelligent, cette entreprise est capable de centraliser toute la connaissance interne de l'entreprise (proc√©dures, produits, modes op√©ratoires, etc.) et la diffuse intelligemment dans les outils de production des conseillers de service client.
R√©sultat :
Plus besoin de chercher l'information
Des r√©ponses instantan√©es et de meilleures qualit√©es
Une autonomie totale des collaborateurs
Apr√®s une croissance fulgurante, elle a su s√©duire √† la fois de nombreuses scale up (Luko, OpenClassrooms, Japhy...) et grands groupes (BNP Paribas, La Poste, Fnac Darty...).
Apr√®s le recrutement de leur Lead Data (r√©aliser ensemble) et suite √† l'annonce de leur lev√©e de 2,5M‚Ç¨ pour tripler la taille de ses √©quipes, le but est maintenant de s'imposer tr√®s vite comme la base de connaissance de r√©f√©rence en France et en Europe. Pour ce faire, nous recherchons un Data Engineer.
Le poste
En travaillant main dans la main avec le Lead Data, ta mission sera de d√©velopper et de maintenir des flux de donn√©es complexes et robustes. La donn√©e √©tant au coeur de l' entreprise, dans le produit comme dans la strat√©gie, tu seras amen√© √† travailler avec un panel d‚Äôinterlocuteurs tr√®s vari√©s :
Data Scientists sur des sujets comme le monitoring des mod√®les de production et l‚Äôenrichissement des donn√©es d‚Äôentrainement.
Product Team sur des sujets de performance et d‚Äôacheminement de donn√©es au service de fonctionnalit√©s produit telles que le dashboard d‚Äôanalytics √† destination de nos clients.
Customer Success / Strategy sur des sujets de pilotage comme le suivi de l‚Äôutilisation de notre plateforme ou la mise en place de KPIs de performance.
Tu travailleras sur les probl√©matiques suivantes :
Tu seras responsable de notre architecture de donn√©es et de son outillage, mais aussi de la mise en place de pipelines de donn√©es complexes et robustes.
Tu seras amen√© √† mettre en place des outils de monitoring et d‚Äôalerting pour suivre de pr√®s nos nombreuses pipelines de donn√©e.
Tu seras garant de la qualit√© de nos donn√©es en assurant l‚Äôapplication des guidelines de code et des tests automatis√©s pour chacune de nos pipelines.
Tu seras amen√© √† mettre en place des outils de reporting / insights √† destination d‚Äôinterlocuteurs vari√©s (Data Science, Product, Customer Success, Clients, etc.).
Tu cr√©eras et d√©velopperas des pipelines de donn√©es avec des outils de scheduling et d‚Äôorchestration.
La stack sur laquelle vous travaillerez :
Langage : Python, Javascript
Framework data : PyTorch, Transformers (Hugging Face), FastAPI
Database : PostgreSQL, MongoDB, ElasticSearch, Redis
Infrastructure : Azure, Docker, Kubernetes, Spark, RabbitMQ, Serverless, Terraform
Environnement / Test : PyTest, Gitlab (git + ci/cd)
BI : Metabase, Superset
Votre profil
Entre 1 et 3 ans d'exp√©rience en CDI
Tu as une exp√©rience significative sur des probl√©matiques de Data engineering
Tu es quelqu'un de pragmatique
Un tr√®s bon niveau en Python et une tr√®s bonne rigueur dans le code
Bonne pratique de dev : clean code, TDD, BDD
Une bonne culture Ops
Une logique cloud (Aws, GCP ou Azure)
Le salaire & avantages
50-7O K‚Ç¨ selon exp√©rience
RTT
Carte Swile & Mutuelle
2/3 jours de t√©l√©travail par semaine
Et plus encore‚Ä¶
Ce qu‚Äôon pr√©f√®re
√ätre impliqu√© √† fond dans une aventure avec de nombreux challenges techniques
Belles opportunit√©s d'√©volutions sur des postes d'Architecte, de Lead ou de Ml Ops
Beaucoup de workshops en interne et catalogue de formations √† votre guise
Une opportunit√© de travailler sur un produit unique qui a d√©j√† s√©duit de tr√®s beaux clients (BNP Paribas, Fnac Darty, Luko, OpenClassrooms)
La possibilit√© de travailler sur une stack tr√®s moderne, des probl√©matiques complexes aussi bien en traitement de donn√©es, qu'en DevOps
Un plan de BSPCE (actions de l'entreprise) tr√®s int√©ressant et motivant !
Une culture d'entreprise fond√©e sur l'apprentissage, l'autonomie, la bienveillance et l'exigence
Le fait de travailler au quotidien avec des fondateurs passionn√©s par leur domaine d'expertise
Ce poste a √©t√© soigneusement choisi par votre coach. Powered by Octopus IT, cabinet d‚ÄôExperts en Recrutement Tech (CDI et clients finaux uniquement) ‚Äì Visitez nous pour plus d‚Äôopportunit√©s :
www.octopusit.fr
Show more
Show less","{'ProgLanguage': ['Python', 'Java', 'R', 'Go', 'JavaScript'], 'DataBase': ['SQL', ' MongoDB', 'Elasticsearch'], 'DataAnalytics': ['R'], 'BigData': ['Spark'], 'MachingLearning': ['PyTorch'], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': ['AWS', 'Azure'], 'DevTools': ['Git', 'Docker'], 'Os': [], 'DBMS': ['PostgreSQL'], 'SoftBigDataProcessing': [], 'Automation': ['Kubernetes'], 'InfrastructureAsCode': ['Terraform'], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': ['Docker', 'Kubernetes'], 'Collaboration': [], 'Other': ['DevOps', 'ML', 'Cloud', 'CI/CD'], 'FrSoftSkills': [], 'EnSoftSkils': []}","{'JobDetail': [], 'TypeContract': ['CDI'], 'Salary': ['50'], 'Level': [], 'Experience': ['a', 'n', 's', '2', '2', '2']}"
"Data engineer - A√©ronautique, Spatial et D√©fense",MP DATA,"√éle-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-a%C3%A9ronautique-spatial-et-d%C3%A9fense-at-mp-data-3731603307?position=46&pageNum=0&refId=%2Bft0CQksufPV00p2d83arQ%3D%3D&trackingId=QMf0V5SMk%2B%2FztsUJF2DHJQ%3D%3D&trk=public_jobs_jserp-result_search-card,"MP DATA recrute
un(e) Data Engineer (H/F).
Dans le cadre de la transformation digitale industrielle, l‚Äô√©quipe de data engineering en charge de l‚Äôexploitation du Cluster Big Data cherche √† se d√©velopper : afin de r√©pondre aux attentes des d√©partements op√©rationnels en termes de :
Valorisation et d'exploitation des donn√©es de l'entreprise
D√©ploiement des outils de traitement de donn√©es pour une utilisation industrielle.
Le Data Engineer doit faire l'interface entre plusieurs services :
L'infrastructure hardware du Cluster,
Les Data Architect,
Les Data Scientists.
Il doit √™tre capable de comprendre les contraintes industrielles li√©es √† chaque :
Use-case d'exploitation des donn√©es,
Les contraintes et les algorithmes propos√©s par les Data Scientists,
Proposer des solutions robustes d‚Äôimpl√©mentation des traitements d‚Äôingestion ou de transformation de donn√©es dans les √©cosyst√®mes Big Data.
Ta mission (si tu l'acceptes) :
En tant que membre du service DATA au sein du d√©partement Data Intelligence, le Data Ing√©nieur est un acteur cl√© dans le traitement et la mise √† disposition des donn√©es au sein de l‚Äôentreprise. Il sera en particulier impliqu√© dans les missions suivantes :
Conception et d√©veloppement de solutions permettant la collecte, l‚Äôorganisation, le stockage et la mod√©lisation des donn√©es. Ceux-ci doivent √™tre suffisamment s√©curis√©s et lisibles pour les Data Analysts et Data Scientists,
Assurer l‚Äôacc√®s aux diff√©rentes sources de donn√©es, et veiller √† la qualit√© des donn√©es,
Donner un acc√®s facilit√© aux Data Analysts et Data Scientists afin exploiter les donn√©es dans des conditions optimales,
Mise √† jour permanente sur les technologies et les langages utilis√©s dans le but de partager ses connaissances et aider √† l‚Äôavancement des projets,
Contribution, sous la responsabilit√© op√©rationnelle de notre Architecte, aux meilleures pratiques, normes, politiques, m√©thodes, outils et proc√©dures sur le Cluster Big Data,
Il est contributeur de la mise en place d‚Äôune politique de donn√©es respectueuse des r√©glementations en vigueur.
Profil recherch√© :
Ing√©nieur issu d‚Äôune grande √©cole, vous avez des connaissances en mod√©lisation et machine learning (deep learning, random forest, svm‚Ä¶). Acquises lors de votre scolarit√© ou de vos exp√©riences pass√©es (stage ou c√©sure).
Vous avez de bonnes connaissances en Python pour coder ces algorithmes.
Suite √† votre cursus ing√©nieur ou vos exp√©riences professionnelles, vous avez des app√©tences m√©tiers dans les domaines de l‚Äôa√©ronautique, spatial, d√©fense etc.
Vous √™tes reconnu(e) pour votre autonomie, votre excellent relationnel et votre capacit√© √† √™tre force de proposition.
Vous √™tes int√©ress√© pour vous d√©passer en data science & data engineering et vous avez une premi√®re exp√©rience dans ce domaine, comme :
C/C++ / Java / Rust
Spark / PySpark
Kafka
Cloud : AWS / GCP / Azure
Technologies de stockage : Snowflake / S3 / GCS / Azure Blob
Django / Flask
Git Lab
SQL : Postgres / MongoDB
CI/CD
D√©roulement des entretiens :
C‚Äôest tr√®s simple :
1. Pr√©qualification t√©l√©phonique de 5 min avec un membre de l'√©quipe,
2. Second √©change de 30 min (Visio / Physique) avec un Manager pour faire connaissance,
3. R√©alisation d'un Test Technique,
4. √âchange avec la Direction Technique
5. Bienvenue dans la Team
Avantages
‚ìÇÔ∏è Remboursement 50 % de ton titre de transport
üè• Mutuelle H√©lium
üí≥ Carte Edenred
‚òÄÔ∏è Des √©v√®nements et Team Building
üç¨ Candy bar
üòé Terrasse plein sud
Pour te faire une id√©e sur MP DATA, je t'invite √† regarder notre site et nos vid√©os sur Welcome to the jungle.
Show more
Show less","{'ProgLanguage': ['Python', 'Java', 'C++', 'R', 'Go'], 'DataBase': ['SQL', ' MongoDB'], 'DataAnalytics': ['R'], 'BigData': ['Spark'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': ['AWS', 'Azure'], 'DevTools': ['Git'], 'Os': [], 'DBMS': ['Snowflake', 'Snowflake'], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Big Data', 'Machine Learning', 'Cloud', 'CI/CD'], 'FrSoftSkills': ['Organisation'], 'EnSoftSkils': []}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's']}"
Data Engineer,ADVANCED Schema,Greater Lille Metropolitan Area,https://fr.linkedin.com/jobs/view/data-engineer-at-advanced-schema-3539059697?position=47&pageNum=0&refId=%2Bft0CQksufPV00p2d83arQ%3D%3D&trackingId=iM3JnHBYLxozyWi13hQleA%3D%3D&trk=public_jobs_jserp-result_search-card,"ADVANCED SCHEMA
est une soci√©t√© de services informatiques
sp√©cialis√©e dans la donn√©e.
Depuis 20 ans, nous cr√©ons des plateformes data sur mesure pour nos clients, orient√©es usages et alliant qualit√©, performance, s√©curit√© et gouvernance.
ADVANCED SCHEMA
a d√©velopp√© de nouvelles activit√©s pour r√©aliser l'ambition du groupe : devenir
une entreprise end-to-end,
en proposant une offre √† 360¬∞ √† nos clients pour les
accompagner √† chaque √©tape de leurs projets.
√Ä ce jour, nous sommes pr√®s de 220 passionn√©s r√©partis entre Paris, Lille, Nantes, Lyon mettant √† profit leur expertises aussi bien dans le domaine du retail, de la finance/assurance, du luxe, des m√©dias, de la sant√© et de l'industrie.
Aujourd‚Äôhui, nous souhaitons int√©grer de nouveaux renforts dans nos √©quipes Lilloises.
En tant que Data Engineer, vous aurez les missions suivantes :
Concevoir des modeÃÅlisations physiques
Construire des mappings techniques et r√©daction de sp√©cifications d‚Äôalimentation.
D√©velopper des flux des donn√©es
Contribuer au pilotage de projets, de proof of concepts
Participer aÃÄ des missions d‚Äôexpertise
Comp√©tences professionnelles & niveau d'√©tudes requis :
Vous √™tes titulaire d'un dipl√¥me Bac +3 minimum dans le domaine de la data
Vous poss√©dez minimum 2 ans d'exp√©rience dans le m√©tier
Positif(ve), curieux(se), rigoureux(se) et dot√©(e) d'une bonne aisance relationnelle
√ätre enthousiaste √† l'id√©e d'apprendre de nouvelles technologies
Exp√©rience de la m√©thodologie Agile / Scrum
Capacit√© √† planifier et √† prioriser les t√¢ches et les activit√©s confi√©es en autonomie
Ma√Ætrise de l‚Äôanglais oral et technique obligatoire
Exp√©rience av√©r√©e dans l'√©criture de code propre avec 2 ou plusieurs des technologies suivantes : BASH, SQL, Java, Python, NoSQL
Notre proposition :
Temps plein en
CDI
avec un
salaire attractif
+ participation aux b√©n√©fices + prime(s) sur investissement personnel
Mode de
travail hybride
(agence, site, t√©l√©travail selon projets/clients)
Ticket restaurant (Sodexo)
Mutuelle financ√©e √† 50%
Pr√©voyance
Comit√© entreprise
5 jours d‚Äôonboarding plein temps via la
ADVANCED SCHEMA Academy
Notre investissement :
Chez
ADVANCED SCHEMA
, nous t‚Äôoffrons un environnement de travail stimulant et collaboratif ainsi que des possibilit√©s de croissance et de d√©veloppement professionnel. √âgalement un
accompagnement/support au quotidien
pour te faire grandir et monter en comp√©tences, sur des projets qui r√©pondent √† de
vrais enjeux pour nos clients
. Si tu es passionn√©(e) par les donn√©es et pr√™t(e) √† relever de nouveaux d√©fis, alors nous aussi nous aimerions te rencontrer
Process de recrutement :
Si ta candidature retient notre attention, nous te proposons :
Un premier √©change t√©l√©phonique/visio
Un entretien physique (+questionnaire d‚Äô√©valuation) avec un senior manager
Un entretien final √† notre si√®ge Parisien afin de rencontrer le DG
Show more
Show less","{'ProgLanguage': ['Python', 'Java', 'R', 'Go', 'Bash'], 'DataBase': ['SQL', 'NoSQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': [], 'FrSoftSkills': [], 'EnSoftSkils': []}","{'JobDetail': ['Hybride', 'Temps plein', 'Senior'], 'TypeContract': ['CDI'], 'Salary': ['50'], 'Level': [], 'Experience': ['a', 'n', 's', '20', '20', '20']}"
Data engineer H/F,Akkodis,Greater Lille Metropolitan Area,https://fr.linkedin.com/jobs/view/data-engineer-h-f-at-akkodis-3890779946?position=48&pageNum=0&refId=%2Bft0CQksufPV00p2d83arQ%3D%3D&trackingId=b%2FUTDT6VHRLqgA4VCIU4OA%3D%3D&trk=public_jobs_jserp-result_search-card,"La ligne de service Consulting & Solutions d‚ÄôAkkodis France renforce ses √©quipes en r√©gion Hauts-de-France et recrute un
Data engineer H/F
en
CDI
sur la
m√©tropole lilloise
:
Description de la mission :
Concevoir, mettre en oeuvre et maintenir des pipelines de donn√©es efficaces et √©volutifs dans un environnement cloud (comme AWS, Azure, Google Cloud Platform‚Ä¶)
Assurer la qualit√© des donn√©es et des mod√®les
D√©finir les bonnes pratiques de d√©veloppement en impl√©mentant des outils de CI/CD
Assurer une veille technologique sur les technologies Cloud
Capacit√© √† interagir avec des parties prenantes diverses : business analyst, architecte, m√©tier‚Ä¶
Veiller au bon fonctionnement des pipelines en production
Profil :
De formation
Bac +4/5 en informatique
ou issu d'une
√©cole d'ing√©nieur
, vous poss√©dez une exp√©rience de
3 ans
minimum en tant que data engineer ainsi que les comp√©tences suivantes :
Une bonne connaissance des √©cosyst√®mes li√©s √† la data (Kafka, ETL, base de donn√©es‚Ä¶)
Une premi√®re exp√©rience sur un cloud provider (AWS, Azure, GCP)
Une bonne maitrise de langages de programmation tels que SQL, Python, Scala
Akkodis accompagne ses clients dans la mondialisation de leurs projets, aussi un anglais courant est requis pour l‚Äôensemble de nos collaborateurs.
Processus de recrutement :
Une charg√©e de recrutement vous contacte pour √©changer sur votre projet professionnel
Vous √©changez ensuite avec un.e manager sur les aspects techniques, les projets
Chez Akkodis nous sommes convaincus que de l‚Äôintelligence collective na√Æt le succ√®s. Il n‚Äôexiste pas qu‚Äôun mod√®le, nous valorisons l‚Äôagilit√© et l‚Äôexcellence, l‚Äôaudace et la cr√©ativit√©.
Et si nous parlions ensemble de vos ambitions pour les prochaines ann√©es ?
Akkodis est une entreprise handi-engag√©e et inclusive. Tous nos postes sont ouverts aux handicaps et √† la diversit√©. Tous diff√©rents, tous comp√©tents !
Akkodis, est un acteur mondial de l‚Äôing√©nierie et de l‚ÄôIT et un leader dans la smart industrie. Nous accompagnons nos clients dans leurs projets de transformation digitale via 4 lignes de service : Consulting, Solutions, Talent et Academy. Akkodis est un partenaire technologique de confiance pour ses clients √† l‚Äô√©chelle internationale. Nous co-cr√©ons et nous imaginons des solutions de pointe pour r√©pondre aux d√©fis majeurs de notre soci√©t√©, qu'il s'agisse d'acc√©l√©rer la transition √©nerg√©tique et de d√©velopper la mobilit√© verte, ou encore de construire des approches centr√©es sur les utilisateurs.
Dot√©s d‚Äôune forte culture de l‚Äôinclusion et de la diversit√©, nos 50 000 experts en IT et en ing√©nierie, pr√©sents dans 30 pays, allient les meilleures comp√©tences technologiques √† une connaissance transverse de toutes les industries pour fa√ßonner un futur plus durable. Nous sommes passionn√©s par l‚Äôid√©e d‚Äôinventer ensemble un avenir meilleur.
Akkodis en France, ce sont pr√®s de 9.000 experts en IT et en ing√©nierie r√©partis sur l'ensemble du territoire, des collaborateurs partageant des valeurs fortes d'honn√™tet√©, de respect, d'√©quit√© et d'inclusion. Notre engagement : leur permettre au quotidien d'√™tre eux-m√™mes au travail, et acteurs de leur vie et de leur d√©veloppement au sein d'Akkodis.
*Akkodis est une marque commerciale sous laquelle les entit√©s AKKA et Modis op√®rent
Show more
Show less","{'ProgLanguage': ['Python', 'Scala', 'R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': ['AWS', 'Azure', 'Google Cloud Platform'], 'DevTools': ['Git'], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Cloud', 'CI/CD'], 'FrSoftSkills': ['Cr√©ativit√©'], 'EnSoftSkils': []}","{'JobDetail': [], 'TypeContract': ['CDI'], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's', '3', '3', '3']}"
Data Engineer H/F,Ippon Technologies,Greater Nantes Metropolitan Area,https://fr.linkedin.com/jobs/view/data-engineer-h-f-at-ippon-technologies-3902436649?position=49&pageNum=0&refId=%2Bft0CQksufPV00p2d83arQ%3D%3D&trackingId=asGOCltto2RnRyvBzxL%2Fvw%3D%3D&trk=public_jobs_jserp-result_search-card,"Envie de rejoindre la communaut√© DATA la plus dynamique de France ?
Notre sp√©cialit√© est de construire des data platform dans le Cloud public avec les meilleurs technos du moment : Snowflake, Databricks, Matillion, DBT.
Membre de la Practice Data, le/la futur(e) Data Engineer sera int√©gr√©(e) √† nos √©quipes de conseil et sera suivi(e) par un(e) mentor qui l‚Äôaidera √† monter en comp√©tences.
Votre champs d‚Äôexpertise :
Intervenir sur les data platforms de nos clients pour d√©velopper de nouveaux pipelines de donn√©es (ingestion, traitement, exposition).
Travailler en collaboration avec les m√©tiers et les data scientists pour leur fournir un support √† l‚Äôindustrialisation de leurs travaux (tests, int√©gration continue, scalabilit√© des mod√®les, craftsmanship etc‚Ä¶)
D√©ployer des infrastructures cloud full
infra-as-code
(Terraform, CloudFormation).
Participer aux √©v√®nements internes √† la communaut√© data (BBL, webinar, datap√©ro interne, meetup, blog, dojos) et externes (Salon du Big Data, GCP Summit, Spark Summit, AWS Summit, Devoxx, workshop partenaire, meetups).
Capitaliser sur les missions et les diff√©rents √©v√®nements de la communaut√© au travers d‚Äôarticles de blogs, REX, BBL interne.
Vos connaissances :
Un framework de calcul distribu√© tel que Spark, Storm, Flink.
Un ou plusieurs langages de programmation (Python, Scala, Java...)
Diff√©rents syst√®mes de stockage de donn√©es (SQL ou NoSQL) et bien s√ªr le langage SQL.
La connaissance de Snowflake est bienvenue ;-)
Un framework de streaming de donn√©es tel que Kafka ou Amazon Kinesis.
Une exp√©rience sur les technologies Cloud : AWS, GCP, Azure
Le delivery et les projets en production faisant partie de notre ADN, vous √™tes capable de livrer du code de qualit√© dans des environnements agiles.
De plus en plus de nos projets se font en remote avec des clients du monde entier, il devient n√©cessaire d‚Äô√™tre √† l‚Äôaise en Anglais.
Ippon technologies c‚Äôest aussi :
üëç B√©n√©ficier d'un suivi de proximit√© r√©alis√© par votre manager technique : points r√©guliers pour votre suivi en mission, votre formation et votre √©volution de carri√®re
‚úåÔ∏è Rejoindre une entreprise o√π les valeurs du sport sont nos leitmotiv : d√©passement de soi, travail en √©quipe, bienveillance.
üóíÔ∏è Apprendre via notre programme de formation BlackBelt : https://bit.ly/3ByqcIL
üòÅ Travailler en pair programming ou avec un.e mentor pour gravir les √©chelons !
üí™ Pouvoir participer √† une aventure humaine au sein de notre Fondation Ippon pour r√©duire la fracture num√©rique dans le monde !
ü§ù Participer √† nos ap√©ros et divers √©v√®nements internes pour consolider la coh√©sion d‚Äô√©quipe
Et apr√®s ?
Et oui alors ? Que se passe-t-il une fois que vous √™tes convaincu d‚Äôavoir lu l‚Äôoffre d‚Äôemploi qui vous correspond bien ?
Nous vous proposons de prendre contact et de nous rencontrer !
Les Next Steps :
1 call RH
1 √©change RH
1 √©change Technique
Si le match est bon des deux c√¥t√©s : Hadjim√© ! Vous vous lancerez sur le tatami Ippon !
Show more
Show less","{'ProgLanguage': ['Python', 'Java', 'Scala', 'R'], 'DataBase': ['SQL', 'NoSQL'], 'DataAnalytics': ['R'], 'BigData': ['Spark', 'Databricks', 'Flink'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': ['AWS', 'Azure'], 'DevTools': [], 'Os': [], 'DBMS': ['Snowflake', 'Snowflake'], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': ['Terraform', 'CloudFormation'], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Big Data', 'Cloud'], 'FrSoftSkills': ['Collaboration'], 'EnSoftSkils': ['Collaboration']}","{'JobDetail': ['Remote', 'Full'], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's']}"
Data Engineer GCP (F/H),Apside,"Paris, √éle-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-gcp-f-h-at-apside-2902806697?position=50&pageNum=0&refId=%2Bft0CQksufPV00p2d83arQ%3D%3D&trackingId=XQDPQRGAuyZFOaSCmiio%2Fw%3D%3D&trk=public_jobs_jserp-result_search-card,"Envie de rejoindre une entreprise apprenante ? Engag√©e pour t‚Äôaccompagner dans ton √©volution professionnelle et dans tes projets personnels ?
Rejoins Apside pour travailler sur les projets de demain !
Le poste ?
Pour le compte de notre
client acteur mondial de la beaut√© et cosm√©tique,
tu interviendras dans la
transformation d‚Äôun projet worlwide,
o√π tu devras
d√©velopper la Data Platform et l'ensemble des services Data qui seront expos√©s aux diff√©rentes √©quipes du client. Aussi, tu seras amen√© √† d√©velopper des use cases data.
Dans ce sens, tes missions seront les suivantes :
Designer l'architecture et d√©velopper la solution
D√©finir et d√©velopper les Data Model
√ätre garant de la qualit√© du code
√ätre DevOps (Utilisation/mise en place de chaine CI/CD et support niveau L3 des d√©veloppements)
Environnement technique :
GCP (BigQuery, Cloud Run, Cloud Build)
SQL
Python
DevOps (Github)
API Development
Terraform
M√©thodologie Agile
Toi ?
Tu as d√©j√† travaill√© sur
Google Cloud Platform (GCP)
?
Tu es
autonome
,
rigoureux
, et
bon communiquant
?
Tu souhaites participer √† un
projet d‚Äôenvergure associant cloud et Big Data
?
Et la suite ?
Tu rencontres d‚Äôabord l‚Äô√©quipe RH pour parler de tes attentes, ton projet, ton futur !
Puis les managers pour parler concret : missions, projets, parcours de carri√®re, et bien s√ªr salaire et avantages J
Et tu discutes avec un de nos Tech Leads, pour √©valuer tes comp√©tences/ te challenger.
Les infos en plus !
T√©l√©travail ! üòä
Un salaire attractif en fonction de ton exp√©rience + diff√©rents avantages
Un groupe en pleine croissance avec un management bienveillant
Et une √©volution personnalis√©e avec la possibilit√© de se former via une plateforme interne
Tu souhaites donner un nouvel √©lan √† ta carri√®re ? Rejoins la vie Apsidienne !
Pour en savoir plus √†
www.apside.com
Show more
Show less","{'ProgLanguage': ['Python', 'R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': ['Google Cloud Platform'], 'DevTools': ['Git'], 'Os': [], 'DBMS': ['BigQuery'], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': ['Terraform'], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['DevOps', 'Big Data', 'Cloud', 'CI/CD'], 'FrSoftSkills': [], 'EnSoftSkils': []}","{'JobDetail': [], 'TypeContract': [], 'Salary': ['Salaire'], 'Level': [], 'Experience': ['a', 'n', 's']}"
Data Engineer H/F,ALFI : Financial Markets Consultancy Services,"Paris, √éle-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-h-f-at-alfi-financial-markets-consultancy-services-3916559634?position=51&pageNum=0&refId=%2Bft0CQksufPV00p2d83arQ%3D%3D&trackingId=EaFvrw7qrUzpdTZKfHP%2BsA%3D%3D&trk=public_jobs_jserp-result_search-card,"ALFI est une soci√©t√© de conseil et services sp√©cialis√©e en syst√®mes d‚Äôinformation. Depuis plus de 20 ans, ALFI est un acteur unique qui m√™le technologie et humain pour accompagner les transformations num√©riques sur les march√©s de l‚ÄôAsset Management, la banque d‚ÄôInvestissement et les Services aux Investisseurs.
Avec plus de 46 r√©f√©rencements de rang un, ALFI est reconnu comme incontournable sur le secteur BFA. Nous avons plus de 35 clients grands comptes actifs tels que HSBC, Soci√©t√© G√©n√©rale, BNP Paribas, Cr√©dit Agricole, Axa‚Ä¶
Depuis 2015, ALFI a int√©gr√© le groupe
MoOngy
, qui compte plus de 6000 salari√©s dans toute l‚ÄôEurope
Missions :
Pour l'un de nos clients grands comptes, nous vous proposons d'intervenir sur une fonction de Consultant Data engineer.
Les principales missions sont :
Comprendre les besoins des utilisateurs et les traduire de mani√®re analytique
D√©veloppement de solutions permettant de traiter des volumes importants de donn√©es
Conception, collection et fabrication des donn√©es brutes
D√©velopper des algorithmes permettant de r√©pondre aux probl√®mes pos√©s et veiller √† leur industrialisation
S√©curisation des Pipelines donn√©es pour les Data Scientists et les Data Analysts
Construire des bases de donn√©es robustes
Organisation de l‚Äôarchitecture du cloud
Profil recherch√© :
Vous √™tes issu d'une formation Bac +5 Ecole scientifique ou informatique.
Vous disposez d'une premi√®re exp√©rience en d√©veloppement et dans la data.
Vous disposez d'un niveau d'anglais op√©rationnel.
Java, Python, C++
SQL
Devops (Jenkins, Kubernetes, Docker)
Conform√©ment √† la r√®glementation, et √† notre politique d‚Äô√©galit√© professionnelle, tous nos postes sont ouverts aux personnes en situation de handicap;
Show more
Show less","{'ProgLanguage': ['Python', 'Java', 'C++', 'R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Docker', 'Jenkins'], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': ['Kubernetes'], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': ['Docker', 'Kubernetes'], 'Collaboration': [], 'Other': ['DevOps', 'Cloud'], 'FrSoftSkills': ['Organisation'], 'EnSoftSkils': []}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's', '20', '20', '20']}"
Data Engineer  H/F,METEOJOB by CleverConnect,"Lille, Hauts-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-h-f-at-meteojob-by-cleverconnect-3895135654?position=52&pageNum=0&refId=%2Bft0CQksufPV00p2d83arQ%3D%3D&trackingId=i0qckqFBFI71hX2Ld1B%2BkQ%3D%3D&trk=public_jobs_jserp-result_search-card,"Entreprise
Qui sommes-nous ?
Nous sommes passionn√©s par les nouvelles technologies, et vous ?
Rejoindre Amiltone, c'est int√©grer des √©quipes dynamiques et soud√©es dans le cadre de projets novateurs et ambitieux. Nous relevons les challenges techniques de nos clients et les accompagnons dans leur transformation digitale.
Pourquoi choisir Amiltone‚ÄØ?
Amiltone, plus qu'une entreprise, un √©tat d'esprit !
Notre objectif ? Votre √©panouissement professionnel !
Nous Avons √† C≈ìur De
Vous accompagner au mieux au travers d'un suivi personnalis√©
Vous faire monter en comp√©tences en vous proposant des formations tout au long de votre carri√®re
Comprendre vos besoins et respecter nos engagements
Vous proposer des missions de qualit√© avec des technologies innovantes
Cultiver votre potentiel gr√¢ce √† notre programme de d√©veloppement personnel Addvise
Votre bien-√™tre passe aussi par des activit√©s extraprofessionnelles, c'est pourquoi nous vous proposons des s√©ances sportives anim√©es par nos coachs, soir√©es pour se retrouver et animations (√† l'agence ou en visio), Gaming nights...
Description Du Poste
Les missions d'un Amiltonien :
En tant que Data Engineer
(H/F)
, vous serez en charge des missions suivantes :
Concevoir et d√©velopper les futures fonctionnalit√©s de la plateforme Big Data sous Google Cloud Platform.
Concevoir les flux d'alimentation et les tables (structure de donn√©e).
Automatiser et industrialiser les flux.
Assurer le run applicatif, le cas √©ch√©ant.
La Stack Technique
Ma√Ætrise des langages suivants : SQL, Talend, BigQuery
Connaissances de Google (GCP)
Notion de programmation fonctionnelle
Description Du Profil
Le profil d'un Amiltonien :
Dipl√¥m√© Bac+4/5 (Ecole d'ing√©nieur/Master), vous disposez de 2 ann√©es d'exp√©rience dans le d√©veloppement de data.
Toujours sur le qui-vive des nouveaut√©s technologiques, vous √™tes force de proposition sur des technos, des outils ou des process qui permettent d'am√©liorer la qualit√© du code et la stabilit√© de nos applications.
Outre vos comp√©tences techniques, nous nous int√©ressons √©galement √† votre potentiel et votre motivation.
Nos postes sont ouverts aux personnes en situation de handicap.
Show more
Show less","{'ProgLanguage': ['R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': ['Google Cloud Platform'], 'DevTools': ['Git'], 'Os': [], 'DBMS': ['BigQuery'], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Big Data', 'Cloud'], 'FrSoftSkills': [], 'EnSoftSkils': []}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's']}"
Data Engineer,Beelix,"Paris, √éle-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-at-beelix-3865239426?position=53&pageNum=0&refId=%2Bft0CQksufPV00p2d83arQ%3D%3D&trackingId=purN2NU8vbF7Jcz8ecfiUg%3D%3D&trk=public_jobs_jserp-result_search-card,"Qui sommes-nous ?
Depuis 2016, nous accompagnons nos clients sur des probl√©matiques de Product Management, Data et Design Thinking. Beelix contribue √† fa√ßonner le monde de demain en participant aux grandes avanc√©es des secteurs suivants:
üöóAutomobile
‚ö°Energie
üì°M√©dias & T√©l√©coms
üëóLuxe & Retail
üí∂ Banque, Finance & Assurance
‚úàÔ∏èD√©fense
Aujourd‚Äôhui, Beelix compte plus de 200 collaborateurs motiv√©s et dynamiques. Lab√©lis√©e Great Place To work en 2023, Beelix est aussi une entreprise engag√©e o√π il fait bon vivre.
Dans le cadre de notre d√©veloppement, nous recherchons un Data Engineer en √éle-de-France.
Quelles missions au quotidien ?
Vous aurez pour missions principales de d√©velopper les projets Big Data demand√©s par le m√©tier, et notamment :
Passer de la donn√©e brute √† de la donn√©e exploitable, expos√©e sous forme de tables requ√™tables dans le Datalake
Consolider ces donn√©es au fur et √† mesure de leur alimentation r√©currente dans le Datalake
Les exploiter pour atteindre la finalit√© business (exposition de Business View, r√©int√©gration des r√©sultats dans le SI, service de scoring, ‚Ä¶)
De mettre en place et de garantir le respect dans la dur√©e d'un processus qualit√© sur l'ensemble du cycle de DEV (documents, tests unitaires / int√©gration / fonctionnels, commentaires, versionning, etc.)
Accompagner les Data Engineers sur son p√©rim√®tre pour garantir la qualit√© des livrables
Expertise souhait√©e
Expertise en SPARK et PySpark
Expertise sur Databricks
Une exp√©rience sur un cloud provider public comme Azure (id√©alement), AWS, ou GCP
Connaissances avanc√©es d'outils de BI comme PowerBI (id√©alement) ou Spotfire
Capacit√© √† interagir avec des parties prenantes diverses : Business analyst, Architectes, M√©tier
Etre expert dans les pratiques du Software Craftsmanship (Test Driven Development, Behavior Driven Development, Clean Code, Code Reviews, etc.)
Des Connaissances sur Azure DevOps, Azure Pipeline, GIT
Maitrise des Traitements Big Data en mode Streaming
Maitrise des Bases de donn√©es relationnelles et NoSQL
Une exp√©rience professionnelle avec des outils comme Azure Databricks, Azure Data Lake Storage ou encore Azure Data Factory
A propos de vous ?
Dipl√¥m√© d'une √©cole d'ing√©nieurs ou √©quivalent
Au moins 3 ans d'exp√©rience en tant que Data Engineer
Exp√©rience en mode de Delivery Agile (Scrum, Kanban, etc.‚Ä¶)
Vous avez un bon niveau d‚Äôanglais tant √† l‚Äô√©crit qu‚Äô√† l‚Äôoral
Pourquoi nous rejoindre ?
Un suivi et un accompagnement au quotidien
Un organisme de formation certifi√© Qualiopi, un abonnement linkedin learning pour chaque salari√© et des partenariats avec des sp√©cialistes pour d‚Äôautres expertises
De nombreux √©v√©nements : Afterworks, Communaut√©s m√©tiers, Happy talks‚Ä¶
une Exp√©rience personnalis√©e bas√©e sur vos besoins gr√¢ce au Pr√©dictive Index
Notre package ¬´ unBeelievable ¬ª : 100% du titre de transport, Tickets restaurants, CSE, Prime de participation ...
Nombreux √©v√®nements (afterworks, sport, etc) et des communaut√©s m√©tiers dynamiques
Le processus de recrutement ?
√âchange t√©l√©phonique (15 min)
Entretien 1 RH pour apprendre √† vous conna√Ætre
Entretien 2 avec votre futur N+1 pour appr√©hender la relation manag√©riale
Entretien 3 avec un Responsable commercial pour avoir la vision strat√©gique
Show more
Show less","{'ProgLanguage': ['R'], 'DataBase': ['SQL', 'NoSQL'], 'DataAnalytics': ['R'], 'BigData': ['Spark', 'Databricks'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': ['PowerBI'], 'Statistics': [], 'CloudComputing': ['AWS', 'Azure'], 'DevTools': ['Git'], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['DevOps', 'Big Data', 'Cloud'], 'FrSoftSkills': [], 'EnSoftSkils': []}","{'JobDetail': [], 'TypeContract': [], 'Salary': ['100'], 'Level': [], 'Experience': ['a', 'n', 's', '3', '3', '3']}"
Data Engineer BI - Nantes,Capgemini,"Nantes, Pays de la Loire, France",https://fr.linkedin.com/jobs/view/data-engineer-bi-nantes-at-capgemini-3803963477?position=54&pageNum=0&refId=%2Bft0CQksufPV00p2d83arQ%3D%3D&trackingId=elA%2FMXRdlrbP2ohTpvEH7w%3D%3D&trk=public_jobs_jserp-result_search-card,"Capgemini
Choisir Capgemini, c'est choisir une entreprise o√π vous serez en mesure de fa√ßonner votre carri√®re selon vos aspirations, o√π vous serez soutenu et inspir√© par une communaut√© d‚Äôexperts dans le monde entier, o√π vous pourrez r√©√©crire votre futur. Rejoignez-nous pour red√©finir les limites de ce qui est possible, contribuer √† lib√©rer la valeur de la technologie pour les plus grandes organisations et participez √† la construction d‚Äôun monde plus durable et inclusif.
Vos missions :
Int√©gr√©(e) au sein d‚Äôune √©quipe projet BI, Big Data ou Data Gouvernance pour des clients intervenant dans des secteurs d'activit√©s divers, vous serez notamment en charge des missions suivantes :
Mener les analyses fonctionnelles destin√©es √† traduire les besoins du client,
Mener les travaux de conception et de mod√©lisation,
Diriger le d√©veloppement de la solution / des traitements d'alimentation du DataWareHouse,
Organiser et pr√©parer les travaux de recette utilisateurs,
Mettre en place les processus d'industrialisation et mener cette derni√®re.
Votre profil :
Dipl√¥me d‚Äôing√©nieur ou √©quivalent universitaire
Minimum 3 ans d'exp√©rience
Anglais courant
Comp√©tences en BI sur SAP BI (Hana, BW, BODS, BI 4), Microsoft BI (SQL Server, SSIS, SSAS, SSRS), Oracle (ODI, OBIEE), Teradata, Informatica (Powercenter), IBM (Datastage, Cognos, TM1), Talend, AB Initio
Ma√Ætrise d'un ou de plusieurs outils de Dataviz : Microsoft Power BI, Tableau, Qlikview
Connaissances en Big Data (Ecosyst√®me Hadoop (HIVE, PIG, Mahout‚Ä¶), Cloudera, Pivotal, Spark, HNX) ou en analytics (R, SAS, IBM SPSS)
3 raisons de nous rejoindre :
Qualit√© de vie au travail : accord de t√©l√©travail en France et √† l‚Äôinternational, accord sur l‚Äô√©galit√©
professionnelle, la parentalit√©, l‚Äô√©quilibre des temps et la mobilit√© durable.
Apprentissage en continu : certifications et formations en libre acc√®s, accompagnement sur mesure avec votre carreer manager, parcours d‚Äôint√©gration sur 9 mois.
Avantages groupe & CSE : plan actionnariat, activit√©s √† tarifs pr√©f√©rentiels, remboursement partiel
vacances, remboursement de votre abonnement sportif ou culturel.
Nos engagements et priorit√©s :
Le groupe Capgemini encourage une culture inclusive dans un cadre multiculturel et handi-accueillant. En nous rejoignant, vous int√©grez un collectif qui valorise la diversit√©, d√©veloppe le potentiel de ses talents, s‚Äôengage dans des initiatives solidaires avec ses partenaires, et se mobilise pour r√©duire son impact environnemental sur tous ses sites et aupr√®s de ses clients.
Capgemini
Capgemini est un leader mondial, responsable et multiculturel, regroupant pr√®s de 350 000 personnes dans plus de 50 pays. Fort de 55 ans d‚Äôexp√©rience, nous sommes un partenaire strat√©gique des entreprises pour la transformation de leurs activit√©s en tirant profit de toute la puissance de la technologie et des innovations dans les domaines en perp√©tuelle √©volution tels que le cloud, la data, l‚ÄôIntelligence Artificielle, la connectivit√©, les logiciels, l‚Äôing√©nierie digitale ou les
plateformes.
Get The Future You Want* | www.capgemini.com/fr-fr
*Capgemini, le futur que vous voulez
Show more
Show less","{'ProgLanguage': ['R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': ['Hadoop', 'Spark'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': ['Tableau', 'Power BI'], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git'], 'Os': [], 'DBMS': ['Oracle', 'SQL Server'], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Big Data', 'Cloud'], 'FrSoftSkills': ['Organisation'], 'EnSoftSkils': ['Initiative']}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's', '3', '3', '3']}"
Data Engineer - Bordeaux,Capgemini,"Bordeaux, Nouvelle-Aquitaine, France",https://fr.linkedin.com/jobs/view/data-engineer-bordeaux-at-capgemini-3889788624?position=55&pageNum=0&refId=%2Bft0CQksufPV00p2d83arQ%3D%3D&trackingId=RojGg5KxbvNEdlE9kfJmnw%3D%3D&trk=public_jobs_jserp-result_search-card,"Choisir Capgemini, c'est choisir une entreprise o√π vous serez en mesure de fa√ßonner votre carri√®re selon vos aspirations. Avec le soutien et l'inspiration d'une
communaut√© d‚Äôexperts dans le monde entier, vous pourrez r√©√©crire votre futur. Rejoignez-nous pour red√©finir les limites de ce qui est possible, contribuer √† lib√©rer la
valeur de la technologie pour les plus grandes organisations et participer √† la construction d‚Äôun monde plus durable et inclusif.
Vos missions :
Vous √™tes passionn√© par le domaine de la Data, vous souhaitez prendre part √† des projets d'envergure, concevoir des solutions, les impl√©menter et les faire √©voluer?
Alors rejoignez notre √©quipe Data Engineering Services au sein de Capgemini Cloud Infrastructure Services en tant que Data Engineer.
Vous avez acquis une exp√©rience solide dans le d√©veloppement, la mise en ≈ìuvre et l‚Äôoptimisation de solutions pour le traitement d'un grand volume de donn√©es, vous √™tes capable de cr√©er des solutions qui r√©pondent aux besoins m√©tiers et IT, alors rejoignez notre √©quipe d‚Äôexperts.
En qualit√© de Data engineer, vos missions sont les suivantes :
‚ñ™ Concevoir et d√©velopper des solutions Data/IA.
‚ñ™ Accompagner les M√©tier dans la compr√©hension et la mise en ≈ìuvre de solution orient√©es donn√©es.
‚ñ™ Collaborer avec les Dev, les Ops, les experts infrastructures dans la construction de solutions et d‚Äôinfrastructures ax√©es sur les donn√©es.
‚ñ™ G√©rer un √©cosyst√®me de partenaires data et assurer un haut niveau d'expertise
‚ñ™ Assurer un r√¥le de veille technologique sur tous les outils autours de la data, de l‚ÄôIA et de la BI.
Votre profil :
Vous √™tes issu d‚Äôune formation ing√©nieur ou √©quivalent bac+5 informatique sp√©cialis√©e en DATA et vous justifiez d‚Äôune exp√©rience de 3 √† 5 ans dans un r√¥le similaire. Expert dans une technologie de base de donn√©es relationnelle (PostgreSQL, Oracle...)
Expert dans une technologie de base NoSQL (MongoDB, Cassandra...)
Vous maitrisez un framework de manipulation de donn√©es (Hadoop, Spark, Kafka...)
Vous maitrisez les concepts DevOps et avez de bonnes notions en scripting et d√©veloppement
Vous avez une exp√©rience des outils BI et de data visualisation (Kibana, PowerBI...)
La maitrise de l'anglais est n√©cessaire.
3 raisons de nous rejoindre :
Qualit√© de vie au travail :
accord de t√©l√©travail en France et √† l‚Äôinternational, accord sur l‚Äô√©galit√© professionnelle, la parentalit√©, l‚Äô√©quilibre des temps et la mobilit√© durable.
Apprentissage en continu :
certifications et formations en libre acc√®s, accompagnement sur mesure avec votre career manager, parcours d‚Äôint√©gration sur 9 mois.
Avantages groupe & CSE :
plan actionnariat, tarif pr√©f√©rentiels, remboursement partiel vacances, remboursement de votre abonnement sportif ou culture
Nos engagements et priorit√©s :
Le groupe Capgemini encourage une culture inclusive dans un cadre multiculturel et handi-accueillant. En nous rejoignant, vous int√©grez un collectif qui valorise la diversit√©, d√©veloppe le potentiel de ses talents, s‚Äôengage dans des initiatives solidaires avec ses partenaires, et se mobilise pour r√©duire son impact environnemental sur tous ses sites et aupr√®s de ses clients.
√Ä propos de Capgemini :
Capgemini est un leader mondial, responsable et multiculturel, regroupant pr√®s de 350 000 personnes dans plus de 50 pays. Fort de 55 ans d‚Äôexp√©rience, nous sommes un partenaire strat√©gique des entreprises pour la transformation de leurs activit√©s en tirant profit de toute la puissance de la technologie et des innovations dans les domaines en perp√©tuelle √©volution tels que le cloud, la data, l‚ÄôIntelligence Artificielle, la connectivit√©, les logiciels, l‚Äôing√©nierie digitale ou les plateformes.
Get The Future You Want* | www.capgemini.com/fr-fr
*Capgemini, le futur que vous voulez
Show more
Show less","{'ProgLanguage': ['R', 'Go'], 'DataBase': ['SQL', 'NoSQL', 'Cassandra'], 'DataAnalytics': ['R'], 'BigData': ['Hadoop', 'Spark'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': ['PowerBI'], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git'], 'Os': [], 'DBMS': ['PostgreSQL', 'Oracle'], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['DevOps', 'Cloud'], 'FrSoftSkills': ['Organisation'], 'EnSoftSkils': ['Initiative']}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': ['Bac+5'], 'Experience': ['a', 'n', 's', '5', '5', '5']}"
Data Engineer - Lille,Capgemini,Greater Lille Metropolitan Area,https://fr.linkedin.com/jobs/view/data-engineer-lille-at-capgemini-3914228495?position=56&pageNum=0&refId=%2Bft0CQksufPV00p2d83arQ%3D%3D&trackingId=YtgjI4L6aNfvnVNQpvZkiQ%3D%3D&trk=public_jobs_jserp-result_search-card,"Capgemini en quelques mots
Choisir Capgemini, c'est choisir une entreprise o√π vous serez en mesure de fa√ßonner votre carri√®re selon vos aspirations, o√π vous serez soutenu et inspir√© par une communaut√© d‚Äôexperts dans le monde entier, o√π vous pourrez r√©√©crire votre futur. Rejoignez-nous pour red√©finir les limites de ce qui est possible, contribuer √† lib√©rer la valeur de la technologie pour les plus grandes organisations et participez √† la construction d‚Äôun monde plus durable et inclusif.
Vos missions
Vous maitrisez au minimum un langage de programmation appliqu√© √† l‚Äôanalyse de donn√©es
(Java, Python, Scala et les environnements Spark et / ou Hadoop).
Vous √™tes passionn√© par le Big Data et le Machine Learning et l‚Äôanalyse de donn√©es
Vous concevez et mettez en ≈ìuvre des strat√©gies s√©curis√©es d'acquisition et d'int√©gration de donn√©es
Vous configurez des r√©f√©rentiels de donn√©es √† la pointe de la technologie dans des environnements distribu√©s
Vous construisez des pipelines de donn√©es pour collecter, transformer et traiter des donn√©es en collaboration avec des scientifiques de donn√©es afin de r√©pondre aux exigences de la mod√©lisation de donn√©es d'analyse avanc√©e
Votre profil
Dipl√¥m√©(e) de Bac+5 en informatique
4 ans d‚Äôexp√©rience
(au sein d‚Äôune ESN ou chez un int√©grateur) en conseil client√®le
Une solide culture technologique
Un bon niveau d‚Äôanglais
3 raisons de nous rejoindre
Qualit√© de vie au travail :
accord de t√©l√©travail en France et √† l‚Äôinternational, accord sur l‚Äô√©galit√©
professionnelle, la parentalit√©, l‚Äô√©quilibre des temps et la mobilit√© durable.
Apprentissage en continu :
certifications et formations en libre acc√®s, accompagnement sur mesure avec
votre carreer manager, parcours d‚Äôint√©gration sur 9 mois.
Avantages groupe & CSE :
plan actionnariat, activit√©s √† tarifs pr√©f√©rentiels, remboursement partiel
vacances, remboursement de votre abonnement sportif ou culturel
Nos engagements et priorit√©s
Le groupe Capgemini encourage une
culture inclusive dans un cadre multiculturel et handi-accueillant.
En nous rejoignant, vous int√©grez un collectif qui valorise la diversit√©, d√©veloppe le potentiel de ses talents, s‚Äôengage dans des
initiatives solidaires avec ses partenaires, et se mobilise pour r√©duire son impact environnemental sur tous ses sites et aupr√®s de ses clients.
Capgemini
est un
leader mondial
, responsable et multiculturel, regroupant pr√®s de 350 000 personnes dans plus de 50 pays. Fort de
55 ans d‚Äôexp√©rience,
nous sommes un partenaire strat√©gique des entreprises pour la transformation de leurs activit√©s en tirant profit de toute la puissance de la technologie et des innovations dans les domaines en perp√©tuelle √©volution tels que le
cloud, la data, l‚ÄôIntelligence Artificielle, la connectivit√©, les logiciels, l‚Äôing√©nierie digitale ou les plateformes.
Get The Future You Want* | www.capgemini.com/fr-fr
*Capgemini, le futur que vous voulez
Show more
Show less","{'ProgLanguage': ['Python', 'Java', 'Scala', 'R'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': ['Hadoop', 'Spark'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git'], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Big Data', 'Machine Learning', 'Cloud'], 'FrSoftSkills': ['Collaboration', 'Organisation'], 'EnSoftSkils': ['Collaboration', 'Initiative']}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': ['Bac+5'], 'Experience': ['a', 'n', 's', '4', '4', '4']}"
Data Engineer,Shippeo,Greater Paris Metropolitan Region,https://fr.linkedin.com/jobs/view/data-engineer-at-shippeo-3908268236?position=57&pageNum=0&refId=%2Bft0CQksufPV00p2d83arQ%3D%3D&trackingId=jafpe4e1k7Y1nMFpkU2qCA%3D%3D&trk=public_jobs_jserp-result_search-card,"Founded in 2014, Shippeo is a French based SaaS company providing supply chain visibility. Shippeo has grown from 70 to 220 employees during the last two years and is continuing to rapidly scale after an additional $40M fundraising round in October 2022.
Shippeo is an exceptionally diverse company with colleagues from 27 different nationalities and speaking 29 languages. With offices throughout Europe, North America and recently Asia, Shippeo provides global coverage to all of our clients.
Our product is composed of a mission critical SaaS web platform (API everywhere), with high traffic inbound/outbound integrations.
Our mission is to anticipate problems and proactively alert end-customers so they can efficiently manage exceptions. We achieve this by collecting and matching millions of theoretical and real data from different stakeholders.
The Data Intelligence Tribe is responsible for leveraging Shippeo‚Äôs data from our large shipper and carrier base, to build data products that help our users (shippers and carriers alike) and ML models to provide predictive insights. This tribe‚Äôs typical responsibilities are to:
get accurately alerted in advance of any potential delays on their multimodal flows or anomalies so that they can proactively anticipate any resulting disruptions
extract the data they need, get direct access to it or analyze it directly on the platform to gain actionable insights that can help them increase their operational performance and the quality and compliance of their tracking
provide best-in-class data quality by implementing advanced cleansing & enhancement rules
As a Data Engineer at Shippeo, your objective is to ensure that data is available and exploitable by our Data Scientists and Analysts on our different data platforms. You will contribute to the construction and maintenance of Shippeo‚Äôs modern data stack that‚Äôs composed of different technology blocks:
Data Acquisition (Kafka, KafkaConnect, RabbitMQ),
Batch data transformation (Airflow, DBT),
Cloud Data Warehousing (Snowflake, BigQuery),
Stream/event data processing (Python, docker, Kubernetes) and all the underlying infrastructure that support these use cases.
Qualifications
Required:
You have a degree (MSc or equivalent) in Computer Science.
3+ years of experience as a Data Engineer.
Experience building, maintaining, testing and optimizing data pipelines and architectures
Programming skills in Python and experience with asynchronous event processing (asyncio).
Advanced working knowledge of SQL, experience working with relational databases and familiarity with a variety of databases.
Working knowledge of message queuing and stream processing.
Knowledge of Docker and Kubernetes.
Knowledge of a cloud platform (preferably GCP).
Experience working with workflow management systems such as Airflow.
Desired:
Experience with cloud based data warehouse solutions (BigQuery, Snowflake).
Experience with Kafka and KafkaConnect (Debezium).
Experience with Infrastructure as code (Terraform/Terragrunt).
Experience building and evolving CI/CD pipelines with Github Actions.
Monitoring and alerting on Grafana / Prometheus.
Experience working on Apache Nifi.
Informations suppl√©mentaires
We are looking for talents who share our values:
üöÄ Ambition
üíô Care
üéØ Deliver
ü§ù Collaboration
Find out more about our values in
Our Culture Book
If you identify with our values and enjoy working in a fast-paced and international environment, Shippeo is just the place for you!
We are committed to fostering diversity and inclusion within our workplace as we value the unique perspectives and experiences that individuals from all backgrounds bring to our team. We are dedicated to providing equal employment opportunities to all candidates, regardless of their background or abilities, and our commitment to inclusion is reflected in our policies, practices, and workplace culture.
We understand that candidates may have unique needs or questions related to disability inclusion. To facilitate this, you can reach our dedicated Disability Advisor at
inclusion@shippeo.com
with any inquiries or requests for accommodations during the application process.
Show more
Show less","{'ProgLanguage': ['Python', 'R'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git', 'Docker'], 'Os': [], 'DBMS': ['Snowflake', 'Snowflake', 'BigQuery'], 'SoftBigDataProcessing': [], 'Automation': ['Kubernetes', 'Airflow'], 'InfrastructureAsCode': ['Terraform'], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': ['Docker', 'Kubernetes'], 'Collaboration': [], 'Other': ['ML', 'Cloud', 'CI/CD'], 'FrSoftSkills': ['Collaboration'], 'EnSoftSkils': ['Collaboration']}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's']}"
Data Analyst H/F,Inetum,"Lille, Hauts-de-France, France",https://fr.linkedin.com/jobs/view/data-analyst-h-f-at-inetum-3843955768?position=58&pageNum=0&refId=%2Bft0CQksufPV00p2d83arQ%3D%3D&trackingId=%2BJ5llu0dbHYqsciKs3%2Fatg%3D%3D&trk=public_jobs_jserp-result_search-card,"D√©tail de l'offre
Informations g√©n√©rales
Entit√© de rattachement
Inetum est un leader europ√©en des services num√©riques. Pour les entreprises, les acteurs publics et la soci√©t√© dans son ensemble, les 28 000 consultants et sp√©cialistes du groupe visent chaque jour l'impact digital des solutions qui contribuent √† la performance, √† l'innovation et au bien commun.
Pr√©sent dans 19 pays au plus pr√®s des territoires, et avec ses grands partenaires √©diteurs de logiciels, Inetum r√©pond aux enjeux de la transformation digitale avec proximit√© et flexibilit√©.
Port√© par son ambition de croissance et d'industrialisation, Inetum a g√©n√©r√© en 2023 un chiffre d'affaires de 2,5 milliards d'‚Ç¨.
Pour r√©pondre √† un march√© en croissance continue depuis plus de 30ans, Inetum a fait le choix d√©lib√©r√© de se recentrer sur 4 m√©tiers afin de gagner en puissance et proposer des solutions sur mesure, adapt√©es aux besoins sp√©cifiques de ses clients le conseil (Inetum Consulting), la gestion des infrastructures et applications √† fa√ßon (Inetum Technologies), l'impl√©mentation de progiciels (Inetum Solutions) et sa propre activit√© d'√©diteur de logiciels (Inetum Software). Inetum a conclu des partenariats strat√©giques avec 4 grands √©diteurs mondiaux - Salesforce, ServiceNow, Microsoft et SAP et poursuit une strat√©gie d'acquisitions d√©di√©e afin d'entrer dans le top 5 europ√©en sur ces technologies et proposer la meilleure expertise √† ses clients.
Tous nos postes sont ouverts aux personnes en situation de handicap.
Description du poste
M√©tier
Applications Delivery - Software Development
Intitul√© du poste
Data Analyst H/F
Contrat
CDI
Description De La Mission
Dans le cadre de la croissance de notre agence lilloise, nous d√©veloppons notre Practice Data et recrutons des profils Data de divers horizons Data Analyst, Data Engineer, Data Scientist et Data Gouv. Les besoins m√©tiers de nos clients et la multitude des technologies font qu'il nous faut nous appuyer sur une diversit√© de comp√©tences. Vous pourriez √™tre l‚Äôun d‚Äôeux et rejoindre Inetum.
En tant que Data Analyst, vos principales missions consistent √†
Analyser et retranscrire le besoin client
Identifier, extraire et exploiter les sources d'acquisition de donn√©es les plus pertinentes
Valoriser de la donn√©e
D√©velopper l'outil de data visualisation pour accompagner les √©quipes m√©tiers dans leurs aides √† la d√©cision
√ätre le lien entre les √©quipes m√©tier pour les accompagner dans la mise en ≈ìuvre des nouveaux outils
Profil
Pour mener √† bien votre r√¥le, il vous faut
parler SQL couramment
un niveau avanc√© sur Excel et/ou Google Spreadsheet
une ma√Ætrise d'un outil d√©cisionnel comme PowerBI, Qlik, Tableau ou encore Google Data Studio
Vous vous reconnaissez dans ces quelques lignes, alors rencontrons-nous !
Notre plus
Rejoindre la r√©gion Nord-Est, c‚Äôest b√©n√©ficier des avantages d‚Äôun Grand Groupe tout en gardant la proximit√© r√©gionale.
Nous mettrons tout en ≈ìuvre pour vous apporter un √©quilibre vie perso / vie pro. C‚Äôest pourquoi nous vous proposons un rythme hybride (selon les contraintes clients)
Une trajectoire de carri√®re personnalis√©e et adapt√©e √† vos souhaits d'√©volution gr√¢ce √† une implantation √† l‚Äôinternational (26 pays, 7 Fablab), des formations cibl√©es et des projets couvrant l‚Äôensemble de la cha√Æne de valeur IT (+25 fili√®res m√©tiers)
Int√©grer un collectif d‚Äôexperts partageant des valeurs de solidarit√© et d‚Äôexcellence
Int√©grer une entreprise ayant une strat√©gie affirm√©e de certifications de ses collaborateurs
Localisation du poste
Localisation du poste
France, Nord, 59 Nord
Ville
Lille
Crit√®res candidat
Niveau d'√©tudes min. requis
Bac+5
Niveau d'exp√©rience min. requis
Plus de 2 ans
Show more
Show less","{'ProgLanguage': ['R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': ['Tableau', 'PowerBI'], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git'], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': [], 'FrSoftSkills': ['Flexibilit√©'], 'EnSoftSkils': []}","{'JobDetail': ['Hybride'], 'TypeContract': ['CDI'], 'Salary': [], 'Level': ['Bac+5'], 'Experience': ['a', 'n', 's', '30', '30', '30']}"
Data Engineer - Nantes,Capgemini,"Nantes, Pays de la Loire, France",https://fr.linkedin.com/jobs/view/data-engineer-nantes-at-capgemini-3803998213?position=59&pageNum=0&refId=%2Bft0CQksufPV00p2d83arQ%3D%3D&trackingId=I6LGHv9gJqEsYZUA6b%2BIRg%3D%3D&trk=public_jobs_jserp-result_search-card,"Capgemini
Choisir Capgemini, c'est choisir une entreprise o√π vous serez en mesure de fa√ßonner votre carri√®re selon vos aspirations, o√π vous serez soutenu et inspir√© par une communaut√© d‚Äôexperts dans le monde entier, o√π vous pourrez r√©√©crire votre futur. Rejoignez-nous pour red√©finir les limites de ce qui est possible, contribuer √† lib√©rer la valeur de la technologie pour les plus grandes organisations et participez √† la construction d‚Äôun monde plus durable et inclusif.
Vos missions :
Int√©gr√©(e) au sein d'une √©quipe projets intervenant pour des clients dans des secteurs d'activit√©s vari√©es, vous serez notamment en charge des missions suivantes :
Concevoir et mettre en oeuvre des strat√©gies s√©curis√©es d'acquisition et d'int√©gration de donn√©es,
Configurer des r√©f√©rentiels de donn√©es √† la pointe de la technologie dans des environnements distribu√©s, majoritairement dans le cloud (Google Cloud Platform, Azure Databricks, AWS) et/ou en environnement Hadoop (distribution MapR, Cloudera, Hortonworks),
Construire des pipelines de donn√©es pour collecter, transformer et traiter des donn√©es en collaboration avec des scientifiques de donn√©es afin de r√©pondre aux exigences de la mod√©lisation de donn√©es d'analyse avanc√©e.
Votre profil :
Dipl√¥me d‚Äôing√©nieur ou √©quivalent universitaire
Minimum 3 ans d'exp√©rience
Anglais courant
Ma√Ætrise des langages Java, Scala ou Python et expertise sur les framework Spark et/ou Hadoop.
Expertise sur les services Cloud Data Platform suivants : Azure Data Lake, Azure synapse, Azure Data Factory, Azure Data Explorer, GCP, AWS, Snowflake, Databricks‚Ä¶
3 raisons de nous rejoindre :
Qualit√© de vie au travail : accord de t√©l√©travail en France et √† l‚Äôinternational, accord sur l‚Äô√©galit√©
professionnelle, la parentalit√©, l‚Äô√©quilibre des temps et la mobilit√© durable.
Apprentissage en continu : certifications et formations en libre acc√®s, accompagnement sur mesure avec votre carreer manager, parcours d‚Äôint√©gration sur 9 mois.
Avantages groupe & CSE : plan actionnariat, activit√©s √† tarifs pr√©f√©rentiels, remboursement partiel
vacances, remboursement de votre abonnement sportif ou culturel.
Nos engagements et priorit√©s :
Le groupe Capgemini encourage une culture inclusive dans un cadre multiculturel et handi-accueillant. En nous rejoignant, vous int√©grez un collectif qui valorise la diversit√©, d√©veloppe le potentiel de ses talents, s‚Äôengage dans des initiatives solidaires avec ses partenaires, et se mobilise pour r√©duire son impact environnemental sur tous ses sites et aupr√®s de ses clients.
Capgemini
Capgemini est un leader mondial, responsable et multiculturel, regroupant pr√®s de 350 000 personnes dans plus de 50 pays. Fort de 55 ans d‚Äôexp√©rience, nous sommes un partenaire strat√©gique des entreprises pour la transformation de leurs activit√©s en tirant profit de toute la puissance de la technologie et des innovations dans les domaines en perp√©tuelle √©volution tels que le cloud, la data, l‚ÄôIntelligence Artificielle, la connectivit√©, les logiciels, l‚Äôing√©nierie digitale ou les plateformes.
Get The Future You Want* | www.capgemini.com/fr-fr
*Capgemini, le futur que vous voulez
Show more
Show less","{'ProgLanguage': ['Python', 'Java', 'Scala', 'R', 'Go'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': ['Hadoop', 'Spark', 'Databricks'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': ['AWS', 'Azure', 'Google Cloud Platform'], 'DevTools': ['Git'], 'Os': [], 'DBMS': ['Snowflake', 'Snowflake'], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Cloud'], 'FrSoftSkills': ['Collaboration', 'Organisation'], 'EnSoftSkils': ['Collaboration', 'Initiative']}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's', '3', '3', '3']}"
Data engineer,SEVETYS,"Paris, √éle-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-at-sevetys-3905649273?position=60&pageNum=0&refId=%2Bft0CQksufPV00p2d83arQ%3D%3D&trackingId=sAzsq9wB%2BUgoQbgu5X0fbg%3D%3D&trk=public_jobs_jserp-result_search-card,"Sevetys, premier groupe fran√ßais de cliniques v√©t√©rinaires, est pr√©sent dans toute la France avec plus de 150 √©tablissements. Cr√©√© en 2016, le groupe souhaite moderniser le m√©tier et mettre la qualit√© des soins et la satisfaction client au c≈ìur de son projet.
Le projet d‚Äôentreprise se caract√©rise par son hyper croissance et une culture de type start-up ax√©e sur le collectif, la coh√©sion, et l‚Äôengagement.
Fort de son succ√®s, Sevetys poursuit sa structuration et recrute un / une :
Data Engineer
‚ÄãLe
Data Engineer
travaille en √©troite collaboration avec une √©quipe Agile pluridisciplinaire pour construire des pipelines de donn√©es de haute qualit√© permettant de mettre en ≈ìuvre des solutions analytiques. Ces solutions g√©n√®reront des informations √† partir de nos donn√©es collect√©es, permettant de faire progresser les capacit√©s de prise de d√©cision du management de l‚Äôentreprise. Ce r√¥le n√©cessite une compr√©hension approfondie de l'architecture des donn√©es, de l'ing√©nierie des donn√©es, de l'analyse des donn√©es, du reporting. Le candidat id√©al est un ing√©nieur en donn√©es/logiciel ayant au moins une premi√®re exp√©rience dans la cr√©ation de produits de donn√©es soutenant des solutions analytiques.
Missions :
Con√ßoit, d√©veloppe, optimise et maintient une architecture de donn√©es et des pipelines qui respectent les objectifs de l'entreprise ;
R√©sout des probl√®mes de donn√©es afin de fournir des informations qui aident notre entreprise √† atteindre ses objectifs ;
Cr√©e des jeux de donn√©es pour les membres de l'√©quipe d'analyse afin d'am√©liorer leur productivit√© ;
Favorise une culture du partage, de la r√©utilisation, de la stabilit√© de la conception √† l'√©chelle et de l'efficacit√© op√©rationnelle des donn√©es et des solutions analytiques ;
Contribue √† l'√©valuation, la mise en ≈ìuvre et le d√©ploiement d'outils et de processus √©mergents pour l'ing√©nierie des donn√©es analytiques afin d'am√©liorer notre productivit√© en tant qu'√©quipe ;
√âlabore et met en ≈ìuvre des plans de communication/√©ducation sur les capacit√©s, les normes et les processus d'ing√©nierie des donn√©es analytiques ;
Travaille en partenariat avec des analystes business et des architectes de solutions pour d√©velopper des architectures techniques pour les projets et initiatives strat√©giques de l'entreprise.
Expertises techniques :
Exp√©rience du d√©veloppement de bases de donn√©es et d'une vari√©t√© de technologies de bases de donn√©es relationnelles ;
Exp√©rience des entrep√¥ts de donn√©es ;
Expertise en SQL et en analyse de donn√©es ; ma√Ætrise Python ;
Id√©alement certifi√© des technologies BI du Cloud Azure (Synapse, Azure Data Factory, PurView) ;
Connaissance de l'intelligence artificielle, des statistiques et/ou des math√©matiques appliqu√©es ;
Exp√©rience dans le d√©veloppement de solutions sur des services et infrastructures de cloud computing dans le domaine des donn√©es et de l'analyse ;
Exp√©rience du d√©ploiement de Power BI ;
Exp√©rience conceptuelle des donn√©es et de l'analyse, par exemple ETL, mod√©lisation dimensionnelle, outils de reporting, gouvernance des donn√©es, entreposage des donn√©es, donn√©es structur√©es et non structur√©es, qualit√© de donn√©es ;
Connaissance CI/CD et GitLab fortement appr√©ci√©.
Exp√©rience agile / Digitale / gouvernance :
Passionn√©(e) le d√©veloppement bas√© sur les donn√©es, la fiabilit√© et l'exp√©rimentation ;
Exp√©rience souhait√©e de travail au sein d'une √©quipe produit Agile collaborative ;
Connaissance de la gouvernance de la donn√©e.
Skills Individuels :
Motiv√©(e) et dot√©(e) de solides comp√©tences en mati√®re de r√©solution de probl√®mes et d'apprentissage ;
Flexibilit√© face aux changements d'orientation du travail au fur et √† mesure de l'√©volution du projet ;
Excellentes capacit√©s de communication, d'√©coute et de persuasion.
Attitude attendue :
Sens aigu des chiffres, curiosit√© intellectuelle et volont√© d'adapter sa position sur la base d'informations compl√©mentaires ;
Forte √©thique de travail ; capacit√© √† travailler √† un niveau abstrait et √† obtenir un consensus.
Informations suppl√©mentaires :
Poste √† pourvoir d√®s que possible ;
Remboursement des frais de transports + Mutuelle ;
Possibilit√© de t√©l√©travail jusqu'√† un jour par semaine.
Show more
Show less","{'ProgLanguage': ['Python', 'R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': ['Power BI'], 'Statistics': ['Statistiques'], 'CloudComputing': ['Azure'], 'DevTools': ['Git'], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Statistiques', 'Cloud', 'CI/CD'], 'FrSoftSkills': ['Communication', 'R√©solution de probl√®mes', 'Collaboration', 'Flexibilit√©'], 'EnSoftSkils': ['Communication', 'Collaboration', 'Initiative']}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's']}"
Data Engineer GCP (H/F),SQLI,Greater Paris Metropolitan Region,https://fr.linkedin.com/jobs/view/data-engineer-gcp-h-f-at-sqli-3849296046?position=1&pageNum=2&refId=rN2g5dxyW%2FccP664CRL%2Fiw%3D%3D&trackingId=q0SSFSDKgsYvdPnzuKCXRg%3D%3D&trk=public_jobs_jserp-result_search-card,"Rejoignez
SQLI
et faites partie de l'√©quipe Data, au sein d‚Äôune soci√©t√© √† taille humaine, mais avec de grandes ambitions. Nous sommes plus de 2200 talents sur 13 pays et 3 continents.‚Äã
Votre futur √©cosyst√®me :
Au sein du p√¥le Data de SQLI
, pour rejoindre une √©quipe dynamique de +40 passionn√©s.
Des projets digitaux pour des clients grands comptes
: notamment dans les secteurs des services financiers, de l'industrie et du retail.
Une organisation orient√©e delivery
: vous travaillerez au sein de nos locaux ou en √©quipe int√©gr√©e chez nos clients en mode 100% agile, en mode projet.
Possibilit√© de t√©l√©travail jusqu'√† 3 jours par semaine
Des communaut√©s d‚ÄôExperts
, pour vous aider √† progresser‚Äã, avec des workshops et ateliers techniques favorisant le partage de connaissances.‚Äã
Des Managers de carri√®re
, pour √™tre suivi par l'un de vos pairs sur l'entit√© Data, avec un
accompagnement dans l‚Äôexpression de vos talents
(certifications et formations notamment via le partenariat Solutions de Microsoft, participation aux √©v√®nements/salons, publications dans la presse...).
Description du poste :
Un poste de
Data Engineer GCP (H/F)
est ouvert √†
PARIS ou ROUEN
(selon votre localisation)
, pour faire partie de l‚Äô√©quipe Data chez SQLI et vous investir dans un environnement technique innovant.
Vos missions seront :
L'analyse et la compr√©hension des besoins m√©tiers.
La participation √† la d√©finition et √† la conception de l‚Äôarchitecture.
La r√©alisation des pr√©sentations, d√©monstrations, POC ou Pilotes pour mettre en lumi√®re les recommandations technologiques.
Les d√©veloppements de jobs d‚Äôalimentation (pr√©paration, ingestion, traitement et contr√¥le qualit√©) et l'automatisation des flux d‚Äôalimentation du Data Lake et du Datawarehouse
Les tests de charge, tests unitaires‚Ä¶
La maintenabilit√© de la solution Big Data/BI : optimisation et performance des traitements.
Qualifications :
Ing√©nieur(e) de formation, avec minimum
3 ans d‚Äôexp√©rience sur des projets Google Cloud Platform (BigQuery, Dataflow, ...)
Toujours en veille, √† l‚Äôaffut des nouveaut√©s technologiques et vous aimez √©changer (Events, conf√©rences, meetups, etc‚Ä¶).
Force de proposition, vous vous sentez libre d‚Äôoser et de vous surpassez en partageant vos id√©es.
Comp√©tences techniques requises :
Ma√Ætrise d'un langage de programmation
(Python, Java, R, Spark, Scala).
Ma√Ætrise de
SQL.
Une exp√©rience sur au moins un ETL/ELT
(Talend, DBT).
Bonne connaissance des outils et framework d‚Äôindustrialisation
CI/CD
et/ou gestion de version (Gitlab).
Serait un plus : une exp√©rience sur Power BI, TIBCO EBX et/ou BO DS + la gestion de Conteners et Kubernetes (GKE).
Vous pensez que ce poste est fait pour vous ? Transmettez-nous votre profil !
Tous nos postes sont ouverts aux personnes en situation de handicap.
Des questions sur vos donn√©es personnelles ? Retrouvez notre politique de confidentialit√© concernant les candidats :
https://www.sqli.com/sites/default/files/2024-01/SQLI-PRIV-Politique-Confidentialite-Candidats-C0-29012024.pdf
Show more
Show less","{'ProgLanguage': ['Python', 'Java', 'Scala', 'R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': ['Spark'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': ['Power BI'], 'Statistics': [], 'CloudComputing': ['Google Cloud Platform'], 'DevTools': ['Git'], 'Os': [], 'DBMS': ['BigQuery'], 'SoftBigDataProcessing': [], 'Automation': ['Kubernetes'], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': ['Kubernetes'], 'Collaboration': [], 'Other': ['Big Data', 'Cloud', 'CI/CD'], 'FrSoftSkills': ['Organisation'], 'EnSoftSkils': []}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's', '3', '3', '3']}"
Data Engineer,Ramify,Greater Paris Metropolitan Region,https://fr.linkedin.com/jobs/view/data-engineer-at-ramify-3896146641?position=2&pageNum=2&refId=rN2g5dxyW%2FccP664CRL%2Fiw%3D%3D&trackingId=vrtH67mVok2YYcaQDsBDEg%3D%3D&trk=public_jobs_jserp-result_search-card,"ABOUT
Ramify‚Äôs mission is to help people achieve financial freedom, no matter who they are and how much they have. We are revolutionizing the private wealth management industry by making smart and affordable financial products for everyone.
No more standardized solutions, hidden fees and complicated words, Ramify enables everyone to become a smart investor. The team combines elements of its research with technology to design customized investment portfolios composed of world-class financial products.
The team comprises around 15 talented individuals. Ramify is looking for talented people in all sectors, who want to have a huge impact, move fast and deliver.
JOB DESCRIPTION
The Quantitative Investment Solutions (QIS) Team is dedicated to designing innovative investment portfolio models and developing cutting-edge investment features within our product suite. Moreover, the QIS Team is at the forefront of driving AI-based solutions for Ramify. This involves conceptualizing and implementing transformative AI solutions tailored to meet the diverse needs of various teams within Ramify.
As a Data Engineer on our QIS Team, you will play a pivotal role in shaping the future of investment strategies through data-driven insights and AI-based solutions. Collaborating closely with our talented team of quantitative researchers, and investment experts, your responsibilities will encompass architecting and implementing robust data pipelines. These pipelines will facilitate the seamless integration of diverse data sources, empowering Ramify teams to make informed decision-making.
Key Responsibilities:
Design, build and launch data pipelines at scale to move data across Ramify platform with SQL technologies.
Design and implement processes and tools for data onboarding and quality, helping to deliver an industry best-practice solution for managing the data lifecycle.
Produce stand-alone tools that can be used by other teams to automate data quality and discover faults.
Build analytical tools that provide insight into business metrics across Ramify.
Architect and lead the implementation of AI based solutions within Ramify
PREFERRED EXPERIENCE
We're looking for people who:
Want to make a difference. We are a small team effectively reshaping how people look at the industry. We need people who 'get it' and want to play an integral part in helping us accomplish this mission and are persistent in getting the job done.
Skills we're looking for:
Master‚Äôs or upper-year undergraduate-level coursework in either Computer Science, Management Information Systems, Business Information Systems, Mathematics or Finance related field.
2+ years of professional experience in data engineering.
2+ years of experience with one or more coding languages such as Python (is a must), Java.
Experience with data modeling and ETL design, implementation and maintenance.
Demonstrable mastery of industry best practices in the data lifecycle, including data quality automation and tooling.
Excellent written and verbal communication skills with ability to communicate complex designs and solutions to non-technical and highly technical audiences alike.
Good attention to detail.
Strong analytics and strategic thinking skills
Nice-to-haves :
Understanding of ML/ Generative AI technologies and their applications.
Possess a passion, curiosity, and energy for finance + investing. You understand the ins and outs of the wealth management, trading, and more importantly - know how to explain these concepts simply
Show more
Show less","{'ProgLanguage': ['Python', 'Java', 'R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': ['Teams'], 'Other': ['ML'], 'FrSoftSkills': ['Communication'], 'EnSoftSkils': ['Communication']}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's']}"
Data Engineer (F/H),Aubay,"√éle-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-f-h-at-aubay-3573871076?position=3&pageNum=2&refId=rN2g5dxyW%2FccP664CRL%2Fiw%3D%3D&trackingId=k79CGxfiT%2FKLoGFBpuNiqw%3D%3D&trk=public_jobs_jserp-result_search-card,"Passionn√© par la Data, tu souhaites rejoindre une communaut√© d‚Äôexperts dans le domaine afin de d√©velopper tes comp√©tences en Data Engineering. Aubay renforce ses √©quipes Data et recherche des Data Engineers pour int√©grer des dispositifs de projets pointus et vari√©s.
Ton quotidien en tant que Data Engineer chez Aubay, :
D√©finition de la strat√©gie de stockage et mise en ≈ìuvre des technologie appropri√©es (base de donn√©es SQL, NoSQL, stockage distribu√©,‚Ä¶)
Ingestion des donn√©es (structur√©es, semi-structur√©es ou non-structur√©es) selon diff√©rentes fr√©quences : batch, micro-batch ou temps r√©el
Conception et mise en ≈ìuvre de pipelines de donn√©es afin de fournir des donn√©es pr√™tes √† l‚Äôemploi aux consommateurs : uniformisation, mise en qualit√©, enrichissement, calcul d‚Äôindicateurs,‚Ä¶
Conception et d√©veloppement d‚ÄôAPI pour exposer les donn√©es aupr√®s d‚Äôapplications tierces
Appui aux Data Scientists pour industrialiser et optimiser les algorithmes de Machine Learning
Pr√©paration et animation d‚Äôateliers de travail avec des interlocuteurs vari√©s : recueil/approfondissement des besoins m√©tiers, avancement/restitution des travaux, transfert de comp√©tences,‚Ä¶
Ton profil :
Tu dispose d‚Äôune formation niveau BAC+5 (Master 2 ou √©cole d‚Äôing√©nieur) sp√©cialis√©e en informatique
Tu as d√©j√† une premi√®re exp√©rience significative (a minima 2 ans) en Data Engineering sur des technologies Big Data
Les technologies telles que Hadoop, Spark ou Kafka sont tes technologies de pr√©dilection
La programmation n‚Äôa plus de secret pour toi et tu maitrise parfaitement un ou plusieurs langages de programmation suivants : Java, Scala et Python
Tu ma√Ætrises les tenants et aboutissants de la philosophie DevOps et des outils orient√©s CI/CD
Tu es soucieux de la qualit√© et de la performance de tes d√©veloppements et tu t'int√©resse √† l‚Äôinnovation frugale
Tu es un expert technique dans ton domaine sans pour autant oublier l‚Äôimportance d‚Äôune communication orale et √©crite de qualit√© et adapt√©e √† chacun de tes interlocuteurs
Tu travaille au quotidien en mode agile et tu en maitrise les fondements
Ce qui nous caract√©rise :
Des missions et projets dans le domaine du Data Engineering en nombre et dans des secteurs vari√©s (Banque, Assurance, Telecom, Industrie,‚Ä¶) qui permettent √† nos collaborateurs de monter en comp√©tences et de devenir des experts Data reconnus
De l‚Äôapprentissage en continu avec des formations et des certifications sur les technologies Data d‚Äôaujourd‚Äôhui et de demain
Des experts Data mobilisables pour accompagner et soutenir techniquement les collaborateurs sur leurs projets
Des communaut√©s de savoir-faire Data proposant de mani√®re r√©guli√®re aux collaborateurs d‚ÄôAubay du contenu et des √©v√®nements de partage (webinar, meetup/afterwork, BBL,‚Ä¶) sur les th√©matiques suivantes : Data Engineering, Data Viz, Data Science/IA, Data Platform & Architecture,‚Ä¶
Aubay encourage la diversit√© sous toutes ses formes et garantit l'√©galit√© des chances √† tous les candidats. Tous nos postes sont ouverts aux personnes en situation de handicap et nous proposons tous les am√©nagements n√©cessaires.
Ta carri√®re chez Aubay :
Tu auras la possibilit√© de d√©velopper et certifier tes comp√©tences sur les derni√®res technologies Data avec un focus fort sur les plateformes Data Cloud telles qu‚ÄôAzure Synapse Analytics, Google Cloud Platform, Snowflake et Databricks
Tu pourras rejoindre la BU d‚Äôexcellence Data et √©voluer au sein d‚Äôun environnement humain et professionnel de haut niveau. Tu profiteras d‚Äôun management sur-mesure pour t'accompagner dans ta trajectoire de carri√®re
Au sein de la BU d‚Äôexcellence, de multiples perspectives s‚Äôoffriront √† toi :
R√¥le de ¬´ Lead ¬ª : Vous pourrez gagner en responsabilit√© sur le plan technologique et devenir un r√©f√©rent aupr√®s de nos clients et des collaborateurs de la communaut√© Data Engineering
R√¥le de ¬´ Champion ¬ª : Vous repr√©senterez Aubay aupr√®s d‚Äôun ou plusieurs de nos partenaires √©diteurs strat√©giques et vous participerez activement √† l‚Äôanimation de la relation sur le plan technologique
R√¥le de ¬´ Head ¬ª : Vous pourrez prendre la responsabilit√© du savoir-faire Data Engineering et de ses offres et en assurer le d√©veloppement au sens large (d√©veloppement business, recrutement, management de collaborateurs, d√©finition de la strat√©gie et animation de la communaut√© au sein du groupe Aubay,‚Ä¶)
Besoin d‚Äôen savoir plus sur le processus de recrutement ?
Un √©change macro au niveau RH avec Doriane
Un entretien technique avec Marius ou Peter, deux de nos r√©f√©rents techniques
Un √©change manag√©rial avec le Directeur de la BU Modern BI & Data
A savoir que l‚Äôordre des √©tapes peut varier selon tes envies (ex : √©change manag√©rial avec l‚Äô√©change technique)
Aubay encourage la diversit√© sous toutes ses formes et garantit l'√©galit√© des chances √† tous les candidats. Tous nos postes sont ouverts aux personnes en situation de handicap et nous proposons tous les am√©nagements n√©cessaires.
Show more
Show less","{'ProgLanguage': ['Python', 'Java', 'Scala', 'R', 'Go'], 'DataBase': ['SQL', 'NoSQL'], 'DataAnalytics': ['R'], 'BigData': ['Hadoop', 'Spark', 'Databricks'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': ['Azure', 'Google Cloud Platform'], 'DevTools': [], 'Os': [], 'DBMS': ['Snowflake', 'Snowflake'], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['DevOps', 'Big Data', 'Machine Learning', 'Cloud', 'CI/CD'], 'FrSoftSkills': ['Communication'], 'EnSoftSkils': ['Communication']}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': ['Bac+5'], 'Experience': ['a', 'n', 's', '2', '2', '2']}"
Data Engineer (F/H) √† Nantes,Siderlog Conseil,"Nantes, Pays de la Loire, France",https://fr.linkedin.com/jobs/view/data-engineer-f-h-%C3%A0-nantes-at-siderlog-conseil-3858540683?position=4&pageNum=2&refId=rN2g5dxyW%2FccP664CRL%2Fiw%3D%3D&trackingId=DxBzvcbPcNHCGYMUrtb6ag%3D%3D&trk=public_jobs_jserp-result_search-card,"Rejoignez une Aventure Passionnante chez Nous !
üöÄ
Si vous recherchez une entreprise en pleine croissance o√π votre potentiel peut s'√©panouir pleinement, vous √™tes au bon endroit !
Chez nous, l'humain est au c≈ìur de notre culture d'entreprise. Nous croyons en l'autonomie, la confiance et le partage comme des valeurs essentielles qui guident chacune de nos actions.
Ne perdez plus de temps, rencontrons-nous d√®s maintenant !
En tant que membre de notre √©quipe de consultants Siderlog, vous travaillerez en √©troite collaboration avec nos clients. Voici un aper√ßu des missions qui vous attend :
Contribution √† la fabrication de produits dans un environnement Cloudera üõ†Ô∏è
Accompagnement sur la fabrication des mod√®les de Machine Learning sur des donn√©es √©nerg√©tiques et plus largement ESG. ü§ñ
Attendu :
Contribuer au sein d'une √©quipe agile √† r√©pondre aux besoins des Caisses r√©gionales.. üåê
D√©finir les architectures des solutions avec le reste de l‚Äô√©quipe üèóÔ∏è
Fabriquer et tester les solutions üß™
D√©ployer dans les diff√©rents environnements üöÄ
Garantir le bon fonctionnement en production üíº
Accompagner l‚Äô√©volution des pratiques de l‚Äô√©quipe dans une logique d‚Äôam√©lioration continue de la qualit√© du code üìà
Entrainer et tester des mod√®les de Machine Learning üß†
Profil :
Une exp√©rience entre 4 √† 7 ans
Lieu : Nantes
D√©but : D√®s que possible
Show more
Show less","{'ProgLanguage': ['R'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Machine Learning', 'Cloud'], 'FrSoftSkills': ['Collaboration'], 'EnSoftSkils': ['Collaboration']}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's', '7', '7', '7']}"
Data Engineer / D√©veloppeur Big Data # H/F,Air France,"Provence-Alpes-C√¥te d'Azur, France",https://fr.linkedin.com/jobs/view/data-engineer-d%C3%A9veloppeur-big-data-%23-h-f-at-air-france-3900080172?position=5&pageNum=2&refId=rN2g5dxyW%2FccP664CRL%2Fiw%3D%3D&trackingId=NX0nz5pJuxjwXtKaw7Y37Q%3D%3D&trk=public_jobs_jserp-result_search-card,"Description du poste
Intitul√© du poste
Data Engineer / D√©veloppeur Big Data # H/F
M√©tier
Syst√®mes d'informations - D√©veloppement
Cat√©gorie socio-professionnelle
Cadre
Pr√©sentation du contexte
Vous avez peut-√™tre d√©j√† voyag√© avec nous, mais que connaissez-vous de nos m√©tiers et de la richesse des donn√©es qu‚Äôils g√©n√®rent au quotidien ? Comment le traitement et l‚Äôexploitation de ces donn√©es peut contribuer √† notre strat√©gie de Revenue Management, ou encore aux multiples op√©rations √† r√©aliser pour permettre √† un vol de partir √† l‚Äôheure ?
Air France-KLM fait r√™ver 104 millions de passagers par an, en les emmenant vers plus de 250 destinations, gr√¢ce √† une flotte de plus de 500 appareils. Le Groupe emploie 80 000 collaborateurs partout dans le monde :les opportunit√©s sont vastes pour mettre √† profit ses comp√©tences, apprendre et se d√©velopper !
Le d√©partement de d√©veloppement DATA, OR & AI d‚ÄôAir France, au sein de la direction des Syst√®mes d‚ÄôInformation, intervient dans toute la cha√Æne de captation et de traitement des donn√©es du groupe pour d√©livrer √† nos m√©tiers des solutions applicatives cl√©s en main.
Le d√©partement est √©galement en charge de l‚Äôensemble des outils techniques (ETL, DataLakes, DataWarehouses, Data visualisation) et du d√©veloppement des talents et comp√©tences de Data Engineering.
Notre mission ? Transformer la donn√©e brute en d√©cision intelligente, pour mieux optimiser les m√©tiers d‚ÄôAir France ‚Äì KLM !
Pour cela, nous avons chacun un r√¥le essentiel √† jouer, pourquoi le v√¥tre ne serait pas celui de Data Engineer et de d√©veloppeur Big Data ?
Description de la mission
Au sein de notre d√©partement, vous travaillerez main dans la main avec d‚Äôautres Data Engineers et d√©veloppeurs Big Data ainsi qu‚Äôavec des sp√©cialistes des m√©tiers.
Int√©gr√© au sein d‚Äôune product team agile passionn√©e et dynamique :
Vous participez √† l‚Äôanalyse des besoins m√©tiers du commercial, des op√©rations a√©riennes, de l‚Äôexploitation sol en a√©roport, de la maintenance a√©ronautique ou encore du Cargo.
Vous contribuez √† la d√©finition, au d√©veloppement, √† l‚Äôindustrialisation et √† la maintenance d‚Äôapplications Big Data ou en Business Intelligence
Vous pr√©sentez la restitution de vos travaux et accompagnez les utilisateurs d‚Äôun point de vue fonctionnel ou m√©thodologique
Vous serez en contact avec les directions m√©tier du groupe Air France KLM.
Nous attachons beaucoup d'importance au d√©veloppement des comp√©tences de nos collaborateurs ainsi qu‚Äô√† leur offrir des conditions de travail favorables √† l‚Äôautonomie et aux missions √† forte valeur ajout√©e. L'ouverture, le respect, la bienveillance et le partage sont des valeurs humaines port√©es par l'entreprise.
Profil recherch√©
Vous √™tes dipl√¥m√© de niveau Master ou Ing√©nieur dans les domaines informatiques, vous avez acquis une exp√©rience professionnelle dans le d√©veloppement d‚Äôapplications.
Vous disposez d‚Äôune exp√©rience du d√©veloppement indispensable en Backend / Java
Vous ma√Ætrisez les bases de donn√©es relationnelles et le langage SQL
En Compl√©ment, Vous Avez Une Connaissance Ou Une Exp√©rience Dans Tout Ou Partie Des Concepts Ou Outils Suivants
Environnement Big Data (Spark, Hadoop, Elasticsearch, Kafka, ...)
Base de donn√©es noSQL (MongoDB, HBase, REDIS) ou Data Warehouse Teradata
Outil de Datavisualisation (Spotfire, PowerBI, Qlik ou Kibana)
Solutions de Cloud (GCP) et hybride (GCP / AZURE)
(Ces comp√©tences compl√©mentaires ou manquantes pouvant aussi s'acqu√©rir √† travers un parcours de reskilling et de formations aux outils du data engineering dispens√© en interne).
Vous avez particip√© √† des projets organis√©s en Scrum ou Kanban, et avez peut-√™tre m√™me ≈ìuvr√© comme Scrum-Master, ce qui vous permettra de vous int√©grer ais√©ment au sein d‚Äôune Product Team. Votre esprit de synth√®se, votre force de conviction et votre ma√Ætrise de la communication facilitent les d√©cisions avec l‚Äôensemble des collaborateurs de l‚Äô√©quipe, √©ventuellement en langue anglaise, √† l‚Äô√©crit comme √† l‚Äôoral.
Vous √™tes autonome, rigoureux(se), responsable et curieux(se), vous aimez travailler en √©quipe. Vous poss√©dez de bonnes capacit√©s d'√©coute, d'analyse, de synth√®se et de communication.
Et bien s√ªr, vous √™tes passionn√©(e), enthousiaste et ing√©nieux(se)
Ce que nous vous offrons
De la cr√©ation de valeur pour l‚Äôensemble des m√©tiers d‚ÄôAir France KLM
Des challenges et probl√©matiques complexes √† r√©soudre
L‚Äôopportunit√© de d√©ployer des solutions Data industrielles √† l‚Äô√©chelle !
Une grande part de responsabilit√© dans une structure hi√©rarchique horizontale
Un important degr√© de libert√© pour apprendre et d√©velopper son expertise au sein de l‚Äô√©quipe
On vous attend le plus rapidement possible ! Et pour une dur√©e ind√©termin√©e ;)
Type de contrat
CDI
Temps partiel possible
Non
Type d'horaires
Administratif
Profil candidat
Niveau d'√©tudes min. requis
Bac + 5 et plus
Langue
Anglais (4 - Confirm√© / C1)
Localisation du poste
Localisation du poste
France, Provence-Alpes-C√¥te d'Azur, Alpes Maritimes (06)
Site
Valbonne
Show more
Show less","{'ProgLanguage': ['Java', 'R', 'Go'], 'DataBase': ['SQL', 'NoSQL', 'HBase', 'Elasticsearch'], 'DataAnalytics': ['R'], 'BigData': ['Hadoop', 'Spark'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': ['PowerBI'], 'Statistics': [], 'CloudComputing': ['Azure'], 'DevTools': [], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': ['HBase'], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Big Data', 'Cloud'], 'FrSoftSkills': ['Communication'], 'EnSoftSkils': ['Communication']}","{'JobDetail': ['Hybride', 'Confirm√©'], 'TypeContract': ['CDI'], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's']}"
Data Engineer GCP (F/H),Apside,"Paris, √éle-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-gcp-f-h-at-apside-2859485219?position=6&pageNum=2&refId=rN2g5dxyW%2FccP664CRL%2Fiw%3D%3D&trackingId=WLa6n235FC%2BQ2IcVACWhbQ%3D%3D&trk=public_jobs_jserp-result_search-card,"Envie de rejoindre une entreprise apprenante ? Engag√©e pour t‚Äôaccompagner dans ton √©volution professionnelle et dans tes projets personnels ?
Rejoins Apside Paris pour travailler sur nos projets de demain !
Le poste :
Tu seras amen√© √† participer √† la migration des donn√©es et le traitements Big Data depuis un cluster Hadoop interne vers l'infrastructure Google Cloud Platform.
Dans ce sens, tes missions seront les suivantes :
Participation aux chantiers de cadrage de la migration
Contribution √† la mise en place des environnements et outils de d√©ploiement automatis√©s
Accompagnement et formation des √©quipes √† l‚Äôoutil GCP
...
Environnement technique :
Jira Big data
Cloud GCP
Hadoop
Kubernetes
Spark, Kafka, Python
Toi ?
Tu as d√©j√† particip√© √† un projet de
migration Google Cloud Platform (GCP)
?
Tu es
rigoureux
,
bon communiquant
?
Tu souhaites participer √† un
projet d‚Äôenvergure associant cloud et Big Data
?
Alors ce poste de
Data Engineer GCP
est fait pour toi !
Et la suite ?
Tu rencontres d‚Äôabord l‚Äô√©quipe RH pour parler de tes attentes, ton projet, ton futur !
Puis les managers pour parler concret : missions, projets, parcours de carri√®re, et bien s√ªr salaire et avantages :)
Et tu discutes avec un de nos Tech Leads, pour √©valuer tes comp√©tences et te challenger.
Tu souhaites donner un nouvel √©lan √† ta carri√®re ? Rejoins la vie Apsidienne !
Pour en savoir plus √† www.apside.com
Show more
Show less","{'ProgLanguage': ['Python', 'R', 'Go'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': ['Hadoop', 'Spark'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': ['Google Cloud Platform'], 'DevTools': [], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': ['Kubernetes'], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': ['Kubernetes'], 'Collaboration': ['JIRA'], 'Other': ['Big Data', 'Cloud'], 'FrSoftSkills': [], 'EnSoftSkils': []}","{'JobDetail': [], 'TypeContract': [], 'Salary': ['Salaire'], 'Level': [], 'Experience': ['a', 'n', 's']}"
Data Engineer confirm√© (H/F),BforBank,Greater Paris Metropolitan Region,https://fr.linkedin.com/jobs/view/data-engineer-confirm%C3%A9-h-f-at-bforbank-3918327555?position=7&pageNum=2&refId=rN2g5dxyW%2FccP664CRL%2Fiw%3D%3D&trackingId=LWDcLx1%2FtfN3JByiaP4tqg%3D%3D&trk=public_jobs_jserp-result_search-card,"Sur le mod√®le d'une
""Tech company"",
BforBank place
l'humain et le digital
au c≈ìur de sa transformation. Notre mission,
offrir √† nos clients une exp√©rience bancaire incomparable
pour r√©pondre √† leurs besoins et usages mobile. üåü üì±
Rejoindre BforBank c‚Äôest
rejoindre une √©quipe engag√©e
dans un
grand projet de d√©veloppement strat√©gique en France et en Europe.
Nous sommes aujourd‚Äôhui 350 passionn√©(e)s et
recherchons nos talents pour construire la banque de demain
. üöÄ
Nous croyons en la force du collectif, chaque jour rassembl√©s autour de nos valeurs, de simplicit√©, d'optimisme et d‚Äôengagement, encourageant chacun √† oser, essayer et accepter d‚Äô√©chouer.
üéØ Au sein de la Direction Technologie, la Data Factory a pour objectifs de piloter, d√©finir, d√©ployer et op√©rer les meilleures solutions technologiques r√©pondant aux cas d‚Äôusage data et d‚Äôautomatisations de processus de la banque au travers de plateformes. √âgalement, la Data Factory contribue au d√©veloppement des produits, √† la cristallisation et √† la diffusion des pratiques au sein des Squads BforBank sur les usages data dans la banque.
Tu rejoindras une squad en charge de r√©soudre des probl√©matiques m√©tiers en cr√©ant des solutions applicatives utilisant les donn√©es, des data products, avec pour finalit√©s la prise de d√©cision via des moteurs de calcul ou des dashboards, la cr√©ation de flux r√©glementaires, la cr√©ation de data layer ou de reportings.
üöÄ Tes missions principales sont les suivantes :
¬∑ Participer aux analyses, √©tudes d‚Äôimpacts et cadrage techniques
¬∑ Concevoir des solutions en respectant les bonnes pratiques d‚Äôarchitecture data et d√©veloppement
¬∑ R√©aliser le d√©veloppement de nouveaux data products et assurer la maintenance √©volutive et corrective des data products existants
¬∑ R√©diger la documentation technique des data products
¬∑ Assurer un support aux testeurs
¬∑ Reporter de ton activit√© √† ta Squad et travailler dans une d√©marche d‚Äôefficacit√© collective
Concr√®tement tu seras amen√©(e) √† produire les livrables suivants :
¬∑ R√©aliser du code applicatif √† l‚Äô√©tat de l‚Äôart sur notre nouvelle Data Platform
¬∑ Cr√©er des data layer et des rapports sur notre outil de Data Visualisation
¬∑ R√©diger les documentations techniques li√©es √† ta solution, incluant le mod√®le de donn√©es, les proc√©dures, l‚Äôordonnancement
Ce que tu ma√Ætrises :
¬∑ Maitrise des services manag√©s de GCP (BigQuery, dataproc, dataflow, CloudSQL ‚Ä¶)
¬∑ Maitrise du langage Python, Pandas, Spark
¬∑ Maitrise de la mod√©lisation de base de donn√©es et du langage SQL
¬∑ Maitrise d‚Äôune chaine CI/CD (GitLab‚Ä¶)
¬∑ Bonne connaissance de Kafka
¬∑ Bonne connaissance d‚Äôun outil d‚Äôint√©gration de donn√©es type ETL (Informatica‚Ä¶)
¬∑ Connaissance de l‚Äôinfra as code (Terraform)
¬∑ Connaissance d‚Äôun outil de reporting (Looker, BO‚Ä¶)
ü§ù Ce poste est fait pour toi si :
¬∑ Tu es passionn√©(e) par la Data et leurs usages
¬∑ Tu es orient√© r√©solution de probl√®me, est curieux(se) et force de proposition
¬∑ Tu appr√©cies le travail en √©quipe
¬∑ Tu as un bon relationnel et est rigoureux(se)
¬∑ Tu as une bonne capacit√© d‚Äôanalyse et r√©dactionnelle
¬∑ Tu t‚Äôadaptes rapidement aux changements
üéì
Formation :
Tu es dipl√¥m√©(e) d‚Äôun master en √©cole de commerce, √©cole d‚Äôing√©nieur ou √©quivalent.
Chez BforBank nous recherchons avant tout des comp√©tences. Tu ne disposes pas du dipl√¥me requis mais as des exp√©riences √©quivalentes ? N'h√©site pas √† postuler !
üíº
Exp√©rience :
Exp√©rience confirm√©e de 3 ans en tant que Data Engineer.
En rejoignant BforBank tu trouveras‚Ä¶
¬∑ Un projet ambitieux de transformation digitale et culturelle √† l‚Äô√©chelon europ√©en, terrain d‚Äôinnovation et d‚Äôouverture d‚Äôesprit
¬∑ Une organisation apprenante, proposant un large choix de formations toute l‚Äôann√©e, et qui favorise l‚Äô√©change avec les autres marques du Groupe
¬∑ Une promo RSE multi-m√©tiers qui fait √©voluer en continu les actions de BforBank vers une banque plus responsable
¬∑ Une organisation du travail en mode Agile, impliquant un degr√© √©lev√© de collaboration et d'autonomie tout en travaillant avec un groupe de pairs diversifi√©s.
¬∑ Une Direction Technologie en pleine expansion, porteuse de nombreux d√©fis strat√©giques
Mais aussi‚Ä¶
De 2 jours √† 5 jours de t√©l√©travail modulables par semaine, dans la limite de 84 jours par an (frais de fonctionnement pris en charge)
25 jours de cong√©s + 16 jours de RTT
80% du co√ªt de la mutuelle d‚Äôentreprise pris en charge / couvert
Avantages collaborateurs Cr√©dit Agricole : taux et tarifs pr√©f√©rentiels
Des frais de transports rembours√©s √† 75%
Un restaurant d‚Äôentreprise
Des douches pour les sportifs et un tarif avantageux aupr√®s d‚Äôune salle de sport toute proche
üìç Le poste est bas√© √† La D√©fense, dans des locaux flambant neufs !
BforBank s'engage √† garantir l'√©galit√© des chances aux candidats car nous sommes convaincus de la richesse apport√©e par la diversit√© et l'inclusion dans nos √©quipes.
Rencontrons-nous !
Le processus de recrutement se d√©roule en 4 √©tapes :
üßëüèº‚Äçüíª
Call de 30 minutes avec notre √©quipe Talent Acquisition
Echange avec le Data Factory Manager et notre √©quipe Talent Acquisition (pr√©sentiel)
Echange avec une personne de l‚Äô√©quipe avec qui tu seras amen√© √† travailler (visio)
Echange avec le CTO (visio ou pr√©sentiel)
Notre processus de recrutement dure en moyenne 3 semaines et l‚Äô√©quipe Talent Acquisition se tiendra √† ta disposition pour te donner un maximum de visibilit√© sur l‚Äôavanc√©e du process.
Show more
Show less","{'ProgLanguage': ['Python', 'R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['Pandas', 'R'], 'BigData': ['Spark'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git'], 'Os': [], 'DBMS': ['BigQuery'], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': ['Terraform'], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Cloud', 'CI/CD'], 'FrSoftSkills': ['Collaboration', 'Organisation'], 'EnSoftSkils': ['Collaboration']}","{'JobDetail': ['Confirm√©'], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's', '3', '3', '3']}"
Data Engineer ‚Äì Grenoble,Capgemini,"Grenoble, Auvergne-Rh√¥ne-Alpes, France",https://fr.linkedin.com/jobs/view/data-engineer-%E2%80%93-grenoble-at-capgemini-3905836212?position=8&pageNum=2&refId=rN2g5dxyW%2FccP664CRL%2Fiw%3D%3D&trackingId=XV6%2FMghiV8sO0nVatsxGlg%3D%3D&trk=public_jobs_jserp-result_search-card,"Choisir Capgemini, c'est choisir une entreprise o√π vous serez en mesure de fa√ßonner votre carri√®re selon vos aspirations. Avec le soutien et l'inspiration d'une communaut√© d‚Äôexperts dans le monde entier, vous pourrez r√©√©crire votre futur. Rejoignez-nous pour red√©finir les limites de ce qui est possible, contribuer √† lib√©rer la valeur de la technologie pour les plus grandes organisations et participer √† la construction d‚Äôun monde plus durable et inclusif.
Vos missions :
En tant que Data Engineer au sein d'une √©quipe multidisciplinaire, vos responsabilit√©s principales seront les suivantes :
Intervenir sur les diff√©rentes phases d'un projet dans un environnement Cloud et Agile.
Contribuer √† la gestion de la qualit√© des donn√©es et extraction et analyse de celle-ci, ainsi qu‚Äô√† la pr√©sentation des donn√©es dans leur forme raffin√©e.
Proposer des nouvelles lectures de donn√©es via un travail de fouille sur les gisements d‚Äôinformation, notamment client.
Adopter une posture de consultant : proposer de nouvelles solutions et accompagner le client dans ses choix.
Votre profil :
Titulaire d'un Bac+5 en √©cole d‚Äôing√©nieur ou en universit√©.
Connaissances approfondies des ETL (Talend, Informatica ou SSIS), du traitement de donn√©es (Spark, Python, Scala) ainsi que des bases de donn√©es (Oracle, SQL Server, Postgres).
Facult√© pour se montrer curieux, autonome et proactif dans la r√©alisation de ses t√¢ches.
Capacit√© √† faire preuve de rigueur et √† travailler en √©quipe.
Bon niveau d‚Äôanglais (B2 minimum).
3 raisons de nous rejoindre :
Qualit√© de vie au travail
: accord de t√©l√©travail en France et √† l‚Äôinternational, accord sur l‚Äô√©galit√© professionnelle, la parentalit√©, l‚Äô√©quilibre des temps et la mobilit√© durable.
Apprentissage en continu
: certifications et formations en libre acc√®s, accompagnement sur mesure avec votre career manager, parcours d‚Äôint√©gration sur 9 mois.
Avantages groupe & CSE
: plan actionnariat, tarif pr√©f√©rentiels, remboursement partiel vacances, remboursement de votre abonnement sportif ou culturel.
Nos engagements et priorit√©s
:
Le groupe Capgemini encourage une culture inclusive dans un cadre multiculturel et handi-accueillant. En nous rejoignant, vous int√©grez un collectif qui valorise la diversit√©, d√©veloppe le potentiel de ses talents, s‚Äôengage dans des initiatives solidaires avec ses partenaires, et se mobilise pour r√©duire son impact environnemental sur tous ses sites et aupr√®s de ses clients.
√Ä propos de Capgemini :
Capgemini est un leader mondial, responsable et multiculturel, regroupant pr√®s de 350 000 personnes dans plus de 50 pays. Fort de 55 ans d‚Äôexp√©rience, nous sommes un partenaire strat√©gique des entreprises pour la transformation de leurs activit√©s en tirant profit de toute la puissance de la technologie et des innovations dans les domaines en perp√©tuelle √©volution tels que le cloud, la data, l‚ÄôIntelligence Artificielle, la connectivit√©, les logiciels, l‚Äôing√©nierie digitale ou les plateformes.
Get The Future You Want* | www.capgemini.com/fr-fr
*Capgemini, le futur que vous voulez
Show more
Show less","{'ProgLanguage': ['Python', 'Scala', 'R'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': ['Spark'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git'], 'Os': [], 'DBMS': ['Oracle', 'SQL Server'], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Cloud'], 'FrSoftSkills': ['Organisation'], 'EnSoftSkils': ['Initiative']}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': ['Bac+5'], 'Experience': ['a', 'n', 's', '55', '55', '55']}"
Data engineer H/F,Extia,"Paris, √éle-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-h-f-at-extia-3599188121?position=9&pageNum=2&refId=rN2g5dxyW%2FccP664CRL%2Fiw%3D%3D&trackingId=S4OeddZAb04OhTrU%2B%2B%2FNSw%3D%3D&trk=public_jobs_jserp-result_search-card,"Vous souhaitez rejoindre une entreprise qui place l‚Äôhumain au c≈ìur de ses pr√©occupations ? On vous attend chez
Extia
!
Soci√©t√© de conseil sp√©cialis√©e dans les m√©tiers de l‚ÄôIT, de l‚Äôing√©nierie et du digital, Extia privil√©gie depuis sa cr√©ation en 2007 une approche qui allie performance et bien-√™tre au travail. Une vision de l‚Äôentreprise partag√©e aujourd‚Äôhui par plus de 2 500 Extiens en France et √† l'international et r√©compens√©e par le label Great Place to Work¬Æ depuis 13 ans, notamment en
2024 o√π les Extiens se hissent √† la premi√®re place du palmar√®s Best Workplaces France
!
Chez Extia, c‚Äôest ¬´ D‚Äôabord qui, ensuite quoi ¬ª alors, allons-y !
D'abord qui
Vous √™tes habitu√© √† travailler aussi bien avec des m√©ta-donn√©es qu‚Äôavec des donn√©es non-structur√©es. A cet effet vous maitrisez un ou plusieurs des concepts comme l‚ÄôETL, le Data mining le Machine learning, les Big data ou encore la Th√©orie des graphes par exemple,
Vous maitrisez les bases de l‚Äôanalyse statistique,
Vous √™tes apte √† r√©diger des scripts en Python et/ou R, et une connaissance d'autres langages de programmation comme Java, Scala ou SAS est un plus,
Vous maitrisez Spark et Hadoop
Vous √™tes familiaris√© avec l‚Äôenvironnement Linux,
Une exp√©rience avec les outils de Stockage de fichiers volumineux (HDFS, Data Lake, S3, stockage Blob), la connaissance des infrastructures cloud AWS ou GCP et des bases en streaming temps r√©el seront aussi de r√©els atouts.
Ensuite quoi
Vous aurez le r√¥le de support technique aux √©quipes d‚Äôanalyse : structurer les donn√©es, r√©aliser des analyses ¬´ statistiques ¬ª ou ¬´ techniques ¬ª sur les donn√©es, d√©velopper des outils d‚Äôanalyse‚Ä¶
Vous m√®nerez des √©tudes afin d‚Äô√©valuer les nouvelles technologies dans le domaine du Big Data, Data Mining ou Machine Learning afin d‚Äôidentifier les solutions les plus pertinentes.
Vous serez en charge de :
Participer √† la d√©finition des besoins et √† la r√©daction des User Stories,
Collaborer avec les Data Scientists au d√©veloppement des modules d‚Äôanalyse de donn√©e,
Concevoir et construire des architectures de donn√©es,
Int√©grer des sources de donn√©es,
Vous assurez que les donn√©es sont facilement accessibles et que leur exploitation fonctionne comme demand√©, m√™me dans des circonstances hautement √©volutives,
Ex√©cuter des processus ETL (extraire / transformer / charger) √† partir d'ensembles de donn√©es complexes et / ou volumineux
Show more
Show less","{'ProgLanguage': ['Python', 'Java', 'Scala', 'R'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': ['Hadoop', 'Spark'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': ['Statistiques'], 'CloudComputing': ['AWS'], 'DevTools': ['Git'], 'Os': ['Linux'], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Big Data', 'Machine Learning', 'Statistiques', 'Cloud'], 'FrSoftSkills': [], 'EnSoftSkils': []}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's', '13', '13', '13']}"
Data Engineer,ALFI : Financial Markets Consultancy Services,"Paris, √éle-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-at-alfi-financial-markets-consultancy-services-3916552424?position=10&pageNum=2&refId=rN2g5dxyW%2FccP664CRL%2Fiw%3D%3D&trackingId=Nz0DrVvTlRt%2FD6z0J3NthQ%3D%3D&trk=public_jobs_jserp-result_search-card,"Le Data Engineer intervient au sein de l‚Äô√©quipe Engineering Open Big Data du D√©partement Guilde Data, qui regroupe l‚Äôensemble des expertises technologiques li√©es √† l‚Äôing√©nierie de la donn√©e, de l‚Äôautomatisation et √† l‚Äôexploitation des mod√®les de Machine Learning.
Votre r√¥le et vos missions :
Vous aurez pour missions principales de d√©velopper les projets Big Data demand√©s par le m√©tier, et notamment :
Passer de la donn√©e brute √† de la donn√©e exploitable, expos√©e sous forme de tables requ√™tables dans le Datalake
Consolider ces donn√©es au fur et √† mesure de leur alimentation r√©currente dans le Datalake
Les exploiter pour atteindre la finalit√© business (exposition de Business View, r√©int√©gration des r√©sultats dans le SI, service de scoring, ‚Ä¶)
De mettre en place et de garantir le respect dans la dur√©e d'un processus qualit√© sur l'ensemble du cycle de DEV (documents, tests unitaires / int√©gration / fonctionnels, commentaires, versionning, etc.)
Accompagner les Data Engineers sur son p√©rim√®tre pour garantier la qualit√© des livrables
Expertise souhait√©e
Comp√©tences techniques :
Expertise en SPARK et PySpark
Expertise sur Databricks
Une exp√©rience sur un cloud provider public comme Azure (id√©alement), AWS, ou GCP
Connaissances avanc√©es d'outils de BI comme PowerBI (id√©alement) ou Spotfire
Comp√©tences transverses :
Capacit√© √† interagir avec des parties prenantes diverses : Business analyst, Architectes, M√©tier
Exp√©rience en mode de Delivery Agile (Scrum, Kanban, etc.‚Ä¶)
Etre expert dans les pratiques du Software Craftsmanship (Test Driven Development, Behavior Driven Development, Clean Code, Code Reviews, etc.)
Et :
Des Connaissances sur Azure DevOps, Azure Pipeline, GIT
Maitrise des Traitements Big Data en mode Streaming
Maitrise des Bases de donn√©es relationnelles et NoSQL
Une exp√©rience professionnelle avec des outils comme Azure Databricks, Azure Data Lake Storage ou encore Azure Data Factory
Conform√©ment √† la r√®glementation, et √† notre politique d‚Äô√©galit√© professionnelle, tous nos postes sont ouverts aux personnes en situation de handicap.
Show more
Show less","{'ProgLanguage': ['R'], 'DataBase': ['SQL', 'NoSQL'], 'DataAnalytics': ['R'], 'BigData': ['Spark', 'Databricks'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': ['PowerBI'], 'Statistics': [], 'CloudComputing': ['AWS', 'Azure'], 'DevTools': ['Git'], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['DevOps', 'Big Data', 'Machine Learning', 'Cloud'], 'FrSoftSkills': [], 'EnSoftSkils': []}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's']}"
Data Engineer H/F,ALFI : Financial Markets Consultancy Services,"Paris, √éle-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-h-f-at-alfi-financial-markets-consultancy-services-3916559634?position=1&pageNum=5&refId=m4Ai8FJKy6LOQmm8GTGEuQ%3D%3D&trackingId=1ns3RRJU2%2Ba8wtICRTGTxQ%3D%3D&trk=public_jobs_jserp-result_search-card,"ALFI est une soci√©t√© de conseil et services sp√©cialis√©e en syst√®mes d‚Äôinformation. Depuis plus de 20 ans, ALFI est un acteur unique qui m√™le technologie et humain pour accompagner les transformations num√©riques sur les march√©s de l‚ÄôAsset Management, la banque d‚ÄôInvestissement et les Services aux Investisseurs.
Avec plus de 46 r√©f√©rencements de rang un, ALFI est reconnu comme incontournable sur le secteur BFA. Nous avons plus de 35 clients grands comptes actifs tels que HSBC, Soci√©t√© G√©n√©rale, BNP Paribas, Cr√©dit Agricole, Axa‚Ä¶
Depuis 2015, ALFI a int√©gr√© le groupe
MoOngy
, qui compte plus de 6000 salari√©s dans toute l‚ÄôEurope
Missions :
Pour l'un de nos clients grands comptes, nous vous proposons d'intervenir sur une fonction de Consultant Data engineer.
Les principales missions sont :
Comprendre les besoins des utilisateurs et les traduire de mani√®re analytique
D√©veloppement de solutions permettant de traiter des volumes importants de donn√©es
Conception, collection et fabrication des donn√©es brutes
D√©velopper des algorithmes permettant de r√©pondre aux probl√®mes pos√©s et veiller √† leur industrialisation
S√©curisation des Pipelines donn√©es pour les Data Scientists et les Data Analysts
Construire des bases de donn√©es robustes
Organisation de l‚Äôarchitecture du cloud
Profil recherch√© :
Vous √™tes issu d'une formation Bac +5 Ecole scientifique ou informatique.
Vous disposez d'une premi√®re exp√©rience en d√©veloppement et dans la data.
Vous disposez d'un niveau d'anglais op√©rationnel.
Java, Python, C++
SQL
Devops (Jenkins, Kubernetes, Docker)
Conform√©ment √† la r√®glementation, et √† notre politique d‚Äô√©galit√© professionnelle, tous nos postes sont ouverts aux personnes en situation de handicap;
Show more
Show less","{'ProgLanguage': ['Python', 'Java', 'C++', 'R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Docker', 'Jenkins'], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': ['Kubernetes'], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': ['Docker', 'Kubernetes'], 'Collaboration': [], 'Other': ['DevOps', 'Cloud'], 'FrSoftSkills': ['Organisation'], 'EnSoftSkils': []}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's', '20', '20', '20']}"
Data Engineer  H/F,METEOJOB by CleverConnect,"Lille, Hauts-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-h-f-at-meteojob-by-cleverconnect-3895135654?position=2&pageNum=5&refId=m4Ai8FJKy6LOQmm8GTGEuQ%3D%3D&trackingId=IM8E8CIOGlRydncAk%2B22Mw%3D%3D&trk=public_jobs_jserp-result_search-card,"Entreprise
Qui sommes-nous ?
Nous sommes passionn√©s par les nouvelles technologies, et vous ?
Rejoindre Amiltone, c'est int√©grer des √©quipes dynamiques et soud√©es dans le cadre de projets novateurs et ambitieux. Nous relevons les challenges techniques de nos clients et les accompagnons dans leur transformation digitale.
Pourquoi choisir Amiltone‚ÄØ?
Amiltone, plus qu'une entreprise, un √©tat d'esprit !
Notre objectif ? Votre √©panouissement professionnel !
Nous Avons √† C≈ìur De
Vous accompagner au mieux au travers d'un suivi personnalis√©
Vous faire monter en comp√©tences en vous proposant des formations tout au long de votre carri√®re
Comprendre vos besoins et respecter nos engagements
Vous proposer des missions de qualit√© avec des technologies innovantes
Cultiver votre potentiel gr√¢ce √† notre programme de d√©veloppement personnel Addvise
Votre bien-√™tre passe aussi par des activit√©s extraprofessionnelles, c'est pourquoi nous vous proposons des s√©ances sportives anim√©es par nos coachs, soir√©es pour se retrouver et animations (√† l'agence ou en visio), Gaming nights...
Description Du Poste
Les missions d'un Amiltonien :
En tant que Data Engineer
(H/F)
, vous serez en charge des missions suivantes :
Concevoir et d√©velopper les futures fonctionnalit√©s de la plateforme Big Data sous Google Cloud Platform.
Concevoir les flux d'alimentation et les tables (structure de donn√©e).
Automatiser et industrialiser les flux.
Assurer le run applicatif, le cas √©ch√©ant.
La Stack Technique
Ma√Ætrise des langages suivants : SQL, Talend, BigQuery
Connaissances de Google (GCP)
Notion de programmation fonctionnelle
Description Du Profil
Le profil d'un Amiltonien :
Dipl√¥m√© Bac+4/5 (Ecole d'ing√©nieur/Master), vous disposez de 2 ann√©es d'exp√©rience dans le d√©veloppement de data.
Toujours sur le qui-vive des nouveaut√©s technologiques, vous √™tes force de proposition sur des technos, des outils ou des process qui permettent d'am√©liorer la qualit√© du code et la stabilit√© de nos applications.
Outre vos comp√©tences techniques, nous nous int√©ressons √©galement √† votre potentiel et votre motivation.
Nos postes sont ouverts aux personnes en situation de handicap.
Show more
Show less","{'ProgLanguage': ['R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': ['Google Cloud Platform'], 'DevTools': ['Git'], 'Os': [], 'DBMS': ['BigQuery'], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Big Data', 'Cloud'], 'FrSoftSkills': [], 'EnSoftSkils': []}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's']}"
Data Engineer,Beelix,"Paris, √éle-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-at-beelix-3865239426?position=3&pageNum=5&refId=m4Ai8FJKy6LOQmm8GTGEuQ%3D%3D&trackingId=%2FEOf9kncJKAyfBSeEKhstw%3D%3D&trk=public_jobs_jserp-result_search-card,"Qui sommes-nous ?
Depuis 2016, nous accompagnons nos clients sur des probl√©matiques de Product Management, Data et Design Thinking. Beelix contribue √† fa√ßonner le monde de demain en participant aux grandes avanc√©es des secteurs suivants:
üöóAutomobile
‚ö°Energie
üì°M√©dias & T√©l√©coms
üëóLuxe & Retail
üí∂ Banque, Finance & Assurance
‚úàÔ∏èD√©fense
Aujourd‚Äôhui, Beelix compte plus de 200 collaborateurs motiv√©s et dynamiques. Lab√©lis√©e Great Place To work en 2023, Beelix est aussi une entreprise engag√©e o√π il fait bon vivre.
Dans le cadre de notre d√©veloppement, nous recherchons un Data Engineer en √éle-de-France.
Quelles missions au quotidien ?
Vous aurez pour missions principales de d√©velopper les projets Big Data demand√©s par le m√©tier, et notamment :
Passer de la donn√©e brute √† de la donn√©e exploitable, expos√©e sous forme de tables requ√™tables dans le Datalake
Consolider ces donn√©es au fur et √† mesure de leur alimentation r√©currente dans le Datalake
Les exploiter pour atteindre la finalit√© business (exposition de Business View, r√©int√©gration des r√©sultats dans le SI, service de scoring, ‚Ä¶)
De mettre en place et de garantir le respect dans la dur√©e d'un processus qualit√© sur l'ensemble du cycle de DEV (documents, tests unitaires / int√©gration / fonctionnels, commentaires, versionning, etc.)
Accompagner les Data Engineers sur son p√©rim√®tre pour garantir la qualit√© des livrables
Expertise souhait√©e
Expertise en SPARK et PySpark
Expertise sur Databricks
Une exp√©rience sur un cloud provider public comme Azure (id√©alement), AWS, ou GCP
Connaissances avanc√©es d'outils de BI comme PowerBI (id√©alement) ou Spotfire
Capacit√© √† interagir avec des parties prenantes diverses : Business analyst, Architectes, M√©tier
Etre expert dans les pratiques du Software Craftsmanship (Test Driven Development, Behavior Driven Development, Clean Code, Code Reviews, etc.)
Des Connaissances sur Azure DevOps, Azure Pipeline, GIT
Maitrise des Traitements Big Data en mode Streaming
Maitrise des Bases de donn√©es relationnelles et NoSQL
Une exp√©rience professionnelle avec des outils comme Azure Databricks, Azure Data Lake Storage ou encore Azure Data Factory
A propos de vous ?
Dipl√¥m√© d'une √©cole d'ing√©nieurs ou √©quivalent
Au moins 3 ans d'exp√©rience en tant que Data Engineer
Exp√©rience en mode de Delivery Agile (Scrum, Kanban, etc.‚Ä¶)
Vous avez un bon niveau d‚Äôanglais tant √† l‚Äô√©crit qu‚Äô√† l‚Äôoral
Pourquoi nous rejoindre ?
Un suivi et un accompagnement au quotidien
Un organisme de formation certifi√© Qualiopi, un abonnement linkedin learning pour chaque salari√© et des partenariats avec des sp√©cialistes pour d‚Äôautres expertises
De nombreux √©v√©nements : Afterworks, Communaut√©s m√©tiers, Happy talks‚Ä¶
une Exp√©rience personnalis√©e bas√©e sur vos besoins gr√¢ce au Pr√©dictive Index
Notre package ¬´ unBeelievable ¬ª : 100% du titre de transport, Tickets restaurants, CSE, Prime de participation ...
Nombreux √©v√®nements (afterworks, sport, etc) et des communaut√©s m√©tiers dynamiques
Le processus de recrutement ?
√âchange t√©l√©phonique (15 min)
Entretien 1 RH pour apprendre √† vous conna√Ætre
Entretien 2 avec votre futur N+1 pour appr√©hender la relation manag√©riale
Entretien 3 avec un Responsable commercial pour avoir la vision strat√©gique
Show more
Show less","{'ProgLanguage': ['R'], 'DataBase': ['SQL', 'NoSQL'], 'DataAnalytics': ['R'], 'BigData': ['Spark', 'Databricks'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': ['PowerBI'], 'Statistics': [], 'CloudComputing': ['AWS', 'Azure'], 'DevTools': ['Git'], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['DevOps', 'Big Data', 'Cloud'], 'FrSoftSkills': [], 'EnSoftSkils': []}","{'JobDetail': [], 'TypeContract': [], 'Salary': ['100'], 'Level': [], 'Experience': ['a', 'n', 's', '3', '3', '3']}"
Data Engineer BI - Nantes,Capgemini,"Nantes, Pays de la Loire, France",https://fr.linkedin.com/jobs/view/data-engineer-bi-nantes-at-capgemini-3803963477?position=4&pageNum=5&refId=m4Ai8FJKy6LOQmm8GTGEuQ%3D%3D&trackingId=mKFfyoLETp5rq4RcnqRS7A%3D%3D&trk=public_jobs_jserp-result_search-card,"Capgemini
Choisir Capgemini, c'est choisir une entreprise o√π vous serez en mesure de fa√ßonner votre carri√®re selon vos aspirations, o√π vous serez soutenu et inspir√© par une communaut√© d‚Äôexperts dans le monde entier, o√π vous pourrez r√©√©crire votre futur. Rejoignez-nous pour red√©finir les limites de ce qui est possible, contribuer √† lib√©rer la valeur de la technologie pour les plus grandes organisations et participez √† la construction d‚Äôun monde plus durable et inclusif.
Vos missions :
Int√©gr√©(e) au sein d‚Äôune √©quipe projet BI, Big Data ou Data Gouvernance pour des clients intervenant dans des secteurs d'activit√©s divers, vous serez notamment en charge des missions suivantes :
Mener les analyses fonctionnelles destin√©es √† traduire les besoins du client,
Mener les travaux de conception et de mod√©lisation,
Diriger le d√©veloppement de la solution / des traitements d'alimentation du DataWareHouse,
Organiser et pr√©parer les travaux de recette utilisateurs,
Mettre en place les processus d'industrialisation et mener cette derni√®re.
Votre profil :
Dipl√¥me d‚Äôing√©nieur ou √©quivalent universitaire
Minimum 3 ans d'exp√©rience
Anglais courant
Comp√©tences en BI sur SAP BI (Hana, BW, BODS, BI 4), Microsoft BI (SQL Server, SSIS, SSAS, SSRS), Oracle (ODI, OBIEE), Teradata, Informatica (Powercenter), IBM (Datastage, Cognos, TM1), Talend, AB Initio
Ma√Ætrise d'un ou de plusieurs outils de Dataviz : Microsoft Power BI, Tableau, Qlikview
Connaissances en Big Data (Ecosyst√®me Hadoop (HIVE, PIG, Mahout‚Ä¶), Cloudera, Pivotal, Spark, HNX) ou en analytics (R, SAS, IBM SPSS)
3 raisons de nous rejoindre :
Qualit√© de vie au travail : accord de t√©l√©travail en France et √† l‚Äôinternational, accord sur l‚Äô√©galit√©
professionnelle, la parentalit√©, l‚Äô√©quilibre des temps et la mobilit√© durable.
Apprentissage en continu : certifications et formations en libre acc√®s, accompagnement sur mesure avec votre carreer manager, parcours d‚Äôint√©gration sur 9 mois.
Avantages groupe & CSE : plan actionnariat, activit√©s √† tarifs pr√©f√©rentiels, remboursement partiel
vacances, remboursement de votre abonnement sportif ou culturel.
Nos engagements et priorit√©s :
Le groupe Capgemini encourage une culture inclusive dans un cadre multiculturel et handi-accueillant. En nous rejoignant, vous int√©grez un collectif qui valorise la diversit√©, d√©veloppe le potentiel de ses talents, s‚Äôengage dans des initiatives solidaires avec ses partenaires, et se mobilise pour r√©duire son impact environnemental sur tous ses sites et aupr√®s de ses clients.
Capgemini
Capgemini est un leader mondial, responsable et multiculturel, regroupant pr√®s de 350 000 personnes dans plus de 50 pays. Fort de 55 ans d‚Äôexp√©rience, nous sommes un partenaire strat√©gique des entreprises pour la transformation de leurs activit√©s en tirant profit de toute la puissance de la technologie et des innovations dans les domaines en perp√©tuelle √©volution tels que le cloud, la data, l‚ÄôIntelligence Artificielle, la connectivit√©, les logiciels, l‚Äôing√©nierie digitale ou les
plateformes.
Get The Future You Want* | www.capgemini.com/fr-fr
*Capgemini, le futur que vous voulez
Show more
Show less","{'ProgLanguage': ['R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': ['Hadoop', 'Spark'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': ['Tableau', 'Power BI'], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git'], 'Os': [], 'DBMS': ['Oracle', 'SQL Server'], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Big Data', 'Cloud'], 'FrSoftSkills': ['Organisation'], 'EnSoftSkils': ['Initiative']}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's', '3', '3', '3']}"
Data Engineer - Bordeaux,Capgemini,"Bordeaux, Nouvelle-Aquitaine, France",https://fr.linkedin.com/jobs/view/data-engineer-bordeaux-at-capgemini-3889788624?position=5&pageNum=5&refId=m4Ai8FJKy6LOQmm8GTGEuQ%3D%3D&trackingId=8tXhqbm2CfcLLAa7lwkaSg%3D%3D&trk=public_jobs_jserp-result_search-card,"Choisir Capgemini, c'est choisir une entreprise o√π vous serez en mesure de fa√ßonner votre carri√®re selon vos aspirations. Avec le soutien et l'inspiration d'une
communaut√© d‚Äôexperts dans le monde entier, vous pourrez r√©√©crire votre futur. Rejoignez-nous pour red√©finir les limites de ce qui est possible, contribuer √† lib√©rer la
valeur de la technologie pour les plus grandes organisations et participer √† la construction d‚Äôun monde plus durable et inclusif.
Vos missions :
Vous √™tes passionn√© par le domaine de la Data, vous souhaitez prendre part √† des projets d'envergure, concevoir des solutions, les impl√©menter et les faire √©voluer?
Alors rejoignez notre √©quipe Data Engineering Services au sein de Capgemini Cloud Infrastructure Services en tant que Data Engineer.
Vous avez acquis une exp√©rience solide dans le d√©veloppement, la mise en ≈ìuvre et l‚Äôoptimisation de solutions pour le traitement d'un grand volume de donn√©es, vous √™tes capable de cr√©er des solutions qui r√©pondent aux besoins m√©tiers et IT, alors rejoignez notre √©quipe d‚Äôexperts.
En qualit√© de Data engineer, vos missions sont les suivantes :
‚ñ™ Concevoir et d√©velopper des solutions Data/IA.
‚ñ™ Accompagner les M√©tier dans la compr√©hension et la mise en ≈ìuvre de solution orient√©es donn√©es.
‚ñ™ Collaborer avec les Dev, les Ops, les experts infrastructures dans la construction de solutions et d‚Äôinfrastructures ax√©es sur les donn√©es.
‚ñ™ G√©rer un √©cosyst√®me de partenaires data et assurer un haut niveau d'expertise
‚ñ™ Assurer un r√¥le de veille technologique sur tous les outils autours de la data, de l‚ÄôIA et de la BI.
Votre profil :
Vous √™tes issu d‚Äôune formation ing√©nieur ou √©quivalent bac+5 informatique sp√©cialis√©e en DATA et vous justifiez d‚Äôune exp√©rience de 3 √† 5 ans dans un r√¥le similaire. Expert dans une technologie de base de donn√©es relationnelle (PostgreSQL, Oracle...)
Expert dans une technologie de base NoSQL (MongoDB, Cassandra...)
Vous maitrisez un framework de manipulation de donn√©es (Hadoop, Spark, Kafka...)
Vous maitrisez les concepts DevOps et avez de bonnes notions en scripting et d√©veloppement
Vous avez une exp√©rience des outils BI et de data visualisation (Kibana, PowerBI...)
La maitrise de l'anglais est n√©cessaire.
3 raisons de nous rejoindre :
Qualit√© de vie au travail :
accord de t√©l√©travail en France et √† l‚Äôinternational, accord sur l‚Äô√©galit√© professionnelle, la parentalit√©, l‚Äô√©quilibre des temps et la mobilit√© durable.
Apprentissage en continu :
certifications et formations en libre acc√®s, accompagnement sur mesure avec votre career manager, parcours d‚Äôint√©gration sur 9 mois.
Avantages groupe & CSE :
plan actionnariat, tarif pr√©f√©rentiels, remboursement partiel vacances, remboursement de votre abonnement sportif ou culture
Nos engagements et priorit√©s :
Le groupe Capgemini encourage une culture inclusive dans un cadre multiculturel et handi-accueillant. En nous rejoignant, vous int√©grez un collectif qui valorise la diversit√©, d√©veloppe le potentiel de ses talents, s‚Äôengage dans des initiatives solidaires avec ses partenaires, et se mobilise pour r√©duire son impact environnemental sur tous ses sites et aupr√®s de ses clients.
√Ä propos de Capgemini :
Capgemini est un leader mondial, responsable et multiculturel, regroupant pr√®s de 350 000 personnes dans plus de 50 pays. Fort de 55 ans d‚Äôexp√©rience, nous sommes un partenaire strat√©gique des entreprises pour la transformation de leurs activit√©s en tirant profit de toute la puissance de la technologie et des innovations dans les domaines en perp√©tuelle √©volution tels que le cloud, la data, l‚ÄôIntelligence Artificielle, la connectivit√©, les logiciels, l‚Äôing√©nierie digitale ou les plateformes.
Get The Future You Want* | www.capgemini.com/fr-fr
*Capgemini, le futur que vous voulez
Show more
Show less","{'ProgLanguage': ['R', 'Go'], 'DataBase': ['SQL', 'NoSQL', 'Cassandra'], 'DataAnalytics': ['R'], 'BigData': ['Hadoop', 'Spark'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': ['PowerBI'], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git'], 'Os': [], 'DBMS': ['PostgreSQL', 'Oracle'], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['DevOps', 'Cloud'], 'FrSoftSkills': ['Organisation'], 'EnSoftSkils': ['Initiative']}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': ['Bac+5'], 'Experience': ['a', 'n', 's', '5', '5', '5']}"
Data Engineer - Lille,Capgemini,Greater Lille Metropolitan Area,https://fr.linkedin.com/jobs/view/data-engineer-lille-at-capgemini-3914228495?position=6&pageNum=5&refId=m4Ai8FJKy6LOQmm8GTGEuQ%3D%3D&trackingId=SSitAc328PqPE9lzCafd9g%3D%3D&trk=public_jobs_jserp-result_search-card,"Capgemini en quelques mots
Choisir Capgemini, c'est choisir une entreprise o√π vous serez en mesure de fa√ßonner votre carri√®re selon vos aspirations, o√π vous serez soutenu et inspir√© par une communaut√© d‚Äôexperts dans le monde entier, o√π vous pourrez r√©√©crire votre futur. Rejoignez-nous pour red√©finir les limites de ce qui est possible, contribuer √† lib√©rer la valeur de la technologie pour les plus grandes organisations et participez √† la construction d‚Äôun monde plus durable et inclusif.
Vos missions
Vous maitrisez au minimum un langage de programmation appliqu√© √† l‚Äôanalyse de donn√©es
(Java, Python, Scala et les environnements Spark et / ou Hadoop).
Vous √™tes passionn√© par le Big Data et le Machine Learning et l‚Äôanalyse de donn√©es
Vous concevez et mettez en ≈ìuvre des strat√©gies s√©curis√©es d'acquisition et d'int√©gration de donn√©es
Vous configurez des r√©f√©rentiels de donn√©es √† la pointe de la technologie dans des environnements distribu√©s
Vous construisez des pipelines de donn√©es pour collecter, transformer et traiter des donn√©es en collaboration avec des scientifiques de donn√©es afin de r√©pondre aux exigences de la mod√©lisation de donn√©es d'analyse avanc√©e
Votre profil
Dipl√¥m√©(e) de Bac+5 en informatique
4 ans d‚Äôexp√©rience
(au sein d‚Äôune ESN ou chez un int√©grateur) en conseil client√®le
Une solide culture technologique
Un bon niveau d‚Äôanglais
3 raisons de nous rejoindre
Qualit√© de vie au travail :
accord de t√©l√©travail en France et √† l‚Äôinternational, accord sur l‚Äô√©galit√©
professionnelle, la parentalit√©, l‚Äô√©quilibre des temps et la mobilit√© durable.
Apprentissage en continu :
certifications et formations en libre acc√®s, accompagnement sur mesure avec
votre carreer manager, parcours d‚Äôint√©gration sur 9 mois.
Avantages groupe & CSE :
plan actionnariat, activit√©s √† tarifs pr√©f√©rentiels, remboursement partiel
vacances, remboursement de votre abonnement sportif ou culturel
Nos engagements et priorit√©s
Le groupe Capgemini encourage une
culture inclusive dans un cadre multiculturel et handi-accueillant.
En nous rejoignant, vous int√©grez un collectif qui valorise la diversit√©, d√©veloppe le potentiel de ses talents, s‚Äôengage dans des
initiatives solidaires avec ses partenaires, et se mobilise pour r√©duire son impact environnemental sur tous ses sites et aupr√®s de ses clients.
Capgemini
est un
leader mondial
, responsable et multiculturel, regroupant pr√®s de 350 000 personnes dans plus de 50 pays. Fort de
55 ans d‚Äôexp√©rience,
nous sommes un partenaire strat√©gique des entreprises pour la transformation de leurs activit√©s en tirant profit de toute la puissance de la technologie et des innovations dans les domaines en perp√©tuelle √©volution tels que le
cloud, la data, l‚ÄôIntelligence Artificielle, la connectivit√©, les logiciels, l‚Äôing√©nierie digitale ou les plateformes.
Get The Future You Want* | www.capgemini.com/fr-fr
*Capgemini, le futur que vous voulez
Show more
Show less","{'ProgLanguage': ['Python', 'Java', 'Scala', 'R'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': ['Hadoop', 'Spark'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git'], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Big Data', 'Machine Learning', 'Cloud'], 'FrSoftSkills': ['Collaboration', 'Organisation'], 'EnSoftSkils': ['Collaboration', 'Initiative']}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': ['Bac+5'], 'Experience': ['a', 'n', 's', '4', '4', '4']}"
Data Engineer,Shippeo,Greater Paris Metropolitan Region,https://fr.linkedin.com/jobs/view/data-engineer-at-shippeo-3908268236?position=7&pageNum=5&refId=m4Ai8FJKy6LOQmm8GTGEuQ%3D%3D&trackingId=FSU6%2BUHrVpCQZ4cxHZWiaQ%3D%3D&trk=public_jobs_jserp-result_search-card,"Founded in 2014, Shippeo is a French based SaaS company providing supply chain visibility. Shippeo has grown from 70 to 220 employees during the last two years and is continuing to rapidly scale after an additional $40M fundraising round in October 2022.
Shippeo is an exceptionally diverse company with colleagues from 27 different nationalities and speaking 29 languages. With offices throughout Europe, North America and recently Asia, Shippeo provides global coverage to all of our clients.
Our product is composed of a mission critical SaaS web platform (API everywhere), with high traffic inbound/outbound integrations.
Our mission is to anticipate problems and proactively alert end-customers so they can efficiently manage exceptions. We achieve this by collecting and matching millions of theoretical and real data from different stakeholders.
The Data Intelligence Tribe is responsible for leveraging Shippeo‚Äôs data from our large shipper and carrier base, to build data products that help our users (shippers and carriers alike) and ML models to provide predictive insights. This tribe‚Äôs typical responsibilities are to:
get accurately alerted in advance of any potential delays on their multimodal flows or anomalies so that they can proactively anticipate any resulting disruptions
extract the data they need, get direct access to it or analyze it directly on the platform to gain actionable insights that can help them increase their operational performance and the quality and compliance of their tracking
provide best-in-class data quality by implementing advanced cleansing & enhancement rules
As a Data Engineer at Shippeo, your objective is to ensure that data is available and exploitable by our Data Scientists and Analysts on our different data platforms. You will contribute to the construction and maintenance of Shippeo‚Äôs modern data stack that‚Äôs composed of different technology blocks:
Data Acquisition (Kafka, KafkaConnect, RabbitMQ),
Batch data transformation (Airflow, DBT),
Cloud Data Warehousing (Snowflake, BigQuery),
Stream/event data processing (Python, docker, Kubernetes) and all the underlying infrastructure that support these use cases.
Qualifications
Required:
You have a degree (MSc or equivalent) in Computer Science.
3+ years of experience as a Data Engineer.
Experience building, maintaining, testing and optimizing data pipelines and architectures
Programming skills in Python and experience with asynchronous event processing (asyncio).
Advanced working knowledge of SQL, experience working with relational databases and familiarity with a variety of databases.
Working knowledge of message queuing and stream processing.
Knowledge of Docker and Kubernetes.
Knowledge of a cloud platform (preferably GCP).
Experience working with workflow management systems such as Airflow.
Desired:
Experience with cloud based data warehouse solutions (BigQuery, Snowflake).
Experience with Kafka and KafkaConnect (Debezium).
Experience with Infrastructure as code (Terraform/Terragrunt).
Experience building and evolving CI/CD pipelines with Github Actions.
Monitoring and alerting on Grafana / Prometheus.
Experience working on Apache Nifi.
Informations suppl√©mentaires
We are looking for talents who share our values:
üöÄ Ambition
üíô Care
üéØ Deliver
ü§ù Collaboration
Find out more about our values in
Our Culture Book
If you identify with our values and enjoy working in a fast-paced and international environment, Shippeo is just the place for you!
We are committed to fostering diversity and inclusion within our workplace as we value the unique perspectives and experiences that individuals from all backgrounds bring to our team. We are dedicated to providing equal employment opportunities to all candidates, regardless of their background or abilities, and our commitment to inclusion is reflected in our policies, practices, and workplace culture.
We understand that candidates may have unique needs or questions related to disability inclusion. To facilitate this, you can reach our dedicated Disability Advisor at
inclusion@shippeo.com
with any inquiries or requests for accommodations during the application process.
Show more
Show less","{'ProgLanguage': ['Python', 'R'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git', 'Docker'], 'Os': [], 'DBMS': ['Snowflake', 'Snowflake', 'BigQuery'], 'SoftBigDataProcessing': [], 'Automation': ['Kubernetes', 'Airflow'], 'InfrastructureAsCode': ['Terraform'], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': ['Docker', 'Kubernetes'], 'Collaboration': [], 'Other': ['ML', 'Cloud', 'CI/CD'], 'FrSoftSkills': ['Collaboration'], 'EnSoftSkils': ['Collaboration']}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's']}"
Data Analyst H/F,Inetum,"Lille, Hauts-de-France, France",https://fr.linkedin.com/jobs/view/data-analyst-h-f-at-inetum-3843955768?position=8&pageNum=5&refId=m4Ai8FJKy6LOQmm8GTGEuQ%3D%3D&trackingId=qaegU2jW5lw0T0CnHeeFJQ%3D%3D&trk=public_jobs_jserp-result_search-card,"D√©tail de l'offre
Informations g√©n√©rales
Entit√© de rattachement
Inetum est un leader europ√©en des services num√©riques. Pour les entreprises, les acteurs publics et la soci√©t√© dans son ensemble, les 28 000 consultants et sp√©cialistes du groupe visent chaque jour l'impact digital des solutions qui contribuent √† la performance, √† l'innovation et au bien commun.
Pr√©sent dans 19 pays au plus pr√®s des territoires, et avec ses grands partenaires √©diteurs de logiciels, Inetum r√©pond aux enjeux de la transformation digitale avec proximit√© et flexibilit√©.
Port√© par son ambition de croissance et d'industrialisation, Inetum a g√©n√©r√© en 2023 un chiffre d'affaires de 2,5 milliards d'‚Ç¨.
Pour r√©pondre √† un march√© en croissance continue depuis plus de 30ans, Inetum a fait le choix d√©lib√©r√© de se recentrer sur 4 m√©tiers afin de gagner en puissance et proposer des solutions sur mesure, adapt√©es aux besoins sp√©cifiques de ses clients le conseil (Inetum Consulting), la gestion des infrastructures et applications √† fa√ßon (Inetum Technologies), l'impl√©mentation de progiciels (Inetum Solutions) et sa propre activit√© d'√©diteur de logiciels (Inetum Software). Inetum a conclu des partenariats strat√©giques avec 4 grands √©diteurs mondiaux - Salesforce, ServiceNow, Microsoft et SAP et poursuit une strat√©gie d'acquisitions d√©di√©e afin d'entrer dans le top 5 europ√©en sur ces technologies et proposer la meilleure expertise √† ses clients.
Tous nos postes sont ouverts aux personnes en situation de handicap.
Description du poste
M√©tier
Applications Delivery - Software Development
Intitul√© du poste
Data Analyst H/F
Contrat
CDI
Description De La Mission
Dans le cadre de la croissance de notre agence lilloise, nous d√©veloppons notre Practice Data et recrutons des profils Data de divers horizons Data Analyst, Data Engineer, Data Scientist et Data Gouv. Les besoins m√©tiers de nos clients et la multitude des technologies font qu'il nous faut nous appuyer sur une diversit√© de comp√©tences. Vous pourriez √™tre l‚Äôun d‚Äôeux et rejoindre Inetum.
En tant que Data Analyst, vos principales missions consistent √†
Analyser et retranscrire le besoin client
Identifier, extraire et exploiter les sources d'acquisition de donn√©es les plus pertinentes
Valoriser de la donn√©e
D√©velopper l'outil de data visualisation pour accompagner les √©quipes m√©tiers dans leurs aides √† la d√©cision
√ätre le lien entre les √©quipes m√©tier pour les accompagner dans la mise en ≈ìuvre des nouveaux outils
Profil
Pour mener √† bien votre r√¥le, il vous faut
parler SQL couramment
un niveau avanc√© sur Excel et/ou Google Spreadsheet
une ma√Ætrise d'un outil d√©cisionnel comme PowerBI, Qlik, Tableau ou encore Google Data Studio
Vous vous reconnaissez dans ces quelques lignes, alors rencontrons-nous !
Notre plus
Rejoindre la r√©gion Nord-Est, c‚Äôest b√©n√©ficier des avantages d‚Äôun Grand Groupe tout en gardant la proximit√© r√©gionale.
Nous mettrons tout en ≈ìuvre pour vous apporter un √©quilibre vie perso / vie pro. C‚Äôest pourquoi nous vous proposons un rythme hybride (selon les contraintes clients)
Une trajectoire de carri√®re personnalis√©e et adapt√©e √† vos souhaits d'√©volution gr√¢ce √† une implantation √† l‚Äôinternational (26 pays, 7 Fablab), des formations cibl√©es et des projets couvrant l‚Äôensemble de la cha√Æne de valeur IT (+25 fili√®res m√©tiers)
Int√©grer un collectif d‚Äôexperts partageant des valeurs de solidarit√© et d‚Äôexcellence
Int√©grer une entreprise ayant une strat√©gie affirm√©e de certifications de ses collaborateurs
Localisation du poste
Localisation du poste
France, Nord, 59 Nord
Ville
Lille
Crit√®res candidat
Niveau d'√©tudes min. requis
Bac+5
Niveau d'exp√©rience min. requis
Plus de 2 ans
Show more
Show less","{'ProgLanguage': ['R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': ['Tableau', 'PowerBI'], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git'], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': [], 'FrSoftSkills': ['Flexibilit√©'], 'EnSoftSkils': []}","{'JobDetail': ['Hybride'], 'TypeContract': ['CDI'], 'Salary': [], 'Level': ['Bac+5'], 'Experience': ['a', 'n', 's', '30', '30', '30']}"
Data Engineer - Nantes,Capgemini,"Nantes, Pays de la Loire, France",https://fr.linkedin.com/jobs/view/data-engineer-nantes-at-capgemini-3803998213?position=9&pageNum=5&refId=m4Ai8FJKy6LOQmm8GTGEuQ%3D%3D&trackingId=aFHy9u7Ci9LKSOU1BEcR5w%3D%3D&trk=public_jobs_jserp-result_search-card,"Capgemini
Choisir Capgemini, c'est choisir une entreprise o√π vous serez en mesure de fa√ßonner votre carri√®re selon vos aspirations, o√π vous serez soutenu et inspir√© par une communaut√© d‚Äôexperts dans le monde entier, o√π vous pourrez r√©√©crire votre futur. Rejoignez-nous pour red√©finir les limites de ce qui est possible, contribuer √† lib√©rer la valeur de la technologie pour les plus grandes organisations et participez √† la construction d‚Äôun monde plus durable et inclusif.
Vos missions :
Int√©gr√©(e) au sein d'une √©quipe projets intervenant pour des clients dans des secteurs d'activit√©s vari√©es, vous serez notamment en charge des missions suivantes :
Concevoir et mettre en oeuvre des strat√©gies s√©curis√©es d'acquisition et d'int√©gration de donn√©es,
Configurer des r√©f√©rentiels de donn√©es √† la pointe de la technologie dans des environnements distribu√©s, majoritairement dans le cloud (Google Cloud Platform, Azure Databricks, AWS) et/ou en environnement Hadoop (distribution MapR, Cloudera, Hortonworks),
Construire des pipelines de donn√©es pour collecter, transformer et traiter des donn√©es en collaboration avec des scientifiques de donn√©es afin de r√©pondre aux exigences de la mod√©lisation de donn√©es d'analyse avanc√©e.
Votre profil :
Dipl√¥me d‚Äôing√©nieur ou √©quivalent universitaire
Minimum 3 ans d'exp√©rience
Anglais courant
Ma√Ætrise des langages Java, Scala ou Python et expertise sur les framework Spark et/ou Hadoop.
Expertise sur les services Cloud Data Platform suivants : Azure Data Lake, Azure synapse, Azure Data Factory, Azure Data Explorer, GCP, AWS, Snowflake, Databricks‚Ä¶
3 raisons de nous rejoindre :
Qualit√© de vie au travail : accord de t√©l√©travail en France et √† l‚Äôinternational, accord sur l‚Äô√©galit√©
professionnelle, la parentalit√©, l‚Äô√©quilibre des temps et la mobilit√© durable.
Apprentissage en continu : certifications et formations en libre acc√®s, accompagnement sur mesure avec votre carreer manager, parcours d‚Äôint√©gration sur 9 mois.
Avantages groupe & CSE : plan actionnariat, activit√©s √† tarifs pr√©f√©rentiels, remboursement partiel
vacances, remboursement de votre abonnement sportif ou culturel.
Nos engagements et priorit√©s :
Le groupe Capgemini encourage une culture inclusive dans un cadre multiculturel et handi-accueillant. En nous rejoignant, vous int√©grez un collectif qui valorise la diversit√©, d√©veloppe le potentiel de ses talents, s‚Äôengage dans des initiatives solidaires avec ses partenaires, et se mobilise pour r√©duire son impact environnemental sur tous ses sites et aupr√®s de ses clients.
Capgemini
Capgemini est un leader mondial, responsable et multiculturel, regroupant pr√®s de 350 000 personnes dans plus de 50 pays. Fort de 55 ans d‚Äôexp√©rience, nous sommes un partenaire strat√©gique des entreprises pour la transformation de leurs activit√©s en tirant profit de toute la puissance de la technologie et des innovations dans les domaines en perp√©tuelle √©volution tels que le cloud, la data, l‚ÄôIntelligence Artificielle, la connectivit√©, les logiciels, l‚Äôing√©nierie digitale ou les plateformes.
Get The Future You Want* | www.capgemini.com/fr-fr
*Capgemini, le futur que vous voulez
Show more
Show less","{'ProgLanguage': ['Python', 'Java', 'Scala', 'R', 'Go'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': ['Hadoop', 'Spark', 'Databricks'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': ['AWS', 'Azure', 'Google Cloud Platform'], 'DevTools': ['Git'], 'Os': [], 'DBMS': ['Snowflake', 'Snowflake'], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Cloud'], 'FrSoftSkills': ['Collaboration', 'Organisation'], 'EnSoftSkils': ['Collaboration', 'Initiative']}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's', '3', '3', '3']}"
Data engineer,SEVETYS,"Paris, √éle-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-at-sevetys-3905649273?position=10&pageNum=5&refId=m4Ai8FJKy6LOQmm8GTGEuQ%3D%3D&trackingId=%2F5qWWISTNEVUYtyP4DjxMw%3D%3D&trk=public_jobs_jserp-result_search-card,"Sevetys, premier groupe fran√ßais de cliniques v√©t√©rinaires, est pr√©sent dans toute la France avec plus de 150 √©tablissements. Cr√©√© en 2016, le groupe souhaite moderniser le m√©tier et mettre la qualit√© des soins et la satisfaction client au c≈ìur de son projet.
Le projet d‚Äôentreprise se caract√©rise par son hyper croissance et une culture de type start-up ax√©e sur le collectif, la coh√©sion, et l‚Äôengagement.
Fort de son succ√®s, Sevetys poursuit sa structuration et recrute un / une :
Data Engineer
‚ÄãLe
Data Engineer
travaille en √©troite collaboration avec une √©quipe Agile pluridisciplinaire pour construire des pipelines de donn√©es de haute qualit√© permettant de mettre en ≈ìuvre des solutions analytiques. Ces solutions g√©n√®reront des informations √† partir de nos donn√©es collect√©es, permettant de faire progresser les capacit√©s de prise de d√©cision du management de l‚Äôentreprise. Ce r√¥le n√©cessite une compr√©hension approfondie de l'architecture des donn√©es, de l'ing√©nierie des donn√©es, de l'analyse des donn√©es, du reporting. Le candidat id√©al est un ing√©nieur en donn√©es/logiciel ayant au moins une premi√®re exp√©rience dans la cr√©ation de produits de donn√©es soutenant des solutions analytiques.
Missions :
Con√ßoit, d√©veloppe, optimise et maintient une architecture de donn√©es et des pipelines qui respectent les objectifs de l'entreprise ;
R√©sout des probl√®mes de donn√©es afin de fournir des informations qui aident notre entreprise √† atteindre ses objectifs ;
Cr√©e des jeux de donn√©es pour les membres de l'√©quipe d'analyse afin d'am√©liorer leur productivit√© ;
Favorise une culture du partage, de la r√©utilisation, de la stabilit√© de la conception √† l'√©chelle et de l'efficacit√© op√©rationnelle des donn√©es et des solutions analytiques ;
Contribue √† l'√©valuation, la mise en ≈ìuvre et le d√©ploiement d'outils et de processus √©mergents pour l'ing√©nierie des donn√©es analytiques afin d'am√©liorer notre productivit√© en tant qu'√©quipe ;
√âlabore et met en ≈ìuvre des plans de communication/√©ducation sur les capacit√©s, les normes et les processus d'ing√©nierie des donn√©es analytiques ;
Travaille en partenariat avec des analystes business et des architectes de solutions pour d√©velopper des architectures techniques pour les projets et initiatives strat√©giques de l'entreprise.
Expertises techniques :
Exp√©rience du d√©veloppement de bases de donn√©es et d'une vari√©t√© de technologies de bases de donn√©es relationnelles ;
Exp√©rience des entrep√¥ts de donn√©es ;
Expertise en SQL et en analyse de donn√©es ; ma√Ætrise Python ;
Id√©alement certifi√© des technologies BI du Cloud Azure (Synapse, Azure Data Factory, PurView) ;
Connaissance de l'intelligence artificielle, des statistiques et/ou des math√©matiques appliqu√©es ;
Exp√©rience dans le d√©veloppement de solutions sur des services et infrastructures de cloud computing dans le domaine des donn√©es et de l'analyse ;
Exp√©rience du d√©ploiement de Power BI ;
Exp√©rience conceptuelle des donn√©es et de l'analyse, par exemple ETL, mod√©lisation dimensionnelle, outils de reporting, gouvernance des donn√©es, entreposage des donn√©es, donn√©es structur√©es et non structur√©es, qualit√© de donn√©es ;
Connaissance CI/CD et GitLab fortement appr√©ci√©.
Exp√©rience agile / Digitale / gouvernance :
Passionn√©(e) le d√©veloppement bas√© sur les donn√©es, la fiabilit√© et l'exp√©rimentation ;
Exp√©rience souhait√©e de travail au sein d'une √©quipe produit Agile collaborative ;
Connaissance de la gouvernance de la donn√©e.
Skills Individuels :
Motiv√©(e) et dot√©(e) de solides comp√©tences en mati√®re de r√©solution de probl√®mes et d'apprentissage ;
Flexibilit√© face aux changements d'orientation du travail au fur et √† mesure de l'√©volution du projet ;
Excellentes capacit√©s de communication, d'√©coute et de persuasion.
Attitude attendue :
Sens aigu des chiffres, curiosit√© intellectuelle et volont√© d'adapter sa position sur la base d'informations compl√©mentaires ;
Forte √©thique de travail ; capacit√© √† travailler √† un niveau abstrait et √† obtenir un consensus.
Informations suppl√©mentaires :
Poste √† pourvoir d√®s que possible ;
Remboursement des frais de transports + Mutuelle ;
Possibilit√© de t√©l√©travail jusqu'√† un jour par semaine.
Show more
Show less","{'ProgLanguage': ['Python', 'R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': ['Power BI'], 'Statistics': ['Statistiques'], 'CloudComputing': ['Azure'], 'DevTools': ['Git'], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Statistiques', 'Cloud', 'CI/CD'], 'FrSoftSkills': ['Communication', 'R√©solution de probl√®mes', 'Collaboration', 'Flexibilit√©'], 'EnSoftSkils': ['Communication', 'Collaboration', 'Initiative']}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's']}"
Data Engineer (H/F) - Lille - CDI,METEOJOB by CleverConnect,"Lille, Hauts-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-h-f-lille-cdi-at-meteojob-by-cleverconnect-3858145866?position=1&pageNum=7&refId=qxFNczJVHC836Oeplk10jg%3D%3D&trackingId=LNFSV%2BxVgNJ97smnq8gZSw%3D%3D&trk=public_jobs_jserp-result_search-card,"Entreprise
Chez LJE Solutions, nous pla√ßons l‚Äôhumain au c≈ìur de chaque projet. Au-del√† des comp√©tences, nous valorisons les
aspirations
et les
valeurs
de chaque individu.
Nous intervenons dans tous les secteurs d'activit√© en France et en Suisse.
Description Du Poste
LJE Solutions recherche pour un de ses clients bas√© √† Lille, un/une Data Engineer.
Notre client est une
ESN dynamique bas√©e √† Lille, qui se distingue dans l'int√©gration et la restitution de donn√©es. Partenaire privil√©gi√© de technologies de pointe comme Power BI, Tableau et Qlik, il recherche des talents d√©sireux de participer √† notre aventure entrepreneuriale.
Nous recherchons un Data Engineer curieux et motiv√© pour jouer un r√¥le cl√© dans l'organisation et le d√©veloppement de l'agence. Ce poste offre une opportunit√© unique de travailler directement avec les fondateurs, experts en technologies, et de contribuer significativement √† la formation interne et √† l'expertise chez nos clients.
Vos Responsabilit√©s
Travailler en √©troite collaboration avec les fondateurs sur des projets d'int√©gration et de restitution de donn√©es,
Participer activement √† la croissance de l'entreprise en apportant des id√©es innovantes et en prenant part √† des projets vari√©s,
Monter en comp√©tence techniquement, avec la possibilit√© d'√©voluer vers des r√¥les de Team Lead ou Tech Lead selon vos aspirations.
Cette entreprise offre un environnement convivial et ambitieux, encourageant la prise d'initiative. Leur structure √† taille humaine valorise chaque collaborateur, avec une approche personnalis√©e et une hi√©rarchie plate qui favorise l'expression et la participation active de tous.
R√©mun√©ration Et Avantages
Poste bas√© √† Lille, avec possibilit√© de t√©l√©travail partiel,
R√©mun√©ration comp√©titive bas√©e sur l'exp√©rience, fourchette indicative de 44k √† 48k ‚Ç¨ en fixe, + variables,
Tickets restaurant,
Mutuelle d'entreprise.
Description Du Profil
Passion pour les technologies de la data, avec une expertise ou un int√©r√™t pour XDi et Talend, sans exclure d'autres ETL du march√©,
Plus de 4 ans d'exp√©rience dans le domaine de la data engineering,
Curiosit√© intellectuelle, agilit√©, excellent savoir-√™tre, forte capacit√© de travail en √©quipe et de partage de connaissances,
Localisation √† Lille ou disposition √† d√©m√©nager, avec une pr√©f√©rence pour les candidats de la r√©gion pour faciliter la collaboration et le partage au sein de notre agence physique.
Show more
Show less","{'ProgLanguage': ['R'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': ['Tableau', 'Power BI'], 'Statistics': [], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': [], 'FrSoftSkills': ['Collaboration', 'Organisation'], 'EnSoftSkils': ['Collaboration', 'Initiative']}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's', '4', '4', '4']}"
Data Engineer - Analytics Engineer H/F,DAVRICOURT | Certified Positive Company¬Æ,"Lille, Hauts-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-analytics-engineer-h-f-at-davricourt-certified-positive-company%C2%AE-3916660249?position=2&pageNum=7&refId=qxFNczJVHC836Oeplk10jg%3D%3D&trackingId=NhUsE28d0XCOa15qs24Cvw%3D%3D&trk=public_jobs_jserp-result_search-card,"Cr√©√©e en 2011, DAVRICOURT est une soci√©t√© de conseil sp√©cialis√©e dans le recrutement et la prestation d'ing√©nieurs et de techniciens au service des industries. Nous intervenons sur les grands sujets de mobilit√©, les enjeux √©nerg√©tiques, la pr√©servation de la sant√©, la conception de produits innovants et les probl√©matiques de transformation digitale dans divers secteurs industriels.
Nous proposons un accompagnement sur mesure, align√© avec nos engagements RSE et notre raison d'√™tre : ¬´ R√©v√©ler les talents de l'industrie et du num√©rique pour les rendre acteurs d'un monde plus responsable ¬ª.
Labellis√©s ¬´ Positive Company ¬ª et certifi√©s ISO9001 pour un management de la qualit√©, nous avons √† coeur d'int√©grer toutes nos parties prenantes dans notre d√©marche RSE et de rentre acteur nos collaborateurs en leur proposant, notamment, d'agir concr√®tement aupr√®s d'associations.
Vous souhaitez (re)donner du sens √† votre travail ? Alors, vous √™tes au bon endroit !
Dans le cadre d'une assistance technique, pour l'un de nos clients se trouvant en m√©tropole Lilloise, nous recherchons :
Un/une : Data Engineer / Analytics engineer.
Vos Missions Sont Les Suivantes
Automatiser et industrialiser les pipelines de transformation de donn√©es qui servent aux dashboards, mod√®les IA et data analyses
Construire et mod√©liser la semantic layer de domaine m√©tier (commerce, supply, sports, etc.) ;
D√©finir la strat√©gie de nos stacks techniques et garantir la qualit√© des donn√©es expos√©es ;
Maintenir et repenser les datasets et pipelines existants pour servir une plus large vari√©t√© de use cases ;
Permettre de l'analytique intelligente en construisant des datasets robustes, fiables et pertinents ;
Contribuer activement √† notre communaut√© d'analytics engineers et de data engineers ;
Et apr√®s ?
En tant que v√©ritable partie prenante de DAVRICOURT, vous vous verrez proposer des projets techniques et √† forte valeur ajout√©e par nos √©quipes.
Vos comp√©tences techniques : - Data-platform : Amazon Web Services, Databricks, Glue, S3 - Code Programming : SQL, Python, Scala - Data orchestration : Airflow - Data modeling : dbt - Data quality : great\_expectations - Software Delivery : Git, Github, Make Pr√©requis : - DB2 ; Expert.e - Databrick ; Confirm√©.e - Airflow ; Confirm√©.e - SQL ; Expert.e Vous √™tes reconnu(e) pour votre esprit d'analyse et vos capacit√©s de synth√®se et d'adaptation. Ce que nous cherchons avant tout, ce sont des personnalit√©s qui participent au d√©veloppement de DAVRICOURT et forment un r√©seau de talents interconnect√©s qui ne craint pas d'affirmer sa diff√©rence. Vous √™tes unique, nous sommes diff√©rents, rencontrons-nous !
LE DAVRIPACKAGE
Salaire comp√©titif - Primes de participation et d'int√©ressement - √âpargne salariale - Mutuelle et pr√©voyance - Plateforme CE - Actions de formation
INT√âRESS√â(E) ?
Si vous √™tes arriv√©(e) √† la fin de cette offre, c'est qu'elle vous a forc√©ment attir√©e, alors surtout n'h√©sitez pas √† postuler ! En cas de doute, notre √©quipe recrutement saura r√©pondre √† vos questions. L'offre d'emploi ne correspond pas tout √† fait √† vos comp√©tences mais nos valeurs vous ressemblent et notre ambition vous motive ? Alors vous pouvez consulter l'ensemble de nos offres sur davricourt.com ET APR√àS ? Notre processus de recrutement est simplifi√© : un seul entretien est pr√©vu par nos √©quipes recrutement et commerciale √† la suite duquel nous pr√©sentons votre profil au client. NB : En l'absence de retour de la part de l'√©quipe recrutement sous 1 semaine, veuillez consid√©rer que votre candidature n'a pas √©t√© retenue. Merci de votre compr√©hension.
Show more
Show less","{'ProgLanguage': ['Python', 'Scala', 'R'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': ['Databricks'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git'], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': ['Airflow'], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': [], 'FrSoftSkills': [], 'EnSoftSkils': []}","{'JobDetail': ['Confirm√©'], 'TypeContract': [], 'Salary': ['1', '1'], 'Level': [], 'Experience': ['a', 'n', 's']}"
Data Engineer H/F,Dalkia,"Angers, Pays de la Loire, France",https://fr.linkedin.com/jobs/view/data-engineer-h-f-at-dalkia-3907349741?position=3&pageNum=7&refId=qxFNczJVHC836Oeplk10jg%3D%3D&trackingId=B5fNfxjGFcGGtQTH25YBbA%3D%3D&trk=public_jobs_jserp-result_search-card,"Descriptif du poste
Et si vous faisiez √©quipe avec nous ? Rejoindre Dalkia, c'est plus de sens et d'implication contre le r√©chauffement climatique ; plus de relations humaines, avec un m√©tier de service anim√© par l'esprit d'√©quipe ; plus de technicit√©, avec des projets ambitieux et innovants fond√©s sur nos expertises ; plus d'employabilit√©, avec des parcours diversifi√©s et individualis√©s. Rejoindre Dalkia, c'est rejoindre plus qu'une entreprise : un collectif de 20 000 collaborateurs engag√©s en faveur de la transition √©nerg√©tique.
Dalkia Froid Solutions, acteur majeur de la r√©frig√©ration, sp√©cialis√© dans les services √©nerg√©tiques pour les process industriels et tertiaires, recherche un(e) Data Engineer
(H/F)
. Rattach√© (e) au Responsable Data au sein de la Direction des Syst√®mes D'Informations, vous √™tes le garant du bon d√©roulement des d√©veloppements de flux de donn√©es et de leur pr√©paration pour leur analyse. Vous aurez l'opportunit√© de rejoindre une √©quipe en construction.
Candidater chez Dalkia Froid Solutions, c‚Äôest avoir l‚Äôenvie d‚Äôint√©grer un grand groupe √† l‚Äôesprit familial. L‚Äôhumain est au c≈ìur de nos m√©tiers, nous donnons la chance √† tous, afin de d√©couvrir nos talents de demain. Venez renforcer notre Direction des Syst√®mes d'Informations et contribuez √† l'optimisation √©nerg√©tique √† travers la data !
Vos Principales Missions
D√©finir l'architecture ETL et d√©velopper les jobs d'int√©gration de donn√©es pour notre environnement Big Data.
Assurer le monitoring quotidien des jobs et optimiser les performances de traitement.
Garantir la qualit√© et l'int√©grit√© des donn√©es en industrialisant leur nettoyage.
Adapter les DataMarts pour le reporting en collaboration avec les √©quipes m√©tiers : comprendre et analyser les besoins utilisateurs, et r√©diger les sp√©cifications fonctionnelles et techniques.
Vous serez √©galement ammen√© √† collaborer avec l'√©quipe Infrastructure pour d√©finir les besoins techniques et planifier les investissements. En lien avec votre √©quipe vous conduirez des projets vari√©s et participerez √† la mise en oeuvre de rapports BI et de mod√®les de machine learning.
Lieu :
Si√®ge Social - Angers / T√©l√©travail possible √† raison de 2 jours par semaine apr√®s p√©riode d'essaie
Votre profil
Dipl√¥m√© (e) d'un bac + 5 minimum sp√©cialis√© en Data Engineer ,vous avez de bonnes qualit√©s relationnelles afin d'accompagner le d√©ploiement des projets. Votre rigueur et votre logique sont incontestables. Vous aimez travailler en √©quipe pour accompagner l'entreprise vers l'excellence op√©rationnelle.
C√¥t√© Outils ? Vous maitrisez les langages SQL et Pyhton et vous avez d√©j√† pratiqu√© les outils DBT et GitLab. Une premi√®re exp√©rience avec un outil de BI/Datavisualisation est souhait√©e.
La connaissance des outils Qlik Sense ou Talend serait un plus!
Pr√™t(e) √† faire une diff√©rence avec nous ? Postulez d√®s maintenant !
Ensemble, nous contribuons collectivement √† la transition √©nerg√©tique. C'est pourquoi chez Dalkia Froid Solutions, nous sommes convaincus que chacun peut participer √† relever ce d√©fi. De ce fait, chaque candidature recevra la m√™me attention.
Show more
Show less","{'ProgLanguage': ['R'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git'], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Big Data', 'Machine Learning'], 'FrSoftSkills': ['Collaboration'], 'EnSoftSkils': ['Collaboration']}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's']}"
DATA Engineer (H/F),Boulanger,"Lesquin, Hauts-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-h-f-at-boulanger-3854554057?position=4&pageNum=7&refId=qxFNczJVHC836Oeplk10jg%3D%3D&trackingId=xUvT4IOdFUTsaQgkLdtq2g%3D%3D&trk=public_jobs_jserp-result_search-card,"Au sein de la direction informatique, le p√¥le DATA a pour missions de maximiser la mise en valeur des donn√©es de BOULANGER ,ELECTRO-DEPOT et KREFEL/HIFI afin d‚Äôaider nos d√©cideurs √† agir sur les leviers de leur performance par des processus d√©cisionnels efficients.
Au sein de ce p√¥le, tu prendras en charge un large domaine m√©tier qu'il te faudra maitriser de bout en bout : de la donn√©es brutes, sa transformation jusqu'√† son exposition dans les reporting. Cela afin d'en assurer le bon fonctionnement, les √©volutions constantes et sa p√©rennit√©
Tes t√¢ches principales portent sur :
Le pilotage et la mise en ≈ìuvre de projets DATA.
La collecte, le stockage et l‚Äôexploitation fluides des donn√©es par le d√©veloppement de solutions
Missions
Maitriser les r√®gles fonctionnelles et les KPI de ton domaine afin de challenger les m√©tiers dans les √©volutions et les nouveaux projets
Accompagner des √©quipes m√©tiers dans leurs travaux d‚Äôidentification et expression des besoins sur la data
Participer aux ateliers de conception et d√©veloppement des applications data
Mod√©liser la solution √† mettre en ≈ìuvre
Concevoir et mettre (ou faire mettre) en ≈ìuvre des flux les pipelines d‚Äôint√©gration (en mode batch ou fil de l'eau) de donn√©es structur√©es/semi-structur√©es
Transformer les donn√©es : consolider, enrichir et optimiser les donn√©es, qui seront exploit√©es par le m√©tier
Cr√©er, faire √©voluer et optimiser les restitutions
Suivre et animer les d√©veloppeurs (ETL, restitution, self-BI internes ou externes)
G√©rer le RUN
Maitrise le SQL et la base de donn√©es (Oracle, Snowflake)
Ma√Ætrise d‚Äôoutils de restitution (tel que Business Object (BO), PowerBI‚Ä¶)
Capacit√© relationnelle, rigueur et dynamisme
Ma√Ætrise un ou plusieurs outils de pr√©paration et traitement de la donn√©e (DataStage, Stambia, ...)
Capacit√© √† s‚Äôadapter √† tout type d‚Äôinterlocuteurs (technique, m√©tiers, Direction)
Show more
Show less","{'ProgLanguage': ['R'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': ['PowerBI'], 'Statistics': [], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'DBMS': ['Oracle', 'Snowflake', 'Snowflake'], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': [], 'FrSoftSkills': [], 'EnSoftSkils': []}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's']}"
Data Engineer,Devoteam Innovative Tech,"Lyon, Auvergne-Rh√¥ne-Alpes, France",https://fr.linkedin.com/jobs/view/data-engineer-at-devoteam-innovative-tech-3889051125?position=5&pageNum=7&refId=qxFNczJVHC836Oeplk10jg%3D%3D&trackingId=xZtN0Jo%2BH71aqqrWbXCorA%3D%3D&trk=public_jobs_jserp-result_search-card,"Company Description
Avec pr√®s de 10 000 collaborateurs √† travers le monde, nous accompagnons les entreprises dans leur transformation num√©rique. Nous imaginons et concr√©tisons leurs ambitions gr√¢ce aux possibilit√©s infinies des plateformes digitales, pour faire √©voluer leur culture et leur mode de travail, et cr√©er de la valeur dans leurs organisations.
Pr√©sent dans 18 pays d‚ÄôEurope et du Moyen-Orient et fort de 25 ans d‚Äôexp√©rience, nous mettons la ""Technologie au service de l‚ÄôHomme"" afin de construire un monde plus humain et plus durable.
Travailler chez Devoteam, c‚Äôest :
travailler aux c√¥t√©s de partenaires comme Google, Microsoft, AWS ou Salesforce dont nous impl√©mentons les solutions chez nos clients.
√©voluer dans un groupe international qui vous accompagne dans le d√©veloppement de votre carri√®re avec des parcours de formation et de certification adapt√©s.
rejoindre une √©quipe sp√©cialis√©e, accompagn√© par un manager de proximit√© qui saura vous guider dans vos choix et favoriser les √©changes avec vos pairs, que ce soit lors d'√©v√©nements techniques ou conviviaux.
grandir dans une entreprise qui challenge ses √©quipes en √©tant agile et ambitieuse, s‚Äôadaptant pour permettre les succ√®s individuels et collectifs.
La mission
En pleine transformation digitale, le client con√ßoit et fournit des produits et services digitaux pour accompagner la transformation digitale de ses entit√©s dans le monde entier.
Le client souhaite renforcer les capacit√©s de d√©veloppements d‚Äôune des √©quipes
sur la technologie de d√©veloppement Databricks (Databricks, Python, Spark SQL) dans un
environnement 100% Cloud Azure. Une exp√©rience Azure pass√©e serait
appr√©ci√©e.
Les principales activit√©s sont :
‚Ä¢ D√©veloppements de pipelines Data permettant la construction et l‚Äô√©volution de leur
Datalake
‚Ä¢ Participation aux d√©ploiements sur les environnements de test et de production
‚Ä¢ Maintien en condition op√©rationnelle des √©l√©ments logiciels en production
En fonction des autres comp√©tences du candidats, d‚Äôautres activit√©s pourraient √™tre :
‚Ä¢ Participation √† des r√©unions de conceptions et de chiffrages
‚Ä¢ Participation √† des r√©unions de prises de d√©cisions techniques
‚Ä¢ Conseils techniques au Tech Lead / Architecte de l‚Äô√©quipe ¬´ Data ¬ª et de la
plateforme
Le candidat devra pouvoir s‚Äôint√©grer dans un projet dynamique en m√©thodologie agile et
dans une √©quipe de grande taille.
Comp√©tences techniques attendues:
Databricks
Python
Travailler en SCRUM
Environnement Azure
Additional information
Le Groupe Devoteam ≈ìuvre pour l'√©galit√© des chances, pour la promotion de ses collaboratrices et de ses collaborateurs au m√©rite et lutte activement contre toute forme de discrimination. Nous sommes persuad√©s que la diversit√© contribue √† la cr√©ativit√©, au dynamisme et √† l'excellence de notre organisation. Tous nos postes sont ouverts aux personnes en situation de handicap.
Show more
Show less","{'ProgLanguage': ['Python', 'R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': ['Spark', 'Databricks'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': ['AWS', 'Azure'], 'DevTools': ['Git'], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Cloud'], 'FrSoftSkills': ['Cr√©ativit√©', 'Organisation'], 'EnSoftSkils': []}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's', '25', '25', '25']}"
Data Engineer,Equativ,"Paris, √éle-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-at-equativ-3814251519?position=6&pageNum=7&refId=qxFNczJVHC836Oeplk10jg%3D%3D&trackingId=jqGUZgOFk6AVjwG%2FgxR61Q%3D%3D&trk=public_jobs_jserp-result_search-card,"üë´ About the team
At Equativ, we‚Äôre on a mission to develop advertising technologies that empower our customers to reach their digital business goals. This means that we rely on massively scalable, widely distributed, highly available, and efficient software systems; the platform deals with over 100 billions requests per day and above 40 Gbps of network traffic.
Our innovation team based in Paris, Nantes, Limoges, Krak√≥w and Berlin is composed of 90 straightforward and energetic engineers working in an Agile environment and ready to tackle the most complex technical challenges.
Our data engineering team is composed of 10 skilled engineers and is based in Paris. We are part of the R&D department which is composed of 140+ engineers spread across Paris, Nantes, Limoges, Krak√≥w and Berlin all working in an Agile environment and ready to tackle the most complex technical challenges.
Our mission üëá
Data Engineering team is central to Equativ‚Äôs data centric business and is responsible to ingest, transform, model and redistribute all data coming from our adtech platform.
We aim at building scalable and robust Big Data platforms from ingestion to business actionable consumption. Our Big Data ecosystem must handle massive log ingestion (tens of billions per day), short & long term data storage, complex data modelling, real-time and batch ELT as well as providing external access through dedicated APIs.
Data Engineers serve Equativ data directly to our customers and throughout the company whether it is for BI analysis, data science algorithms (clustering and optimization), customer reporting, invoicing and more.
Equativ Data Engineering team is engaged in an ambitious migration of its main data stack (Hadoop on-premise) to GCP with the objective to increase reporting features, lower maintenance time, improve performances and simplify the access to our raw data.
What you'll do ‚úèÔ∏è
As a Big Data Engineer, you‚Äôll primarily focus on maintaining and enhancing the operationality of our on-premise and cloud data pipelines which feed our warehouses and APIs
-Design, develop, test, promote and industrialize all data components from data ingestion to datawarehouse delivery (ClickHouse, BigQuery):
Propose and develop innovative solutions to achieve the best levels of scalability and performance for our Big Data engines
Automate and streamline our real-time and batch data pipelines (on-premise and in the cloud) in order to simplify access to our data by other teams and lower amount of work spent by other teams on ETL processes
Perform end-to-end monitoring to ensure high availability of production data processing, data quality and reliability
Apply best in class Devops guidelines and secure deployments
-Brainstorm with other team members working on our data backend (datawarehouse modelling and data exposure through our reporting APIs) on optimizing our architecture and support them in the use of our pipelines
-Contribute to data roadmap definition in coordination with other R&D and product teams in order to build a best in class data infrastructure that will generate insights for Equativ‚Äôs analytics
-Take part in improving and deploy data engineering standards, procedures, processes and operational guidelines around target data components at Equativ
üí™ About you
Master degree in Computer Science or similar technical field of study
3+ years of software development with open source technologies
Fluent in Java and/or in Scala. SQL mastery
Very good understanding of Devops principles (Gitlab, Docker, Kubernetes, Gradle, ci/cd)
Experience with large-scale data engineering technologies (ClickHouse, Flink, Kafka, Hadoop, Spark, Hbase)
Experience on building data pipelines on Google Cloud Platform (BigQuery, Dataflow, GCS, Cloud Run, Airflow ‚Ä¶) would be a big plus
Experience in working with high QPS Rest APIs is a plus
Entrepreneurial spirit and know-how to identify opportunities of improvement
Working proficiency and communication skills in verbal and written English
Passion for playing with large volume of data
üöÄ How you'll grow
Within 1 month:
You'll be just finishing your onboarding.
You'll probably have tackled a few small tasks in peer-coding
Within 4 months:
You'll have an overview of 50% of the stack, CI/CD and team‚Äôs main processes. You‚Äôll be able to work on more complex developments
You'll now have enough knowledge to participate to deployments of chosen applications
Within 9 months:
You'll be autonomous on most of our stack and will have participated to major projects
You‚Äôll be helping the team on production matters
üëã About us
Equativ is the new single name for Smart Adserver, DynAdmic, LiquidM and Nowtilus ‚Äî four proven innovators in advertising technology. The vertically integrated company provides brand and privacy-safe solutions that empower its clients to achieve maximum impact while respecting the rights of consumers. The union combines client expertise and engineering excellence to serve the interests of both the supply- side and demand-side with equal professionalism and technical sophistication.
Headquartered in Paris and New York, Equativ operates globally with a team of more than 550 people in 20 offices. Equativ offers the market its own independent ad server, SSP, buyer tools, and media services to fulfill the promise of advertising technology. Learn more at Equativ.com.
The company is ranked on the Deloitte Technology Fast 500 EMEA and in the Financial Times‚Äô FT 1000: Europe‚Äôs Fastest-Growing Companies.
Equativ (formerly Smart AdServer) has been awarded the HappyIndex@Work label and is proud to be among the best companies in the ChooseMyCompany ranking, recognized for its flexible working environment.
Come and lead the charge with us in building a transparent ecosystem based on quality!
Show more
Show less","{'ProgLanguage': ['Java', 'Scala', 'R', 'Go'], 'DataBase': ['SQL', 'HBase'], 'DataAnalytics': ['R'], 'BigData': ['Hadoop', 'Spark', 'Flink'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': ['Google Cloud Platform'], 'DevTools': ['Git', 'Docker'], 'Os': [], 'DBMS': ['BigQuery'], 'SoftBigDataProcessing': ['HBase'], 'Automation': ['Kubernetes', 'Airflow'], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': ['Docker', 'Kubernetes'], 'Collaboration': ['Teams'], 'Other': ['DevOps', 'Big Data', 'ML', 'Cloud', 'CI/CD'], 'FrSoftSkills': ['Communication'], 'EnSoftSkils': ['Communication']}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's']}"
Data Engineer / Data Ops,FRG Technology Consulting,"√éle-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-data-ops-at-frg-technology-consulting-3913842168?position=7&pageNum=7&refId=qxFNczJVHC836Oeplk10jg%3D%3D&trackingId=wtMwTXpyAki1tPFfxSjiwg%3D%3D&trk=public_jobs_jserp-result_search-card,"Vous √™tes un expert passionn√© par la Data et √† la recherche de d√©fis excitants ? Mon client recherche actuellement un
Data Engineer
/ Data Ops
talentueux pour rejoindre une √©quipe dynamique et humaine.
Missions principales :
Participation active au d√©ploiement de la nouvelle plateforme sur Azure & Snowflake
Forte autonomie et gestion compl√®te des projets data
Analyse des besoins actuels et futurs
Cr√©ation de sp√©cifications fonctionnelles et techniques
Mod√©lisation de donn√©es
D√©veloppement de packages SSIS
Int√©gration des donn√©es dans SnowFlake & Azure,
Cr√©ation de rapports avec Power BI et Excel
Profil recherch√© :
3 √† 4 ans d'exp√©rience
minimum
dans la BI (SSIS, SQLServer, SSAS, SSRS) et/ou le cloud (Azure , Snowflake) ainsi qu'en SQL
Comp√©tences en
architecture sur Snowflake
fortement appr√©ci√©es
1 √† 2 ans d'exp√©rience en tant que DevOps ( CI/CD ; GitLab)
Autonome, rigoureux et anglais courant
Show more
Show less","{'ProgLanguage': ['R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': ['Power BI'], 'Statistics': [], 'CloudComputing': ['Azure'], 'DevTools': ['Git'], 'Os': [], 'DBMS': ['Snowflake', 'Snowflake'], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['DevOps', 'Cloud', 'CI/CD'], 'FrSoftSkills': [], 'EnSoftSkils': []}","{'JobDetail': [], 'TypeContract': [], 'Salary': ['3'], 'Level': [], 'Experience': ['a', 'n', 's', '4', '4', '4']}"
APPRENTI DATA ENGINEER (H/F),Akademija Oxford,"Paris, √éle-de-France, France",https://fr.linkedin.com/jobs/view/apprenti-data-engineer-h-f-at-akademija-oxford-3917872047?position=8&pageNum=7&refId=qxFNczJVHC836Oeplk10jg%3D%3D&trackingId=S8NNV%2BXLAWM1uLDL%2BGQBiQ%3D%3D&trk=public_jobs_jserp-result_search-card,"Une de nos entreprises partenaires, ESN situ√©e √† Paris, recherche un Apprenti Data Engineer (H/F) pr√©parant un bac +4/+5 sp√©cialit√© Big Data pour la rentr√©e de Septembre 2021.
Show more
Show less","{'ProgLanguage': ['R'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Big Data'], 'FrSoftSkills': [], 'EnSoftSkils': []}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's']}"
Data Engineer Senior,AXA en France,"Hauts-de-Seine, √éle-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-senior-at-axa-en-france-3884386043?position=9&pageNum=7&refId=qxFNczJVHC836Oeplk10jg%3D%3D&trackingId=92af2kgoDOP%2BDxhZe1t2gQ%3D%3D&trk=public_jobs_jserp-result_search-card,"Environnement
En tant que
Senior Data Engineer F/H
, vous allez contribuer directement aux projets des directions m√©tier (ex : fraude sant√©, multi√©quipements, pricing IARD, optimisation du lead management, fragilit√© auto, ‚Ä¶) d‚ÄôAXA France et √† la construction du socle technique Big Data.
Vous allez int√©grer une √©quipe d'une dizaine de personne compos√©e de Data Engineer et des Tech Lead travaillant en mode Feature Team au sein des tribus m√©tier de la Direction Transformation Digital Tech et DATA (DT2).
La Direction Transformation Digital Tech et DATA d'AXA France en quelques mots :
- Une organisation agile en feature teams : tribus, guildes, squads
- Des projets sur des applications innovantes √† fort trafic (web, mobile‚Ä¶)
- Des m√©thodologies craft (TDD, BDD, clean code, code review‚Ä¶) et DevOps
- Une communaut√© de partage de bonnes pratiques (BBL, dojo, meetup, conf‚Ä¶)
Votre r√¥le et vos missions
Vous aurez pour missions principales de d√©velopper les projets Big Data demand√©s par le m√©tier, et notamment :
Passer de la donn√©e brute √† de la donn√©e exploitable, expos√©e sous forme de tables requ√™tables dans le datalake
Consolider ces donn√©es au fur et √† mesure de leur alimentation r√©currente dans le data lake
Les exploiter pour atteindre la finalit√© business (exposition de business view, r√©int√©gration des r√©sultats dans le SI, service de scoring, ‚Ä¶)
De travailler √† la cr√©ation du socle technique Big Data et industrialiser le cycle de d√©veloppement de l'√©quipe
De mettre en place et de garantir le respect dans la dur√©e d'un processus qualit√© sur l'ensemble du cycle de DEV (documents, tests unitaires / int√©gration / fonctionnels, commentaires, versionning, etc.)
Votre profil
Vous justifiez de plusieurs exp√©riences significatives (+ de 5 ans) sur du
d√©veloppement big data, en particulier sur du PySpark.
Comp√©tences techniques :
Connaissances avanc√©es en d√©veloppement en
PySpark
(Spark avec le langage Python)
Maitrise de l'environnement
Microsoft Azure
Connaissances avanc√©es d'outils de BI comme
PowerBI
Comp√©tences transverses :
Capacit√© √† interagir avec des parties prenantes diverses : Business analyst, Architectes, M√©tier
Exp√©rience en mode de delivery Agile (Scrum, Kanban, etc...)
Driver et accompagner des Data Engineer junior sur les aspects technique
Et Id√©alement :
Des Connaissances sur Azure DevOps, Azure Pipeline, GIT, JIRA
Maitrise des Traitements Big Data en mode Streaming
Maitrise des Bases de donn√©es relationnelles et NoSQL
Une exp√©rience professionnelle avec des outils comme Azure Databricks, Azure Data Lake Storage ou encore Azure Data Factory
Qui sommes nous ?
AXA est un des leaders de l‚Äôassurance et de la gestion d‚Äôactifs dans le monde.
Nous aidons nos 108 millions de clients √† traverser les petites et grandes difficult√©s de la vie.
Chaque jour, nous agissons ensemble pour inventer la meilleure mani√®re de les prot√©ger et voulons donner √† chacun les moyens de vivre une vie meilleure.
Un challenge qui donne le sourire et envie de se lever le matin !
Chez AXA, nous sommes persuad√©s que pour bien prendre soin de nos clients, nous devons commencer par bien prendre soin de nos collaborateurs. C‚Äôest pour cette raison que nous menons une politique RH engag√©e qui favorise la diversit√©, qui pr√©serve l‚Äô√©quilibre vie priv√©e-vie professionnelle et acc√©l√®re le d√©veloppement des comp√©tences et des carri√®res.
Ainsi, en rejoignant AXA France vous travaillerez dans une entreprise responsable, offrant une v√©ritable culture d‚Äôexpertise, acc√©l√©rant le d√©veloppement des comp√©tences de chacun et proposant une r√©mun√©ration attractive.
Pourquoi nous rejoindre ?
Vous √™tes porteur d‚Äôid√©es et d‚Äôinitiatives innovantes ? Vous proposez des solutions et √™tes au service du client ? Faites partie de notre grande famille en rejoignant
Un leader mondial offrant des opportunit√©s de carri√®res int√©ressantes
Une entreprise qui donne une place de choix √† l‚Äôinnovation, √† l‚Äôinitiative et aux actions solidaires (notamment via l‚Äôassociation AXA Atout C≈ìur)
Un environnement inclusif √† tous les niveaux (mixit√©, handicap, initiatives pour favoriser l‚Äôinsertion des jeunes, orientation sexuelle, etc.)
Un acc√®s √† de multiples avantages (cong√©s, temps partiel, t√©l√©travail, etc.)
Un cadre stimulant, qui permet de rencontrer des collaborateurs performants et d‚Äôenrichir ses comp√©tences
Victime ou t√©moin, en cas de discrimination, vous pouvez adresser vos signalements et/ou alertes discrimination √† alerte.discrimination.harcelement@axa.fr
Show more
Show less","{'ProgLanguage': ['Python', 'R'], 'DataBase': ['SQL', 'NoSQL'], 'DataAnalytics': ['R'], 'BigData': ['Spark', 'Databricks'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': ['PowerBI'], 'Statistics': [], 'CloudComputing': ['Azure'], 'DevTools': ['Git'], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': ['JIRA', 'Teams'], 'Other': ['DevOps', 'Big Data'], 'FrSoftSkills': ['Organisation'], 'EnSoftSkils': ['Initiative']}","{'JobDetail': ['Junior', 'Senior'], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's', '5', '5', '5']}"
Data Engineer,CGI,"Niort, Nouvelle-Aquitaine, France",https://fr.linkedin.com/jobs/view/data-engineer-at-cgi-3902057928?position=10&pageNum=7&refId=qxFNczJVHC836Oeplk10jg%3D%3D&trackingId=5o7L%2B5v8w0zofLBPaTvnxA%3D%3D&trk=public_jobs_jserp-result_search-card,"Description de poste
Big Data, Data Science, Data analyse, Data architecture ... √áa n‚Äôa pas de secret pour vous ?
Que vous commenciez votre carri√®re professionnelle ou que vous soyez sp√©cialiste de l‚Äôune de ces disciplines, int√©grer notre communaut√© Data, c‚Äôest l‚Äôassurance de progresser, innover, partager, vous certifier et rendre service √† nos clients.
Si vous souhaitez int√©grer nos √©quipes √† Niort et accompagner les plus grands acteurs du secteur des Assurances, cette annonce est susceptible de vous int√©resser.
En tant que Data Engineer, vous serez responsable de la conception, du d√©veloppement, de la gestion et de l'int√©gration des syst√®mes bas√©s sur les technologies AWS, Terraform, OpenShift, Kafka et Hadoop. Ce r√¥le implique la mise en place d'architectures √©volutives et hautement disponibles pour r√©pondre aux besoins de traitement et de stockage de donn√©es de l'entreprise.
Fonctions et responsabilit√©s
Vos responsabilit√©s seront les suivantes:
-Maintenir et d√©velopper des solutions bas√©es sur les services AWS pour le stockage, le traitement et l'analyse de donn√©es
-Utiliser les services AWS appropri√©s tels que Amazon EC2, S3, RDS, Lambda, etc., pour r√©pondre aux exigences du projet.
-Cr√©er et maintenir les configurations Terraform pour la gestion de l'infrastructure en tant que code (IaC) sur AWS
-Participer √† la maintenance et √† la mise en place d'environnements OpenShift pour l'h√©bergement d'applications et de services
-G√©rer et administrer les clusters Kafka pour garantir la disponibilit√©, la performance et la s√©curit√© du syst√®me de messagerie
Participer √† l‚Äôassistance utilisateurs sur les briques de la plateforme Hadoop Cloudera Data
-Travailler avec les projets et les devOps pour assurer un traitement efficace des donn√©es
En rejoignant CGI, vous b√©n√©ficiez notamment d‚Äôune offre compl√®te de formations (techniques, m√©tiers, d√©veloppement personnel,‚Ä¶), de flexibilit√© gr√¢ce √† notre accord t√©l√©travail (jusqu‚Äô√† 3 jours de t√©l√©travail par semaine), d‚Äôune politique de cong√©s avantageuse (27 jours de cong√©s pay√©s, RTT, cong√©s anciennet√© et enfant malade,‚Ä¶) et d‚Äôun package d‚Äôavantages int√©ressant (r√©gime d‚Äôachats d‚Äôactions, participation, CSE,...).
Qualit√©s requises pour r√©ussir dans ce r√¥le
Ayant une premi√®re exp√©rience en tant que Data Engineer, vous avez une premi√®re exp√©rience relative aux points suivants:
-D√©veloppement et int√©gration sur les technologies AWS, Terraform, OpenShift, Kafka et Hadoop
-Connaissance avanc√©e de l'administration Kafka, y compris la configuration, la gestion et la r√©solution des probl√®mes
-Mise en ≈ìuvre de l'infrastructure en tant que code √† l'aide de Terraform
-Bonne compr√©hension des bonnes pratiques de s√©curit√© pour les syst√®mes cloud, les clusters Kafka et les plateformes Hadoop
CGI est un employeur inclusif et attentif aux candidatures des personnes en situation de handicap, √† l‚Äô√©volution de carri√®res des hommes et des femmes et au bien-√™tre de nos salari√©s LGBT+. Dans un souci d‚Äôaccessibilit√© et de clart√©, le point m√©dian n‚Äôest pas utilis√© dans cette annonce. Tous les termes employ√©s se r√©f√®rent aussi bien au genre f√©minin que masculin.
Ensemble, en tant que propri√©taires, mettons notre savoir-faire √† l‚Äô≈ìuvre.
La vie chez CGI est ancr√©e dans l‚Äôactionnariat, le travail d‚Äô√©quipe, le respect et un sentiment d‚Äôappartenance. Chez nous, vous pourrez exploiter votre plein potentiel parce que‚Ä¶
Nous vous invitons √† devenir propri√©taire d√®s le jour 1 alors que nous travaillons ensemble √† faire de notre r√™ve une r√©alit√©. C‚Äôest pourquoi nous nous d√©signons comme associ√©s de CGI, plut√¥t que comme employ√©s. Nous tirons profit des retomb√©es de notre succ√®s collectif et contribuons activement √† l‚Äôorientation et √† la strat√©gie de notre entreprise.
Votre travail cr√©e de la valeur. Vous √©laborerez des solutions novatrices et d√©velopperez des relations durables avec vos coll√®gues et clients, tout en ayant acc√®s √† des capacit√©s mondiales pour concr√©tiser vos id√©es, saisir de nouvelles opportunit√©s, et b√©n√©ficier d‚Äôune expertise sectorielle et technologique de pointe.
Vous ferez √©voluer votre carri√®re en vous joignant √† une entreprise b√¢tie pour cro√Ætre et durer. Vous serez soutenus par des leaders qui ont votre sant√© et bien-√™tre √† c≈ìur et qui vous permettront de saisir des occasions afin de parfaire vos comp√©tences et √©largir les horizons.
Joignez-vous √† nous, l‚Äôune des plus importantes entreprises de conseil en technologie de l‚Äôinformation (TI) et en management au monde.
Show more
Show less","{'ProgLanguage': ['R'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': ['Hadoop'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': ['AWS'], 'DevTools': [], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': ['Terraform'], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': ['OpenShift'], 'Collaboration': [], 'Other': ['DevOps', 'Big Data', 'Cloud'], 'FrSoftSkills': ['Flexibilit√©'], 'EnSoftSkils': []}","{'JobDetail': [], 'TypeContract': [], 'Salary': ['1'], 'Level': [], 'Experience': ['a', 'n', 's']}"
Data Engineer Cloud (F/H),Apside,"√éle-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-cloud-f-h-at-apside-3904088503?position=1&pageNum=10&refId=HRcIsejJK7jV9EjNnax1mg%3D%3D&trackingId=A0LLcSHoCZK8NlxKh6FDbw%3D%3D&trk=public_jobs_jserp-result_search-card,"üí•
D√©couvrez la Vie Apsidienne
üìπ
et vous aussi, devenez Apsidien
On aurait pu demander √† Chat GPT de vous d√©montrer en quoi
Apside est l‚ÄôESN qu‚Äôil vous faut,
mais on pr√©f√®re que vous le d√©couvriez vous-m√™mes üëáüòè
üî•
D√©couvrez votre future mission
üëâ
Contexte
Rejoignez notre Practise Cloud/Data, afin d‚Äôintervenir sur des sujets √† haute valeur ajout√©e !
Notre
client migre actuellement toutes ses applications vers le cloud AWS.
De plus, dans le cadre du d√©veloppement d'un produit de restitution automatis√©e de donn√©es, ils recherchent actuellement d√©veloppeur data ayant d√©j√† travaill√© sur un projet similaire. La solution produit est techniquement con√ßue en lien avec le Tech Lead validant l'architecture logicielle √† mettre en place sur le cloud AWS.
Secteur
: culture/m√©dia
M√©thode de travail
: Agile Safe
üòé Mission
Capter les donn√©es (structur√©es et non structur√©es) produites dans les diff√©rentes applications
Int√©grer les √©l√©ments
Structurer la donn√©e (s√©mantique, etc‚Ä¶)
Cartographier les √©l√©ments √† disposition
Nettoyer la donn√©e (√©limination des doublons, etc‚Ä¶)
Valider la donn√©e
Cr√©er les r√©f√©rentiels de donn√©es
Environnement technique
:
Python
Lambda
Step Function
AWS / AWS RDS
PostegreSQL
Snowflake
Spark
üìç
Localisation
La D√©fense
üí∞
Le package salarial que nous vous proposons
Contrat :
CDI
Avantages groupe :
carte ticket restaurant Swile, prime de mobilit√©, RTT, accord t√©l√©travail, Mutuelle, prime de cooptation, avantages CE, prise en charge de la mutuelle √† 100% etc‚Ä¶
Avantages agence :
Communaut√© Cloud/Data, afterworks, communaut√© techlead
Formation :
certifications techniques, cours particuliers d‚Äôanglais en interne, acc√®s √† un catalogue de formations gr√¢ce √† notre plateforme e-learning (
Academy by Apside
) ou via nos organismes partenaires.
üîÆ
√î vous futur Apsidien, qui √™tes-vous ?
Au moins 4 ans d'exp√©rience en tant que Data Engineer
Maitrise de l‚Äôenvironnement cloud AWS
Force de proposition, bon relationnel et autonome
üòè
Apside a suscit√© votre curiosit√© ?
Dans un environnement marqu√© par une acc√©l√©ration des √©volutions technologiques, de transformations des usages et de disruptions majeures, Apside est un partenaire de confiance qui accompagne ses clients √† cr√©er de la valeur et √† adresser leurs enjeux strat√©giques en leur mettant √† disposition des expertises technologiques (
Data / IA, Cloud, Cyber
) et une exp√©rience sectorielle (
Industrie, Banque, Assurance, Service, Secteur Public
). Pour un accompagnement global, le groupe propose des offres transverses autour du
Handicap
(Apsid‚ÄôEA), du
Digital Learning
, et du
Conseil
.
ü§î
Et votre place dans tout √ßa ?
üëâ Notre volont√©
est de vous accompagner dans la construction et l‚Äô√©panouissement de votre carri√®re
en nous appuyant notamment
sur 3 piliers :
Une
r√©mun√©ration
√† hauteur de vos investissements et de vos comp√©tences
Une
trajectoire professionnelle
stimulante sur mesure
Un
engagement
autour des valeurs Apsidiennes : la qualit√© de vie et des conditions de travail au c≈ìur de nos enjeux
Engag√©e pour
un monde plus inclusif et plus responsable
, Apside r√©invente l‚ÄôESN et propose l‚ÄôEngagement Soci√©tal et Num√©rique. D√©couvrez notre d√©marche RSE ainsi que notre vision de l‚ÄôEntreprise Engag√©e.
Convaincu ? A vous de jouer, envoyez-nous votre CV !
Rejoignez l‚Äôaventure Apsidienne et d√©couvrez notre vision d‚Äôune ESN singuli√®re et r√©siliente
üöÄ
Show more
Show less","{'ProgLanguage': ['Python', 'R'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': ['Spark'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': ['AWS'], 'DevTools': ['Git'], 'Os': [], 'DBMS': ['Snowflake', 'Snowflake'], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Cloud'], 'FrSoftSkills': [], 'EnSoftSkils': []}","{'JobDetail': [], 'TypeContract': ['CDI'], 'Salary': ['100'], 'Level': [], 'Experience': ['a', 'n', 's', '4', '4', '4']}"
Data Engineer (H/F),Lucky Cart,"Paris, √éle-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-h-f-at-lucky-cart-3908686253?position=2&pageNum=10&refId=HRcIsejJK7jV9EjNnax1mg%3D%3D&trackingId=2G4ZPVp%2FMNUAbuqkLQDlwA%3D%3D&trk=public_jobs_jserp-result_search-card,"Cette offre d‚Äôemploi est fournie par P√¥le emploi
Description
Descriptif du poste La forte croissance que nous enregistrons et les projets de d√©veloppement √† l'international nous am√®nent √† renforcer notre √©quipe data en recrutant un Data Engineer (H/F). Rattach√©(e) au Lead Dataflow, vos travaux d'innovation et de recherche en data engineering permettront de faire √©voluer les produits de Lucky Cart, d'√©valuer au mieux leur performance et d'√©largir la palette de services connexes. Vos recherches pourront faire l'objet de publications, de pr√©sentation dans des s√©minaires ou des meetups et de d√©p√¥ts de brevet. Votre leadership, votre ambition et votre engagement feront de vous une partie int√©grante de la forte expansion de Lucky Cart en France et en Europe. Au c≈ìur de la soci√©t√©, vous collaborerez au quotidien avec toutes les √©quipes impliqu√©es (marketing, R&D, data et juridique) pour mener √† bien vos missions. MISSIONS Sous la responsabilit√© du Lead Dataflow, vous aurez pour missions : D√©finir, d√©velopper et mettre en place et maintenir les outils et infrastructures ad√©quats √† la conception d'algorithmes de data science et de recherche op√©rationnelle, int√©grant les contraintes li√©es √† des volumes de donn√©es tr√®s importants, √† des mod√®les de grande dimension, au temps r√©el, ainsi qu'√† la s√©curit√©, la disponibilit√© et la performance, D√©ployer des pipelines de donn√©es et les mod√®les ci-dessus en production notamment en concevant et en d√©veloppant une architecture en micro-services, Assurer la fiabilit√© des pipelines de donn√©es, des processus ETL et de la transformation des donn√©es en r√©alisant et en mettant en ≈ìuvre des tests manuels et automatis√©s, √ätre force de proposition sur tous les sujets d'architecture et de mod√©lisation, Participer √† l'am√©lioration des √©tapes du workflow scientifique de Lucky Cart: phase de recherche sur des environnements de calculs distribu√©s, d√©veloppement d'outils, mise en production, et tests, data lineage, √ätre force de proposition et prendre le lead sur des dispositifs innovants, Travailler en parfaite collaboration avec les autres fonctions au sein de la soci√©t√© (marketing, R&D, Sales, Produit), Assurer un reporting r√©gulier de l'activit√©. Profil recherch√© COMP√âTENCES Ma√Ætriser un ou plusieurs langages structur√©s (Python, Javascript, Java, C/C++, Scala ), Ma√Ætriser diff√©rents syst√®mes de base de donn√©es (SQL et NoSQL) Avoir une app√©tence pour les technologies utilis√©es dans le Big Data (Hadoop, Map Reduce, Spark, Kafka ), Avoir une exp√©rience sur une plateforme Cloud (GCP, Azure, AWS,..) √ätre familier avec les concepts et algorithmes de statistiques, de data science, de deep learning et d'optimisation en g√©n√©ral (recherche op√©rationnelle notamment), Avoir une bonne connaissance/exp√©rience de m√©thodologies d'ing√©nierie informatique: contr√¥le des sources, tests unitaires, revue de code, √ätre curieux et avoir une forte capacit√© d'adaptation dans un environnement en mutation constante, Chercher constamment √† √©largir et approfondir ses connaissances notamment dans des domaines connexes √† la data science, le e-commerce et la distribution, Partager les connaissances et comp√©tences acquises avec les membres de l'√©quipe par des canaux officiels et informels, D√©montrer la capacit√© √† collaborer avec des personnes d'autres disciplines. Autonomie, organisation, bonne communication. COMP√âTENCES SOUHAITABLES Avoir des connaissances solides en architecture r√©seau et en administration de syst√®mes (Linux/Ubuntu/Apache/Nginx) ainsi qu'en outils du cloud (GCP ou AWS par exemple), √ätre familier avec les langages couramment utilis√©s dans la communaut√© data scientist (Python, R), Ma√Ætrise des outils ETL/ELT (DBT), Avoir une ou plusieurs exp√©riences pratiques de mise en ≈ìuvre de technologie Big Data et de leur optimisation. PROFILS Bac +5, √âcole d'ing√©nieur ou grande √©cole d'informatique, Phd (CIFRE) ou Master Recherche, Anglais courant, 3 ans d'exp
PROFIL SOUHAIT√â
Exp√©rience
36 Mois
Savoirs et savoir-faire
Concevoir et g√©rer un projet
Concevoir un logiciel, un syst√®me d'informations, une application
√âvaluer le r√©sultat de ses actions
Langue
Anglais
Source: Pole emploi (https://www.pole-emploi.fr)
Show more
Show less","{'ProgLanguage': ['Python', 'Java', 'C++', 'Scala', 'R', 'Go', 'JavaScript'], 'DataBase': ['SQL', 'NoSQL'], 'DataAnalytics': ['R'], 'BigData': ['Hadoop', 'Spark'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': ['Statistiques'], 'CloudComputing': ['AWS', 'Azure'], 'DevTools': [], 'Os': ['Linux'], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Big Data', 'Statistiques', 'Cloud'], 'FrSoftSkills': ['Communication', 'Leadership', 'Collaboration', 'Organisation'], 'EnSoftSkils': ['Communication', 'Leadership', 'Collaboration']}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's', '3', '3', '3']}"
Data Engineer (F/H/X),Goaheadspace,"Pantin, √éle-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-f-h-x-at-goaheadspace-3915359112?position=3&pageNum=10&refId=HRcIsejJK7jV9EjNnax1mg%3D%3D&trackingId=DHbJVvuc2OSbGuvg%2BMNULw%3D%3D&trk=public_jobs_jserp-result_search-card,"MFG Labs est une soci√©t√© de conseil et r√©alisation experte en data, qui aide les entreprises √† am√©liorer leurs prises de d√©cision, √† automatiser leurs processus et √† cr√©er de nouveaux services gr√¢ce √† la data science, au design et √† l'utilisation des derni√®res technologies.
MFG Labs intervient √† toutes les √©tapes de votre transformation data : de la cr√©ation d'une feuille de route de projets data, √† la d√©couverte d'insights, √† la mod√©lisation de probl√©matiques complexes, de la cr√©ation d'un mod√®le pr√©dictif √† l'impl√©mentation technique d'une solution data sur-mesure
MFG Labs accompagne ses clients de diff√©rentes mani√®res :
Strat√©gie
Solutions
Fondations
MFG Labs d√©ploie une approche holistique pluridisciplinaire, en m√™lant des data scientists, des designers, des data engineers et des consultants, afin d'apporter des solutions compl√®tes de bout en bout √† des probl√©matiques complexes.
Dans le cadre du d√©veloppement de l‚Äô√©quipe, nous recherchons un.e Data Engineer √†
Pantin (magasins g√©n√©raux).
Au sein de l‚Äô√©quipe Data Technology, vous aurez pour mission de travailler sur des probl√©matiques de collecte de la donn√©e sur tout type de support digital : web, mobile, application, voire IoT.
Votre r√¥le au sein de l‚Äô√©quipe :
Faire partie d‚Äôune √©quipe pluridisciplinaire avec des talents en Design de Service, Consulting et Data science.
D√©velopper des applications de production int√©grant diff√©rents outils : des Math√©matiques Appliqu√©s, Machine (Deep) Learning, Recherche Op√©rationnelle, Statistiques.
D√©velopper des pipelines de traitement de donn√©es avec l‚Äô√©quipe de Data Science pour : ing√©rer, transformer et d√©livrer des donn√©es et mod√®les √† nos applications.
D√©ployer des applications utilisant les derniers outils mis √† disposition par les diff√©rents Clouds publics.
√Ä propos de vous :
Vous √™tes titulaire d'un niveau Bac +4/Bac +5 d'une √©cole d'ing√©nieur
Vous avez au minimum deux ans d'exp√©rience hors stage ou alternance
Vous √™tes rigoureux¬∑se vis-√†-vis de vous-m√™me et des autres quant √† la qualit√© du code.
Vous avez quelques connaissances et comp√©tences solides en d√©veloppement et en en Data Ing√©nierie au sens large.
En
d√©veloppement
Python 3 et SQL
Framework de traitement de donn√©es (Spark ou √©quivalent)
Docker
GIT
En +
Framework permettant de d√©ployer des APIs (Flask ou √©quivalent)
CI/CD
La pratique d'au moins un cloud (AWS, GCP ou Azure) est appr√©ci√©e
En Data Ing√©nierie
Datawarehouse ou Datalake
Data Pipelines Batch et/ou Straming
En +
Outils de BI (Tableau, Power BI‚Ä¶)
Outils MLOps (Sagemaker, VertexAI, etc.)
Si vous vous reconnaissez dans cette annonce, n'h√©sitez pas √† postuler !
Show more
Show less","{'ProgLanguage': ['Python', 'R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': ['Spark'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': ['Tableau', 'Power BI'], 'Statistics': ['Statistiques'], 'CloudComputing': ['AWS', 'Azure'], 'DevTools': ['Git', 'Docker'], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': ['Docker'], 'Collaboration': [], 'Other': ['ML', 'Statistiques', 'Cloud', 'CI/CD'], 'FrSoftSkills': [], 'EnSoftSkils': []}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's']}"
Ing√©nieur Data Spark (F/H),Thales,"V√©lizy-Villacoublay, √éle-de-France, France",https://fr.linkedin.com/jobs/view/ing%C3%A9nieur-data-spark-f-h-at-thales-3890949531?position=4&pageNum=10&refId=HRcIsejJK7jV9EjNnax1mg%3D%3D&trackingId=KOKvMv%2FEWmd6g5W8%2Fuxusg%3D%3D&trk=public_jobs_jserp-result_search-card,"QUI SOMMES-NOUS ?
Thales est un leader mondial des hautes technologies comptant plus de 81 000 collaborateurs pr√©sents sur tous les continents. Le Groupe investit dans les innovations du num√©rique et de la ¬´ deep tech ¬ª ‚Äì big data, intelligence artificielle, connectivit√©, cybers√©curit√© et quantique ‚Äì pour construire un avenir de confiance, essentiel au d√©veloppement de nos soci√©t√©s, en pla√ßant l‚Äôhumain au c≈ìur des d√©cisions.
Thales propose des solutions, services et produits qui aident ses clients ‚Äì entreprises, organisations, Etats ‚Äì dans cinq grands march√©s vitaux pour le fonctionnement de nos soci√©t√©s : identit√© et s√©curit√© num√©riques, d√©fense, a√©ronautique, espace, et transport.
QUI ETES-VOUS ?
Dipl√¥m√© d‚Äôun Bac+5 en √©cole d‚Äôing√©nieur ou √©quivalent universitaire avec une sp√©cialisation en informatique, vous avez au moins 3 ans d'exp√©rience dans les technologies Big Data.
CE QUE NOUS POUVONS ACCOMPLIR ENSEMBLE :
En tant que Data Engineer, vous jouerez un r√¥le cl√© dans la conception, le d√©veloppement et la maintenance de notre infrastructure de donn√©es, ainsi que dans la transformation et la gestion des flux de donn√©es.
VOS MISSIONS :
‚Ä¢ Concevoir, d√©velopper et d√©ployer des solutions Big Data en utilisant les technologies Spark.
‚Ä¢ Mettre en place des pipelines de donn√©es performants pour l'ingestion, le traitement et le stockage des donn√©es massives.
‚Ä¢ Collaborer √©troitement avec les √©quipes m√©tier pour comprendre leurs besoins en mati√®re d'analyse de donn√©es et proposer des solutions adapt√©es.
‚Ä¢ Optimiser les performances des clusters Hadoop pour garantir une exploitation efficace des donn√©es.
‚Ä¢ Assurer la qualit√© et la fiabilit√© des donn√©es trait√©es, en mettant en place des processus de validation et de nettoyage.
‚Ä¢ Identifier et r√©soudre les probl√®mes li√©s √† l'infrastructure Big Data et proposer des am√©liorations.
‚Ä¢ Travailler en √©troite collaboration avec les Data Scientists et les Data Analysts pour fournir des insights pertinents √† partir des donn√©es.
Innovation, passion, ambition : rejoignez Thales et cr√©ez le monde de demain, d√®s aujourd‚Äôhui.
Show more
Show less","{'ProgLanguage': ['R'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': ['Hadoop', 'Spark'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Big Data'], 'FrSoftSkills': ['Collaboration', 'Organisation'], 'EnSoftSkils': ['Collaboration']}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': ['Bac+5'], 'Experience': ['a', 'n', 's', '3', '3', '3']}"
Data Engineer,Harnham,"Paris, √éle-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-at-harnham-3901400227?position=5&pageNum=10&refId=HRcIsejJK7jV9EjNnax1mg%3D%3D&trackingId=wN4sNzpNxe0wTqIrMNl96Q%3D%3D&trk=public_jobs_jserp-result_search-card,"DATA ENGINEER
LA DEFENSE (92)
56K EUR
Rejoignez une √©quipe en tant que Data Engineer au sein d‚Äôune start-up orient√©e Intelligence Artificiel, et aidez √† fa√ßonner l‚Äôavenir technologique. C‚Äôest votre chance de mettre en pratique vos comp√©tences techniques et de jouer un r√¥le dans le futur du domaine des donn√©es.
VOTRE MISSION :
Concevoir et d√©velopper des pipelines de donn√©es pour assurer la collecte, le traitement, et le stockage efficaces des donn√©es pour comprendre les besoins.
Collaboration avec les √©quipes m√©tiers
Elaborer des processus de validation des donn√©es et mettre en place des tests automatis√©s
Concevoir et impl√©menter des mod√®les de donn√©es
VOTRE PROFIL :
Au moins 6 mois de stage en tant que Data Engineer
Dipl√¥m√© d‚Äôun Master (2 ans minimum)
Maitrise d'un ou plusieurs Clouds Publics (AWS; GCP; Azure)
Maitrise d'outils classiques (Python, Spark, SQL)
Show more
Show less","{'ProgLanguage': ['Python', 'R'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': ['Spark'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': ['AWS', 'Azure'], 'DevTools': [], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Cloud'], 'FrSoftSkills': ['Collaboration'], 'EnSoftSkils': ['Collaboration']}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's', '2', '2', '2']}"
Data Engineer H/F,Amiltone,"Lille, Hauts-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-h-f-at-amiltone-3846492584?position=6&pageNum=10&refId=HRcIsejJK7jV9EjNnax1mg%3D%3D&trackingId=Z88evJjtQR%2FlNLg9ifY3YA%3D%3D&trk=public_jobs_jserp-result_search-card,"Qui sommes-nous ?
Nous sommes passionn√©s par les nouvelles technologies, et vous ?
Rejoindre Amiltone, c‚Äôest int√©grer des √©quipes dynamiques et soud√©es dans le cadre de projets novateurs et ambitieux. Nous relevons les challenges techniques de nos clients et les accompagnons dans leur transformation digitale.
Pourquoi choisir Amiltone‚ÄØ?
Amiltone, plus qu‚Äôune entreprise, un √©tat d‚Äôesprit !
Notre objectif ? Votre √©panouissement professionnel !
Nous Avons √† C≈ìur De
Vous accompagner au mieux au travers d‚Äôun suivi personnalis√©
Vous faire monter en comp√©tences en vous proposant des formations tout au long de votre carri√®re
Comprendre vos besoins et respecter nos engagements
Vous proposer des missions de qualit√© avec des technologies innovantes
Cultiver votre potentiel gr√¢ce √† notre programme de d√©veloppement personnel Addvise
Votre bien-√™tre passe aussi par des activit√©s extraprofessionnelles, c‚Äôest pourquoi nous vous proposons des s√©ances sportives anim√©es par nos coachs, soir√©es pour se retrouver et animations (√† l'agence ou en visio), Gaming nights‚Ä¶
Les Missions D'un Amiltonien
En tant que Data Engineer
(H/F)
, vous serez en charge des missions suivantes :
‚Äì Concevoir et d√©velopper les futures fonctionnalit√©s de la plateforme Big Data sous Google Cloud Platform.
‚Äì Concevoir les flux d'alimentation et les tables (structure de donn√©e).
‚Äì Automatiser et industrialiser les flux.
‚Äì Assurer le run applicatif, le cas √©ch√©ant.
La Stack Technique
Ma√Ætrise des langages suivants : SQL, Talend, BigQuery
Connaissances de Google (GCP)
Notion de programmation fonctionnelle
Le Profil D‚Äôun Amiltonien
Dipl√¥m√© Bac+4/5 (Ecole d'ing√©nieur/Master), vous disposez de 2 ann√©es d'exp√©rience dans le d√©veloppement de data.
Toujours sur le qui-vive des nouveaut√©s technologiques, vous √™tes force de proposition sur des technos, des outils ou des process qui permettent d'am√©liorer la qualit√© du code et la stabilit√© de nos applications.
Outre vos comp√©tences techniques, nous nous int√©ressons √©galement √† votre potentiel et votre motivation.
Nos postes sont ouverts aux personnes en situation de handicap.
Postuler
Show more
Show less","{'ProgLanguage': ['R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': ['Google Cloud Platform'], 'DevTools': ['Git'], 'Os': [], 'DBMS': ['BigQuery'], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Big Data', 'Cloud'], 'FrSoftSkills': [], 'EnSoftSkils': []}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's']}"
Data Engineer F/H,METEOJOB by CleverConnect,"Chassieu, Auvergne-Rh√¥ne-Alpes, France",https://fr.linkedin.com/jobs/view/data-engineer-f-h-at-meteojob-by-cleverconnect-3899961883?position=7&pageNum=10&refId=HRcIsejJK7jV9EjNnax1mg%3D%3D&trackingId=d0mkfeGcuvE%2BEVN40N%2B5sQ%3D%3D&trk=public_jobs_jserp-result_search-card,"Entreprise
Cabinet de recrutement de dimension internationale, b√©n√©ficiant de l'exp√©rience d'un grand Groupe RH, S&you est sp√©cialis√© dans le recrutement d'Experts, Cadres et M√©tiers du tertiaire. Nos 50 consultants exp√©riment√©s mettent en ≈ìuvre tout notre savoir-faire pour vous accompagner au mieux dans vos projets (recrutement, bilan professionnel, coaching, formation‚Ä¶). La relation de confiance que nous cr√©ons avec nos candidats et nos clients repr√©sente pour nous le facteur-cl√© de la performance.
Description Du Poste
Titulaire d'u BTS/Licence en Management des organisations/Gestion des SIExp√©rience en maintenance des donn√©es de base de SAP de 2ans minimumGestion des priorit√©s - Organisation Rigueur Fiabilit√©Communicant - Aisance relationnelle Capacit√© d'√©coute A l'aise dans l'√©change t√©l√©phoniqueCollectif - Travail d'√©quipe et partage d'informationsAnglais
Description Du Profil
Leader mondial de la distribution de produits chimiques industriels et de sp√©cialit√©sGroupe international, pr√©sent dans 74 pays, 15 000 collaborateurs,Solutions compl√®tes et personnalis√©es (produits et services) dans le domaine de la chimie. Un r√©seau de vente et de commercialisation de proximit√© : 700 collaborateurs et 15 sites en France.
Show more
Show less","{'ProgLanguage': ['R'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': [], 'FrSoftSkills': [""Travail d'√©quipe"", 'Organisation'], 'EnSoftSkils': []}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's', '2', '2', '2']}"
Consultant Data Engineer,WHIZE,"Neuilly-sur-Seine, √éle-de-France, France",https://fr.linkedin.com/jobs/view/consultant-data-engineer-at-whize-3907486262?position=8&pageNum=10&refId=HRcIsejJK7jV9EjNnax1mg%3D%3D&trackingId=BpPPQnoBOzIBq7GyjlOP0Q%3D%3D&trk=public_jobs_jserp-result_search-card,"Offre d‚Äôemploi pour un CDI : Consultant Data Engineer
WHIZE est sp√©cialis√©e dans le d√©veloppement de solutions sur mesure en architecture Serverless (Azure, Amazon WS, Google CP) et de solutions bas√©es sur l'√©cosyst√®me Microsoft 365 (SharePoint, Teams, Power Platform).
Vos missions :
Concevoir des solutions de traitement de volume tr√®s important de donn√©es.
D√©veloppement de flux de donn√©es et pr√©paration de leur analyse.
Pr√©paration des donn√©es pour l'analyse des donn√©es collect√©es.
Profil recherch√© :
2 ans minimum d‚Äôexp√©rience.
Ma√Ætrise du langage Python et Scala
Connaissance d'un ou plusieurs ETL du march√© (Talent , SSIS, Azure Data Factory, ...)
Forte expertise en SQL
√ätre √† l‚Äôaise avec un ou plusieurs outils Devops (Jenkins, git, GitHub, gitlab, docker, kubernetes, etc‚Ä¶)
Connaissances appr√©ci√©es :
Hadoop, Spark, Kafka
Connaissance des syst√®mes NoSQL : Elasticsearch, HBase, Cassandra, Redshift
Connaissance de l'offre data d'un des providers Cloud (GCP, Azure, AWS)
Qu‚Äôattendez vous pour nous rejoindre ?
Vous ferez partie d‚Äôune soci√©t√© √† taille humaine et qui b√©n√©ficie des avantages d'un grand groupe. Nous adressons une centaine de clients en direct dont la moiti√© sont des grands comptes.
Vous serez accompagn√©(e) et manag√©(e) par le CEO de WHIZE (THE WHIZE MAN).
Vous allez compl√©ter notre √©quipe dynamique et travailler avec nous dans une ambiance Start-up et conviviale.
Vous occuperez des postes int√©ressants et √©volutifs.
Vous b√©n√©ficierez des √©v√®nements internes organis√©s pour parler tech, business et projets.
Vous r√©aliserez des projets √† forte valeur ajout√©e.
üìç : Neuilly-Sur-Seine+ T√©l√©travail
Show more
Show less","{'ProgLanguage': ['Python', 'Scala', 'R', 'Go'], 'DataBase': ['SQL', 'NoSQL', 'Cassandra', 'HBase', 'Elasticsearch'], 'DataAnalytics': ['R'], 'BigData': ['Hadoop', 'Spark'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': ['AWS', 'Azure'], 'DevTools': ['Git', 'Docker', 'Jenkins'], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': ['HBase'], 'Automation': ['Kubernetes'], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': ['Docker', 'Kubernetes'], 'Collaboration': ['Teams'], 'Other': ['DevOps', 'Cloud'], 'FrSoftSkills': [], 'EnSoftSkils': []}","{'JobDetail': [], 'TypeContract': ['CDI'], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's', '2', '2', '2']}"
Data Engineer,Pictarine,"Toulouse, Occitanie, France",https://fr.linkedin.com/jobs/view/data-engineer-at-pictarine-3911913926?position=9&pageNum=10&refId=HRcIsejJK7jV9EjNnax1mg%3D%3D&trackingId=DxQ%2B1qOzrBDlMQeznOUung%3D%3D&trk=public_jobs_jserp-result_search-card,"Mission and challenges üéØ
Si tu es enthousiaste √† embarquer dans la nouvelle √©quipe data de Pictarine pour la faire rayonner avec tout ton savoir-faire, alors c‚Äôest l‚Äôaventure qu‚Äôil te faut! üèîÔ∏è
Avec plus de 1K tables, 2M de clients et 4M de commandes en 2022, les √©quipes de Pictarine ne sont jamais √† court d‚Äôid√©es pour explorer de nouveaux horizons. üöÄ
En tant que Data Engineer chez Pictarine tu vas pouvoir utiliser toutes tes comp√©tences SQL pour garantir la qualit√© de la data sur GCP, accompagner et challenger les besoins data.
Tu √©volueras au sein de l‚Äô√©quipe Engineering, compos√©e des p√¥les dev & data.
Ton r√¥le comprendra les aspects suivants üëáüèª
Tu es garant de la qualit√© de la data !
En simplifiant la structure de la data et r√©duisant le nombre de tables
En transformant les donn√©es pour les rendre facilement utilisables
En orchestrant le flux des donn√©es de mani√®re continue et automatique
Tu accompagnes et challenges les √©quipes de Pictarine !
En co-construisant des solutions data appropri√©es
En √©levant le niveau de jeu des m√©thodes data existantes
En faisant rayonner la data autour de bonnes pratiques et d‚Äôoutillages ad√©quates
Profil Recherch√©
About you üíé
Tu as au moins 5 ans d‚Äôexp√©rience sur un poste similaire
Tu ma√Ætrises le data warehouse BigQuery et son langage SQL
Tu es √† l'aise avec les services GCP
Tu as de bonnes connaissances dans la conception de mod√®les de donn√©es et les strat√©gies d'optimisation des requ√™tes SQL
Tu as des comp√©tences en DevOps pour le d√©ploiement et la gestion efficace des pipelines de donn√©es
Tu as une bonne ma√Ætrise de Python & Github
Tu es organis√©, rigoureux et portes une grande attention aux d√©tails
Tu es dot√© d‚Äôexcellentes qualit√©s relationnelles, de communication et de vulgarisation
Tu as une passion pour r√©soudre des probl√®mes business avec la programmation
Tu es curieux de tester des nouvelles technologies
Tu es un team player et toujours √† l'aff√ªt de nouvelles id√©es
Work @ Pictarine‚ú®
Un environnement de travail agile, collaboratif, international et multiculturel
Des perspectives d‚Äô√©volution rapides
Des locaux tout beaux √† Lab√®ge avec du mat√©riel dernier cri (mais aussi des snacks √† profusion et un frigo √† boissons toujours bien rempli)
Un apprentissage permanent : conf√©rence, meet-up, Pictarine Academy, cours d‚Äôanglais.
Des events tous les mois : massage, pilates, TGIF, team building .
Un environnement de travail flexible : horaires, politique de remote hybride.
Un package de r√©mun√©ration attractif : salaire comp√©titif, RTT, mutuelle & pr√©voyance 100% prise en charge, int√©ressement.
Des petits + : D√©veloppement de photos gratuit, subvention sport, 3 jours ‚Äúentraide familiale‚Äù, jours de cong√©s en plus avec l'anciennet√©... ü§´ on ne te d√©voile pas tout !
Recruitment process ‚öôÔ∏è
Tu souhaites nous rejoindre ? Viens rencontrer les gens avec qui tu vas bosser :
1er √©change pour apprendre √† se conna√Ætre avec Marie - Engineering Manager Data (15‚Äô)
Entretien Manager avec Marie (60-90‚Äô)
Test pratique afin de nous montrer tes talents üôÇ (3 heures)
Entretien final avec 2 membres du Codir (90‚Äô)
Welcome aboard !
Show more
Show less","{'ProgLanguage': ['Python', 'R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git'], 'Os': [], 'DBMS': ['BigQuery'], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['DevOps'], 'FrSoftSkills': ['Communication'], 'EnSoftSkils': ['Communication']}","{'JobDetail': ['Hybride', 'Remote'], 'TypeContract': [], 'Salary': ['100', '100'], 'Level': [], 'Experience': ['a', 'n', 's', '5', '5', '5']}"
Data Engineer & Analyst - Paris - F/H/X - CDI,Partoo,"Paris, √éle-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-analyst-paris-f-h-x-cdi-at-partoo-3892387658?position=10&pageNum=10&refId=HRcIsejJK7jV9EjNnax1mg%3D%3D&trackingId=635c5xyg%2BPtkrIMGv0yEMw%3D%3D&trk=public_jobs_jserp-result_search-card,"Partoo, who are we? üëÄ
Partoo est une scale-up saas B2B qui a √† c≈ìur d‚Äôaider les commerces locaux, grandes entreprises ou PME √† se rapprocher de leurs clients. Pour cela, ils ont d√©velopp√© une plateforme tout-en-un et diff√©rentes solutions qui s‚Äôarticulent autour de 3 propositions de valeur : Get found, Get chosen & Get clients.
√Ä travers ces 3 propositions, ils ont d√©velopp√© plusieurs produits qui s‚Äôadaptent aux √©volutions du parcours d‚Äôachat des clients :
üîé Get found
Presence: Synchroniser les informations des magasins sur les principales plateformes (Google, Facebook, Waze, etc.), annuaires et GPS
Store Locator: Aider les clients √† trouver le magasin qui leur convient gr√¢ce √† des donn√©es locales actualis√©es et des filtres d√©di√©s sur les sites web des enseignes
R√©seaux sociaux: G√©rer les publications sur Facebook, Google, Instagram, etc
üéØ Get chosen
Review: Centraliser, r√©pondre et analyser les avis clients re√ßus sur Google et Facebook
Booster: Obtenir des avis positifs suppl√©mentaires sur Google par le biais de SMS et de QR codes
ü§ó Get clients
Messages: Centraliser et r√©pondre √† tous les messages de chat re√ßus via Google Business Messages, Messenger et bient√¥t aussi via Instagram, whatsapp, etc. (templates messages, conversations starter, appels manqu√©s...)
Quelques chiffres üóùÔ∏è
> Un label Happy at Work et l'une des meilleures notes Glassdoor de l'√©cosyst√®me avec 4.6/5 pour plus de 260 avis‚≠êÔ∏è‚≠êÔ∏è‚≠êÔ∏è‚≠êÔ∏è‚≠êÔ∏è Ô∏èÔ∏èÔ∏èÔ∏èÔ∏èÔ∏è
> 450+ employ√©s heureux, 37 nationalit√©s diff√©rentes, des bureaux √† Paris et Barcelone üöÄ
> Ils g√®rent 300 000 points de vente et travaillent de mani√®re transversale avec +1000 cha√Ænes (Carrefour, Generali, Toyota, D√©cathlon, Leroy Merlin etc.) et +6000 pme dans environ 150 pays
Notre m√©mo 2024: le mot du CEO (https://www.partoo.co/fr/blog/memo-2024/)
IMPACT üí•
Partoo compte aujourd‚Äôhui pas moins de 400 collaborateurs, qui ≈ìuvrent au quotidien √† maintenir une croissance saine, en phase avec les enjeux et challenges √©conomiques du moment.
Une des composantes clefs pour y parvenir r√©side en notre capacit√© √† d√©velopper et maintenir un haut niveau d‚Äôefficacit√© op√©rationnelle. Dans cette logique, am√©liorer notre capacit√© √† exploiter et utiliser la donn√©e pr√©sente dans nos syst√®mes est indispensable. Si nous avons d√©j√† une √©quipe Data en place, celle-ci est aujourd‚Äôhui mobilis√©e presque exclusivement sur les th√©matiques data relatives au fonctionnement de notre application ainsi qu‚Äô√† la construction d‚Äô√©l√©ments de visibilit√© pour nos clients.
Nous souhaitons donc recruter un Data Engineer & Analyst dont l‚Äôobjectif principal sera de permettre aux √©quipes Op√©rations et client-facing de visibiliser et tirer le meilleur parti d‚Äôune donn√©e aujourd‚Äôhui difficile d‚Äôacc√®s.
Manager : Adel Adman (cc. Cl√©ment Bouillaud, en charge de la team Operations)
TEAM üíô
Meetings r√©current avec les membres de Partoo :
Membre √† part enti√®re de l‚Äô√©quipe Data (elle-m√™me int√©gr√©e dans l‚Äô√©quipe Produit), tu seras n√©anmoins en contact r√©gulier avec les √©quipes Op√©rations, qui seront tes principales interlocutrices.
En d‚Äôautres termes, tu seras le pilier central entre les √©quipes Ops et Data.
Dans un premier temps, tu auras un meeting hebdomadaire avec Adel (Lead Data) et avec Cl√©ment (COO), le temps de cadrer tes premi√®res priorit√©s et de trouver la bonne r√©currence de rencontre avec les √©quipes Op√©rations.
MISSIONS üî•
Ton principal objectif consiste √† faire en sorte que chaque personne, des √©quipes Op√©rations comme des √©quipes client-facing, ait acc√®s √† la donn√©e dont elle a besoin, au moment o√π elle en a besoin, sur le support le plus ad√©quat. Pour y parvenir, plusieurs missions seront tiennes :
Architecture
:
Cr√©er des architectures de donn√©es robustes et √©volutives pour collecter, stocker et analyser de grandes quantit√©s de donn√©es provenant de diverses sources (Salesforce, Intercom, Chargebee, back office de Partoo, etc.)
Analyser et am√©liorer continuellement le mod√®le de donn√©es Salesforce (SF), en accompagnant l'√©quipe Ops dans le monitoring des anomalies et l'optimisation des performances
Int√©grations et flux
:
D√©velopper et optimiser des pipelines de donn√©es, assurant l'int√©gration fluide des donn√©es dans notre Data Warehouse depuis diff√©rentes sources, et inversement
Transformation & analyse
:
Concevoir et ex√©cuter des requ√™tes SQL complexes pour l'analyse de donn√©es, permettant de soutenir les d√©cisions business
Identifier et construire des KPI cruciaux, fournissant des insights pr√©cieux aux √©quipes business
Visualisation
:
Fournir aux √©quipes Ops et client-facing des outils de visualisation de donn√©es (Looker Studio, embedding, etc.), cl√©s dans l'optimisation de notre gestion de client√®le.
Formation
:
Former les √©quipes Op√©rations sur l‚Äôexploitation des tables de notre Datawarehouse ainsi que sur l‚Äôusage de Looker Studio et propager les principales best practices associ√©es. Tout √ßa, en collaboration au quotidien avec les √©quipes Ops !
DESIRED PROFILE üéØ
Comp√©tences recherch√©es :
Une tr√®s bonne connaissance du langage SQL, notamment PostgreSQL et BigQuery.
Ma√Ætrise du scripting Python et des notebooks pour l'analyse de donn√©es
D‚Äôexcellentes capacit√©s d'analyse pour comprendre les besoins business, identifier les anomalies dans les donn√©es et proposer des am√©liorations pertinentes
Une bonne aptitude √† manipuler et analyser de grands ensembles de donn√©es et en extraire des insights actionnables
Une tr√®s bonne ma√Ætrise d'au moins un outil de business intelligence tel que Looker Studio, PowerBI ou Tableau
Profils recherch√© :
Tu as plus de 3 ans d'exp√©rience en Data Engineering /Advanced Data Analysis
Tu ma√Ætrises les stacks de data les plus r√©centes (dbt, Airflow, Airbyte, etc.) et les meilleures pratiques en mati√®re de donn√©es (ETL, reverse-ETL, etc.)
Tu es orient√©(e) utilisateur et sais convertir les besoins commerciaux en solutions techniques
Tu sais communiquer avec les √©quipes et t'assurer que les meilleures pratiques sont adopt√©es
Tu es un team player !
Tu souhaites apprendre et grandir avec nous
RECRUITMENT PROCESS üõ†Ô∏è
A first video call with Marine, Talent Acquisition Specialist, 45 min
Interview with Adel, Lead Data Engineer, 1h
Case Study
Interview with Cl√©ment, Chief Operations Officer, 1h
√Ä comp√©tences √©gales, ce poste est ouvert aux travailleurs et travailleuses en situation de handicap ou assimil√©s au sens de l‚Äôarticle L5212-13 du Code du travail. Partoo s‚Äôengage en faveur de la diversit√©, l‚Äô√©galit√© professionnelle, l‚Äôemploi des travailleurs handicap√©s.
With equal skills, this position is open to disabled workers or those considered to be disabled within the meaning of Article L5212-13 of the French Labour Code. Partoo is committed to diversity, professional equality and the employment of disabled workers.
Show more
Show less","{'ProgLanguage': ['Python', 'R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': ['Tableau', 'PowerBI'], 'Statistics': [], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'DBMS': ['PostgreSQL', 'BigQuery'], 'SoftBigDataProcessing': [], 'Automation': ['Airflow'], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': [], 'FrSoftSkills': ['Collaboration'], 'EnSoftSkils': ['Collaboration']}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's', '3', '3', '3']}"
DATA Engineer GCP F/H,SOFTEAM,"√éle-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-gcp-f-h-at-softeam-3852605158?position=1&pageNum=12&refId=i1uQoaWCgdgsEjOn6HkbXA%3D%3D&trackingId=OCPLFEp6cHnUuz3d6XseAw%3D%3D&trk=public_jobs_jserp-result_search-card,"Vous √©voluez dans le domaine de la
Data
et souhaitez int√©grer un leader de la transformation num√©rique sp√©cialis√© dans les secteurs de la
Banque, du Luxe, de l'Assurance, de la Finance, de l'Energie
et la possibilit√© d'√©voluer au sein du Groupe
Docaposte
!
Softeam
est labellis√© ""
HappyIndex¬Æ AtWork
"" 2022 pour la
5√®me
ann√©e cons√©cutive !
Nos collaborateurs travaillent en ¬´
mode projet
¬ª autour des
Modern DATA Platform
‚òÅ et
technologies Big Data Azure Cloud / On premise
et autre ""playeur"" du march√©. Nous accompagnons de bout en bout nos clients sur des probl√©matiques de
Gouvernance, d‚ÄôInt√©gration, de Visualisation et d‚ÄôIA
.
CE QUE NOUS RECHERCHONS
SOFTEAM Data
recherche un(e)
Data Engineer Cloud GCP
, disposant de solides connaissances techniques.
CE QUE NOUS ATTENDONS DE VOUS
En tant que
Data Engineer Cloud GCP
, vous concevez, mettez en place et administrez
des clusters et des solutions big data
.
Vos missions d√©taill√©es :
A
comprendre le besoin de nos clients
au travers de missions de type : aide aux choix d‚Äôoutils, cadrage des besoins, POC ;
Recueillir et analyser les besoins et proposer une architecture technique
adapt√©e aux cas d‚Äôusage des clients ;
Conduire des projets de
d√©ploiement des Modern Data Platform
(Applications Cloud Native, Migration d‚Äôapplications existantes) et participer √† la mise en ≈ìuvre ;
D√©velopper et maintenir des cas d‚Äôusages clients avec
les outils et les infrastructures Big Data / Cloud GCP. Mod√©liser et analyser des donn√©es dans le Cloud
. Garantir la s√©curit√© / compliance des donn√©es ;
Fournir une expertise technique approfondie
aux √©quipes projets ;
R√©diger
la documentation permettant √† l'IT d'assurer la maintenance.
VOUS ETES
Ing√©nieur(e) de formation
, vous disposez d'une exp√©rience de
3 ans
minimum en tant que
Data Engineer
.
Vous avez un minimum de
4
ann√©es d‚Äôexp√©rience sur des
projets Data et id√©alement au moins une premi√®re exp√©rience sur des projets Cloud GCP
(Compute, Stockage), ou √† d√©faut une certification GCP avec l‚Äôambition de vous pr√©parer √† d‚Äôautres.
Vous ma√Ætrisez au minimum
un langage de programmation
(Spark, Scala, Python, Java, R) ;
Vous avez une grande aisance dans la
communication orale et √©crite
alli√©e √† un esprit de synth√®se, de la rigueur et un tr√®s bon sens de la formalisation ;
Fournir une expertise technique
approfondie aux √©quipes projets ;
R√©aliser une veille technologique
permanente sur les tendances du march√© et les perspectives concurrentielles.
NOUS VOUS OFFRONS
Des
missions engageantes
aupr√®s des
grands acteurs du march√©
.
Un
management de proximit√©
avec Gilles SALVADOR, Directeur du Centre d'Expertise Data, toujours bienveillant et √† l'√©coute et avec qui vous pourrez
√©changer au quotidien
sur les
enjeux de votre mission
et √©voquer vos
futurs projets
afin que nous puissions vous aider √† les r√©aliser.
La
possibilit√© d‚Äô√©voluer
et de
monter en comp√©tences
gr√¢ce √† des
formations et √† des certifications
aupr√®s de nos clients et de nos consultants, des 12@13, notre Entit√© Softeam Institute, Organisme de formation interne de renomm√© qui d√©livre des formations aupr√®s de nos clients...
QUI SOMMES-NOUS ?
SOFTEAM DATA
est une marque de
DOCAPOSTE
sp√©cialis√©e dans
l'informatique d√©cisionnelle
et les
nouvelles technologies
. Nous apportons notre expertise √† nos clients, principalement
des Grands Comptes
de la place
financi√®re fran√ßaise
, dans des projets de transformation digitale et cognitive.
2000 Softeamien.nes sont d√©di√©.es √† la transformation m√©tier et digitale de nos clients et ont g√©n√©r√©
200 M‚Ç¨ de chiffre d‚Äôaffaires
en 2020.
SOFTEAM SPIRIT
Des
communaut√©s d'expertises
sur les sujets de la
Data
;
De super
nouveaux locaux
qui sont en plus accessibles facilement ;
Une
√©cole de formation
int√©gr√©e ;
Des
√©v√®nements
: des soir√©es avec les consultants, des 12@13... ;
Une entreprise labellis√©e
""Happy at Work""
pour la 5√®me ann√©e cons√©cutive.
N‚Äôattendez plus, rejoignez SOFTEAM et venez nous rencontrer dans nos nouveaux locaux situ√©s √† la D√©fense #DevenezSofteamien !
Show more
Show less","{'ProgLanguage': ['Python', 'Java', 'Scala', 'R', 'Go'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': ['Spark'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': ['Azure'], 'DevTools': ['Git'], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Big Data', 'Cloud'], 'FrSoftSkills': ['Communication'], 'EnSoftSkils': ['Communication']}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's', '3', '3', '3']}"
Data engineer F/H,DOCAPOSTE,"Lyon, Auvergne-Rh√¥ne-Alpes, France",https://fr.linkedin.com/jobs/view/data-engineer-f-h-at-docaposte-3879674310?position=2&pageNum=12&refId=i1uQoaWCgdgsEjOn6HkbXA%3D%3D&trackingId=tNIA3zNJaorwrKqWNrfZWQ%3D%3D&trk=public_jobs_jserp-result_search-card,"Intitul√© du poste
Data engineer F/H
Contrat
CDI
T√©l√©travail
Oui
Description de la mission
Au sein du p√¥le, vous avez la charge de manipuler les donn√©es de la plus grosse base de donn√©es m√©dicale du monde, transmises par l'Assurance Maladie. Votre mission est de pr√©parer et de mettre √† disposition les donn√©es pour les diff√©rents acteurs de l'entreprise. Vous industrialisez les flux de donn√©es de centaines de milliers de patients, pour les suivre sur une dizaine d'ann√©es et rep√©rer certains √©v√©nements de leur prise en charge. Ainsi, les analyses pourront mettre en √©vidence les diff√©rents cycles des parcours de soin. Ce travail collaboratif se d√©roule en mode projet pluridisciplinaire.
Ainsi vous devez :
√Ä partir de bases de donn√©es complexes et volumineuses, r√©aliser les op√©rations de contr√¥le d'int√©grit√©, d'extraction, de nettoyage, et programmer leurs automatisations pour constitution des bases de donn√©es d'√©tudes
Coder des algorithmes sp√©cifiques de s√©lection de soins (hospitalisations, d√©livrance de m√©dicaments, consultations ‚Ä¶) et de s√©quences de traitement en utilisant toutes les particularit√©s des donn√©es,
R√©aliser des jointures complexes entre les diff√©rentes tables de donn√©es,
Optimiser les temps de traitement et de l'espace de stockage : millions de patients sur des T√©ra de donn√©es, en automatisant au maximum les op√©rations de traitement,
Travailler en mode collaboratif pour la r√©daction de macros/fonctions g√©n√©riques pour que votre travail puisse servir √† toute l'√©quipe,
Votre nouvel environnement
Filiale du groupe DOCAPOSTE SANTE, nous sommes leader en France dans le traitement et l‚Äôanalyse des donn√©es de sant√© en vie r√©elle, et plus particuli√®rement celles issues des bases du Syst√®me National des Donn√©es de Sant√© (SNDS) et des bases en OPEN DATA. Nous √©laborons et produisons pour nos clients (industries pharmaceutiques, fabricants de dispositifs m√©dicaux, institutionnels) des √©tudes pharmaco-√©pid√©miologiques, m√©dico-√©conomiques et de parcours de soins √† partir de solides m√©thodes statistiques et de solutions innovantes s'appuyant sur l'Intelligence Artificielle (Machine Learning, Deep Learning, ‚Ä¶).
2jours de T√©l√©travail
Nous vous accompagnons
Un programme de formation et d'accompagnement est pr√©vu en fonction de vos comp√©tences pr√©c√©demment acquises et de votre exp√©riences
Localisation du poste
Europe, France, Auvergne-Rh√¥ne-Alpes, Rh√¥ne (69)
Lieu
Niveau d'√©tudes min. requis
Dipl√¥me
Niveau d'exp√©rience min. requis
Langues
Profil : Pour l‚Äô√©galit√© des chances, Docaposte fait vivre la diversit√©. Nos postes sont ouverts √† tous.
LYON
Crit√®res candidat
Profil : Pour l‚Äô√©galit√© des chances, Docaposte fait vivre la diversit√©. Nos postes sont ouverts √† tous.
Rigueur
manipulation de donn√©es de sant√©
Analytique
Donn√©es riches et complexes
R√©f√©rence
2023-4471D
Entit√© qui recrute
HEVA
Show more
Show less","{'ProgLanguage': ['R', 'Go'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': ['Statistiques'], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Machine Learning', 'Statistiques'], 'FrSoftSkills': [], 'EnSoftSkils': []}","{'JobDetail': [], 'TypeContract': ['CDI'], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's']}"
Data Engineer Senior H/F,HARDIS GROUP,"√éle-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-senior-h-f-at-hardis-group-3914403221?position=3&pageNum=12&refId=i1uQoaWCgdgsEjOn6HkbXA%3D%3D&trackingId=Hsh7TRaHQ7Ph0DtzJdvbPQ%3D%3D&trk=public_jobs_jserp-result_search-card,"GCP, Python, Data Pipeline, MicroServices, CI/CD, Machine learning, ces mots vous parlent, alors lisez la suite !
MISSION
Au sein de notre entit√© Business Applications parisienne et int√©gr√©(e) au sein d‚Äôune √©quipe projet, vous contribuez √† l‚Äô√©laboration et l‚Äô√©volution des couches m√©tiers des applications que nous r√©alisons pour nos clients.
En tant que
Data Engineer Senior (H/F)
, vous participez √† des projets innovants √† forte valeur ajout√©e pour nos clients, √† la fois technologique et m√©tier. Entour√©(e) de d√©veloppeurs, lead d√©veloppeur, architecte et Scrum master, vous travaillez en m√©thode agile (Scrum).
Notre vision du Cloud Data Engineer :
- Vous √™tes capable d‚Äôappr√©hender un contexte client et d‚Äôimpl√©menter une plateforme pour valoriser sa donn√©e.
- Vous avez d√©j√† une exp√©rience sur GCP ou AWS.
- Vous √™tes √† l‚Äôaise sur l‚Äôun des langages suivants (Python, Java, JavaScript).
- Vous avez d√©j√† utilis√© un framework de calculs distribu√© (Spark, Beam, ‚Ä¶).
- Vous connaissez et utilisez les diff√©rentes solutions de stockage (SQL, NoSQL, Search Engine...).
- Vous maitrisez les principes du d√©veloppement Cloud.
- Vous avez des connaissances en machine learning.
PROFIL
De formation Bac + 5, issu(e) d‚Äôune √©cole d‚Äôing√©nieur ou √©quivalent, vous justifiez d‚Äôau moins 7 ans d'exp√©rience professionnelle r√©ussie dans les domaines de la Data/GCP en contexte agile.
Vous √™tes √† l‚Äôaise avec un ou plusieurs des sujets suivants :
Python, Java, JavaScript, GCP, AWS, Spark, Beam, Kafka, Airflow, ELK.
Vous √™tes √† la fois autonome et force de proposition. Vous aimez partager vos connaissances et souhaitez √©voluer au sein d‚Äôune √©quipe technophile et riche en expertises. Vous √™tes organis√©(e), m√©thodique et avez une excellente capacit√© d‚Äôanalyse. La curiosit√©, l‚Äôesprit d‚Äô√©quipe et la bonne humeur sont indispensables pour int√©grer l‚Äô√©quipe Business Applications Paris.
A propos de Hardis Group
Soci√©t√© de conseil et de services IT, int√©grateur Salesforce et √©diteur de logiciels pour la logistique, Hardis Group s‚Äôest donn√© pour mission d‚Äôacc√©l√©rer la transformation du commerce, de la supply chain et des syst√®mes d‚Äôinformation, notamment gr√¢ce aux technologies cloud.
Ses 1500 collaborateurs accompagnent les transformations strat√©giques, organisationnelles et technologiques des entreprises, partout en Europe, afin de d√©velopper leur comp√©titivit√©, leur productivit√© et leur attractivit√©.
L‚Äôentreprise articule sa strat√©gie RSE autour de trois piliers : la r√©duction de l‚Äôempreinte environnementale de ses activit√©s et de celles de ses clients, la diversit√© et l‚Äô√©galit√© des chances ainsi que l‚Äôinsertion par l‚Äô√©ducation.
Hardis Group a r√©alis√© un chiffre d‚Äôaffaires de 132,7 millions d‚Äôeuros en 2021. La soci√©t√© est implant√©e √† Grenoble (si√®ge social), Paris, Lyon, Lille, Nantes, Bordeaux, Madrid, Utrecht et Varsovie.
www.hardis-group.com
www.reflex-logistics.comdu
Show more
Show less","{'ProgLanguage': ['Python', 'Java', 'R', 'JavaScript'], 'DataBase': ['SQL', 'NoSQL'], 'DataAnalytics': ['R'], 'BigData': ['Spark'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': ['AWS'], 'DevTools': [], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': ['Airflow'], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Machine Learning', 'Cloud', 'CI/CD'], 'FrSoftSkills': ['Organisation'], 'EnSoftSkils': []}","{'JobDetail': ['Senior'], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's', '7', '7', '7']}"
Analytics Engineer - Data Platform,"Yotta - Expert en recrutement Data, AI & Marketing","Paris, √éle-de-France, France",https://fr.linkedin.com/jobs/view/analytics-engineer-data-platform-at-yotta-expert-en-recrutement-data-ai-marketing-3911767667?position=4&pageNum=12&refId=i1uQoaWCgdgsEjOn6HkbXA%3D%3D&trackingId=DUhjb0tdZV1ahZ%2FY6k4VuA%3D%3D&trk=public_jobs_jserp-result_search-card,"Analytics Engineer - Data Platform
70K √† 75K‚Ç¨
Paris, France
Cette soci√©t√© sp√©cialis√©e en Data construit des Plateformes Data pour ses clients avec notamment une approche et des technologies Data modernes.
Elle accompagne notamment des clients sur la construction de leurs architectures et leurs plateformes data.
En forte croissance, elle recherche √† consolider son √©quipe Data en recrutant un profil Analytics Engineer ayant une belle exp√©rience et pouvant apporter son expertise sur la partie Data & Analytics.
Au sein d‚Äôune √©quipe Data et rattach√© directement au Directeur Data vous travaillerez sur la mise en place de Modern Data Stack et des architectures Data complexes.
Le r√¥le :
Vous travaillerez sur la mise en place de Modern Data Stack
Vous travaillerez sur la partie mod√©lisation et traitement de donn√©es (Python, Dbt‚Ä¶)
Mise en place de flux et de pipeline de donn√©es dans des environnements Cloud (Snowflake, BigQuery‚Ä¶)
Vous mettrez en place toute la partie ETL / ELT
Vous serez r√©f√©rent sur tous les sujets Data & Analytics.
Vous pourrez apporter votre expertise et encadrer des profils Data & Analytics Engineer.
Vous travaillerez sur la mise en place d‚Äôarchitectures et d‚Äôinfrastructures c√¥t√© Data
Vous travaillerez sur la partie Data Visualisation (Looker, Data Studio)
Le profil :
Dipl√¥m√©(e) d‚Äôune √©cole d‚Äôing√©nieur ou d‚Äôinformatique
Vous avez une premi√®re exp√©rience r√©ussie en tant qu‚ÄôAnalytics Engineer ou Data Engineer.
Vous ma√Ætrisez Python, SQL
Vous avez une belle exp√©rience sur des technos comme Snowflake et BigQuery
Vous avez une forte app√©tence analytics et business
Vous avez une expertise dans le traitement de donn√©es
Vous avez d√©j√† √©volu√© dans un environnement Cloud, id√©alement Azure ou GCP.
Curieux et force de proposition
Show more
Show less","{'ProgLanguage': ['Python', 'R'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': ['Azure'], 'DevTools': [], 'Os': [], 'DBMS': ['Snowflake', 'Snowflake', 'BigQuery'], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Cloud'], 'FrSoftSkills': [], 'EnSoftSkils': []}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's']}"
"Data Engineer ‚Äì Antibes, France (H/F)",Astek,"Antibes, Provence-Alpes-C√¥te d'Azur, France",https://fr.linkedin.com/jobs/view/data-engineer-%E2%80%93-antibes-france-h-f-at-astek-3909192086?position=5&pageNum=12&refId=i1uQoaWCgdgsEjOn6HkbXA%3D%3D&trackingId=2n0iCg5u%2BtPts3c9AwBHzQ%3D%3D&trk=public_jobs_jserp-result_search-card,"CDI
Antibes - France
Publi√©e il y a 2 semaines
Le Groupe Astek
Ce Que Nous Allons Accomplir Ensemble :
Intervenir dans la conception, le d√©veloppement, les tests unitaires, la qualification, l‚Äôint√©gration continue et la mise en production d‚Äô√©volutions sur les projets du p√¥le produits scoring (un p√¥le visant √† d√©velopper des solutions permettant de g√©n√©rer des scores ou des segments d‚Äôinformation pertinents dans divers domaines, notamment : profiling TV, PUB, SAB, MMDM, Voscastview) chez l‚Äôun de nos partenaires sp√©cialis√© dans le secteur des t√©l√©coms.
Votre Mission, Si Vous L‚Äôacceptez :
En collaboration avec les autres membres de l‚Äô√©quipe, vous devrez prendre en charge le RUN des applications du p√¥le produit scoring.
Conception d‚Äôune solution se basant sur les d√©veloppements existants et les besoins m√©tiers remont√©s par le Product Owner.
R√©alisation et d√©veloppement de nouvelles fonctionnalit√©s sur les composants des applications du p√¥le produits scoring et environnement CGP.
Votre Future √âquipe :
Au sein d‚Äôun environnement riche et complexe, vous √©voluerez avec des experts passionn√©s √† la fois techniques et fonctionnels (Ing√©nieurs sp√©cialis√©s, chef de projet, scrum master, product owner, analystes ‚Ä¶).
Votre stack de jeu
D ans un environnement SAFE sous cloud GCP, Big Query, OnPrime, Grafana, Python et Ansible.
Vous ?
De formation Ing√©nieur, vous justifiez d‚Äôune premi√®re exp√©rience sur un poste de Data engineer. Vous poss√©dez des comp√©tences d‚Äôautonomie et d‚Äôadaptabilit√© et vous avez une capacit√© √† communiquer efficacement au sein d‚Äôune √©quipe.
Le Groupe Astek
Cr√©√© en France en 1988, Astek est un acteur mondial de l‚Äôing√©nierie et du conseil en technologies. Fort de son expertise dans de nombreux secteurs industriels et tertiaires, Astek accompagne ses clients internationaux dans le d√©ploiement intelligent de leurs produits et de leurs services, et dans la mise en ≈ìuvre de leur transformation digitale.
Depuis sa cr√©ation, le Groupe a fond√© son d√©veloppement sur une forte culture d‚Äôentrepreneuriat et d‚Äôinnovation, et sur l‚Äôaccompagnement et la mont√©e en comp√©tence de
ses 7800 collaborateurs
qui s‚Äôengagent chaque jour √† promouvoir la compl√©mentarit√© entre les technologies num√©riques et l‚Äôing√©nierie des syst√®mes complexes.
Rejoignez un Groupe en fort d√©veloppement en France et √† travers le monde ayant r√©alis√© un chiffre d‚Äôaffaires de 600 M‚Ç¨ en 2023.
Tous les d√©tails sur le Groupe sur le site https://astekgroup.fr. Et vous pouvez aussi nous suivre sur notre blog : https://blog.groupeastek.com.
Rencontrons-nous
Cr√©√© en France en 1988, Astek est un acteur mondial de l‚Äôing√©nierie et du conseil en technologies, pr√©sent sur les 5 continents. Fort de son expertise dans de nombreux secteurs industriels et tertiaires, Astek accompagne ses clients internationaux dans le d√©ploiement intelligent de leurs produits et de leurs services, et dans la mise en ≈ìuvre de leur transformation digitale.
Depuis sa cr√©ation, le Groupe a fond√© son d√©veloppement sur une forte culture d‚Äôentrepreneuriat et d‚Äôinnovation, et sur l‚Äôaccompagnement et la mont√©e en comp√©tence de ses 7800 collaborateurs qui s‚Äôengagent chaque jour √† promouvoir la compl√©mentarit√© entre les technologies num√©riques et l‚Äôing√©nierie des syst√®mes complexes.
Rejoignez un Groupe en fort d√©veloppement en France et √† travers le monde et ayant r√©alis√© un chiffre d‚Äôaffaires hors
acquisitions de 600M‚Ç¨ en 2023.
Tous les d√©tails sur le Groupe sur le site
Nos Plus
Astek est green et fait b√©n√©ficier ses salari√©s d‚Äôune indemnit√© kilom√©trique v√©lo
Une politique CARE sur-mesure d√©ploy√©e par nos √©quipes RH pour nos collaborateurs (https://astekgroup.fr/engagements)
Notre charte de la Diversit√©
Mots-cl√©s :
ing√©nieur ‚Äì ing√©nieure ‚Äì consultant ‚Äì consultante ‚Äì Data engineer ‚Äì Big Data
Caract√©ristiques de l'emploi
Cat√©gorie Ing√©nieur
Job Industry T√©l√©com / M√©dia
Postuler en ligne
Nom *
Pr√©nom *
Email *
Un email valide est requis.
T√©l√©phone *
Un num√©ro de t√©l√©phone valide est requis.
Joindre un CV *
Mots-cl√©s :
ing√©nieur ‚Äì ing√©nieure ‚Äì consultant ‚Äì consultante ‚Äì Data engineer ‚Äì Big Data
Show more
Show less","{'ProgLanguage': ['Python', 'R', 'Go'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git'], 'Os': [], 'DBMS': ['Big Query'], 'SoftBigDataProcessing': [], 'Automation': ['Ansible', 'Chef'], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Big Data', 'Cloud'], 'FrSoftSkills': ['Adaptabilit√©', 'Collaboration'], 'EnSoftSkils': ['Collaboration']}","{'JobDetail': [], 'TypeContract': ['CDI'], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's']}"
Data Engineer - H/F,Free Pro,"Marseille, Provence-Alpes-C√¥te d'Azur, France",https://fr.linkedin.com/jobs/view/data-engineer-h-f-at-free-pro-3861276685?position=6&pageNum=12&refId=i1uQoaWCgdgsEjOn6HkbXA%3D%3D&trackingId=osuodqT4KvIclbWuJD5WAw%3D%3D&trk=public_jobs_jserp-result_search-card,"Au sein de la Direction Technique & innovation, dans le service recherche et innovation, vous travaillez sur des projets d‚Äôenvergure, notamment autour de la 5G et du Edge. Ce p√¥le d‚Äôinnovation d√©friche et pr√©pare les technologies de demain, le tout dans un contexte de croissance avec une forte composante technique. Dans une √©quipe d‚Äôing√©nieurs experts FULL STACK passionn√©s dans les d√©veloppements Back / Front / DevOps / Syst√®me / Embarqu√© ainsi que PO / CP, vous int√©grez une √©quipe dont le moteur est sa capacit√© √† apporter des r√©ponses techniques innovantes en rupture de l‚Äôexistant, via des POC fiables et rapides, qui pr√©figureront les produits Free Pro de demain.
Vos Missions
D√©velopper les solutions techniques de collecte, stockage et transformation de la donn√©e, dans un contexte MLOps :
Ma√Ætrise avanc√©e des langages de programmation pour le traitement des donn√©es, tels que Python, et SQL
Capacit√© √† construire et √† maintenir des architectures de donn√©es robustes et des pipelines de donn√©es √©volutifs
Exp√©rience approfondie avec les syst√®mes de gestion, le maintien et la documentation de base de donn√©es (SQL, NoSQL) et des outils d'extraction de donn√©es.
Exp√©rience dans la manipulation et l'analyse de grands ensembles de donn√©es (Big Data) avec des outils tels que Hadoop, Spark, ou Kafka
Industrialiser et automatiser le nettoyage de la donn√©e
Mettre en place et maintenir les batchs, c‚Äôest-√†-dire les automatisations d‚Äôune s√©rie de traitements en vue de l'int√©gration dans des mod√®les statistiques
Compr√©hension des algorithmes d'apprentissage automatique et de leur mise en ≈ìuvre pratique
G√©rer le cycle de vie de la donn√©e conform√©ment √† la politique de gouvernance des donn√©es de l'entreprise (RGPD...)
R√©aliser les tests unitaires et d‚Äôint√©gration
Assurer le suivi de production et la maintenance
De formation Bac+3 √† Bac+5, vous justifiez d‚Äôune exp√©rience r√©ussie sur ce type de poste. Si vous souhaitez monter en comp√©tence sur la technique et √©voluer dans un environnement en perp√©tuel √©volution, ce poste est fait pour vous.
Comp√©tences Requises
Comp√©tences solides en statistique et en mod√©lisation math√©matique en vue de l'int√©gration dans des mod√®les de Machine Learning
Aptitude √† travailler avec des outils de visualisation de donn√©es comme Matplotlib, Seaborn, Tableau, Power BI.
Des connaissances sp√©cifiques dans les domaines de la 5G du Edge computing ou de l‚ÄôIA seraient un atout suppl√©mentaire.
Autonomie et prise d‚Äôinitiative
Show more
Show less","{'ProgLanguage': ['Python', 'R', 'Go'], 'DataBase': ['SQL', 'NoSQL'], 'DataAnalytics': ['R'], 'BigData': ['Hadoop', 'Spark'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': ['Tableau', 'Power BI', 'Matplotlib', 'Seaborn'], 'Statistics': ['Statistiques'], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['DevOps', 'Big Data', 'ML', 'Machine Learning', 'Statistiques'], 'FrSoftSkills': [], 'EnSoftSkils': ['Initiative']}","{'JobDetail': ['Full'], 'TypeContract': [], 'Salary': [], 'Level': ['Bac+5', 'Bac+3'], 'Experience': ['a', 'n', 's']}"
Data Engineer,Coders Connect,"Paris, √éle-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-at-coders-connect-3870419202?position=7&pageNum=12&refId=i1uQoaWCgdgsEjOn6HkbXA%3D%3D&trackingId=AmMTr7URpiCs3fAUP7p3%2Bw%3D%3D&trk=public_jobs_jserp-result_search-card,"Coders Connect and Sanofi are joining forces to bring an electrifying twist to the biopharmaceutical world!
Work with a rhythm that suits your style (2 days remote and 3 days onsite magic).
Language
: Proficiency in English is required for this role to ensure effective communication within our diverse, global team.
About Sanofi:
We're not just a company; we're a global movement, focused on human health and making a real difference. Our mission? To battle pain, ease suffering, and sprinkle a little bit of magic in the process by developing life-changing medicines and vaccines through breakthrough science and wizard-level technology.
Digital & Data: The Pulse of Our Mission
At the heart of our quest lies our digital and data powerhouse. Think of us as the digital healthcare platform of your dreams, where innovation meets speed, and technology shakes hands with medicine. With our scale, deep-rooted connections in health ecosystems worldwide, and a knack for pushing boundaries, we're here to revolutionise medicine, one digital solution at a time.
The Role: Data Engineering Virtuoso
As our Data Engineering Virtuoso, you're tasked with designing and orchestrating the data pipelines that power our ambitious data analytics initiatives. You'll ensure our data's integrity and accessibility, laying the groundwork for groundbreaking insights and innovations.
Requirements
Cloud Platforms: Proficient in AWS services, with Azure & GCP knowledge a plus. Your work involves leveraging cloud solutions for scalable data processing and storage.
Data Modeling & Query Performance: Expertise in crafting data models and optimizing SQL queries to enhance performance. Experience with Snowflake or similar data warehousing solutions is highly valued.
Integration Services: Skilled in utilizing Integration Services like IICS and Tibco, you facilitate seamless data flow and integration across various platforms.
Scripting & Development: Proficient in scripting languages such as Python and R, enabling you to automate tasks and manipulate data efficiently. Familiarity with GitHub for source code management underscores your commitment to collaborative development and version control.
Visualization & Reporting: Knowledgeable in creating insightful data visualizations using tools like PowerBI, Tableau, or similar, turning complex data into actionable insights.
Data Governance & Compliance: A keen understanding of data quality, security, and governance standards, especially in healthcare environments subject to regulations like GxP, SOX, and data privacy laws.
Real World Data & Standard Models: Experience with Real World Data (e.g., EHR, Claims) and familiarity with standard data models (e.g., OMOP, FHIR) enhance your ability to contribute to our healthcare objectives.
Pipeline Frameworks: Proficiency in using frameworks like Apache Airflow or Kedro for crafting efficient, reliable data pipelines that support our AI and ML initiatives.
The Reward:
A chance to play a crucial role in a collaboration that's redefining healthcare through digital transformation.
A seat at the round table of diversity and inclusion, where different backgrounds and experiences conjure the richness of our culture.
An endless horizon of professional growth, learning opportunities, and the chance to contribute to a future where better health is a global reality.
The Call to Adventure:
If you're ready to join a quest for better ‚Äì better treatments, better outcomes, and better science ‚Äì and believe in the magic of bringing diverse talents together to make miracles happen, we want you. Let's embark on this journey together and transform the future of healthcare.
Better is out there. Are you ready to find it with us?
Show more
Show less","{'ProgLanguage': ['Python', 'Scala', 'R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': ['Apache Airflow'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': ['Tableau', 'PowerBI'], 'Statistics': [], 'CloudComputing': ['AWS', 'Azure'], 'DevTools': ['Git'], 'Os': [], 'DBMS': ['Snowflake', 'Snowflake'], 'SoftBigDataProcessing': [], 'Automation': ['Airflow'], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['ML', 'Cloud'], 'FrSoftSkills': ['Communication', 'Collaboration'], 'EnSoftSkils': ['Communication', 'Collaboration', 'Initiative']}","{'JobDetail': ['Remote'], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's']}"
Consultant Data Engineer F/H,SOFTEAM,"√éle-de-France, France",https://fr.linkedin.com/jobs/view/consultant-data-engineer-f-h-at-softeam-3839971789?position=8&pageNum=12&refId=i1uQoaWCgdgsEjOn6HkbXA%3D%3D&trackingId=lzmkxHMNpIVX3skYoOGs4w%3D%3D&trk=public_jobs_jserp-result_search-card,"Vous √©voluez dans le domaine de la Data et souhaitez int√©grer
un leader de la transformation num√©rique sp√©cialis√© dans les secteurs de la Banque-Finance-Assurance ?
Rejoignez notre communaut√© et d√©veloppez vos comp√©tences chez
SOFTEAM DATA !
VOTRE MISSION
Pour le compte d'un client grand compte, vos missions seront :
A
comprendre le besoin
de nos clients au travers de missions de type : aide aux choix d‚Äôoutils, cadrage des besoins, POC ;
Recueillir et analyser les besoins et proposer une architecture technique
adapt√©e aux cas d‚Äôusage des clients ;
Conduire des projets de
d√©ploiement des Modern Data Platform
(Applications Cloud Native, Migration d‚Äôapplications existantes) et participer √† la mise en ≈ìuvre
Fournir une expertise technique approfondie
aux √©quipes projets
R√©diger la documentation permettant √† l'IT d'assurer la maintenance ;
VOTRE PROFIL
Vos
comp√©tentes techniques
:
Vous avez un minimum de
3
ann√©es d‚Äôexp√©rience sur des
projets Data sur les outils ETL
(Talend, SQL Server) et
Reporting
(Power BI, Tableau Software).
Id√©alement au moins une premi√®re exp√©rience sur des projets
Cloud AWS ou Azure ou GCP
.
Vous avez une grande aisance dans la
communication orale et √©crite
alli√©e √† un esprit de synth√®se, de la rigueur et un tr√®s bon sens de la formalisation
Fournir une expertise technique
approfondie aux √©quipes projets
R√©aliser une veille technologique
permanente sur les tendances du march√© et les perspectives concurrentielles
Vos
atouts
:
Vous √™tes dipl√¥m√© d‚Äôune formation Bac+5 en informatique ;
Vous avez des comp√©tences approfondies dans un ou plusieurs de ces domaines : Op√©rations / Gestion des syst√®mes, Conception ou d√©veloppement de logiciels, Processus DevOps et outillage, Strat√©gie d'entreprise, Infrastructure Cloud (virtualisation, mise en r√©seau, stockage, base de donn√©es), S√©curit√© et conformit√© ;
Vous souhaitez vous impliquer dans le d√©veloppement d‚Äô√©quipes et de communaut√©s techniques autour du Cloud et des solutions Data
Vos exp√©riences pass√©es vous ont amen√© √† mettre en avant votre capacit√© √† int√©grer des probl√©matiques fonctionnelles complexes, comprendre les enjeux m√©tiers, analyser les risques et √™tre force de propositions,
Enfin, on vous appr√©cie pour vos qualit√©s de communication, de r√©daction et votre bon relationnel‚Ä¶and a good level of english would be a definite asset !
NOUS VOUS OFFRONS
Des missions engageantes aupr√®s des grands acteurs du march√©.
Un management de proximit√©, √† l‚Äô√©coute et bienveillant.
La possibilit√© d‚Äô√©voluer dans chacune des facettes des m√©tiers de l‚ÄôIT !
QUI SOMMES NOUS ?
Softeam Data est le d√©partement de Softeam, marque de Docaposte, sp√©cialis√© dans les diff√©rents domaines de la Data (Hadoop et Cloud) et de l‚Äôinformatique d√©cisionnelle. Nous apportons notre expertise √† nos clients, principalement des grands comptes de la place financi√®re fran√ßaise, dans des projets de transformation digitale et cognitive.
Plus de 1650 Softeamien.nes sont d√©di√©.es √† la transformation m√©tier et digitale de nos clients et ont g√©n√©r√© 191 M‚Ç¨ de chiffre d‚Äôaffaires en 2019.
SOFTEAM est labellis√© Happy At Work !
Show more
Show less","{'ProgLanguage': ['R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': ['Hadoop'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': ['Tableau', 'Power BI'], 'Statistics': [], 'CloudComputing': ['AWS', 'Azure'], 'DevTools': ['Git'], 'Os': [], 'DBMS': ['SQL Server'], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['DevOps', 'Cloud'], 'FrSoftSkills': ['Communication'], 'EnSoftSkils': ['Communication']}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': ['Bac+5'], 'Experience': ['a', 'n', 's']}"
Data Engineer - Stream Data Processing - Distributed Data Processing,Pathway,"Paris, √éle-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-stream-data-processing-distributed-data-processing-at-pathway-3887662141?position=9&pageNum=12&refId=i1uQoaWCgdgsEjOn6HkbXA%3D%3D&trackingId=xsdo8N7LQI1tK8vmCd6DnA%3D%3D&trk=public_jobs_jserp-result_search-card,"About Pathway
Deeptech start-up, founded in March 2020.
Our primary developer offering is an ultra-performant Data Processing Framework (unified streaming + batch) with a Python API, distributed Rust engine, and capabilities for data source integration & transformation at scale (Kafka, S3, databases/CDC,...)
The single-machine version is provided on a free-to-use license (`pip install pathway`)
Major data use cases are around event-stream data (including real-world data such as IoT), and graph data that changes over time
Our enterprise offering is currently used by leaders of the logistics industry, such as DB Schenker or La Poste, and tested across multiple industries. Pathway has been featured in Gartner's market guide for Event Stream Processing
Learn more at http://pathway.com/ and https://github.com/pathwaycom/
Pathway is VC-funded, with amazing BAs from the AI space and industry. We have operations across Europe and in the US. We are headquartered in Paris, with significant support from the French ecosystem (BPI, Agoranov, WILCO,...).
The Team
Pathway is built by and for overachievers. Its co-founders and employees have worked in the best AI labs in the world (Microsoft Research, Google Brain, ETH Zurich), worked at Google, and graduated from top universities (Polytechnique, ENSAE, Sciences Po, HEC Paris, PhD obtained at the age of 20, etc...). Pathway's CTO is a co-author with Goeff Hinton and Yoshua Bengio. The management team also includes the co-founder of Spoj.com (1M+ developer users) and NK.pl (13.5M+ users) and experienced growth leader who has scaled companies with multiple exits.
The opportunity
We are searching for a person with a Data Processing or Data Engineering profile, willing to work with live client datasets, and to test, benchmark, and showcase our brand-new stream data processing technology.
The end-user of our product are mostly developers and data engineers working in a corporate environment. Our development framework is one day expected to become for them a part of their preferred development stack for analytics projects at work - their daily bread & butter.
You Will
You will be working closely with our CTO, Head of Product, as well as key developers. You will be expected to:
Implement the flow of data from their location in client's warehouses up to Pathway's ingress
Set up CDC interfaces for change streams between client data stores and i/o data processed by Pathway; ensuring data persistence for Pathway outputs
Design ETL pipelines within Pathway
Contribute to benchmark framework design (throughput / latency / memory footprint; consistency), including in a distributed system setup.
Contribute to building open-source test frameworks for simulated streaming data scenarios on public datasets
Requirements
Inside-out understanding of at least one major distributed data processing framework (Spark, Dask, Ray,...)
6 months+ experience working with a streaming dataflow framework (e.g.: Flink, Kafka Streams or ksqldb, Spark in streaming mode, Beam/Dataflow)
Ability to set up distributed dataflows independently
Experience with data streams: message queues, message brokers (Kafka), CDC
Working familiarity with data schema and schema versioning concepts; Avro, Protobuf, or others
Familiarities with Kubernetes
Familiarity with deployments in both Azure and AWS clouds
Good working knowledge of Python
Good working knowledge of SQL
Experienced in working for an innovative tech company (SaaS, IT infrastructure or similar preferred), with a long-term vision
Warmly disposed towards open-source and open-core software, but pragmatic about licensing
Bonus Points
Know the ways of developers in a corporate environment
Passionate about trends in data
Proficiency in Rust
Experience with Machine Learning pipelines or MLOps
Familiarity with any modern data transformation workflow tooling (dbt, Airflow, Dagster, Prefect,...)
Familiarity with Databricks Data Lakehouse architecture
Familiarity with Snowflake's data product vision (2022+)
Experience in a startup environment
Benefits
Why You Should Apply
Intellectually stimulating work environment. Be a pioneer: you get to work with a new type of stream processing framework
Work in one of the hottest data startups in France, with exciting career prospects
Responsibilities and ability to make significant contribution to the company' success
Compensation: annual salary of ‚Ç¨60K-‚Ç¨100K + Employee stock option plan.
Inclusive workplace culture
Further details
Type of contract: Permanent employment contract
Preferable joining date: early 2023
Compensation: annual salary of ‚Ç¨60K-‚Ç¨100K + Employee stock option plan
Location: Remote work from home. Possibility to work or meet with other team members in one of our offices:
Paris - Agoranov (where Doctolib, Alan, and Criteo were born) near Saint-Placide Metro (75006)
Paris Area - Drahi X-Novation Center, Ecole Polytechnique, Palaiseau
Wroclaw - University area
Candidates based anywhere in the EU, United States, and Canada will be considered.
Show more
Show less","{'ProgLanguage': ['Python', 'R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': ['Spark', 'Databricks', 'Flink'], 'MachingLearning': [], 'DataSerialization': ['Avro'], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': ['AWS', 'Azure'], 'DevTools': ['Git'], 'Os': [], 'DBMS': ['Snowflake', 'Snowflake'], 'SoftBigDataProcessing': [], 'Automation': ['Kubernetes', 'Airflow'], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': ['Kubernetes'], 'Collaboration': [], 'Other': ['ML', 'Machine Learning', 'Cloud'], 'FrSoftSkills': [], 'EnSoftSkils': []}","{'JobDetail': ['Remote'], 'TypeContract': [], 'Salary': ['60K'], 'Level': [], 'Experience': ['a', 'n', 's']}"
Senior Data Engineer - Valbonne,Capgemini,"Valbonne, Provence-Alpes-C√¥te d'Azur, France",https://fr.linkedin.com/jobs/view/senior-data-engineer-valbonne-at-capgemini-3888072146?position=10&pageNum=12&refId=i1uQoaWCgdgsEjOn6HkbXA%3D%3D&trackingId=9jlk%2BtDmBpVNLdSnj6hq%2Fg%3D%3D&trk=public_jobs_jserp-result_search-card,"Choisir Capgemini, c'est choisir une entreprise o√π vous serez en mesure de fa√ßonner votre carri√®re selon vos aspirations. Avec le soutien et l'inspiration d'une communaut√© d‚Äôexperts dans le monde entier, vous pourrez r√©√©crire votre futur. Rejoignez nous pour red√©finir les limites de ce qui est possible, contribuer √† lib√©rer la valeur de la technologie pour les plus grandes organisations et participer √† la construction d‚Äôun monde plus durable et inclusif.
Vos missions :
En tant que Senior Data Engineer au sein d'une √©quipe multidisciplinaire, vos responsabilit√©s principales seront les suivantes :
Participer √† des ateliers clients.
Acqu√©rir des donn√©es et optimiser le stockage.
Cr√©er de flux de donn√©es optimis√©s et √©laborer des algorithmes de transformation.
Traiter et analyser pour la visualisation et le machine learning.
Encadrer des ing√©nieurs juniors et contribuer √† la communaut√© Data.
Votre profil :
Vous poss√©dez un dipl√¥me d'ing√©nieur informatique et/ou Master avec une sp√©cialit√© data.
Vous parlez couramment fran√ßais et anglais.
Vous poss√©dez au minimum 6 ans d'exp√©rience sur un r√¥le similaire.
Vous ma√Ætrisez les outils Spark, Python, Scala ainsi qu'une bonne compr√©hension des syst√®mes d'extraction, de transformation et de changement (ETL).
Vous avez un certain leadership et un esprit d'√©quipe, id√©alement dans un cadre agile.
3 raisons de nous rejoindre :
Qualit√© de vie au travail :
accord de t√©l√©travail en France et √† l'international, accord sur l'√©galit√© professionnelle, la parentalit√©, l'√©quilibre des temps et la mobilit√© durable.
Apprentissage en continu
: certifications et formations en libre acc√®s, accompagnement sur mesure avec votre carrer manager, parcours d'int√©gration sur 9 mois.
Avantages groupe & CSE :
plan actionnariat, activit√©s √† tarifs pr√©f√©rentiels, remboursement partiel vacances, remboursement de votre abonnement sportif ou culturel.
Nos engagements et priorit√©s :
Le groupe Capgemini encourage une culture inclusive dans un cadre multiculturel et handi-accueillant. En nous rejoignant, vous int√©grez un collectif qui valorise la diversit√©, d√©veloppe le potentiel de ses talents, s'engage dans des initiatives solidaires avec ses partenaires, et se mobilise pour r√©duire son impact environnemental sur tous ses sites et aupr√®s de ses clients.
A Propos de Capgemini :
Capgemini est un leader mondial, responsable et multiculturel, regroupant pr√®s de 350 000 personnes dans plus de 50 pays. Fort de 55 ans d‚Äôexp√©rience, nous sommes un partenaire strat√©gique des entreprises pour la transformation de leurs activit√©s en tirant profit de toute la puissance de la technologie et des innovations dans les domaines en perp√©tuelle √©volution tels que le cloud, la data, l‚ÄôIntelligence Artificielle, la connectivit√©, les logiciels, l‚Äôing√©nierie digitale ou les plateformes.
Get The Future You Want* | www.capgemini.com/fr-fr
*Capgemini, le futur que vous voulez
Show more
Show less","{'ProgLanguage': ['Python', 'Scala', 'R', 'Go'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': ['Spark'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git'], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Machine Learning', 'Cloud'], 'FrSoftSkills': ['Leadership', 'Organisation'], 'EnSoftSkils': ['Leadership', 'Initiative']}","{'JobDetail': ['Junior', 'Senior'], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's', '6', '6', '6']}"
Data Engineer,Harnham,"Paris, √éle-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-at-harnham-3913552815?position=1&pageNum=15&refId=WygPS3lGVIiC9LmdVGUPqQ%3D%3D&trackingId=XLPnhzttKDURkvTaCX0X0A%3D%3D&trk=public_jobs_jserp-result_search-card,"DATA ENGINEER
PARIS (75) / LILLE (59)
50K-60K EUR
SQL ‚Äì Python ‚Äì CI/CD ‚Äì ETL
Une nouvelle opportunit√© s‚Äôouvre pour un Data Engineer dans une agence marketing, ax√©e Intelligence Artificielle. Si vous recherchez un d√©fi stimulant dans un environnement avec de belles possibilit√©s d‚Äô√©volution, cette opportunit√© est faite pour vous.
VOTRE MISSION :
Mise en place et maintiens de pipelines de donn√©es
Migration d‚Äôoutils
Implementation d‚Äôoutils
Implementation de dashboard focus BI
VOTRE PROFIL :
3 ans d‚Äôexp√©rience en tant que Data Engineer
Competences solides sur un des Cloud Public (AWS ; GCP ou Azure)
Competences avec SQL et Python
Modelisation de donn√©es / DBT
Connaissance de CI/CD et processus ETL
N‚Äôh√©sitez plus pour postuler !
Show more
Show less","{'ProgLanguage': ['Python', 'R'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': ['AWS', 'Azure'], 'DevTools': [], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Cloud', 'CI/CD'], 'FrSoftSkills': [], 'EnSoftSkils': []}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's', '3', '3', '3']}"
(Senior) Data Engineer,Mirakl,France,https://fr.linkedin.com/jobs/view/senior-data-engineer-at-mirakl-3904076524?position=2&pageNum=15&refId=WygPS3lGVIiC9LmdVGUPqQ%3D%3D&trackingId=1%2FTsV5ZQo7vBKr5nLOc0Iw%3D%3D&trk=public_jobs_jserp-result_search-card,"Mirakl, leader et pionnier de l‚Äô√©conomie de plateforme, propose aux entreprises une suite unique de solutions leur permettant de transformer significativement leur e-commerce afin d'acc√©l√©rer de fa√ßon durable et rentable leur croissance. Depuis 2012, Mirakl accompagne les entreprises B2C et B2B avec la technologie la plus avanc√©e, s√©curis√©e et √©volutive leur permettant de digitaliser leur activit√© et d'√©largir leur offre via la marketplace ou le dropship, faciliter la gestion des catalogues et des paiements de leurs fournisseurs pour plus d'efficacit√©, offrir une exp√©rience d'achat personnalis√©e √† leurs clients, et augmenter leurs profits gr√¢ce au retail media. Bas√©e √† Paris et Boston, Mirakl est certifi√©e Great Place to Work.
A propos de Mirakl Labs
Nos √©quipes techniques et produits, nomm√©es Mirakl Labs, sont principalement r√©parties entre nos 2 hubs situ√©s √† Paris et √† Bordeaux. Elles collaborent au quotidien afin d'adresser les probl√©matiques de nos clients et utilisateurs en r√©pondant √† diff√©rents challenges li√©s aux nouvelles fonctionnalit√©s, √† la scalabilit√©, la s√©curit√© et l‚Äôergonomie‚Ä¶
Elles op√®rent en mode agile et s'organisent en Squads compos√©es d'un Squad Lead, de 5 d√©veloppeurs, d'un Product Manager et d'un QA. Chaque Squad est sp√©cialis√©e sur un scope fonctionnel afin de concevoir et r√©aliser de nouvelles features, leurs √©volutions et des APIs (avec un d√©coupage en micro-services). Nos √©quipes Infrastructure, Architecture, S√©curit√©, Documentation, Product Design, Data et Support op√®rent en transverse en apportant leur expertise et de la coh√©rence sur l‚Äôensemble des produits.
Toutes les √©quipes sont responsables de leur p√©rim√®tre et chacun des collaborateurs apporte son exp√©rience et ses id√©es. Innovation, feedback et implication dans les prises de d√©cision sont au c≈ìur de notre philosophie.
Et pour favoriser ce partage avec d‚Äôautres passionn√©s, nous sommes sponsors, speakers, et h√¥tes de diff√©rents √©v√©nements, meetups, et associations de la sc√®ne Tech en France. Au cours des derni√®res ann√©es, nous avons particip√© √† des √©v√©nements tels que Devoxx, ReactEurope, ProductConf et Flupa UX Days.
A propos du job
La solution SaaS Mirakl est le moteur des marketplaces des plus importants e-commer√ßants √† travers le monde. Cette solution g√®re et produit de gros volumes de donn√©es qui pr√©sentent des challenges extr√™mement int√©ressants pour les sp√©cialistes de la donn√©e (produits, commandes, clients, niveaux de stock, prix, messages, appels API, donn√©es de navigation, s√©ries temporelles, donn√©es g√©olocalis√©es etc.).
En tant que (Senior) Data Engineer au sein de l‚Äô√©quipe Data Mirakl, vos principales missions seront de :
contribuer √† l'enrichissement de la Data Platform (ETL)
am√©liorer la robustesse de nos pipelines de production pour nos applications Machine Learning (inf√©rence real time etc.)
Int√©gr√©(e) dans une √©quipe de sp√©cialistes de la donn√©e (data engineers, machine learning engineers, data scientists, data analysts), vous √™tes un des acteurs cl√©s pour garantir la place de Mirakl comme solution dominante sur son march√©.
Notre stack et nos outils
Apache Spark, Kafka, AWS, Databricks, Python, Airflow, Mlflow, Tensorflow, Delta lake, Superset, Kubernetes, Redshift, SQL, Terraform, Ansible
Au quotidien, vous allez :
Participer √† la d√©finition et √† l‚Äôimpl√©mentation d‚Äôune architecture performante, robuste, scalable et aux co√ªts ma√Ætris√©s pour nos applications Spark ainsi que pour nos pipelines de production de Machine Learning (√©valuation des feature stores, refactoring de DAG Airflow)
Accompagner les Data Scientists lors de leur mise en production (relecture de code, pair programming) et mettre en place les best practices
Optimiser et am√©liorer la CI/CD de l‚Äô√©quipe en collaboration avec l‚Äô√©quipe SRE
Assurer la mont√©e en comp√©tence des membres de l‚Äô√©quipe sur les sujets de MLOps et Data Engineering
R√©fl√©chir √† la meilleure fa√ßon d'int√©grer les donn√©es Google Analytics dans la data platform
Partager ses connaissances et pr√©senter les travaux devant toutes les √©quipes Labs
Ce qu‚Äôon peut vous apporter :
Des projets data driven, divers et vari√©s (traitements massifs d‚Äôimages, de textes, time series etc.) pour des produits diff√©rents de Mirakl
Une culture orient√©e sur la veille technologique
Des projets qui ont un vrai impact business devant √™tre d√©ploy√©s sur des centaines de clients dans un contexte multilingue
Quelques exemples de sujets en cours :
Enrichissement des donn√©es produit √† partir des images et des descriptions
Mod√©ration automatique des produits
Mapping automatique des donn√©es produit
Identification des produits √† fort potentiels
D√©tection de comportements frauduleux
Sentiment analysis sur les messages √©chang√©s entre clients et vendeurs et dans les √©valuations
D√©termination de prix optimaux
Monitoring de la qualit√© de service des vendeurs
Des applications d‚Äôinf√©rence en synchrone de nos mod√®les de ML
Vous aimerez ce job si :
Vous √™tes passionn√©(e) par la data et les technologies modernes permettant d'en tirer partie
Vous vous int√©ressez √† la data science et avez des connaissances g√©n√©rales sur les algorithmes de Machine Learning
Vous avez un background en d√©veloppement et avez √©volu√© dans un environnement Data
Vous avez a minima 4 ans d‚Äôexp√©rience en environnement Machine Learning et/ou Data
Vous avez mis en production avec succ√®s des applications Big Data faisant appel √† du Machine Learning, du NLP, du traitement d‚Äôimages dans des projets d'envergure, √† fort volume de donn√©es
Votre ma√Ætrisez Python, √™tes un pro des frameworks data de la fondation Apache et √™tes √† l'aise dans un environnement AWS
Vous ma√Ætrisez au moins un outil d‚Äôorchestration (Airflow, Data Pipeline ou tout autre outil similaire)
Vous pr√©sentez vos travaux de mani√®re simple et accessible
Vous fa√Ætes preuve d'un bon relationnel et vous aimez mentorer des collaborateurs
Vous parlez couramment anglais et fran√ßais
Les plus pour le poste :
Vous avez une exp√©rience significative dans le domaine du e-commerce
Vous avez d√©j√† mis en place un Data Lake, Data Warehouse ou une Data Platform
Vous avez d√©ploy√© des applicatifs en environnement Kubernetes
Vous avez mis en place des pipelines d'ingestion de donn√©es avec une approche CDC √† l'aide de Debezium ou autre
Vous ma√Ætrisez Java/Scala
Mirakl est engag√©e en faveur de la diversit√©, de l‚Äô√©galit√© des chances et de l‚Äôinclusion. Nous c√©l√©brons nos diff√©rences car nous sommes convaincus que les qualit√©s visibles et invisibles de chaque Mirakl Worker sont une source de force et d‚Äôinnovation. Dans le cadre de cet engagement, nous √©tudions toutes les candidatures sans distinction de : genre, ethnicit√©, religion, orientation sexuelle, handicap, √¢ge ou toute autre caract√©ristique prot√©g√©e par la loi.
Show more
Show less","{'ProgLanguage': ['Python', 'Java', 'Scala', 'R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': ['Spark', 'Databricks'], 'MachingLearning': ['TensorFlow'], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': ['AWS'], 'DevTools': ['Git'], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': ['Ansible', 'Kubernetes', 'Airflow'], 'InfrastructureAsCode': ['Terraform'], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': ['Kubernetes'], 'Collaboration': [], 'Other': ['Big Data', 'ML', 'Machine Learning', 'CI/CD'], 'FrSoftSkills': ['Collaboration'], 'EnSoftSkils': ['Collaboration']}","{'JobDetail': ['Senior'], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's', '4', '4', '4']}"
Business Data Analyst,Accor,"Issy-les-Moulineaux, √éle-de-France, France",https://fr.linkedin.com/jobs/view/business-data-analyst-at-accor-3849451754?position=3&pageNum=15&refId=WygPS3lGVIiC9LmdVGUPqQ%3D%3D&trackingId=Y6WI0u9WzB93sWd9Yzj7KA%3D%3D&trk=public_jobs_jserp-result_search-card,"Company Description
Leading the hospitality revolution, Accor is more than a hotel group. With luxury to economy, homestays to resorts, we are a holistic ecosystem of 40 brands in 110 countries, Talent and Solutions, ready to engage with the future‚Äôs endless possibilities. Accor has an offer to bring new life to the way you live, work, play and do business with a personalized guest experience.
Astore is Accor‚Äôs Procurement Organization, that is revolutionizing the hospitality sector by offering all the products and services necessary to ensure the proper functioning of all hospitality businesses. With a team of 200 experts serving 5000 customers in 20 countries, Astore is able to negotiate some of the best prices and conditions on the market. With more than 7500 clients worldwide and about 2000 external partners, our ambition is to become the first choice for procurement solution for the hospitality sector.
Astore Digital Factory leads all our Digital activities within the Procurement function. Its main responsibility is to develop the business thanks to best-in-class digital tools maximizing the impact (Revenue, EBITDA) of our Procurement business teams in the Paris HQ and in the different worldwide regions. The digital platforms are covering all Procurement business processes: (i) Hospitality supply chain at site (e-ordering through marketplace, Supplier directory, Pre-opening project management, Inventory & recipe management, Invoice to pay, Data, Customer Analytics & Procurement news) and (ii) Internal Procurement operations (Source to contract, CRM, Marketing & Sales automation, Ticketing, Customer Website, Full order to pay Revenue / Back end rebate Management, CSR, Finance process & Business performance analytics).
The Hotel Tools Product team is in charge of all tools at hotel level (e-ordering, inventory & recipe management, invoice to pay), out of which some are ‚Äúcustom‚Äù and others ‚ÄúSaaS‚Äù (Mirakl, Tradeshift, FutureLog).
Job Description
The Business Data Analyst (BDA) is the interface between the Data and business teams. The BDA is in charge of understanding the demands of Procurement department and carefully providing and planning a solution. The BDA is a data-driven professional, uses the data analysis process to understand, interpret, and predict patterns in business, and then use those data-driven insights to enhance their business process and making decisions. The BDA aims to identify opportunities to grow, optimize, and improve an organization‚Äôs business processes. His function is on of vision and strategy implementation. The BDA also helps in making judgments that are aligned with corporate objectives.
Main Activities
Has experience in Data-driven Business Analysis on simple and complex problems
In charge of prioritization of business requirements according to the objectifs requested
Collaborates with the users or business experts to define what it is expected
Analyses requirements and participates in the design of the solution with the technical team
Lies at the intersection of Data Analysis and Business Analysis
Creates and modifies computer programs to extract information from company databases
Interacts with data engineer and data scientists to understand how data needs to be converted, loaded and presented
Develops and deploys dashboards, reports, to collect data-backed insights
Interprets key business data sets
Provides insights on potential areas of growth, optimization, and improvements
Works cross-department on data-driven strategies that improve business processes and decision-making
Is responsible of writing or providing US stories or/and Business Rules.
Qualifications
Skills & profile
:
BS/BA Degree (MS preferred) preferably in Computer Science, Statistics, Math or equivalent combination of education and experience.)
1-5 years of experience with data analysis and preparation, including experience with very large data sets
Experience working with unstructured data sets is a plus
Mathematical skills to help collect, measure, organize and analyze data
Knowledge of programming languages like SQL, R, Python
Technical proficiency regarding database design development, data models
Knowledge of data visualization
Knowledge of how to create and apply the most accurate algorithms to datasets in order to find solutions
Knowledge of the project management process.
3+ years in management/executive role
Experience in Agile Development
Additional Information
What benefits can Accor offer its employees?
A real Work life balance
Remote work / autnomous framework
Attractive Finance Benefits
Profit sharing bonus ""interessement participation"" compulsory and voluntary plans / 700 ‚Ç¨ per year Allowance Green transportation such as electrical bike, scooter / Pass Navigo subsidised max 75% / Referral bonus / meal ticket / free coffee
Learning & development
Management talent at the earth our of HR Accor strategy.
We want you to feel free to dare and free to grow, by opening new doors to continuous learning and skills development. Challenge yourself and switch between jobs, brands, and career paths
Show more
Show less","{'ProgLanguage': ['Python', 'R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': ['Statistics'], 'CloudComputing': [], 'DevTools': ['Git'], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': ['Teams'], 'Other': [], 'FrSoftSkills': [], 'EnSoftSkils': ['Organization']}","{'JobDetail': ['Remote', 'Full'], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's']}"
Data Engineer,MindPal,"Marseille, Provence-Alpes-C√¥te d'Azur, France",https://fr.linkedin.com/jobs/view/data-engineer-at-mindpal-3896991761?position=4&pageNum=15&refId=WygPS3lGVIiC9LmdVGUPqQ%3D%3D&trackingId=1bDNsrHHWU0dtp4FwYXNSg%3D%3D&trk=public_jobs_jserp-result_search-card,"We are looking for
Data Engineer!
Responsibilities
Designing, creating, and maintaining data processing systems
Analyzing and optimizing data processing workflows
Collaborating with the team to ensure data quality and efficiency
Testing and implementing new solutions
Requirements
At least 2 years of experience in designing and creating data processing systems
Proficiency in tools and programming languages related to data engineering (e.g. Hadoop, Spark, Scala, Python)
Excellent knowledge of databases and SQL language
Ability to work in a team and communicate effectively with other departments
Communicative English skills
Experience with AWS/AWS Glue is a plus
We Offer
B2B contract
Full-time job
Remote work and flexible hours
Show more
Show less","{'ProgLanguage': ['Python', 'Scala', 'R'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': ['Hadoop', 'Spark'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': ['AWS'], 'DevTools': [], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': [], 'FrSoftSkills': [], 'EnSoftSkils': []}","{'JobDetail': ['Remote', 'Full'], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's']}"
Data Engineer Flight Ops (H/F),METEOJOB by CleverConnect,"Toulouse, Occitanie, France",https://fr.linkedin.com/jobs/view/data-engineer-flight-ops-h-f-at-meteojob-by-cleverconnect-3905908053?position=5&pageNum=15&refId=WygPS3lGVIiC9LmdVGUPqQ%3D%3D&trackingId=Bn4zuis8yDC4gLergvr0yw%3D%3D&trk=public_jobs_jserp-result_search-card,"Description Du Poste
Les missions du poste
ACTIVUS Recherche Un(e) Data Engineer Flight Ops (H/F)
Au sein de l'√©quipe de la BI, vous int√©grez une √©quipe 13 personnes d√©di√©es aux donn√©es BI des op√©rations a√©riennes.
Missions
La mission consiste √† piloter la partie Data du projet de migration du SI.
L'environnement est en BI traditionnelle avec un usage fr√©quent de Qlikview et PowerBI.
La mission sera centr√©e dans le contexte de migration du SI vers un nouvel √©diteur.
Migration : combinaison de LCM et innovation
PROFIL
Tr√®s bon niveau en conception
Tr√®s bon niveau SQL et informatica
Connaissance de Qlikview
Grande autonomie et grande app√©tence √† comprendre les enjeux techniques et fonctionnels de l'environnement pour proposer des solutions adapt√©es.
App√©tence pour le fonctionnel
Excellente capacit√© d'analyse
Bonne capacit√© de synth√®se
Curiosit√© et force de proposition
Bonne capacit√© de communication
Pr√©sence sur site au moins 1 x mois pour les Toulousains
Alors ! Serez-vous des n√¥tres ?
Bienvenue chez Activus Group
Saisissez l'opportunit√© de rejoindre notre groupe qui vous permettra d'atteindre un niveau d'excellence tout en travaillant dans une bonne ambiance !
Nous rejoindre c'est int√©grer un groupe humain ayant pour domaines d'expertise :
Intelligence Artificielle et Big Data
Conseil & Audit
Infrastructure et cloud
Applications digitales
SSI/Cyber s√©curit√©
Digitalisation de la production
Nous puisons notre force dans une √©quipe de femmes et d'hommes passionn√©s et ambitieux, toujours pr√™ts √† relever de nouveaux d√©fis !
Ecoute, proximit√©, r√©activit√© et efficacit√© se retrouvent dans notre management quotidien : b√©n√©ficiez d'un accompagnement personnalis√© tout au long de votre carri√®re.
Parce que nous remportons en permanence de nouveaux projets, nous saurons vous trouver LE poste, que ce soit en interne au sein de notre p√¥le √©dition ou chez un de nos clients.
Alors, ferez-vous partie de l'aventure ACTIVUS Group ? Nous n'attendons plus que vous !
: Vous n'√™tes pas de la r√©gion ? Un accompagnement au re-logement en cas de d√©m√©nagement vous est propos√© par notre partenaire, le Groupe Mobility.
JE POSTULE
Show more
Show less","{'ProgLanguage': ['R'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': ['PowerBI'], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git'], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Big Data', 'Cloud'], 'FrSoftSkills': ['Communication'], 'EnSoftSkils': ['Communication']}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's']}"
Senior Data Engineer - Snowflake,FRG Technology Consulting,"Paris, √éle-de-France, France",https://fr.linkedin.com/jobs/view/senior-data-engineer-snowflake-at-frg-technology-consulting-3904054143?position=6&pageNum=15&refId=WygPS3lGVIiC9LmdVGUPqQ%3D%3D&trackingId=fblI8d1CV4iunCzBt2LoYA%3D%3D&trk=public_jobs_jserp-result_search-card,"Mon client, un End User sur Paris, est √† la recherche d'un(e) Data Ops, pour intervenir sur l'ensemble de la cha√Æne d√©cisionnelle au sein du p√¥le data.
Show more
Show less","{'ProgLanguage': ['R'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': [], 'FrSoftSkills': [], 'EnSoftSkils': []}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's']}"
Data Engineer,Harnham,"Paris, √éle-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-at-harnham-3909639055?position=7&pageNum=15&refId=WygPS3lGVIiC9LmdVGUPqQ%3D%3D&trackingId=zTGtx8tc2u8Yi8uHv3DjJQ%3D%3D&trk=public_jobs_jserp-result_search-card,"DATA ENGINEER
PARIS (75) / LILLE (59)
50K-65K EUR
Cloud AWS ‚Äì Python ‚Äì PySpark - Glue
Une nouvelle opportunit√© s‚Äôouvre pour un Data Engineer dans le domaine de l‚Äôassurance. La personne rejoindra une grande √©quipe ayant pour projet la cr√©ation d‚Äôune nouvelle plateforme Data ! Si vous recherchez un d√©fi stimulant dans un environnement qui encourage les nouvelles id√©es, cette opportunit√© est faite pour vous.
VOTRE MISSION :
Collaboration avec les Data Architectes pour garantir un bon alignement sur l‚Äôarchitecture
Developpement des processus d‚Äôingestion pour la diffusion des donn√©es dans le Datalake
Mise en place de m√©canisme pour g√©n√©rer les couches de donn√©es organis√©es
Implementation d‚Äôoutils MLOps pour la mise en ≈ìuvre d‚Äôalgorithmes ML
Conception de Data Warehouse pour acc√©l√©rer la g√©n√©ration de mod√®les en Etoile
Travail dans une √©quipe agile avec le train Agile Release, le Product Owner et le SCRUM Master
VOTRE PROFIL :
3 √† 5 ans d‚Äôexp√©rience en tant que Data Engineer
Comp√©tences solides en Cloud AWS, Python, PySpark et SQL
Comp√©tences avec les services AWS Cloud Computing : Glue ; Ath√©na ; Redshift
Capacit√© √† travailler en autonomie
Francais et Anglais : Fluent obligatoire
Les outils BI tels que Power BI ou QuickSight est un plus
N‚Äôh√©sitez plus pour postuler !
Show more
Show less","{'ProgLanguage': ['Python', 'R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': ['Spark'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': ['Power BI'], 'Statistics': [], 'CloudComputing': ['AWS'], 'DevTools': [], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['ML', 'Cloud'], 'FrSoftSkills': ['Collaboration'], 'EnSoftSkils': ['Collaboration']}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's', '5', '5', '5']}"
Data Engineer H/F,KALI GROUP,"Chassieu, Auvergne-Rh√¥ne-Alpes, France",https://fr.linkedin.com/jobs/view/data-engineer-h-f-at-kali-group-3902539083?position=8&pageNum=15&refId=WygPS3lGVIiC9LmdVGUPqQ%3D%3D&trackingId=7YS96tv6tGYzHug2%2F5BNOA%3D%3D&trk=public_jobs_jserp-result_search-card,"Cr√©√©e en 2021 √† Lyon, Kali Group est une start-up qui vient bousculer le monde du conseil.
Parce que chez Kali, nous croyons aux rencontres, √† l'importance de saisir les opportunit√©s et d'avancer comme on le souhaite dans sa vie professionnelle, nous voulons √™tre les premiers √† proposer un mod√®le d'accompagnement bas√© sur la libert√©. Ainsi, l'assistance technique peut √™tre un v√©ritable propulseur de r√©ussite, levier de recrutement, pour une collaboration p√©renne entre ing√©nieurs et industriels.
Notre mod√®le novateur porte d√©j√† ses fruits, avec des √©quipes en hyper-croissances, et l'ouverture de deux nouvelles agences en r√©gion.
Le Poste
Rejoignez le bureau d'√©tudes d'un industriel en plein d√©veloppement de la r√©gion lyonnaise !
Dans le cadre du d√©veloppement de nos activit√©s nous recherchons un Data Engineer (H/F).
Vous aurez pour objectifs et responsabilit√©s le traitement et l'analyse de donn√©es industrielles.
A ce titre vous, vous √™tes en charge de :
√âlaborer la strat√©gie sur les donn√©es ;
Superviser la cr√©ation et la modification du data lake ;
Documenter les flux de donn√©es, les r√®gles de gestion, et √©valuer la criticit√© des donn√©es techniques ;
Identifier les besoins m√©tiers, suivre l'√©volution des donn√©es et mettre en place des alertes de surveillance ;
√âtablir des standards de documentation des proc√©dures et soutenir la r√©daction de documents ;
√âlaborer des indicateurs, rapports et tableaux de bord et les actualiser ;
Accompagner l'√©quipe Donn√©es Industrielles dans son d√©veloppement de comp√©tences.
Superviser les projets d'am√©lioration de l'outil industriel en respectant les objectifs de co√ªts, qualit√© et d√©lais.
Profil
Apportez vos comp√©tences :
Issu d'une formation Ing√©nieur g√©n√©raliste ou master en gestion de donn√©es industrielles, vous justifiez d'une exp√©rience similaire r√©ussie de minimum 3 ans.
Vous poss√©dez de bonnes connaissances en ERP et vous ma√Ætrisez les outils d'extraction et de traitement de base de donn√©es. Vous avez d√©j√† eu une exp√©rience en gestion de projet. Vous √™tes p√©dagogue et un bon communicant.
Rencontrons-nous
Vous √™tes disponible imm√©diatement ? Si vous vous reconnaissez dans les missions et le profil, n'h√©sitez plus et postulez.
Nous pourrons √©changer √† propos de votre projet et dessiner ensemble votre avenir professionnel !
Show more
Show less","{'ProgLanguage': ['R', 'Go'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': ['Tableau'], 'Statistics': [], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': [], 'FrSoftSkills': ['Collaboration'], 'EnSoftSkils': ['Collaboration']}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's', '3', '3', '3']}"
Senior Data Engineer - Rennes - I&D (H/F),Capgemini,"Rennes, Brittany, France",https://fr.linkedin.com/jobs/view/senior-data-engineer-rennes-i-d-h-f-at-capgemini-3907763489?position=9&pageNum=15&refId=WygPS3lGVIiC9LmdVGUPqQ%3D%3D&trackingId=G7viAH9wdKGhtwRaTs0RtQ%3D%3D&trk=public_jobs_jserp-result_search-card,"Description de l'entreprise
Capgemini est un leader mondial, responsable et multiculturel, regroupant 270 000 personnes dans pr√®s de 50 pays.
Partenaire strat√©gique des entreprises pour la transformation de leurs activit√©s en tirant profit de toute la puissance de la technologie, le Groupe est guid√© au quotidien par sa raison d‚Äô√™tre : lib√©rer les √©nergies humaines par la technologie pour un avenir inclusif et durable.
Fort de plus de 50 ans d‚Äôexp√©rience et d‚Äôune grande expertise des diff√©rents secteurs d‚Äôactivit√©, Capgemini est reconnu par ses clients pour r√©pondre √† l‚Äôensemble de leurs besoins, de la strat√©gie et du design jusqu‚Äôau management des op√©rations, en tirant parti des innovations dans les domaines en perp√©tuelle √©volution du cloud, de la data, de l‚ÄôIntelligence Artificielle, de la connectivit√©, des logiciels, de l‚Äôing√©nierie digitale et des plateformes. Le Groupe a r√©alis√© un chiffre d'affaires de 16 milliards d'euros en 2020.
Dans ce contexte, notre practice Insights & Data (I&D) s‚Äôappuie sur une √©quipe de 1300 personnes qui supporte nos clients de tous les secteurs dans leur transformation data. Cette √©quipe combine des comp√©tences m√©tiers avec une forte expertise data, analytique et d‚Äôintelligence artificielle pour mettre en ≈ìuvre des solutions qui visent √† am√©liorer la gestion et la valorisation des donn√©es.
Description de la mission
Vous int√©grez une communaut√© d‚Äôexperts passionn√©s reconnus par nos clients sur des technologies de pointe (Google Cloud Platform, Azure, AWS)
Vous interagissez au plus proche de nos clients, des partenaires pour concevoir et mettre en ≈ìuvre des solutions/projets innovants et comp√©titifs
Vous r√©pondez aux probl√©matiques de nos clients en proposant la meilleure plateforme data dans un environnement Agile
Vous avez acquis de l‚Äôexp√©rience sur les cadres de r√©f√©rence et patterns d‚Äôarchitecture Data, DevOps
Vous adaptez chaque architecture en fonction du contexte gr√¢ce √† votre maitrise des caract√©ristiques fondamentales de chaque solution (catalogue des offres de services manag√©s, performance, s√©curit√©, d√©ploiement des data centers ‚Ä¶)
Vous utilisez les solutions d‚Äôint√©gration associ√©es et les solutions d√©cisionnelles ainsi qu‚Äôanalytiques qui viennent consommer les donn√©es manipul√©es
Vous √™tes en mesure d‚Äôencadrer les √©quipes dans la mise en place des architectures pr√©conis√©es et/ ou des plateformes Data
Pourquoi nous rejoindre ?
En plus de votre quotidien, vous pourrez entreprendre, √™tre form√©, utiliser nos incubateurs pour innover, et vous dessiner une trajectoire de carri√®re personnalis√©e.
Vous int√©grerez une √©quipe ambitieuse, fun et dynamique !
Une culture forte et bienveillante, et une grande place laiss√©e √† la libert√©
Des clients vari√©s, leaders de leur secteur
Une approche pragmatique, qui r√©pond aux vrais enjeux des entreprises
Un v√©ritable accompagnement dans l‚Äô√©volution de votre carri√®re
Une √©quipe √† taille humaine, en renouvellement et en hyper croissance
Une priorit√© accord√©e au d√©veloppement des collaborateurs ‚Äì un management qui aide les √©quipes √† progresser, √† r√©ussir
Pas de profil type chez Capgemini, mais quelques ingr√©dients pour laisser la magie op√©rer ... !
Dipl√¥m√©(e) de Bac+5 en informatique, vous comptez au moins 6 ans d‚Äôexp√©rience (au sein d‚Äôune ESN ou chez un int√©grateur) en conseil client√®le et une solide culture technologique, un bon niveau d‚Äôanglais.
Vous avez des qualit√©s de p√©dagogue, et pour vous la transmission de comp√©tences fait partie de votre quotidien actuel. La phase d‚Äôavant-vente vous int√©resse.
CAPGEMINI, Entreprise handi accueillante, conform√©ment √† la norme AFNOR NF X50-783, est √©galement signataire de la charte de la diversit√© en entreprise
Show more
Show less","{'ProgLanguage': ['R', 'Go'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': ['AWS', 'Azure', 'Google Cloud Platform'], 'DevTools': ['Git'], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['DevOps', 'Cloud'], 'FrSoftSkills': [], 'EnSoftSkils': []}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': ['Bac+5'], 'Experience': ['a', 'n', 's', '50', '50', '50']}"
Data Engineer (h/f),emagine,"Toulouse, Occitanie, France",https://fr.linkedin.com/jobs/view/data-engineer-h-f-at-emagine-3902565294?position=10&pageNum=15&refId=WygPS3lGVIiC9LmdVGUPqQ%3D%3D&trackingId=JuMAL3bOsE0qxrG2Ze3umg%3D%3D&trk=public_jobs_jserp-result_search-card,"emagine recherche pour son client final grand compte, un(e) Data Engineer.
Lieu : Toulouse
D√©marrage : D√©but Juin
Conditions : Full remote - 1 √† 2 jours/mois sur site
La mission consiste √† piloter la partie Data du projet de migration du SI Catering. La mission sera centr√©e sur la continuit√© du Data Warehouse Catering dans le contexte de migration du SI vers un nouvel √©diteur.
L‚Äôenvironnement est en BI traditionnelle avec un usage fr√©quent de Qlikview et PowerBI.
Vous int√©grerez une √©quipe BI de 13 personnes (12 d√©veloppeurs et un charg√© de
produit).
Comp√©tences attendues :
Tr√®s bon niveau en conception
Tr√®s bon niveau SQL et informatica
Connaissance de Qlikview
Grande autonomie et grande app√©tence √† comprendre les enjeux techniques et fonctionnels de l‚Äôenvironnement pour proposer des solutions adapt√©es.
App√©tence pour le fonctionnel
Exp√©rience probante en design d‚Äôarchitecture data
Si cette mission vous correspond et vous int√©resse, vous pouvez me joindre au +33 6 46 85 54 21
K√©vin GALLAIS
Show more
Show less","{'ProgLanguage': ['R'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': ['PowerBI'], 'Statistics': [], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': [], 'FrSoftSkills': [], 'EnSoftSkils': []}","{'JobDetail': ['Remote', 'Full'], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's']}"
