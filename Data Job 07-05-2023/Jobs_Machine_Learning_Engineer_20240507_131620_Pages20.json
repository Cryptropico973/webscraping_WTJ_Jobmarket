[
    {
		"source": "LinkedIn",
        "title": "APPRENTI.E DATA SCIENTIST",
        "company": "Akademija Oxford",
        "location": "Val-De-Marne, \u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/apprenti-e-data-scientist-at-akademija-oxford-3917870308?position=2&pageNum=0&refId=yQtK%2BQI72QI4xq%2BIXLe7ew%3D%3D&trackingId=jc8E23Lh1rAPK0uaxTqX8Q%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Une des entreprises leader sur le march\u00e9 de la sant\u00e9, situ\u00e9e dans le Val-De-Marne, recherche un.e Apprenti.e Data Scientist dans le cadre d\u2019un contrat d\u2019apprentissage et pour un d\u00e9marrage en Octobre 2021.\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "R"
            ],
            "DataBase": [],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [],
            "DevTools": [],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [],
            "FrSoftSkills": [],
            "EnSoftSkils": []
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "Data Scientist AI",
        "company": "Cephalgo",
        "location": "France",
        "link": "https://fr.linkedin.com/jobs/view/data-scientist-ai-at-cephalgo-3817203204?position=3&pageNum=0&refId=yQtK%2BQI72QI4xq%2BIXLe7ew%3D%3D&trackingId=%2FMsr%2BzIYJWA3gNVxjpMtVg%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "The ideal candidate's favorite words are learning, data, scale, and agility. You will leverage your strong collaboration skills and ability to extract valuable insights from highly complex data sets to ask the right questions and find the right answers.\nResponsibilities\nCollect, process, and clean data from diverse sources to prepare it for analysis, ensuring consistency and reliability\nAnalyze raw data: assessing quality, cleansing, structuring for downstream processing and applying machine learning (ML) and deep learning (DL) techniques\nA focus on quantitative analytics and data modeling.\nDesign accurate and scalable prediction algorithms\nEnsuring scalable ML/DL pipeline construction\nImplementing data storage solutions that optimize for volume, velocity, and variety of EEG data\nCollaborate with the team to bring analytical prototypes to production\nStay up-to-date with the latest technologies and trends in data science and machine learning\nQualifications\nMaster's degree or equivalent experience in Computer Science\nAt least 2 years' of experience in DL, quantitative analytics and data modeling\nA strong statistical and programming background\nExperienced in MLOP pipeline construction and big data technologies like Spark, MLFlow, Snowflake, Hadoop for hosting the data\nDeep understanding of predictive modeling, machine-learning, clustering and classification techniques, and algorithms\nFluency in a programming language (Python, C,C++, Java, SQL)\nExcellent problem-solving skills and ability to work independently or as part of a team\nExperienced in working interdisciplinary tasks\nWe Offer\nCompetitive salary and benefits package\nA collaborative work environment with a supportive team\nOpportunities for professional growth and development\nAccess to the latest tools and technologies.\nFlexible working hours and remote work options\nCEPHALGO focuses on introducing technological innovations to assist medical professionals to provide better mental health care. Located in Strasbourg, extended beyond Europe, CEPHALGO\u2019s patient monitoring technique using EEG and AI has been applied in psychiatry across Europe. Further information can be found at https://cephalgo.com.\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "Java",
                "C++",
                "Scala",
                "R",
                "Go"
            ],
            "DataBase": [
                "SQL"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [
                "Hadoop",
                "Spark"
            ],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [],
            "DevTools": [],
            "Os": [],
            "DBMS": [
                "Snowflake",
                "Snowflake"
            ],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [
                "Big Data",
                "ML",
                "Machine Learning"
            ],
            "FrSoftSkills": [
                "Collaboration"
            ],
            "EnSoftSkils": [
                "Collaboration"
            ]
        },
        "details": {
            "JobDetail": [
                "Remote"
            ],
            "TypeContract": [],
            "Salary": [
                "Salary",
                "Package"
            ],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "Machine Learning Engineer",
        "company": "Homa",
        "location": "Paris, \u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/machine-learning-engineer-at-homa-3904059928?position=4&pageNum=0&refId=yQtK%2BQI72QI4xq%2BIXLe7ew%3D%3D&trackingId=M2ZC1odjrRSebrnghqCEFQ%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Welcome to Homa, the gaming technology lab that is taking the industry by storm! Our team of over 200 people, hailing from more than 35 different countries, is dedicated to empowering mobile game creators worldwide to bring their creative ideas to the top charts.\nOur Homa Lab platform offers a comprehensive suite of cutting-edge tools that allow developers to stay on top of the latest trends, test new features in real-time, and easily distribute and monetize their games. Our success speaks for itself - our apps have been downloaded over 1 billion times!\nSince our inception, we have raised $165 million in total from prominent investors, including Headline, Northzone, Eurazeo, Singular, Quadrille Capital, Fabric Ventures, and Bpifrance. We have also received support from renowned business angels, such as the founders of King, Sorare and Spotify founders.\nBut what really makes Homa special is our team. We are a diverse group of artists, business developers, engineers, entrepreneurs, and former strategy consultants who all share the same passion for taking over the gaming industry. When you become part of Homa, you'll be joining a dedicated team that creates innovative and high-performing games that resonate with players worldwide.\nIf you're ready to take your career to the next level and make a real impact in the company, then Homa is the perfect place for you. Join us and let's create the future of gaming together!\nMeet the team\n\ud83d\udc69\u200d\ud83d\udc69\u200d\ud83d\udc67\u200d\ud83d\udc67\nYou will join the Data department organized into:\nA Data Platform team with 5 Data Engineers responsible for ingesting large amounts of data from multiple different sources, creating and maintaining a core data model which aims at making data standardized, reliable and easily available\nA Data Science and ML Platform team with 6 Data Scientists / ML Engineer working on ML-driven data products: Autobidder for User Acquisition, N-Testing for experimentation\nAn Advanced Analytics & Data Science team with 6 Data Analysts and Scientists exploiting our data for:\nGame Analytics\nUser Acquisition and Marketing Analytics\nMarket Inteligence Analytics\nOps Analytics\nRole and Missions \u2014 What you will do\n\ud83d\ude80\nWe are looking for a Machine Learning Engineer to join the team in order to scale and industrialize Machine Learning & AI at Homa. Under the responsibility of our Associate Director, your responsibilities will be the following:\nTake part in ML Projects: Spearhead development and implementation of ML models for Marketing Tech (User Acquisition, Monetization) and Game Tech (Bayesian A/B Testing, Segmentation)\nML Industrialization & Democratization: Enhance ML engineering processes, adopt ML Ops tools, and contribute to model interpretability and collaborative efforts\nImplement Scalable ML Solutions: Build Serving APIs for handling millions of requests daily with low latency\nCollaborative Innovation: Work closely with diverse teams, leveraging GenAI tools for productivity and product improvements\nStay Updated: Integrate latest ML technologies and advancements into our tech stack\nCurrent Tech Stack: AWS, Redshift, Databricks, Python, DBT, Spark, Airflow, Kafka, Kubernetes, LightGBM, MLFlow, Metabase\nRequirements\nIf you're creative, ambitious, and up for taking over the industry, we want you on our team! We are also looking for:\nFirst ML Experience: :2 years in implementing and deploying ML models to production\nKey Technology Proficiency: Experience in Neural Networks (TensorFlow / PyTorch), Gradient Boosting libraries (LightGBM / XGBoost), and at least one top Cloud provider (GCP, Azure, AWS)\nMLOps Skills: Knowledge of ML Ops tools like MLFlow\nAPI Development Expertise: Ability in building high-performance Serving APIs\nCollaborative Skills: Excellent communication and teamwork abilities\nInnovative Mindset: Passion for staying ahead in ML trends and technologies\nLanguage Skills: Fluency English is mandatory (interviews will be led in English)\nOur Culture\u2014Who we are\n\ud83e\ude90\nAt Homa, we are building a community of brilliant talents. We believe that true innovation comes from diversity and collaboration, and that's why we prioritize brainpower and determination over formal education. So if you have the talent, energy and motivation, there is no obstacle to your success here.\nAs the creative experts behind the platform, we provide developers with the data they need to bring their ideas to life. Our team lives by three central values that guide everything we do:\n\u2728\nAmbition\n: we're not afraid to tackle difficult challenges and set our goals extremely high. We're on a mission to revolutionize an industry dominated by well-established companies, and we won't stop until we succeed.\n\u2728\nHumility\n: we leave our pride & ego aside. We are always ready to lend a helping hand, celebrate each other's successes, and learn from our failures. As Mr. Lamar said, \"Sit down. Be humble.\"\n\u2728\nCuriosity\n: we keep our minds open and never stop learning. We believe that questioning everything is the best way to stay ahead of the curve, and we encourage all our team members to stay curious and never stop exploring new ideas.\nAt Homa, you'll be challenged, supported, and inspired every day, and we can't wait to see what you bring to the table.\nBenefits\nWhile success is its own reward, here are some of the benefits that come with working at Homa:\nWe offer essential benefits in France and specific locations, including health insurance, meal vouchers, public transport subsidies, childcare benefits, and life insurance\nIf you're interested in working from our newly renovated Paris HQ with a rooftop garden and WeWork amenities, we have a desk waiting for you\nYou will be working in English with our international team of top-tier talents from 35+ countries\nYou will have bi-annual reviews with your manager to reflect on your performance, celebrate wins, and receive constructive feedback\nYou will be able to attend diverse team events and Workations (the famous company-wide Homa trip)\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "Scala",
                "R",
                "Go"
            ],
            "DataBase": [],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [
                "Spark",
                "Databricks"
            ],
            "MachingLearning": [
                "TensorFlow",
                "PyTorch",
                "XGBoost",
                "LightGBM"
            ],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [
                "AWS",
                "Azure"
            ],
            "DevTools": [],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [
                "Kubernetes",
                "Airflow"
            ],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [
                "Kubernetes"
            ],
            "Collaboration": [
                "Teams"
            ],
            "Other": [
                "ML",
                "Machine Learning",
                "Cloud"
            ],
            "FrSoftSkills": [
                "Communication",
                "Collaboration"
            ],
            "EnSoftSkils": [
                "Communication",
                "Teamwork",
                "Collaboration"
            ]
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "ML Engineer Intern",
        "company": "Quack AI (YC S23)",
        "location": "Paris, \u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/ml-engineer-intern-at-quack-ai-yc-s23-3822705279?position=5&pageNum=0&refId=yQtK%2BQI72QI4xq%2BIXLe7ew%3D%3D&trackingId=InfLwcDonZtcUdLfeNQdaw%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "You will be the first member of the ML team and will grow along with it. As such, your responsibilities will start in model improvement but grow with our internal team & open-source research. During your internship, you will: - establish a coherent way to evaluate our models on code-related tasks that are relevant for actual usage - fine-tune LLMs for code-related tasks (can't make promises about training from scratch) - integrate or create rich new datasets to feed into your training experiments - Work with other teammates to integrate the models you trained in Quack products\nAbout You\nAs an engineer, you have a disturbing obsession with making something useful, not something shiny. Your curious nature makes you excited about modern technologies and tools (e.g. ChatGPT and/or GitHub Copilot are in your daily toolset). Your peers describe you as humble, and you make sure to always learn new things however experienced you may be. This drives you not to shy away from community/user feedback, but instead to seek the hard truth and iterate.\nIn short, you will probably be a good fit if you: - have already founded or intend to found a startup at some point - spend more time on your favorite newsfeed (e.g. Twitter, GitHub) browsing the latest models and research papers. Although given the choice, you'd prefer to share your model checkpoint and your code publicly, rather than spending weeks writing the research paper for citations. - have experience with deep learning frameworks (PyTorch), NLP (Transformers, etc.) and GPUs (e.g. you've seem OOM & you know a few tricks to mitigate them). - you have already trained or finetuned deep learning models (computer vision or NLP) and you're also comfortable running inference with LLMs (not 3rd party API). - are comfortable using Python (more than Jupyter notebooks) and GitHub, you focus on results but you don't leave a mess behind. Open-source experience is big plus.\nPlease note we only consider internships onsite, for a period of 5-6 months! The internship is meant to lead to a full-time position.\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "R",
                "Go"
            ],
            "DataBase": [],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [],
            "MachingLearning": [
                "PyTorch"
            ],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [],
            "DevTools": [
                "Git"
            ],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [
                "ML"
            ],
            "FrSoftSkills": [],
            "EnSoftSkils": []
        },
        "details": {
            "JobDetail": [
                "Full"
            ],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "Data Scientist - Payment Success",
        "company": "Checkout.com",
        "location": "Paris, \u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/data-scientist-payment-success-at-checkout-com-3903448233?position=6&pageNum=0&refId=yQtK%2BQI72QI4xq%2BIXLe7ew%3D%3D&trackingId=xy%2FVSUwKWskFiToypwkeAA%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Company Description\nCheckout.com is one of the most exciting fintechs in the world. Our mission is to enable businesses and their communities to thrive in the digital economy. We\u2019re the strategic payments partner for some of the best known fast-moving brands globally such as Wise, Hut Group, Sony Electronics, Homebase, Henkel, Klarna and many others. Purpose-built with performance and scalability in mind, our flexible cloud-based payments platform helps global enterprises launch new products and create experiences customers love. And it's not just what we build that makes us different. It's how.\nWe empower passionate problem-solvers to collaborate, innovate and do their best work. That\u2019s why we\u2019re on the Forbes Cloud 100 list and a Great Place to Work accredited company. And we\u2019re just getting started. We\u2019re building diverse and inclusive teams around the world \u2014 because that\u2019s how we create even better experiences for our merchants and our partners. And we need your help. Join us to build the digital economy of tomorrow.\nJob Description\nAbout the opportunity:\nWe empower businesses in the digital economy, and we know that every payment counts. Our Payment Performance team\u2019s mission is to manage and optimise merchants\u2019 payment flow, to achieve optimal conversion, compliance and cost.\nCheckout.com is looking for a data scientist to automate research and investigations tailored for our Tier-1 merchants. This role encompasses the development of automation tools for monitoring, including dashboards and auto-generated presentations, as well as in-depth diagnostic solutions powered by machine learning and recommendation engines.\nYou will also work closely with Payment Performance Managers to ensure the delivery of a high level of service to our key merchants, underpinned by data-driven expertise. The ideal candidate must be a driven technologist with an affinity for problem solving and creating new tools.\nWhat you'll be doing:\nConduct deep-dive exploratory data analysis to uncover insights and anomalies\nDevelop cutting-edge automation tools aimed at monitoring and optimising merchants\u2019 performance\nCreate intuitive, real-time dashboards and reports to provide merchant performance visibility, enabling data-driven decision-making\nPropose enhancements of existing processes/tools by utilising statistical and machine learning techniques\nEffectively communicate research findings to both technical and non-technical stakeholders through reports and presentations\nQualifications\n2+ years experience as data scientist, working with large and diversified data sets\nBachelor\u2019s degree, preferably in Mathematics / Statistics / Computer Science / Engineering, Finance or equivalent\nSQL/ Python knowledge to extract & analyse data from our Data Warehouse\nExperience with Git & Spark, Databricks, Retool, API\nAbility to find creative and effective solutions for business problems\nFlexible, adaptable and has a willingness to learn\nPayments or Fintech experience is a plus\nIf you don't meet all the requirements but think you might still be right for the role, please apply anyway. We're always keen to speak to people who connect with our mission and values\nIf possible, please submit CVs in English.\nAdditional Information\nApply without meeting all requirements statement\nIf you don't meet all the requirements but think you might still be right for the role, please apply anyway. We're always keen to speak to people who connect with our mission and values.\nWe believe in equal opportunities\nWe work as one team. Wherever you come from. However you identify. And whichever payment method you use.\nOur clients come from all over the world \u2014 and so do we. Hiring hard-working people and giving them a community to thrive in is critical to our success.\nWhen you join our team, we\u2019ll empower you to unlock your potential so you can do your best work. We\u2019d love to hear how you think you could make a difference here with us.\nWe want to set you up for success and make our process as accessible as possible. So let us know in your application, or tell your recruiter directly, if you need anything to make your experience or working environment more comfortable. We\u2019ll be happy to support you.\nTake a peek inside life at Checkout.com via\nOur Culture video https://youtu.be/BEwnpHuadSw\nOur careers page https://www.checkout.com/careers\nOur LinkedIn Life pages bit.ly/3OaoN1U\nOur Instagram https://www.instagram.com/checkout_com/\nApply Without Meeting All Requirements Statement\nIf you don't meet all the requirements but think you might still be right for the role, please apply anyway. We're always keen to speak to people who connect with our mission and values.\nWe believe in equal opportunities\nWe work as one team. Wherever you come from. However you identify. And whichever payment method you use.\nOur clients come from all over the world \u2014 and so do we. Hiring hard-working people and giving them a community to thrive in is critical to our success.\nWhen you join our team, we\u2019ll empower you to unlock your potential so you can do your best work. We\u2019d love to hear how you think you could make a difference here with us.\nWe want to set you up for success and make our process as accessible as possible. So let us know in your application, or tell your recruiter directly, if you need anything to make your experience or working environment more comfortable. We\u2019ll be happy to support you.\nTake a peek inside life at Checkout.com via\nOur Culture video https://youtu.be/BEwnpHuadSw\nOur careers page https://www.checkout.com/careers\nOur LinkedIn Life pages bit.ly/3OaoN1U\nOur Instagram https://www.instagram.com/checkout_com/\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "Scala",
                "R"
            ],
            "DataBase": [
                "SQL"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [
                "Spark",
                "Databricks"
            ],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [
                "Statistics"
            ],
            "CloudComputing": [],
            "DevTools": [
                "Git"
            ],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [
                "Teams"
            ],
            "Other": [
                "Machine Learning",
                "Cloud"
            ],
            "FrSoftSkills": [],
            "EnSoftSkils": [
                "Problem Solving"
            ]
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "Data Scientist F/H (IA)",
        "company": "Renault Digital",
        "location": "Boulogne-Billancourt, \u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/data-scientist-f-h-ia-at-renault-digital-3885142754?position=7&pageNum=0&refId=yQtK%2BQI72QI4xq%2BIXLe7ew%3D%3D&trackingId=D4tAhj%2BOSjCEsMs94Et8sg%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Le groupe RENAULT entre dans une nouvelle \u00e8re gr\u00e2ce \u00e0 la strat\u00e9gie RENAULuTion qui place\nL\u2019IA\nau c\u0153ur de notre business. Renault Digital, cr\u00e9\u00e9 en 2017, est un acteur incontournable de ce nouveau cycle et participe activement \u00e0 relever les challenges des nouvelles mobilit\u00e9s et de l\u2019industrie 4.0\nContexte :\nVous travaillez au sein du Centre d\u2019excellence IA, dans une \u00e9quipe de 30 data Scientists et data Analysts dont les missions principales sont d\u2019une part la r\u00e9alisation d\u2019enablers IA permettant de d\u00e9ployer l\u2019IA \u00e0 l\u2019\u00e9chelle dans le groupe, et d\u2019autre part de participer \u00e0 la r\u00e9alisation de projets m\u00e9tiers en collaboration avec les \u00e9quipes data sciences locales. Vous serez garant(e) de la valeur ajout\u00e9e de la donn\u00e9e et de l\u2019intelligence artificielle appliqu\u00e9e dans les processus m\u00e9tiers.\nLe/la Data Scientist\nIA est charg\u00e9(e) d'animer une \u00e9quipe multidisciplinaire compos\u00e9e de Data Scientists, d'Ing\u00e9nieurs Data, de DevOps et de D\u00e9veloppeurs.\nSa mission principale, dans un premier temps, sera d'explorer et de benchmarker les solutions dans le domaine de GEN AI et LLM, et de faciliter leur int\u00e9gration rapide dans l'architecture existante du groupe RENAULT. Le/la Data Scientist IA travaillera \u00e9galement en \u00e9troite collaboration avec l'\u00e9cosyst\u00e8me externe, y compris les laboratoires de recherche, les IRT et les soci\u00e9t\u00e9s du CAC 40.\nResponsabilit\u00e9s principales :\nVous animez une \u00e9quipe multidisciplinaire compos\u00e9e de Data Scientists, d'Ing\u00e9nieurs Data, de DevOps et de D\u00e9veloppeurs.\nVous explorez et benchmarkez les solutions existantes dans le domaine de GEN AI et LLM.\nVous facilitez l'int\u00e9gration rapide de ces solutions dans l'architecture existante de RENAULT.\nVous d\u00e9veloppez une strat\u00e9gie pour l'adoption et l'int\u00e9gration des nouvelles technologies IA.\nVous g\u00e9rez toutes les activit\u00e9s du Lab IA, y compris la planification et le suivi du budget.\nVous collaborez avec d'autres d\u00e9partements et \u00e9quipes pour garantir l'alignement des activit\u00e9s du Lab IA, avec les objectifs strat\u00e9giques de RENAULT.\nVous travaillez en \u00e9troite collaboration avec l'\u00e9cosyst\u00e8me externe, y compris les laboratoires de recherche, les IRT et les soci\u00e9t\u00e9s du CAC 40.\nProfil recherch\u00e9 :\nVous \u00eates dipl\u00f4m\u00e9(e) d\u2019une \u00e9cole d\u2019ing\u00e9nieur avec une sp\u00e9cialisation Machine Learning ou PHD en ML.\nVous disposez de minimum 7 ans d\u2019exp\u00e9rience en tant que Data Scientist.\nVous avez une exp\u00e9rience r\u00e9ussie dans l\u2019animation d'\u00e9quipes techniques.\nVous poss\u00e9dez une exp\u00e9rience dans l'exploration et le benchmarking de solutions IA.\nVous \u00eates capable de collaborer efficacement avec une \u00e9quipe multidisciplinaire.\nVous poss\u00e9dez une exp\u00e9rience / ou capacit\u00e9 d\u00e9montr\u00e9e \u00e0 travailler en collaboration avec des laboratoires de recherche, des IRT et des soci\u00e9t\u00e9s du CAC 40.\nVous avez une capacit\u00e9 d\u2019\u00e9coute et de compr\u00e9hension de probl\u00e9matiques business vari\u00e9es (industrie 4.0, marketing, engineering, qualit\u00e9, apr\u00e8s-vente, \u2026).\nVous \u00eates capable de vulgariser et pr\u00e9senter de nouvelles approches et simplifier les r\u00e9sultats.\nVous disposez d\u2019une connaissance approfondie des technologies GEN AI et LLM et en particulier des architectures RAG.\nVous avez des connaissances approfondies des algorithmes de machine learning (clustering, classification, r\u00e9gression, d\u00e9tection d\u2019anomalie, optimisation de mod\u00e8les, traitement d\u2019images et de langage naturel avec du deep learning).\nVous avez une exp\u00e9rience avec au moins l'un des langages de programmation suivants : Python (obligatoire), SQL (obligatoire), R, Scala ou Java.\nVous poss\u00e9dez une exp\u00e9rience sur des frameworks de Machine Learning bien connus : Scikit-learn, TensorFlow/Keras, TFx, PyTorch (un plus) \u2026\nVous avez une exp\u00e9rience en industrialisation de syst\u00e8mes de machine learning.\nVous disposez d\u2019une exp\u00e9rience avec Docker, et un orchestrateur (kubeflow, airflow \u2026), kubernetes, Git, Gitlab CI/CD (un plus).\nVous utilisez Google Cloud Platform (Storage, BigQuery, Dataproc, Dataflow, AI Platform, \u2026).\nVous avez des connaissances sur les outils DevOps pour AI et ML (MLOps).\nVous \u00eates capable d\u2019\u00e9changer en anglais technique \u00e9crit et oral.\nInformations compl\u00e9mentaires :\nVotre poste sera bas\u00e9 \u00e0 Boulogne-Billancourt (France) en CDI (temps plein)\nVous b\u00e9n\u00e9ficiez de 2 \u00e0 3 jours de t\u00e9l\u00e9travail par semaine\nVous \u00eates pr\u00eat(e)s \u00e0 relever avec nous tous ces d\u00e9fis, n\u2019h\u00e9sitez pas \u00e0 postuler !!\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "Java",
                "Scala",
                "R",
                "Go"
            ],
            "DataBase": [
                "SQL"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [],
            "MachingLearning": [
                "Scikit-Learn",
                "TensorFlow",
                "Keras",
                "PyTorch"
            ],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [
                "Google Cloud Platform"
            ],
            "DevTools": [
                "Git",
                "Docker"
            ],
            "Os": [],
            "DBMS": [
                "BigQuery"
            ],
            "SoftBigDataProcessing": [],
            "Automation": [
                "Kubernetes",
                "Airflow"
            ],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [
                "Docker",
                "Kubernetes"
            ],
            "Collaboration": [],
            "Other": [
                "DevOps",
                "ML",
                "Machine Learning",
                "Cloud",
                "CI/CD"
            ],
            "FrSoftSkills": [
                "Collaboration"
            ],
            "EnSoftSkils": [
                "Collaboration"
            ]
        },
        "details": {
            "JobDetail": [
                "Temps plein"
            ],
            "TypeContract": [
                "CDI"
            ],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s",
                "7",
                "7",
                "7"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "Machine Learning Scientist/Engineer",
        "company": "NuMind (YC S22)",
        "location": "Paris, \u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/machine-learning-scientist-engineer-at-numind-yc-s22-3856851886?position=8&pageNum=0&refId=yQtK%2BQI72QI4xq%2BIXLe7ew%3D%3D&trackingId=LL81pl8bl8cr3KGq4PTOUg%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "About Us\nNuMind (https://www.numind.ai/) is a software company developing a tool to create custom NLP models specialized in information extraction (see\u00a0https://www.youtube.com/watch?v=MQhYe5HXqss). We also develop open-source foundation models (https://huggingface.co/numind), and write research papers (see https://arxiv.org/abs/2402.15343).\nWe aim to become leader in the field of custom information extraction.\nWe are a team of 7: CEO, CTO, COO, 2 senior software engineers, and 2 machine learning scientists. Our CEO was head of ML at Wolfram Research and our CTO co-founded\u00a0Make.org.\nMost of the team are located in France (Paris).\nWe were part of YCombinator\u2019s S22 batch, and raised a good seed round.\nJob Description\nNuMind is a tool to create NLP models (e.g. classifiers and entity recognizers). The user provides information about the task (e.g. by labeling documents), and the computer creates models automatically.\nYour job will be to make this happen in the most effective way. This will involve designing & testing various machine learning solutions, and implementing these solutions directly into NuMind.\nR&D topics include:\nTransfer learning, few-shot learning\nActive learning\nAutomatic machine learning\nPerformance measurements\nDistillation\nProbability calibration\nOut-of-domain robustness\nModel explanations\nThis position is for someone who has both a researcher and engineer mindset.\nResponsibilities\nTraining task-specific foundation models\nSetting up benchmarks to test ML solutions\nIdentifying & testing existing ML solutions\nDesigning & testing new ML solutions from scratch\nImplementing selected solutions into the product\nStaying up to date with relevant NLP research\nQualifications\nExpert-level understanding of machine learning.\nAbility to design, train, test deep learning models\nAbility to conduct machine learning research (e.g. conducting experiments, drawing conclusions, communicating results)\nAbility to develop production-grade code\nGood understanding of the following field: statistics, computer science (esp. data structures & algorithms), and numerical analysis\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "R",
                "Go"
            ],
            "DataBase": [],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [
                "Statistics"
            ],
            "CloudComputing": [],
            "DevTools": [],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [
                "ML",
                "Machine Learning"
            ],
            "FrSoftSkills": [],
            "EnSoftSkils": []
        },
        "details": {
            "JobDetail": [
                "Senior"
            ],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "Machine Learning Engineer",
        "company": "HackerPulse",
        "location": "France",
        "link": "https://fr.linkedin.com/jobs/view/machine-learning-engineer-at-hackerpulse-3917868826?position=9&pageNum=0&refId=yQtK%2BQI72QI4xq%2BIXLe7ew%3D%3D&trackingId=1QYto5w2S4fXMCqg%2BRO1Iw%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Showcase your software engineering talents using ML-powered profiles. Loved by 11k+ engineers! Backed by Antler.\nThe Role\nYou Will Be Responsible For\nDeveloping scripts to process structured and unstructured data.\nRecommending, developing and implementing ways to improve data reliability, efficiency and quality.\nSupporting translation of data business needs into technical system requirements.\nWorking with stakeholders to understand needs in order with respect to data structure, availability, scalability and accessibility.\nDeveloping high-quality code to build and deploy machine learning models.\nIdeal Profile\nYou possess a degree in Computer Science, Applied Mathematics, Engineering or related field.\nYou have at least 1 year experience, ideally within a Data Engineer role.\nDemonstrated experience working with large and complex data sets as well as experience analyzing volumes of data.\nYou are a strong networker & relationship builder\nYou pay strong attention to detail and deliver work that is of a high standard\nYou are a self-starter and demonstrate a high level of resilience\nWhat's on Offer?\nGreat work environment\nExcellent career development opportunities\nLeadership Role\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Scala",
                "R"
            ],
            "DataBase": [],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [],
            "DevTools": [],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [
                "ML",
                "Machine Learning"
            ],
            "FrSoftSkills": [
                "Leadership"
            ],
            "EnSoftSkils": [
                "Leadership"
            ]
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "Machine Learning Engineer",
        "company": "AXA Group Operations",
        "location": "Paris, \u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/machine-learning-engineer-at-axa-group-operations-3856840119?position=10&pageNum=0&refId=yQtK%2BQI72QI4xq%2BIXLe7ew%3D%3D&trackingId=aDMVjJOCXpYSYFyuB45cvw%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Ready to shape the future? Join our team as a Machine Learning Engineer Extraordinaire!\nAbout the job\nBased in Paris or Barcelona, you will be part of the Artificial Intelligence Engineering team, in the Group Emerging Technologies and Data (GETD) division of AXA. This transversal team\u2019s mission is both to build AI-powered initiatives (proofs of concept, proofs of value, pilots) with AXA entities & strategic partners and to define & implement MLOps best practices, tools, and collaboration models to be followed across the whole AXA Group. Our team is composed of 10 people, spread in 3 countries (France, Spain & Switzerland) and we work in hybrid mode (60% remote + 40% on-site).\nAXA is a global leader in insurance and asset management present in nearly 60 countries. We leverage Artificial Intelligence to protect our 100+ million customers, in every domain of core insurance (Property & Casualty, Life & Savings, Health, \u2026). As a responsible company, AXA defined and follows strong Responsible AI principles around robustness, interpretability, fairness, and sustainability.\nKey responsibilities\nIn this role, you will:\nBuild and improve reusable tools & modelling pipelines and support knowledge sharing across several teams.\nWork with Data Scientists to improve both technical and statistical performance of models.\nConvert the machine learning models into application program interfaces (APIs) so that other applications can use them in alignment with architecture & infrastructure standards.\nSecure and monitor ML processing, including safeguards, A/B testing, fault-tolerance, and failover.\nContribute to the definition and deployment of best practices in Machine Learning & MLOps,\nContribute to the sharing of knowledge and expertise through communities and working groups (internal and external).\nHelp the different actors of the organization (such as product managers and stakeholders) understand what results they gain from MLOps and best engineering practices in Data and AI.\nWhat is needed to succeed\nAs we want you to succeed in this role, here is a list of examples of key factors:\n4+ years of experience with DevOps: versioning (Git), containers (Docker/Kubernetes), CI/CD, Static analysis tools, \u2026\nProficiency in ML Ops and ML Engineering frameworks: experiment trackers (like mlFlow) & orchestrators (Airflow, Kubeflow, Sagemaker Pipeline)\nA practical knowledge in one of the popular ML Python libraries (TensorFlow, PyTorch, Keras, Scikit-Learn) and Open-Source libraries.\nA good understanding of Agile methodologies and a mindset of continuous improvement.\nAbility to articulate the results of your work for various audiences.\nGood communication in English and interpersonal skills for working in a multicultural work environment.\nPassion about solving challenging problems leveraging new technologies.\nNice to have\nHere are other elements we will consider:\n2+ years of experience in delivering and running ML models in production, using at least one of some of the main Big Data frameworks and platforms: Spark, Databricks, Snowflake, \u2026\nPractical knowledge in Infrastructure as code (Terraform, CloudFormation, \u2026).\nPractical knowledge of cloud services (Azure or Amazon Web Services).\nTheoretical knowledge in Event Driven Architecture (using Kafka, Event Hub, or Rabbit MQ).\nInsurance & Finance functional knowledge\nWhat we offer\nOn top of usual benefits, we also offer:\nHybrid working (60% remote + 40% on-site).\nGlobal communities of practice and 2 yearly global events gathering Engineers and Data Scientists.\nLearning and mentoring opportunities through partnerships with LinkedIn Learning and O\u2019Reilly.\nAmong a strong Employee benefit program, mental health, and well-being platform to access personalised care.\nWe bring together the expertise, cultural diversity and creativity of over 8,000 employees worldwide. We\u2019re committed to equal opportunities in all aspects of employment (gender, LGBT+, disabled persons, or people of different origins) and to promoting Diversity & Inclusion by creating a work environment where all employees are treated with dignity and respect, and where individual differences are valued.\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "R",
                "Go"
            ],
            "DataBase": [],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [
                "Spark",
                "Databricks"
            ],
            "MachingLearning": [
                "Scikit-Learn",
                "TensorFlow",
                "Keras",
                "PyTorch"
            ],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [
                "Azure"
            ],
            "DevTools": [
                "Git",
                "Docker"
            ],
            "Os": [],
            "DBMS": [
                "Snowflake",
                "Snowflake"
            ],
            "SoftBigDataProcessing": [],
            "Automation": [
                "Kubernetes",
                "Airflow"
            ],
            "InfrastructureAsCode": [
                "Terraform",
                "CloudFormation"
            ],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [
                "Docker",
                "Kubernetes"
            ],
            "Collaboration": [
                "Teams"
            ],
            "Other": [
                "DevOps",
                "Big Data",
                "ML",
                "Machine Learning",
                "Cloud",
                "CI/CD"
            ],
            "FrSoftSkills": [
                "Communication",
                "Collaboration"
            ],
            "EnSoftSkils": [
                "Communication",
                "Creativity",
                "Collaboration",
                "Organization",
                "Initiative",
                "Interpersonal Skills"
            ]
        },
        "details": {
            "JobDetail": [
                "Remote"
            ],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "Data Scientist IA Gen",
        "company": "eXalt Value",
        "location": "\u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/data-scientist-ia-gen-at-exalt-value-3897781437?position=11&pageNum=0&refId=yQtK%2BQI72QI4xq%2BIXLe7ew%3D%3D&trackingId=HyYqh0IWgpGblFq6D%2BxjCQ%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "eXalt\nest un cabinet de conseil IT\nPure player Data\n& IA bas\u00e9 \u00e0 Paris (1er arrondissement).\nNotre offre s\u2019articule autour de 4 piliers r\u00e9unis au sein d\u2019une m\u00eame communaut\u00e9 pour un accompagnement \u00e0 360\u00b0 alliant une expertise technique et m\u00e9thodologique \u00e0 une approche conseil m\u00e9tier:\nData Gouvernance & Project\nData Engineering & Big Data\nData Performance & Analytics\nData Science & IA\nFiliale du groupe eXalt cr\u00e9\u00e9 en 2018,\nregroupant plus de\n950 collaborateurs en France\n(Paris, Lyon, Bordeaux, Lille, Nantes, Marseille)\net \u00e0 l\u2019international\n(Colombie, Etats-Unis, Espagne, Belgique),\neXalt Value\nd\u00e9montre une\nexpertise approfondie\ndans le domaine de la Data & IA et conseille les entreprises dans le d\u00e9ploiement de leurs strat\u00e9gies data-driven.\nB\u00e9n\u00e9ficiant de la renomm\u00e9e et des relations client du groupe eXalt\n(1er dans la cat\u00e9gorie Conseil & Audit au classement des Champions de la Croissance 2024), eXalt Value\nest en pleine croissance et regroupe aujourd\u2019hui une communaut\u00e9 d\u2019expertise de plus de 60 collaborateurs en r\u00e9gion parisienne.\nNos consultants interviennent sur d\nes projets d\u2019envergure stimulants\ndans divers secteurs d\u2019activit\u00e9, Banque & Assurance, M\u00e9dias, Transports, Retail, Tourisme, etc.\nNous recherchons un\nData Scientist IA Gen H/F\npour rejoindre notre communaut\u00e9 sur le\npilier Data Science & IA.\nVos missions:\nIdentifier les besoins sp\u00e9cifiques des diff\u00e9rentes \u00e9quipes, \u00e0 travers des ateliers d'id\u00e9ation, et proposer des solutions algorithmiques innovantes et adapt\u00e9es \u00e0 chaque situation.\nAnalyser les donn\u00e9es disponibles pour s\u00e9lectionner les mod\u00e8les d'IA les plus pertinents face aux besoins identifi\u00e9s, en tenant compte des particularit\u00e9s de chaque cas d'usage.\nD\u00e9velopper, tester et d\u00e9ployer les algorithmes des mod\u00e8les d'apprentissage automatique et des algorithmes avanc\u00e9s pour r\u00e9soudre des probl\u00e8mes complexes gr\u00e2ce \u00e0 des m\u00e9thodes statistiques, math\u00e9matiques et de machine learning.\nCollaborer avec les Data Engineer afin d\u2019int\u00e9grer les solutions IA dans les produits et les applications existants.\nExploiter les derni\u00e8res avanc\u00e9es en mati\u00e8re d'IA, notamment le Deep Learning, le Reinforcement Learning, le Traitement du Langage Naturel (NLP), la vision par ordinateur, etc., pour cr\u00e9er des solutions innovantes.\nConseiller les clients tout au long du cycle de vie des projets sur les solutions techniques les plus adapt\u00e9es \u00e0 leurs environnements.\nLes Pr\u00e9requis :\nTitulaire d'un Bac+5, id\u00e9alement Ecole d'Ing\u00e9nieur\nCompr\u00e9hension des enjeux business autours de\nl\u2019exploitation des donn\u00e9es et le d\u00e9ploiement des solutions IA\nMa\u00eetrise du\nMachine Learning et du Deep Learning,\ny compris des principaux frameworks (TensorFlow, PyTorch, Scikit-learn, Pandas, NumPy,) et des m\u00e9thodes statistiques.\nSolides connaissances de\nPython\n(Java, Spark, Scala sont un plus).\nAisance avec l'ensemble du cycle de vie de d\u00e9veloppement et de d\u00e9ploiement de mod\u00e8les d'IA (MLOps).\nExp\u00e9rience de travail en\nm\u00e9thode Agile\nCapacit\u00e9 \u00e0 travailler de mani\u00e8re autonome et en \u00e9quipe.\nExcellentes comp\u00e9tences en communication et pr\u00e9sentation.\nMa\u00eetrise de l\u2019anglais (oral & \u00e9crit dans un contexte international professionnel).\nVotre environnement eXalt\u00e9:\nRejoindre\neXalt Value\n, c\u2019est \u00e9galement :\nUn Lab IA\nau sein duquel vous pourrez exp\u00e9rimenter les divers outils et techniques, autour de use cases internes et externes.\nUn environnement de travail Collaboratif\nfavorisant les initiatives et projets transverses \u00e0 la Practice Data & IA (Data Hub, etc ;)\nUn collectif de consultants passionn\u00e9s,\ns\u2019int\u00e9ressant aux tendances innovantes du secteur\nUne Practice de proximit\u00e9,\nprivil\u00e9giant la mont\u00e9e en comp\u00e9tence de ses collaborateurs (formations, coachings, mentorats, etc.)\nUn suivi individualis\u00e9 et de proximit\u00e9\npar un.e Data Sales Manager r\u00e9f\u00e9rent du compte client, un.e Charg\u00e9.e RH et un.e Practice Manager\nUne \u00e9quipe sympa et dynamique,\nqui privil\u00e9gie des moments de partage (s\u00e9minaires, eXaltemps, meet-ups, d\u00e9jeuners d\u2019\u00e9quipe, etc.)\nNotre processus de recrutement :\nUn entretien RH avec Estelle,\n\u00e0 la suite duquel vous saurez tout (ou presque) d\u2019eXalt Value,\nUn entretien technique avec un Manager IA assorti d\u2019un \u00e9change technique,\nlors duquel vous aurez l\u2019occasion de d\u00e9montrer vos talents et de challenger vos acquis.\nUn entretien final avec la Directrice Associ\u00e9e ou le Directeur Op\u00e9rationnel,\npour finir de vous convaincre de nous rejoindre \ud83d\ude0a\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "Java",
                "Scala",
                "R",
                "Go"
            ],
            "DataBase": [],
            "DataAnalytics": [
                "Pandas",
                "NumPy",
                "R"
            ],
            "BigData": [
                "Spark"
            ],
            "MachingLearning": [
                "Scikit-Learn",
                "TensorFlow",
                "PyTorch"
            ],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [
                "Statistiques"
            ],
            "CloudComputing": [],
            "DevTools": [],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [
                "Big Data",
                "ML",
                "Machine Learning",
                "Statistiques"
            ],
            "FrSoftSkills": [
                "Communication"
            ],
            "EnSoftSkils": [
                "Communication",
                "Initiative"
            ]
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [],
            "Salary": [],
            "Level": [
                "Bac+5"
            ],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "APPRENTI DATA ENGINEER (H/F)",
        "company": "Akademija Oxford",
        "location": "Paris, \u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/apprenti-data-engineer-h-f-at-akademija-oxford-3917872047?position=12&pageNum=0&refId=yQtK%2BQI72QI4xq%2BIXLe7ew%3D%3D&trackingId=z5ilj7SaqSsVBBnTFNeAXg%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Une de nos entreprises partenaires, ESN situ\u00e9e \u00e0 Paris, recherche un Apprenti Data Engineer (H/F) pr\u00e9parant un bac +4/+5 sp\u00e9cialit\u00e9 Big Data pour la rentr\u00e9e de Septembre 2021.\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "R"
            ],
            "DataBase": [],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [],
            "DevTools": [],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [
                "Big Data"
            ],
            "FrSoftSkills": [],
            "EnSoftSkils": []
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "Data Scientist\u2013 Machine Learning",
        "company": "EyeTech Solutions",
        "location": "Paris, \u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/data-scientist%E2%80%93-machine-learning-at-eyetech-solutions-3913336440?position=13&pageNum=0&refId=yQtK%2BQI72QI4xq%2BIXLe7ew%3D%3D&trackingId=NzcnScNBx6QNKLahrX6oHw%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Data Scientist\u2013 Machine Learning\nTravailler sur le d\u00e9veloppement de mod\u00e8le de machine learning pr\u00e9dictif.\nPour une Solution SaaS de monitoring analytique, pr\u00e9dictif et prescriptif en milieu industriel.\nData Scientist\u2013 Machine Learning\nFond\u00e9e en 2016, notre soci\u00e9t\u00e9 d\u00e9veloppe une solution SAAS d\u00e9di\u00e9e au monitoring automatique des lignes de production.\nNotre \u00e9quipe sp\u00e9cialis\u00e9e dans les donn\u00e9es est responsable de la conception, du d\u00e9veloppement et de la maintenance de la plateforme IA de notre solution, dont les principales fonctionnalit\u00e9s incluent le monitoring analytique, pr\u00e9dictif et prescriptif.\nCette m\u00eame \u00e9quipe est \u00e9galement charg\u00e9e du d\u00e9veloppement d'une nouvelle plateforme IA qui sera int\u00e9gr\u00e9e \u00e0 nos solutions existantes.\nNos solutions reposent sur une stack technologique moderne, utilisant des outils tels que Airflow, Mlflow, MongoDB, Kubernetes, CI/CD.\nData Scientist\u2013 Machine Learning\nTravaux sur le d\u00e9veloppement de mod\u00e8le de machine learning pr\u00e9dictif\nCollaboration avec le Lead Data Scientist et le Lead Tech Senior pour d\u00e9finir les orientations du produit et organiser les t\u00e2ches.\nContribution au d\u00e9veloppement des fonctionnalit\u00e9s li\u00e9es aux donn\u00e9es et \u00e0 l\u2019intelligence artificielle.\nCommunication et pr\u00e9sentation clients.\nVeille scientifique et travaux de recherche et d\u00e9veloppement.\nData Scientist\u2013 Machine Learning\n3 ans d\u2019exp\u00e9rience minimum en tant que Data Scientist (IA, ML) dans l\u2019industrialisation d\u2019un produit\nCapaciter \u00e0 vulgariser, comprendre et transformer les besoins\nDiplome universitaire\nData Scientist\u2013 Machine Learning\nLocaux \u00e0 Paris\nSalaire selon profil, entre 50K et 55K\nT\u00e9l\u00e9travail 2 jours / semaine\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "R",
                "Go"
            ],
            "DataBase": [
                " MongoDB"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [],
            "DevTools": [],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [
                "Kubernetes",
                "Airflow"
            ],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [
                "Kubernetes"
            ],
            "Collaboration": [],
            "Other": [
                "ML",
                "Machine Learning",
                "CI/CD"
            ],
            "FrSoftSkills": [
                "Communication",
                "Collaboration"
            ],
            "EnSoftSkils": [
                "Communication",
                "Collaboration"
            ]
        },
        "details": {
            "JobDetail": [
                "Senior"
            ],
            "TypeContract": [],
            "Salary": [
                "50K"
            ],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s",
                "3",
                "3",
                "3"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "Machine Learning Developer",
        "company": "MindPal",
        "location": "Marseille, Provence-Alpes-C\u00f4te d'Azur, France",
        "link": "https://fr.linkedin.com/jobs/view/machine-learning-developer-at-mindpal-3911352774?position=14&pageNum=0&refId=yQtK%2BQI72QI4xq%2BIXLe7ew%3D%3D&trackingId=S9QpfJ8pqiWYDqVaalnicg%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "We are looking for\nMachine Learning Developer\nJob Responsibilities\nWorking on machine learning projects\nAnalyzing and processing data to create machine learning models\nImplementing and optimizing machine learning algorithms\nTesting and evaluating models\nCollaborating with the programming team and other departments within the company to develop innovative solutions\nRequirements\nMinimum 2 years of experience in the field of machine learning\nKnowledge of machine learning algorithms and techniques\nAbility to analyze and process data\nFamiliarity with machine learning tools and technologies\nProficient in English communication\nEducation in computer science\nWe Offer\nB2B contract type\nFull-time employment\nRemote and flexible working hours\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "R",
                "Go"
            ],
            "DataBase": [],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [],
            "DevTools": [],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [
                "Machine Learning"
            ],
            "FrSoftSkills": [
                "Communication"
            ],
            "EnSoftSkils": [
                "Communication"
            ]
        },
        "details": {
            "JobDetail": [
                "Remote",
                "Full"
            ],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "Data Scientist H/F",
        "company": "Valeuriad",
        "location": "Nantes, Pays de la Loire, France",
        "link": "https://fr.linkedin.com/jobs/view/data-scientist-h-f-at-valeuriad-3741220588?position=15&pageNum=0&refId=yQtK%2BQI72QI4xq%2BIXLe7ew%3D%3D&trackingId=ROf9n%2BzXJSHQCeLW7px%2FgA%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Rejoins la\nTeam Data\ncr\u00e9\u00e9e par\nNicolas Greffard,\nDocteur en Intelligence Artificielle\n, d\u00e9j\u00e0 compos\u00e9e de\n20\nData Scientists\net\nData Engineer\ntalentueux \ud83d\ude0d\nNous recherchons de\nnouvelles p\u00e9pites\npour rejoindre notre \u00e9quipe de choc et r\u00e9pondre aux\nmultiples probl\u00e9matiques Data science\nde nos\nclients nantais\nmais \u00e9galement\ncontribuer \u00e0 nos projets de R&D\net travailler sur des\nconf\u00e9rences incroyables\n(DevFest, Salon de la Data)\n\ud83e\udd29\nTa future mission si tu l'acceptes\n\ud83d\ude09\nNous te proposons d'intervenir au sein de nos\ngrandes DSI clientes\n, sur des sujets de\ncollecte\n, d\n'alimentation\net de\ntransformation de donn\u00e9es\nautour de l\u2019intelligence artificielle.\nLe job en d\u00e9tail\n\ud83e\udd29\nToutes Les Missions Ne Sont Pas Identiques, Mais Voici Des Exemples De Choses Sur Lesquelles Nos Data Scientists Sont Intervenus\n\u00c9change avec les architectes, les PO et PPO, les d\u00e9veloppeurs et la gouvernance de donn\u00e9es ;\nDeep learning (RNN, LSTM, CNN, DQN) et Machine learning ;\nAnalyse de donn\u00e9es : statistiques descriptives et exploratoires, Data Mining ;\nTraitement d\u2019images (pattern matching, extraction de descripteurs, tf-idf et classification, etc..) et traitement de texte.\nTraitement du langage / Text-Mining (Word2Vec, BoW, BERT, etc..) ;\nRestitutiondes r\u00e9sultats : dataviz, indicateurs, dashboards (tableaux de bord), optimisation d\u2019application streamlit ;\nMLOps : pour pour amener l'IA jusqu'\u00e0 la prod ;\nAm\u00e9lioration de mod\u00e8les : validation crois\u00e9e, s\u00e9lection de descripteurs, m\u00e9triques d\u2019erreurs ;\nAssurer la veille technologique sur les algorithmes et outils de Data Science.\nLangages : Principalement du Python, souvent du SQL et parfois du R ou m\u00eame du SAS ;\nFramework : ceux qui reviennent sans arr\u00eat : Tensorflow, PyTorch, Huggingface, SkLearn, Lime, Streamlit, \u00e9cosyst\u00e8me Hadoop ;\nInt\u00e9gration continue : en fonction des contextes applicatifs : docker, docker-compose, Docker Swarm, GitHub actions, Jenkins, kubernetes, concourse.\nPourquoi choisir Valeuriad ?\n\ud83d\ude0a\nEn plus d\u2019\u00eatre aujourd\u2019hui un acteur nantais reconnu de l\u2019expertise IT, nous nous inscrivons depuis notre cr\u00e9ation dans une d\u00e9marche d'entreprise\nOpale\net\nHolacratique\n, o\u00f9 l'ensemble de nos prises de d\u00e9cisions et projets sont r\u00e9alis\u00e9s par et avec l'ensemble de nos\n120 co\u00e9quipiers\n\ud83d\udcaa\nRejoindre Valeuriad, c'est pouvoir s'investir dans la co-construction de l'entreprise :\nPar un r\u00f4le, avec une fiche de poste et un temps d\u00e9di\u00e9 (gestionnaire des Ci\u2019s, porteur des partenariats \u00e9coles, organisateur d\u2019\u00e9v\u00e9nements, PO des projets internes, gestion de l'Acad\u00e9mie Valeuriad\u2026).\nPar les projets strat\u00e9giques (200 jours mis \u00e0 disposition pour les co\u00e9quipiers chaque ann\u00e9e) pour cr\u00e9er et faire grandir des projets structurants (cr\u00e9ation de nouveaux avantages \u00e0 l'anciennet\u00e9, cr\u00e9ation d'indicateurs mensuels pour \u00eatre toujours plus transparents, m\u00e9c\u00e9nat de comp\u00e9tences pour des associations caritatives...).\nPar les projets cagnottes (150\u20ac par co\u00e9quipiers et par an) pour r\u00e9aliser des projets collaboratifs qui te tiennent \u00e0 c\u0153ur avec d'autres Valeurieux (d\u00e9couverte du c\u00e9cifoot, challenge \u00e9cologique, challenges sportifs pour des dons \u00e0 des associations humanitaires, borne photo...).\nPar les ateliers collaboratifs, chaque mois des brainstorming et ateliers de travail sont propos\u00e9s par les diff\u00e9rents porteurs de projets et sont ouverts \u00e0 tous les volontaires.\nMais avant-tout nous sommes une\n\u00e9quipe soud\u00e9e\n, des coll\u00e8gues qui appr\u00e9cient passer du temps ensemble lors de nos soir\u00e9es hebdomadaires et se cr\u00e9er des\nsouvenirs inoubliables\n\ud83e\udd29 C'est pour \u00e7a que chez Valeuriad, le plus important pour nous reste le savoir-\u00eatre : des passionn\u00e9s, du dynamisme, des sourires, de l'\u00e9coute et le sens de la f\u00eate \ud83d\ude09\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "R",
                " R ",
                "Go"
            ],
            "DataBase": [
                "SQL"
            ],
            "DataAnalytics": [
                "R",
                " R "
            ],
            "BigData": [
                "Hadoop"
            ],
            "MachingLearning": [
                "TensorFlow",
                "PyTorch"
            ],
            "DataSerialization": [],
            "DataVisualization": [
                "Tableau"
            ],
            "Statistics": [
                "Statistiques",
                "Statistiques Descriptives"
            ],
            "CloudComputing": [],
            "DevTools": [
                "Git",
                "Docker",
                "Jenkins"
            ],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [
                "Kubernetes"
            ],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [
                "Docker",
                "Kubernetes"
            ],
            "Collaboration": [],
            "Other": [
                "ML",
                "Machine Learning",
                "Statistiques"
            ],
            "FrSoftSkills": [],
            "EnSoftSkils": []
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "Machine Learning Engineer",
        "company": "Aether Energy (YC W24)",
        "location": "Paris, \u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/machine-learning-engineer-at-aether-energy-yc-w24-3911654324?position=16&pageNum=0&refId=yQtK%2BQI72QI4xq%2BIXLe7ew%3D%3D&trackingId=UgxrSSib%2BZoj8AFXCv6EoQ%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "We raised a $3M seed recently.\nWe encourage all applicants from the EU to apply.\nOverview\nAether is on a mission to develop a comprehensive AI-driven platform for the solar energy industry. Our founders have strong technical academic background from UC Berkeley, complemented by extensive technical experience gained at some of the most influential companies in the energy sector.\nAether is seeking a machine learning engineer with a strong background in software engineering.\nIdeal candidates should have backgrounds in Physics, Mechanical Engineering, Electrical Engineering, or Materials Science, coupled with expertise in Computational Mathematics. A Master's degree is essential for this role, while a PhD, though not mandatory, would be highly valuable.\nWe are proud of our recent success and invite you to check out our YCombinator launch at\nthis link\n.\nWe're Looking For Someone Who:\nGets things done. This is an emerging Y Combinator seed company, and we require you to make an impact from day one.\nYour growth potential here is unlimited.\nQualifications\nThis role will be 60% Machine Learning/Data Science focused, and 40% backend engineering focused. You will need to be comfortable writing production-level code.\nREQUIRED\nStrong proficiency in Python\nKnowledge of unsupervised and supervised machine learning techniques\nA deep understanding of Computer Vision models such as UNET, DeepLab, or HRNet (High-Resolution Network).\nInterested in developing foundational LLM models (our use-case is energy)\nProficiency in data exploration (using BigQuery, Jupyter notebooks, and SQL), model development, and the establishment of data/ML pipelines\nComfortable working with APIs and Databases.\nKnowledge of best practices in collaborative coding with tools like Git and CI/CD.\nStrong software engineering skills and an understanding of good design patterns.\nYou must be Fluent in English.\nPreferred -\nWe know you won\u2019t know everything but having a good general breadth of the requirements below will set you apart.\nA keen interest in the intersection of physical systems and AI.\nKnowledge of the Django framework.\nFamiliarity with Python libraries, including Pandas, NumPy, scikit-learn, PyTorch/Tensorflow, PyTorch Lightning, and vector databases.\nCompetency in deploying data and code to cloud platforms (GCP/Digital Ocean).\nUnderstanding of energy related data: battery data, solar data, etc.\nIdeally, previous experience in high-growth start-ups.\nYour math has to be good. We will check for this.\nCompensation/Time Commitment/Location:\nYou will need to work US EST hours from Monday to Thursday. You must be in our Paris office 3x a week starting in August.\n1st 3 months will be on a contract basis to assess performance.\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "R",
                "Go"
            ],
            "DataBase": [
                "SQL"
            ],
            "DataAnalytics": [
                "Pandas",
                "NumPy",
                "R"
            ],
            "BigData": [],
            "MachingLearning": [
                "Scikit-Learn",
                "TensorFlow",
                "PyTorch"
            ],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [],
            "DevTools": [
                "Git"
            ],
            "Os": [],
            "DBMS": [
                "BigQuery"
            ],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [
                "ML",
                "Machine Learning",
                "Cloud",
                "CI/CD"
            ],
            "FrSoftSkills": [],
            "EnSoftSkils": []
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "Machine Learning Developer",
        "company": "MindPal",
        "location": "Lyon, Auvergne-Rh\u00f4ne-Alpes, France",
        "link": "https://fr.linkedin.com/jobs/view/machine-learning-developer-at-mindpal-3910999113?position=17&pageNum=0&refId=yQtK%2BQI72QI4xq%2BIXLe7ew%3D%3D&trackingId=Y0yIRDfmVh1K7Tj5YtvCvQ%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "We are looking for\nMachine Learning Developer\nJob Responsibilities\nWorking on machine learning projects\nAnalyzing and processing data to create machine learning models\nImplementing and optimizing machine learning algorithms\nTesting and evaluating models\nCollaborating with the programming team and other departments within the company to develop innovative solutions\nRequirements\nMinimum 2 years of experience in the field of machine learning\nKnowledge of machine learning algorithms and techniques\nAbility to analyze and process data\nFamiliarity with machine learning tools and technologies\nProficient in English communication\nEducation in computer science\nWe Offer\nB2B contract type\nFull-time employment\nRemote and flexible working hours\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "R",
                "Go"
            ],
            "DataBase": [],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [],
            "DevTools": [],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [
                "Machine Learning"
            ],
            "FrSoftSkills": [
                "Communication"
            ],
            "EnSoftSkils": [
                "Communication"
            ]
        },
        "details": {
            "JobDetail": [
                "Remote",
                "Full"
            ],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "Machine Learning Engineer",
        "company": "Mirakl",
        "location": "Paris, \u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/machine-learning-engineer-at-mirakl-3879686188?position=18&pageNum=0&refId=yQtK%2BQI72QI4xq%2BIXLe7ew%3D%3D&trackingId=zCfIe%2BoRL7dqvQczKuQbSw%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Mirakl, leader et pionnier de l\u2019\u00e9conomie de plateforme, propose aux entreprises une suite unique de solutions leur permettant de transformer significativement leur e-commerce afin d'acc\u00e9l\u00e9rer de fa\u00e7on durable et rentable leur croissance. Depuis 2012, Mirakl accompagne les entreprises B2C et B2B avec la technologie la plus avanc\u00e9e, s\u00e9curis\u00e9e et \u00e9volutive leur permettant de digitaliser leur activit\u00e9 et d'\u00e9largir leur offre via la marketplace ou le dropship, faciliter la gestion des catalogues et des paiements de leurs fournisseurs pour plus d'efficacit\u00e9, offrir une exp\u00e9rience d'achat personnalis\u00e9e \u00e0 leurs clients, et augmenter leurs profits gr\u00e2ce au retail media. Bas\u00e9e \u00e0 Paris et Boston, Mirakl est certifi\u00e9e Great Place to Work.\nA propos de Mirakl Labs\nNos \u00e9quipes techniques et produits, nomm\u00e9es Mirakl Labs, sont principalement r\u00e9parties entre nos 2 hubs situ\u00e9s \u00e0 Paris et \u00e0 Bordeaux. Elles collaborent au quotidien afin d'adresser les probl\u00e9matiques de nos clients et utilisateurs en r\u00e9pondant \u00e0 diff\u00e9rents challenges li\u00e9s aux nouvelles fonctionnalit\u00e9s, \u00e0 la scalabilit\u00e9, la s\u00e9curit\u00e9 et l\u2019ergonomie\u2026\nElles op\u00e8rent en mode agile et s'organisent en Squads compos\u00e9es d'un Squad Lead, de 5 d\u00e9veloppeurs, d'un Product Manager et d'un QA. Chaque Squad est sp\u00e9cialis\u00e9e sur un scope fonctionnel afin de concevoir et r\u00e9aliser de nouvelles features, leurs \u00e9volutions et des APIs (avec un d\u00e9coupage en micro-services). Nos \u00e9quipes Infrastructure, Architecture, S\u00e9curit\u00e9, Documentation, Product Design, Data et Support op\u00e8rent en transverse en apportant leur expertise et de la coh\u00e9rence sur l\u2019ensemble des produits.\nToutes les \u00e9quipes sont responsables de leur p\u00e9rim\u00e8tre et chacun des collaborateurs apporte son exp\u00e9rience et ses id\u00e9es. Innovation, feedback et implication dans les prises de d\u00e9cision sont au c\u0153ur de notre philosophie.\nEt pour favoriser ce partage avec d\u2019autres passionn\u00e9s, nous sommes sponsors, speakers, et h\u00f4tes de diff\u00e9rents \u00e9v\u00e9nements, meetups, et associations de la sc\u00e8ne Tech en France. Au cours des derni\u00e8res ann\u00e9es, nous avons particip\u00e9 \u00e0 des \u00e9v\u00e9nements tels que Devoxx, ReactEurope, ProductConf et Flupa UX Days.\nA propos du job\nInt\u00e9gr\u00e9.e dans notre \u00e9quipe Data Science, votre principale mission sera de prototyper, it\u00e9rer, et mettre en production des algorithmes en collaboration avec les \u00e9quipes Produit, les Data Engineers et les \u00e9quipes de d\u00e9veloppement. Les sujets que vous traiterez auront un vrai impact sur nos clients : l\u2019ambition est d\u2019exploiter au maximum nos donn\u00e9es riches et vari\u00e9es afin de d\u00e9velopper leur chiffre d'affaires, d\u2019optimiser la gestion op\u00e9rationnelle de leur marketplace et de garantir la s\u00e9curit\u00e9 des utilisateurs et des transactions.\nA propos de l\u2019\u00e9quipe\nGet to Know the Data Science Team That Powers the Mirakl Platform\nCe qu\u2019il y a pour vous dans ce job\nImpl\u00e9menter, optimiser et d\u00e9ployer des algorithmes qui auront un impact visible sur plus de 500 sites e-commerce/marketplaces dans 40 pays dont certains une volum\u00e9trie tr\u00e8s importantes (millions de produits, de clients, de commandes par an)\nTraiter des sujets tr\u00e8s divers et vari\u00e9s d\u2019un point de vue:\nBusiness\nMachine learning (NLP, Image processing, Time series, LLM, syst\u00e8me de recommandation, etc.)\nInfrastructure (spark, model endpoints, etc.)\nUne plateforme Machine Learning et Data Platform state-of-the-art\nConcevoir et d\u00e9ployer des infrastructures \u00e0 faible latence avec les Data Engineers\nUne vraie autonomie et responsabilit\u00e9 dans les projets dont vous avez l\u2019ownership\nLa possibilit\u00e9 d'avoir un contrat freelance ou CDI\nNotre stack et nos outils\nPython, Tensorflow, Pytorch, Databricks, Spark, Aws, Airflow, MLflow, Delta Lake, SQL\nAu quotidien\n,\nvous allez :\nDesigner, optimiser et mettre en production des mod\u00e8les de machine learning de fa\u00e7on scalable (apprentissage et inf\u00e9rence)\nRassembler et manipuler les donn\u00e9es, prototyper des algorithmes de machine learning\nMettre en place et monitorer des serving endpoints\nParticiper \u00e0 l\u2019\u00e9volution de la plateforme Machine Learning de Mirakl\nContinuer \u00e0 mettre en place des best practices de programmation mais aussi de d\u00e9ploiement\nEffectuer de la veille technologique sur les mod\u00e8les state-of-the-art, ainsi que sur les stack machine learning\nPr\u00e9senter les r\u00e9sultats au weekly data science et aux sessions de brainstorming de l\u2019\u00e9quipe\n\u00c9changer avec les autres \u00e9quipes pour affiner les cas d\u2019utilisation, l\u2019exp\u00e9rience utilisateur et les modes d\u2019int\u00e9gration\nVous aimerez ce job si :\nVous avez minimum 3 ans d\u2019exp\u00e9rience en tant que Machine Learning Engineer (le poste est \u00e9volutif selon votre s\u00e9niorit\u00e9)\nVous avez de solides comp\u00e9tences en d\u00e9veloppement Python\nVous aimez le software engineering et le machine learning\nVous avez une exp\u00e9rience significative dans la mise en production, le scaling des mod\u00e8les et des bests practices MLOps\nVous avez l\u2019habitude de chercher, manipuler et analyser des donn\u00e9es \u00e0 forte volum\u00e9trie, id\u00e9alement avec Spark\nVous avez une bonne connaissance des algorithmes de Deep Learning (texte et/ou image), des architectures State-Of-the-Art - par exemple les Transformers\nVous avez de l\u2019exp\u00e9rience dans l\u2019optimisation de mod\u00e8les de machine learning et de leur inf\u00e9rence\nVous avez de l\u2019exp\u00e9rience dans la mise en place de serving de mod\u00e8les\nVous aimez avoir l\u2019ownership de vos sujets et aimez partager votre travail dans le cadre de pr\u00e9sentations internes, dans des conf\u00e9rences ou en r\u00e9digeant des articles\nPetit plus :\nVous avez une exp\u00e9rience en environnement e-commerce, sur des algorithmes de syst\u00e8mes de recommandations et/ou retail media\nVous avez une exp\u00e9rience dans le serving de mod\u00e8les \u00e0 faible latence\nVous \u00eates sp\u00e9cialiste NLP\nOptimisation de LLM\nMirakl est engag\u00e9e en faveur de la diversit\u00e9, de l\u2019\u00e9galit\u00e9 des chances et de l\u2019inclusion. Nous c\u00e9l\u00e9brons nos diff\u00e9rences car nous sommes convaincus que les qualit\u00e9s visibles et invisibles de chaque Mirakl Worker sont une source de force et d\u2019innovation. Dans le cadre de cet engagement, nous \u00e9tudions toutes les candidatures sans distinction de : genre, ethnicit\u00e9, religion, orientation sexuelle, handicap, \u00e2ge ou toute autre caract\u00e9ristique prot\u00e9g\u00e9e par la loi.\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "Scala",
                "R",
                "Go"
            ],
            "DataBase": [
                "SQL"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [
                "Spark",
                "Databricks"
            ],
            "MachingLearning": [
                "TensorFlow",
                "PyTorch"
            ],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [
                "AWS"
            ],
            "DevTools": [
                "Git"
            ],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [
                "Airflow"
            ],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [
                "ML",
                "Machine Learning"
            ],
            "FrSoftSkills": [
                "Collaboration"
            ],
            "EnSoftSkils": [
                "Collaboration"
            ]
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [
                "CDI"
            ],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s",
                "3",
                "3",
                "3"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "Machine Learning Engineer",
        "company": "Mirakl",
        "location": "Paris, \u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/machine-learning-engineer-at-mirakl-3879682593?position=19&pageNum=0&refId=yQtK%2BQI72QI4xq%2BIXLe7ew%3D%3D&trackingId=sNWSPslunM2GgQQJZJaQkA%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Mirakl, leader et pionnier de l\u2019\u00e9conomie de plateforme, propose aux entreprises une suite unique de solutions leur permettant de transformer significativement leur e-commerce afin d'acc\u00e9l\u00e9rer de fa\u00e7on durable et rentable leur croissance. Depuis 2012, Mirakl accompagne les entreprises B2C et B2B avec la technologie la plus avanc\u00e9e, s\u00e9curis\u00e9e et \u00e9volutive leur permettant de digitaliser leur activit\u00e9 et d'\u00e9largir leur offre via la marketplace ou le dropship, faciliter la gestion des catalogues et des paiements de leurs fournisseurs pour plus d'efficacit\u00e9, offrir une exp\u00e9rience d'achat personnalis\u00e9e \u00e0 leurs clients, et augmenter leurs profits gr\u00e2ce au retail media. Bas\u00e9e \u00e0 Paris et Boston, Mirakl est certifi\u00e9e Great Place to Work.\nA propos de Mirakl Labs\nNos \u00e9quipes techniques et produits, nomm\u00e9es Mirakl Labs, sont principalement r\u00e9parties entre nos 2 hubs situ\u00e9s \u00e0 Paris et \u00e0 Bordeaux. Elles collaborent au quotidien afin d'adresser les probl\u00e9matiques de nos clients et utilisateurs en r\u00e9pondant \u00e0 diff\u00e9rents challenges li\u00e9s aux nouvelles fonctionnalit\u00e9s, \u00e0 la scalabilit\u00e9, la s\u00e9curit\u00e9 et l\u2019ergonomie\u2026\nElles op\u00e8rent en mode agile et s'organisent en Squads compos\u00e9es d'un Squad Lead, de 5 d\u00e9veloppeurs, d'un Product Manager et d'un QA. Chaque Squad est sp\u00e9cialis\u00e9e sur un scope fonctionnel afin de concevoir et r\u00e9aliser de nouvelles features, leurs \u00e9volutions et des APIs (avec un d\u00e9coupage en micro-services). Nos \u00e9quipes Infrastructure, Architecture, S\u00e9curit\u00e9, Documentation, Product Design, Data et Support op\u00e8rent en transverse en apportant leur expertise et de la coh\u00e9rence sur l\u2019ensemble des produits.\nToutes les \u00e9quipes sont responsables de leur p\u00e9rim\u00e8tre et chacun des collaborateurs apporte son exp\u00e9rience et ses id\u00e9es. Innovation, feedback et implication dans les prises de d\u00e9cision sont au c\u0153ur de notre philosophie.\nEt pour favoriser ce partage avec d\u2019autres passionn\u00e9s, nous sommes sponsors, speakers, et h\u00f4tes de diff\u00e9rents \u00e9v\u00e9nements, meetups, et associations de la sc\u00e8ne Tech en France. Au cours des derni\u00e8res ann\u00e9es, nous avons particip\u00e9 \u00e0 des \u00e9v\u00e9nements tels que Devoxx, ReactEurope, ProductConf et Flupa UX Days.\nA propos du job\nInt\u00e9gr\u00e9.e dans notre \u00e9quipe Data Science, votre principale mission sera de prototyper, it\u00e9rer, et mettre en production des algorithmes en collaboration avec les \u00e9quipes Produit, les Data Engineers et les \u00e9quipes de d\u00e9veloppement. Les sujets que vous traiterez auront un vrai impact sur nos clients : l\u2019ambition est d\u2019exploiter au maximum nos donn\u00e9es riches et vari\u00e9es afin de d\u00e9velopper leur chiffre d'affaires, d\u2019optimiser la gestion op\u00e9rationnelle de leur marketplace et de garantir la s\u00e9curit\u00e9 des utilisateurs et des transactions.\nA propos de l\u2019\u00e9quipe\nGet to Know the Data Science Team That Powers the Mirakl Platform\nCe qu\u2019il y a pour vous dans ce job\nImpl\u00e9menter, optimiser et d\u00e9ployer des algorithmes qui auront un impact visible sur plus de 500 sites e-commerce/marketplaces dans 40 pays dont certains une volum\u00e9trie tr\u00e8s importantes (millions de produits, de clients, de commandes par an)\nTraiter des sujets tr\u00e8s divers et vari\u00e9s d\u2019un point de vue:\nBusiness\nMachine learning (NLP, Image processing, Time series, LLM, syst\u00e8me de recommandation, etc.)\nInfrastructure (spark, model endpoints, etc.)\nUne plateforme Machine Learning et Data Platform state-of-the-art\nConcevoir et d\u00e9ployer des infrastructures \u00e0 faible latence avec les Data Engineers\nUne vraie autonomie et responsabilit\u00e9 dans les projets dont vous avez l\u2019ownership\nLa possibilit\u00e9 d'avoir un contrat freelance ou CDI\nNotre stack et nos outils\nPython, Tensorflow, Pytorch, Databricks, Spark, Aws, Airflow, MLflow, Delta Lake, SQL\nAu quotidien\n,\nvous allez :\nDesigner, optimiser et mettre en production des mod\u00e8les de machine learning de fa\u00e7on scalable (apprentissage et inf\u00e9rence)\nRassembler et manipuler les donn\u00e9es, prototyper des algorithmes de machine learning\nMettre en place et monitorer des serving endpoints\nParticiper \u00e0 l\u2019\u00e9volution de la plateforme Machine Learning de Mirakl\nContinuer \u00e0 mettre en place des best practices de programmation mais aussi de d\u00e9ploiement\nEffectuer de la veille technologique sur les mod\u00e8les state-of-the-art, ainsi que sur les stack machine learning\nPr\u00e9senter les r\u00e9sultats au weekly data science et aux sessions de brainstorming de l\u2019\u00e9quipe\n\u00c9changer avec les autres \u00e9quipes pour affiner les cas d\u2019utilisation, l\u2019exp\u00e9rience utilisateur et les modes d\u2019int\u00e9gration\nVous aimerez ce job si :\nVous avez minimum 3 ans d\u2019exp\u00e9rience en tant que Machine Learning Engineer (le poste est \u00e9volutif selon votre s\u00e9niorit\u00e9)\nVous avez de solides comp\u00e9tences en d\u00e9veloppement Python\nVous aimez le software engineering et le machine learning\nVous avez une exp\u00e9rience significative dans la mise en production, le scaling des mod\u00e8les et des bests practices MLOps\nVous avez l\u2019habitude de chercher, manipuler et analyser des donn\u00e9es \u00e0 forte volum\u00e9trie, id\u00e9alement avec Spark\nVous avez une bonne connaissance des algorithmes de Deep Learning (texte et/ou image), des architectures State-Of-the-Art - par exemple les Transformers\nVous avez de l\u2019exp\u00e9rience dans l\u2019optimisation de mod\u00e8les de machine learning et de leur inf\u00e9rence\nVous avez de l\u2019exp\u00e9rience dans la mise en place de serving de mod\u00e8les\nVous aimez avoir l\u2019ownership de vos sujets et aimez partager votre travail dans le cadre de pr\u00e9sentations internes, dans des conf\u00e9rences ou en r\u00e9digeant des articles\nPetit plus :\nVous avez une exp\u00e9rience en environnement e-commerce, sur des algorithmes de syst\u00e8mes de recommandations et/ou retail media*\nVous avez une exp\u00e9rience dans le serving de mod\u00e8les \u00e0 faible latence\nVous \u00eates sp\u00e9cialiste NLP\nOptimisation de LLM\nMirakl est engag\u00e9e en faveur de la diversit\u00e9, de l\u2019\u00e9galit\u00e9 des chances et de l\u2019inclusion. Nous c\u00e9l\u00e9brons nos diff\u00e9rences car nous sommes convaincus que les qualit\u00e9s visibles et invisibles de chaque Mirakl Worker sont une source de force et d\u2019innovation. Dans le cadre de cet engagement, nous \u00e9tudions toutes les candidatures sans distinction de : genre, ethnicit\u00e9, religion, orientation sexuelle, handicap, \u00e2ge ou toute autre caract\u00e9ristique prot\u00e9g\u00e9e par la loi.\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "Scala",
                "R",
                "Go"
            ],
            "DataBase": [
                "SQL"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [
                "Spark",
                "Databricks"
            ],
            "MachingLearning": [
                "TensorFlow",
                "PyTorch"
            ],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [
                "AWS"
            ],
            "DevTools": [
                "Git"
            ],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [
                "Airflow"
            ],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [
                "ML",
                "Machine Learning"
            ],
            "FrSoftSkills": [
                "Collaboration"
            ],
            "EnSoftSkils": [
                "Collaboration"
            ]
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [
                "CDI"
            ],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s",
                "3",
                "3",
                "3"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "Data Scientist - Toulouse",
        "company": "Capgemini",
        "location": "Toulouse, Occitanie, France",
        "link": "https://fr.linkedin.com/jobs/view/data-scientist-toulouse-at-capgemini-3913358664?position=20&pageNum=0&refId=yQtK%2BQI72QI4xq%2BIXLe7ew%3D%3D&trackingId=ZmJ%2FMecMtoNnmDFV%2BwaS4w%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Capgemini en quelques mots\nChoisir Capgemini, c'est choisir une entreprise o\u00f9 vous serez en mesure de fa\u00e7onner votre carri\u00e8re selon vos aspirations, o\u00f9 vous serez soutenu et inspir\u00e9 par une communaut\u00e9 d\u2019experts dans le monde entier, o\u00f9 vous pourrez r\u00e9\u00e9crire votre futur. Rejoignez-nous pour red\u00e9finir les limites de ce qui est possible, contribuer \u00e0 lib\u00e9rer la valeur de la technologie pour les plus grandes organisations et participez \u00e0 la construction d\u2019un monde plus durable et inclusif.\nVos missions\nEn tant que\nLead Technique Data Science\nau sein de la practice Insights & Data, vous serez amener \u00e0 intervenir sur des projets data pour :\nId\u00e9aliser les cas d\u2019usages et cadrer le projet afin de r\u00e9pondre aux exigences m\u00e9tiers \u00e0 partir de solutions innovantes d\u2019Intelligence Artificielle\nPromouvoir les bonnes pratiques au sein de l\u2019\u00e9quipe avec le d\u00e9veloppement d\u2019une m\u00e9thodologie de travail et d\u2019am\u00e9lioration continue appropri\u00e9s\nParticiper aux propositions commerciales sur la partie Data\nConstruire une relation de confiance avec le client en tant qu\u2019interlocuteur privil\u00e9gi\u00e9 et assurer la qualit\u00e9 des rendus finaux ainsi que le d\u00e9veloppement de nouveaux enjeux business\nFaire parti des leaders de la communaut\u00e9 Data Science et influencer sur la strat\u00e9gie Data d\u2019Insights & Data\nContinuer de vous former sur tous les aspects de votre m\u00e9tier et assurer une veille technologique sur les innovations les plus pertinentes \u00e0 mettre en place\nVotre profil\nDe formation Bac + 5 en \u00e9cole d\u2019ing\u00e9nieur ou \u00e9quivalent universitaire avec une sp\u00e9cialisation Data Science\nA partir de 6 ans d\u2019exp\u00e9riences\nCompr\u00e9hension fine des enjeux business et pilotage d'une \u00e9quipe\nConnaissance de plusieurs langages de programmation (Python, Scala, Spark\u2026) et Cloud (AWS, GCP, Azure, OVH)\nLe Machine Learning, le NLP et le Deep Learning n\u2019ont plus de secret pour vous\nBon niveau d'anglais\n3 raisons de nous rejoindre\nQualit\u00e9 de vie au travail :\naccord de t\u00e9l\u00e9travail en France et \u00e0 l\u2019international, accord sur l\u2019\u00e9galit\u00e9\nprofessionnelle, la parentalit\u00e9, l\u2019\u00e9quilibre des temps et la mobilit\u00e9 durable.\nApprentissage en continu :\ncertifications et formations en libre acc\u00e8s, accompagnement sur mesure avec\nvotre carreer manager, parcours d\u2019int\u00e9gration sur 9 mois.\nAvantages groupe & CSE :\nplan actionnariat, activit\u00e9s \u00e0 tarifs pr\u00e9f\u00e9rentiels, remboursement partiel\nvacances, remboursement de votre abonnement sportif ou culturel\nNos engagements et priorit\u00e9s\nLe groupe Capgemini encourage une\nculture inclusive dans un cadre multiculturel et handi-accueillant.\nEn nous rejoignant, vous int\u00e9grez un collectif qui valorise la diversit\u00e9, d\u00e9veloppe le potentiel de ses talents, s\u2019engage dans des\ninitiatives solidaires avec ses partenaires, et se mobilise pour r\u00e9duire son impact environnemental sur tous ses sites et aupr\u00e8s de ses clients.\nCapgemini\nest un\nleader mondial\n, responsable et multiculturel, regroupant pr\u00e8s de 350 000 personnes dans plus de 50 pays. Fort de\n55 ans d\u2019exp\u00e9rience\n, nous sommes un partenaire strat\u00e9gique des entreprises pour la transformation de leurs activit\u00e9s en tirant profit de toute la puissance de la technologie et des innovations dans les domaines en perp\u00e9tuelle \u00e9volution tels que\nle cloud, la data, l\u2019Intelligence Artificielle, la connectivit\u00e9, les logiciels, l\u2019ing\u00e9nierie digitale ou les plateformes.\nGet The Future You Want* | www.capgemini.com/fr-fr\n*Capgemini, le futur que vous voulez\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "Scala",
                "R"
            ],
            "DataBase": [],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [
                "Spark"
            ],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [
                "AWS",
                "Azure"
            ],
            "DevTools": [
                "Git"
            ],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [
                "Machine Learning",
                "Cloud"
            ],
            "FrSoftSkills": [
                "Organisation"
            ],
            "EnSoftSkils": [
                "Initiative"
            ]
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s",
                "6",
                "6",
                "6"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "Machine Learning Developer",
        "company": "MindPal",
        "location": "Paris, \u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/machine-learning-developer-at-mindpal-3896993704?position=21&pageNum=0&refId=yQtK%2BQI72QI4xq%2BIXLe7ew%3D%3D&trackingId=BBIjgxCdqZVKjdefTyXyug%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "We are looking for\nMachine Learning Developer\nJob Responsibilities\nWorking on machine learning projects\nAnalyzing and processing data to create machine learning models\nImplementing and optimizing machine learning algorithms\nTesting and evaluating models\nCollaborating with the programming team and other departments within the company to develop innovative solutions\nRequirements\nMinimum 2 years of experience in the field of machine learning\nKnowledge of machine learning algorithms and techniques\nAbility to analyze and process data\nFamiliarity with machine learning tools and technologies\nProficient in English communication\nEducation in computer science\nWe Offer\nB2B contract type\nFull-time employment\nRemote and flexible working hours\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "R",
                "Go"
            ],
            "DataBase": [],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [],
            "DevTools": [],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [
                "Machine Learning"
            ],
            "FrSoftSkills": [
                "Communication"
            ],
            "EnSoftSkils": [
                "Communication"
            ]
        },
        "details": {
            "JobDetail": [
                "Remote",
                "Full"
            ],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "ML Engineer",
        "company": "Scaleway",
        "location": "Paris, \u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/ml-engineer-at-scaleway-3828501763?position=22&pageNum=0&refId=yQtK%2BQI72QI4xq%2BIXLe7ew%3D%3D&trackingId=j8OgxmEWn%2BJBHYzf4lRvxw%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "About The Job\nThe newly established Inference team at Scaleway is on a mission to revolutionize how Machine Learning (ML) is deployed and scaled in the cloud. We are seeking a talented ML Engineer to join us in developing and deploying Large Language Model (LLM) endpoints on both dedicated instances and serverless environments. As we plan to broaden our offerings to include various types of ML models later this year, this role offers a unique opportunity to be at the forefront of ML technology and its application in the cloud.\nReporting to our Manager, Gr\u00e9goire de Turckheim, you will play a crucial role in building and optimizing ML model deployments, ensuring high performance, scalability, and reliability.\nMinimum Qualifications\nProficient in Python and familiar with other programming languages such as Go\nStrong background in Machine Learning, including experience with LLMs, NLP, or other ML model types\nExperience with ML frameworks (e.g., TensorFlow, PyTorch) and understanding of MLOps principles\nKnowledge of deploying ML models in cloud environments, including serverless architectures\nFamiliarity with container technologies (Docker, Kubernetes) and orchestration systems\nUnderstanding of REST and gRPC APIs for integrating ML models into applications\nExcellent command of English, both written and verbal\nPreferred Qualifications\nGood understanding of Linux system administration and cloud ecosystems\nResponsibilities\nOptimize ML models for high performance and low latency in cloud environments\nDesign, develop, and maintain scalable and efficient ML model deployments, focusing on LLMs initially and expanding to other models\nCollaborate with the Inference team to architect and implement serverless solutions for ML model hosting\nEnsure the reliability, availability, and security of ML model deployments\nStay abreast of the latest ML technologies and cloud trends to continuously improve our offerings\nTechnical Stack\nProgramming Languages: Python, Go\nML Frameworks: TensorFlow, PyTorch\nContainer Technologies: Kubernetes, Docker\nCloud and Serverless Technologies\nLinux Systems\nData Storage: S3, PostgreSQL, Redis\nVersion Control: Git\nLocation\nThis position is based in our offices in Paris or Lille (France)\nRecruitment Process\nScreening call - 30 mins with the recruiter\nManager Interview - 45 mins\nTechnical Interviews / or Home Assignment\nTeam Interview\nHR Interview - 45 mins\nOffer sent\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "Scala",
                "R",
                "Go"
            ],
            "DataBase": [
                "SQL"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [],
            "MachingLearning": [
                "TensorFlow",
                "PyTorch"
            ],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [],
            "DevTools": [
                "Git",
                "Docker"
            ],
            "Os": [
                "Linux"
            ],
            "DBMS": [
                "PostgreSQL"
            ],
            "SoftBigDataProcessing": [],
            "Automation": [
                "Kubernetes"
            ],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [
                "Docker",
                "Kubernetes"
            ],
            "Collaboration": [],
            "Other": [
                "ML",
                "Machine Learning",
                "Cloud"
            ],
            "FrSoftSkills": [],
            "EnSoftSkils": []
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "Data scientist H/F",
        "company": "Manpower",
        "location": "Greater Saint-Etienne Metropolitan Area",
        "link": "https://fr.linkedin.com/jobs/view/data-scientist-h-f-at-manpower-3909184596?position=23&pageNum=0&refId=yQtK%2BQI72QI4xq%2BIXLe7ew%3D%3D&trackingId=pqOFKhA8DqgAh1vVazkYgA%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Vous le saviez ?\n\u200bLe m\u00e9tier de DATA SCIENTIST H/F a \u00e9t\u00e9 \u00e9lu le \u00ab m\u00e9tier le plus sexy du XXIe si\u00e8cle \u00bb, par le Harvard Business Review !\n\u200b\nRejoignez donc une \u00e9quipe passionn\u00e9e et dynamique au sein d'une entreprise incontest\u00e9e des syst\u00e8mes automatis\u00e9s et d'\u00e9nergie, qui repousse constamment les limites de la technologie et en pleine croissance !\nLes missions\nEn tant que Data Scientist H/F, vous \u00eates sensibilis\u00e9s aux risques \u00e9ventuels et vous pouvez envisager de mettre en place des mesures ad\u00e9quates pour s\u00e9curiser les donn\u00e9es et les syst\u00e8mes contre les menaces.\nVos missions seront donc :\nRassemblement, purification et manipulation d'ensembles de donn\u00e9es massifs provenant de diverses sources telles que des bases de donn\u00e9es internes et externes, des API et des donn\u00e9es non structur\u00e9es.\nConception et impl\u00e9mentation de mod\u00e8les pr\u00e9dictifs et d'algorithmes d'apprentissage automatique pour r\u00e9soudre des d\u00e9fis commerciaux complexes.\nR\u00e9alisation d'analyses statistiques approfondies afin d'identifier des tendances, des sch\u00e9mas et des insights significatifs.\nCollaboration \u00e9troite avec les \u00e9quipes interfonctionnelles pour comprendre leurs besoins en donn\u00e9es et proposer des solutions analytiques.\nCr\u00e9ation de tableaux de bord interactifs, de visualisations de donn\u00e9es et de rapports pour une communication efficace des r\u00e9sultats d'analyse aux parties prenantes.\nVeille constante sur les avanc\u00e9es technologiques en science des donn\u00e9es et proposition d'am\u00e9liorations continues pour les processus et m\u00e9thodologies existants.\nLe profil\nEt si on parlait de vous...\n\u200bVous disposez de qualifications dans les domaines des sciences des donn\u00e9es, de l'informatique, des math\u00e9matiques, des statistiques, de l'\u00e9conomie, de l'informatique, de la gestion, de l'ing\u00e9nierie industrielle ou dans des domaines connexes.\nVous avez une exp\u00e9rience pertinente dans ce domaine.\nVous \u00eates familier avec les concepts de collecte, d'extraction et d'analyse de donn\u00e9es.\nVous poss\u00e9dez des comp\u00e9tences analytiques et \u00eates capable de travailler en \u00e9quipe.\nVous \u00eates capable de pr\u00e9senter des informations complexes de mani\u00e8re claire et compr\u00e9hensible.\nVous maitrisez les langages de programmation courants tels que Python, R ou SQL ainsi que l'anglais professionnel.\nVous poss\u00e9dez des comp\u00e9tences avanc\u00e9es en analyse statistique et en mod\u00e9lisation pr\u00e9dictive.\nVous \u00eates dot\u00e9 d'une exp\u00e9rience pratique avec les biblioth\u00e8ques et les frameworks d'apprentissage automatique tels que TensorFlow, Scikit-Learn ou PyTorch.\nConditions & avantages :\nCDI Temps plein\nD\u00e9placements \u00e0 pr\u00e9voir en France et \u00e0 l'international (EMEA Germany, Italy, Spain, UK) selon besoin de l'activit\u00e9\nSalaire ouvert fonction de vos pr\u00e9tentions salariales, adaptable au profil !\nStatut cadre forfait jour\nRTT\nTickets restaurant\nParticipation et int\u00e9ressement\nVous vous reconnaissez ?\nN'h\u00e9sitez plus, postulez !!\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "R",
                " R ",
                "Go"
            ],
            "DataBase": [
                "SQL"
            ],
            "DataAnalytics": [
                "R",
                " R "
            ],
            "BigData": [],
            "MachingLearning": [
                "Scikit-Learn",
                "TensorFlow",
                "PyTorch"
            ],
            "DataSerialization": [],
            "DataVisualization": [
                "Tableau"
            ],
            "Statistics": [
                "Statistiques"
            ],
            "CloudComputing": [],
            "DevTools": [],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [
                "Statistiques"
            ],
            "FrSoftSkills": [
                "Communication",
                "Collaboration"
            ],
            "EnSoftSkils": [
                "Communication",
                "Collaboration"
            ]
        },
        "details": {
            "JobDetail": [
                "Temps plein"
            ],
            "TypeContract": [
                "CDI"
            ],
            "Salary": [
                "Salaire"
            ],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "Data Scientist H/F",
        "company": "Lincoln France",
        "location": "\u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/data-scientist-h-f-at-lincoln-france-3892490370?position=24&pageNum=0&refId=yQtK%2BQI72QI4xq%2BIXLe7ew%3D%3D&trackingId=VxQ5FtG7T3MpDPE15vlMRg%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "CDI\n\ud83d\udcca\n4 ans minimum\nChez Lincoln\n, nous formons une communaut\u00e9 d'innovateurs passionn\u00e9s qui red\u00e9finissent l'analyse de donn\u00e9es depuis\nplus de 30 ans\n. En tant que\nPure Player Data\n, notre expertise est reconnue dans les domaines\nde la Modern BI, du Big Data et de la Science des donn\u00e9es\n.\nNotre mission ?\nTransformer les donn\u00e9es en solutions concr\u00e8tes pour nos clients grands comptes dans divers secteurs tels que la banque, le retail, les t\u00e9l\u00e9coms, l'industrie, la sant\u00e9, etc.\nDescription du poste\nNous recherchons un\nData Scientist H/F\npour accompagner nos clients dans leurs projets strat\u00e9giques.\nVos missions\nCollecter, nettoyer et pr\u00e9parer les donn\u00e9es pour l'analyse.\nConcevoir, d\u00e9velopper et mettre en \u0153uvre des mod\u00e8les pr\u00e9dictifs et analytiques en utilisant des techniques avanc\u00e9es d'apprentissage automatique et de science des donn\u00e9es.\nAnalyser les r\u00e9sultats des mod\u00e8les et fournir des insights exploitables aux \u00e9quipes clients.\nCollaborer avec les \u00e9quipes interfonctionnelles pour comprendre les besoins commerciaux et recommander des solutions bas\u00e9es sur les donn\u00e9es.\nPr\u00e9requis :\nSolides comp\u00e9tences en programmation (\nPython, R, SQL, etc.)\net en manipulation de donn\u00e9es.\nExp\u00e9rience pratique avec des frameworks et des biblioth\u00e8ques d'apprentissage automatique (\nTensorFlow, PyTorch, Scikit-learn\n,\netc\n.).\nMa\u00eetrise des techniques avanc\u00e9es d'analyse de donn\u00e9es, y compris l'apprentissage automatique, l'apprentissage profond, la vision par ordinateur, le traitement du langage naturel, etc.\nExp\u00e9rience de travail en\nm\u00e9thode Agile\npour la gestion de projet et le d\u00e9veloppement de solutions.\nCapacit\u00e9 \u00e0 travailler de mani\u00e8re autonome et en \u00e9quipe.\nExcellentes comp\u00e9tences en communication et en pr\u00e9sentation.\nLes plus du poste\nEnvironnement Collaboratif\n: projets innovants favorisant le partage des connaissances.\nAccompagnement individualis\u00e9 et de proximit\u00e9\n: formations certifiantes, attribution d\u2019un Career Manager pour vous orienter dans votre trajectoire professionnelle, opportunit\u00e9s d\u2019\u00e9volution de carri\u00e8re.\nFlexibilit\u00e9 du Travail\n: T\u00e9l\u00e9travail et horaires flexibles pour votre \u00e9quilibre vie professionnelle-personnelle.\nR\u00e9mun\u00e9ration Comp\u00e9titive\n: Salaire comp\u00e9titif avec des avantages sociaux attrayants.\nMobilit\u00e9\n: Possibilit\u00e9 de mobilit\u00e9 \u00e0 Lille, Lyon ou Aix-en-Provence offrant des exp\u00e9riences diversifi\u00e9es au sein de Lincoln.\nNotre processus de recrutement :\nUn entretien RH (1h) et entretien technique (1h)\nCette annonce n\u2019est pas faite pour vous si :\nVous \u00eates freelance et vous comptez le rester !\nToujours l\u00e0 ? Postulez et rejoignez nos\n400 experts en Data\n\ud83d\ude09.\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "R"
            ],
            "DataBase": [
                "SQL"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [],
            "MachingLearning": [
                "Scikit-Learn",
                "TensorFlow",
                "PyTorch"
            ],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [],
            "DevTools": [],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [
                "Big Data"
            ],
            "FrSoftSkills": [
                "Communication",
                "Flexibilit\u00e9"
            ],
            "EnSoftSkils": [
                "Communication"
            ]
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [
                "CDI"
            ],
            "Salary": [
                "400"
            ],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s",
                "4",
                "4",
                "4"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "Data Scientist H/F",
        "company": "MERITIS",
        "location": "\u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/data-scientist-h-f-at-meritis-3869246366?position=25&pageNum=0&refId=yQtK%2BQI72QI4xq%2BIXLe7ew%3D%3D&trackingId=xPOEDHtBlsI1dkywsqirRg%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Nous recherchons un\nData Scientist\npour intervenir dans le cadre d'un\nprojet de d\u00e9tection de document.\nVos missions :\nSujet de\nfraude documentaire:\nla probl\u00e9matique est de d\u00e9tecter si un document (RIB ou pi\u00e8ce d\u2019identit\u00e9) a \u00e9t\u00e9 manipul\u00e9 (montage, remplacement de la photo d\u2019identit\u00e9, changement du nom/pr\u00e9nom, ou de l\u2019IBAN etc).\nLes technos connues utilis\u00e9es:\nPython avec les libs/framework suivants : pytorch, jupyterlab, pandas\nMod\u00e8les : layoutLM (techno \u00e0 priori assez r\u00e9cente), yolo, resnet (classique), docTR (ocr)\nConnaitre les transformers\nAutre : Labelstudio\nCe poste est-il fait pour vous\n? :\nVous \u00eates dipl\u00f4m\u00e9 d'un\nBac +5\net justifiez d'\nau moins 4 ans d'exp\u00e9rience\nVous \u00eates\nproactif et autonome \u200b\nVous aimez travailler\nau contact de plusieurs \u00e9quipes m\u00e9tiers\nConnaissance du secteur de l'assurance obligatoire\nDescriptif de l\u2019entreprise :\n\u200b\nMeritis est un cabinet de conseil, pilotage et d\u00e9veloppement IT fond\u00e9 en 2007 pr\u00e9sent \u00e0 Paris, Sophia-Antipolis, Aix-en-Provence, Montpellier, Toulouse, Nantes... Et bient\u00f4t sur de nouveaux territoires ! Notre mission ? Connecter les meilleurs talents aux entreprises pour leur donner un temps d\u2019avance.\u200b\nNous accompagnons nos clients dans l\u2019int\u00e9gralit\u00e9 de leurs besoins en transformation num\u00e9rique \u00e0 travers de nombreux domaines d\u2019expertises : Software Engineering, Finance, Pilotage de projets, Devops, Data, Cloud, Cybers\u00e9curit\u00e9 ou encore Agilit\u00e9.\u200b\nIntervenant aussi bien dans les secteurs de la Banque, de l'Assurance, des T\u00e9l\u00e9communications que de l'Industrie ou des Transports, aujourd'hui 40% des entreprises du CAC40 sont clientes Meritis.\u200b\nFort de nos valeurs d\u2019exigence, d\u2019humilit\u00e9, de bienveillance et de proximit\u00e9, nous comptons aujourd\u2019hui plus de 900 collaborateurs.\u200b\nNous mettons un point d\u2019honneur \u00e0 \u00eatre proche de nos collaborateurs et \u00e0 les accompagner de mani\u00e8re individualis\u00e9e quelles que soient leurs fonctions dans l\u2019entreprise.\nCertifi\u00e9e Great Place To Work depuis 2013, notre conception du bien-\u00eatre au travail va bien au-del\u00e0 d'un simple label, ce sont nos collaborateurs qui en parlent le mieux : https://www.glassdoor.fr/Avis/Meritis-Avis-E1163008.htm.\u200b\nVos diff\u00e9rences sont nos atouts. C\u2019est pourquoi Meritis est engag\u00e9e en faveur de la diversit\u00e9 et de la non-discrimination. Tous nos m\u00e9tiers sont accessibles aux personnes en situation de handicap. Si vous avez une question ou pensez \u00eatre victime ou t\u00e9moin d\u2019une discrimination, vous pouvez contacter ethiquegroup@meritis.fr. \u00bb\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "R"
            ],
            "DataBase": [],
            "DataAnalytics": [
                "Pandas",
                "R"
            ],
            "BigData": [],
            "MachingLearning": [
                "PyTorch"
            ],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [],
            "DevTools": [],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [
                "DevOps",
                "Cloud"
            ],
            "FrSoftSkills": [
                "Communication"
            ],
            "EnSoftSkils": [
                "Communication"
            ]
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s",
                "4",
                "4",
                "4"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "Data Scientist (F/M)",
        "company": "VINCI Airports",
        "location": "Nanterre, \u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/data-scientist-f-m-at-vinci-airports-3888479165?position=26&pageNum=0&refId=yQtK%2BQI72QI4xq%2BIXLe7ew%3D%3D&trackingId=vzqwaH6Ln5pQ3a64dvQh5g%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Premier op\u00e9rateur a\u00e9roportuaire priv\u00e9 au monde,\nVINCI Airports\ng\u00e8re plus de 70 a\u00e9roports dans 13 pays en Europe, en Asie et sur le continent am\u00e9ricain. Gr\u00e2ce \u00e0 son expertise d\u2019int\u00e9grateur global, VINCI Airports d\u00e9veloppe, finance, construit et exploite les a\u00e9roports en apportant sa capacit\u00e9 d\u2019investissement et son savoir-faire dans l\u2019optimisation de la performance op\u00e9rationnelle, la modernisation des infrastructures et la conduite de leur transition environnementale.\nNous recherchons actuellement\nun(e) Data Scientist (F/M)\nen CDI.\nRattach\u00e9(e) au D\u00e9partement Data de la Direction financi\u00e8re de VINCI Airports, vous participerez, en coordination avec les \u00e9quipes m\u00e9tiers et appuy\u00e9(e) par l\u2019\u00e9quipe d\u2019ing\u00e9nieurs Data (si\u00e8ge VINCI Airports et Pays), \u00e0 la mise en \u0153uvre du projet \u00ab SMART DATA HUB \u00bb, un projet strat\u00e9gique et passionnant, qui a pour vocation de fournir \u00e0 l\u2019ensemble des a\u00e9roports du groupe la capacit\u00e9 \u00e0 mieux piloter la performance de l\u2019activit\u00e9 autour de la Data.\nPour ce faire vous serez amen\u00e9(e) \u00e0 d\u00e9velopper des solutions avanc\u00e9es en Data Science, Mod\u00e8les de Machine Learning, avec un accent particulier sur le traitement du langage naturel (NLP) dans le d\u00e9partement Data de VINCI Airports pour les besoins de digitalisation et d\u2019am\u00e9lioration des processus de VINCI Airports.\nMissions :\nMod\u00e9lisation et pr\u00e9vision : Concevoir, d\u00e9velopper et mettre en \u0153uvre des mod\u00e8les statistiques et algorithmiques. Utiliser des m\u00e9thodes d'apprentissage automatique et d'intelligence artificielle (IA) pour cr\u00e9er des mod\u00e8les pr\u00e9dictifs.\nAnalyse des donn\u00e9es : Collecter, nettoyer et pr\u00e9parer les donn\u00e9es brutes en vue de leur analyse. Utiliser des techniques de visualisation et des outils statistiques pour explorer et comprendre les ensembles de donn\u00e9es.\nExploitation des donn\u00e9es : Identifier les opportunit\u00e9s d'am\u00e9lioration des processus et des performances en utilisant les donn\u00e9es disponibles. Travailler en \u00e9troite collaboration avec les \u00e9quipes op\u00e9rationnelles pour comprendre leurs besoins et proposer des solutions bas\u00e9es sur les donn\u00e9es.\nCommunication des r\u00e9sultats : Pr\u00e9senter les r\u00e9sultats de l'analyse de mani\u00e8re claire et compr\u00e9hensible \u00e0 des publics non techniques. Collaborer avec des \u00e9quipes multidisciplinaires pour fournir des recommandations bas\u00e9es sur les donn\u00e9es pour la prise de d\u00e9cision strat\u00e9gique.\nTravailler sur des projets impliquant des mod\u00e8les de langage comme GPT d\u00e9velopp\u00e9s par Open AI ou Google (ou autres nouvelles solutions sur le march\u00e9).\nParticiper \u00e0 des formations et des ateliers avec les analystes de VINCI Airports pour d\u00e9velopper leurs comp\u00e9tences techniques et m\u00e9thodologiques gr\u00e2ce aux solutions Data science/NLP.\nL\u2019ensemble de ces actions seront \u00e0 entreprendre sur l\u2019ensemble des domaines m\u00e9tiers de VINCI Airports : Trafic, commercial, op\u00e9rations...\nEffectuer une veille constante sur les derni\u00e8res avanc\u00e9es en Data Science, LLM et NLP pour proposer des solutions innovantes et les int\u00e9grer aux mod\u00e8les d\u00e9velopp\u00e9s par l\u2019\u00e9quipe Data.\nLe profil que nous recherchons \u00e0 ce poste :\nDipl\u00f4me universitaire (Bac+5) en statistiques, math\u00e9matiques, informatique, science des donn\u00e9es, Intelligence Artificielle ou un domaine connexe.\nExp\u00e9rience pratique dans l'analyse de donn\u00e9es et l'utilisation d'outils d'analyse tels que Python, R, SAS, SQL,\u2026\nBonne connaissance des techniques d'apprentissage automatique (machine learning), des algorithmes statistiques et de l'analyse pr\u00e9dictive.\nConnaissance approfondie des concepts de Machine Learning et des biblioth\u00e8ques telles que TensorFlow, PyTorch, Scikit-Learn.\nMotivation pour la recherche et la r\u00e9solution de probl\u00e8mes complexes.\nInt\u00e9r\u00eat et exp\u00e9rience en traitement du langage naturel (NLP), y compris la familiarit\u00e9 avec les mod\u00e8les de langage comme GPT.\nCapacit\u00e9 \u00e0 travailler de mani\u00e8re autonome et \u00e0 g\u00e9rer efficacement les projets, tout en respectant les d\u00e9lais impartis.\nComp\u00e9tences en communication orale et \u00e9crite pour pr\u00e9senter des r\u00e9sultats complexes de mani\u00e8re claire et concise.\nCuriosit\u00e9 intellectuelle et passion pour l'exploration des donn\u00e9es afin de d\u00e9couvrir des informations cach\u00e9es et de g\u00e9n\u00e9rer des id\u00e9es novatrices.\nTravail en \u00e9quipe.\nVous \u00eates capable de converser en Anglais.\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "R",
                "Go"
            ],
            "DataBase": [
                "SQL"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [],
            "MachingLearning": [
                "Scikit-Learn",
                "TensorFlow",
                "PyTorch"
            ],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [
                "Statistiques"
            ],
            "CloudComputing": [],
            "DevTools": [
                "Git"
            ],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [
                "Machine Learning",
                "Statistiques"
            ],
            "FrSoftSkills": [
                "Communication",
                "R\u00e9solution de probl\u00e8mes",
                "Collaboration"
            ],
            "EnSoftSkils": [
                "Communication",
                "Collaboration"
            ]
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [
                "CDI"
            ],
            "Salary": [],
            "Level": [
                "Bac+5"
            ],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "Machine Learning Engineer",
        "company": "Mirakl",
        "location": "Bordeaux, Nouvelle-Aquitaine, France",
        "link": "https://fr.linkedin.com/jobs/view/machine-learning-engineer-at-mirakl-3879681732?position=27&pageNum=0&refId=yQtK%2BQI72QI4xq%2BIXLe7ew%3D%3D&trackingId=VyngslIikMlHwijXXBSpww%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Mirakl, leader et pionnier de l\u2019\u00e9conomie de plateforme, propose aux entreprises une suite unique de solutions leur permettant de transformer significativement leur e-commerce afin d'acc\u00e9l\u00e9rer de fa\u00e7on durable et rentable leur croissance. Depuis 2012, Mirakl accompagne les entreprises B2C et B2B avec la technologie la plus avanc\u00e9e, s\u00e9curis\u00e9e et \u00e9volutive leur permettant de digitaliser leur activit\u00e9 et d'\u00e9largir leur offre via la marketplace ou le dropship, faciliter la gestion des catalogues et des paiements de leurs fournisseurs pour plus d'efficacit\u00e9, offrir une exp\u00e9rience d'achat personnalis\u00e9e \u00e0 leurs clients, et augmenter leurs profits gr\u00e2ce au retail media. Bas\u00e9e \u00e0 Paris et Boston, Mirakl est certifi\u00e9e Great Place to Work.\nA propos de Mirakl Labs\nNos \u00e9quipes techniques et produits, nomm\u00e9es Mirakl Labs, sont principalement r\u00e9parties entre nos 2 hubs situ\u00e9s \u00e0 Paris et \u00e0 Bordeaux. Elles collaborent au quotidien afin d'adresser les probl\u00e9matiques de nos clients et utilisateurs en r\u00e9pondant \u00e0 diff\u00e9rents challenges li\u00e9s aux nouvelles fonctionnalit\u00e9s, \u00e0 la scalabilit\u00e9, la s\u00e9curit\u00e9 et l\u2019ergonomie\u2026\nElles op\u00e8rent en mode agile et s'organisent en Squads compos\u00e9es d'un Squad Lead, de 5 d\u00e9veloppeurs, d'un Product Manager et d'un QA. Chaque Squad est sp\u00e9cialis\u00e9e sur un scope fonctionnel afin de concevoir et r\u00e9aliser de nouvelles features, leurs \u00e9volutions et des APIs (avec un d\u00e9coupage en micro-services). Nos \u00e9quipes Infrastructure, Architecture, S\u00e9curit\u00e9, Documentation, Product Design, Data et Support op\u00e8rent en transverse en apportant leur expertise et de la coh\u00e9rence sur l\u2019ensemble des produits.\nToutes les \u00e9quipes sont responsables de leur p\u00e9rim\u00e8tre et chacun des collaborateurs apporte son exp\u00e9rience et ses id\u00e9es. Innovation, feedback et implication dans les prises de d\u00e9cision sont au c\u0153ur de notre philosophie.\nEt pour favoriser ce partage avec d\u2019autres passionn\u00e9s, nous sommes sponsors, speakers, et h\u00f4tes de diff\u00e9rents \u00e9v\u00e9nements, meetups, et associations de la sc\u00e8ne Tech en France. Au cours des derni\u00e8res ann\u00e9es, nous avons particip\u00e9 \u00e0 des \u00e9v\u00e9nements tels que Devoxx, ReactEurope, ProductConf et Flupa UX Days.\nA propos du job\nInt\u00e9gr\u00e9.e dans notre \u00e9quipe Data Science, votre principale mission sera de prototyper, it\u00e9rer, et mettre en production des algorithmes en collaboration avec les \u00e9quipes Produit, les Data Engineers et les \u00e9quipes de d\u00e9veloppement. Les sujets que vous traiterez auront un vrai impact sur nos clients : l\u2019ambition est d\u2019exploiter au maximum nos donn\u00e9es riches et vari\u00e9es afin de d\u00e9velopper leur chiffre d'affaires, d\u2019optimiser la gestion op\u00e9rationnelle de leur marketplace et de garantir la s\u00e9curit\u00e9 des utilisateurs et des transactions.\nA propos de l\u2019\u00e9quipe\nGet to Know the Data Science Team That Powers the Mirakl Platform\nCe qu\u2019il y a pour vous dans ce job\nImpl\u00e9menter, optimiser et d\u00e9ployer des algorithmes qui auront un impact visible sur plus de 500 sites e-commerce/marketplaces dans 40 pays dont certains une volum\u00e9trie tr\u00e8s importantes (millions de produits, de clients, de commandes par an)\nTraiter des sujets tr\u00e8s divers et vari\u00e9s d\u2019un point de vue:\nBusiness\nMachine learning (NLP, Image processing, Time series, LLM, syst\u00e8me de recommandation, etc.)\nInfrastructure (spark, model endpoints, etc.)\nUne plateforme Machine Learning et Data Platform state-of-the-art\nConcevoir et d\u00e9ployer des infrastructures \u00e0 faible latence avec les Data Engineers\nUne vraie autonomie et responsabilit\u00e9 dans les projets dont vous avez l\u2019ownership\nLa possibilit\u00e9 d'avoir un contrat freelance ou CDI\nNotre stack et nos outils\nPython, Tensorflow, Pytorch, Databricks, Spark, Aws, Airflow, MLflow, Delta Lake, SQL\nAu quotidien\n,\nvous allez :\nDesigner, optimiser et mettre en production des mod\u00e8les de machine learning de fa\u00e7on scalable (apprentissage et inf\u00e9rence)\nRassembler et manipuler les donn\u00e9es, prototyper des algorithmes de machine learning\nMettre en place et monitorer des serving endpoints\nParticiper \u00e0 l\u2019\u00e9volution de la plateforme Machine Learning de Mirakl\nContinuer \u00e0 mettre en place des best practices de programmation mais aussi de d\u00e9ploiement\nEffectuer de la veille technologique sur les mod\u00e8les state-of-the-art, ainsi que sur les stack machine learning\nPr\u00e9senter les r\u00e9sultats au weekly data science et aux sessions de brainstorming de l\u2019\u00e9quipe\n\u00c9changer avec les autres \u00e9quipes pour affiner les cas d\u2019utilisation, l\u2019exp\u00e9rience utilisateur et les modes d\u2019int\u00e9gration\nVous aimerez ce job si :\nVous avez minimum 3 ans d\u2019exp\u00e9rience en tant que Machine Learning Engineer (le poste est \u00e9volutif selon votre s\u00e9niorit\u00e9)\nVous avez de solides comp\u00e9tences en d\u00e9veloppement Python\nVous aimez le software engineering et le machine learning\nVous avez une exp\u00e9rience significative dans la mise en production, le scaling des mod\u00e8les et des bests practices MLOps\nVous avez l\u2019habitude de chercher, manipuler et analyser des donn\u00e9es \u00e0 forte volum\u00e9trie, id\u00e9alement avec Spark\nVous avez une bonne connaissance des algorithmes de Deep Learning (texte et/ou image), des architectures State-Of-the-Art - par exemple les Transformers\nVous avez de l\u2019exp\u00e9rience dans l\u2019optimisation de mod\u00e8les de machine learning et de leur inf\u00e9rence\nVous avez de l\u2019exp\u00e9rience dans la mise en place de serving de mod\u00e8les\nVous aimez avoir l\u2019ownership de vos sujets et aimez partager votre travail dans le cadre de pr\u00e9sentations internes, dans des conf\u00e9rences ou en r\u00e9digeant des articles\nPetit plus :\nVous avez une exp\u00e9rience en environnement e-commerce, sur des algorithmes de syst\u00e8mes de recommandations et/ou retail media*\nVous avez une exp\u00e9rience dans le serving de mod\u00e8les \u00e0 faible latence\nVous \u00eates sp\u00e9cialiste NLP\nOptimisation de LLM\nMirakl est engag\u00e9e en faveur de la diversit\u00e9, de l\u2019\u00e9galit\u00e9 des chances et de l\u2019inclusion. Nous c\u00e9l\u00e9brons nos diff\u00e9rences car nous sommes convaincus que les qualit\u00e9s visibles et invisibles de chaque Mirakl Worker sont une source de force et d\u2019innovation. Dans le cadre de cet engagement, nous \u00e9tudions toutes les candidatures sans distinction de : genre, ethnicit\u00e9, religion, orientation sexuelle, handicap, \u00e2ge ou toute autre caract\u00e9ristique prot\u00e9g\u00e9e par la loi.\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "Scala",
                "R",
                "Go"
            ],
            "DataBase": [
                "SQL"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [
                "Spark",
                "Databricks"
            ],
            "MachingLearning": [
                "TensorFlow",
                "PyTorch"
            ],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [
                "AWS"
            ],
            "DevTools": [
                "Git"
            ],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [
                "Airflow"
            ],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [
                "ML",
                "Machine Learning"
            ],
            "FrSoftSkills": [
                "Collaboration"
            ],
            "EnSoftSkils": [
                "Collaboration"
            ]
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [
                "CDI"
            ],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s",
                "3",
                "3",
                "3"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "Data Scientist",
        "company": "Unreal Staffing, Inc",
        "location": "Paris, \u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/data-scientist-at-unreal-staffing-inc-3913911173?position=28&pageNum=0&refId=yQtK%2BQI72QI4xq%2BIXLe7ew%3D%3D&trackingId=YOZu13Kgh9UhRtY6c002%2FA%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "About Us\nThe fashion industry contributes significantly to global greenhouse gas emissions. To address this, we developed a Carbon Management Platform tailored for the textile and fashion industry. We automate life-cycle assessment to help brands understand and reduce their environmental footprint.\nData At Our Company\nOur Data team manages customer data parsing and analytics. We clean and normalize customer data for accurate analysis and provide analytics on product-level environmental impacts.\nRequirements\nWhat You'll Be Working With\nInteresting data: Our data describes physical objects, such as shoes, t-shirts, and packaging boxes, enabling real insights into the environmental impact of products\nUnique opportunity: Apply your data science skills to reduce the environmental footprint of fashion companies\nWhat We're Looking For\nStrong communication skills\nExperience with heterogeneous data and basic NLP techniques\nProficiency in Python and SQL\nBasic software engineering skills\nBenefits\nRemote work in Europe\nCoworking space allowance up to \u20ac300/month\nModern amenities including MacBook, headset, ChatGPT subscription, GitHub Copilot, etc\n100% health insurance coverage with Alan at the best coverage level\nOption to work from our office in Paris\nWork retreats organized 3 times a year\nTransparent compensation package with salary range \u20ac60k - \u20ac80k and significant equity\nOpportunities for promotion based on performance and impact on the company\nStrong belief in open-source software and contribution to the community\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "R"
            ],
            "DataBase": [
                "SQL"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [],
            "DevTools": [
                "Git"
            ],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [],
            "FrSoftSkills": [
                "Communication"
            ],
            "EnSoftSkils": [
                "Communication"
            ]
        },
        "details": {
            "JobDetail": [
                "Remote"
            ],
            "TypeContract": [],
            "Salary": [
                "60k",
                "60k"
            ],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "Data Scientist - Python (Mid-senior, Senior)",
        "company": "Pathway",
        "location": "Paris, \u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/data-scientist-python-mid-senior-senior-at-pathway-3887683294?position=29&pageNum=0&refId=yQtK%2BQI72QI4xq%2BIXLe7ew%3D%3D&trackingId=8Z9%2F32JrjFfrpYPIa3H87Q%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "About Pathway\nDeeptech start-up, founded in March 2020.\nOur primary developer offering is an ultra-performant Data Processing Framework (unified streaming + batch) with a Python API, distributed Rust engine, and capabilities for data source integration & transformation at scale (Kafka, S3, databases/CDC,...)\nThe single-machine version is provided on a free-to-use license (`pip install pathway`)\nMajor data use cases are around event-stream data (including real-world data such as IoT), and graph data that changes over time\nOur enterprise offering is currently used by leaders of the logistics industry, such as DB Schenker or La Poste, and tested across multiple industries. Pathway has been featured in Gartner's market guide for Event Stream Processing\nLearn more at http://pathway.com/ and https://github.com/pathwaycom/\nPathway is VC-funded, with amazing BAs from the AI space and industry. We have operations across Europe and in the US. We are headquartered in Paris, with significant support from the French ecosystem (BPI, Agoranov, WILCO,...).\nThe Team\nPathway is built by and for overachievers. Its co-founders and employees have worked in the best AI labs in the world (Microsoft Research, Google Brain, ETH Zurich), worked at Google, and graduated from top universities (Polytechnique, ENSAE, Sciences Po, HEC Paris, PhD obtained at the age of 20, etc...). Pathway's CTO is a co-author with Goeff Hinton and Yoshua Bengio. The management team also includes the co-founder of Spoj.com (1M+ developer users) and NK.pl (13.5M+ users) and experienced growth leader who has scaled companies with multiple exits.\nThe opportunity\nWe are currently searching for\nData Scientists\nwith\nexperience in the Python stack\n, to help explore and discover the most pertinent insights in datasets on spatio-temporal event streams. In this job, statistical rigor and beauty of visualization meet on equal footing.\nYou Will\nbe working with spatiotemporal data with advanced schemas (time-changing graph models)/\nbe designing data cross-sections, proposing analytics metrics and KPI's in line with clients' objectives, selecting clustering algorithms, and preparing visualizations, to enable fast data exploration and insight discovery - all within our product\nbe designing dashboards in SQL with some Python elements/extensions\nbe directly helping us with Customer Conversion and Adoption within Customer organizations, by contributing to both deployment instances and \"demonstrators\" of our product, performed on client data sets\nwork directly with our Product Owner and CTO to propose and implement extensions to our product, based on repetitive client needs\ndepending on your seniority, implement machine learning algorithms on spatiotemporal event streams and other geospatial data\nThe results of your work will play a crucial role in proving how our technology can help with compelling industry use cases.\nRequirements\nYou Are\nReady for hands-on contribution to the product, helping to ensure the success of demonstrators for clients, and contribution to product codebase\nIntuitive, with good visual taste, and good common sense judgment\nCommitted to beautiful user-centered design: you know that stories are made for people, and you are willing to listen to what they have to say\nCurious at heart and thrilled to work with real-world data, especially spatio-temporal data\nLike trains, trucks, cranes, pythons, pandas, and other things that move\nNot afraid to switch between the roles of data scientist, data-vis magician, statistician, engineer, and detective, at a moment's notice\nHave 2 years+ experience in positions related to Data Science.\nHave a very good working knowledge of Python\nKnow SQL. Are able to work with tables and other data types (arrays, json,...)\nWould be able to implement the Transit Node Routing algorithm in Python just based on reading its Wikipedia article\nHave experience with git, build systems, and CI/CD\nHave at least basic undergrad textbook familiarity with graph algorithms, finite automata, and text (string) search algorithms\nUnderstand statistical concepts, such as correlated random variables, significance, and non-Gaussian noise\nPrepared to be quizzed & grilled by the datasets you encounter, everyday. Here are some questions you should be able to answer off the top of your head: what can \"-273.15\" signify; why \"65535\" is a suspicious integer value; how many months does it take a containership to go around the world; and, roughly what order of g-force is attained by an astronaut in a space rocket at liftoff?\nRespectful of others\nFluent in English\nBonus Points\nShowing a portfolio: code on github, visualization works, a research paper or a PhD thesis with an original statistical / probabilistic analysis or experiment design,..\nSuccessful track-record in Data Science or algorithms contests (Kaggle, Codeforces,...)\nExperience in topics linked to logistics/moving assets\nFamiliarity with some form of GIS software\nFamiliarity with Pandas, SciPy, NetworkX, and similar tools from the Python stack\nExperience in Data Visualization and UX\nSome knowledge of French, Polish, or German\nWhy You Should Apply\nJoin an intellectually stimulating work environment\nBe a pioneer: you get to work with a new type of data processing\nWork in one of the hottest data/AI startups in France\nUncover exciting career prospects\nMake significant contribution to our success\nJoin & co-create an inclusive workplace culture\nBenefits\nType of contract: Permanent employment contract\nPreferable joining date: February 2023. The positions (at least 2) are open until filled\nCompensation: annual salary of \u20ac50K-\u20ac70K (mid) up to \u20ac60K-\u20ac90K (senior, upper band negotiable) + Employee stock option plan\nLocation: Remote work from home. Possibility to work or meet with other team members in one of our offices:\nParis Area - Drahi X-Novation Center, Ecole Polytechnique, Palaiseau\nParis - Agoranov (where Doctolib, Alan, and Criteo were born) near Saint-Placide Metro (75006)\nWroclaw - University area\nPermanent residence will be required in France or Poland, exceptional candidates will be considered anywhere in the EU.\nIf you meet our broad requirements but are missing some experience, don't hesitate to reach out to us.\nNote\n: CS & engineering school students with exceptional profiles and/or strong motivation to join Pathway are invited to apply for Data Science internships. (Minimum duration: 5-6 months, remuneration level: \u20ac1500 / month.)\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "R",
                "Go"
            ],
            "DataBase": [
                "SQL"
            ],
            "DataAnalytics": [
                "Pandas",
                "R"
            ],
            "BigData": [],
            "MachingLearning": [],
            "DataSerialization": [
                "Json"
            ],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [],
            "DevTools": [
                "Git"
            ],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [
                "Machine Learning",
                "CI/CD"
            ],
            "FrSoftSkills": [],
            "EnSoftSkils": [
                "Organization"
            ]
        },
        "details": {
            "JobDetail": [
                "Remote",
                "Senior"
            ],
            "TypeContract": [],
            "Salary": [
                "50K"
            ],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "Ing\u00e9nieur Data scientist \u2013Intelligence artificielle-  IDF, France (H/F)",
        "company": "Astek",
        "location": "\u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/ing%C3%A9nieur-data-scientist-%E2%80%93intelligence-artificielle-idf-france-h-f-at-astek-3886897805?position=30&pageNum=0&refId=yQtK%2BQI72QI4xq%2BIXLe7ew%3D%3D&trackingId=%2BpRfK1D3sBWSXTZF%2FMOYsg%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Ce que nous allons accomplir ensemble :\nPour l\u2019un de nos projets dans le domaine a\u00e9ronautique, vous interviendrez en tant\nqu\u2019ing\u00e9nieur Data scientist / Intelligence artificielle\nsur la mise en place de syst\u00e8mes experts destin\u00e9s aux avions civils et militaires.\nVotre future \u00e9quipe :\nTeam IT de 12 personnes\nData scientist, ing\u00e9nieurs syst\u00e8mes, int\u00e9grateurs, architectes\nVous travaillerez avec de v\u00e9ritables passionn\u00e9s !\nVotre mission (...si vous l\u2019acceptez !) :\nVous participerez au d\u00e9veloppement des fonctions d\u2019analyses multisyst\u00e8mes. Pour cela vous assurerez l\u2019\u00e9tablissement d\u2019une sp\u00e9cification formelles sur les mod\u00e8les d\u2019analyses.\nVous assurerez l\u2019analyse des donn\u00e9es et la proposition de m\u00e9thodes pour le traitement des signaux.\nVous d\u00e9velopperez les outils capables de traiter de mani\u00e8re automatique les donn\u00e9es syst\u00e8mes.\nVous assurerez la r\u00e9alisation des sc\u00e9narios, ainsi que les tests et simulations.\nVous r\u00e9aliserez \u00e9galement une activit\u00e9 de support.\nVotre stack de jeu :\nData scientist, python, principe de gestion de configuration, et tra\u00e7abilit\u00e9, syst\u00e8mes a\u00e9ronautiques, intelligence artificielle\nLes petits plus du projet :\nVous \u00e9voluerez au sein d\u2019\u00e9quipes agiles impliqu\u00e9es et r\u00e9actives.\nVous interviendrez de A \u00e0 Z sur des projets riches fonctionnellement et ambitieux techniquement :\nforte volum\u00e9trie, haut niveau de performance, exigence maximale en termes d\u2019intelligence artificielle et encore bien d'autres sujets captivants.\nVous ?\nDe formation Ing\u00e9nieur, vous justifiez d\u2019une exp\u00e9rience significative en Data scientist et ou Intelligence artificielle.\nUne connaissance des m\u00e9thodes d\u2019analyse de donn\u00e9es serait un plus.\nId\u00e9alement vous avez une connaissance des syst\u00e8mes a\u00e9ronautiques.\nDes postes \u00e9galement ouverts aux d\u00e9butants si stages significatifs.\nNous ?\nCr\u00e9\u00e9 en France en 1988, Astek est un acteur mondial de l\u2019ing\u00e9nierie et du conseil en technologies, pr\u00e9sent sur les 5 continents. Fort de son expertise dans de nombreux secteurs industriels et tertiaires, Astek accompagne ses clients internationaux dans le d\u00e9ploiement intelligent de leurs produits et de leurs services, et dans la mise en \u0153uvre de leur transformation digitale.\nDepuis sa cr\u00e9ation, le Groupe a fond\u00e9 son d\u00e9veloppement sur une forte culture d\u2019entrepreneuriat et d\u2019innovation, et sur l\u2019accompagnement et la mont\u00e9e en comp\u00e9tence de ses 5 200 collaborateurs qui s\u2019engagent chaque jour \u00e0 promouvoir la compl\u00e9mentarit\u00e9 entre les technologies num\u00e9riques et l\u2019ing\u00e9nierie des syst\u00e8mes complexes.\nRejoignez un Groupe en fort d\u00e9veloppement en France et \u00e0 travers le monde gr\u00e2ce \u00e0 une lev\u00e9e de fonds de 200M\u20ac r\u00e9alis\u00e9e en 2021. Ensemble \u00ab Let\u2019s move forward! \u00bb\n\u2728 Tous les d\u00e9tails sur le Groupe sur le site\nhttps://astekgroup.fr.\nEt vous pouvez aussi nous suivre sur\nnotre blog : https://blog.groupeastek.com\n.\nRencontrons-nous !\nVous vous \u00eates reconnu sur l\u2019annonce et Astek vous pla\u00eet !\nPour en savoir plus sur vous, Franck , notre Talent Acquisition vous contacte. Puis, vous aurez 3 entretiens max, avec L\u00e9onard (votre futur n+1), L\u00e9onard notre Directeur !\nNos plus\nAstek est green et fait b\u00e9n\u00e9ficier ses salari\u00e9s d\u2019une indemnit\u00e9 kilom\u00e9trique v\u00e9lo\nUn programme CARE sur-mesure d\u00e9ploy\u00e9 par nos \u00e9quipes RH pour nos collaborateurs : https://astekgroup.fr/engagements\nNotre charte de la Diversit\u00e9\nBienvenue dans la team ! Allez-y, maintenant c\u2019est \u00e0 vous de jouer !\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "R"
            ],
            "DataBase": [],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [],
            "DevTools": [
                "Git"
            ],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [],
            "FrSoftSkills": [],
            "EnSoftSkils": []
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "Data scientist H/F",
        "company": "MP DATA",
        "location": "Clermont-Ferrand, Auvergne-Rh\u00f4ne-Alpes, France",
        "link": "https://fr.linkedin.com/jobs/view/data-scientist-h-f-at-mp-data-3904074177?position=31&pageNum=0&refId=yQtK%2BQI72QI4xq%2BIXLe7ew%3D%3D&trackingId=J6F2hFOY0AwUYhiTRYoWOw%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "MP DATA est une soci\u00e9t\u00e9 sp\u00e9cialis\u00e9e dans l\u2019acquisition, le traitement, et la valorisation des donn\u00e9es. Depuis sa cr\u00e9ation en 2015, MP DATA accompagne ses clients, majoritairement industriels, dans le management de leur performance et l\u2019exploitation de leur donn\u00e9e.\nLes collaborateurs, tous issus de grandes \u00e9coles, incarnent au quotidien les valeurs d\u2019Excellence, de Partage et d\u2019Engagement. Ils associent savoir-faire technique, m\u00e9thodologie et passion et mettent leurs comp\u00e9tences au service de missions et projets au sein de grands groupes fran\u00e7ais.\nMP DATA accompagne ses clients sur toute la chaine au travers de 3 p\u00f4les d\u2019expertise : Conseil et Strat\u00e9gie, Infrastructure & CloudOPS, Data Science.\nNous recherchons un(e) Data Scientist passionn\u00e9(e) pour rejoindre notre \u00e9quipe dynamique.\nEn tant que membre cl\u00e9 du p\u00f4le Data Science de notre client, un grand acteur du secteur automobile, vous serez charg\u00e9(e) d'analyser, interpr\u00e9ter et exploiter les donn\u00e9es pour fournir des solutions innovantes \u00e0 nos clients.\nConception et mise en \u0153uvre de mod\u00e8les pr\u00e9dictifs et d'algorithmes avanc\u00e9s.\nAnalyse approfondie des donn\u00e9es pour identifier des tendances et des opportunit\u00e9s.\nCollaboration \u00e9troite avec les \u00e9quipes clients pour comprendre leurs besoins et d\u00e9finir des solutions sur mesure.\nParticipation active \u00e0 la veille technologique et \u00e0 l'am\u00e9lioration continue de nos pratiques en Data Science.\nProfil :\nDipl\u00f4me\ning\u00e9nieur Grande \u00c9cole\nen Data Science, Statistiques, Informatique ou domaine connexe.\nExp\u00e9rience pratique dans le d\u00e9veloppement et l'application de mod\u00e8les pr\u00e9dictifs,\nMa\u00eetrise des langages de programmation tels que Python,\nExcellentes comp\u00e9tences analytiques et capacit\u00e9 \u00e0 traduire des r\u00e9sultats complexes en recommandations claires,\nForte aptitude \u00e0 travailler en \u00e9quipe et \u00e0 communiquer efficacement.\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "R",
                "Go"
            ],
            "DataBase": [],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [
                "Statistiques"
            ],
            "CloudComputing": [],
            "DevTools": [],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [
                "Statistiques",
                "Cloud"
            ],
            "FrSoftSkills": [
                "Collaboration"
            ],
            "EnSoftSkils": [
                "Collaboration"
            ]
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "Machine Learning Developer",
        "company": "MindPal",
        "location": "Toulouse, Occitanie, France",
        "link": "https://fr.linkedin.com/jobs/view/machine-learning-developer-at-mindpal-3896992755?position=32&pageNum=0&refId=yQtK%2BQI72QI4xq%2BIXLe7ew%3D%3D&trackingId=HzkCAJL5IgT2jewzT8XLnQ%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "We are looking for\nMachine Learning Developer\nJob Responsibilities\nWorking on machine learning projects\nAnalyzing and processing data to create machine learning models\nImplementing and optimizing machine learning algorithms\nTesting and evaluating models\nCollaborating with the programming team and other departments within the company to develop innovative solutions\nRequirements\nMinimum 2 years of experience in the field of machine learning\nKnowledge of machine learning algorithms and techniques\nAbility to analyze and process data\nFamiliarity with machine learning tools and technologies\nProficient in English communication\nEducation in computer science\nWe Offer\nB2B contract type\nFull-time employment\nRemote and flexible working hours\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "R",
                "Go"
            ],
            "DataBase": [],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [],
            "DevTools": [],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [
                "Machine Learning"
            ],
            "FrSoftSkills": [
                "Communication"
            ],
            "EnSoftSkils": [
                "Communication"
            ]
        },
        "details": {
            "JobDetail": [
                "Remote",
                "Full"
            ],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "Machine Learning Engineer",
        "company": "Enzo Tech Group",
        "location": "Paris, \u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/machine-learning-engineer-at-enzo-tech-group-3914687840?position=33&pageNum=0&refId=yQtK%2BQI72QI4xq%2BIXLe7ew%3D%3D&trackingId=NdlwdYY5RySLcq4VgUN4ZQ%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Position:\nMachine Learning Engineer / MLOps Engineer / AI Engineer\nLocation:\nParis\nType:\nFreelance, Contract\nDuration:\n6 months\nSearching for a\nMLOps Engineer\nto lead the implementation of\nMLOps\npractices at scale with a focus on\nlarge language models\n(LLM)\n.\nRole:\nLead the implementation of\nMLOps\npractices at scale, focusing on industrialising AI solutions and ensuring their efficient deployment.\nCollaborate with software engineering teams to integrate machine learning models into production environments.\nManage and optimise\nAI infrastructure\non\nAzure\n, including\nDatabricks\nclusters and other relevant technologies.\nDevelop and maintain automation pipelines for model training, testing, monitoring, and retraining.\nRequirements\nProven experience as an MLOps Engineer or similar role, with expertise in large-scale AI deployments.\nDeep understanding of MLOps principles, including model versioning\nExpertise and support to data scientists and engineers working on AI initiatives.\nCVs: s.allenby@enzotechgroup.com\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "R"
            ],
            "DataBase": [],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [
                "Databricks"
            ],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [
                "Azure"
            ],
            "DevTools": [],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [
                "Teams"
            ],
            "Other": [
                "ML",
                "Machine Learning"
            ],
            "FrSoftSkills": [],
            "EnSoftSkils": [
                "Initiative"
            ]
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "Data Scientist (M/W)",
        "company": "Mines Paris",
        "location": "Valbonne, Provence-Alpes-C\u00f4te d'Azur, France",
        "link": "https://fr.linkedin.com/jobs/view/data-scientist-m-w-at-mines-paris-3908686193?position=34&pageNum=0&refId=yQtK%2BQI72QI4xq%2BIXLe7ew%3D%3D&trackingId=ftiG2eHI0umbtJ%2B7auSKhw%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "\u00c0 propos de nous\nMines Paris est une des plus prestigieuses \u00e9coles d'ing\u00e9nieurs en France. Mines Paris est un \u00e9tablissement public qui forme des ing\u00e9nieurs g\u00e9n\u00e9ralistes via une exp\u00e9rience p\u00e9dagogique innovante et pluridisciplinaire (sciences de l'ing\u00e9nieur et sciences humaines et sociales). Son appartenance \u00e0 l'Universit\u00e9 PSL, qui se positionne dans le top 50 des classements internationaux, constitue une v\u00e9ritable opportunit\u00e9 d'enrichissement des parcours.\nMission\nYour Environment\nAs part of the scientific program of The Transition Institute 1.5 (TTI.5), which focuses on the conditions for the emergence of a transition to a low-carbon planet, taking into account technical, social, economic, political and geopolitical issues, Mines Paris - PSL has an opening for a Data Scientist.\nInsofar as these issues may represent obstacles to the transition, it is essential to understand their fundamentals and decipher the mechanisms that drive them. The TTI.5 scientific program has been designed to harmonize, enhance and extend the various research projects already on offer at Mines Paris - PSL. It is also intended to provide new impetus in areas that have been little addressed until now, but which are nonetheless essential to steering the transition, or to filling gaps such as that of a complete vision of the distribution of resources worldwide.\nYour Challenges And Responsabilities\nIn order to tackle the various transition strategies, it is essential to have a picture of the production of the various raw materials needed for today's and tomorrow's world. At the same time, the exploitation and circulation of different resources can be strongly impacted by geopolitical conditions and times of tension and conflict.\nThe aim of this project, with its high methodological stakes, is to develop and couple:\nglobal resource mapping for two critical \"identifiable\" resources (lithium and cobalt)\na mapping of armed tensions (conflicts, installation of military bases, etc.).\nTo achieve this, we will need to develop a tool for extracting data from a very large mass of information, to be identified, in a changing context that will need to be taken into account for the tool's sustainability.\nThe Development Prospects For This Work Could Include\na double cartography animated over time ;\nthe enrichment of military base and tension indicators, with an equal focus on cases of local armed non-tension around the resource\na scalable database that can be continuously updated\na tool that can be replicated for other resources in a rapidly changing world\nProfil\nLet's talk about you !...\nThe position is aimed at an engineer / master data scientist with a degree from a university or Grande Ecole. Additional skills in GIS would be a plus. He/she may receive in-house training on mining resource issues.\nThe candidate will be strongly encouraged to participate in TTI.5 activities, and may also take part in those of the referral centers. He/she must have demonstrated good teamwork skills.\nFluency in spoken and written English is imperative.\nKnowledge And Skills\nThe main skills required for this post are :\nMastery of algorithms and programming languages (ability to write efficient, scalable code)\nMastery of data management language and databases (ability to find, collect and analyze large volumes of data)\nMastery of data visualization tools\nSoft Skills\nSelf-motivated\nSpirit of initiative\nSense of teamwork\ncreativity\nFlexibility\nCommunication and teaching skills\nAnalytical skills\nThoroughness\n\u2026And about us ! Working at Mines Paris also means :\nJoining a prestigious institution with a rich history\nPlaying a part in the digital transition and the transition to carbon neutrality to tackle the climate emergency\nBelonging to PSL University, ranked 41st in the Academic Ranking of World Universities\nJoin a dynamic, multidisciplinary team!\nA pleasant living environment in a pine forest, at the heart of the 1st technology cluster on the C\u00f4te d'Azur and 1st technology park in Europe!\nR\u00e9f\u00e9rence de l'offre : 6jpx490r88\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Scala",
                "R",
                "Go"
            ],
            "DataBase": [],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [],
            "DevTools": [
                "Git"
            ],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [],
            "FrSoftSkills": [
                "Communication"
            ],
            "EnSoftSkils": [
                "Communication",
                "Teamwork",
                "Creativity",
                "Flexibility",
                "Initiative"
            ]
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "Data Scientist (H/F) \u2013 Digital Factory",
        "company": "TNP Consultants",
        "location": "Paris, \u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/data-scientist-h-f-%E2%80%93-digital-factory-at-tnp-consultants-3591227915?position=35&pageNum=0&refId=yQtK%2BQI72QI4xq%2BIXLe7ew%3D%3D&trackingId=YBmYpDdSnkcUOVH060pqcQ%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Pr\u00e9sentation de TNP Consultants\nFort de 450 collaborateurs, TNP est un cabinet de conseil ind\u00e9pendant multi-sp\u00e9cialiste et multisectoriel, pr\u00e9sent en France, au Maroc, au Luxembourg, en Suisse et en Inde. Acc\u00e9l\u00e9rateur de performance, nous intervenons dans la mise en place de programmes de transformation sur les probl\u00e9matiques r\u00e9glementaires, excellence op\u00e9rationnelle, digital et business solutions dans les secteurs banque, assurance & protection sociale, le secteur public et industrie & services.\nCette ann\u00e9e, TNP recrute 200 collaborateurs ! Pour accompagner nos clients dans le cadre de leur transformation digitale, nous recherchons des consultants Data Scientists (H/F).\nVOTRE R\u00d4LE AU SEIN DE L\u2019\u00c9QUIPE DATA SCIENTIST\nAu Sein De La DIGITAL FACTORY, Vous Participerez Au D\u00e9veloppement Des Activit\u00e9s Data Science. Vous Serez Notamment En Charge\nD\u2019aider nos clients \u00e0 d\u00e9finir les use cases m\u00e9tiers et proposer des d\u00e9marches d\u2019\u00e9tudes adapt\u00e9es aux contextes et aux enjeux m\u00e9tiers ;\nDe mod\u00e9liser des ph\u00e9nom\u00e8nes et restituer des analyses \u00e0 l\u2019usage des m\u00e9tiers (Data Visualisation) ;\nDe prototyper des outils d\u2019analyse ou de pr\u00e9diction utilisables par les m\u00e9tiers ;\nDe former et accompagner les m\u00e9tiers dans l\u2019utilisation de ces outils ;\nAccompagner des mont\u00e9es en comp\u00e9tences d\u2019autres Data Scientists.\nDe mettre en production les mod\u00e8les et Dashboard d\u00e9velopp\u00e9s dans un outil de cloud.\nVOTRE PROFIL\nVous \u00eates dipl\u00f4m\u00e9s d\u2019une \u00e9cole d\u2019ing\u00e9nieur ou d\u2019un master 2 en Math\u00e9matiques, informatiques et/ou statistiques. Vous justifiez d\u2019au moins 4 ann\u00e9es d\u2019exp\u00e9rience au sein d\u2019un cabinet de conseil.\nComp\u00e9tences techniques requises\nVous maitrisez la programmation en Python/R.\nVous avez un excellent niveau en statistique.\nVous avez des connaissances th\u00e9oriques et pratiques dans la mod\u00e9lisation en Machine Learning et Deep Learning (Mod\u00e8les d\u2019agr\u00e9gation, R\u00e9seaux de neurone)\nVous avez d\u00e9j\u00e0 utilis\u00e9 au moins une solution cloud comme AWS /Azure.\nGestion des codes : Git, Bitbucket\nVous disposez d\u2019un bon niveau d\u2019anglais.\nSoft Skills\nPassionn\u00e9 par la data et l\u2019IA\nEsprit de synth\u00e8se et d\u2019analyse\nRigoureux pour assurer une qualit\u00e9 de livrables et didactique pour pr\u00e9senter les sujets aux m\u00e9tiers\nSens de l\u2019\u00e9coute et de la communication\nSavoir travailler en \u00e9quipe\nCurieux et cr\u00e9atif\nUn \u00e9tat d\u2019esprit orient\u00e9 business et apport de valeur pour les \u00e9quipes m\u00e9tiers ;\nCoach\u00e9(e) tout au long de votre carri\u00e8re, vous b\u00e9n\u00e9ficierez d\u2019une formation continue, pour enrichir votre expertise et accompagner votre d\u00e9veloppement personnel. En \u00e9troite collaboration avec les Associ\u00e9s, vous \u00e9voluerez dans un cabinet ind\u00e9pendant en forte croissance et intervenant aupr\u00e8s des grands comptes en France et \u00e0 l\u2019international.\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "R",
                "Go"
            ],
            "DataBase": [],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [
                "Statistiques"
            ],
            "CloudComputing": [
                "AWS",
                "Azure"
            ],
            "DevTools": [
                "Git"
            ],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [
                "Machine Learning",
                "Statistiques",
                "Cloud"
            ],
            "FrSoftSkills": [
                "Communication",
                "Collaboration"
            ],
            "EnSoftSkils": [
                "Communication",
                "Collaboration"
            ]
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "ML Engineer",
        "company": "Scaleway",
        "location": "Lille, Hauts-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/ml-engineer-at-scaleway-3828506145?position=36&pageNum=0&refId=yQtK%2BQI72QI4xq%2BIXLe7ew%3D%3D&trackingId=sBm7Q6tnfv5hsdx68AV4aw%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "About The Job\nThe newly established Inference team at Scaleway is on a mission to revolutionize how Machine Learning (ML) is deployed and scaled in the cloud. We are seeking a talented ML Engineer to join us in developing and deploying Large Language Model (LLM) endpoints on both dedicated instances and serverless environments. As we plan to broaden our offerings to include various types of ML models later this year, this role offers a unique opportunity to be at the forefront of ML technology and its application in the cloud.\nReporting to our Manager, Gr\u00e9goire de Turckheim, you will play a crucial role in building and optimizing ML model deployments, ensuring high performance, scalability, and reliability.\nMinimum Qualifications\nProficient in Python and familiar with other programming languages such as Go\nStrong background in Machine Learning, including experience with LLMs, NLP, or other ML model types\nExperience with ML frameworks (e.g., TensorFlow, PyTorch) and understanding of MLOps principles\nKnowledge of deploying ML models in cloud environments, including serverless architectures\nFamiliarity with container technologies (Docker, Kubernetes) and orchestration systems\nUnderstanding of REST and gRPC APIs for integrating ML models into applications\nExcellent command of English, both written and verbal\nPreferred Qualifications\nGood understanding of Linux system administration and cloud ecosystems\nResponsibilities\nOptimize ML models for high performance and low latency in cloud environments\nDesign, develop, and maintain scalable and efficient ML model deployments, focusing on LLMs initially and expanding to other models\nCollaborate with the Inference team to architect and implement serverless solutions for ML model hosting\nEnsure the reliability, availability, and security of ML model deployments\nStay abreast of the latest ML technologies and cloud trends to continuously improve our offerings\nTechnical Stack\nProgramming Languages: Python, Go\nML Frameworks: TensorFlow, PyTorch\nContainer Technologies: Kubernetes, Docker\nCloud and Serverless Technologies\nLinux Systems\nData Storage: S3, PostgreSQL, Redis\nVersion Control: Git\nLocation\nThis position is based in our offices in Paris or Lille (France)\nRecruitment Process\nScreening call - 30 mins with the recruiter\nManager Interview - 45 mins\nTechnical Interviews / or Home Assignment\nTeam Interview\nHR Interview - 45 mins\nOffer sent\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "Scala",
                "R",
                "Go"
            ],
            "DataBase": [
                "SQL"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [],
            "MachingLearning": [
                "TensorFlow",
                "PyTorch"
            ],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [],
            "DevTools": [
                "Git",
                "Docker"
            ],
            "Os": [
                "Linux"
            ],
            "DBMS": [
                "PostgreSQL"
            ],
            "SoftBigDataProcessing": [],
            "Automation": [
                "Kubernetes"
            ],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [
                "Docker",
                "Kubernetes"
            ],
            "Collaboration": [],
            "Other": [
                "ML",
                "Machine Learning",
                "Cloud"
            ],
            "FrSoftSkills": [],
            "EnSoftSkils": []
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "ML ENGINEER",
        "company": "STATION F",
        "location": "Paris, \u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/ml-engineer-at-station-f-3852509522?position=37&pageNum=0&refId=yQtK%2BQI72QI4xq%2BIXLe7ew%3D%3D&trackingId=W%2BvJiwmk3Ubk9B3dmp5jBw%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "\u00c0 propos\nFond\u00e9e par Flore, Christian et Tristan,\nVeeton\nambitionne de r\u00e9volutionner la photographie commerciale.\nVeeton d\u00e9veloppe une technologie de pointe permettant aux marques de mode de\ng\u00e9n\u00e9rer\nleur\nshooting e-commerce\nen\nun clic\n.\nLa recherche et le d\u00e9veloppement tech sont au c\u0153ur du projet. En quelques mois :\nNous avons d\u00e9ploy\u00e9 avec succ\u00e8s 2 versions de notre mod\u00e8le pionnier\nNous sommes incub\u00e9s \u00e0 Station F dans le programme Microsoft GenAI\nNotre travail R&D a \u00e9t\u00e9 reconnu comme Deep Tech par Bpifrance\nNous collaborons avec une dizaine de marques et grands groupes reconnus\nDescriptif du poste\nEn Tant Que Membre De La Founder Team, Tu Seras Au C\u0153ur De L'innovation Et De La Recherche Chez Veeton. Votre Mission Sera Polyvalente\nR\u00e9solution de probl\u00e8mes ML complexes : vous serez en premi\u00e8re ligne pour manipuler et s'attaquer \u00e0 des notions en deep learning les plus complexes, avec par exemple, le conditionnement de mod\u00e8les de diffusion. Une ambition : repousser les limites de ce qui est possible en computer vision.\nD\u00e9ploiement de mod\u00e8les : d\u00e9ployez des mod\u00e8le en production, \u00e0 la fois en interne et pour les clients, de la mani\u00e8re la plus efficiente. Passez de la recherche au produit.\nApprentissage continu et impl\u00e9mentation : lisez les derniers articles et mettez en \u0153uvre les d\u00e9couvertes dans les domaines de recherche pertinents (voir ci-dessus) pour tester leur int\u00e9gration dans nos syst\u00e8mes. Chez Veeton, int\u00e9grer rapidement de nouvelles connaissances dans les projets est essentiel pour r\u00e9ussir.\nEsprit Pionnier. Soyez adaptable, lead sur vos sujets, prenez des risques calcul\u00e9s et adoptez une approche pratique pour r\u00e9soudre les probl\u00e8mes. Votre passion pour l'innovation et le produit aura un impact direct sur le succ\u00e8s de Veeton.\nProfil recherch\u00e9\nMaster en Math\u00e9matiques Appliqu\u00e9es / Informatique provenant des tops \u00e9coles d'ing\u00e9nieurs / universit\u00e9s\nSolides comp\u00e9tences en r\u00e9solution de probl\u00e8mes et autonomie\nUne exp\u00e9rience pr\u00e9alable dans la recherche en IA est recommand\u00e9e\nProcess de recrutement\nPremi\u00e8re rencontre avec un fondateur\nPremi\u00e8re test : fit, \u00e9valuation g\u00e9n\u00e9rale des math\u00e9matiques et de la logique\n2e test: petite revue de litt\u00e9rature\n3e test : informatique pratique et codage\nDernier appel avec les fondateurs\nInformations compl\u00e9mentaires\nType de contrat : CDI\nLieu : Paris\nNiveau d'\u00e9tudes : Bac +5 / Master\nT\u00e9l\u00e9travail ponctuel autoris\u00e9\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "R"
            ],
            "DataBase": [],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [],
            "DevTools": [],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [
                "ML"
            ],
            "FrSoftSkills": [
                "R\u00e9solution de probl\u00e8mes"
            ],
            "EnSoftSkils": []
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [
                "CDI"
            ],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "Stage Machine Learning",
        "company": "La Javaness",
        "location": "Paris, \u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/stage-machine-learning-at-la-javaness-3829261041?position=38&pageNum=0&refId=yQtK%2BQI72QI4xq%2BIXLe7ew%3D%3D&trackingId=yC4g2zfRWZACZQhif0JeJg%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Descriptif du poste\nInt\u00e9gr\u00e9(e) \u00e0 notre Lab Data compos\u00e9 d'une vingtaine d'experts en Machine Learning, tes activit\u00e9s s'orienteront autour de plusieurs grands axes :\nR\u00e9aliser des missions avec de r\u00e9elles donn\u00e9es clients, o\u00f9 tu pourras tr\u00e8s vite gagner en responsabilit\u00e9\nEffectuer un travail de R&D autour de l'\u00e9tat de l'art technologique et scientifique des m\u00e9thodes de machine learning, dans le but de perfectionner les outils utilis\u00e9s en interne\nParticiper aux data meeting hebdomadaires, au cours desquels chacun partage ses derni\u00e8res avanc\u00e9es et d\u00e9couvertes\nCollaborer avec les autres m\u00e9tiers (IT, Design, Business...), pour imaginer des solutions compl\u00e8tes et innovantes r\u00e9pondant aux besoins clients\nTravailler au plus pr\u00e8s des clients, en les conseillant directement et en concevant le produit qui saura r\u00e9pondre \u00e0 leurs attentes\nRequirements\nVenant d'une formation en Data Science, Computer Science, Math\u00e9matiques, ou d'un parcours au cours duquel tu as acquis les comp\u00e9tences recherch\u00e9es, tu justifies de bonnes connaissances des algorithmes de Machine Learning. Tu dois \u00e9galement \u00eatre curieux et effectuer une veille autour des derni\u00e8res avanc\u00e9es technologiques sur le sujet. Projets personnels et/ou participations \u00e0 des comp\u00e9titions Kaggle sauront attester de cet int\u00e9r\u00eat.\nDe solides connaissances en Python et une bonne ma\u00eetrise de ses librairies de Machine Learning (pandas, scikit-learn, etc.) sont obligatoires. La ma\u00eetrise d'un ou plusieurs frameworks de Deep Learning (Keras, Pytorch...) est un r\u00e9el plus.\nComp\u00e9tences obligatoires:\nPython\nMachine Learning / Deep Learning\nComp\u00e9tences appr\u00e9ci\u00e9es:\nP\u00e9dagogie, vulgarisation de concepts techniques\nEsprit de synth\u00e8se\n\u00c9cosyst\u00e8me Big Data (Hadoop, Spark)\nProgrammation logiciel et web\nFormat: Stage de 4 \u00e0 6 mois de pr\u00e9f\u00e9rence en fin d'\u00e9tudes\nBenefits\n\ud83c\udf74Une prime \u00ab paniers repas \u00bb vers\u00e9e mensuellement \u00e0 hauteur de 98\u20ac net\n\ud83d\udeb2 Au choix: La prise en charge int\u00e9grale de ton pass Navigo, ou une prime mobilit\u00e9 durable de 500\u20ac/an vers\u00e9e mensuellement\n\ud83e\udd38 Des cours de sport en visio chaque semaine gratuits pour tous\n\ud83c\udfe0 Du t\u00e9l\u00e9travail flexible pour tous\n\ud83d\udcd8 Du partage de connaissance en interne : chaque vendredi apr\u00e8s midi, \u00ab une s\u00e9ance de pr\u00e9sentation \u00bb est organis\u00e9e par un collaborateur sur un sujet qu'il souhaite partager \u00e0 tous\n\ud83d\udcbb Au choix: un ordinateur Mac, Linux, ou Windows selon tes pr\u00e9f\u00e9rences et comp\u00e9tences\n\ud83d\uddfa\ufe0f Des locaux situ\u00e9s dans le centre de Paris (10e), avec une super terrasse pour profiter de l'\u00e9t\u00e9\n\ud83c\udf7a Des ap\u00e9ros, s\u00e9minaires, d\u00e9jeuners en commun et autres r\u00e9jouissances plusieurs fois par an\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "R",
                "Go"
            ],
            "DataBase": [],
            "DataAnalytics": [
                "Pandas",
                "R"
            ],
            "BigData": [
                "Hadoop",
                "Spark"
            ],
            "MachingLearning": [
                "Scikit-Learn",
                "Keras",
                "PyTorch"
            ],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [],
            "DevTools": [],
            "Os": [
                "Linux",
                "Windows"
            ],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [
                "Big Data",
                "Machine Learning"
            ],
            "FrSoftSkills": [],
            "EnSoftSkils": []
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "Data Scientist - Tech Lead H/F",
        "company": "LEA Recrutement",
        "location": "Montpellier, Occitanie, France",
        "link": "https://fr.linkedin.com/jobs/view/data-scientist-tech-lead-h-f-at-lea-recrutement-3911193777?position=39&pageNum=0&refId=yQtK%2BQI72QI4xq%2BIXLe7ew%3D%3D&trackingId=%2B51nk02%2F3A0fFXgrpu4KVg%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Cette offre d\u2019emploi est fournie par P\u00f4le emploi\nDescription\nRejoignez une entreprise leader dans les secteurs de l'IoT et de la Data Science, solide et \u00e0 la pointe de l'innovation ! LEA Recrutement pr\u00e9sente, pour le compte de notre partenaire, une nouvelle offre d'emploi. Nous accompagnons notre client, tr\u00e8s belle r\u00e9f\u00e9rence dans le monde l'IoT et de la Data Science, \u00e0 recruter son Lead Developer Data Science/IA H/F en CDI \u00e0 Montpellier. La confidentialit\u00e9 de votre candidature est assur\u00e9e. Vous int\u00e9grez une entreprise faisant partie des acteurs majeurs du secteur de l'IoT et d\u00e9ployant cette technologie afin de la rendre accessible au plus grand nombre dans les secteurs publics comme priv\u00e9s. Vous occupez le r\u00f4le de r\u00e9f\u00e9rent technique au sein de l'\u00e9quipe de d\u00e9veloppement sous la supervision d'un chef de projet et/ou d'un responsable de produit. Vous soutenez l'\u00e9quipe dans des aspects techniques avanc\u00e9s afin d'assurer la s\u00e9curit\u00e9 des projets et de maintenir le niveau de qualit\u00e9 requis. Vos missions : * Conception et optimisation des mod\u00e8les d'analyse de donn\u00e9es * Pilotage des projets en coordonnant les aspects techniques et op\u00e9rationnels * Analyse des flux de donn\u00e9es * Am\u00e9lioration de la collecte, du traitement et de l'utilisation des donn\u00e9es pour maximiser l'efficacit\u00e9 des dispositifs et des syst\u00e8mes * Assurer la s\u00e9curit\u00e9 et la confidentialit\u00e9 des donn\u00e9es collect\u00e9es * Explorer de nouvelles approches et technologies dans une optique d'am\u00e9lioration des produits * Formation et accompagnement des d\u00e9veloppeurs juniors Stack technologique : Python, Spark, Hadoop, BigQuery, Kafka, ElasticSearch, FastAPI, Panda, Scikit learn, Tensorflow.. Avantages: * Tickets restaurant * Mutuelle 100% * Equipe dynamique * Pluralit\u00e9 des projets * Belles perspectives d'\u00e9volution et de carri\u00e8re . Votre profil : * De formation Bac+5 Ing\u00e9nieur (id\u00e9alement en robotique / syst\u00e8mes embarqu\u00e9s) * Exp\u00e9rience de 2 ans minimum * Exp\u00e9rience en contexte Open Source et IoT * Attrait pour la m\u00e9thodologie Agile/Scrum * Fort esprit d'\u00e9quipe * Rigueur * Excellentes capacit\u00e9s de communication et de partage de connaissances * Attrait pour les environnements complexes Vous \u00eates int\u00e9ress\u00e9 ? N'h\u00e9sitez pas \u00e0 postuler LEA Recrutement\nPROFIL SOUHAIT\u00c9\nExp\u00e9rience\nExp\u00e9rience exig\u00e9e de 1 An(s)\nSource: Pole emploi (https://www.pole-emploi.fr)\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "R"
            ],
            "DataBase": [
                "Elasticsearch"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [
                "Hadoop",
                "Spark"
            ],
            "MachingLearning": [
                "TensorFlow"
            ],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [],
            "DevTools": [],
            "Os": [],
            "DBMS": [
                "BigQuery"
            ],
            "SoftBigDataProcessing": [],
            "Automation": [
                "Chef"
            ],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [],
            "FrSoftSkills": [
                "Communication"
            ],
            "EnSoftSkils": [
                "Communication"
            ]
        },
        "details": {
            "JobDetail": [
                "Junior"
            ],
            "TypeContract": [
                "CDI"
            ],
            "Salary": [],
            "Level": [
                "Bac+5"
            ],
            "Experience": [
                "a",
                "n",
                "s",
                "2",
                "2",
                "2"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "Data Scientist H/F",
        "company": "Harmonie Mutuelle",
        "location": "Rennes, Brittany, France",
        "link": "https://fr.linkedin.com/jobs/view/data-scientist-h-f-at-harmonie-mutuelle-3903667706?position=40&pageNum=0&refId=yQtK%2BQI72QI4xq%2BIXLe7ew%3D%3D&trackingId=cYiMpKFclIynq6l1xFqzmQ%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Vous \u00eates en qu\u00eate d'une nouvelle aventure professionnelle collective et porteuse de sens ?\nVous voulez un parcours qui vous ressemble ? Vous avez envie d'\u00e9voluer dans un\nenvironnement de travail \u00e9panouissant fond\u00e9 sur la confiance, la diversit\u00e9 et l'\u00e9galit\u00e9 des\nchances ?\nVous \u00eates au bon endroit ! Ensemble, nous pouvons faire la diff\u00e9rence.\nLe poste :\nNous op\u00e9rons notre transformation digitale et renfor\u00e7ons le besoin de pilotage de nos flux et activit\u00e9s au sein de la Direction des Services et de la Satisfaction Clients. Dans ce cadre, nous recherchons un(e) Data Scientist pour renforcer l'\u00e9quipe Pilotage et Analyse Data Science. Parmi nos sujets : analyser les activit\u00e9s des centres de gestion, mesurer l'efficacit\u00e9 des actions de digitalisation, robotisation et d\u00e9mat\u00e9rialisation, analyser et d\u00e9tecter les fraudes \u00e0 la mutuelle, mod\u00e9liser des dimensionnements de flux et d'\u00e9quipes...\nVos missions principales :\nVous participez au d\u00e9veloppement de cette \u00e9quipe avec pour mission principale la production op\u00e9rationnelle d'algorithmes data science de d\u00e9tection de fraude :\n- Ex\u00e9cuter des algorithmes existants, monitorer, valider les productions\n- Maintenir ces mod\u00e8les math\u00e9matiques. Suivre leurs performances r\u00e9elles\n- Collecter l'ensemble des informations (hypoth\u00e8ses, roadmap, projet, nouvelles donn\u00e9es) n\u00e9cessaires \u00e0 l'am\u00e9lioration continue des mod\u00e8les et au d\u00e9veloppement de nouveaux\n- Explorer et croiser les donn\u00e9es, \u00e0 des fins d'investigation et de d\u00e9tection unitaires de cas de fraudes\n- Interpr\u00e9ter les donn\u00e9es collect\u00e9es, structurer et partager les r\u00e9sultats\nEn compl\u00e9ment de cette activit\u00e9, vous interviendrez sur les missions suivantes :\n- Participer aux analyses de performances et de pilotage de cette activit\u00e9 globale de gestion de la fraude\n- Intervenir sur des projets transverses au sein de l'\u00e9quipe et d'Harmonie Mutuelle (datalab, analyse d'impact...)\nLe profil recherch\u00e9 :\nIssu(e) d'une formation Bac +5 avec une sp\u00e9cialisation en Statistiques / Econom\u00e9trie / Analyse de donn\u00e9es, vous avez au moins 2 ans d'exp\u00e9rience en data science. Vous maitrisez les techniques de data mining, machine learning, mod\u00e9lisations supervis\u00e9es ou non et le pragmatisme.\nVous \u00eates \u00e0 l'aise sous SAS, SQL, et Python.\nVous savez et aimez d\u00e9velopper. Vous avez une app\u00e9tence et exp\u00e9rience sur les sujets d'investigation de fautes/fraudes \u00e0 impact directs sur notre soci\u00e9t\u00e9.\nVous \u00eates curieux(se), rigoureux(se) et dot\u00e9(e) d'un bon esprit d'analyse et de synth\u00e8se. Vous \u00eates force de proposition, autonome, dynamique, innovant, cr\u00e9atif.\nVous aimez le travail en \u00e9quipe.\nUne connaissance des m\u00e9tiers de la mutuelle serait un plus.\nInfos compl\u00e9mentaires :\n- 22, 5 jours de RTT par an\n- Des horaires flexibles pour la majorit\u00e9 des postes\n- Jusqu'\u00e0 3 jours de t\u00e9l\u00e9travail par semaine (\u00e0 partir de 6 mois d'anciennet\u00e9)\n- Carte d\u00e9jeuner et CSE (enveloppes loisirs, culture, avantages vacances...)\n- Compte Epargne Temps\n- Forfait mobilit\u00e9 durable : jusqu'\u00e0 300 \u20ac par an (cumulable avec le remboursement de l'abonnement aux transports en commun, dans la limite de 500 Euros au total)\n- Contrat collectif sant\u00e9 et pr\u00e9voyance\n- PEE et Retraite\n- Prime d'int\u00e9ressement\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "R",
                "Go"
            ],
            "DataBase": [
                "SQL"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [
                "Statistiques"
            ],
            "CloudComputing": [],
            "DevTools": [
                "Git"
            ],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [
                "Machine Learning",
                "Statistiques"
            ],
            "FrSoftSkills": [],
            "EnSoftSkils": []
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s",
                "2",
                "2",
                "2"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "DATA SCIENTIST F/H",
        "company": "H\u00f4pitaux de Vend\u00e9e",
        "location": "La Roche-sur-Yon, Pays de la Loire, France",
        "link": "https://fr.linkedin.com/jobs/view/data-scientist-f-h-at-h%C3%B4pitaux-de-vend%C3%A9e-3845962350?position=41&pageNum=0&refId=yQtK%2BQI72QI4xq%2BIXLe7ew%3D%3D&trackingId=s8FKJujewBvsC2Fk6yteAQ%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Vos futures missionsAu CHD Vend\u00e9e, le Data Scientist intervient sur divers projets et notamment le d\u00e9ploiement d\u2019une solution innovante d\u2019interrogation des donn\u00e9es m\u00e9dicales \u00e0 partir d\u2019un entrep\u00f4t de donn\u00e9es de sant\u00e9 (eHOP).Vos missions en lien avec eHOP seront le traitement et l'analyse des donn\u00e9es avec les \u00e9quipes m\u00e9dicales de l\u2019\u00e9tablissement en r\u00e9ponse aux cas d\u2019usages (projets de l\u2019\u00e9tablissement). Vous serez en charge de cr\u00e9er, modifier, supprimer des \u00e9tudes, g\u00e9rer les datamarts. Vous participerez \u00e0 la conception m\u00e9thodologique des projets en analyse de donn\u00e9es de sant\u00e9. Vous d\u00e9velopperez au sein de l\u2019\u00e9quipe l\u2019axe apprentissage automatique qui puisse r\u00e9pondre aux cas d\u2019usages (machine learning, analyse de texte notamment \u00e0 vis\u00e9e d\u2019optimisation du codage PMSI). Enfin votre r\u00f4le sera \u00e9galement de d\u00e9velopper, impl\u00e9menter et \u00e9valuer des m\u00e9thodes d\u2019apprentissage automatique pour tirer parti des larges volumes de donn\u00e9es de sant\u00e9 (prescriptions, biologie \u2026).Au sein du D\u00e9partement d'Information M\u00e9dicale (DIM), vous participerez \u00e0 tous les travaux du DIM au sein de l\u2019\u00e9quipe des statisticiens et vous collaborerez avec l\u2019Unit\u00e9 de Recherche Clinique en particulier pour les faisabilit\u00e9s des \u00e9tudes ou les recherches en donn\u00e9es de sant\u00e9.Mais ce n'est pas tout, d'autres missions vous serons confi\u00e9es. En effet vous participerez aux cycles R&D des environnements techniques (veille technologique), en lien avec l\u2019\u00e9quipe d\u2019ing\u00e9nieurs : prospective/prototypage, \u00e9valuation, conception et d\u00e9veloppements, transfert industriel. Vous valoriserez les travaux au travers de publications scientifiques dans des journaux et des conf\u00e9rences de r\u00e9f\u00e9rence. Vous participerez aux r\u00e9ponses d\u2019appel d\u2019offre inter-r\u00e9gionaux (plateforme HUGO) ainsi qu'aux ateliers et aux travaux du GCS HUGO.\nLes petits plus chez nous :\nHoraires de travail du lundi au vendredi avec une amplitude de 7h45\nDu temps pour soi : 19 jours de RTT, 28 jours de CA par an\nPossibilit\u00e9 de t\u00e9l\u00e9travail partiel hors p\u00e9riode d'int\u00e9gration\nUn accompagnement et des formations dispens\u00e9es au sein du service\nVotre meilleur profilVous \u00eates d\u00e9tenteur(trice) d'un dipl\u00f4me d'Ing\u00e9nieur/universitaire BAC+5 ou un doctorat sp\u00e9cialis\u00e9 en math\u00e9matiques, statistiques, apprentissage automatique/profond? C'est super!Vous disposez d\u00e9j\u00e0 d'une expertise d\u2019au moins un langage parmi python et R et d\u2019une exp\u00e9rience en programmation et en gestion de base de donn\u00e9es (relationnelles et noSQL)? Vous avez une certaine ma\u00eetrise de l\u2019\u00e9cosyst\u00e8me Big Data (Hadoop, Spark), traitements batch et/ou streaming, calcul GPU, framework Deep Learning (Tensorflow, Keras, PyTorch). C'est un vrai plus !On vous d\u00e9crit comme quelqu'un de rigoureux(se), d'autonome avec un bon esprit d'analyse, vous \u00eates m\u00e9thodique et vous avez un bon relationnel ?\nOn attend avec impatience votre candidature !\nLes bonnes raisons de nous rejoindre\nCe Qui Vous Attend Au CHD Vend\u00e9e\nDes conditions de recrutement attractives\nL'opportunit\u00e9 de suivre des formations\nDes perspectives d'\u00e9panouissement professionnel gr\u00e2ce \u00e0 notre politique de mobilit\u00e9 interne\nUn Comit\u00e9 de Gestion des \u0152uvres Sociales dynamique proposant de nombreux avantages (prestations sociales, culturelles et de loisirs)\nDes op\u00e9rations bien-\u00eatre pour prendre bien soin de vous\nUn abonnement Gymlib donnant acc\u00e8s \u00e0 des activit\u00e9s sportives et de loisirs en dehors de l'\u00e9tablissement pour adopter un mode de vie sain et actif au quotidien\nL'acc\u00e8s \u00e0 des avantages pour vos trajets domicile-travail car c'est bon pour votre sant\u00e9, pour la plan\u00e8te et aussi pour votre porte-monnaie (prise en charge de 75% des frais de transport en commun et location de v\u00e9lo jusqu'\u00e0 96,35\u20ac mensuels, offre de covoiturage Karos et forfait mobilit\u00e9s durables de 100\u20ac \u00e0 300\u20ac par an).\nUn service de conciergerie Happytal qui vous fera b\u00e9n\u00e9ficier de services et d\u2019offres avantageuses pour vous accompagner au quotidien !\nUne cr\u00e8che hospitali\u00e8re et des cr\u00e8ches partenaires pour prendre soin de vos bambins\nEt un self qui ne sert pas que de la mogette vend\u00e9enne (co\u00fbt moyen de 4\u20ac/repas)\nEt encore on ne vous dit pas tout ! D\u00e9couvrez bien d'autres avantages en cliquant ici !\nNotre mission : prendre soin de nos agents autant que de nos patients.\nN\u2019h\u00e9sitez plus, rejoignez-nous !\nOuverts \u00e0 tous, nos postes sont handi-accueillants.\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "R",
                " R ",
                "Go"
            ],
            "DataBase": [
                "SQL",
                "NoSQL"
            ],
            "DataAnalytics": [
                "R",
                " R "
            ],
            "BigData": [
                "Hadoop",
                "Spark"
            ],
            "MachingLearning": [
                "TensorFlow",
                "Keras",
                "PyTorch"
            ],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [
                "Statistiques"
            ],
            "CloudComputing": [],
            "DevTools": [],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [
                "Big Data",
                "ML",
                "Machine Learning",
                "Statistiques"
            ],
            "FrSoftSkills": [],
            "EnSoftSkils": []
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [],
            "Salary": [],
            "Level": [
                "Bac+5"
            ],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "Data Scientist F/H",
        "company": "OUTSCALE",
        "location": "St.-Cloud, \u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/data-scientist-f-h-at-outscale-3891855564?position=42&pageNum=0&refId=yQtK%2BQI72QI4xq%2BIXLe7ew%3D%3D&trackingId=Q2pHvQrdESPoMl8F1%2FLHng%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "OUTSCALE, marque de Dassault Syst\u00e8mes, est un op\u00e9rateur souverain et durable de l Exp\u00e9rience en tant que Service qui offre \u00e0 ses clients des environnements technologiques de confiance.\nNous offrons des exp\u00e9riences uniques gr\u00e2ce au savoir-faire de nos \u00e9quipes passionn\u00e9es, qui se refl\u00e8te notamment par la cr\u00e9ation de solutions de Business Exp\u00e9riences, le d\u00e9veloppement de notre propre orchestrateur Cloud, TINA OS, ou encore l obtention de la qualification SecNumCloud.\nNotre mission ? B\u00e2tir un monde num\u00e9rique accessible et meilleur pour tous \u00e0 travers la cr\u00e9ation du jumeau virtuel de l organisation.\nNous menons une politique RH engag\u00e9e et inclusive favorisant le bien-\u00eatre de nos collaborateur\u00b7rices : respect de l \u00e9quilibre vie priv\u00e9e/vie professionnelle, d\u00e9veloppement personnel et des comp\u00e9tences professionnelles, onboarding complet\nNous rejoindre, c est partager une passion pour l innovation, des valeurs communes et imaginer ensemble des solutions de confiance pour construire un monde meilleur et durable !\nNous recrutons\nun\u00b7e\nData Scientist\nafin de renforcer notre \u00e9quipe\nBusiness Experience\n.\nVos missions\nAnalyser des probl\u00e9matiques et proposer des solutions.\nMod\u00e9liser, impl\u00e9menter et \u00e9valuer des algorithmes.\nTraiter des donn\u00e9es non structur\u00e9es.\nOptimiser des mod\u00e8les ML/DL pour la scalabilit\u00e9, l'efficacit\u00e9 et les performances.\nIndustrialiser des algorithmes dans les services API.\nD\u00e9ployer des services sur le cloud.\nParticiper \u00e0 la r\u00e9daction de sp\u00e9cifications et documentations techniques.\nParticiper \u00e0 des \u00e9v\u00e9nements et publications scientifiques.\nStack technique\nPython\nFrameworks ML/DL (Pytorch)\nArchitectures de r\u00e9seaux neuronaux (LLMs)\nImpl\u00e9mentation d\u2019algorithmes ML/DL (apprentissage supervis\u00e9/non-supervis\u00e9)\nVotre profil:\nDipl\u00f4m\u00e9\u00b7e d\u2019un Master en Intelligence Artificielle, Machine Learning.\n3 ans d\u2019exp\u00e9rience minimum post-dipl\u00f4me dans le domaine de l\u2019IA, Data Science, Machine Learning, NLP, Computer Vision.\nVous ma\u00eetrisez l\u2019analyse et la transformation des donn\u00e9es.\nId\u00e9alement, vous avez de l\u2019exp\u00e9rience dans le d\u00e9ploiement des mod\u00e8les ML/DL sur le cloud.\nMotiv\u00e9\u00b7e, organis\u00e9\u00b7e, curieux\u00b7se, vous appr\u00e9ciez travailler en \u00e9quipe.\nLa Diversit\u00e9 d\u2019OUTSCALE trouve aussi son expression dans notre politique de recrutement qui privil\u00e9gie l\u2019\u00e9galit\u00e9 des chances, la diversit\u00e9 des individus au sein de nos \u00e9quipes.\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "Scala",
                "R",
                "Go"
            ],
            "DataBase": [],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [],
            "MachingLearning": [
                "PyTorch"
            ],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [],
            "DevTools": [],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [
                "ML",
                "Machine Learning",
                "Cloud"
            ],
            "FrSoftSkills": [
                "Organisation"
            ],
            "EnSoftSkils": []
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s",
                "3",
                "3",
                "3"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "ML Engineer - CDI - F/H",
        "company": "Modjo",
        "location": "Paris, \u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/ml-engineer-cdi-f-h-at-modjo-3909458542?position=43&pageNum=0&refId=yQtK%2BQI72QI4xq%2BIXLe7ew%3D%3D&trackingId=CFjJynY85L4gH81P0zWlkg%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Modjo:\nModjo is the leader European AI Revenue Platform whose mission is to drive revenue teams productivity & performance with AI-extracted knowledge from customers interactions.\nWhile AI is challenging how companies work across the world and all industries, Modjo brings these new capabilities to sales teams thanks to a platform that analyzes all interactions sales people have with their customers to improve sales teams productivity, drive strategy, and increase revenue.\nWe are a growing team of over 65 people, helping over 400 clients like BouyguesTelecom, Doctolib, Spendesk and Payfit in France and abroad. \ud83c\udf0e\nJust like Slack, Zoom or Hubspot, Modjo is a product company. This means that our product is the core of what we are doing and how we are creating value to customers. Therefore, the success of the company relies on the capacity of its Tech & Product teams to deliver together the best product to its users.\nTeam organization :\nThe overall tech department is composed of 10 Software Engineers (2 squads), 2 ML Engineers, a Data Team (1 team lead + 1 analyst) and the CTO. You will be part of the Data Science team alongside the other ML Engineers.\nMission:\nModjo's core capabilities include capturing conversations between sales teams and their customers (video & audio recordings, emails..) and leveraging this data thanks to speech-to-text and various LLM-based processings to extract and structure data out of it.\nAs part of this, your main missions will be:\nCollaborating with Product and Engineering to build features that require machine-learning expertise\nBuild, maintain and optimize our infrastructure for doing production machine learning including our speech-to-text stack (processing thousands of hours of audio every day) and our infrastructure for using LLMs\nDesign and implement processes, tools and pipelines in order to work efficiently with LLMs for our multiple use cases\nStay up to date with latest speech-to-text and LLM technologies in order to include them in the product and build the relevant technological asset for Modjo to differentiate from basic competition. This includes exploring model-finetuning models and RAGs\nYour profile :\nWe think you would be a great fit if :\nYou have 3y+ experience in Machine Learning and Engineering\nYou have experience working with and knowledge about NLP, LLM and speech-to-text\nYou have experience with putting models in production, including monitoring and CI/CD\nYou are interested in solving real world use cases with LLMs and building the proper technology around it\nYou are eager to learn a lot in an autonomous way, both in Science and Engineering fields\nYou are willing to work in English (language of the team)\nYou want to join a company where the product you will be building is core to our strategy\nYou are looking for a challenging job, but also an environment where you can thrive and have fun on a day-to-day basis :)\nWe are looking for someone who will thrive and share our values:\n\ud83d\ude03 Pleasure\n\u201cIf you Smile, things will work out\u201d - Serena Williams\n\u2705 Action\n\u201cDone is better than perfect\u201d - Sheryl Sandberg\n\ud83d\udcda Continuous Learning\n\u201cAmateurs call it Genius, masters call it practice\u201d - Thierry Henry\n\ud83e\udd32 Team Spirit\n\u201cGreat things in business are never done by one person; they\u2019re done by a team of people\u201d - Steve Jobs\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "R"
            ],
            "DataBase": [],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [],
            "DevTools": [],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [
                "Slack",
                "Teams"
            ],
            "Other": [
                "ML",
                "Machine Learning",
                "CI/CD"
            ],
            "FrSoftSkills": [],
            "EnSoftSkils": [
                "Organization"
            ]
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "Machine Learning Engineer",
        "company": "Alki",
        "location": "Paris, \u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/machine-learning-engineer-at-alki-3916860370?position=44&pageNum=0&refId=yQtK%2BQI72QI4xq%2BIXLe7ew%3D%3D&trackingId=%2FMnB%2FBQVOOdlsVeaM7eK2Q%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Full Stack Machine Learning Engineer (Time Series Forecasting)\nLocation:\nRemote or Paris\nJob Type\n: Full-Time\nCompany overview\n: At Alki, we\u2019re leveraging cutting edge AI technologies to transform logistics warehouses and drive innovation. Our mission is to bridge the gap between Amazon and other logistics players. We are looking for a skilled full stack ML engineer with a strong focus on time series forecasting to industrialize and streamline our machine learning operations (MLOps) capabilities from R&D to production.\nResponsibilities:\nDesign & build robust data pipelines specifically tailored for time series data, ensuring efficient data ingestion, pre-processing & exploration to support ML models\nDesign, implement, and optimize sophisticated time series forecasting algorithms\nTranslate advanced statistical and machine learning models from R&D into scalable production solutions\nManage the deployment of machine learning systems, including setting up continuous integration and delivery pipelines (CI/CD) for automated model training and deployment\nMonitor and maintain operational ML models (thousands), quickly identifying and addressing performance degradation or shifts in model accuracy/data\nCollaborate with cross-functional teams, including CTO, AI researcher, software engineer, to ensure models effectively address business needs and enhance decision-making\nStay abreast of the latest developments in machine learning, artificial intelligence, and related technologies to continuously improve our MLOps practices and time series models\nQualifications\nMaster\u2019s/PhD degree in Computer Science, Applied Maths, Statistics, or a related field\nStrong experience with a proven track record of deploying ML models to production\nStrong understanding of the challenges associated with deploying, monitoring, and maintaining thousands of ML models in a production environment\nStrong experience with AutoML, HPO, NAS\nProficient in Python, including extensive experience with ML libraries such as TensorFlow or PyTorch, and statistical modeling tools\nKnowledge of AWS cloud services related to machine learning and data processing, including Amazon S3, EC2, RDS, Lambda, and SageMaker\nFamiliarity with data orchestration tools\nExperience in building and maintaining CI/CD pipelines for automated model deployment\nExcellent analytical and problem-solving abilities, with a strong collaborative mindset\nExperience in time series analysis and forecasting is a plus\nBenefits:\nCompetitive salary\nStrong opportunities for professional development and career advancement\nFlexible working hours and remote work options\nDynamic and innovative work environment\nHow to apply:\nPlease submit your resume and any relevant project portfolio to tanguy@alki.io. We are excited to hear how you can contribute to our team at Alki!\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "Scala",
                "R",
                "Go"
            ],
            "DataBase": [],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [],
            "MachingLearning": [
                "TensorFlow",
                "PyTorch"
            ],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [
                "Statistics"
            ],
            "CloudComputing": [
                "AWS"
            ],
            "DevTools": [],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [
                "Teams"
            ],
            "Other": [
                "ML",
                "Machine Learning",
                "Cloud",
                "CI/CD"
            ],
            "FrSoftSkills": [],
            "EnSoftSkils": []
        },
        "details": {
            "JobDetail": [
                "Remote",
                "Full"
            ],
            "TypeContract": [],
            "Salary": [
                "Salary"
            ],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "Data Scientist: Flexible working",
        "company": "SoftwareOne",
        "location": "Levallois-Perret, \u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/data-scientist-flexible-working-at-softwareone-3872563771?position=45&pageNum=0&refId=yQtK%2BQI72QI4xq%2BIXLe7ew%3D%3D&trackingId=1mkqBUzG6uJHG4L9KhbTrA%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Why SoftwareOne?\nSoftwareOne is a leading global software and cloud solutions provider that is redefining how companies build, buy and manage everything in the cloud. By helping clients to migrate and modernize their workloads and applications \u2013 and in parallel, to navigate and optimize the resulting software and cloud changes \u2013 SoftwareOne unlocks the value of technology. The company\u2019s 8,900 employees are driven to deliver a portfolio of 7,500 software brands with sales and delivery capabilities in 90 countries. Headquartered in Switzerland, SoftwareOne is listed on the SIX Swiss Exchange under the ticker symbol SWON. Visit us at https://www.softwareone.com/en\nThe role\nDATA Scientist\nThe primary focus for a candidate will be in applying different techniques (data mining/statistical analysis/build prediction systems/recommendation systems) using large company data sets to find opportunities for services and products and using models to test the effectiveness of different courses of action. The Candidate must have strong experience using a variety of data mining/data analysis methods, using a variety of data tools, building and implementing models, using/creating algorithms and creating/running simulations.\nWork with business cases to identify opportunities for leveraging company data to drive business solutions.\nMine and analyze data from company databases to drive optimization and improvement of product development and sales techniques\nAssess the effectiveness and accuracy of new data sources and data gathering\nExtending company\u2019s data with third party sources of information when needed\nUse predictive modeling to increase revenue generation, ad targeting and other business outcomes.\nWhat We Need To See From You\nCore:\nAnalyze business cases and identify data sources (internal/external) and data mining/analysis methods to use\nDevelop a normalization engine to execute cleansing/deduplication for a raw data through ETL process for data sources\nCreate, train and test predictive models to solve defined business cases\nDevelop algorithms to apply to data sets\nDesign data structure models for collected data\nFacilitate the build of a solution from PoC to production\nWork with business owners to gather additional information about business cases\nJob Specific:\nWork with Google Cloud data and AI tools\nBe ready to work in agile style (daily, sprint planning, sprint review, retrospective)\nWork in an environment that adapts quickly to creative change using agile principles\nActively work with different development groups inside of organization\nBe ready to adapt a new tool/library/technology/platform\nDesirable Skills:\nFluent in French and English\nAt least 4 years experience in Machine learning models creation\nMaster\u2019s in Statistics, Mathematics, Computer Science preferred\nProfessional Machine learning engineering certification\nExperience with common data science toolkits and libraries, such as pandas, keras, scipy, scikit, tensorflow, NumPy etc\nKnowledge and interest in the following:\nprediction models, Vertex AI, Tenserflow, BigQuery ML, Python,\nnatural language processing, deep learning models, dataPROC, Hadoop, SQL\nExperience using statistical computer languages namely Python to manipulate data and draw insights from large data sets\nStrong knowledge and experience using SQL language\nExperience with C++/C# and Java as a plus\nBackground in technology or professional services preferably in one or more of the domains of GCP and Security,\nStrong understanding of consulting business\nStrong structural work methods, multitasking and time management skills\nSelf-driven independent work ethics that drives internal and external accountability\nMay require periodic travel for workshops\nJob Function\nSoftware & Cloud Services\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "Java",
                "C++",
                "C#",
                "R",
                "Go"
            ],
            "DataBase": [
                "SQL"
            ],
            "DataAnalytics": [
                "Pandas",
                "NumPy",
                "R"
            ],
            "BigData": [
                "Hadoop"
            ],
            "MachingLearning": [
                "TensorFlow",
                "Keras"
            ],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [
                "Statistics"
            ],
            "CloudComputing": [],
            "DevTools": [],
            "Os": [],
            "DBMS": [
                "BigQuery"
            ],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [
                "ML",
                "Machine Learning",
                "Cloud"
            ],
            "FrSoftSkills": [],
            "EnSoftSkils": [
                "Time Management",
                "Organization"
            ]
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "DATA ENGINEER S\u00c9CURIT\u00c9 H/F",
        "company": "Akademija Oxford",
        "location": "Boulogne-Billancourt, \u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/data-engineer-s%C3%A9curit%C3%A9-h-f-at-akademija-oxford-3917866657?position=46&pageNum=0&refId=yQtK%2BQI72QI4xq%2BIXLe7ew%3D%3D&trackingId=gmzTOS5EqA1TFKx71E5KxQ%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Une entreprise du secteur de la protection de l\u2019environnement et bas\u00e9e dans les Hauts-De-Seine recherche un.e Data Engineer S\u00e9curit\u00e9 dans le cadre d\u2019un contrat d\u2019apprentissage.\nAu sein de son Data Service, votre r\u00f4le sera d\u2019\u00e9tablir la strat\u00e9gie des architectures data sur les aspects s\u00e9curit\u00e9 en lien avec la strat\u00e9gie globale m\u00e9tier et contribuer \u00e0 la d\u00e9clinaison des principes du mod\u00e8le de s\u00e9curit\u00e9 globale.\nVous devrez \u00e9galement \u00e9laborer des mod\u00e8les de r\u00e9f\u00e9rence pour les architectures data, mais aussi contribuer \u00e0 la d\u00e9clinaison des politiques de s\u00e9curit\u00e9 en standards de s\u00e9curit\u00e9 op\u00e9rationnels.\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "R"
            ],
            "DataBase": [],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [],
            "DevTools": [],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [],
            "FrSoftSkills": [],
            "EnSoftSkils": []
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "Machine Learning Engineer, Fast Optimized Inference - EMEA Remote",
        "company": "Hugging Face",
        "location": "France",
        "link": "https://fr.linkedin.com/jobs/view/machine-learning-engineer-fast-optimized-inference-emea-remote-at-hugging-face-3848456024?position=47&pageNum=0&refId=yQtK%2BQI72QI4xq%2BIXLe7ew%3D%3D&trackingId=40f7SjBkwfaM26PIt8L6Kw%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Here at Hugging Face, we're on a journey to advance good Machine Learning and make it more accessible. Along the way, we contribute to the development of technology for the better.\nWe have built the fastest-growing, open-source, library of pre-trained models in the world. With more than 1 Million+ models and 320K+ stars on GitHub, over 15.000 companies are using HF technology in production, including leading AI organizations such as Google, Elastic, Salesforce, Algolia, Grammarly and NASA.\nAbout the role:\nAs a Machine learning Engineer, you work mainly on creating great libraries highly focused on real world ML use cases. We're building on top of our open-source to create more specialized code with a focus on industrial level of usage.\nWe are searching for someone who brings fresh ideas, demonstrates a unique and informed viewpoint, and enjoys collaborating with a progressive, nimble and decentralized approach to develop real-world solutions and positive user experiences at every interaction.\nObjectives of this role:\nDevelop specialized software for specific machine learning (ML) use cases that have broad applications, similar to [text-generation-inference](https://github.com/huggingface/text-generation-inference).\nUtilize existing library frameworks to create scalable software solutions for industrial purposes.\nEnhance the reliability, quality, and time-to-market of our software suite. Measure and optimize system performance to stay ahead of customer needs and drive innovation.\nManage the production environment by monitoring availability and ensuring overall system health. We run our own tools\nAbout you:\nIf you are a passionate Machine Learning Engineer with a keen interest in AI and proficient with Python, Rust and specialized Cuda kernels Frameworks (transformers of course + Keras or PyTorch), we would love to hear from you. Join our team and contribute to the advancement of AI technologies while working alongside talented professionals in a collaborative and stimulating environment.\nMore about Hugging Face\nWe are actively working to build a culture that values diversity, equity, and inclusivity\n.\nWe are intentionally building a workplace where people feel respected and supported\u2014regardless of who you are or where you come from. We believe this is foundational to building a great company and community. Hugging Face is an equal opportunity employer and we do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.\nWe value development.\nYou will work with some of the smartest people in our industry. We are an organization that has a bias for impact and is always challenging ourselves to continuously grow. We provide all employees with reimbursement for relevant conferences, training, and education.\nWe care about your well-being\n.\nWe offer flexible working hours and remote options. We offer health, dental, and vision benefits for employees and their dependents. We also offer flexible parental leave and paid time off.\nWe support our employees wherever they are\n.\nWhile we have office spaces in NYC and Paris, we're very distributed and all remote employees have the opportunity to visit our offices. If needed, we'll also outfit your workstation to ensure you succeed.\nWe want our teammates to be shareholders\n.\nAll employees have company equity as part of their compensation package. If we succeed in becoming a category-defining platform in machine learning and artificial intelligence, everyone enjoys the upside.\nWe support the community\n.\nWe believe major scientific advancements are the result of collaboration across the field. Join a community supporting the ML/AI community.\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "Scala",
                "R",
                "Go"
            ],
            "DataBase": [],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [],
            "MachingLearning": [
                "Keras",
                "PyTorch"
            ],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [],
            "DevTools": [
                "Git"
            ],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [
                "ML",
                "Machine Learning"
            ],
            "FrSoftSkills": [
                "Collaboration"
            ],
            "EnSoftSkils": [
                "Collaboration",
                "Organization"
            ]
        },
        "details": {
            "JobDetail": [
                "Remote"
            ],
            "TypeContract": [],
            "Salary": [
                "Package"
            ],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "Front-End Software Engineer -",
        "company": "Licorne Society",
        "location": "Paris, \u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/front-end-software-engineer-at-licorne-society-3918084328?position=48&pageNum=0&refId=yQtK%2BQI72QI4xq%2BIXLe7ew%3D%3D&trackingId=zc%2FSiKPzq3iNoHK%2FoEY1hQ%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Licorne Society a \u00e9t\u00e9 missionn\u00e9 par une startup en pleine croissance pour les aider \u00e0 trouver leur Front-End Software Engineer\nCONTEXTE\nNous recherchons un D\u00e9veloppeur Fullstack \u00e0 dominante Front End pour rejoindre notre \u00e9quipe ambitieuse sur un projet technique complexe : une plateforme No-code B2B qui r\u00e9invente la gestion des op\u00e9rations au sein des entreprises, gr\u00e2ce \u00e0 l'IA.\nLes entreprises s\u2019appuient sur notre plateforme de gestion int\u00e9gr\u00e9e pour orchestrer leurs processus, automatiser les t\u00e2ches r\u00e9currentes et, \u00e0 terme, accro\u00eetre leur performance op\u00e9rationnelle.\nNous Disposons D'un Premier Produit Stable Et Nous Renfor\u00e7ons Notre \u00c9quipe Tech Pour Acc\u00e9l\u00e9rer Le D\u00e9veloppement Du Produit, Elle Est Pour L'instant Compos\u00e9e De\nMatthieu (CTO)\nHugo (Dev Fullstack)\nMatthieu notre CTO a l'habitude des exp\u00e9riences entrepreneuriales et a notamment co-fond\u00e9 Tessan.\nDescription Du Poste\nEn tant que Dev Fullstack \u00e0 dominante Front-end, tu seras amen\u00e9\u00b7e \u00e0 :\nTravailler sur les d\u00e9veloppements front-end et \u00eatre force de proposition concernant l'UI et UX du produit,\nD\u00e9velopper de nouvelles fonctionnalit\u00e9s sur le projet,\nParticiper \u00e0 la conception et l'am\u00e9lioration des bonnes pratiques de d\u00e9veloppement,\nAvoir la possibilit\u00e9 de toucher au backend si cela t'int\u00e9resse.\nStack globale du projet : TypeScript, Angular, React, Nest, Node.js, MongoDB, AWS...\nPACKAGE\nPossibilit\u00e9 de travailler 1 jour par semaine en remote\nMutuelle d'entreprise\nTitre de transport\nR\u00e9mun\u00e9ration attractive\nPROFIL RECHERCH\u00c9\nAujourd'hui, nous recherchons un profil r\u00e9pondant aux crit\u00e8res suivants :\nTu as d\u00e9j\u00e0 connu plusieurs ann\u00e9es (au moins 2-3 ans) d'exp\u00e9rience professionnelle en d\u00e9veloppement frontend,\nTu es une personne curieuse, proactive et autonome,\nTu appr\u00e9cies l'UI et l'UX.\nLES PLUS DU POSTE\nDevenir l'une des premi\u00e8res recrues d'une startup early et ambitieuse\nPossibilit\u00e9 de vivre une aventure depuis quasi le d\u00e9but\nRemote possible\nDes locaux neufs dans Paris centre (3\u00e8me)\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "R",
                "Go"
            ],
            "DataBase": [
                " MongoDB"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [
                "AWS"
            ],
            "DevTools": [],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [],
            "FrSoftSkills": [],
            "EnSoftSkils": []
        },
        "details": {
            "JobDetail": [
                "Remote",
                "Full"
            ],
            "TypeContract": [],
            "Salary": [
                "1"
            ],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s",
                "3",
                "3",
                "3"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "AI/ML Engineer - Autonomous Driving",
        "company": "Hashlist",
        "location": "Greater Paris Metropolitan Region",
        "link": "https://fr.linkedin.com/jobs/view/ai-ml-engineer-autonomous-driving-at-hashlist-3889037092?position=49&pageNum=0&refId=yQtK%2BQI72QI4xq%2BIXLe7ew%3D%3D&trackingId=OTKZXcWzsMgaTNJHRBjIjg%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Hashlist is a platform for tech positions & projects within the automotive sector.\nWe work with some of the largest OEMs, Tier1s, and Ecosystem Players developing for the automotive sector to help them fill on-demand tech talent gaps faster.\nAre you ready to be a part of that journey? We are now looking for a AI/ML Engineer that can help our client develop autonomous vehicles in Paris, France.\nResponsibilities:\nDesign, develop, and implement machine learning models and algorithms to improve ADAS (advanced driver assistance systems) and full AD (autonomous driving).\nCollaborate with data engineers to design data collection strategies, preprocess data, and enhance data quality for training machine learning models.\nUtilize state-of-the-art machine learning frameworks (e.g., TensorFlow, PyTorch) to develop models that are efficient, scalable, and can be deployed in embedded automotive systems.\nConduct experiments and iterative testing to evaluate the performance of machine learning models, utilizing A/B testing and other statistical methods to validate improvements.\nIntegrate machine learning models into automotive software systems, working closely with software engineers to ensure seamless deployment and operation.\nDocument the machine learning development process, including model design, evaluation metrics, and deployment strategies, to ensure reproducibility and facilitate knowledge sharing within the team.\nQualifications\n:\nBachelor\u2019s or Master\u2019s degree in Computer Science, Artificial Intelligence, Data Science, or a related field, with a strong focus on machine learning.\nProven experience in designing and implementing machine learning models, with a portfolio of projects that demonstrates expertise in predictive modeling, classification, clustering, and deep learning.\nProficiency in programming languages such as Python, and experience with machine learning libraries and frameworks (TensorFlow, PyTorch).\nStrong understanding of data structures, data modeling, and software architecture principles relevant to machine learning and artificial intelligence applications.\nExperience with data preprocessing techniques, feature engineering, and understanding of the principles of dataset construction for machine learning.\nFamiliarity with automotive systems and applications where machine learning can be applied is a plus.\nExcellent problem-solving skills, with the ability to work independently and in cross-functional teams to deliver innovative solutions.\nStrong communication skills, with the capacity to articulate complex technical concepts to both technical and non-technical stakeholders.\nNext steps:\nPress \"Apply\"\nWe will review your application\nIf qualified, you will be accepted into the network and can be considered for this and similar positions & projects.\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "Scala",
                "R",
                "Go"
            ],
            "DataBase": [],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [],
            "MachingLearning": [
                "TensorFlow",
                "PyTorch"
            ],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [],
            "DevTools": [],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [
                "Teams"
            ],
            "Other": [
                "ML",
                "Machine Learning"
            ],
            "FrSoftSkills": [
                "Communication"
            ],
            "EnSoftSkils": [
                "Communication"
            ]
        },
        "details": {
            "JobDetail": [
                "Full"
            ],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "Ing\u00e9nieur Machine Learning \u2013 Bordeaux, France (H/F)",
        "company": "Astek",
        "location": "Bordeaux, Nouvelle-Aquitaine, France",
        "link": "https://fr.linkedin.com/jobs/view/ing%C3%A9nieur-machine-learning-%E2%80%93-bordeaux-france-h-f-at-astek-3882494346?position=50&pageNum=0&refId=yQtK%2BQI72QI4xq%2BIXLe7ew%3D%3D&trackingId=OkvQZW0XsSpFo8jYXsjIAw%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "CDI\nBordeaux - France\nPubli\u00e9e il y a 1 mois\nLe Groupe Astek\nCe Que Nous Allons Accomplir Ensemble :\nRejoignez nos \u00e9quipes et intervenons ensemble sur les projets de nos partenaires autour des enheux d\u2019innovation.\nVotre Mission, Si Vous L\u2019acceptez :\nCadrer techniquement les projets et accompagner les Data Scientists dans la construction des mod\u00e8les en veillant \u00e0 respecter les bonnes pratiques d\u2019ing\u00e9nierie logicielle.\nMettre en place la d\u00e9marche ML OPS\nD\u00e9ployer les mod\u00e8les en production en respectant des contraintes de co\u00fbts, pr\u00e9cisions et performances techniques.\nImpl\u00e9menter les outils permettant de monitorer ces mod\u00e8les en production\nVous ?\nVous \u00eates issu(e) d\u2019une formation Bac+5 (\u00c9cole d\u2019ing\u00e9nieur, Universit\u00e9 ou \u00e9quivalent \u2026) en informatique\nVous justifiez d\u2019une exp\u00e9rience significative d\u2019au moins 5 ans au sein d\u2019une \u00e9quipe dans un environnement Data \u00e0 l\u2019\u00e9chelle du SI d\u2019un grand groupe\nVous \u00eates un bon communiquant et disposez de capacit\u00e9s d\u2019analyse et de synth\u00e8se \u00e9prouv\u00e9es\nVous accordez de l\u2019importance \u00e0 la veille technologique\nComp\u00e9tences Techniques :\nExpertise en SPARK et PySpark\nConnaissance de Kubernetes\nConnaissance de d\u2019Apache Kafka\nUne exp\u00e9rience sur un cloud provider public comme Azure (id\u00e9alement), AWS, ou GCP\nExpertise de d\u00e9veloppement en Python\nExpertise du ML OPS\nComp\u00e9tences Transverses :\nCapacit\u00e9 \u00e0 interagir avec des parties prenantes diverses : Data Scientists, Business analyst, Architectes, M\u00e9tier\nForte exp\u00e9rience en mode de Delivery Agile (Scrum, Kanban, etc.\u2026)\nEtre expert dans les pratiques du Software Craftsmanship (Test Driven, Development, Behavior Driven Development, Clean Code, Code Reviews, etc.)\nEt :\nDes Connaissances sur Azure DevOps, Azure Pipeline, GIT\nMaitrise des Traitements Big Data en mode Streaming\nMaitrise des Bases de donn\u00e9es relationnelles et NoSQL\nUne exp\u00e9rience professionnelle avec des outils comme Azure Databricks, Azure, Machine Learning , Azure Data Lake Storage ou encore Azure Data Factory\nLe Groupe Astek\nCr\u00e9\u00e9 en France en 1988, Astek est un acteur mondial de l\u2019ing\u00e9nierie et du conseil en technologies. Fort de son expertise dans de nombreux secteurs industriels et tertiaires, Astek accompagne ses clients internationaux dans le d\u00e9ploiement intelligent de leurs produits et de leurs services, et dans la mise en \u0153uvre de leur transformation digitale.\nDepuis sa cr\u00e9ation, le Groupe a fond\u00e9 son d\u00e9veloppement sur une forte culture d\u2019entrepreneuriat et d\u2019innovation, et sur l\u2019accompagnement et la mont\u00e9e en comp\u00e9tence de\nses 7800 collaborateurs\nqui s\u2019engagent chaque jour \u00e0 promouvoir la compl\u00e9mentarit\u00e9 entre les technologies num\u00e9riques et l\u2019ing\u00e9nierie des syst\u00e8mes complexes.\nRejoignez un Groupe en fort d\u00e9veloppement en France et \u00e0 travers le monde ayant r\u00e9alis\u00e9 un chiffre d\u2019affaires de 600 M\u20ac en 2023.\nTous les d\u00e9tails sur le Groupe sur le site https://astekgroup.fr. Et vous pouvez aussi nous suivre sur notre blog : https://blog.groupeastek.com.\nRencontrons-nous\nNotre projet commun vous plait ?\nPostulez \u00e0 cette annonce, et soyez transparent !\nNotre Talent Acquisition Officer, vous contactera pour un premier \u00e9change t\u00e9l\u00e9phonique.\nPuis vous rencontrerez votre futur manager, avec lequel vous \u00e9changerez autour d\u2019Astek, de votre parcours, de vos attentes et de votre future mission .\nEnfin, vous rencontrerez notre Directeur de d\u00e9partement, avec lequel vous pourrez valider votre int\u00e9r\u00eat et ad\u00e9quation pour le poste et finaliser les \u00e9l\u00e9ments contractuels.\nNos Plus\nAstek est green et fait b\u00e9n\u00e9ficier ses salari\u00e9s d\u2019une indemnit\u00e9 kilom\u00e9trique v\u00e9lo\nUne politique CARE sur-mesure d\u00e9ploy\u00e9e par nos \u00e9quipes RH pour nos collaborateurs (https://astekgroup.fr/engagements)\nNotre charte de la Diversit\u00e9\nBienvenue dans la team ! Allez-y, maintenant c\u2019est \u00e0 vous de jouer !\nMots-cl\u00e9s :\ning\u00e9nieur \u2013 ing\u00e9nieure \u2013 consultant \u2013 consultante\nCaract\u00e9ristiques de l'emploi\nCat\u00e9gorie Chef de Projet\nJob Industry A\u00e9rospatial / D\u00e9fense / S\u00e9curit\u00e9, Distribution / Services Internet, Energie / Sciences de la Vie / Autres industries, Finance / Gouvernement, T\u00e9l\u00e9com / M\u00e9dia, Transports Terrestres\nPostuler en ligne\nNom *\nPr\u00e9nom *\nEmail *\nUn email valide est requis.\nT\u00e9l\u00e9phone *\nUn num\u00e9ro de t\u00e9l\u00e9phone valide est requis.\nJoindre un CV *\nMots-cl\u00e9s :\ning\u00e9nieur \u2013 ing\u00e9nieure \u2013 consultant \u2013 consultante\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "R",
                "Go"
            ],
            "DataBase": [
                "SQL",
                "NoSQL"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [
                "Spark",
                "Databricks"
            ],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [
                "AWS",
                "Azure"
            ],
            "DevTools": [
                "Git"
            ],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [
                "Apache Kafka"
            ],
            "Automation": [
                "Kubernetes",
                "Chef"
            ],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [
                "Kubernetes"
            ],
            "Collaboration": [],
            "Other": [
                "DevOps",
                "Big Data",
                "ML",
                "Machine Learning",
                "Cloud"
            ],
            "FrSoftSkills": [],
            "EnSoftSkils": []
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [
                "CDI"
            ],
            "Salary": [],
            "Level": [
                "Bac+5"
            ],
            "Experience": [
                "a",
                "n",
                "s",
                "5",
                "5",
                "5"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "Machine Learning Engineer",
        "company": "TEC Partners - Technical Recruitment Specialists",
        "location": "Paris, \u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/machine-learning-engineer-at-tec-partners-technical-recruitment-specialists-3890985195?position=51&pageNum=0&refId=yQtK%2BQI72QI4xq%2BIXLe7ew%3D%3D&trackingId=iL7WfDKY%2FCtafk1kH24ogg%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Role Overview:\nAs a Senior Machine Learning Engineer, you will play a crucial role in the development and deployment of AI models to enhance creativity processes for our users. From curating data to training and validating models, you will have end-to-end ownership of your work. You will collaborate closely with cross-functional teams, share your expertise on AI, and participate in strategic decisions concerning our tech stack.\nResponsibilities:\nDevelop and deploy machine learning models tailored to user needs.\nOwn the entire process from data preprocessing to model deployment (MLOps).\nCollaborate with cross-functional teams on strategic decisions regarding the tech stack.\nShare knowledge and expertise on AI with the team.\nWork closely with users to understand their needs and improve product features.\nRequirements:\n5+ years of experience in machine learning, ideally in an early-stage startup environment.\nProven experience in training and deploying machine learning models for products.\nFamiliarity with data preprocessing pipelines and MLOps.\nWillingness to work with new technologies and parts of the stack.\nAbility to thrive in a fast-paced environment.\nPhD in computer science, machine learning, or related field preferred.\nFluent in English; proficiency in French is a plus.\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "R"
            ],
            "DataBase": [],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [],
            "DevTools": [],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [
                "Teams"
            ],
            "Other": [
                "ML",
                "Machine Learning"
            ],
            "FrSoftSkills": [],
            "EnSoftSkils": [
                "Creativity"
            ]
        },
        "details": {
            "JobDetail": [
                "Senior"
            ],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "Data Scientist H/F",
        "company": "IT&M STATS",
        "location": "\u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/data-scientist-h-f-at-it-m-stats-3803674187?position=52&pageNum=0&refId=yQtK%2BQI72QI4xq%2BIXLe7ew%3D%3D&trackingId=rmNOjg8bQoT2D7iPRXrmeg%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "IT&M Stats intervient dans le domaine des statistiques, de la programmation et de la data science, principalement dans les secteurs de l\u2019Industrie Pharmaceutique, Cosm\u00e9tique, dans la Sant\u00e9 et l\u2019Agro-alimentaire et aupr\u00e8s des Banques et Assurances. IT&M Stats est une filiale du Groupe Astek, acteur mondial de l\u2019ing\u00e9nierie et du conseil en technologies.\nNous basons notre relation sur :\nUn respect des collaborateurs et des clients, de leurs aspirations,\nUn suivi personnalis\u00e9 des collaborateurs et des clients,\nUne gestion r\u00e9guli\u00e8re des carri\u00e8res des collaborateurs,\nDes \u00e9changes transparents,\nUne r\u00e9activit\u00e9, une disponibilit\u00e9 et une \u00e9coute permanentes.\nNous recherchons un\nData Scientist\npour intervenir dans le secteur\ncosm\u00e9tique\n.\nCela vous int\u00e9resse ? Voici la suite !\n\ud83d\udc47\nMaintenance et mise \u00e0 jour de dashboards de suivi de tests sous PowerBi\nAnalyser les donn\u00e9es g\u00e9n\u00e9r\u00e9es en interne et externe et r\u00e9aliser des analyses crois\u00e9es /meta analyse pour une meilleure compr\u00e9hension de la performance de nos produits/services\nR\u00e9aliser des analyses pr\u00e9dictives de la performance cosm\u00e9tique en fonction de la formulation\nR\u00e9aliser des interfaces dynamiques sous R Shiny\nR\u00e9-analyser et v\u00e9rifier les analyses statistiques r\u00e9alis\u00e9es par les prestataires externes le cas \u00e9ch\u00e9ant\nContribuer \u00e0 la mise en place des \u00e9tudes et aider le d\u00e9partement \u00e0 l\u2019am\u00e9lioration des process (Plan d\u2019exp\u00e9rience, calcul du nombre de sujets n\u00e9cessaires, etc\u2026)\nVous pensez \u00eatre la perle rare ?\nVous \u00eates titulaire d\u2019un dipl\u00f4me de type Bac+5 (Master 2 ou \u00e9cole d\u2019ing\u00e9nieur) avec une sp\u00e9cialisation en statistiques, math\u00e9matiques ou data science\nVous justifiez d\u2019une exp\u00e9rience professionnelle de 2 \u00e0 3 ans\nUne bonne maitrise de R (dont R Shiny) est attendue\nVous maitrisez PowerBI\nVous \u00eates organis\u00e9, rigoureux, autonome, flexible, vous aimez communiquer et travailler en \u00e9quipe et vous avez un bon esprit de synth\u00e8se et d\u2019analyse\nVous avez un bon niveau d\u2019anglais\n\ud83c\udf40\nVoici ce que nous pouvons vous offrir\u2026\nUn poste en CDI \u00e0 pourvoir d\u00e8s que possible, de la bonne humeur, des formations, des soir\u00e9es, de la bienveillance, un suivi personnalis\u00e9, une gestion r\u00e9guli\u00e8re de votre carri\u00e8re, des \u00e9changes transparents et une \u00e9coute permanente.\nSi vous \u00eates convaincu que vous \u00eates la perle rare, postulez ! Nous sommes impatients de vous rencontrer.\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "R",
                " R ",
                "Go"
            ],
            "DataBase": [],
            "DataAnalytics": [
                "R",
                " R "
            ],
            "BigData": [],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [
                "PowerBI"
            ],
            "Statistics": [
                "Statistiques"
            ],
            "CloudComputing": [],
            "DevTools": [],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [
                "Statistiques"
            ],
            "FrSoftSkills": [],
            "EnSoftSkils": []
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [
                "CDI"
            ],
            "Salary": [],
            "Level": [
                "Bac+5"
            ],
            "Experience": [
                "a",
                "n",
                "s",
                "3",
                "3",
                "3"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "Machine Learning Researcher",
        "company": "Finegrain",
        "location": "Paris, \u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/machine-learning-researcher-at-finegrain-3773290571?position=53&pageNum=0&refId=yQtK%2BQI72QI4xq%2BIXLe7ew%3D%3D&trackingId=0eNYdRX4KS0xBN4zlDAgkQ%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "**Our mission**\nAt Finegrain, we believe the Internet deserves better images, and we're building the ultimate GenAI platform to make it happen - at massive scale.\n**Our unfair advantage**\nOur founders are repeat entrepreneurs who sold their first AI company to Google, and we are backed by a stellar and worldwide team of investors.\n**Meet Refiners**\nUnder the hoods, Finegrain relies on a breakthrough micro framework for foundation model adaptation called Refiners. We're building it in the open (MIT license), on top of our beloved PyTorch.\n**Your mission**\nJoin us as a Machine Learning Research Engineer to help extend the capabilities of the Refiners framework, and train breakthrough adapters with it!\n**Skills**\nWe're looking for folks who:\n1. love PyTorch\n2. know visual foundation models like Stable Diffusion, SAM, BLIP-2 inside out\n3. enjoy keeping track of the latest innovations on arXiv\n**Why join us?**\n1. You'll be part of our founding team.\n2. You'll work at Station F, the world's largest startup campus.\n3. You'll rub shoulders with some of the sharpest minds in AI.\n4. You'll help shape a product set to break new ground.\n5. You'll work on real, impactful AI. No fluff.\n**Process**\nIt all starts with taking a look at our bounty program: just pick one, and show us what you got. If you complete it, you'll get paid!\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "R",
                "Go"
            ],
            "DataBase": [],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [],
            "MachingLearning": [
                "PyTorch"
            ],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [],
            "DevTools": [],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [
                "Machine Learning"
            ],
            "FrSoftSkills": [],
            "EnSoftSkils": []
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "Data Scientist Traitement du Langage Naturel H/F (H/F)",
        "company": "Acelys Services Num\u00e9riques",
        "location": "Montpellier, Occitanie, France",
        "link": "https://fr.linkedin.com/jobs/view/data-scientist-traitement-du-langage-naturel-h-f-h-f-at-acelys-services-num%C3%A9riques-3906686343?position=54&pageNum=0&refId=yQtK%2BQI72QI4xq%2BIXLe7ew%3D%3D&trackingId=k7gOk4M1o6kwltMI%2F88zwA%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Cette offre d\u2019emploi est fournie par P\u00f4le emploi\nDescription\nCr\u00e9\u00e9e en 1997, Acelys Services Num\u00e9riques est la 1\u00e8re DFS (Digital Factory Services) de la R\u00e9gion qui propose \u00e0 ses clients des services industrialis\u00e9s de d\u00e9veloppement et d'int\u00e9gration \u00e0 haute valeur ajout\u00e9e de solutions num\u00e9riques. En particulier sur les domaines : - Du d\u00e9veloppement logiciel & mobile ; - De la Business Intelligence & la Data Science ; - De l'int\u00e9gration des solutions de d\u00e9mat\u00e9rialisation ; - De la cybers\u00e9curit\u00e9 et des infrastructures - De l'innovation R&D et l'\u00e9dition de logiciels. Depuis 2017, Acelys confirme sa ma\u00eetrise de la s\u00e9curit\u00e9 de son syst\u00e8me de management de la s\u00e9curit\u00e9 de l'information avec la certification ISO 27001 ! Bas\u00e9 \u00e0 Montpellier, au sein du dynamique P\u00f4le Eureka, notre centre abrite pr\u00e8s de 70% de nos collaborateurs. Notre histoire solide, notre ind\u00e9pendance, et notre pr\u00e9sence r\u00e9gionale font de nous un pilier de l'innovation num\u00e9rique ! Avec une \u00e9quipe de plus de 200 professionnels passionn\u00e9s, Acelys favorise la croissance et le d\u00e9veloppement de chacun. Nous encourageons la promotion interne et offrons un environnement propice \u00e0 l'acquisition de nouvelles comp\u00e9tences. Rejoignez-nous d\u00e8s aujourd'hui pour faire partie d'une \u00e9quipe dynamique et contribuer \u00e0 fa\u00e7onner l'avenir num\u00e9rique avec nous ! Description du poste : Acelys recherche un.e Data Scientist exp\u00e9riment\u00e9 en IA et NLP pour rejoindre notre \u00e9quipe dynamique au sein du p\u00f4le de R&D/IA d'une quinzaine de talents. Notre p\u00f4le R&D, expert dans le traitement du langage naturel (p\u00f4le Edition) m\u00e8ne depuis 10 ans des travaux en \u00e9troite collaboration avec des laboratoires de recherche sur des probl\u00e9matiques technologiques. Vous travaillerez en lien avec les chercheurs, ing\u00e9nieurs et autres experts en utilisant des techniques d'apprentissage automatique et de traitement du langage naturel pour r\u00e9soudre des probl\u00e8mes complexes, tels que la recherche documentaire, la similarit\u00e9 s\u00e9mantique, la classification... Profil recherch\u00e9 : - Vous \u00eates dipl\u00f4m\u00e9.e en informatique, en sciences des donn\u00e9es ou dans un domaine connexe - Vous disposez de solides comp\u00e9tences en programmation (Python, TensorFlow, PyTorch, etc.) - Vous avez connaissance des techniques d'apprentissage automatique et du traitement automatique du langage naturel - Vous \u00eates exp\u00e9riment\u00e9.e sur les pratiques CI/CD (int\u00e9gration continue et d\u00e9ploiement continu) - Une exp\u00e9rience sur les Frameworks Python est appr\u00e9ci\u00e9e : Langchain, Django/Flask,Transformers Avantages : - Salaire comp\u00e9titif et avantages sociaux : Carte Swile, pr\u00e9voyance Cadre, RTT, Plan Epargne Entreprise avec abondements, t\u00e9l\u00e9travail et un accord de participation tr\u00e8s avantageux (1,5 mois de salaire ces derni\u00e8res ann\u00e9es en moyenne) - Environnement de travail collaboratif et stimulant - Contribution \u00e0 des projets innovants Acelys Services Num\u00e9riques c'est plus de 25 ans d'histoire, \u00e9crivons la suite ensemble !\nPROFIL SOUHAIT\u00c9\nExp\u00e9rience\n18 Mois\nSavoirs et savoir-faire\nAdapter les outils de traitement statistique de donn\u00e9es\nD\u00e9finir et faire \u00e9voluer des proc\u00e9d\u00e9s de traitement de l'information\nPr\u00e9senter et diffuser les r\u00e9sultats des \u00e9tudes r\u00e9alis\u00e9es\nR\u00e9aliser une veille documentaire\nR\u00e9diger l'information produite\nSavoir-\u00eatre professionnels\nFaire preuve de rigueur et de pr\u00e9cision\nPrendre des initiatives et \u00eatre force de proposition\nTravailler en \u00e9quipe\nSource: Pole emploi (https://www.pole-emploi.fr)\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "R",
                "Go"
            ],
            "DataBase": [],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [],
            "MachingLearning": [
                "TensorFlow",
                "PyTorch"
            ],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [],
            "DevTools": [
                "Git"
            ],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [
                "CI/CD"
            ],
            "FrSoftSkills": [
                "Collaboration"
            ],
            "EnSoftSkils": [
                "Collaboration",
                "Initiative"
            ]
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [],
            "Salary": [
                "1,5"
            ],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s",
                "10",
                "10",
                "10"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "Data Scientist @ start-up",
        "company": "Licorne Society",
        "location": "Paris, \u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/data-scientist-%40-start-up-at-licorne-society-3918084326?position=55&pageNum=0&refId=yQtK%2BQI72QI4xq%2BIXLe7ew%3D%3D&trackingId=sWEXuF3Fgjkz%2Ffcbveih4g%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Licorne Society est \u00e0 la recherche de Data Scientist pour des startups innovantes, ne laisse pas passer ta chance !\nC\u2019est quoi Licorne Society ?\nLicorne Society est le seul outil qui te met en relation avec plus de 3000 startups recrutant en France, tous secteurs et m\u00e9tiers confondus. Qu\u2019elles soient en cr\u00e9ation ou en phase d\u2019hypercroissance, toutes les startups t\u2019attendent sur Licorne Society. Ah oui, et c\u2019est gratuit !\nNotre promesse : faire matcher ta recherche avec les meilleures opportunit\u00e9s et mettre en avant ton profil aupr\u00e8s des startups qui recrutent.\n>> www.licornesociety.com <<\nL'inscription Prend Moins De 10 Minutes. Tu Pourras Alors Acc\u00e9der \u00e0 L'ensemble Des Offres En Startup Du March\u00e9 Et \u00catre Contact\u00e9 Directement Par Les Recruteurs\n1 - Remplis ton profil et tes attentes.\n2 - Passe en revue les offres que nous te proposons en fonction de tes crit\u00e8res de recherche et re\u00e7ois une notification \u00e0 chaque nouvelle offre publi\u00e9e. Avec notre mode Tinder, tu n\u2019as qu\u2019\u00e0 swiper les offres. Matcher avec le job de tes r\u00eaves n\u2019a jamais \u00e9t\u00e9 aussi simple !\n3 - Re\u00e7ois des sollicitations directes pour des postes de Data Scientist au sein de nos startups pr\u00e9f\u00e9r\u00e9es (pour ne citer que BackMarket, PlayPlay, Payfit, Trustpair ou encore Choco)\nProfil Recherch\u00e9\nTu as une premi\u00e8re exp\u00e9rience de Data Scientist et tu es tr\u00e8s motiv\u00e9 pour rejoindre une start-up / scale-up ou tu es pr\u00eat \u00e0 d\u00e9crocher ton tout premier job\nTu as la fibre entrepreneuriale\nTu as soif de challenge et de nouveaux apprentissages\nTu es pr\u00eat \u00e0 cliquer sur le lien d\u2019inscription : www.licornesociety.com\nLes parcours particuli\u00e8rement valoris\u00e9s chez Licorne Society :\ndes exemples de prises d\u2019initiatives ou projets men\u00e9s avec l\u2019esprit entrepreneurial\ndes exp\u00e9riences dans des environnements particuli\u00e8rement exigeants\ndes exemples de r\u00e9alisations \u00e9difiants ou r\u00e9sultats chiffr\u00e9s\nOn se dit \u00e0 tout de suite sur la plateforme ?\n>> www.licornesociety.com <<\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "R"
            ],
            "DataBase": [],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [],
            "DevTools": [],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [],
            "FrSoftSkills": [],
            "EnSoftSkils": [
                "Initiative"
            ]
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "Data Scientist (confirm\u00e9/s\u00e9nior) - H/F - CDI",
        "company": "Talan",
        "location": "Paris, \u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/data-scientist-confirm%C3%A9-s%C3%A9nior-h-f-cdi-at-talan-3909648101?position=56&pageNum=0&refId=yQtK%2BQI72QI4xq%2BIXLe7ew%3D%3D&trackingId=A3%2FrGa020OIf9eWPHOE68Q%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Talan est un groupe international de conseil en transformation et en innovation par la technologie, cr\u00e9\u00e9 en 2002.\nNos 5000 consultantes et consultants partagent \u00e0 travers le monde l\u2019audace d\u2019innover, le go\u00fbt de l\u2019excellence, et l\u2019envie de relever les d\u00e9fis les plus complexes.\nNous accompagnons les entreprises dans des secteurs vari\u00e9s\u202f: \u00e9nergie, industrie, transport, finance, luxe\u2026 \u00e0 travers 3 grandes expertises\u202f:\nLe Conseil en Management et Innovation (320 Consultants en France)\nLa valorisation des donn\u00e9es, leurs structurations, et leurs usages (Data et Technologies)\nL\u2019int\u00e9gration de solutions logicielles (Cloud et Applications Services)\nNos valeurs\u202f: engagement, respect, partage, esprit d\u2019\u00e9quipe et optimisme.\nTalan est une entreprise responsable, reconnue par ses collaborateurs et attach\u00e9e \u00e0 la diversit\u00e9. Des am\u00e9nagements peuvent \u00eatre propos\u00e9s si vous \u00eates en situation de handicap.\nRetrouvez nos engagements RSEiciet nos actions en faveur de la diversit\u00e9ici\nJob Description\nNous sommes \u00e0 la recherche d\u2019un Data Scientist capable de participer \u00e0 des projets techniques Data Science et IA. Vous devrez faire preuve d\u2019un \u00e9tat d\u2019esprit \u00e0 la fois innovant, m\u00e9thodique, orient\u00e9 solution (et non probl\u00e8me!), et communiquant.\nVotre but ultime sera de garantir l\u2019excellence de vos solutions Data Science/IA, pi\u00e8ces maitresses de la r\u00e9alisation de projets disruptifs pour nos clients.\nVOTRE ROLE SUR NOS PROJETS\n:\nEn mission: analyse des besoins m\u00e9tiers, d\u00e9finition des principes et m\u00e9thodes de collecte et de traitement des donn\u00e9es, choix des mod\u00e8les de Machine Learning ou de Deep Learning, mise en application des techniques de traitement et de visualisation de la data, restitution des analyses et r\u00e9sultats obtenus aupr\u00e8s des m\u00e9tiers et des sponsors\nPartager techniquement les membres de l\u2019\u00e9quipe: solutions et code reviews, recommandations, certifications \u00e0 r\u00e9aliser, \u2026\nParticipation \u00e0 des meet-up, coding dogo,\u2026\nCommunication: \u00e9criture d\u2019articles, retours d\u2019exp\u00e9rience\u2026\nVOTRE ROLE CHEZ TALAN :\nBenchmark de solutions et conseil aupr\u00e8s de nos clients sur les solutions technologiques \u00e0 adopter, en lien avec leurs besoins\nR\u00e9alisation de POC (Proof Of Concept)\nParticipation \u00e0 des projets internes et partage de connaissances au sein de nos \u00e9quipes.\nPartage de connaissances et formations interne\nQualifications\nVOTRE PROFIL:\nIssu d\u2019une formation Grande \u00c9cole d\u2019Ing\u00e9nieur/Doctorant, sp\u00e9cialis\u00e9e en Data Science ou Intelligence Artificielle\nVous disposez d\u2019au moins 3 ann\u00e9es d\u2019exp\u00e9rience dans le domaine\nMaitrise des techniques d\u2019analyses statistiques, de mod\u00e9lisations pr\u00e9dictives, de Machine Learning, de Deep Learning,...\nMaitrise des techniques de data management et de DataViz\nMaitrise de Python, R, RShiny, SQL\u2026\nMaitrise de l\u2019utilisation des outils DevOps: Git, Docker, Jenkins/Nexus,\u2026\nBonnes connaissances Big Data: pySpark, Spark, NoSQL\u2026\nConnaissance d\u2019outils tels que Dataiku, AWS SageMaker, Azure ML,\u2026\nAutonomie, organisation, sens du partage\nExcellente communication\nOrientation m\u00e9tier\nAdditional Information\nAVANTAGES\n:\nPlan de formation pour accompagner votre carri\u00e8re (formations \u00e9diteurs, certifications) gr\u00e2ce \u00e0 nos partenariats nous accordant une position de partenaire privil\u00e9gi\u00e9, et management de proximit\u00e9 par des experts\nLocaux modernes en centre-ville\nTop 5 du Palmar\u00e8s Great Place to Work\nT\u00e9l\u00e9travail jusqu\u2019\u00e0 5 jours selon les missions, prime d\u2019\u00e9quipement de 100\u20ac\nMobilit\u00e9 en France et \u00e0 l\u2019\u00e9tranger\nTop 1% des entreprises \u00e9valu\u00e9es par Ecovadis dans le domaine social, environnemental et \u00e9thique\nTickets restaurant, prime vacances, 50% transport (abonnement transport public), mutuelle\nPermanence handicap (consultant d\u00e9di\u00e9 aux collaborateurs en situation de handicap et aux proches aidants)\nActionnariat salari\u00e9\nPrime de cooptations\nRTT\nPROCESS RECRUTEMENT\n:\nL\u2019\u00e9quipe recrutement s\u2019engage \u00e0 vous proposer un processus de recrutement rapide et fluide\n1 entretien RHpar Teams (45min)\n1 test technique\n1 entretien op\u00e9rationnel avec le responsable de domaine, au si\u00e8ge (1heure)\n1 entretien avec le directeur de p\u00f4le, au si\u00e8ge(1heure)\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "R",
                "Go"
            ],
            "DataBase": [
                "SQL",
                "NoSQL"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [
                "Spark"
            ],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [
                "Statistiques"
            ],
            "CloudComputing": [
                "AWS",
                "Azure"
            ],
            "DevTools": [
                "Git",
                "Docker",
                "Jenkins"
            ],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [
                "Docker"
            ],
            "Collaboration": [
                "Teams"
            ],
            "Other": [
                "DevOps",
                "Big Data",
                "ML",
                "Machine Learning",
                "Statistiques",
                "Cloud"
            ],
            "FrSoftSkills": [
                "Communication",
                "Organisation"
            ],
            "EnSoftSkils": [
                "Communication"
            ]
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "Data Scientist",
        "company": "Enzo Tech Group",
        "location": "\u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/data-scientist-at-enzo-tech-group-3914681877?position=57&pageNum=0&refId=yQtK%2BQI72QI4xq%2BIXLe7ew%3D%3D&trackingId=vgOKhxU0hjGhrc3P6nhGew%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Role:\nData Scientist\nLocation:\nParis (3 days) / Remote (2 days)\nSearching for a\nData Scientist\npartnering with a global customer who are searching for multiple Data Scientist's as they continue to invest in designing and building high-quality AI solutions.\nResponsibilities\nAnalyze raw data: assessing quality, cleansing, structuring for downstream processing\nDesign accurate and scalable prediction algorithms\nCollaborate with engineering team to bring analytical prototypes to production\nGenerate actionable insights for business improvements\nQualifications\nBachelor's degree or equivalent experience in quantative field (Statistics, Mathematics, Computer Science, Engineering, etc.)\nTech Stack: GenAI, Databricks, Azure\nAt least 1 - 2 years' of experience in quantitative analytics or data modelling\nDeep understanding of predictive modelling, machine-learning, clustering and classification techniques, and algorithms\nFluency in a programming language (Python, C,C++, Java, SQL)\nCVs:\nApply via job post or directly\n@\nk.downs@enzotechgroup.com\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "Java",
                "C++",
                "Scala",
                "R",
                "Go"
            ],
            "DataBase": [
                "SQL"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [
                "Databricks"
            ],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [
                "Statistics"
            ],
            "CloudComputing": [
                "Azure"
            ],
            "DevTools": [],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [],
            "FrSoftSkills": [],
            "EnSoftSkils": []
        },
        "details": {
            "JobDetail": [
                "Remote"
            ],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "Senior Machine Learning Engineer",
        "company": "Homa",
        "location": "Paris, \u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/senior-machine-learning-engineer-at-homa-3911467922?position=58&pageNum=0&refId=yQtK%2BQI72QI4xq%2BIXLe7ew%3D%3D&trackingId=e2z0gDbl2yM%2B0Ya45vsw2A%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Welcome to Homa, the gaming technology lab that is taking the industry by storm! Our team of over 200 people, hailing from more than 35 different countries, is dedicated to empowering mobile game creators worldwide to bring their creative ideas to the top charts.\nOur Homa Lab platform offers a comprehensive suite of cutting-edge tools that allow developers to stay on top of the latest trends, test new features in real-time, and easily distribute and monetize their games. Our success speaks for itself - our apps have been downloaded over 1 billion times!\nSince our inception, we have raised $165 million in total from prominent investors, including Headline, Northzone, Eurazeo, Singular, Quadrille Capital, Fabric Ventures, and Bpifrance. We have also received support from renowned business angels, such as the founders of King, Sorare and Spotify founders.\nBut what really makes Homa special is our team. We are a diverse group of artists, business developers, engineers, entrepreneurs, and former strategy consultants who all share the same passion for taking over the gaming industry. When you become part of Homa, you'll be joining a dedicated team that creates innovative and high-performing games that resonate with players worldwide.\nIf you're ready to take your career to the next level and make a real impact in the company, then Homa is the perfect place for you. Join us and let's create the future of gaming together!\nMeet the team\n\ud83d\udc69\u200d\ud83d\udc69\u200d\ud83d\udc67\u200d\ud83d\udc67\nYou will join the Data department organized into:\nA Data Platform team with 5 Data Engineers responsible for ingesting large amounts of data from multiple different sources, creating and maintaining a core data model which aims at making data standardized, reliable and easily available\nA Data Science and ML Platform team with 6 Data Scientists / ML Engineer working on ML-driven data products: Autobidder for User Acquisition, N-Testing for experimentation\nAn Advanced Analytics & Data Science team with 6 Data Analysts and Scientists exploiting our data for:\nGame Analytics\nUser Acquisition and Marketing Analytics\nMarket Inteligence Analytics\nOps Analytics\nRole and Missions \u2014 What you will do\n\ud83d\ude80\nWe are looking for a Senior Machine Learning Engineer to join the team in order to scale and industrialize Machine Learning & AI at Homa. Under the responsibility of our Associate Director, your responsibilities will be the following:\nLead ML Projects: Spearhead development and implementation of ML models for Marketing Tech (User Acquisition, Monetization) and Game Tech (Bayesian A/B Testing, Segmentation)\nML Industrialization & Democratization: Enhance ML engineering processes, adopt ML Ops tools, and contribute to model interpretability and collaborative efforts\nImplement Scalable ML Solutions: Build Serving APIs for handling millions of requests daily with low latency\nCollaborative Innovation: Work closely with diverse teams, leveraging GenAI tools for productivity and product improvements\nStay Updated: Integrate latest ML technologies and advancements into our tech stack\nCurrent Tech Stack: AWS, Redshift, Databricks, Python, DBT, Spark, Airflow, Kafka, Kubernetes, LightGBM, MLFlow, Metabase\nRequirements\nIf you're creative, ambitious, and up for taking over the industry, we want you on our team! We are also looking for:\nExtensive ML Experience: 5+ years in implementing and deploying ML models to production\nKey Technology Proficiency: Expertise in Neural Networks (TensorFlow / PyTorch), Gradient Boosting libraries (LightGBM / XGBoost), and at least one top Cloud provider (GCP, Azure, AWS)\nMLOps Skills: Experience with ML Ops tools like MLFlow\nAPI Development Expertise: Proven ability in building high-performance Serving APIs\nCollaborative Skills: Excellent communication and teamwork abilities\nInnovative Mindset: Passion for staying ahead in ML trends and technologies\nLanguage Skills: Fluent English is mandatory (interviews will be led in English)\nOur Culture\u2014Who we are\n\ud83e\ude90\nAt Homa, we are building a community of brilliant talents. We believe that true innovation comes from diversity and collaboration, and that's why we prioritize brainpower and determination over formal education. So if you have the talent, energy and motivation, there is no obstacle to your success here.\nAs the creative experts behind the platform, we provide developers with the data they need to bring their ideas to life. Our team lives by three central values that guide everything we do:\n\u2728\nAmbition\n: we're not afraid to tackle difficult challenges and set our goals extremely high. We're on a mission to revolutionize an industry dominated by well-established companies, and we won't stop until we succeed.\n\u2728\nHumility\n: we leave our pride & ego aside. We are always ready to lend a helping hand, celebrate each other's successes, and learn from our failures. As Mr. Lamar said, \"Sit down. Be humble.\"\n\u2728\nCuriosity\n: we keep our minds open and never stop learning. We believe that questioning everything is the best way to stay ahead of the curve, and we encourage all our team members to stay curious and never stop exploring new ideas.\nAt Homa, you'll be challenged, supported, and inspired every day, and we can't wait to see what you bring to the table.\nBenefits\nWhile success is its own reward, here are some of the benefits that come with working at Homa:\nWe offer essential benefits in France and specific locations, including health insurance, meal vouchers, public transport subsidies, childcare benefits, and life insurance\nIf you're interested in working from our newly renovated Paris HQ with a rooftop garden and WeWork amenities, we have a desk waiting for you\nYou will be working in English with our international team of top-tier talents from 35+ countries\nYou will have bi-annual reviews with your manager to reflect on your performance, celebrate wins, and receive constructive feedback\nYou will be able to attend diverse team events and Workations (the famous company-wide Homa trip)\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "Scala",
                "R",
                "Go"
            ],
            "DataBase": [],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [
                "Spark",
                "Databricks"
            ],
            "MachingLearning": [
                "TensorFlow",
                "PyTorch",
                "XGBoost",
                "LightGBM"
            ],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [
                "AWS",
                "Azure"
            ],
            "DevTools": [],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [
                "Kubernetes",
                "Airflow"
            ],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [
                "Kubernetes"
            ],
            "Collaboration": [
                "Teams"
            ],
            "Other": [
                "ML",
                "Machine Learning",
                "Cloud"
            ],
            "FrSoftSkills": [
                "Communication",
                "Collaboration"
            ],
            "EnSoftSkils": [
                "Communication",
                "Teamwork",
                "Collaboration"
            ]
        },
        "details": {
            "JobDetail": [
                "Senior"
            ],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "Software Engineer",
        "company": "BrainChip",
        "location": "Toulouse, Occitanie, France",
        "link": "https://fr.linkedin.com/jobs/view/software-engineer-at-brainchip-3902556694?position=59&pageNum=0&refId=yQtK%2BQI72QI4xq%2BIXLe7ew%3D%3D&trackingId=stpDKfqbqIGKFS22BwsK9w%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Brainchip is a leading technology company specializing in the design of electronics IP that accelerates AI on the edge. Our innovative solutions enable ultra-efficient and high-performance neural network processing for artificial intelligence applications. As part of our continuous growth, we are seeking a skilled Software Engineer with expertise in machine learning frameworks to join our team.\nResponsibilities:\nCollaborate with cross-functional teams to design, develop, and deploy machine learning models and algorithms for our products.\nImplement and optimize machine learning frameworks such as Tensorflow/Keras, PyTorch, and ONNX.\nDevelop software tools and infrastructure to support machine learning workflows, data preprocessing, model training, and evaluation.\nStay up-to-date with the latest advancements in machine learning and apply relevant techniques to enhance our products.\nConduct code reviews, provide constructive feedback, and maintain code quality and documentation.\nRequirements:\nBachelor's or Master's degree in Computer Science, Engineering, or a related field.\nStrong proficiency in machine learning frameworks such as Tensorflow/Keras, PyTorch, and ONNX.\nDemonstrated experience in developing and deploying machine learning models and algorithms.\nSolid understanding of deep learning concepts, neural networks, and related architectures.\nProficiency in programming languages such as Python, or C++.\nExperience with data preprocessing, feature engineering, and data visualization techniques.\nKnowledge of software engineering best practices, including version control, testing, and code documentation.\nStrong problem-solving skills and ability to work in a fast-paced, collaborative environment.\nExcellent communication skills and ability to effectively articulate technical concepts to both technical and non-technical team members.\nPreferred Qualifications:\nUnderstanding of computer vision or natural language processing (NLP) concepts and applications.\nExperience with deployment and optimization of machine learning models on edge devices.\nActive participation in the machine learning community, such as publications or open-source contributions.\nBenefits:\nCompetitive salary and comprehensive benefits package.\nOpportunities for professional growth and career advancement.\nCollaborative and inclusive work environment.\nFlexible work hours with the possibility to work remotely three days a week.\nAccess to cutting-edge technology and resources.\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "C++",
                "R",
                "Go"
            ],
            "DataBase": [],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [],
            "MachingLearning": [
                "TensorFlow",
                "Keras",
                "PyTorch"
            ],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [],
            "DevTools": [],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [
                "Teams"
            ],
            "Other": [
                "Machine Learning"
            ],
            "FrSoftSkills": [
                "Communication"
            ],
            "EnSoftSkils": [
                "Communication"
            ]
        },
        "details": {
            "JobDetail": [
                "Remote"
            ],
            "TypeContract": [],
            "Salary": [
                "Salary",
                "Package"
            ],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "Geospatial Data Scientist",
        "company": "EarthDaily Agro",
        "location": "Balma, Occitanie, France",
        "link": "https://fr.linkedin.com/jobs/view/geospatial-data-scientist-at-earthdaily-agro-3884744208?position=60&pageNum=0&refId=yQtK%2BQI72QI4xq%2BIXLe7ew%3D%3D&trackingId=PY3NroHcCVU8s8yVo95V2w%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "STRUCTURE D\u2019ACCUEIL\nEarthDaily Agro fournit des donn\u00e9es et des analyses de l'\u00e8re spatiale aux organisations et aux personnes qui nourrissent la plan\u00e8te !\nAvec 35 ans d'exp\u00e9rience dans le secteur, EarthDaily Agro fournit \u00e0 ses clients les donn\u00e9es, les analyses et les connaissances dont ils ont besoin pour prendre des d\u00e9cisions plus efficaces. Les services B2B vont de la gestion globale des risques et du suivi des produits agricoles \u00e0 la commercialisation d'intrants et au conseil en agriculture de pr\u00e9cision, en utilisant les derni\u00e8res recherches en agronomie, en technologies de l'information et en t\u00e9l\u00e9d\u00e9tection.\nEarthDaily Agro d\u00e9veloppe \u00e9galement des solutions commerciales hautement personnalis\u00e9es pour les pr\u00eateurs agricoles, les assureurs, les fournisseurs d'intrants et les entreprises alimentaires, avec des analyses faciles \u00e0 utiliser, qui aident \u00e0 r\u00e9duire les risques quotidiens de l'agriculture.\nEarthDaily Agro, dont le si\u00e8ge social se trouve \u00e0 Minneapolis, MN, USA, et qui poss\u00e8de des bureaux en France, au Br\u00e9sil, en Australie et en Suisse, est une division de EarthDaily Analytics Corp.\nEarthDaily Analytics Corp, une soci\u00e9t\u00e9 de traitement et d'analyse de donn\u00e9es verticalement int\u00e9gr\u00e9e, lance une nouvelle constellation de satellites d'observation de la terre. La constellation de satellites EarthDaily am\u00e9liorera consid\u00e9rablement les capacit\u00e9s d'analyse g\u00e9ospatiale dans les secteurs de l'agriculture, de la sylviculture, de l'environnement, des services financiers et du renseignement, parmi de nombreux autres segments.\nRESPONSABILIT\u00c9S\nVous serez en charge de r\u00e9soudre des challenges li\u00e9s \u00e0 l\u2019agriculture en utilisant la t\u00e9l\u00e9d\u00e9tection, en particulier les images de la future constellation EarthDaily, et des donn\u00e9es m\u00e9t\u00e9o. Bas\u00e9 \u00e0 Balma, \u00e0 proximit\u00e9 de Toulouse, vous int\u00e9grerez une \u00e9quipe internationale avec des coll\u00e8gues au Br\u00e9sil et aux USA.\nVOS RESPONSABILIT\u00c9S INCLURONT :\nL\u2019agriculture fait face \u00e0 des challenges sans\u202fpr\u00e9c\u00e9dent\u202f: le changement climatique induit des risques accrus, et les agriculteurs doivent maintenir voire am\u00e9liorer leur productivit\u00e9 tout en r\u00e9duisant leur impact environnemental. Avec la future constellation EarthDaily (jusqu\u2019\u00e0 5 m de r\u00e9solution, revisite quotidienne avec 22 bandes spectrales du visible \u00e0 l\u2019infra-rouge thermique), EarthDaily Agro disposera d\u2019une technologie clef pour r\u00e9pondre \u00e0 ces probl\u00e9matiques.\u202fRejoignez EarthDaily Agro pour contribuer \u00e0 minimiser ces risques avec la technologie.\nEarthDaily Agro est \u00e0 la recherche d\u2019un.e\u202fData\u202fScientist en t\u00e9l\u00e9d\u00e9tection pour rejoindre\u202fson \u00e9quipe R&D et construire des analytiques \u00e0 valeur ajout\u00e9e \u00e0 destination de ses clients dans le monde agricole.\nVous mettez en place des solutions inventives pour r\u00e9pondre aux probl\u00e9matiques des clients, demandant des comp\u00e9tences fortes en analyse de donn\u00e9es et\u202fen\u202fmachine\u202flearning, dans un\u202fcontexte\u202fde larges volumes de donn\u00e9es et d\u2019une base existante de plus de 100 analytiques. Vous d\u00e9veloppez des\u202fPOCs\u202fet prototypes, d\u00e9finissez / testez / validez et sp\u00e9cifiez les algorithmes appropri\u00e9s. Vous \u00eates activement\u202fimpliqu\u00e9.e\u202fdans le design et la mise en place de la solution op\u00e9rationnelle sur notre plateforme Cloud.\nVos missions\u202f:\nComprendre les probl\u00e9matiques m\u00e9tier et les traduire en solution algorithmique bas\u00e9e sur les donn\u00e9es issues de la t\u00e9l\u00e9d\u00e9tection.\nCr\u00e9er et\u202fimpl\u00e9menter\u202fdes mod\u00e8les bas\u00e9s sur l\u2019\u00e9tat de l\u2019art, pour extraire l\u2019information pertinente d\u2019un large volume de donn\u00e9es\nCollaborer au sein d\u2019une \u00e9quipe Agile pluridisciplinaire et internationale de Data Scientists, Data Engineers et experts m\u00e9tiers dans toutes les phases du projet\u202f: de l\u2019id\u00e9ation \u00e0 l\u2019industrialisation et d\u00e9ploiement op\u00e9rationnel\nR\u00e9diger des supports de pr\u00e9sentation des r\u00e9sultats, conditions d\u2019utilisation, et\u202fd\u00e9fendre\u202fla solution propos\u00e9e par une approche pragmatique\n\u00catre\u202fproactif(ve)\u202fpour alimenter le pipeline d\u2019innovation avec des nouvelles id\u00e9es, contribuer \u00e0 d\u00e9finir la roadmap R&D\nEDUCATION, CONNAISSANCES ET CAPACIT\u00c9S\nMaster ou doctorat en Machine Learning / Math\u00e9matiques appliqu\u00e9es, t\u00e9l\u00e9d\u00e9tection,\u202fou domaine associ\u00e9\nAu moins 3 ans d\u2019exp\u00e9rience professionnelle, exp\u00e9rience dans un domaine associ\u00e9 \u00e0 l\u2019agriculture et en entreprise priv\u00e9e appr\u00e9ci\u00e9e\nEtat d\u2019esprit orient\u00e9 r\u00e9sultats et pragmatique pour \u00e9voluer dans un contexte de plannings serr\u00e9s\nMa\u00eetrise\u202fde\u202fPython, connaissance en SIG (QGIS,\u202fGDAL/OGR),\nLa connaissance\u202fdes biblioth\u00e8ques de\u202fMachine\u202fLearning /\u202fDeep\u202fLearning (Scikit-learn, Pytorch, Tensorflow\u2026), des outils de MLOps (ZenML, MLFlow), des syst\u00e8mes de\u202fgestion de\u202fversion (git), de Docker, Kubernetes et du fonctionnement des workflows sur AWS (et Azure)\u202fest appr\u00e9ci\u00e9e\nFacilit\u00e9s de communication pour le travail en \u00e9quipe dans un contexte international\nAnglais courant\u202f(oral\u202fet \u00e9crit)\u202f:\u202fl\u2019\u00e9quipe d\u2019accueil est internationale, les r\u00e9unions internes se d\u00e9roulent\u202fprincipalement\u202fen anglais.\nVous \u00eates curieux(se)\u202fet cr\u00e9atif(ve), collaboratif(ve)\u202fet adaptable\u202f?\u202fRejoignez-nous\u202f!\nCONDITIONS\nEmploi en CDI, d\u00e9marrage d\u00e8s que possible\nPoste\u202fbas\u00e9\u202f\u00e0 Balma, premi\u00e8re couronne\u202fde Toulouse\u202faccessible en transports en commun.\u202fPossibilit\u00e9 de t\u00e9l\u00e9travail partiel.\nPowered by JazzHR\nm5SHCur65r\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "R",
                "Go"
            ],
            "DataBase": [],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [],
            "MachingLearning": [
                "Scikit-Learn",
                "TensorFlow",
                "PyTorch"
            ],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [
                "AWS",
                "Azure"
            ],
            "DevTools": [
                "Git",
                "Docker"
            ],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [
                "Kubernetes"
            ],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [
                "Docker",
                "Kubernetes"
            ],
            "Collaboration": [],
            "Other": [
                "ML",
                "Machine Learning",
                "Cloud"
            ],
            "FrSoftSkills": [
                "Communication",
                "Organisation"
            ],
            "EnSoftSkils": [
                "Communication"
            ]
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [
                "CDI"
            ],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s",
                "35",
                "35",
                "35"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "Data Scientist (F/M)",
        "company": "VINCI Airports",
        "location": "Nanterre, \u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/data-scientist-f-m-at-vinci-airports-3888479165?position=1&pageNum=2&refId=rHF5P6MO3jZ6rW9i1nxesw%3D%3D&trackingId=5NI7NhaKbwRxfxA472k5mQ%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Premier op\u00e9rateur a\u00e9roportuaire priv\u00e9 au monde,\nVINCI Airports\ng\u00e8re plus de 70 a\u00e9roports dans 13 pays en Europe, en Asie et sur le continent am\u00e9ricain. Gr\u00e2ce \u00e0 son expertise d\u2019int\u00e9grateur global, VINCI Airports d\u00e9veloppe, finance, construit et exploite les a\u00e9roports en apportant sa capacit\u00e9 d\u2019investissement et son savoir-faire dans l\u2019optimisation de la performance op\u00e9rationnelle, la modernisation des infrastructures et la conduite de leur transition environnementale.\nNous recherchons actuellement\nun(e) Data Scientist (F/M)\nen CDI.\nRattach\u00e9(e) au D\u00e9partement Data de la Direction financi\u00e8re de VINCI Airports, vous participerez, en coordination avec les \u00e9quipes m\u00e9tiers et appuy\u00e9(e) par l\u2019\u00e9quipe d\u2019ing\u00e9nieurs Data (si\u00e8ge VINCI Airports et Pays), \u00e0 la mise en \u0153uvre du projet \u00ab SMART DATA HUB \u00bb, un projet strat\u00e9gique et passionnant, qui a pour vocation de fournir \u00e0 l\u2019ensemble des a\u00e9roports du groupe la capacit\u00e9 \u00e0 mieux piloter la performance de l\u2019activit\u00e9 autour de la Data.\nPour ce faire vous serez amen\u00e9(e) \u00e0 d\u00e9velopper des solutions avanc\u00e9es en Data Science, Mod\u00e8les de Machine Learning, avec un accent particulier sur le traitement du langage naturel (NLP) dans le d\u00e9partement Data de VINCI Airports pour les besoins de digitalisation et d\u2019am\u00e9lioration des processus de VINCI Airports.\nMissions :\nMod\u00e9lisation et pr\u00e9vision : Concevoir, d\u00e9velopper et mettre en \u0153uvre des mod\u00e8les statistiques et algorithmiques. Utiliser des m\u00e9thodes d'apprentissage automatique et d'intelligence artificielle (IA) pour cr\u00e9er des mod\u00e8les pr\u00e9dictifs.\nAnalyse des donn\u00e9es : Collecter, nettoyer et pr\u00e9parer les donn\u00e9es brutes en vue de leur analyse. Utiliser des techniques de visualisation et des outils statistiques pour explorer et comprendre les ensembles de donn\u00e9es.\nExploitation des donn\u00e9es : Identifier les opportunit\u00e9s d'am\u00e9lioration des processus et des performances en utilisant les donn\u00e9es disponibles. Travailler en \u00e9troite collaboration avec les \u00e9quipes op\u00e9rationnelles pour comprendre leurs besoins et proposer des solutions bas\u00e9es sur les donn\u00e9es.\nCommunication des r\u00e9sultats : Pr\u00e9senter les r\u00e9sultats de l'analyse de mani\u00e8re claire et compr\u00e9hensible \u00e0 des publics non techniques. Collaborer avec des \u00e9quipes multidisciplinaires pour fournir des recommandations bas\u00e9es sur les donn\u00e9es pour la prise de d\u00e9cision strat\u00e9gique.\nTravailler sur des projets impliquant des mod\u00e8les de langage comme GPT d\u00e9velopp\u00e9s par Open AI ou Google (ou autres nouvelles solutions sur le march\u00e9).\nParticiper \u00e0 des formations et des ateliers avec les analystes de VINCI Airports pour d\u00e9velopper leurs comp\u00e9tences techniques et m\u00e9thodologiques gr\u00e2ce aux solutions Data science/NLP.\nL\u2019ensemble de ces actions seront \u00e0 entreprendre sur l\u2019ensemble des domaines m\u00e9tiers de VINCI Airports : Trafic, commercial, op\u00e9rations...\nEffectuer une veille constante sur les derni\u00e8res avanc\u00e9es en Data Science, LLM et NLP pour proposer des solutions innovantes et les int\u00e9grer aux mod\u00e8les d\u00e9velopp\u00e9s par l\u2019\u00e9quipe Data.\nLe profil que nous recherchons \u00e0 ce poste :\nDipl\u00f4me universitaire (Bac+5) en statistiques, math\u00e9matiques, informatique, science des donn\u00e9es, Intelligence Artificielle ou un domaine connexe.\nExp\u00e9rience pratique dans l'analyse de donn\u00e9es et l'utilisation d'outils d'analyse tels que Python, R, SAS, SQL,\u2026\nBonne connaissance des techniques d'apprentissage automatique (machine learning), des algorithmes statistiques et de l'analyse pr\u00e9dictive.\nConnaissance approfondie des concepts de Machine Learning et des biblioth\u00e8ques telles que TensorFlow, PyTorch, Scikit-Learn.\nMotivation pour la recherche et la r\u00e9solution de probl\u00e8mes complexes.\nInt\u00e9r\u00eat et exp\u00e9rience en traitement du langage naturel (NLP), y compris la familiarit\u00e9 avec les mod\u00e8les de langage comme GPT.\nCapacit\u00e9 \u00e0 travailler de mani\u00e8re autonome et \u00e0 g\u00e9rer efficacement les projets, tout en respectant les d\u00e9lais impartis.\nComp\u00e9tences en communication orale et \u00e9crite pour pr\u00e9senter des r\u00e9sultats complexes de mani\u00e8re claire et concise.\nCuriosit\u00e9 intellectuelle et passion pour l'exploration des donn\u00e9es afin de d\u00e9couvrir des informations cach\u00e9es et de g\u00e9n\u00e9rer des id\u00e9es novatrices.\nTravail en \u00e9quipe.\nVous \u00eates capable de converser en Anglais.\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "R",
                "Go"
            ],
            "DataBase": [
                "SQL"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [],
            "MachingLearning": [
                "Scikit-Learn",
                "TensorFlow",
                "PyTorch"
            ],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [
                "Statistiques"
            ],
            "CloudComputing": [],
            "DevTools": [
                "Git"
            ],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [
                "Machine Learning",
                "Statistiques"
            ],
            "FrSoftSkills": [
                "Communication",
                "R\u00e9solution de probl\u00e8mes",
                "Collaboration"
            ],
            "EnSoftSkils": [
                "Communication",
                "Collaboration"
            ]
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [
                "CDI"
            ],
            "Salary": [],
            "Level": [
                "Bac+5"
            ],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "Machine Learning Engineer",
        "company": "Mirakl",
        "location": "Bordeaux, Nouvelle-Aquitaine, France",
        "link": "https://fr.linkedin.com/jobs/view/machine-learning-engineer-at-mirakl-3879681732?position=2&pageNum=2&refId=rHF5P6MO3jZ6rW9i1nxesw%3D%3D&trackingId=9BUg8aU0LdZr97UGsoJlEA%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Mirakl, leader et pionnier de l\u2019\u00e9conomie de plateforme, propose aux entreprises une suite unique de solutions leur permettant de transformer significativement leur e-commerce afin d'acc\u00e9l\u00e9rer de fa\u00e7on durable et rentable leur croissance. Depuis 2012, Mirakl accompagne les entreprises B2C et B2B avec la technologie la plus avanc\u00e9e, s\u00e9curis\u00e9e et \u00e9volutive leur permettant de digitaliser leur activit\u00e9 et d'\u00e9largir leur offre via la marketplace ou le dropship, faciliter la gestion des catalogues et des paiements de leurs fournisseurs pour plus d'efficacit\u00e9, offrir une exp\u00e9rience d'achat personnalis\u00e9e \u00e0 leurs clients, et augmenter leurs profits gr\u00e2ce au retail media. Bas\u00e9e \u00e0 Paris et Boston, Mirakl est certifi\u00e9e Great Place to Work.\nA propos de Mirakl Labs\nNos \u00e9quipes techniques et produits, nomm\u00e9es Mirakl Labs, sont principalement r\u00e9parties entre nos 2 hubs situ\u00e9s \u00e0 Paris et \u00e0 Bordeaux. Elles collaborent au quotidien afin d'adresser les probl\u00e9matiques de nos clients et utilisateurs en r\u00e9pondant \u00e0 diff\u00e9rents challenges li\u00e9s aux nouvelles fonctionnalit\u00e9s, \u00e0 la scalabilit\u00e9, la s\u00e9curit\u00e9 et l\u2019ergonomie\u2026\nElles op\u00e8rent en mode agile et s'organisent en Squads compos\u00e9es d'un Squad Lead, de 5 d\u00e9veloppeurs, d'un Product Manager et d'un QA. Chaque Squad est sp\u00e9cialis\u00e9e sur un scope fonctionnel afin de concevoir et r\u00e9aliser de nouvelles features, leurs \u00e9volutions et des APIs (avec un d\u00e9coupage en micro-services). Nos \u00e9quipes Infrastructure, Architecture, S\u00e9curit\u00e9, Documentation, Product Design, Data et Support op\u00e8rent en transverse en apportant leur expertise et de la coh\u00e9rence sur l\u2019ensemble des produits.\nToutes les \u00e9quipes sont responsables de leur p\u00e9rim\u00e8tre et chacun des collaborateurs apporte son exp\u00e9rience et ses id\u00e9es. Innovation, feedback et implication dans les prises de d\u00e9cision sont au c\u0153ur de notre philosophie.\nEt pour favoriser ce partage avec d\u2019autres passionn\u00e9s, nous sommes sponsors, speakers, et h\u00f4tes de diff\u00e9rents \u00e9v\u00e9nements, meetups, et associations de la sc\u00e8ne Tech en France. Au cours des derni\u00e8res ann\u00e9es, nous avons particip\u00e9 \u00e0 des \u00e9v\u00e9nements tels que Devoxx, ReactEurope, ProductConf et Flupa UX Days.\nA propos du job\nInt\u00e9gr\u00e9.e dans notre \u00e9quipe Data Science, votre principale mission sera de prototyper, it\u00e9rer, et mettre en production des algorithmes en collaboration avec les \u00e9quipes Produit, les Data Engineers et les \u00e9quipes de d\u00e9veloppement. Les sujets que vous traiterez auront un vrai impact sur nos clients : l\u2019ambition est d\u2019exploiter au maximum nos donn\u00e9es riches et vari\u00e9es afin de d\u00e9velopper leur chiffre d'affaires, d\u2019optimiser la gestion op\u00e9rationnelle de leur marketplace et de garantir la s\u00e9curit\u00e9 des utilisateurs et des transactions.\nA propos de l\u2019\u00e9quipe\nGet to Know the Data Science Team That Powers the Mirakl Platform\nCe qu\u2019il y a pour vous dans ce job\nImpl\u00e9menter, optimiser et d\u00e9ployer des algorithmes qui auront un impact visible sur plus de 500 sites e-commerce/marketplaces dans 40 pays dont certains une volum\u00e9trie tr\u00e8s importantes (millions de produits, de clients, de commandes par an)\nTraiter des sujets tr\u00e8s divers et vari\u00e9s d\u2019un point de vue:\nBusiness\nMachine learning (NLP, Image processing, Time series, LLM, syst\u00e8me de recommandation, etc.)\nInfrastructure (spark, model endpoints, etc.)\nUne plateforme Machine Learning et Data Platform state-of-the-art\nConcevoir et d\u00e9ployer des infrastructures \u00e0 faible latence avec les Data Engineers\nUne vraie autonomie et responsabilit\u00e9 dans les projets dont vous avez l\u2019ownership\nLa possibilit\u00e9 d'avoir un contrat freelance ou CDI\nNotre stack et nos outils\nPython, Tensorflow, Pytorch, Databricks, Spark, Aws, Airflow, MLflow, Delta Lake, SQL\nAu quotidien\n,\nvous allez :\nDesigner, optimiser et mettre en production des mod\u00e8les de machine learning de fa\u00e7on scalable (apprentissage et inf\u00e9rence)\nRassembler et manipuler les donn\u00e9es, prototyper des algorithmes de machine learning\nMettre en place et monitorer des serving endpoints\nParticiper \u00e0 l\u2019\u00e9volution de la plateforme Machine Learning de Mirakl\nContinuer \u00e0 mettre en place des best practices de programmation mais aussi de d\u00e9ploiement\nEffectuer de la veille technologique sur les mod\u00e8les state-of-the-art, ainsi que sur les stack machine learning\nPr\u00e9senter les r\u00e9sultats au weekly data science et aux sessions de brainstorming de l\u2019\u00e9quipe\n\u00c9changer avec les autres \u00e9quipes pour affiner les cas d\u2019utilisation, l\u2019exp\u00e9rience utilisateur et les modes d\u2019int\u00e9gration\nVous aimerez ce job si :\nVous avez minimum 3 ans d\u2019exp\u00e9rience en tant que Machine Learning Engineer (le poste est \u00e9volutif selon votre s\u00e9niorit\u00e9)\nVous avez de solides comp\u00e9tences en d\u00e9veloppement Python\nVous aimez le software engineering et le machine learning\nVous avez une exp\u00e9rience significative dans la mise en production, le scaling des mod\u00e8les et des bests practices MLOps\nVous avez l\u2019habitude de chercher, manipuler et analyser des donn\u00e9es \u00e0 forte volum\u00e9trie, id\u00e9alement avec Spark\nVous avez une bonne connaissance des algorithmes de Deep Learning (texte et/ou image), des architectures State-Of-the-Art - par exemple les Transformers\nVous avez de l\u2019exp\u00e9rience dans l\u2019optimisation de mod\u00e8les de machine learning et de leur inf\u00e9rence\nVous avez de l\u2019exp\u00e9rience dans la mise en place de serving de mod\u00e8les\nVous aimez avoir l\u2019ownership de vos sujets et aimez partager votre travail dans le cadre de pr\u00e9sentations internes, dans des conf\u00e9rences ou en r\u00e9digeant des articles\nPetit plus :\nVous avez une exp\u00e9rience en environnement e-commerce, sur des algorithmes de syst\u00e8mes de recommandations et/ou retail media*\nVous avez une exp\u00e9rience dans le serving de mod\u00e8les \u00e0 faible latence\nVous \u00eates sp\u00e9cialiste NLP\nOptimisation de LLM\nMirakl est engag\u00e9e en faveur de la diversit\u00e9, de l\u2019\u00e9galit\u00e9 des chances et de l\u2019inclusion. Nous c\u00e9l\u00e9brons nos diff\u00e9rences car nous sommes convaincus que les qualit\u00e9s visibles et invisibles de chaque Mirakl Worker sont une source de force et d\u2019innovation. Dans le cadre de cet engagement, nous \u00e9tudions toutes les candidatures sans distinction de : genre, ethnicit\u00e9, religion, orientation sexuelle, handicap, \u00e2ge ou toute autre caract\u00e9ristique prot\u00e9g\u00e9e par la loi.\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "Scala",
                "R",
                "Go"
            ],
            "DataBase": [
                "SQL"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [
                "Spark",
                "Databricks"
            ],
            "MachingLearning": [
                "TensorFlow",
                "PyTorch"
            ],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [
                "AWS"
            ],
            "DevTools": [
                "Git"
            ],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [
                "Airflow"
            ],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [
                "ML",
                "Machine Learning"
            ],
            "FrSoftSkills": [
                "Collaboration"
            ],
            "EnSoftSkils": [
                "Collaboration"
            ]
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [
                "CDI"
            ],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s",
                "3",
                "3",
                "3"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "Data Scientist",
        "company": "Unreal Staffing, Inc",
        "location": "Paris, \u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/data-scientist-at-unreal-staffing-inc-3913911173?position=3&pageNum=2&refId=rHF5P6MO3jZ6rW9i1nxesw%3D%3D&trackingId=GNqkQzs2gW5huzkmNtBwdQ%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "About Us\nThe fashion industry contributes significantly to global greenhouse gas emissions. To address this, we developed a Carbon Management Platform tailored for the textile and fashion industry. We automate life-cycle assessment to help brands understand and reduce their environmental footprint.\nData At Our Company\nOur Data team manages customer data parsing and analytics. We clean and normalize customer data for accurate analysis and provide analytics on product-level environmental impacts.\nRequirements\nWhat You'll Be Working With\nInteresting data: Our data describes physical objects, such as shoes, t-shirts, and packaging boxes, enabling real insights into the environmental impact of products\nUnique opportunity: Apply your data science skills to reduce the environmental footprint of fashion companies\nWhat We're Looking For\nStrong communication skills\nExperience with heterogeneous data and basic NLP techniques\nProficiency in Python and SQL\nBasic software engineering skills\nBenefits\nRemote work in Europe\nCoworking space allowance up to \u20ac300/month\nModern amenities including MacBook, headset, ChatGPT subscription, GitHub Copilot, etc\n100% health insurance coverage with Alan at the best coverage level\nOption to work from our office in Paris\nWork retreats organized 3 times a year\nTransparent compensation package with salary range \u20ac60k - \u20ac80k and significant equity\nOpportunities for promotion based on performance and impact on the company\nStrong belief in open-source software and contribution to the community\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "R"
            ],
            "DataBase": [
                "SQL"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [],
            "DevTools": [
                "Git"
            ],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [],
            "FrSoftSkills": [
                "Communication"
            ],
            "EnSoftSkils": [
                "Communication"
            ]
        },
        "details": {
            "JobDetail": [
                "Remote"
            ],
            "TypeContract": [],
            "Salary": [
                "60k",
                "60k"
            ],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "Data Scientist - Python (Mid-senior, Senior)",
        "company": "Pathway",
        "location": "Paris, \u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/data-scientist-python-mid-senior-senior-at-pathway-3887683294?position=4&pageNum=2&refId=rHF5P6MO3jZ6rW9i1nxesw%3D%3D&trackingId=B0Snu3fMA18R1gyURcTfvw%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "About Pathway\nDeeptech start-up, founded in March 2020.\nOur primary developer offering is an ultra-performant Data Processing Framework (unified streaming + batch) with a Python API, distributed Rust engine, and capabilities for data source integration & transformation at scale (Kafka, S3, databases/CDC,...)\nThe single-machine version is provided on a free-to-use license (`pip install pathway`)\nMajor data use cases are around event-stream data (including real-world data such as IoT), and graph data that changes over time\nOur enterprise offering is currently used by leaders of the logistics industry, such as DB Schenker or La Poste, and tested across multiple industries. Pathway has been featured in Gartner's market guide for Event Stream Processing\nLearn more at http://pathway.com/ and https://github.com/pathwaycom/\nPathway is VC-funded, with amazing BAs from the AI space and industry. We have operations across Europe and in the US. We are headquartered in Paris, with significant support from the French ecosystem (BPI, Agoranov, WILCO,...).\nThe Team\nPathway is built by and for overachievers. Its co-founders and employees have worked in the best AI labs in the world (Microsoft Research, Google Brain, ETH Zurich), worked at Google, and graduated from top universities (Polytechnique, ENSAE, Sciences Po, HEC Paris, PhD obtained at the age of 20, etc...). Pathway's CTO is a co-author with Goeff Hinton and Yoshua Bengio. The management team also includes the co-founder of Spoj.com (1M+ developer users) and NK.pl (13.5M+ users) and experienced growth leader who has scaled companies with multiple exits.\nThe opportunity\nWe are currently searching for\nData Scientists\nwith\nexperience in the Python stack\n, to help explore and discover the most pertinent insights in datasets on spatio-temporal event streams. In this job, statistical rigor and beauty of visualization meet on equal footing.\nYou Will\nbe working with spatiotemporal data with advanced schemas (time-changing graph models)/\nbe designing data cross-sections, proposing analytics metrics and KPI's in line with clients' objectives, selecting clustering algorithms, and preparing visualizations, to enable fast data exploration and insight discovery - all within our product\nbe designing dashboards in SQL with some Python elements/extensions\nbe directly helping us with Customer Conversion and Adoption within Customer organizations, by contributing to both deployment instances and \"demonstrators\" of our product, performed on client data sets\nwork directly with our Product Owner and CTO to propose and implement extensions to our product, based on repetitive client needs\ndepending on your seniority, implement machine learning algorithms on spatiotemporal event streams and other geospatial data\nThe results of your work will play a crucial role in proving how our technology can help with compelling industry use cases.\nRequirements\nYou Are\nReady for hands-on contribution to the product, helping to ensure the success of demonstrators for clients, and contribution to product codebase\nIntuitive, with good visual taste, and good common sense judgment\nCommitted to beautiful user-centered design: you know that stories are made for people, and you are willing to listen to what they have to say\nCurious at heart and thrilled to work with real-world data, especially spatio-temporal data\nLike trains, trucks, cranes, pythons, pandas, and other things that move\nNot afraid to switch between the roles of data scientist, data-vis magician, statistician, engineer, and detective, at a moment's notice\nHave 2 years+ experience in positions related to Data Science.\nHave a very good working knowledge of Python\nKnow SQL. Are able to work with tables and other data types (arrays, json,...)\nWould be able to implement the Transit Node Routing algorithm in Python just based on reading its Wikipedia article\nHave experience with git, build systems, and CI/CD\nHave at least basic undergrad textbook familiarity with graph algorithms, finite automata, and text (string) search algorithms\nUnderstand statistical concepts, such as correlated random variables, significance, and non-Gaussian noise\nPrepared to be quizzed & grilled by the datasets you encounter, everyday. Here are some questions you should be able to answer off the top of your head: what can \"-273.15\" signify; why \"65535\" is a suspicious integer value; how many months does it take a containership to go around the world; and, roughly what order of g-force is attained by an astronaut in a space rocket at liftoff?\nRespectful of others\nFluent in English\nBonus Points\nShowing a portfolio: code on github, visualization works, a research paper or a PhD thesis with an original statistical / probabilistic analysis or experiment design,..\nSuccessful track-record in Data Science or algorithms contests (Kaggle, Codeforces,...)\nExperience in topics linked to logistics/moving assets\nFamiliarity with some form of GIS software\nFamiliarity with Pandas, SciPy, NetworkX, and similar tools from the Python stack\nExperience in Data Visualization and UX\nSome knowledge of French, Polish, or German\nWhy You Should Apply\nJoin an intellectually stimulating work environment\nBe a pioneer: you get to work with a new type of data processing\nWork in one of the hottest data/AI startups in France\nUncover exciting career prospects\nMake significant contribution to our success\nJoin & co-create an inclusive workplace culture\nBenefits\nType of contract: Permanent employment contract\nPreferable joining date: February 2023. The positions (at least 2) are open until filled\nCompensation: annual salary of \u20ac50K-\u20ac70K (mid) up to \u20ac60K-\u20ac90K (senior, upper band negotiable) + Employee stock option plan\nLocation: Remote work from home. Possibility to work or meet with other team members in one of our offices:\nParis Area - Drahi X-Novation Center, Ecole Polytechnique, Palaiseau\nParis - Agoranov (where Doctolib, Alan, and Criteo were born) near Saint-Placide Metro (75006)\nWroclaw - University area\nPermanent residence will be required in France or Poland, exceptional candidates will be considered anywhere in the EU.\nIf you meet our broad requirements but are missing some experience, don't hesitate to reach out to us.\nNote\n: CS & engineering school students with exceptional profiles and/or strong motivation to join Pathway are invited to apply for Data Science internships. (Minimum duration: 5-6 months, remuneration level: \u20ac1500 / month.)\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "R",
                "Go"
            ],
            "DataBase": [
                "SQL"
            ],
            "DataAnalytics": [
                "Pandas",
                "R"
            ],
            "BigData": [],
            "MachingLearning": [],
            "DataSerialization": [
                "Json"
            ],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [],
            "DevTools": [
                "Git"
            ],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [
                "Machine Learning",
                "CI/CD"
            ],
            "FrSoftSkills": [],
            "EnSoftSkils": [
                "Organization"
            ]
        },
        "details": {
            "JobDetail": [
                "Remote",
                "Senior"
            ],
            "TypeContract": [],
            "Salary": [
                "50K"
            ],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "Ing\u00e9nieur Data scientist \u2013Intelligence artificielle-  IDF, France (H/F)",
        "company": "Astek",
        "location": "\u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/ing%C3%A9nieur-data-scientist-%E2%80%93intelligence-artificielle-idf-france-h-f-at-astek-3886897805?position=5&pageNum=2&refId=rHF5P6MO3jZ6rW9i1nxesw%3D%3D&trackingId=07ofJ%2Fg2osWr8mbqWCj8Jg%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Ce que nous allons accomplir ensemble :\nPour l\u2019un de nos projets dans le domaine a\u00e9ronautique, vous interviendrez en tant\nqu\u2019ing\u00e9nieur Data scientist / Intelligence artificielle\nsur la mise en place de syst\u00e8mes experts destin\u00e9s aux avions civils et militaires.\nVotre future \u00e9quipe :\nTeam IT de 12 personnes\nData scientist, ing\u00e9nieurs syst\u00e8mes, int\u00e9grateurs, architectes\nVous travaillerez avec de v\u00e9ritables passionn\u00e9s !\nVotre mission (...si vous l\u2019acceptez !) :\nVous participerez au d\u00e9veloppement des fonctions d\u2019analyses multisyst\u00e8mes. Pour cela vous assurerez l\u2019\u00e9tablissement d\u2019une sp\u00e9cification formelles sur les mod\u00e8les d\u2019analyses.\nVous assurerez l\u2019analyse des donn\u00e9es et la proposition de m\u00e9thodes pour le traitement des signaux.\nVous d\u00e9velopperez les outils capables de traiter de mani\u00e8re automatique les donn\u00e9es syst\u00e8mes.\nVous assurerez la r\u00e9alisation des sc\u00e9narios, ainsi que les tests et simulations.\nVous r\u00e9aliserez \u00e9galement une activit\u00e9 de support.\nVotre stack de jeu :\nData scientist, python, principe de gestion de configuration, et tra\u00e7abilit\u00e9, syst\u00e8mes a\u00e9ronautiques, intelligence artificielle\nLes petits plus du projet :\nVous \u00e9voluerez au sein d\u2019\u00e9quipes agiles impliqu\u00e9es et r\u00e9actives.\nVous interviendrez de A \u00e0 Z sur des projets riches fonctionnellement et ambitieux techniquement :\nforte volum\u00e9trie, haut niveau de performance, exigence maximale en termes d\u2019intelligence artificielle et encore bien d'autres sujets captivants.\nVous ?\nDe formation Ing\u00e9nieur, vous justifiez d\u2019une exp\u00e9rience significative en Data scientist et ou Intelligence artificielle.\nUne connaissance des m\u00e9thodes d\u2019analyse de donn\u00e9es serait un plus.\nId\u00e9alement vous avez une connaissance des syst\u00e8mes a\u00e9ronautiques.\nDes postes \u00e9galement ouverts aux d\u00e9butants si stages significatifs.\nNous ?\nCr\u00e9\u00e9 en France en 1988, Astek est un acteur mondial de l\u2019ing\u00e9nierie et du conseil en technologies, pr\u00e9sent sur les 5 continents. Fort de son expertise dans de nombreux secteurs industriels et tertiaires, Astek accompagne ses clients internationaux dans le d\u00e9ploiement intelligent de leurs produits et de leurs services, et dans la mise en \u0153uvre de leur transformation digitale.\nDepuis sa cr\u00e9ation, le Groupe a fond\u00e9 son d\u00e9veloppement sur une forte culture d\u2019entrepreneuriat et d\u2019innovation, et sur l\u2019accompagnement et la mont\u00e9e en comp\u00e9tence de ses 5 200 collaborateurs qui s\u2019engagent chaque jour \u00e0 promouvoir la compl\u00e9mentarit\u00e9 entre les technologies num\u00e9riques et l\u2019ing\u00e9nierie des syst\u00e8mes complexes.\nRejoignez un Groupe en fort d\u00e9veloppement en France et \u00e0 travers le monde gr\u00e2ce \u00e0 une lev\u00e9e de fonds de 200M\u20ac r\u00e9alis\u00e9e en 2021. Ensemble \u00ab Let\u2019s move forward! \u00bb\n\u2728 Tous les d\u00e9tails sur le Groupe sur le site\nhttps://astekgroup.fr.\nEt vous pouvez aussi nous suivre sur\nnotre blog : https://blog.groupeastek.com\n.\nRencontrons-nous !\nVous vous \u00eates reconnu sur l\u2019annonce et Astek vous pla\u00eet !\nPour en savoir plus sur vous, Franck , notre Talent Acquisition vous contacte. Puis, vous aurez 3 entretiens max, avec L\u00e9onard (votre futur n+1), L\u00e9onard notre Directeur !\nNos plus\nAstek est green et fait b\u00e9n\u00e9ficier ses salari\u00e9s d\u2019une indemnit\u00e9 kilom\u00e9trique v\u00e9lo\nUn programme CARE sur-mesure d\u00e9ploy\u00e9 par nos \u00e9quipes RH pour nos collaborateurs : https://astekgroup.fr/engagements\nNotre charte de la Diversit\u00e9\nBienvenue dans la team ! Allez-y, maintenant c\u2019est \u00e0 vous de jouer !\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "R"
            ],
            "DataBase": [],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [],
            "DevTools": [
                "Git"
            ],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [],
            "FrSoftSkills": [],
            "EnSoftSkils": []
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "Data scientist H/F",
        "company": "MP DATA",
        "location": "Clermont-Ferrand, Auvergne-Rh\u00f4ne-Alpes, France",
        "link": "https://fr.linkedin.com/jobs/view/data-scientist-h-f-at-mp-data-3904074177?position=6&pageNum=2&refId=rHF5P6MO3jZ6rW9i1nxesw%3D%3D&trackingId=tZj38Lk9HSQA2jKy9S%2BUtw%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "MP DATA est une soci\u00e9t\u00e9 sp\u00e9cialis\u00e9e dans l\u2019acquisition, le traitement, et la valorisation des donn\u00e9es. Depuis sa cr\u00e9ation en 2015, MP DATA accompagne ses clients, majoritairement industriels, dans le management de leur performance et l\u2019exploitation de leur donn\u00e9e.\nLes collaborateurs, tous issus de grandes \u00e9coles, incarnent au quotidien les valeurs d\u2019Excellence, de Partage et d\u2019Engagement. Ils associent savoir-faire technique, m\u00e9thodologie et passion et mettent leurs comp\u00e9tences au service de missions et projets au sein de grands groupes fran\u00e7ais.\nMP DATA accompagne ses clients sur toute la chaine au travers de 3 p\u00f4les d\u2019expertise : Conseil et Strat\u00e9gie, Infrastructure & CloudOPS, Data Science.\nNous recherchons un(e) Data Scientist passionn\u00e9(e) pour rejoindre notre \u00e9quipe dynamique.\nEn tant que membre cl\u00e9 du p\u00f4le Data Science de notre client, un grand acteur du secteur automobile, vous serez charg\u00e9(e) d'analyser, interpr\u00e9ter et exploiter les donn\u00e9es pour fournir des solutions innovantes \u00e0 nos clients.\nConception et mise en \u0153uvre de mod\u00e8les pr\u00e9dictifs et d'algorithmes avanc\u00e9s.\nAnalyse approfondie des donn\u00e9es pour identifier des tendances et des opportunit\u00e9s.\nCollaboration \u00e9troite avec les \u00e9quipes clients pour comprendre leurs besoins et d\u00e9finir des solutions sur mesure.\nParticipation active \u00e0 la veille technologique et \u00e0 l'am\u00e9lioration continue de nos pratiques en Data Science.\nProfil :\nDipl\u00f4me\ning\u00e9nieur Grande \u00c9cole\nen Data Science, Statistiques, Informatique ou domaine connexe.\nExp\u00e9rience pratique dans le d\u00e9veloppement et l'application de mod\u00e8les pr\u00e9dictifs,\nMa\u00eetrise des langages de programmation tels que Python,\nExcellentes comp\u00e9tences analytiques et capacit\u00e9 \u00e0 traduire des r\u00e9sultats complexes en recommandations claires,\nForte aptitude \u00e0 travailler en \u00e9quipe et \u00e0 communiquer efficacement.\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "R",
                "Go"
            ],
            "DataBase": [],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [
                "Statistiques"
            ],
            "CloudComputing": [],
            "DevTools": [],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [
                "Statistiques",
                "Cloud"
            ],
            "FrSoftSkills": [
                "Collaboration"
            ],
            "EnSoftSkils": [
                "Collaboration"
            ]
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "Machine Learning Developer",
        "company": "MindPal",
        "location": "Toulouse, Occitanie, France",
        "link": "https://fr.linkedin.com/jobs/view/machine-learning-developer-at-mindpal-3896992755?position=7&pageNum=2&refId=rHF5P6MO3jZ6rW9i1nxesw%3D%3D&trackingId=m0ZvcDDpRnCzubGmA7JCcQ%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "We are looking for\nMachine Learning Developer\nJob Responsibilities\nWorking on machine learning projects\nAnalyzing and processing data to create machine learning models\nImplementing and optimizing machine learning algorithms\nTesting and evaluating models\nCollaborating with the programming team and other departments within the company to develop innovative solutions\nRequirements\nMinimum 2 years of experience in the field of machine learning\nKnowledge of machine learning algorithms and techniques\nAbility to analyze and process data\nFamiliarity with machine learning tools and technologies\nProficient in English communication\nEducation in computer science\nWe Offer\nB2B contract type\nFull-time employment\nRemote and flexible working hours\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "R",
                "Go"
            ],
            "DataBase": [],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [],
            "DevTools": [],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [
                "Machine Learning"
            ],
            "FrSoftSkills": [
                "Communication"
            ],
            "EnSoftSkils": [
                "Communication"
            ]
        },
        "details": {
            "JobDetail": [
                "Remote",
                "Full"
            ],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "Machine Learning Engineer",
        "company": "Enzo Tech Group",
        "location": "Paris, \u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/machine-learning-engineer-at-enzo-tech-group-3914687840?position=8&pageNum=2&refId=rHF5P6MO3jZ6rW9i1nxesw%3D%3D&trackingId=74br4h3JTXLFgFViA%2BBHXw%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Position:\nMachine Learning Engineer / MLOps Engineer / AI Engineer\nLocation:\nParis\nType:\nFreelance, Contract\nDuration:\n6 months\nSearching for a\nMLOps Engineer\nto lead the implementation of\nMLOps\npractices at scale with a focus on\nlarge language models\n(LLM)\n.\nRole:\nLead the implementation of\nMLOps\npractices at scale, focusing on industrialising AI solutions and ensuring their efficient deployment.\nCollaborate with software engineering teams to integrate machine learning models into production environments.\nManage and optimise\nAI infrastructure\non\nAzure\n, including\nDatabricks\nclusters and other relevant technologies.\nDevelop and maintain automation pipelines for model training, testing, monitoring, and retraining.\nRequirements\nProven experience as an MLOps Engineer or similar role, with expertise in large-scale AI deployments.\nDeep understanding of MLOps principles, including model versioning\nExpertise and support to data scientists and engineers working on AI initiatives.\nCVs: s.allenby@enzotechgroup.com\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "R"
            ],
            "DataBase": [],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [
                "Databricks"
            ],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [
                "Azure"
            ],
            "DevTools": [],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [
                "Teams"
            ],
            "Other": [
                "ML",
                "Machine Learning"
            ],
            "FrSoftSkills": [],
            "EnSoftSkils": [
                "Initiative"
            ]
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "Data Scientist (M/W)",
        "company": "Mines Paris",
        "location": "Valbonne, Provence-Alpes-C\u00f4te d'Azur, France",
        "link": "https://fr.linkedin.com/jobs/view/data-scientist-m-w-at-mines-paris-3908686193?position=9&pageNum=2&refId=rHF5P6MO3jZ6rW9i1nxesw%3D%3D&trackingId=EMZLNREChwrZgbUttdSvLg%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "\u00c0 propos de nous\nMines Paris est une des plus prestigieuses \u00e9coles d'ing\u00e9nieurs en France. Mines Paris est un \u00e9tablissement public qui forme des ing\u00e9nieurs g\u00e9n\u00e9ralistes via une exp\u00e9rience p\u00e9dagogique innovante et pluridisciplinaire (sciences de l'ing\u00e9nieur et sciences humaines et sociales). Son appartenance \u00e0 l'Universit\u00e9 PSL, qui se positionne dans le top 50 des classements internationaux, constitue une v\u00e9ritable opportunit\u00e9 d'enrichissement des parcours.\nMission\nYour Environment\nAs part of the scientific program of The Transition Institute 1.5 (TTI.5), which focuses on the conditions for the emergence of a transition to a low-carbon planet, taking into account technical, social, economic, political and geopolitical issues, Mines Paris - PSL has an opening for a Data Scientist.\nInsofar as these issues may represent obstacles to the transition, it is essential to understand their fundamentals and decipher the mechanisms that drive them. The TTI.5 scientific program has been designed to harmonize, enhance and extend the various research projects already on offer at Mines Paris - PSL. It is also intended to provide new impetus in areas that have been little addressed until now, but which are nonetheless essential to steering the transition, or to filling gaps such as that of a complete vision of the distribution of resources worldwide.\nYour Challenges And Responsabilities\nIn order to tackle the various transition strategies, it is essential to have a picture of the production of the various raw materials needed for today's and tomorrow's world. At the same time, the exploitation and circulation of different resources can be strongly impacted by geopolitical conditions and times of tension and conflict.\nThe aim of this project, with its high methodological stakes, is to develop and couple:\nglobal resource mapping for two critical \"identifiable\" resources (lithium and cobalt)\na mapping of armed tensions (conflicts, installation of military bases, etc.).\nTo achieve this, we will need to develop a tool for extracting data from a very large mass of information, to be identified, in a changing context that will need to be taken into account for the tool's sustainability.\nThe Development Prospects For This Work Could Include\na double cartography animated over time ;\nthe enrichment of military base and tension indicators, with an equal focus on cases of local armed non-tension around the resource\na scalable database that can be continuously updated\na tool that can be replicated for other resources in a rapidly changing world\nProfil\nLet's talk about you !...\nThe position is aimed at an engineer / master data scientist with a degree from a university or Grande Ecole. Additional skills in GIS would be a plus. He/she may receive in-house training on mining resource issues.\nThe candidate will be strongly encouraged to participate in TTI.5 activities, and may also take part in those of the referral centers. He/she must have demonstrated good teamwork skills.\nFluency in spoken and written English is imperative.\nKnowledge And Skills\nThe main skills required for this post are :\nMastery of algorithms and programming languages (ability to write efficient, scalable code)\nMastery of data management language and databases (ability to find, collect and analyze large volumes of data)\nMastery of data visualization tools\nSoft Skills\nSelf-motivated\nSpirit of initiative\nSense of teamwork\ncreativity\nFlexibility\nCommunication and teaching skills\nAnalytical skills\nThoroughness\n\u2026And about us ! Working at Mines Paris also means :\nJoining a prestigious institution with a rich history\nPlaying a part in the digital transition and the transition to carbon neutrality to tackle the climate emergency\nBelonging to PSL University, ranked 41st in the Academic Ranking of World Universities\nJoin a dynamic, multidisciplinary team!\nA pleasant living environment in a pine forest, at the heart of the 1st technology cluster on the C\u00f4te d'Azur and 1st technology park in Europe!\nR\u00e9f\u00e9rence de l'offre : 6jpx490r88\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Scala",
                "R",
                "Go"
            ],
            "DataBase": [],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [],
            "DevTools": [
                "Git"
            ],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [],
            "FrSoftSkills": [
                "Communication"
            ],
            "EnSoftSkils": [
                "Communication",
                "Teamwork",
                "Creativity",
                "Flexibility",
                "Initiative"
            ]
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "Data Scientist (H/F) \u2013 Digital Factory",
        "company": "TNP Consultants",
        "location": "Paris, \u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/data-scientist-h-f-%E2%80%93-digital-factory-at-tnp-consultants-3591227915?position=10&pageNum=2&refId=rHF5P6MO3jZ6rW9i1nxesw%3D%3D&trackingId=V2tY27%2FEbdHiFLr47YCFQw%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Pr\u00e9sentation de TNP Consultants\nFort de 450 collaborateurs, TNP est un cabinet de conseil ind\u00e9pendant multi-sp\u00e9cialiste et multisectoriel, pr\u00e9sent en France, au Maroc, au Luxembourg, en Suisse et en Inde. Acc\u00e9l\u00e9rateur de performance, nous intervenons dans la mise en place de programmes de transformation sur les probl\u00e9matiques r\u00e9glementaires, excellence op\u00e9rationnelle, digital et business solutions dans les secteurs banque, assurance & protection sociale, le secteur public et industrie & services.\nCette ann\u00e9e, TNP recrute 200 collaborateurs ! Pour accompagner nos clients dans le cadre de leur transformation digitale, nous recherchons des consultants Data Scientists (H/F).\nVOTRE R\u00d4LE AU SEIN DE L\u2019\u00c9QUIPE DATA SCIENTIST\nAu Sein De La DIGITAL FACTORY, Vous Participerez Au D\u00e9veloppement Des Activit\u00e9s Data Science. Vous Serez Notamment En Charge\nD\u2019aider nos clients \u00e0 d\u00e9finir les use cases m\u00e9tiers et proposer des d\u00e9marches d\u2019\u00e9tudes adapt\u00e9es aux contextes et aux enjeux m\u00e9tiers ;\nDe mod\u00e9liser des ph\u00e9nom\u00e8nes et restituer des analyses \u00e0 l\u2019usage des m\u00e9tiers (Data Visualisation) ;\nDe prototyper des outils d\u2019analyse ou de pr\u00e9diction utilisables par les m\u00e9tiers ;\nDe former et accompagner les m\u00e9tiers dans l\u2019utilisation de ces outils ;\nAccompagner des mont\u00e9es en comp\u00e9tences d\u2019autres Data Scientists.\nDe mettre en production les mod\u00e8les et Dashboard d\u00e9velopp\u00e9s dans un outil de cloud.\nVOTRE PROFIL\nVous \u00eates dipl\u00f4m\u00e9s d\u2019une \u00e9cole d\u2019ing\u00e9nieur ou d\u2019un master 2 en Math\u00e9matiques, informatiques et/ou statistiques. Vous justifiez d\u2019au moins 4 ann\u00e9es d\u2019exp\u00e9rience au sein d\u2019un cabinet de conseil.\nComp\u00e9tences techniques requises\nVous maitrisez la programmation en Python/R.\nVous avez un excellent niveau en statistique.\nVous avez des connaissances th\u00e9oriques et pratiques dans la mod\u00e9lisation en Machine Learning et Deep Learning (Mod\u00e8les d\u2019agr\u00e9gation, R\u00e9seaux de neurone)\nVous avez d\u00e9j\u00e0 utilis\u00e9 au moins une solution cloud comme AWS /Azure.\nGestion des codes : Git, Bitbucket\nVous disposez d\u2019un bon niveau d\u2019anglais.\nSoft Skills\nPassionn\u00e9 par la data et l\u2019IA\nEsprit de synth\u00e8se et d\u2019analyse\nRigoureux pour assurer une qualit\u00e9 de livrables et didactique pour pr\u00e9senter les sujets aux m\u00e9tiers\nSens de l\u2019\u00e9coute et de la communication\nSavoir travailler en \u00e9quipe\nCurieux et cr\u00e9atif\nUn \u00e9tat d\u2019esprit orient\u00e9 business et apport de valeur pour les \u00e9quipes m\u00e9tiers ;\nCoach\u00e9(e) tout au long de votre carri\u00e8re, vous b\u00e9n\u00e9ficierez d\u2019une formation continue, pour enrichir votre expertise et accompagner votre d\u00e9veloppement personnel. En \u00e9troite collaboration avec les Associ\u00e9s, vous \u00e9voluerez dans un cabinet ind\u00e9pendant en forte croissance et intervenant aupr\u00e8s des grands comptes en France et \u00e0 l\u2019international.\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "R",
                "Go"
            ],
            "DataBase": [],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [
                "Statistiques"
            ],
            "CloudComputing": [
                "AWS",
                "Azure"
            ],
            "DevTools": [
                "Git"
            ],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [
                "Machine Learning",
                "Statistiques",
                "Cloud"
            ],
            "FrSoftSkills": [
                "Communication",
                "Collaboration"
            ],
            "EnSoftSkils": [
                "Communication",
                "Collaboration"
            ]
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "Machine Learning Engineer",
        "company": "TEC Partners - Technical Recruitment Specialists",
        "location": "Paris, \u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/machine-learning-engineer-at-tec-partners-technical-recruitment-specialists-3890985195?position=1&pageNum=5&refId=cgEkFyElpsEmkUEI1JEAcQ%3D%3D&trackingId=Q7FExlMmd3Bkvpz40%2Fiz7Q%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Role Overview:\nAs a Senior Machine Learning Engineer, you will play a crucial role in the development and deployment of AI models to enhance creativity processes for our users. From curating data to training and validating models, you will have end-to-end ownership of your work. You will collaborate closely with cross-functional teams, share your expertise on AI, and participate in strategic decisions concerning our tech stack.\nResponsibilities:\nDevelop and deploy machine learning models tailored to user needs.\nOwn the entire process from data preprocessing to model deployment (MLOps).\nCollaborate with cross-functional teams on strategic decisions regarding the tech stack.\nShare knowledge and expertise on AI with the team.\nWork closely with users to understand their needs and improve product features.\nRequirements:\n5+ years of experience in machine learning, ideally in an early-stage startup environment.\nProven experience in training and deploying machine learning models for products.\nFamiliarity with data preprocessing pipelines and MLOps.\nWillingness to work with new technologies and parts of the stack.\nAbility to thrive in a fast-paced environment.\nPhD in computer science, machine learning, or related field preferred.\nFluent in English; proficiency in French is a plus.\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "R"
            ],
            "DataBase": [],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [],
            "DevTools": [],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [
                "Teams"
            ],
            "Other": [
                "ML",
                "Machine Learning"
            ],
            "FrSoftSkills": [],
            "EnSoftSkils": [
                "Creativity"
            ]
        },
        "details": {
            "JobDetail": [
                "Senior"
            ],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "Data Scientist H/F",
        "company": "IT&M STATS",
        "location": "\u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/data-scientist-h-f-at-it-m-stats-3803674187?position=2&pageNum=5&refId=cgEkFyElpsEmkUEI1JEAcQ%3D%3D&trackingId=XDL7uwsLCW%2BV4hf4wl%2BQoA%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "IT&M Stats intervient dans le domaine des statistiques, de la programmation et de la data science, principalement dans les secteurs de l\u2019Industrie Pharmaceutique, Cosm\u00e9tique, dans la Sant\u00e9 et l\u2019Agro-alimentaire et aupr\u00e8s des Banques et Assurances. IT&M Stats est une filiale du Groupe Astek, acteur mondial de l\u2019ing\u00e9nierie et du conseil en technologies.\nNous basons notre relation sur :\nUn respect des collaborateurs et des clients, de leurs aspirations,\nUn suivi personnalis\u00e9 des collaborateurs et des clients,\nUne gestion r\u00e9guli\u00e8re des carri\u00e8res des collaborateurs,\nDes \u00e9changes transparents,\nUne r\u00e9activit\u00e9, une disponibilit\u00e9 et une \u00e9coute permanentes.\nNous recherchons un\nData Scientist\npour intervenir dans le secteur\ncosm\u00e9tique\n.\nCela vous int\u00e9resse ? Voici la suite !\n\ud83d\udc47\nMaintenance et mise \u00e0 jour de dashboards de suivi de tests sous PowerBi\nAnalyser les donn\u00e9es g\u00e9n\u00e9r\u00e9es en interne et externe et r\u00e9aliser des analyses crois\u00e9es /meta analyse pour une meilleure compr\u00e9hension de la performance de nos produits/services\nR\u00e9aliser des analyses pr\u00e9dictives de la performance cosm\u00e9tique en fonction de la formulation\nR\u00e9aliser des interfaces dynamiques sous R Shiny\nR\u00e9-analyser et v\u00e9rifier les analyses statistiques r\u00e9alis\u00e9es par les prestataires externes le cas \u00e9ch\u00e9ant\nContribuer \u00e0 la mise en place des \u00e9tudes et aider le d\u00e9partement \u00e0 l\u2019am\u00e9lioration des process (Plan d\u2019exp\u00e9rience, calcul du nombre de sujets n\u00e9cessaires, etc\u2026)\nVous pensez \u00eatre la perle rare ?\nVous \u00eates titulaire d\u2019un dipl\u00f4me de type Bac+5 (Master 2 ou \u00e9cole d\u2019ing\u00e9nieur) avec une sp\u00e9cialisation en statistiques, math\u00e9matiques ou data science\nVous justifiez d\u2019une exp\u00e9rience professionnelle de 2 \u00e0 3 ans\nUne bonne maitrise de R (dont R Shiny) est attendue\nVous maitrisez PowerBI\nVous \u00eates organis\u00e9, rigoureux, autonome, flexible, vous aimez communiquer et travailler en \u00e9quipe et vous avez un bon esprit de synth\u00e8se et d\u2019analyse\nVous avez un bon niveau d\u2019anglais\n\ud83c\udf40\nVoici ce que nous pouvons vous offrir\u2026\nUn poste en CDI \u00e0 pourvoir d\u00e8s que possible, de la bonne humeur, des formations, des soir\u00e9es, de la bienveillance, un suivi personnalis\u00e9, une gestion r\u00e9guli\u00e8re de votre carri\u00e8re, des \u00e9changes transparents et une \u00e9coute permanente.\nSi vous \u00eates convaincu que vous \u00eates la perle rare, postulez ! Nous sommes impatients de vous rencontrer.\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "R",
                " R ",
                "Go"
            ],
            "DataBase": [],
            "DataAnalytics": [
                "R",
                " R "
            ],
            "BigData": [],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [
                "PowerBI"
            ],
            "Statistics": [
                "Statistiques"
            ],
            "CloudComputing": [],
            "DevTools": [],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [
                "Statistiques"
            ],
            "FrSoftSkills": [],
            "EnSoftSkils": []
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [
                "CDI"
            ],
            "Salary": [],
            "Level": [
                "Bac+5"
            ],
            "Experience": [
                "a",
                "n",
                "s",
                "3",
                "3",
                "3"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "Machine Learning Researcher",
        "company": "Finegrain",
        "location": "Paris, \u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/machine-learning-researcher-at-finegrain-3773290571?position=3&pageNum=5&refId=cgEkFyElpsEmkUEI1JEAcQ%3D%3D&trackingId=Rl4P%2Bj9txAKz3mCjRXs%2FPQ%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "**Our mission**\nAt Finegrain, we believe the Internet deserves better images, and we're building the ultimate GenAI platform to make it happen - at massive scale.\n**Our unfair advantage**\nOur founders are repeat entrepreneurs who sold their first AI company to Google, and we are backed by a stellar and worldwide team of investors.\n**Meet Refiners**\nUnder the hoods, Finegrain relies on a breakthrough micro framework for foundation model adaptation called Refiners. We're building it in the open (MIT license), on top of our beloved PyTorch.\n**Your mission**\nJoin us as a Machine Learning Research Engineer to help extend the capabilities of the Refiners framework, and train breakthrough adapters with it!\n**Skills**\nWe're looking for folks who:\n1. love PyTorch\n2. know visual foundation models like Stable Diffusion, SAM, BLIP-2 inside out\n3. enjoy keeping track of the latest innovations on arXiv\n**Why join us?**\n1. You'll be part of our founding team.\n2. You'll work at Station F, the world's largest startup campus.\n3. You'll rub shoulders with some of the sharpest minds in AI.\n4. You'll help shape a product set to break new ground.\n5. You'll work on real, impactful AI. No fluff.\n**Process**\nIt all starts with taking a look at our bounty program: just pick one, and show us what you got. If you complete it, you'll get paid!\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "R",
                "Go"
            ],
            "DataBase": [],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [],
            "MachingLearning": [
                "PyTorch"
            ],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [],
            "DevTools": [],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [
                "Machine Learning"
            ],
            "FrSoftSkills": [],
            "EnSoftSkils": []
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "Data Scientist @ start-up",
        "company": "Licorne Society",
        "location": "Paris, \u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/data-scientist-%40-start-up-at-licorne-society-3918084326?position=4&pageNum=5&refId=cgEkFyElpsEmkUEI1JEAcQ%3D%3D&trackingId=0UrsO6t5%2BraykIZC05woNQ%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Licorne Society est \u00e0 la recherche de Data Scientist pour des startups innovantes, ne laisse pas passer ta chance !\nC\u2019est quoi Licorne Society ?\nLicorne Society est le seul outil qui te met en relation avec plus de 3000 startups recrutant en France, tous secteurs et m\u00e9tiers confondus. Qu\u2019elles soient en cr\u00e9ation ou en phase d\u2019hypercroissance, toutes les startups t\u2019attendent sur Licorne Society. Ah oui, et c\u2019est gratuit !\nNotre promesse : faire matcher ta recherche avec les meilleures opportunit\u00e9s et mettre en avant ton profil aupr\u00e8s des startups qui recrutent.\n>> www.licornesociety.com <<\nL'inscription Prend Moins De 10 Minutes. Tu Pourras Alors Acc\u00e9der \u00e0 L'ensemble Des Offres En Startup Du March\u00e9 Et \u00catre Contact\u00e9 Directement Par Les Recruteurs\n1 - Remplis ton profil et tes attentes.\n2 - Passe en revue les offres que nous te proposons en fonction de tes crit\u00e8res de recherche et re\u00e7ois une notification \u00e0 chaque nouvelle offre publi\u00e9e. Avec notre mode Tinder, tu n\u2019as qu\u2019\u00e0 swiper les offres. Matcher avec le job de tes r\u00eaves n\u2019a jamais \u00e9t\u00e9 aussi simple !\n3 - Re\u00e7ois des sollicitations directes pour des postes de Data Scientist au sein de nos startups pr\u00e9f\u00e9r\u00e9es (pour ne citer que BackMarket, PlayPlay, Payfit, Trustpair ou encore Choco)\nProfil Recherch\u00e9\nTu as une premi\u00e8re exp\u00e9rience de Data Scientist et tu es tr\u00e8s motiv\u00e9 pour rejoindre une start-up / scale-up ou tu es pr\u00eat \u00e0 d\u00e9crocher ton tout premier job\nTu as la fibre entrepreneuriale\nTu as soif de challenge et de nouveaux apprentissages\nTu es pr\u00eat \u00e0 cliquer sur le lien d\u2019inscription : www.licornesociety.com\nLes parcours particuli\u00e8rement valoris\u00e9s chez Licorne Society :\ndes exemples de prises d\u2019initiatives ou projets men\u00e9s avec l\u2019esprit entrepreneurial\ndes exp\u00e9riences dans des environnements particuli\u00e8rement exigeants\ndes exemples de r\u00e9alisations \u00e9difiants ou r\u00e9sultats chiffr\u00e9s\nOn se dit \u00e0 tout de suite sur la plateforme ?\n>> www.licornesociety.com <<\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "R"
            ],
            "DataBase": [],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [],
            "DevTools": [],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [],
            "FrSoftSkills": [],
            "EnSoftSkils": [
                "Initiative"
            ]
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "Data Scientist Traitement du Langage Naturel H/F (H/F)",
        "company": "Acelys Services Num\u00e9riques",
        "location": "Montpellier, Occitanie, France",
        "link": "https://fr.linkedin.com/jobs/view/data-scientist-traitement-du-langage-naturel-h-f-h-f-at-acelys-services-num%C3%A9riques-3906686343?position=5&pageNum=5&refId=cgEkFyElpsEmkUEI1JEAcQ%3D%3D&trackingId=uLK7I3gBnC%2Fvr8WC5zSMrA%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Cette offre d\u2019emploi est fournie par P\u00f4le emploi\nDescription\nCr\u00e9\u00e9e en 1997, Acelys Services Num\u00e9riques est la 1\u00e8re DFS (Digital Factory Services) de la R\u00e9gion qui propose \u00e0 ses clients des services industrialis\u00e9s de d\u00e9veloppement et d'int\u00e9gration \u00e0 haute valeur ajout\u00e9e de solutions num\u00e9riques. En particulier sur les domaines : - Du d\u00e9veloppement logiciel & mobile ; - De la Business Intelligence & la Data Science ; - De l'int\u00e9gration des solutions de d\u00e9mat\u00e9rialisation ; - De la cybers\u00e9curit\u00e9 et des infrastructures - De l'innovation R&D et l'\u00e9dition de logiciels. Depuis 2017, Acelys confirme sa ma\u00eetrise de la s\u00e9curit\u00e9 de son syst\u00e8me de management de la s\u00e9curit\u00e9 de l'information avec la certification ISO 27001 ! Bas\u00e9 \u00e0 Montpellier, au sein du dynamique P\u00f4le Eureka, notre centre abrite pr\u00e8s de 70% de nos collaborateurs. Notre histoire solide, notre ind\u00e9pendance, et notre pr\u00e9sence r\u00e9gionale font de nous un pilier de l'innovation num\u00e9rique ! Avec une \u00e9quipe de plus de 200 professionnels passionn\u00e9s, Acelys favorise la croissance et le d\u00e9veloppement de chacun. Nous encourageons la promotion interne et offrons un environnement propice \u00e0 l'acquisition de nouvelles comp\u00e9tences. Rejoignez-nous d\u00e8s aujourd'hui pour faire partie d'une \u00e9quipe dynamique et contribuer \u00e0 fa\u00e7onner l'avenir num\u00e9rique avec nous ! Description du poste : Acelys recherche un.e Data Scientist exp\u00e9riment\u00e9 en IA et NLP pour rejoindre notre \u00e9quipe dynamique au sein du p\u00f4le de R&D/IA d'une quinzaine de talents. Notre p\u00f4le R&D, expert dans le traitement du langage naturel (p\u00f4le Edition) m\u00e8ne depuis 10 ans des travaux en \u00e9troite collaboration avec des laboratoires de recherche sur des probl\u00e9matiques technologiques. Vous travaillerez en lien avec les chercheurs, ing\u00e9nieurs et autres experts en utilisant des techniques d'apprentissage automatique et de traitement du langage naturel pour r\u00e9soudre des probl\u00e8mes complexes, tels que la recherche documentaire, la similarit\u00e9 s\u00e9mantique, la classification... Profil recherch\u00e9 : - Vous \u00eates dipl\u00f4m\u00e9.e en informatique, en sciences des donn\u00e9es ou dans un domaine connexe - Vous disposez de solides comp\u00e9tences en programmation (Python, TensorFlow, PyTorch, etc.) - Vous avez connaissance des techniques d'apprentissage automatique et du traitement automatique du langage naturel - Vous \u00eates exp\u00e9riment\u00e9.e sur les pratiques CI/CD (int\u00e9gration continue et d\u00e9ploiement continu) - Une exp\u00e9rience sur les Frameworks Python est appr\u00e9ci\u00e9e : Langchain, Django/Flask,Transformers Avantages : - Salaire comp\u00e9titif et avantages sociaux : Carte Swile, pr\u00e9voyance Cadre, RTT, Plan Epargne Entreprise avec abondements, t\u00e9l\u00e9travail et un accord de participation tr\u00e8s avantageux (1,5 mois de salaire ces derni\u00e8res ann\u00e9es en moyenne) - Environnement de travail collaboratif et stimulant - Contribution \u00e0 des projets innovants Acelys Services Num\u00e9riques c'est plus de 25 ans d'histoire, \u00e9crivons la suite ensemble !\nPROFIL SOUHAIT\u00c9\nExp\u00e9rience\n18 Mois\nSavoirs et savoir-faire\nAdapter les outils de traitement statistique de donn\u00e9es\nD\u00e9finir et faire \u00e9voluer des proc\u00e9d\u00e9s de traitement de l'information\nPr\u00e9senter et diffuser les r\u00e9sultats des \u00e9tudes r\u00e9alis\u00e9es\nR\u00e9aliser une veille documentaire\nR\u00e9diger l'information produite\nSavoir-\u00eatre professionnels\nFaire preuve de rigueur et de pr\u00e9cision\nPrendre des initiatives et \u00eatre force de proposition\nTravailler en \u00e9quipe\nSource: Pole emploi (https://www.pole-emploi.fr)\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "R",
                "Go"
            ],
            "DataBase": [],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [],
            "MachingLearning": [
                "TensorFlow",
                "PyTorch"
            ],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [],
            "DevTools": [
                "Git"
            ],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [
                "CI/CD"
            ],
            "FrSoftSkills": [
                "Collaboration"
            ],
            "EnSoftSkils": [
                "Collaboration",
                "Initiative"
            ]
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [],
            "Salary": [
                "1,5"
            ],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s",
                "10",
                "10",
                "10"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "Data Scientist (confirm\u00e9/s\u00e9nior) - H/F - CDI",
        "company": "Talan",
        "location": "Paris, \u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/data-scientist-confirm%C3%A9-s%C3%A9nior-h-f-cdi-at-talan-3909648101?position=6&pageNum=5&refId=cgEkFyElpsEmkUEI1JEAcQ%3D%3D&trackingId=WZ1cTu0jbDdK3D8aTl3BIw%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Talan est un groupe international de conseil en transformation et en innovation par la technologie, cr\u00e9\u00e9 en 2002.\nNos 5000 consultantes et consultants partagent \u00e0 travers le monde l\u2019audace d\u2019innover, le go\u00fbt de l\u2019excellence, et l\u2019envie de relever les d\u00e9fis les plus complexes.\nNous accompagnons les entreprises dans des secteurs vari\u00e9s\u202f: \u00e9nergie, industrie, transport, finance, luxe\u2026 \u00e0 travers 3 grandes expertises\u202f:\nLe Conseil en Management et Innovation (320 Consultants en France)\nLa valorisation des donn\u00e9es, leurs structurations, et leurs usages (Data et Technologies)\nL\u2019int\u00e9gration de solutions logicielles (Cloud et Applications Services)\nNos valeurs\u202f: engagement, respect, partage, esprit d\u2019\u00e9quipe et optimisme.\nTalan est une entreprise responsable, reconnue par ses collaborateurs et attach\u00e9e \u00e0 la diversit\u00e9. Des am\u00e9nagements peuvent \u00eatre propos\u00e9s si vous \u00eates en situation de handicap.\nRetrouvez nos engagements RSEiciet nos actions en faveur de la diversit\u00e9ici\nJob Description\nNous sommes \u00e0 la recherche d\u2019un Data Scientist capable de participer \u00e0 des projets techniques Data Science et IA. Vous devrez faire preuve d\u2019un \u00e9tat d\u2019esprit \u00e0 la fois innovant, m\u00e9thodique, orient\u00e9 solution (et non probl\u00e8me!), et communiquant.\nVotre but ultime sera de garantir l\u2019excellence de vos solutions Data Science/IA, pi\u00e8ces maitresses de la r\u00e9alisation de projets disruptifs pour nos clients.\nVOTRE ROLE SUR NOS PROJETS\n:\nEn mission: analyse des besoins m\u00e9tiers, d\u00e9finition des principes et m\u00e9thodes de collecte et de traitement des donn\u00e9es, choix des mod\u00e8les de Machine Learning ou de Deep Learning, mise en application des techniques de traitement et de visualisation de la data, restitution des analyses et r\u00e9sultats obtenus aupr\u00e8s des m\u00e9tiers et des sponsors\nPartager techniquement les membres de l\u2019\u00e9quipe: solutions et code reviews, recommandations, certifications \u00e0 r\u00e9aliser, \u2026\nParticipation \u00e0 des meet-up, coding dogo,\u2026\nCommunication: \u00e9criture d\u2019articles, retours d\u2019exp\u00e9rience\u2026\nVOTRE ROLE CHEZ TALAN :\nBenchmark de solutions et conseil aupr\u00e8s de nos clients sur les solutions technologiques \u00e0 adopter, en lien avec leurs besoins\nR\u00e9alisation de POC (Proof Of Concept)\nParticipation \u00e0 des projets internes et partage de connaissances au sein de nos \u00e9quipes.\nPartage de connaissances et formations interne\nQualifications\nVOTRE PROFIL:\nIssu d\u2019une formation Grande \u00c9cole d\u2019Ing\u00e9nieur/Doctorant, sp\u00e9cialis\u00e9e en Data Science ou Intelligence Artificielle\nVous disposez d\u2019au moins 3 ann\u00e9es d\u2019exp\u00e9rience dans le domaine\nMaitrise des techniques d\u2019analyses statistiques, de mod\u00e9lisations pr\u00e9dictives, de Machine Learning, de Deep Learning,...\nMaitrise des techniques de data management et de DataViz\nMaitrise de Python, R, RShiny, SQL\u2026\nMaitrise de l\u2019utilisation des outils DevOps: Git, Docker, Jenkins/Nexus,\u2026\nBonnes connaissances Big Data: pySpark, Spark, NoSQL\u2026\nConnaissance d\u2019outils tels que Dataiku, AWS SageMaker, Azure ML,\u2026\nAutonomie, organisation, sens du partage\nExcellente communication\nOrientation m\u00e9tier\nAdditional Information\nAVANTAGES\n:\nPlan de formation pour accompagner votre carri\u00e8re (formations \u00e9diteurs, certifications) gr\u00e2ce \u00e0 nos partenariats nous accordant une position de partenaire privil\u00e9gi\u00e9, et management de proximit\u00e9 par des experts\nLocaux modernes en centre-ville\nTop 5 du Palmar\u00e8s Great Place to Work\nT\u00e9l\u00e9travail jusqu\u2019\u00e0 5 jours selon les missions, prime d\u2019\u00e9quipement de 100\u20ac\nMobilit\u00e9 en France et \u00e0 l\u2019\u00e9tranger\nTop 1% des entreprises \u00e9valu\u00e9es par Ecovadis dans le domaine social, environnemental et \u00e9thique\nTickets restaurant, prime vacances, 50% transport (abonnement transport public), mutuelle\nPermanence handicap (consultant d\u00e9di\u00e9 aux collaborateurs en situation de handicap et aux proches aidants)\nActionnariat salari\u00e9\nPrime de cooptations\nRTT\nPROCESS RECRUTEMENT\n:\nL\u2019\u00e9quipe recrutement s\u2019engage \u00e0 vous proposer un processus de recrutement rapide et fluide\n1 entretien RHpar Teams (45min)\n1 test technique\n1 entretien op\u00e9rationnel avec le responsable de domaine, au si\u00e8ge (1heure)\n1 entretien avec le directeur de p\u00f4le, au si\u00e8ge(1heure)\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "R",
                "Go"
            ],
            "DataBase": [
                "SQL",
                "NoSQL"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [
                "Spark"
            ],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [
                "Statistiques"
            ],
            "CloudComputing": [
                "AWS",
                "Azure"
            ],
            "DevTools": [
                "Git",
                "Docker",
                "Jenkins"
            ],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [
                "Docker"
            ],
            "Collaboration": [
                "Teams"
            ],
            "Other": [
                "DevOps",
                "Big Data",
                "ML",
                "Machine Learning",
                "Statistiques",
                "Cloud"
            ],
            "FrSoftSkills": [
                "Communication",
                "Organisation"
            ],
            "EnSoftSkils": [
                "Communication"
            ]
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "Data Scientist",
        "company": "Enzo Tech Group",
        "location": "\u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/data-scientist-at-enzo-tech-group-3914681877?position=7&pageNum=5&refId=cgEkFyElpsEmkUEI1JEAcQ%3D%3D&trackingId=Tdq7G83TDv5xt6M%2FLD03Og%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Role:\nData Scientist\nLocation:\nParis (3 days) / Remote (2 days)\nSearching for a\nData Scientist\npartnering with a global customer who are searching for multiple Data Scientist's as they continue to invest in designing and building high-quality AI solutions.\nResponsibilities\nAnalyze raw data: assessing quality, cleansing, structuring for downstream processing\nDesign accurate and scalable prediction algorithms\nCollaborate with engineering team to bring analytical prototypes to production\nGenerate actionable insights for business improvements\nQualifications\nBachelor's degree or equivalent experience in quantative field (Statistics, Mathematics, Computer Science, Engineering, etc.)\nTech Stack: GenAI, Databricks, Azure\nAt least 1 - 2 years' of experience in quantitative analytics or data modelling\nDeep understanding of predictive modelling, machine-learning, clustering and classification techniques, and algorithms\nFluency in a programming language (Python, C,C++, Java, SQL)\nCVs:\nApply via job post or directly\n@\nk.downs@enzotechgroup.com\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "Java",
                "C++",
                "Scala",
                "R",
                "Go"
            ],
            "DataBase": [
                "SQL"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [
                "Databricks"
            ],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [
                "Statistics"
            ],
            "CloudComputing": [
                "Azure"
            ],
            "DevTools": [],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [],
            "FrSoftSkills": [],
            "EnSoftSkils": []
        },
        "details": {
            "JobDetail": [
                "Remote"
            ],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "Senior Machine Learning Engineer",
        "company": "Homa",
        "location": "Paris, \u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/senior-machine-learning-engineer-at-homa-3911467922?position=8&pageNum=5&refId=cgEkFyElpsEmkUEI1JEAcQ%3D%3D&trackingId=t3LVA3N7PzxT2Pe1Yn5%2Biw%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Welcome to Homa, the gaming technology lab that is taking the industry by storm! Our team of over 200 people, hailing from more than 35 different countries, is dedicated to empowering mobile game creators worldwide to bring their creative ideas to the top charts.\nOur Homa Lab platform offers a comprehensive suite of cutting-edge tools that allow developers to stay on top of the latest trends, test new features in real-time, and easily distribute and monetize their games. Our success speaks for itself - our apps have been downloaded over 1 billion times!\nSince our inception, we have raised $165 million in total from prominent investors, including Headline, Northzone, Eurazeo, Singular, Quadrille Capital, Fabric Ventures, and Bpifrance. We have also received support from renowned business angels, such as the founders of King, Sorare and Spotify founders.\nBut what really makes Homa special is our team. We are a diverse group of artists, business developers, engineers, entrepreneurs, and former strategy consultants who all share the same passion for taking over the gaming industry. When you become part of Homa, you'll be joining a dedicated team that creates innovative and high-performing games that resonate with players worldwide.\nIf you're ready to take your career to the next level and make a real impact in the company, then Homa is the perfect place for you. Join us and let's create the future of gaming together!\nMeet the team\n\ud83d\udc69\u200d\ud83d\udc69\u200d\ud83d\udc67\u200d\ud83d\udc67\nYou will join the Data department organized into:\nA Data Platform team with 5 Data Engineers responsible for ingesting large amounts of data from multiple different sources, creating and maintaining a core data model which aims at making data standardized, reliable and easily available\nA Data Science and ML Platform team with 6 Data Scientists / ML Engineer working on ML-driven data products: Autobidder for User Acquisition, N-Testing for experimentation\nAn Advanced Analytics & Data Science team with 6 Data Analysts and Scientists exploiting our data for:\nGame Analytics\nUser Acquisition and Marketing Analytics\nMarket Inteligence Analytics\nOps Analytics\nRole and Missions \u2014 What you will do\n\ud83d\ude80\nWe are looking for a Senior Machine Learning Engineer to join the team in order to scale and industrialize Machine Learning & AI at Homa. Under the responsibility of our Associate Director, your responsibilities will be the following:\nLead ML Projects: Spearhead development and implementation of ML models for Marketing Tech (User Acquisition, Monetization) and Game Tech (Bayesian A/B Testing, Segmentation)\nML Industrialization & Democratization: Enhance ML engineering processes, adopt ML Ops tools, and contribute to model interpretability and collaborative efforts\nImplement Scalable ML Solutions: Build Serving APIs for handling millions of requests daily with low latency\nCollaborative Innovation: Work closely with diverse teams, leveraging GenAI tools for productivity and product improvements\nStay Updated: Integrate latest ML technologies and advancements into our tech stack\nCurrent Tech Stack: AWS, Redshift, Databricks, Python, DBT, Spark, Airflow, Kafka, Kubernetes, LightGBM, MLFlow, Metabase\nRequirements\nIf you're creative, ambitious, and up for taking over the industry, we want you on our team! We are also looking for:\nExtensive ML Experience: 5+ years in implementing and deploying ML models to production\nKey Technology Proficiency: Expertise in Neural Networks (TensorFlow / PyTorch), Gradient Boosting libraries (LightGBM / XGBoost), and at least one top Cloud provider (GCP, Azure, AWS)\nMLOps Skills: Experience with ML Ops tools like MLFlow\nAPI Development Expertise: Proven ability in building high-performance Serving APIs\nCollaborative Skills: Excellent communication and teamwork abilities\nInnovative Mindset: Passion for staying ahead in ML trends and technologies\nLanguage Skills: Fluent English is mandatory (interviews will be led in English)\nOur Culture\u2014Who we are\n\ud83e\ude90\nAt Homa, we are building a community of brilliant talents. We believe that true innovation comes from diversity and collaboration, and that's why we prioritize brainpower and determination over formal education. So if you have the talent, energy and motivation, there is no obstacle to your success here.\nAs the creative experts behind the platform, we provide developers with the data they need to bring their ideas to life. Our team lives by three central values that guide everything we do:\n\u2728\nAmbition\n: we're not afraid to tackle difficult challenges and set our goals extremely high. We're on a mission to revolutionize an industry dominated by well-established companies, and we won't stop until we succeed.\n\u2728\nHumility\n: we leave our pride & ego aside. We are always ready to lend a helping hand, celebrate each other's successes, and learn from our failures. As Mr. Lamar said, \"Sit down. Be humble.\"\n\u2728\nCuriosity\n: we keep our minds open and never stop learning. We believe that questioning everything is the best way to stay ahead of the curve, and we encourage all our team members to stay curious and never stop exploring new ideas.\nAt Homa, you'll be challenged, supported, and inspired every day, and we can't wait to see what you bring to the table.\nBenefits\nWhile success is its own reward, here are some of the benefits that come with working at Homa:\nWe offer essential benefits in France and specific locations, including health insurance, meal vouchers, public transport subsidies, childcare benefits, and life insurance\nIf you're interested in working from our newly renovated Paris HQ with a rooftop garden and WeWork amenities, we have a desk waiting for you\nYou will be working in English with our international team of top-tier talents from 35+ countries\nYou will have bi-annual reviews with your manager to reflect on your performance, celebrate wins, and receive constructive feedback\nYou will be able to attend diverse team events and Workations (the famous company-wide Homa trip)\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "Scala",
                "R",
                "Go"
            ],
            "DataBase": [],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [
                "Spark",
                "Databricks"
            ],
            "MachingLearning": [
                "TensorFlow",
                "PyTorch",
                "XGBoost",
                "LightGBM"
            ],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [
                "AWS",
                "Azure"
            ],
            "DevTools": [],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [
                "Kubernetes",
                "Airflow"
            ],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [
                "Kubernetes"
            ],
            "Collaboration": [
                "Teams"
            ],
            "Other": [
                "ML",
                "Machine Learning",
                "Cloud"
            ],
            "FrSoftSkills": [
                "Communication",
                "Collaboration"
            ],
            "EnSoftSkils": [
                "Communication",
                "Teamwork",
                "Collaboration"
            ]
        },
        "details": {
            "JobDetail": [
                "Senior"
            ],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "Software Engineer",
        "company": "BrainChip",
        "location": "Toulouse, Occitanie, France",
        "link": "https://fr.linkedin.com/jobs/view/software-engineer-at-brainchip-3902556694?position=9&pageNum=5&refId=cgEkFyElpsEmkUEI1JEAcQ%3D%3D&trackingId=j%2Fdb36RHk%2FOPvl8xBCyrhQ%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Brainchip is a leading technology company specializing in the design of electronics IP that accelerates AI on the edge. Our innovative solutions enable ultra-efficient and high-performance neural network processing for artificial intelligence applications. As part of our continuous growth, we are seeking a skilled Software Engineer with expertise in machine learning frameworks to join our team.\nResponsibilities:\nCollaborate with cross-functional teams to design, develop, and deploy machine learning models and algorithms for our products.\nImplement and optimize machine learning frameworks such as Tensorflow/Keras, PyTorch, and ONNX.\nDevelop software tools and infrastructure to support machine learning workflows, data preprocessing, model training, and evaluation.\nStay up-to-date with the latest advancements in machine learning and apply relevant techniques to enhance our products.\nConduct code reviews, provide constructive feedback, and maintain code quality and documentation.\nRequirements:\nBachelor's or Master's degree in Computer Science, Engineering, or a related field.\nStrong proficiency in machine learning frameworks such as Tensorflow/Keras, PyTorch, and ONNX.\nDemonstrated experience in developing and deploying machine learning models and algorithms.\nSolid understanding of deep learning concepts, neural networks, and related architectures.\nProficiency in programming languages such as Python, or C++.\nExperience with data preprocessing, feature engineering, and data visualization techniques.\nKnowledge of software engineering best practices, including version control, testing, and code documentation.\nStrong problem-solving skills and ability to work in a fast-paced, collaborative environment.\nExcellent communication skills and ability to effectively articulate technical concepts to both technical and non-technical team members.\nPreferred Qualifications:\nUnderstanding of computer vision or natural language processing (NLP) concepts and applications.\nExperience with deployment and optimization of machine learning models on edge devices.\nActive participation in the machine learning community, such as publications or open-source contributions.\nBenefits:\nCompetitive salary and comprehensive benefits package.\nOpportunities for professional growth and career advancement.\nCollaborative and inclusive work environment.\nFlexible work hours with the possibility to work remotely three days a week.\nAccess to cutting-edge technology and resources.\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "C++",
                "R",
                "Go"
            ],
            "DataBase": [],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [],
            "MachingLearning": [
                "TensorFlow",
                "Keras",
                "PyTorch"
            ],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [],
            "DevTools": [],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [
                "Teams"
            ],
            "Other": [
                "Machine Learning"
            ],
            "FrSoftSkills": [
                "Communication"
            ],
            "EnSoftSkils": [
                "Communication"
            ]
        },
        "details": {
            "JobDetail": [
                "Remote"
            ],
            "TypeContract": [],
            "Salary": [
                "Salary",
                "Package"
            ],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "Geospatial Data Scientist",
        "company": "EarthDaily Agro",
        "location": "Balma, Occitanie, France",
        "link": "https://fr.linkedin.com/jobs/view/geospatial-data-scientist-at-earthdaily-agro-3884744208?position=10&pageNum=5&refId=cgEkFyElpsEmkUEI1JEAcQ%3D%3D&trackingId=XW9RSjSOGZWnjKpXBeYXWg%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "STRUCTURE D\u2019ACCUEIL\nEarthDaily Agro fournit des donn\u00e9es et des analyses de l'\u00e8re spatiale aux organisations et aux personnes qui nourrissent la plan\u00e8te !\nAvec 35 ans d'exp\u00e9rience dans le secteur, EarthDaily Agro fournit \u00e0 ses clients les donn\u00e9es, les analyses et les connaissances dont ils ont besoin pour prendre des d\u00e9cisions plus efficaces. Les services B2B vont de la gestion globale des risques et du suivi des produits agricoles \u00e0 la commercialisation d'intrants et au conseil en agriculture de pr\u00e9cision, en utilisant les derni\u00e8res recherches en agronomie, en technologies de l'information et en t\u00e9l\u00e9d\u00e9tection.\nEarthDaily Agro d\u00e9veloppe \u00e9galement des solutions commerciales hautement personnalis\u00e9es pour les pr\u00eateurs agricoles, les assureurs, les fournisseurs d'intrants et les entreprises alimentaires, avec des analyses faciles \u00e0 utiliser, qui aident \u00e0 r\u00e9duire les risques quotidiens de l'agriculture.\nEarthDaily Agro, dont le si\u00e8ge social se trouve \u00e0 Minneapolis, MN, USA, et qui poss\u00e8de des bureaux en France, au Br\u00e9sil, en Australie et en Suisse, est une division de EarthDaily Analytics Corp.\nEarthDaily Analytics Corp, une soci\u00e9t\u00e9 de traitement et d'analyse de donn\u00e9es verticalement int\u00e9gr\u00e9e, lance une nouvelle constellation de satellites d'observation de la terre. La constellation de satellites EarthDaily am\u00e9liorera consid\u00e9rablement les capacit\u00e9s d'analyse g\u00e9ospatiale dans les secteurs de l'agriculture, de la sylviculture, de l'environnement, des services financiers et du renseignement, parmi de nombreux autres segments.\nRESPONSABILIT\u00c9S\nVous serez en charge de r\u00e9soudre des challenges li\u00e9s \u00e0 l\u2019agriculture en utilisant la t\u00e9l\u00e9d\u00e9tection, en particulier les images de la future constellation EarthDaily, et des donn\u00e9es m\u00e9t\u00e9o. Bas\u00e9 \u00e0 Balma, \u00e0 proximit\u00e9 de Toulouse, vous int\u00e9grerez une \u00e9quipe internationale avec des coll\u00e8gues au Br\u00e9sil et aux USA.\nVOS RESPONSABILIT\u00c9S INCLURONT :\nL\u2019agriculture fait face \u00e0 des challenges sans\u202fpr\u00e9c\u00e9dent\u202f: le changement climatique induit des risques accrus, et les agriculteurs doivent maintenir voire am\u00e9liorer leur productivit\u00e9 tout en r\u00e9duisant leur impact environnemental. Avec la future constellation EarthDaily (jusqu\u2019\u00e0 5 m de r\u00e9solution, revisite quotidienne avec 22 bandes spectrales du visible \u00e0 l\u2019infra-rouge thermique), EarthDaily Agro disposera d\u2019une technologie clef pour r\u00e9pondre \u00e0 ces probl\u00e9matiques.\u202fRejoignez EarthDaily Agro pour contribuer \u00e0 minimiser ces risques avec la technologie.\nEarthDaily Agro est \u00e0 la recherche d\u2019un.e\u202fData\u202fScientist en t\u00e9l\u00e9d\u00e9tection pour rejoindre\u202fson \u00e9quipe R&D et construire des analytiques \u00e0 valeur ajout\u00e9e \u00e0 destination de ses clients dans le monde agricole.\nVous mettez en place des solutions inventives pour r\u00e9pondre aux probl\u00e9matiques des clients, demandant des comp\u00e9tences fortes en analyse de donn\u00e9es et\u202fen\u202fmachine\u202flearning, dans un\u202fcontexte\u202fde larges volumes de donn\u00e9es et d\u2019une base existante de plus de 100 analytiques. Vous d\u00e9veloppez des\u202fPOCs\u202fet prototypes, d\u00e9finissez / testez / validez et sp\u00e9cifiez les algorithmes appropri\u00e9s. Vous \u00eates activement\u202fimpliqu\u00e9.e\u202fdans le design et la mise en place de la solution op\u00e9rationnelle sur notre plateforme Cloud.\nVos missions\u202f:\nComprendre les probl\u00e9matiques m\u00e9tier et les traduire en solution algorithmique bas\u00e9e sur les donn\u00e9es issues de la t\u00e9l\u00e9d\u00e9tection.\nCr\u00e9er et\u202fimpl\u00e9menter\u202fdes mod\u00e8les bas\u00e9s sur l\u2019\u00e9tat de l\u2019art, pour extraire l\u2019information pertinente d\u2019un large volume de donn\u00e9es\nCollaborer au sein d\u2019une \u00e9quipe Agile pluridisciplinaire et internationale de Data Scientists, Data Engineers et experts m\u00e9tiers dans toutes les phases du projet\u202f: de l\u2019id\u00e9ation \u00e0 l\u2019industrialisation et d\u00e9ploiement op\u00e9rationnel\nR\u00e9diger des supports de pr\u00e9sentation des r\u00e9sultats, conditions d\u2019utilisation, et\u202fd\u00e9fendre\u202fla solution propos\u00e9e par une approche pragmatique\n\u00catre\u202fproactif(ve)\u202fpour alimenter le pipeline d\u2019innovation avec des nouvelles id\u00e9es, contribuer \u00e0 d\u00e9finir la roadmap R&D\nEDUCATION, CONNAISSANCES ET CAPACIT\u00c9S\nMaster ou doctorat en Machine Learning / Math\u00e9matiques appliqu\u00e9es, t\u00e9l\u00e9d\u00e9tection,\u202fou domaine associ\u00e9\nAu moins 3 ans d\u2019exp\u00e9rience professionnelle, exp\u00e9rience dans un domaine associ\u00e9 \u00e0 l\u2019agriculture et en entreprise priv\u00e9e appr\u00e9ci\u00e9e\nEtat d\u2019esprit orient\u00e9 r\u00e9sultats et pragmatique pour \u00e9voluer dans un contexte de plannings serr\u00e9s\nMa\u00eetrise\u202fde\u202fPython, connaissance en SIG (QGIS,\u202fGDAL/OGR),\nLa connaissance\u202fdes biblioth\u00e8ques de\u202fMachine\u202fLearning /\u202fDeep\u202fLearning (Scikit-learn, Pytorch, Tensorflow\u2026), des outils de MLOps (ZenML, MLFlow), des syst\u00e8mes de\u202fgestion de\u202fversion (git), de Docker, Kubernetes et du fonctionnement des workflows sur AWS (et Azure)\u202fest appr\u00e9ci\u00e9e\nFacilit\u00e9s de communication pour le travail en \u00e9quipe dans un contexte international\nAnglais courant\u202f(oral\u202fet \u00e9crit)\u202f:\u202fl\u2019\u00e9quipe d\u2019accueil est internationale, les r\u00e9unions internes se d\u00e9roulent\u202fprincipalement\u202fen anglais.\nVous \u00eates curieux(se)\u202fet cr\u00e9atif(ve), collaboratif(ve)\u202fet adaptable\u202f?\u202fRejoignez-nous\u202f!\nCONDITIONS\nEmploi en CDI, d\u00e9marrage d\u00e8s que possible\nPoste\u202fbas\u00e9\u202f\u00e0 Balma, premi\u00e8re couronne\u202fde Toulouse\u202faccessible en transports en commun.\u202fPossibilit\u00e9 de t\u00e9l\u00e9travail partiel.\nPowered by JazzHR\nm5SHCur65r\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "R",
                "Go"
            ],
            "DataBase": [],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [],
            "MachingLearning": [
                "Scikit-Learn",
                "TensorFlow",
                "PyTorch"
            ],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [
                "AWS",
                "Azure"
            ],
            "DevTools": [
                "Git",
                "Docker"
            ],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [
                "Kubernetes"
            ],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [
                "Docker",
                "Kubernetes"
            ],
            "Collaboration": [],
            "Other": [
                "ML",
                "Machine Learning",
                "Cloud"
            ],
            "FrSoftSkills": [
                "Communication",
                "Organisation"
            ],
            "EnSoftSkils": [
                "Communication"
            ]
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [
                "CDI"
            ],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s",
                "35",
                "35",
                "35"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "Machine Learning Engineer H/F",
        "company": "ADHERENCE CONSULTING",
        "location": "Capinghem, Hauts-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/machine-learning-engineer-h-f-at-adherence-consulting-3913991636?position=2&pageNum=7&refId=t%2BUJ5L12Z3oEUZfxhV2uAw%3D%3D&trackingId=LFKax0SYTWGpZSD3eQqsdA%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Adherence Consulting : Votre partenaire IT de choix !\nImplant\u00e9s \u00e0 Paris, Lille et Marseille, nous sommes au coeur de l'innovation technologique et organisationnelle.\nNotre mission ? Booster votre performance et vous accompagner dans chaque \u00e9tape de votre transformation digitale.\nSi vous \u00eates pr\u00eat(e) pour une carri\u00e8re qui d\u00e9passe vos attentes, c'est le moment !\nhttps://www.adherence-consulting.fr/\nNous recherchons un ML Engineer qui rejoindra l'\u00e9quipe MLOPS. Les missions de cette \u00e9quipe sont :\nD'accompagner les Data Scientists sur toutes les parties techniquement complexes de leur projet (mise en production, entra\u00eenement avec gros volumes de data)\nDe mettre \u00e0 disposition des Data Scientists tous les outils techniques permettant d'entra\u00eener / r\u00e9entra\u00eener, de mettre en production des mod\u00e8les de ML\nLe ML Engineer devra avoir des comp\u00e9tences en Data Science (ie. comprendre les algorithmes de ML \"connus\") et avoir une bonne ma\u00eetrise sur le build de pipeline ML.\nIl devra \u00e9galement avoir une exp\u00e9rience de mise en production / run de mod\u00e8les de ML (exp\u00e9rience indispensable)\nEn termes de technologies, l'\u00e9cosyst\u00e8me est constitu\u00e9 de :\nPython (avec tensorflow) et SQL\nBig Query, GCS, Data Flow, Vertex AI\nDocker, Github, Github Actions\nDatadog\nMLOPS\nData science\nPython\nCloud\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "R",
                "Go"
            ],
            "DataBase": [
                "SQL"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [],
            "MachingLearning": [
                "TensorFlow"
            ],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [],
            "DevTools": [
                "Git",
                "Docker"
            ],
            "Os": [],
            "DBMS": [
                "Big Query"
            ],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [
                "Docker"
            ],
            "Collaboration": [],
            "Other": [
                "ML",
                "Cloud"
            ],
            "FrSoftSkills": [
                "Organisation"
            ],
            "EnSoftSkils": []
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "Ing\u00e9nieur Data Scientist exp\u00e9riment\u00e9 (H/ F)",
        "company": "Thales",
        "location": "V\u00e9lizy-Villacoublay, \u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/ing%C3%A9nieur-data-scientist-exp%C3%A9riment%C3%A9-h-f-at-thales-3886249645?position=3&pageNum=7&refId=t%2BUJ5L12Z3oEUZfxhV2uAw%3D%3D&trackingId=l7pWDNRo5j9ML706yVZujg%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "QUI ETES-VOUS ?\nDe formation Bac+5 en informatique (\u00e9cole d\u2019ing\u00e9nieur, Master ou \u00e9quivalent) vous \u00eates passionn\u00e9(e) par les technologies du Data. Vous avez d\u00e9j\u00e0 5 ans d\u2019exp\u00e9rience dans ce domaine et vous recherchez un nouveau challenge professionnel ?\nVous vous consid\u00e9rez comme une personne cr\u00e9ative et aimez sortir des sentiers battus\nVous adorez travailler en \u00e9quipe et promouvez les \u00e9changes stimulants\nVous \u00eates un(e) mentor pr\u00eat(e) \u00e0 partager vos connaissances\nVous \u00eates dynamique et m\u00e9ticuleux(se)\nCOMP\u00c9TENCES :\nVous avez une connaissance approfondie de l'une des sp\u00e9cialit\u00e9s suivantes :\nConception d'algorithmes\nDialogue coop\u00e9ratif homme/machine\nIA bas\u00e9e sur les donn\u00e9es\nIA et raisonnement symboliques\nPure Back - Langages et frameworks de programmation\nMath\u00e9matiques et statistiques\nVous savez explorer, utiliser et valoriser les donn\u00e9es, quel que soit leur type (donn\u00e9es structur\u00e9es ou non) et leur source (interne, externe, web, objets connect\u00e9s, etc.)\nVous \u00eates capable de pr\u00e9senter vos r\u00e9sultats : storytelling, traduction des insights en plans d'action, cr\u00e9ation de tableaux de bord, data visualisation...\nCE QUE NOUS POUVONS FAIRE ENSEMBLE :\nEn tant que \"Data Science \" chez Thales, vous serez en charge de :\nTrouver des informations exploitables sur la fa\u00e7on dont l'algorithme de surface du produit peut \u00eatre am\u00e9lior\u00e9\nCollaborer avec notre \u00e9quipe d'ing\u00e9nierie des donn\u00e9es pour construire des pipelines de donn\u00e9es \u00e9volutives\nConstruire des modules de Machine Learning pour mettre en avant de meilleurs produits sur le march\u00e9\nConcevoir et mettre en \u0153uvre des solutions pour rendre nos algorithmes plus transparents aux yeux de nos partenaires\nD\u00e9ployer ces solutions en production et surveiller leur impact \u00e0 l'aide de tests A/B\nTravailler sur le Machine Learning (Neural Network \u2013 NN, CNN, RNN, Deep Learning,\nRenforcement Learning, Frugal Learning, ...), la causalit\u00e9 versus la corr\u00e9lation, et/ou d'autres techniques d'IA bas\u00e9es sur les donn\u00e9es telles que Random Forest ou Evolutionary Algorithms\nR\u00e9diger des articles et des brevets pour documenter ce travail r\u00e9volutionnaire\nD\u00e9ployer des technologies Back End (langages de programmation ou frameworks comme PHP, ASP, C++, C#, Java, Python, Ruby, REST, MongoDB, PaaS\u2026)\nD\u00e9ployer des concepts en math\u00e9matiques/sciences statistiques et permettre leur application aux \u00e9tudes de solutions : mod\u00e9lisation statistique, alg\u00e8bre lin\u00e9aire, optimisation, machine learning\nVOTRE CARRI\u00c8RE CHEZ THALES\nDiff\u00e9rentes opportunit\u00e9s vous permettront de d\u00e9couvrir d'autres domaines ou sites. Vous pourrez \u00e9voluer et d\u00e9velopper vos comp\u00e9tences dans diff\u00e9rents domaines :\nExplorez un espace attentif au d\u00e9veloppement personnel\nD\u00e9veloppez vos talents dans un autre domaine du groupe Thales, en d\u00e9couvrant de nouveaux produits, de nouveaux clients, un nouveau pays ou en vous orientant vers une solution plus complexe\nChoisissez entre une expertise technique ou un parcours de leadership\nConstruisez une carri\u00e8re internationale au sein d'un groupe d'ing\u00e9nierie de premier plan.\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "Java",
                "C++",
                "C#",
                "R",
                "Go"
            ],
            "DataBase": [
                " MongoDB"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [
                "Tableau"
            ],
            "Statistics": [
                "Statistiques"
            ],
            "CloudComputing": [],
            "DevTools": [],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [
                "Machine Learning",
                "Statistiques"
            ],
            "FrSoftSkills": [
                "Leadership"
            ],
            "EnSoftSkils": [
                "Leadership"
            ]
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [],
            "Salary": [],
            "Level": [
                "Bac+5"
            ],
            "Experience": [
                "a",
                "n",
                "s",
                "5",
                "5",
                "5"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "Data Scientist H/F",
        "company": "ADHERENCE CONSULTING",
        "location": "Lille, Hauts-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/data-scientist-h-f-at-adherence-consulting-3913991657?position=4&pageNum=7&refId=t%2BUJ5L12Z3oEUZfxhV2uAw%3D%3D&trackingId=jkRLP%2Bd7Ugx%2B7ylQmOCMAQ%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Adherence Consulting : Votre partenaire IT de choix !\nImplant\u00e9s \u00e0 Paris, Lille et Marseille, nous sommes au coeur de l'innovation technologique et organisationnelle.\nNotre mission ? Booster votre performance et vous accompagner dans chaque \u00e9tape de votre transformation digitale.\nSi vous \u00eates pr\u00eat(e) pour une carri\u00e8re qui d\u00e9passe vos attentes, c'est le moment !\nhttps://www.adherence-consulting.fr/\nImplant\u00e9e au carrefour de l'innovation technologique et organisationnelle, notre entreprise se positionne comme un partenaire IT de premier plan. Situ\u00e9s \u00e0 Paris, Lille, et Marseille, nous nous engageons \u00e0 booster la performance de nos clients \u00e0 travers une transformation digitale sur mesure. Rejoignez une \u00e9quipe ambitieuse pour une carri\u00e8re qui d\u00e9passe vos attentes.\nDate de D\u00e9but : Fin avril 2024 maximum.\nMission Principale : D\u00e9velopper un syst\u00e8me de recommandation destin\u00e9 aux utilisateurs pour am\u00e9liorer le Diagnostique de Performance Energ\u00e9tique de leur logement. Ce syst\u00e8me \u00e9voluera de recommandations bas\u00e9es sur des r\u00e8gles gouvernementales vers des suggestions personnalis\u00e9es incluant des travaux et produits sp\u00e9cifiques.\nResponsabilit\u00e9s\nD\u00e9velopper et maintenir le code backend en Python, participer \u00e0 la transcription de r\u00e8gles DPE en code de calcul python\nAssurer la maintenance d'un syst\u00e8me existant en Data Science.\nUtiliser des comp\u00e9tences en Data Science, particuli\u00e8rement dans les r\u00e9seaux de neurones, pour am\u00e9liorer et innover dans le syst\u00e8me de recommandation.\nCollaborer \u00e9troitement avec les \u00e9quipes M\u00e9tiers pour analyser, \u00e9valuer et exploiter la richesse des donn\u00e9es disponibles.\nG\u00e9rer le cycle complet du d\u00e9veloppement des projets Data Science, incluant la conception, le d\u00e9ploiement, le monitoring, et la documentation.\nAttention, le poste est ouvert uniquement en CDI. Une exp\u00e9rience de 5 \u00e0 6 ans minimum est exig\u00e9e.\nPour R\u00e9ussir dans ce Poste : Vous \u00eates un(e) passionn\u00e9(e) de technologie et de data, capable de piloter des projets complexes avec une grande autonomie. Vous avez une excellente ma\u00eetrise de la programmation en Python et une exp\u00e9rience solide dans la mise en oeuvre de solutions de Data Science. Votre capacit\u00e9 \u00e0 communiquer et \u00e0 travailler en \u00e9quipe vous permettra de vous int\u00e9grer rapidement et de contribuer efficacement aux projets de l'entreprise.\nComp\u00e9tences Techniques Requises\nMa\u00eetrise avanc\u00e9e de Python, avec une solide exp\u00e9rience en d\u00e9veloppement backend.\nConnaissance approfondie de FastAPI, Git, SQL, Docker, et Google Cloud Platform (GCP).\nExp\u00e9rience significative en Data Science, notamment dans l'utilisation de r\u00e9seaux de neurones.\nCapacit\u00e9 \u00e0 traduire les \u00e9volutions du DPE en code de calcul scientifique.\nFamiliarit\u00e9 avec les technologies telles que TensorFlow pour le d\u00e9veloppement de syst\u00e8mes de recommandation.\nQualit\u00e9s Professionnelles\nAutonomie dans la gestion de projets complexes.\nExcellente capacit\u00e9 de programmation et de r\u00e9solution de probl\u00e8mes.\nCommunication efficace avec les partenaires business.\nCapacit\u00e9 \u00e0 travailler en \u00e9quipe et \u00e0 partager les connaissances et bonnes pratiques.\nModalit\u00e9s De Travail\nPossibilit\u00e9 de t\u00e9l\u00e9travail\nInt\u00e9gration dans une \u00e9quipe projet dynamique avec des ambitions transversales fortes au sein du groupe.\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "R",
                "Go"
            ],
            "DataBase": [
                "SQL"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [],
            "MachingLearning": [
                "TensorFlow"
            ],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [
                "Google Cloud Platform"
            ],
            "DevTools": [
                "Git",
                "Docker"
            ],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [
                "Docker"
            ],
            "Collaboration": [],
            "Other": [
                "Cloud"
            ],
            "FrSoftSkills": [
                "Communication",
                "R\u00e9solution de probl\u00e8mes",
                "Organisation"
            ],
            "EnSoftSkils": [
                "Communication"
            ]
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [
                "CDI"
            ],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s",
                "6",
                "6",
                "6"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "Data Scientist",
        "company": "Sidetrade",
        "location": "Boulogne-Billancourt, \u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/data-scientist-at-sidetrade-3894699040?position=5&pageNum=7&refId=t%2BUJ5L12Z3oEUZfxhV2uAw%3D%3D&trackingId=y0KjEovXu7Bo4JxPsUl%2Btg%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Calling all tech enthusiasts! Are you a problem-solving, curious, and strategic Data Scientist ? Join us at Sidetrade, the leading global SaaS provider recognized by Gartner.(https://go.sidetrade.com/GartnerMagicQuadrant22.ht)\nIndulge your passion for high-availability software and performance enhancement as part of our dynamic team. Embrace the challenge, embrace the excitement - become a Data Scientist and thrive! Shape the future of AI-powered Order-to-Cash at Sidetrade today. Join us in creating innovative solutions that redefine the industry!\nAbout Sidetrade\u202fand its amazing R&D team\nSidetrade is a fast-growing international software company that is transforming the Order-to-Cash process for global enterprises. Its AI-powered SaaS platform digitizes the financial customer journey, empowering CFOs to secure and accelerate cash flow generation. Recognized as a Leader in Gartner's Magic Quadrant for two consecutive years, Sidetrade fosters a culture of innovation, collaboration, and customer-centricity from its headquarters in Europe and North America.\nThe R&D team comprises experienced tech professionals who share a deep passion for technology. Together, they are dedicated to developing cutting-edge software solutions that drive the transformation of our customers' work processes. We provide comprehensive training, coaching, resources, and mentorship to empower every team member's growth and nurture their success.\nWhat you will love at Sidetrade:\nWe are seeking a passionate and knowledgeable Data Scientist with a multifaceted skill set. Immerse yourself in the exhilarating world of AI and Data Science within our cutting-edge tech environment. Collaborate with like-minded individuals, embracing the latest tools, techniques, and technologies. Fuel your professional growth and innovation within our agile development ecosystem.\nYour missions :\nBuild solutions with AI, GenAI, LLM, Machine learning, Deep learning, Big Data for our products\nDefine the technical and functional orientations of the product in interaction with our Product, Marketing and Sales teams.\nParticipate in developing the architecture (LakeHouse, DataWareHouse, DataLake,\u00a0ETL, Search Engine, NoSQL, SQL) and designing scalable and smart algorithms\nEnhance your skills through constant discussions with specialists in their fields, and internal hackathons\nParticipate in data science guild projects: Exploratory research, Data mining, Data analysis, POC Machine learning,..\nYou will be involved in the entire development cycle: design, implementation, testing, release and maintenance.\nThrough your expertise, you will reinforce the continuous improvement of development processes.\nTechnical environment :\nLanguages : Python & SQL\nData Storage : Oracle, Postgres, Elasticsearch, Greenplum, MongoDB\nData Science framework : Dataiku, Jupyter Notebook, Metaflow\nDataviz : Tableau Server, PowerBI\nData processing : Talend, Python, DBT, Kafka\nSource control : Git\nD\u00e9ployment: Bash, Ansible, Docker\nConfluence, Jira, Teams\nRequirements\nMaster degree\n2 to 5 years' experience in a similar position\nProven data science experience with production launch of Machine Learning models\nApplied knowledge of AI, GenAI and LLM\nSolid knowledge of Python and object-oriented programming\nGood knowledge of SQL and NoSQL databases\nFamiliarity with API Rest and Web development issues\nSensitivy to the performance of your algorithms, both in terms of relevance and hardware impact\nA taste for discovery and technology watch\nYou know how to grasp a rich technical stack (Scheduling/Message queuing/Front/API/Data Workflow / Distributed Computing Framework / Machine Learning / SQL & NoSQL databases) and challenge it\nFluent in English (written and spoken) is a must (most of the meeting are in English).\nBenefits\nJoin our Immersive Bootcamp\nReview your onboarding plan with your manager and develop an action plan to achieve your goals\nCollaborate with the team and participate to the roadmap to optimize software performancebuild your internal network across all departments\nExpand your skill set, share your expertise and unlock your full potential\nAt Sidetrade, we cultivate a multicultural environment that fuels innovation. With over 22 nationalities represented, we strongly value diversity, gender equality, inclusivity, and fairness. As an equal opportunity employer, we reject all forms of discrimination and harassment. Your unique contributions are celebrated, driving collective success in our inclusive workplace.\nDiscover more on\u00a0www.sidetrade.com\nAgencies\nOnly applications from invited agencies through the Workable portal will be accepted. Unsolicited CVs sent directly to managers or HR will not incur any fees.\nApply for this job\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "Scala",
                "R",
                "Go",
                "Bash"
            ],
            "DataBase": [
                "SQL",
                "NoSQL",
                " MongoDB",
                "Elasticsearch"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [
                "Tableau",
                "PowerBI"
            ],
            "Statistics": [],
            "CloudComputing": [],
            "DevTools": [
                "Git",
                "Docker"
            ],
            "Os": [],
            "DBMS": [
                "Oracle"
            ],
            "SoftBigDataProcessing": [],
            "Automation": [
                "Ansible"
            ],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [
                "Docker"
            ],
            "Collaboration": [
                "JIRA",
                "Confluence",
                "Teams"
            ],
            "Other": [
                "Big Data",
                "Machine Learning"
            ],
            "FrSoftSkills": [
                "Collaboration"
            ],
            "EnSoftSkils": [
                "Collaboration"
            ]
        },
        "details": {
            "JobDetail": [
                "Full"
            ],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "Data Scientist",
        "company": "Withings",
        "location": "Paris, \u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/data-scientist-at-withings-3888804341?position=6&pageNum=7&refId=t%2BUJ5L12Z3oEUZfxhV2uAw%3D%3D&trackingId=NNiMc5DHZg%2FmikTMTlTLEw%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Vos missions\nL'\u00e9quipe Machine Learning est responsable du d\u00e9veloppement de tous les algorithmes de pr\u00e9diction des produits Withings. Int\u00e9gr\u00e9.e en son sein, tu auras les responsabilit\u00e9s suivantes:\nRecherche algorithmique pour analyser les donn\u00e9es pertinentes et les partager avec l\u2019\u00e9quipe\nR\u00e9alisation de prototypes par la mise en pratique des m\u00e9thodes retenues\nImpl\u00e9mentation de services sur la plateforme / produits Withings, en tenant compte des contraintes de ressources et de temps d\u2019ex\u00e9cution\nMise en avant de nouvelles fonctionnalit\u00e9s pour les applications et produits Withings\nMaintien du lien avec les \u00e9quipes de Recherche Appliqu\u00e9e et de D\u00e9veloppement Produit pour comprendre et exploiter les donn\u00e9es recueillies\nREQUIREMENTS\nFormation Bac+5 type grande \u00e9cole d\u2019ing\u00e9nieur ou \u00e9quivalent\nUn\ndoctorat\ndans un domaine connexe est tr\u00e8s appr\u00e9ci\u00e9\nUne premi\u00e8re exp\u00e9rience r\u00e9ussie dans le domaine du Machine Learning, de l'algorithmie appliqu\u00e9 aux donn\u00e9es de sant\u00e9 ou \u00e0 l'embarqu\u00e9 est fortement appr\u00e9ci\u00e9e\nFortes comp\u00e9tences informatiques : calculs scientifiques, Python...\nRigueur, autonomie, prise d'initiatives, curiosit\u00e9...\nConnaissances en traitement de signal, C/C++ appr\u00e9ci\u00e9es\nMa\u00eetrise parfaite de la communication en fran\u00e7ais et en anglais, aussi bien \u00e0 l\u2019\u00e9crit qu\u2019\u00e0 l\u2019oral\nRejoindre l\u2019aventure Withings, c\u2019est :\nInt\u00e9grer un des pionniers et leaders mondiaux de la sant\u00e9 connect\u00e9e, plusieurs fois prim\u00e9 au Consumer Electronic Show\nContribuer \u00e0 des projets innovants et ambitieux pour la sant\u00e9 de demain dans un environnement agile et en constante \u00e9volution\nInt\u00e9grer une entreprise internationale, membre de la FrenchTech 120, dont les \u00e9quipes sont bas\u00e9es \u00e0 Issy-les-Moulineaux, Boston, Hong-Kong et Shenzhen\nParticiper \u00e0 l\u2019am\u00e9lioration continue de nos produits et services en les b\u00eata-testant avant leur sortie, notamment lors de nos nombreuses sessions sportives entre coll\u00e8gues\nB\u00e9n\u00e9ficier de nombreux avantages : Stock Options, smartphone et ordinateur de votre choix, r\u00e9ductions pour des activit\u00e9s culturelles et sportives, restaurant d\u2019entreprise, et bien plus encore\nParticiper \u00e0 la Withings Med Academy en assistant \u00e0 des conf\u00e9rences de professionnels de sant\u00e9 afin de renforcer ses connaissances dans le domaine m\u00e9dical\nCollaborer avec des coll\u00e8gues passionn\u00e9s et c\u00e9l\u00e9brer ensemble chacune de nos r\u00e9ussites !\nToutes les candidatures re\u00e7ues sont \u00e9tudi\u00e9es ind\u00e9pendamment de l\u2019origine ethnique, des croyances, de la religion, du genre, de l\u2019orientation sexuelle ou de la sant\u00e9 des candidats. Withings aspire \u00e0 offrir et garantir l\u2019\u00e9galit\u00e9 des chances aux candidats et seules les personnes habilit\u00e9es (RH et Management) auront acc\u00e8s aux informations concernant votre candidature.\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "C++",
                "R",
                "Go"
            ],
            "DataBase": [],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [],
            "DevTools": [],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [
                "Machine Learning"
            ],
            "FrSoftSkills": [
                "Communication"
            ],
            "EnSoftSkils": [
                "Communication",
                "Initiative"
            ]
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [],
            "Salary": [],
            "Level": [
                "Bac+5"
            ],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "Senior Machine Learning Engineer",
        "company": "FarmWise",
        "location": "Paris, \u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/senior-machine-learning-engineer-at-farmwise-3831137831?position=7&pageNum=7&refId=t%2BUJ5L12Z3oEUZfxhV2uAw%3D%3D&trackingId=og9gk8XWq6b4gHD2PwSg%2Bw%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Company Overview:\nAt FarmWise, we harness the power of AI to find solutions to combat food production challenges, and help growers thrive in this new farming era. We work hand in hand with growers to understand their constraints, address their priorities, and build products that are changing their lives for good. We\u2019re a diverse team of analytical problem-solvers who are deeply motivated by challenges. We value open communication and a dedication to self-improvement. If you are interested in working on technology that will have a big impact on agriculture. Join us!\nJob Overview:\nAs a Sr. Machine Learning Engineer at FarmWise, you will play a pivotal role in leading and executing research and development initiatives. You will focus on advanced topics such as panoptic segmentation models for plant and weed detection, optimization of embedded models, 3D visual odometry, etc. You\u2019ll be part of a team of Data and Machine Learning engineers. This role encompasses the entire machine learning lifecycle, from defining state-of-the-art methodologies to deploying sophisticated solutions into production environments and maintaining automated and robust data pipelines.\nResponsibilities:\nLead and collaborate with cross-functional teams to identify and define complex machine learning challenges in agriculture.\nDesign, develop, and implement advanced machine learning algorithms, with a focus on automated diagnosis of mislabeled images and model robustness.\nConduct in-depth research to establish and integrate state-of-the-art approaches in machine learning domains.\nDesign and execute comprehensive experiments to evaluate and optimize machine learning models.\nCollaborate closely with the engineering team to successfully deploy advanced models into production environments.\nMentor and guide junior team members, fostering a culture of continuous learning and improvement.\nQualifications:\nExtensive experience in Python, PyTorch, and other relevant machine learning frameworks.\nProven track record of successfully leading and implementing machine learning projects, with a focus on computer vision and related domains.\nStrong problem-solving skills, analytical mindset, and ability to thrive in a fast-paced environment.\nExcellent communication skills, both technical and non-technical, and a commitment to mentorship.\nWhat We Offer:\nJoin a dynamic team of industry experts dedicated to making a positive impact on agriculture through technological innovation.\nWork with cutting-edge technologies and contribute to the development of groundbreaking solutions.\nEnjoy a hybrid-remote work policy, providing flexibility to accommodate your work preferences.\nHiring Process:\nHR Interview\nTechnical Interview\nTake-home challenge\nIn person interviews with various team members\nFarmWise is an equal opportunity employer, and we encourage applicants from all backgrounds to apply. If you are passionate about pushing the boundaries of technology in agriculture, we look forward to receiving your application!\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "R",
                "Go"
            ],
            "DataBase": [],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [],
            "MachingLearning": [
                "PyTorch"
            ],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [],
            "DevTools": [],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [
                "Teams"
            ],
            "Other": [
                "Machine Learning"
            ],
            "FrSoftSkills": [
                "Communication"
            ],
            "EnSoftSkils": [
                "Communication",
                "Flexibility",
                "Initiative"
            ]
        },
        "details": {
            "JobDetail": [
                "Remote",
                "Full",
                "Junior"
            ],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "Machine Learning Engineer",
        "company": "Liftoff Mobile",
        "location": "Paris, \u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/machine-learning-engineer-at-liftoff-mobile-3812712612?position=8&pageNum=7&refId=t%2BUJ5L12Z3oEUZfxhV2uAw%3D%3D&trackingId=NWyeR0M5O0Fdt84GDUM05w%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Liftoff is the leading growth acceleration platform for the mobile industry, helping advertisers, publishers, game developers and DSPs scale revenue growth with solutions to market and monetize mobile apps.\nLiftoff\u2019s solutions, including Accelerate, Direct, Influence, Monetize, Intelligence, and Vungle Exchange, support over 6,600 mobile businesses across 74 countries in sectors such as gaming, social, finance, ecommerce, and entertainment. Founded in 2012 and headquartered in Redwood City, CA, Liftoff has a diverse, global presence.\nAbout the team:\nThe Conversion ML team is responsible for improving and maintaining machine learning models that have a pivotal impact on the performance of Accelerate customers\u2019 advertising campaigns. The team collaborates closely with other ML-oriented teams at Liftoff. We use many modern ML frameworks and architectures, including Spark and PyTorch to build deep neural networks.\nLocation:\nThis role is located in Liftoff's Hub in Paris, France or can be in any of the following locations: England or Germany. ML Engineers located in Paris will be asked to come into the office once a week and once a month if located in one of the above countries.\nResponsibilities:\nOwn both the ML models and the underlying software tooling and infrastructure. Our ML Engineer role combines the classic \"ML Scientist\" and \"Data Engineer\" role at other companies.\nHave a closed feedback loop from hypothesis generation to live AB testing, with no cross-team friction and sub-day iteration cycles.\nTake on unique modeling challenges not covered in the scientific literature, like extreme positive sample sparsity and labeling delay.\nWork with modeling techniques at the state-of-the-art of probability prediction, as well as a multitude of other ML areas.\nBecome an expert in Clojure, Go, and the many other cutting-edge open source technologies that maximize our development velocity.\nJoin a nimble, consistently excellent, and experienced engineering team (former Google/LI/Ooyala/etc).\nRequirements:\nVery strong coding ability (experience in Go or Clojure is a plus).\n4+ years of industry experience applying Machine Learning to large scale problems.\nStrong core CS fundamentals (data structures, algorithms, architecting systems).\nA passion for quality and excellence, and the ability to temper it when necessary to ship.\nSets ego aside in pursuit of finding the best solution, no matter where it comes from.\nB.S. or higher in Computer Science. PhD a big plus.\n1\nWe use Covey as part of our hiring and / or promotional process for jobs in NYC and certain features may qualify it as an AEDT. As part of the evaluation process we provide Covey with job requirements and candidate submitted applications. We began using Covey Scout for Inbound on January 22, 2024.\nPlease see the independent bias audit report covering our use of Covey here.\nLiftoff is committed to providing and maintaining a work environment where all employees and candidates are treated with dignity and respect and that is free of bias, prejudice, and harassment. Liftoff is further committed to providing an equal employment opportunity for all employees and candidates for employment free from discrimination and harassment on the basis of sex, gender (including sexual harassment, gender harassment, and harassment due to pregnancy, childbirth, breastfeeding, and related conditions), sexual orientation, gender identity, gender expression, gender nonconformity, race, creed, religion, color, national origin, ancestry (including association, affiliation, or participation with persons or activities related to national origin, English-proficiency or accent, or immigration status), physical or mental disability, medical condition(s), genetic information of an individual or family member of the individual, marital or domestic partner status, age, veteran or military status, family care status, requesting or taking pregnancy, parental or disability leave, requesting an accommodation, or any other characteristic protected by federal, state, or local law, regulation, or ordinance. All such discrimination and harassment is unlawful and will not be tolerated. Liftoff maintains a continued commitment to equal employment opportunity and expects the full cooperation of all personnel.\nAgency and Third Party Recruiter Notice:\nLiftoff does not accept unsolicited resumes from individual recruiters or third-party recruiting agencies in response to job postings. No fee will be paid to third parties who submit unsolicited candidates directly to our hiring managers or Recruiting Team. All candidates must be submitted via our Applicant Tracking System by approved Liftoff vendors who have been expressly requested to make a submission by our Recruiting Team for a specific job opening. No placement fees will be paid to any firm unless such a request has been made by the Liftoff Recruiting Team and such a candidate was submitted to the Liftoff Recruiting Team via our Applicant Tracking System.\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "R",
                "Go"
            ],
            "DataBase": [],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [
                "Spark"
            ],
            "MachingLearning": [
                "PyTorch"
            ],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [],
            "DevTools": [],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [
                "Teams"
            ],
            "Other": [
                "ML",
                "Machine Learning"
            ],
            "FrSoftSkills": [],
            "EnSoftSkils": []
        },
        "details": {
            "JobDetail": [
                "Full"
            ],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "Data Scientist H/F",
        "company": "METEOJOB by CleverConnect",
        "location": "Rennes, Brittany, France",
        "link": "https://fr.linkedin.com/jobs/view/data-scientist-h-f-at-meteojob-by-cleverconnect-3907968677?position=9&pageNum=7&refId=t%2BUJ5L12Z3oEUZfxhV2uAw%3D%3D&trackingId=HWI2OEcplVLJRzdP5BSzzg%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Entreprise\nQui sommes-nous ?\nNous sommes passionn\u00e9s par les nouvelles technologies, et vous ?\nRejoindre Amiltone, c'est int\u00e9grer des \u00e9quipes dynamiques et soud\u00e9es dans le cadre de projets novateurs et ambitieux. Nous relevons les challenges techniques de nos clients et les accompagnons dans leur transformation digitale.\nPourquoi choisir Amiltone\u202f?\nAmiltone, plus qu'une entreprise, un \u00e9tat d'esprit !\nNotre objectif ? Votre \u00e9panouissement professionnel !\nNous Avons \u00e0 C\u0153ur De\nVous accompagner au mieux au travers d'un suivi personnalis\u00e9\nVous faire monter en comp\u00e9tences en vous proposant des formations tout au long de votre carri\u00e8re\nComprendre vos besoins et respecter nos engagements\nVous proposer des missions de qualit\u00e9 avec des technologies innovantes\nCultiver votre potentiel gr\u00e2ce \u00e0 notre programme de d\u00e9veloppement personnel Addvise\nVotre bien-\u00eatre passe aussi par des activit\u00e9s extraprofessionnelles, c'est pourquoi nous vous proposons des s\u00e9ances sportives anim\u00e9es par nos coachs, soir\u00e9es pour se retrouver et animations (\u00e0 l'agence ou en visio), Gaming nights...\nDescription Du Poste\nVos missions ?\nInt\u00e9gr\u00e9 \u00e0 notre \u00e9quipe de 10 personnes, vous assurez les missions suivantes :\nR\u00e9ceptionner et analyser la donn\u00e9e brute\nTraiter la donn\u00e9e en streaming ou en statique\nAdapter ou cr\u00e9er des mod\u00e8les de machine learning\nEvaluer la pr\u00e9cision/robustesse d'un mod\u00e8le\nOutils de monitoring et de visualisation\nD\u00e9veloppement des mod\u00e8les\nMaintenir et documenter les codes et les process\nLa stack Technique :\nOutils : MongoDB, PostgreSQL\nNLP (IA g\u00e9n\u00e9rative)\nQlik Sense\nDocker, Jenkins\nGitlab/Github\nDescription Du Profil\nAlors ? Pr\u00eat \u00e0 devenir Amiltonien ?\nN'h\u00e9sitez Pas \u00e0 Postuler Si Vous Vous Reconnaissez\nDipl\u00f4m\u00e9 bac+5 (\u00e9cole d'ing\u00e9nieur ou master), vous avez au moins 2 ans d'exp\u00e9rience en tant que Data Scientist.\nVous aimez d\u00e9couvrir de nouveaux contextes fonctionnels et comprendre les objectifs des applications que vous d\u00e9veloppez.\nA l'aise dans une organisation agile, vous faites preuve de rigueur et appliquez les standards de qualit\u00e9 Amiltone durant toute la dur\u00e9e des d\u00e9veloppements.\nOutre vos comp\u00e9tences techniques, nous nous int\u00e9ressons \u00e9galement \u00e0 votre potentiel et votre motivation.\nNos postes sont ouverts aux personnes en situation de handicap.\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "R",
                "Go"
            ],
            "DataBase": [
                "SQL",
                " MongoDB"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [],
            "DevTools": [
                "Git",
                "Docker",
                "Jenkins"
            ],
            "Os": [],
            "DBMS": [
                "PostgreSQL"
            ],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [
                "Docker"
            ],
            "Collaboration": [],
            "Other": [
                "Machine Learning"
            ],
            "FrSoftSkills": [
                "Organisation"
            ],
            "EnSoftSkils": []
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [],
            "Salary": [],
            "Level": [
                "Bac+5"
            ],
            "Experience": [
                "a",
                "n",
                "s",
                "2",
                "2",
                "2"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "Data scientist (H/F)",
        "company": "METEO FRANCE",
        "location": "Toulouse, Occitanie, France",
        "link": "https://fr.linkedin.com/jobs/view/data-scientist-h-f-at-meteo-france-3914118639?position=10&pageNum=7&refId=t%2BUJ5L12Z3oEUZfxhV2uAw%3D%3D&trackingId=bTv0yeNdhHci6Oanp%2FOY0g%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Cette offre d\u2019emploi est fournie par P\u00f4le emploi\nDescription\nL'offre d'apprentissage concerne un travail autour de la th\u00e9matique de l'intelligence artificielle pour la pr\u00e9vision num\u00e9rique du temps avec notamment pour cible principale la partie assimilation. Le travail consistera \u00e0 voir l'apport de l'intelligence artificielle sur diff\u00e9rentes th\u00e9matiques : \u00e9mulateur de mod\u00e8le m\u00e9t\u00e9orologique, apprentissage d'erreur mod\u00e8le, ... Ce travail peut aussi inclure une partie sur le traitement initial des donn\u00e9es, notamment sous la forme de la cr\u00e9ation de jeux de donn\u00e9es, l'optimisation du chargement en m\u00e9moire des donn\u00e9es, ou la visualisation de donn\u00e9es. Le dipl\u00f4me pr\u00e9par\u00e9 doit \u00eatre un dipl\u00f4me d'ing\u00e9nieur ou un master sp\u00e9cialis\u00e9 dans une fili\u00e8re data. Les comp\u00e9tences de bases attendues sont celles d'un apprentis datascientist. Des comp\u00e9tences en math\u00e9matiques, en statistiques et en informatique (de pr\u00e9f\u00e9rence python) sont attendues. Une premi\u00e8re exp\u00e9rience en deep learning serait int\u00e9ressante. La pratique de git est un plus.\nPROFIL SOUHAIT\u00c9\nExp\u00e9rience\nExp\u00e9rience exig\u00e9e de 1 An(s)\nLangue\nFran\u00e7ais\nSource: Pole emploi (https://www.pole-emploi.fr)\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "R"
            ],
            "DataBase": [],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [
                "Statistiques"
            ],
            "CloudComputing": [],
            "DevTools": [
                "Git"
            ],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [
                "Statistiques"
            ],
            "FrSoftSkills": [],
            "EnSoftSkils": []
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "Software Engineer Internship - AI Startup - Paris",
        "company": "HrFlow.ai",
        "location": "Paris, \u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/software-engineer-internship-ai-startup-paris-at-hrflow-ai-3829229297?position=1&pageNum=10&refId=95T5IhjHY6ggpolfwE5Syg%3D%3D&trackingId=W6jFL5MTzDDUsUmeeClUIg%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Who we are:\nAfter two years of intense AI research and development at Ecole Normale Superieure and Ecole Centrale Paris, HrFlow.ai was founded in June 2016 to solve the labor market and employment challenges at scale using the latest innovations in AI.\nHaving developed a proprietary AI and workflow technology from the ground up that unifies HR data silos, identifies the right candidates for the right jobs without bias, and automates it all, HrFlow.ai has already gained traction with over +1,000 clients, large and small.\nHrFlow.ai raised an initial seed round of 2.3M$ in 2018 from some of the most successful technology entrepreneurs in Europe and the United States, including Xavier Niel (Free Telecom & Station F), Dominique Vidal (Index Ventures), Romain Niccoli (Criteo & Pigment), Jean-Baptiste Rudelle (Criteo), Franck Le Ouay (Criteo & LIFEN), Thibaud Elzi\u00e8re (Fotolia & e-Founders), and has since self-funded its growth.\nWe love AI engineering, problem-solving, and business. Join our diverse team and help us build the next chapter of our exciting growth!\n\ud83d\ude80 Role:\nAs a Software Engineer Intern, you will have the opportunity to immerse yourself in real-world software development projects, working alongside experienced engineers in a dynamic and collaborative environment. You will play a key role in building and enhancing our software solutions while gaining hands-on experience with cutting-edge technologies.\nThis internship will provide you with invaluable insights into the software development lifecycle, from concept to deployment, and help you develop essential skills for a successful career in technology.\n\ud83d\udc51 What you will be doing:\nAssisting in the development and maintenance of software applications using Javascript and Python and related technologies.\nWriting clean, efficient, and well-documented code that adheres to best practices.\nParticipating in code reviews and providing constructive feedback to peers.\nCollaborating with cross-functional teams to translate requirements into technical solutions.\nContributing to the design and architecture of software systems.\nLearning new technologies and tools to stay updated with industry trends.\n\ud83c\udfaf Requirements:\nStrong understanding of Javascript and Python programming language fundamentals.\nFamiliarity with software development concepts such as data structures, algorithms, and object-oriented design.\nBasic knowledge of web development frameworks (e.g., Django, Flask) is a plus.\nExperience with version control systems, such as Git.\nExcellent problem-solving and analytical skills.\nAbility to work independently and as part of a team.\nEffective communication and interpersonal skills.\n\ud83d\ude4c Perks & Benefits:\nGo fast and learn a lot\nHigh-impact position and responsibilities without any day being the same.\nCompetitive salary and variable compensation\nOne fully paid international conference each year\nGenerous time & paid vacation\nGym club & public transportation\nHealth & retirement packages\nFun & smart colleagues\nLatest hardware\n\ud83d\udc8c Application Process:\nApply on LinkedIn\nInterview with our Principal Engineer to discuss your experience and qualifications in more detail.\nInterview with our Chief Executive Officer to discuss your fit within our organization and your career goals.\nWe appreciate your interest in this position and look forward to reviewing your application.\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "Java",
                "R",
                "Go",
                "JavaScript"
            ],
            "DataBase": [],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [],
            "DevTools": [
                "Git"
            ],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [
                "Teams"
            ],
            "Other": [],
            "FrSoftSkills": [
                "Communication"
            ],
            "EnSoftSkils": [
                "Communication",
                "Organization",
                "Interpersonal Skills"
            ]
        },
        "details": {
            "JobDetail": [
                "Full"
            ],
            "TypeContract": [],
            "Salary": [
                "Salary",
                "Package"
            ],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "Senior Data Scientist (NLP - LLM)",
        "company": "Nextra",
        "location": "Marseille, Provence-Alpes-C\u00f4te d'Azur, France",
        "link": "https://fr.linkedin.com/jobs/view/senior-data-scientist-nlp-llm-at-nextra-3907593536?position=2&pageNum=10&refId=95T5IhjHY6ggpolfwE5Syg%3D%3D&trackingId=IP9pg13sL7XH0L1LuIKj5A%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "NOTRE CONTEXTE\n: ______________\nNextra intervient aupr\u00e8s des directions g\u00e9n\u00e9rales et des directions des op\u00e9rations (CEO, CTO, COO, directions supply-chain, data, industrielles, R&D) afin de les accompagner dans la r\u00e9alisation de leurs projets en DATA Engineering.\nVOTRE IMPACT\n: ______________\nEn tant que Data Scientist, vous interviendrez aupr\u00e8s de nos clients de toutes tailles et les accompagnerez dans leurs projets techniques. Au-del\u00e0 de vos missions, nous nous attachons \u00e0 vous lib\u00e9rer du temps pour que vous contribuiez au d\u00e9veloppement de la soci\u00e9t\u00e9 et puissiez porter les sujets qui vous tiennent \u00e0 c\u0153ur et agir comme un v\u00e9ritable intrapreneur.\nVOTRE ROLE\n: ______________\nEn tant que\ndata scientist\n, vous interviendrez aupr\u00e8s de nos clients de toutes tailles sur des missions telles que :\nElaboration de mod\u00e8les algorithmiques pr\u00e9dictifs d\u2019aide \u00e0 la d\u00e9cision\nR\u00e9solution de probl\u00e8mes analytiques, statistiques et d\u2019apprentissage automatique (Machine Learning, Deep Learning, NLP)\nD\u00e9ploiement de solutions Cloud, d\u2019APIs et de bases de donn\u00e9es\nCadrage et d\u00e9ploiement d'approches Data Science industrialis\u00e9es (MLOps...)\nParticiper aux projets de recherche et de d\u00e9veloppement en NLP, en se concentrant sur les mod\u00e8les de langage de derni\u00e8re g\u00e9n\u00e9ration\nExploiter des LLM tels que GPT, BERT, et autres, pour cr\u00e9er des applications innovantes dans le domaine du traitement automatique du langage\nInterpr\u00e9ter les r\u00e9sultats pour am\u00e9liorer la performance des mod\u00e8les de langage\nVous travaillerez en synergie avec nos consultants en transformation pour construire des solutions \u00e0 forte valeur ajout\u00e9e adapt\u00e9es aux attentes des clients.\nCE POSTE EST FAIT POUR VOUS SI :\n______________\nMaster en informatique, linguistique computationnelle, IA, ou un domaine connexe, avec sp\u00e9cialisation en NLP\nPlusieurs ann\u00e9es d'exp\u00e9rience professionnelle dans des projets NLP, avec une expertise en LLM\nForte ma\u00eetrise des algorithmes de machine learning, deep learning et NLP\nComp\u00e9tences en programmation avec Python et familiarit\u00e9 avec des frameworks comme TensorFlow ou PyTorch.\nLA CULTURE DE NEXTRA\n: ______________\nChez\nNextra\n, l\u2019organisation est horizontale, tout le monde est responsable et contribue selon ses comp\u00e9tences au projet. Les r\u00f4les sont attribu\u00e9s en fonction des souhaits, des comp\u00e9tences, des projets, des opportunit\u00e9s de march\u00e9 et des besoins de l'entreprise.\nAu quotidien, vous serez amen\u00e9 \u00e0 travailler aux c\u00f4t\u00e9s de Data Scientist, de financiers, de formateurs et de conseillers. Vous pourrez prendre part \u00e0 des chantiers internes selon vos app\u00e9tences (BD, Partenariats, Offres, Academy, Outils, Technologies, etc.) et agir en v\u00e9ritable intrapreneur.\nEt rejoignez-nous vite pour nous aider \u00e0 faire de\nNextra\nun hub d\u2019innovation de r\u00e9f\u00e9rence \ud83d\udcaa\ud83c\udffb\nVOS AVANTAGES : ______________\n\ud83d\ude8c 100% de l\u2019abonnement Transport rembours\u00e9\n\ud83c\udf82 13\n\u00e8me\nmois et super bonus (illimit\u00e9)\n\ud83c\udf7d\ufe0f Tickets restaurant (10\u20ac)\n\ud83d\udcbb 15\u20ac de forfait t\u00e9l\u00e9phone rembours\u00e9s\n\ud83d\ude80 2 s\u00e9minaires annuels (mars et septembre)\n\ud83c\udf8a 10 \u00e9v\u00e8nements dans l\u2019ann\u00e9e (Christmas Party, Comedy Club, Team Buildings, ...)\n\ud83d\udcb5 R\u00e9mun\u00e9ration pour chaque cooptation (1000 \u20ac pour un CDI)\n\u2600\ufe0f Super mutuelle avec Alan\n\ud83c\udfe1 T\u00e9l\u00e9travail 3 jours par semaine\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "R",
                "Go"
            ],
            "DataBase": [],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [],
            "MachingLearning": [
                "TensorFlow",
                "PyTorch"
            ],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [
                "Statistiques"
            ],
            "CloudComputing": [],
            "DevTools": [],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [
                "ML",
                "Machine Learning",
                "Statistiques",
                "Cloud"
            ],
            "FrSoftSkills": [
                "R\u00e9solution de probl\u00e8mes",
                "Organisation"
            ],
            "EnSoftSkils": []
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [
                "CDI"
            ],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "Ing\u00e9nieur IA GENERATIVE (H/F) | POEI",
        "company": "DataScientest.com",
        "location": "Levallois-Perret, \u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/ing%C3%A9nieur-ia-generative-h-f-poei-at-datascientest-com-3910231319?position=3&pageNum=10&refId=95T5IhjHY6ggpolfwE5Syg%3D%3D&trackingId=4qW0LrWxNjEz8DXtZB0lfQ%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Ing\u00e9nieur IA GENERATIVE (H/F) | POEI\nLevallois-Perret\nCDI\nPostuler\nRetour\nDatascientest Is Hiring!\nIng\u00e9nieur IA GENERATIVE (H/F) | POEI\n\u00c0 propos\nChez DataScientest, ils sont convaincus que la transition des entreprises vers les Data Sciences, l\u2019Intelligence Artificielle et le Cloud, doit passer par la formation et l\u2019accompagnement des professionnels et des particuliers aux outils de demain !\nEn 7 ans, Datascientest est devenu le leader des formations en Data Science, en France.\nIls ont cr\u00e9\u00e9 5 cursus de formation aux m\u00e9tiers de Data Manager, Data Analyst, Data Scientist, ML Engineer et Data Engineer.\nAujourd\u2019hui plus de 30 groupes du CAC40 leur font confiance (TotalEnergies, Axa, Cr\u00e9dit Agricole, Michelin, Allianz\u2026), et ils ont form\u00e9 plus de 7 000,00 apprenants !\nDataScientest se positionne \u00e9galement sur les march\u00e9s Allemands et Espagnols avec l'ambition de devenir le leader europ\u00e9en du secteur.\nSon succ\u00e8s ?\nUn format p\u00e9dagogique hybride unique: l\u2019alliance d\u2019une plateforme d\u2019apprentissage con\u00e7ue par leurs data scientists et un suivi personnalis\u00e9.\nDes s\u00e9ances de coaching anim\u00e9es par des professeurs internalis\u00e9s de qualit\u00e9.\nUn studio de R&D performant.\nDes partenariats strat\u00e9giques (Microsoft, Amazon Web Services, MicroStrategy, OVHCloud\u2026),\nEt surtout LA MEILLEURE \u00c9QUIPE !\nDescriptif du poste\nVous \u00eates demandeur d'emploi et vivement int\u00e9ress\u00e9(e) par les m\u00e9tiers de la Data et de l'IA ?\nNous vous proposons un CDI pr\u00e9c\u00e9d\u00e9 d'une formation professionnalisante acc\u00e9l\u00e9r\u00e9e de 400h, dans le cadre d'une POEI\n(Pr\u00e9paration Op\u00e9rationnelle \u00e0 l'Emploi Individuel),\npour que vous soyez pleinement op\u00e9rationnel et 100% \u00e0 l'aise dans la mission qui vous sera confi\u00e9e.\nPour b\u00e9n\u00e9ficier du dispositif de la POEI, vous devez \u00eatre inscrit \u00e0 France Travail (ex. P\u00f4le Emploi).\nAssur\u00e9e par des professionnels reconnus, cette formation se d\u00e9roule sur une p\u00e9riode de 12 semaines. A l'issue de la formation et au sein de nos \u00e9quipes projets, vous \u00e9voluerez sur un\nposte d\u2019Ing\u00e9nieur IA G\u00e9n\u00e9rative (LLMOPS).\nLES MISSIONS\nEn Tant Qu'Ing\u00e9nieur IA G\u00e9n\u00e9rative, Vous Serez Charg\u00e9(e) De Proposer Les Meilleures Solutions \u00e0 L'entreprise En Leur Permettant D'optimiser Leur Activit\u00e9, \u00e0 Travers Quelques Missions Principales\nAvoir la bonne approche du NLP\nMaitriser les m\u00e9canismes d\u2019attention Transformers et LLM\nG\u00e9rer les cycles de vie et construire une App LLM\nAvoir une compr\u00e9hension approfondie des concepts de Prompt Engineering\nMaitriser la gestion du cycle de vie complet des projets de LLM avec MLflow et CometLLM\nUtiliser Docker pour la conteneurisation d'environnements utilisables via Kubernetes et g\u00e9rer l\u2019installation et la configuration de Kubeflow pour le machine learning dans Kubernetes.\nUtiliser des fonctionnalit\u00e9s de Vertex AI /Amazon Bedrock/ Mistral... pour le traitement du langage naturel (LLM)\nProfil recherch\u00e9\nVous \u00eates dipl\u00f4m\u00e9(e) au minimum d'un\nBac +5\net vous justifiez d'au moins\n2 \u00e0 3 ann\u00e9es d'exp\u00e9rience professionnelle en tant que Data Engineer ou Data scientist ou chercheur post doctorant \u00e0 la recherche de votre premier CDI\nAvantages \u00e0 Travailler Chez Notre Partenaire\nUne Acad\u00e9mie au service de votre mont\u00e9e en comp\u00e9tences (formations et certifications sur les technologies de pointe)\nUn accompagnement personnalis\u00e9 et un management de proximit\u00e9 pour vous proposer des \u00e9volutions de carri\u00e8re\nUne int\u00e9gration dans des communaut\u00e9s techniques et de pratiques (encadrement par des experts, \u00e9changes sur les bonnes pratiques, favoriser l'innovation...)\nUne entreprise reconnue \"Great Place To Work\"\nDes \u00e9v\u00e8nements et s\u00e9minaires inoubliables, des soir\u00e9es d'agence conviviales\nProcess de recrutement\nEchange t\u00e9l\u00e9phonique de pr\u00e9qualification RH\nPr\u00e9paration et envoi de votre candidature \u00e0 notre partenaire\nOrganisation d'un entretien en distanciel ou en pr\u00e9sentiel avec un manager technique et un membre des ressources humaines\nInformations compl\u00e9mentaires\nType de contrat : CDI\nLieu : Levallois-Perret\nNiveau d'\u00e9tudes : Bac +5 / Master\nExp\u00e9rience : > 2 ans\nT\u00e9l\u00e9travail ponctuel autoris\u00e9\nSalaire : entre 34000\u20ac et 40000\u20ac / an\nVous \u00eates int\u00e9ress\u00e9 par cette offre ?\nPostuler\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "R",
                "Go"
            ],
            "DataBase": [],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [],
            "DevTools": [
                "Docker"
            ],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [
                "Kubernetes"
            ],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [
                "Docker",
                "Kubernetes"
            ],
            "Collaboration": [],
            "Other": [
                "ML",
                "Machine Learning",
                "Cloud"
            ],
            "FrSoftSkills": [
                "Organisation"
            ],
            "EnSoftSkils": []
        },
        "details": {
            "JobDetail": [
                "Hybride"
            ],
            "TypeContract": [
                "CDI"
            ],
            "Salary": [
                "34000"
            ],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s",
                "7",
                "7",
                "7"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "Ing\u00e9nieur Machine Learning \u2013 Toulouse, France (H/F)",
        "company": "Astek",
        "location": "Toulouse, Occitanie, France",
        "link": "https://fr.linkedin.com/jobs/view/ing%C3%A9nieur-machine-learning-%E2%80%93-toulouse-france-h-f-at-astek-3882495207?position=4&pageNum=10&refId=95T5IhjHY6ggpolfwE5Syg%3D%3D&trackingId=CGad6fA8r8G8lVh7odfkYg%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "CDI\nToulouse - France\nPubli\u00e9e il y a 1 mois\nLe Groupe Astek\nCe Que Nous Allons Accomplir Ensemble :\nRejoignez nos \u00e9quipes et intervenons ensemble sur les projets de nos partenaires autour des enheux d\u2019innovation.\nVotre Mission, Si Vous L\u2019acceptez :\nCadrer techniquement les projets et accompagner les Data Scientists dans la construction des mod\u00e8les en veillant \u00e0 respecter les bonnes pratiques d\u2019ing\u00e9nierie logicielle.\nMettre en place la d\u00e9marche ML OPS\nD\u00e9ployer les mod\u00e8les en production en respectant des contraintes de co\u00fbts, pr\u00e9cisions et performances techniques.\nImpl\u00e9menter les outils permettant de monitorer ces mod\u00e8les en production\nVous ?\nVous \u00eates issu(e) d\u2019une formation Bac+5 (\u00c9cole d\u2019ing\u00e9nieur, Universit\u00e9 ou \u00e9quivalent \u2026) en informatique\nVous justifiez d\u2019une exp\u00e9rience significative d\u2019au moins 5 ans au sein d\u2019une \u00e9quipe dans un environnement Data \u00e0 l\u2019\u00e9chelle du SI d\u2019un grand groupe\nVous \u00eates un bon communiquant et disposez de capacit\u00e9s d\u2019analyse et de synth\u00e8se \u00e9prouv\u00e9es\nVous accordez de l\u2019importance \u00e0 la veille technologique\nComp\u00e9tences Techniques :\nExpertise en SPARK et PySpark\nConnaissance de Kubernetes\nConnaissance de d\u2019Apache Kafka\nUne exp\u00e9rience sur un cloud provider public comme Azure (id\u00e9alement), AWS, ou GCP\nExpertise de d\u00e9veloppement en Python\nExpertise du ML OPS\nComp\u00e9tences Transverses :\nCapacit\u00e9 \u00e0 interagir avec des parties prenantes diverses : Data Scientists, Business analyst, Architectes, M\u00e9tier\nForte exp\u00e9rience en mode de Delivery Agile (Scrum, Kanban, etc.\u2026)\nEtre expert dans les pratiques du Software Craftsmanship (Test Driven, Development, Behavior Driven Development, Clean Code, Code Reviews, etc.)\nEt :\nDes Connaissances sur Azure DevOps, Azure Pipeline, GIT\nMaitrise des Traitements Big Data en mode Streaming\nMaitrise des Bases de donn\u00e9es relationnelles et NoSQL\nUne exp\u00e9rience professionnelle avec des outils comme Azure Databricks, Azure, Machine Learning , Azure Data Lake Storage ou encore Azure Data Factory\nLe Groupe Astek\nCr\u00e9\u00e9 en France en 1988, Astek est un acteur mondial de l\u2019ing\u00e9nierie et du conseil en technologies. Fort de son expertise dans de nombreux secteurs industriels et tertiaires, Astek accompagne ses clients internationaux dans le d\u00e9ploiement intelligent de leurs produits et de leurs services, et dans la mise en \u0153uvre de leur transformation digitale.\nDepuis sa cr\u00e9ation, le Groupe a fond\u00e9 son d\u00e9veloppement sur une forte culture d\u2019entrepreneuriat et d\u2019innovation, et sur l\u2019accompagnement et la mont\u00e9e en comp\u00e9tence de\nses 7800 collaborateurs\nqui s\u2019engagent chaque jour \u00e0 promouvoir la compl\u00e9mentarit\u00e9 entre les technologies num\u00e9riques et l\u2019ing\u00e9nierie des syst\u00e8mes complexes.\nRejoignez un Groupe en fort d\u00e9veloppement en France et \u00e0 travers le monde ayant r\u00e9alis\u00e9 un chiffre d\u2019affaires de 600 M\u20ac en 2023.\nTous les d\u00e9tails sur le Groupe sur le site https://astekgroup.fr. Et vous pouvez aussi nous suivre sur notre blog : https://blog.groupeastek.com.\nRencontrons-nous\nNotre projet commun vous plait ?\nPostulez \u00e0 cette annonce, et soyez transparent !\nNotre Talent Acquisition Officer, vous contactera pour un premier \u00e9change t\u00e9l\u00e9phonique.\nPuis vous rencontrerez votre futur manager, avec lequel vous \u00e9changerez autour d\u2019Astek, de votre parcours, de vos attentes et de votre future mission .\nEnfin, vous rencontrerez notre Directeur de d\u00e9partement, avec lequel vous pourrez valider votre int\u00e9r\u00eat et ad\u00e9quation pour le poste et finaliser les \u00e9l\u00e9ments contractuels.\nNos Plus\nAstek est green et fait b\u00e9n\u00e9ficier ses salari\u00e9s d\u2019une indemnit\u00e9 kilom\u00e9trique v\u00e9lo\nUne politique CARE sur-mesure d\u00e9ploy\u00e9e par nos \u00e9quipes RH pour nos collaborateurs (https://astekgroup.fr/engagements)\nNotre charte de la Diversit\u00e9\nBienvenue dans la team ! Allez-y, maintenant c\u2019est \u00e0 vous de jouer !\nMots-cl\u00e9s :\ning\u00e9nieur \u2013 ing\u00e9nieure \u2013 consultant \u2013 consultante\nCaract\u00e9ristiques de l'emploi\nCat\u00e9gorie Chef de Projet\nJob Industry A\u00e9rospatial / D\u00e9fense / S\u00e9curit\u00e9, Distribution / Services Internet, Energie / Sciences de la Vie / Autres industries, Finance / Gouvernement, T\u00e9l\u00e9com / M\u00e9dia, Transports Terrestres\nPostuler en ligne\nNom *\nPr\u00e9nom *\nEmail *\nUn email valide est requis.\nT\u00e9l\u00e9phone *\nUn num\u00e9ro de t\u00e9l\u00e9phone valide est requis.\nJoindre un CV *\nMots-cl\u00e9s :\ning\u00e9nieur \u2013 ing\u00e9nieure \u2013 consultant \u2013 consultante\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "R",
                "Go"
            ],
            "DataBase": [
                "SQL",
                "NoSQL"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [
                "Spark",
                "Databricks"
            ],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [
                "AWS",
                "Azure"
            ],
            "DevTools": [
                "Git"
            ],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [
                "Apache Kafka"
            ],
            "Automation": [
                "Kubernetes",
                "Chef"
            ],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [
                "Kubernetes"
            ],
            "Collaboration": [],
            "Other": [
                "DevOps",
                "Big Data",
                "ML",
                "Machine Learning",
                "Cloud"
            ],
            "FrSoftSkills": [],
            "EnSoftSkils": []
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [
                "CDI"
            ],
            "Salary": [],
            "Level": [
                "Bac+5"
            ],
            "Experience": [
                "a",
                "n",
                "s",
                "5",
                "5",
                "5"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "DATA SCIENTIST EN ALTERNANCE F/H",
        "company": "STATION F",
        "location": "Paris, \u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/data-scientist-en-alternance-f-h-at-station-f-3866142994?position=5&pageNum=10&refId=95T5IhjHY6ggpolfwE5Syg%3D%3D&trackingId=vsqeTCuk8%2FZnICYm1zg7Zg%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "\u00c0 propos\nWalter Learning con\u00e7oit, produit et diffuse des formations en ligne \u00e0 destination des professionnels, sous plusieurs marques :\nWalter Learning : formations g\u00e9n\u00e9ralistes (HACCP, bureautique, web & digital, etc.) et formations longues (CAP...)\nWalter Sant\u00e9 : formations sp\u00e9cialis\u00e9es pour les m\u00e9decins, kin\u00e9s, infirmiers, dentistes, sages-femmes...\nLe pari de Walter Learning, c\u2019est de proposer un nouveau mod\u00e8le de formation professionnelle, offrant la flexibilit\u00e9 et la cr\u00e9ativit\u00e9 du e-learning, coupl\u00e9es \u00e0 la rigueur et la justesse attendues par les professionnels.\nLeur Savoir-faire Se Situe Dans L\u2019alliance Des Sciences De L\u2019\u00e9ducation, Du Digital Et De L\u2019audiovisuel. Walter Learning C\u2019est\nDes formations denses, o\u00f9 chaque mot est pes\u00e9,\nDes formateurs reconnus ;\nUne plateforme d\u2019apprentissage cod\u00e9e-maison, facile d\u2019utilisation ;\nUn apprentissage souple, sans contraintes ;\nUn support apprenants aux petits soins.\nWalter Learning a commenc\u00e9 \u00e0 commercialiser son produit en mai 2019. Depuis, l\u2019entreprise a d\u00e9montr\u00e9 une croissance tr\u00e8s forte, sur un march\u00e9 gigantesque, puisqu'elle a vendu plus de 80 000 formations \u00e0 fin 2023. Walter Learning est autofinanc\u00e9e et rentable.\nDescriptif du poste\nWalter Learning recherche pour le compte des d\u00e9partements IT de ses partenaires, des data scientists en alternance.\nLes Missions Sont Les Suivantes\nTraiter les donn\u00e9es et construire et entra\u00eener des algorithmes\nElaborer des mod\u00e8les pr\u00e9dictifs\nFournir des outils d'aide \u00e0 la d\u00e9cision et recommendations strat\u00e9giques aux \u00e9quipes m\u00e9tiers\nLes Comp\u00e9tences Que Vous Allez D\u00e9velopper\nCompr\u00e9hension des enjeux business & marketing\nAisance avec les donn\u00e9es chiffr\u00e9es et la mod\u00e9lisation de donn\u00e9es\nLangages de programmation et de requ\u00eatage\nForte orientation business et use cases\nModalit\u00e9s De L\u2019alternance\nContrat de 12 mois\n1 jour par semaine en formation\nR\u00e9mun\u00e9ration en fonction de votre profil\nProfil recherch\u00e9\nPas de dipl\u00f4me requis\nForte app\u00e9tence pour les outils informatiques et les chiffres\nInformations compl\u00e9mentaires\nType de contrat : Alternance (12 \u00e0 12 mois)\nLieu : Paris\nNiveau d'\u00e9tudes : Sans dipl\u00f4me\nExp\u00e9rience :\nSalaire : entre 760\u20ac et 1760\u20ac / an\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "R",
                "Go"
            ],
            "DataBase": [],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [],
            "DevTools": [
                "Git"
            ],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [],
            "FrSoftSkills": [
                "Cr\u00e9ativit\u00e9",
                "Flexibilit\u00e9"
            ],
            "EnSoftSkils": []
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [],
            "Salary": [
                "760"
            ],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "Data Scientist F/H",
        "company": "Orange",
        "location": "France",
        "link": "https://fr.linkedin.com/jobs/view/data-scientist-f-h-at-orange-3905556668?position=6&pageNum=10&refId=95T5IhjHY6ggpolfwE5Syg%3D%3D&trackingId=GpBU4JqYRPY0kcNLjMgnpg%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Et si Business & D\u00e9cision et le groupe Orange conjuguaient leurs forces pour devenir l'un des leaders europ\u00e9ens de la Data transformation ?\nNous l'avons fait ! Notre alchimie nous positionne comme un acteur unique intervenant sur toutes les \u00e9tapes du voyage de la donn\u00e9e.\nBusiness & D\u00e9cision en croissance sur l'ann\u00e9e 2021, continue sur sa lanc\u00e9e avec un nouvel objectif de plus de 500 recrutements de profils #DataSpecialist.\nNous intervenons sur l'ensemble du cycle de vie des projets de clients du CAC40 :\nD\u00e8s la phase de r\u00e9flexion d'un projet, en passant par le management consulting, le cadrage, les \u00e9tudes m\u00e9tiers, le cadrage de l'architecture, jusqu'au run, et expertises.\nNous formons et certifions r\u00e9guli\u00e8rement nos consultants sur les technologies du march\u00e9 ; la formation \u00e9tant l'une de nos priorit\u00e9s afin de vous accompagner dans le d\u00e9veloppement de vos comp\u00e9tences et vos perspectives d'\u00e9volutions.\nNous recherchons aujourd'hui, un Data Scientist afin d'intervenir chez nos clients pour les accompagner sur les missions suivantes\u00a0:\n- Analyse et cadrage des besoins m\u00e9tiers,\n- Pr\u00e9paration des donn\u00e9es,\n- Choix des algorithmes \u00e0 mettre en oeuvre,\n- Programmation et d\u00e9veloppement,\n- Interpr\u00e9tation des r\u00e9sultats,\n- Mise en production,\n- Veille technologique,\nEn tant que Data Scientist expert, vous \u00eates capable de\u00a0manipuler une grande quantit\u00e9 de bases de donn\u00e9es et de sources,\u00a0quels que soit leurs formats, de mettre en oeuvre les algorithmes n\u00e9cessaires, de prendre de la hauteur par rapport aux r\u00e9sultats obtenus, et d'assurer une interaction avec le client sur les r\u00e9sultats obtenus.\nDe formation Bac +5 en Math\u00e9matiques, Statistiques ou IT\nVous maitrisez au moins un des langages de programmation suivants : Python, R, Scala, SQL, ... Vous avez des notions sur les solutions de studios Data Science (KNIME, Dataiku, H2O, Alteryx, SAS, SPSS, ...) et sur les environnements Cloud (Azure, AWS, GCP).\nVous avez d\u00e9j\u00e0 travaill\u00e9 sur des probl\u00e9matiques de type\u00a0: Machine Learning, Deep Learning, Time Series, Clustering, Anomly detection,\nUn int\u00e9r\u00eat ou une premi\u00e8re exp\u00e9rience sur les sujets d'IA G\u00e9n\u00e9rative est un plus.\nRef : 20521918\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "Scala",
                "R",
                "Go"
            ],
            "DataBase": [
                "SQL"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [],
            "MachingLearning": [
                "Orange"
            ],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [
                "Statistiques"
            ],
            "CloudComputing": [
                "AWS",
                "Azure"
            ],
            "DevTools": [],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [
                "ML",
                "Machine Learning",
                "Statistiques",
                "Cloud"
            ],
            "FrSoftSkills": [],
            "EnSoftSkils": []
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "Data Scientist - France, Paris",
        "company": "Dataiku",
        "location": "Paris, \u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/data-scientist-france-paris-at-dataiku-3834882798?position=7&pageNum=10&refId=95T5IhjHY6ggpolfwE5Syg%3D%3D&trackingId=fO1YQR1hy3Bv%2FWziSyZpHg%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "At Dataiku, we're not just adapting to the AI revolution, we're leading it. Since our beginning in Paris in 2013, we've been pioneering the future of AI with a platform that makes data actionable and accessible. With over 1,000 teammates across 25 countries and backed by a renowned set of investors, we're the architects of Everyday AI, enabling data experts and domain experts to work together to build AI into their daily operations, from advanced analytics to Generative AI.\nHeadquartered in New York City, Dataiku was founded in Paris in 2013 and achieved unicorn status in 2019. Now, more than 1,300 employees work across the globe in our offices and remotely. Backed by a renowned set of investors and partners including CapitalG, Tiger Global, and ICONIQ Growth, we\u2019ve set out to build the future of AI.\nThe role of a Data Scientist at Dataiku is unique. Our Data Scientists not only develop solutions to real-world problems but also participate in client-facing endeavors throughout the customer journey. This includes supporting their discovery of the platform, helping integrate Dataiku with other tools and technologies, providing user training, and co-developing data science projects from design to deployment.\nJust as the non-technical skills are important, so too are the technical. Our Data Scientists work on the Dataiku platform daily. Aside from the visual tools, our team uses mostly Python, with occasional work in other languages (e.g., R, SQL, Pyspark, JavaScript, etc.). An ideal candidate is excited to teach data science and how to use the Dataiku platform to customers, and learn about new technologies.\nHow you'll make an impact\nHelp users discover and master the Dataiku platform, via user training, office hours, demos, and ongoing consultative support.\nAnalyze and investigate various kinds of data and machine learning applications across industries and use cases.\nProvide strategic input to the customer and account teams that help make our customers successful.\nScope and co-develop production-level data science projects with our customers.\nMentor and help educate data scientists and other customer team members to aid in career development and growth.\nWhat you'll need to be successful\nCuriosity and a desire to learn new technical skills.\nEmpathy and an eagerness to share your knowledge with your colleagues, Dataiku\u2019s customers, and the general public.\nAbility to clearly explain complex topics to technical as well as non-technical audiences.\nOver 3 years of experience with coding (Python, R, SQL).\nOver 3 years of experience building ML models.\nUnderstanding of underlying data systems and platform mechanics such as Cloud architectures, K8S, Spark, and SQL.\nWhat will make you stand out\nExperience with Consulting and/or Customer-facing Data Science roles.\nExperience with Data Engineering or MLOps.\nExperience developing WebApps in Javascript, RShiny, or Dash.\nExperience building APIs.\nExperience using enterprise data science tools.\nPassion for teaching or public speaking.\nBenefits\nExposure to a wide range of enterprise customers across industries. Examples of Dataiku\u2019s hundreds of customers include GE, Unilever, Comcast, Ubisoft, OVH, Santander, and Capgemini.\nA wide diversity of projects.\nOpportunity to contribute to the core vision of our company and product: simplify and democratize the way people work with data and use Artificial Intelligence.\nExposure to the latest, open-source technologies that Dataiku integrates. See our release notes for our latest developments: https://doc.dataiku.com/dss/latest/release_notes/index.html\nOpportunity to work with a smart, passionate, and driven team in hypergrowth mode.\nDataiku has a strong culture based on key values: Transparency, Ambition, Excellence, Humility, and Empathy.\nWhat are you waiting for!\nAt Dataiku, you'll be part of a journey to shape the ever-evolving world of AI. We're not just building a product; we're crafting the future of AI. If you're ready to make a significant impact in a company that values innovation, collaboration, and your personal growth, we can't wait to welcome you to Dataiku! And if you\u2019d like to learn even more about working here, you can visit our Dataiku LinkedIn page .\nOur practices are rooted in the idea that everyone should be treated with dignity, decency and fairness. Dataiku also believes that a diverse identity is a source of strength and allows us to optimize across the many dimensions that are needed for our success. Therefore, we are proud to be an equal opportunity employer. All employment practices are based on business needs, without regard to race, ethnicity, gender identity or expression, sexual orientation, religion, age, neurodiversity, disability status, citizenship, veteran status or any other aspect which makes an individual unique or protected by laws and regulations in the locations where we operate. This applies to all policies and procedures related to recruitment and hiring, compensation, benefits, performance, promotion and termination and all other conditions and terms of employment. If you need assistance or an accommodation, please contact us at: reasonable-accommodations@dataiku.com\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "Java",
                "R",
                "Go",
                "JavaScript",
                "HTML"
            ],
            "DataBase": [
                "SQL"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [
                "Spark"
            ],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [
                "AWS"
            ],
            "DevTools": [],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [
                "Teams"
            ],
            "Other": [
                "ML",
                "Machine Learning",
                "Cloud"
            ],
            "FrSoftSkills": [
                "Collaboration"
            ],
            "EnSoftSkils": [
                "Empathy",
                "Collaboration"
            ]
        },
        "details": {
            "JobDetail": [
                "Remote"
            ],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "Software Engineer",
        "company": "TekSynap",
        "location": "Us, \u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/software-engineer-at-teksynap-3915308799?position=8&pageNum=10&refId=95T5IhjHY6ggpolfwE5Syg%3D%3D&trackingId=Uew%2BdJYigH2sWesQ9ThtlQ%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "BOEM and BSEE are responsible for managing the nation\u2019s offshore energy, minerals, and natural resources on the Federal Outer Continental Shelf (OCS). BSEE promotes safety, protects the environment, and conserves resources offshore through vigorous regulatory oversight and enforcement. BOEM manages the responsible exploration and development of offshore energy and marine mineral resources on the OCS. OCS production accounts for about 18 percent of domestic crude oil and four percent of domestic natural gas supply.\nResponsibilities\nConduct meetings with Stakeholders to clarify and understand business requirements\nCreate, design, update, document and implement logical and physical database changes.\nDesign and implement design solutions based on industry best practices.\nUtilize existing SOA services where feasible. build new SOA services, APIs and microservices when applicable and ensure the code is modular, re-usable, and portable.\nModify or write new on-line programs, unit test cases, batch programs, interfaces, configuration changes, and reports. Build unit tests and integration tests as necessary.\nEnsure proper exception handling and appropriate logging.\nIdentify and resolve information assurance weaknesses and vulnerabilities.\nPerform peer code reviews and ensure automation build failures resulting from code issues are resolved.\nCollaborate closely with end users and administrators to gain an understanding of their data needs, proactively optimize database performance, and uphold data quality standards.\nDocument database architecture, configurations, and processes to ensure that knowledge is well-documented and can be easily transferred to other team members.\nDevelop and maintain Extract, Transform, Load (ETL) processes to move, transform, and load data from various sources into the database, ensuring data consistency and quality.\nFormulates/defines system scope and objectives.\nDevises or modifies procedures to solve complex problems considering computer equipment capacity and limitations.\nPrepares detailed specifications from which programs will be written.\nDesigns, codes, tests, debugs, and documents programs.\nParticipates in related areas, such as such as design, implementation, integration, management, and maintenance of complex databases, with respect to the operating system, access methods, access time, device allocation, validation checks, organization, protection and security, documentation, guidelines, and statistical methods\nEvaluation of commercial off-the-shelf (COTS) products\nAnalysis of hardware/software issues.\nMay provide guidance to other developers.\nRequired Qualifications\nFive years of technical experience in applications software development, three of which are in systems analysis, and 1 year of which is acting as technical lead.\nKnowledge of software languages such as HTML, Python, PL/SQL, SQL, C#, Perl or other languages.\nCompetent to work at a high level for all phases of system/database development.\nBachelor\u2019s degree in Engineering/Computer Science or area related to the project\u2019s functional requirement.\nDOI Background Investigation, Entry on Duty\nDesired Qualifications\nUse OF proven, efficient methodologies to support the Oracle and Structured Query Language (SQL) databases\nExperience in design and development of comprehensive database schemas, encompassing tables, views, indexes, triggers, stored procedures, functions, and other essential objects.\nExperience optimizing SQL queries and integrating data across various systems and applications.\nExperience developing and maintaining Extract, Transform, Load (ETL) processes to move, transform, and load data from various sources into the database, ensuring data consistency and quality.\nWe are seeking a Software Engineer to join our team supporting DOI BSEE TIMS contract in New Orleans, LA.\nTekSynap is a fast growing high-tech company that understands both the pace of technology today and the need to have a comprehensive well planned information management environment. \u201cTechnology moving at the speed of thought\u201d embodies these principles \u2013 the need to nimbly utilize the best that information technology offers to meet the business needs of our Federal Government customers.\nWe offer our full-time employees a competitive benefits package to include health, dental, vision, 401K, life insurance, short-term and long-term disability plans, vacation time and holidays.\nVisit us at www.TekSynap.com.\nApply now to explore jobs with us!\nThe safety and health of our employees is of the upmost importance. Employees are required to comply with any contractually mandated Federal COVID-19 requirements. More information can be found here.\nBy applying to a role at TekSynap you are providing consent to receive text messages regarding your interview and employment status. If at any time you would like to opt out of text messaging, respond \"STOP\".\nCOMPETENCIES\nEstablish Focus\nChange Management\nDevelop Others\nOral Communication\nWritten Communication\nInterpersonal Awareness\nBuild Relationships\nAnalytical Thinking\nConceptual Thinking\nStrategic Thinking\nTechnical Expertise\nInitiative\nFoster Innovation\nResults Oriented\nTeamwork\nCustomer Service\nWORK ENVIRONMENT AND PHYSICAL DEMANDS\nThe work environment characteristics described here are representative of those an employee encounters while performing the essential functions of the job. Reasonable accommodation may be made to enable individuals with disabilities to perform the essential functions.\nLocation New Orleans, LA\nType of environment Office, Telework may be available\nNoise level (Low-Medium)\nWork schedule Schedule is day shift Monday \u2013 Friday. May be requested to work evenings and weekends to meet program and contract needs.\nAmount of Travel Less than 10%\nPHYSICAL DEMANDS\nThe physical demands described here are representative of those that must be met by an employee to successfully perform the essential functions of this job. Reasonable accommodations may be made to enable individuals with disabilities to perform the essential functions.\nWhile performing the duties of this job, the employee is regularly required to use hands to handle, feel, touch; reach with hands and arms; talk and hear. The employee is regularly required to stand; walk; sit; climb or balance; and stoop, kneel, crouch, or crawl. The employee is regularly required to lift up to 10 pounds. The employee is frequently required to lift up to 25 pounds; and up to 50 pounds. The vision requirements include close vision, distance vision, peripheral vision, depth perception, and ability to adjust focus.\nWORK AUTHORIZATION/SECURITY CLEARANCE\nPositions require a DOI Entrance on Duty (EOD)\nOther Duties\nPlease note this job description is not designed to cover or contain a comprehensive listing of activities, duties or responsibilities that are required of the employee for this job. Duties, responsibilities and activities may change at any time with or without notice.\nEQUAL EMPLOYMENT OPPORTUNITY\nIn order to provide equal employment and advancement opportunities to all individuals, employment decisions will be based on merit, qualifications, and abilities. TekSynap does not discriminate against any person because of race, color, creed, religion, sex, national origin, disability, age, genetic information or any other characteristic protected by law (referred to as \u201cprotected status\u201d). This nondiscrimination policy extends to all terms, conditions, and privileges of employment as well as the use of all company facilities, participation in all company-sponsored activities, and all employment actions such as promotions, compensation, benefits, and termination of employment.\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "C#",
                "R",
                "Go",
                "HTML"
            ],
            "DataBase": [
                "SQL"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [],
            "DevTools": [],
            "Os": [],
            "DBMS": [
                "Oracle"
            ],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [
                "ML"
            ],
            "FrSoftSkills": [
                "Communication"
            ],
            "EnSoftSkils": [
                "Communication",
                "Teamwork",
                "Organization",
                "Initiative"
            ]
        },
        "details": {
            "JobDetail": [
                "Full"
            ],
            "TypeContract": [],
            "Salary": [
                "401K"
            ],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "Data Scientist H/F",
        "company": "Harry Hope.",
        "location": "Nancy, Grand Est, France",
        "link": "https://fr.linkedin.com/jobs/view/data-scientist-h-f-at-harry-hope-3917429026?position=9&pageNum=10&refId=95T5IhjHY6ggpolfwE5Syg%3D%3D&trackingId=snv4Ww%2BqN3ZyrzJ2S2xAZw%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Jean, consultant sp\u00e9cialis\u00e9 sur les m\u00e9tiers de l'IT sur la lorraine au sein du cabinet de recrutement Harry Hope accompagne les candidats dans leurs recherches d'une meilleure opportunit\u00e9 professionnelle sur leur secteur g\u00e9ographique privil\u00e9gi\u00e9. Nous ne sommes pas une ESN, nous intervenons dans la mise en relation avec des clients finaux sur des postes en CDI. Notre client, une soci\u00e9t\u00e9 en pleine croissance dans le secteur de l'IA, recherche un Data Scientist (H/F) pour compl\u00e9ter son \u00e9quipe d\u00e9di\u00e9e.\nInt\u00e9gr\u00e9 \u00e0 une \u00e9quipe technique compos\u00e9e de Data scientist, de d\u00e9veloppeurs et de chercheurs, vous aurez l'occasion d'intervenir dans la r\u00e9cup\u00e9ration, l'exploitation, la mod\u00e9lisation, l'\u00e9valuation et l'interpr\u00e9tation de donn\u00e9es stock\u00e9es dans les bases de donn\u00e9es de la structure permettant de les exploiter selon les besoins. En parall\u00e8le de vos missions concernant les donn\u00e9es propre \u00e0 l'activit\u00e9 principale de l'entreprise, vous intervenez \u00e9galement dans l'exploitation et la structuration des datas r\u00e9cup\u00e9r\u00e9es sur internet en lien avec l'IA en cours de d\u00e9veloppement.\nDipl\u00f4m\u00e9 en informatique, vous disposez \u00e0 minima d'une premi\u00e8re exp\u00e9rience \u00e0 un poste similaire (alternance ou premier emploi). Techniquement, vous avez une grande expertise en statistiques et en math\u00e9matiques appliqu\u00e9es. Vous maitrisez les domaines du Big Data, du machine learning et de la programmation informatique (Python, Java, R, SQL). Humainement, vous \u00eates reconnu pour votre dynamisme, votre flexibilit\u00e9 et votre engagement. Vous \u00eates capable de vous impliquer \u00e0 fond dans les projets qui vous sont confi\u00e9s et vous appr\u00e9ciez le travail collaboratif. Passionn\u00e9 par la Data, vous assurez une veille constante sur les nouvelles technologies en lien avec votre activit\u00e9. Enfin, vous maitrisez l'anglais \u00e0 l'oral comme \u00e0 l'\u00e9crit.\nInformations compl\u00e9mentaires : Salaire selon profil et exp\u00e9riences (38/42kEUR), possibilit\u00e9 d'\u00e9voluer rapidement, CDI \u00e0 pouvoir rapidement \u00e0 Nancy.\nSi cette opportunit\u00e9 correspond \u00e0 vos aspirations professionnelles alors faites-moi parvenir votre candidature. J'\u00e9tudierai cette derni\u00e8re et reviendrai vers vous dans les meilleurs d\u00e9lais pour un suivi personnalis\u00e9 de votre profil !\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "Java",
                "R"
            ],
            "DataBase": [
                "SQL"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [
                "Statistiques"
            ],
            "CloudComputing": [],
            "DevTools": [],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [
                "Big Data",
                "Machine Learning",
                "Statistiques"
            ],
            "FrSoftSkills": [
                "Flexibilit\u00e9"
            ],
            "EnSoftSkils": []
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [
                "CDI"
            ],
            "Salary": [
                "38"
            ],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "Data Scientist",
        "company": "DxO Labs",
        "location": "Boulogne-Billancourt, \u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/data-scientist-at-dxo-labs-3915441544?position=10&pageNum=10&refId=95T5IhjHY6ggpolfwE5Syg%3D%3D&trackingId=THWgNCJAFK3FSQXIel7eHQ%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "En 20 ans, DxO Labs s\u2019est affirm\u00e9e comme l\u2019une des entreprises fran\u00e7aises les plus innovantes du secteur de la photographie num\u00e9rique et du traitement d\u2019image.\nNous concevons et commercialisons des logiciels d\u2019\u00e9dition photo avanc\u00e9e pour les photographes, amateurs ou experts. Nos solutions, issues de l\u2019excellence et du savoir-faire incomparable de nos \u00e9quipes d\u2019experts internationales et multiculturelles, offrent les outils de correction et de traitement les plus performants.\nDxO Labs s\u2019appuie depuis toujours sur l\u2019excellence et le savoir-faire incomparable de ses \u00e9quipes d\u2019experts internationales et multiculturelles.\nSi vous souhaitez vous projeter et d\u00e9couvrir nos produits; cliquez sur https://www.dxo.com/fr/\nAfin de renforcer notre \u00e9quipe R&D, nous recrutons, dans le cadre d\u2019un contrat en CDI plein temps un\nData Scientist\nBas\u00e9 \u00e0 notre si\u00e8ge social de Boulogne-Billancourt et rapportant au Directeur Traitement Images.\nAu sein de notre \u00e9quipe R&D Image et en \u00e9troite collaboration avec nos \u00e9quipes UX et produit, votre r\u00f4le sera de nous aider \u00e0 doter nos logiciels fonctionnalit\u00e9s IA innovantes bas\u00e9es sur l\u2019analyse d\u2019une grande quantit\u00e9 de donn\u00e9es.\nVos missions :\nAvec nos product managers et nos chercheurs en traitement d\u2019image, d\u00e9finir de nouvelles fonctionnalit\u00e9s utilisateur.\nConstituer les bases d\u2019apprentissage n\u00e9cessaires.\nConcevoir, impl\u00e9menter et entrainer des mod\u00e8les de deep learning.\nEvaluer ces mod\u00e8les gr\u00e2ce \u00e0 des prototypes.\nAider nos experts logiciel \u00e0 int\u00e9grer ces nouvelles fonctionnalit\u00e9s utilisateur dans nos produits.\n\u00catre au fait des derni\u00e8res recherches et m\u00e9thodes au croisement entre la data science, la vision par ordinateur et la retouche photo.\nVotre profil :\nAu moins 5 ans d'exp\u00e9rience en tant que Data Scientist, de pr\u00e9f\u00e9rence dans le secteur technologique ou des logiciels\nDeep learning (connaissances \u00e0 jour par rapport \u00e0 l\u2019\u00e9tat de l\u2019art en 2024)\nPython, PyTorch\nAu moins B2 en Anglais et Fran\u00e7ais\nCapacit\u00e9 \u00e0 travailler de mani\u00e8re autonome et en \u00e9quipe, avec un esprit curieux et tourn\u00e9 innovation\nId\u00e9alement\nConnaissance en Traitement d\u2019image (p.ex. analyse s\u00e9mantique, g\u00e9n\u00e9ration d'images)\nTraitement de la langue (LLM)\nTensorFlow, AWS, WinML, CoreML, C++\nUn vrai + : Passionn\u00e9 de photographie\nSi vous vous retrouvez dans le descriptif candidat : Postulez sans attendre sur recruit@dxo.com\nNous verrons ensemble si vos comp\u00e9tences et votre savoir-\u00eatre correspondent \u00e0 notre ADN\nLocalisation :\nBas\u00e9 \u00e0 Boulogne-Billancourt (M\u00e9tro 9 station Billancourt \u2013 Tramway T2 station Les Moulineaux),\nT\u00e9l\u00e9travail possible \u00e0 hauteur de 2j/semaine\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "C++",
                "R"
            ],
            "DataBase": [],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [],
            "MachingLearning": [
                "TensorFlow",
                "PyTorch"
            ],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [
                "AWS"
            ],
            "DevTools": [],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [
                "ML"
            ],
            "FrSoftSkills": [
                "Collaboration"
            ],
            "EnSoftSkils": [
                "Collaboration"
            ]
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [
                "CDI"
            ],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s",
                "20",
                "20",
                "20"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "Stage - Data Scientist (H/F)",
        "company": "Equancy |\u00a0Groupe EDG",
        "location": "Paris, \u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/stage-data-scientist-h-f-at-equancy-%C2%A0groupe-edg-3911741622?position=1&pageNum=12&refId=VZ0t85WXynm0JJPlCprWOg%3D%3D&trackingId=q8lbv7YeGnGPlFWpF4v7Zg%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Equancy\nest un cabinet de conseil international, bas\u00e9 \u00e0 Paris et Duba\u00ef, sp\u00e9cialis\u00e9 dans la transformation data des entreprises.\nNous planifions, concevons et mettons en \u0153uvre des solutions Big Data, Data Science et Intelligence Artificielle pour nos clients. Nos projets vont de la mise en \u0153uvre d\u2019infrastructures sp\u00e9cialis\u00e9es dans le traitement de la donn\u00e9e de nos clients, de lacs de donn\u00e9es jusqu\u2019au d\u00e9veloppement de syst\u00e8mes op\u00e9rationnels int\u00e9grant des algorithmes de\nmachine learning\nou de\ndeep learning\n. Nous sommes experts dans l\u2019industrialisation de ces plates-formes, en appliquant les principes du devops \u00e0 nos infrastructures data.\nNos clients sont de grands groupes fran\u00e7ais et internationaux (LVMH, Picard, Chanel VINCI, Volkswagen). Ils nous font confiance autant dans l\u2019accompagnement au cadrage de leurs besoins que dans la r\u00e9alisation des solutions data innovantes\nAfin d\u2019accompagner la croissance de son activit\u00e9, Equancy recherche un Stagiaire Data Scientist Junior (H/F) pour int\u00e9grer sa Practice data.\nDans ce cadre :\nVous participez \u00e0 la compr\u00e9hension du besoin m\u00e9tier et \u00e0 la d\u00e9finition de l\u2019approche de data science, encadr\u00e9 par un data scientist senior ou expert : donn\u00e9es \u00e0 utiliser, pr\u00e9parations n\u00e9cessaires, approche algorithmique et de mod\u00e9lisation, \u00e9valuation des performances, optimisation des param\u00e8tres, it\u00e9rations pour am\u00e9liorer;\nVous r\u00e9alisez les analyses n\u00e9cessaires \u00e0 une bonne prise en charge des donn\u00e9es \u00e0 disposition, contr\u00f4lez la coh\u00e9rence, validez leur lecture;\nVous d\u00e9veloppez les traitements en Python (essentiellement) pour pr\u00e9parer les donn\u00e9es, entra\u00eener et optimiser les mod\u00e8les de data science (statistiques, machine learning, deep learning), \u00e9valuer et valider leur performance;\nLe cas \u00e9ch\u00e9ant, en cas de fortes volum\u00e9tries, vous travaillez en pyspark;\nVous pourriez avoir \u00e0 d\u00e9velopper des interfaces de visualisation et d\u2019interaction avec les mod\u00e8les d\u00e9velopp\u00e9s (dash);\nVous participez \u00e0 l\u2019industrialisation (MLOps) des mod\u00e8les qui sont mis en production et interagissez avec l\u2019\u00e9quipe de data engineering ; Vous \u00e9voluez dans des \u00e9quipes fonctionnant en m\u00e9thode Agile;\nVous documentez vos travaux et vos analyses;\nVous participez \u00e0 la r\u00e9daction des restitutions et pr\u00e9sentations des travaux r\u00e9alis\u00e9s aupr\u00e8s des commanditaires (internes ou clients).\nProfil recherch\u00e9:\nDe formation Bac+4/5 type Ecole d\u2019ing\u00e9nieur ou universit\u00e9 en Informatique;\nVous maitrisez Python et ses modules de data science (pandas, sklearn, seaborn, dash);\nVous connaissez les techniques de pr\u00e9paration de donn\u00e9es, cr\u00e9ation de features;\nVous connaissez les algorithmes de statistiques, machine learning et deep learning;\nVous vous int\u00e9ressez particuli\u00e8rement \u00e0 l\u2019industrialisation, au passage \u00e0 l\u2019\u00e9chelle de mod\u00e8les de data science, au-del\u00e0 d\u2019une approche exp\u00e9rimentale de la data science;\nVous avez envie de conna\u00eetre les environnements cloud (Google Cloud, Amazon Web Services, MS Azure);\nVous aimez travailler en \u00e9quipe;\nVous \u00eates r\u00e9actif, avec le sens du service, vous justifiez de bonnes capacit\u00e9s d\u2019\u00e9coute, d\u2019un bon relationnel et d\u2019une bonne gestion du stress;\nVous \u00eates curieux, autonome et proactif.\nEquancy c'est aussi :\nUn cadre de travail :\n\u00b7 Superbes locaux au c\u0153ur de Paris : Espace WeWork Jules Lefebvre, \u00e0 cot\u00e9 de Saint Lazare, au sein d\u2019un b\u00e2timent historique, avec de grands espaces et vue panoramique sur tout Paris;\n\u00b7 Equilibre vie pro / vie perso;\n\u00b7 Une politique de t\u00e9l\u00e9travail de deux jours par semaine;\n\u00b7 \u00c9quipement pour travailler en remote + participation aux frais du t\u00e9l\u00e9travail (allocation mensuelle);\n\u00b7 Engagement environnemental;\n\u00b7 Des activit\u00e9s sportives propos\u00e9es\n\u00b7 Une conciergerie propos\u00e9e par We Work.\nEnvironnement de travail stimulant, proximit\u00e9 forte avec les directeurs et les associ\u00e9s ;\n\u00c9quipe dynamique, passionn\u00e9e et internationale.\nL\u2019aventure vous tente ? \u00c9crivez-nous !\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "R",
                "Go"
            ],
            "DataBase": [],
            "DataAnalytics": [
                "Pandas",
                "R"
            ],
            "BigData": [
                "Spark"
            ],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [
                "Seaborn"
            ],
            "Statistics": [
                "Statistiques"
            ],
            "CloudComputing": [
                "Azure"
            ],
            "DevTools": [],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [
                "DevOps",
                "Big Data",
                "ML",
                "Machine Learning",
                "Statistiques",
                "Cloud"
            ],
            "FrSoftSkills": [
                "Gestion du stress"
            ],
            "EnSoftSkils": []
        },
        "details": {
            "JobDetail": [
                "Remote",
                "Junior",
                "Senior"
            ],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "Data Scientist F/H",
        "company": "ANSSI - Agence nationale de la s\u00e9curit\u00e9 des syst\u00e8mes d'information",
        "location": "Paris, \u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/data-scientist-f-h-at-anssi-agence-nationale-de-la-s%C3%A9curit%C3%A9-des-syst%C3%A8mes-d-information-3908568608?position=2&pageNum=12&refId=VZ0t85WXynm0JJPlCprWOg%3D%3D&trackingId=CPze%2Fp6VNxwNj%2BWlur5ePw%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "T\u00e9l\u00e9charger en PDF\nDescriptif de l'organisation\nRejoindre l\u2019Agence nationale de la s\u00e9curit\u00e9 des syst\u00e8mes d\u2019information (ANSSI), c\u2019est mettre ses comp\u00e9tences au service de l\u2019int\u00e9r\u00eat g\u00e9n\u00e9ral en participant \u00e0 une mission capitale, d\u2019actualit\u00e9 et porteuse de grandes responsabilit\u00e9s dans un monde o\u00f9 la cybers\u00e9curit\u00e9 est devenue l\u2019affaire de tous !\nAu sein de la Sous-direction-Op\u00e9ration (SDO), se trouve la division-d\u00e9tection (DD) dont le bureau Dispositifs de D\u00e9tection Syst\u00e8me (DDS) met en \u0153uvre la capacit\u00e9 de d\u00e9tection syst\u00e8me, c\u2019est-\u00e0-dire l\u2019ensemble des proc\u00e9d\u00e9s adapt\u00e9s \u00e0 la caract\u00e9risation d\u2019activit\u00e9s malveillantes \u00e0 partir d\u2019\u00e9v\u00e8nements g\u00e9n\u00e9r\u00e9s au niveau des syst\u00e8mes d\u2019exploitation.\nDescriptif des missions\nEn s\u2019appuyant sur les connaissances des ing\u00e9nieurs en cyberd\u00e9fense, vous \u00eates responsable des algorithmes de d\u00e9tection, de la phase de conception \u00e0 la mise en production. Vous avez \u00e0 votre disposition les donn\u00e9es collect\u00e9es par le bureau, issues de journaux d\u2019\u00e9v\u00e9nements de postes de travail ou de serveurs (Windows Security, Sysmon, Auditd\u2026).\nV\u00e9ritable r\u00e9f\u00e9rent au sein de l'\u00e9quipe, vous \u00eates est en mesure de proposer et tester de nouvelles id\u00e9es en liens avec des probl\u00e9matiques concr\u00e8tes, d'am\u00e9liorer des algorithmes existant, mais aussi d'accompagner les analystes dans l'interpr\u00e9tation des r\u00e9sultats.\nLe Caract\u00e8re Op\u00e9rationnel Des Missions Assur\u00e9es Par Le Bureau N\u00e9cessite Que Les Travaux Men\u00e9s R\u00e9pondent \u00e0 Un Fort Enjeu D'exploitabilit\u00e9. A Cette Fin, L\u2019agent Data-Scientiste Aura Pour Missions De\nProposer et mettre en place des algorithmes de d\u00e9tection d\u2019intrusions ;\nAssurer une veille des derniers papiers de recherche sur les sujets de Data Science, en particulier sur la d\u00e9tection d\u2019anomalies et le NLP ;\nTravailler avec d\u2019autres \u00e9quipes expertes en traitement de la donn\u00e9e, et des \u00e9quipes expertes en s\u00e9curit\u00e9 informatique ;\nConcevoir des m\u00e9thodes de r\u00e9duction du taux de faux positifs ;\nPr\u00e9parer et assurer le maintien en condition op\u00e9rationnelle et de s\u00e9curit\u00e9, notamment via l'am\u00e9lioration d'outils de monitoring ;\nR\u00e9diger des documents techniques.\nProfil recherch\u00e9\nVous \u00eates dipl\u00f4m\u00e9(e) d\u2019une formation de type \u00e9cole d\u2019ing\u00e9nieur ou d\u2019un cursus universitaire \u00e9quivalent dans le domaine du traitement de la donn\u00e9e. Une exp\u00e9rience d\u2019au moins 3 ans est souhait\u00e9e.\nComp\u00e9tences Requises\nMaitrise de Python et des principales biblioth\u00e8ques de data science : pandas, numpy, scikit-learn\u2026 ;\nMaitrise des principales m\u00e9thodes de Machine Learning et Deep Learning ;\nConnaissances en NLP ;\nMaitrise des concepts statistiques sous-jacents aux m\u00e9thodes d\u2019analyses de donn\u00e9es, et des biais \u00e9ventuels\nDes connaissances dans les domaines suivants seront des atouts importants :\nScripting PowerShell et Bash ;\nGit, DevSecOps, orchestration de conteneurs ;\nFonctionnement des syst\u00e8mes d\u2019exploitation (Windows, Linux\u2026) ;\nAutonomie, rigueur et capacit\u00e9 \u00e0 travailler seul ou en \u00e9quipe sont des comp\u00e9tences indispensables.\nSavoir \u00catre\nAvoir le sens du service public ;\nAutonomie et capacit\u00e9 d'adaptation ;\nDynamique et rigoureux/euse.\nProcess de recrutement\nSi votre candidature est pr\u00e9s\u00e9lectionn\u00e9e, vous serez contact\u00e9(e) pour appr\u00e9cier vos attentes et vos motivations au cours d'un entretien t\u00e9l\u00e9phonique ou physique.\nDes tests techniques pourront vous \u00eatre propos\u00e9s.\nVous ferez l'objet d'une proc\u00e9dure d'habilitation.\nJe postule\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "R",
                "Go",
                "Bash"
            ],
            "DataBase": [],
            "DataAnalytics": [
                "Pandas",
                "NumPy",
                "R"
            ],
            "BigData": [],
            "MachingLearning": [
                "Scikit-Learn"
            ],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [
                "Statistiques"
            ],
            "CloudComputing": [],
            "DevTools": [
                "Git"
            ],
            "Os": [
                "Linux",
                "Windows"
            ],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [
                "Machine Learning",
                "Statistiques"
            ],
            "FrSoftSkills": [
                "Organisation"
            ],
            "EnSoftSkils": []
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s",
                "3",
                "3",
                "3"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "Software Engineer (Crawling)",
        "company": "Wiser Solutions, Inc.",
        "location": "Paris, \u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/software-engineer-crawling-at-wiser-solutions-inc-3909448442?position=3&pageNum=12&refId=VZ0t85WXynm0JJPlCprWOg%3D%3D&trackingId=McqmubnUf92Vt414ZyVsXg%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Wiser Solutions is a suite of in-store and eCommerce intelligenceand execution tools. We're on a mission to enable brands, retailers, and retail channel partners to gather intelligence and automate actions to optimize in-store and online pricing, marketing, and operations initiatives. Our Commerce Execution Suite is available globally.\nJob Description\nLocation: Remote in France\nVeuillez soumettre votre curriculum vitae en anglais\nNous recherchons un Software Engineer (Crawling) hautement qualifi\u00e9 pour \u00eatre un contributeur essentiel au d\u00e9veloppement de notre suite de crawlers et d'extractions. Si vous aimez travailler sur des probl\u00e8mes complexes et \u00e9crire un code propre, vous allez adorerer ce r\u00f4le. Notre objectif est de r\u00e9soudre un probl\u00e8me complexe. Notre travail consiste \u00e0 collecter, cat\u00e9goriser et analyser des donn\u00e9es semi-structur\u00e9es provenant de diff\u00e9rentes sources (plus de 200 millions de produits provenant de plus de 100 sites Web dans notre catalogue de plus de 500 millions de produits). Nous aidons nos clients \u00e0 d\u00e9couvrir de nouveaux mod\u00e8les dans leurs donn\u00e9es pouvant \u00eatre exploit\u00e9s afin qu'ils deviennent plus comp\u00e9titifs et augmentent leurs revenus.\nFonctions essentielles:\nD\u00e9velopper et maintenir divers crawlers et composants c\u00f4t\u00e9 serveur.\nAssurer des performances optimales des diff\u00e9rentes bases de donn\u00e9es et une r\u00e9activit\u00e9 aux demandes frontend.\nD\u00e9velopper des applications haute performance en \u00e9crivant un code testable, r\u00e9utilisable et efficace.\nMettre en place des protocoles de s\u00e9curit\u00e9 efficaces, des mesures de protection des donn\u00e9es et des solutions de stockage.\nEffectuer des tests diagnostiques, r\u00e9parer les d\u00e9fauts et fournir un support technique.\nDocumenter les processus, y compris les sch\u00e9mas de base de donn\u00e9es, ainsi que pr\u00e9parer des rapports.\nRecommander et mettre en \u0153uvre des am\u00e9liorations aux processus et technologies.\nApporter de nouvelles id\u00e9es \u00e0 la table - certaines de nos meilleures innovations viennent de l'\u00e9quipe.\nTechnologies utilis\u00e9es:\nLangages : La ma\u00eetrise de Python, JavaScript (JS), HTML et SQL est essentielle.\nEnvironnement : Exp\u00e9rience avec la Google Cloud Platform (GCP), Kubernetes, les pratiques d'int\u00e9gration continue et de d\u00e9ploiement continu (CI/CD), GitHub etCircleCI.\nMariaDB, MySQL, MongoDB\nQualifications\nExp\u00e9rience : Un minimum de 3 ans dans un domaine pertinent est requis.\nProtocoles : Bonne compr\u00e9hension des protocoles TCP/IP et HTTP.\nConnaissance en s\u00e9curit\u00e9 Web : Familiarit\u00e9 avec les principes et pratiques de s\u00e9curit\u00e9 Web.\nSyst\u00e8mes : Comp\u00e9tent dans le travail avec les syst\u00e8mes d'exploitation bas\u00e9s sur Linux, notamment Debian et Ubuntu.\nM\u00e9thodologie : Les m\u00e9thodologies Agile et Scrum devraient \u00eatre naturelles.\nExcellentes comp\u00e9tences interpersonnelles, de communication et de collaboration.\nExpertise en d\u00e9veloppement back-end en utilisant Python.\nCompr\u00e9hension solide de la GCP, de Kubernetes et des concepts d'infrastructure.\nComp\u00e9tences en programmation RDBMS & SQL (l'exp\u00e9rience avec MYSQL, MariaDB & MongoDB est un plus).\nCe poste peut n\u00e9cessiter d\u2019\u00eatre sur appel pour r\u00e9soudre des probl\u00e8mes critiques li\u00e9s aux applications de production en dehors des heures normales de travail.\nFacultatif:\nConnaissance facultative de l'intelligence artificielle (IA) et de l'apprentissage automatique (ML), de l'analyse de donn\u00e9es et de AWS serait un plus.\nPoints bonus:\nExp\u00e9rience de travail sur des environnements de microservices ou de syst\u00e8mes distribu\u00e9s.\nExp\u00e9rience avec la conception orient\u00e9e domaine.\nExp\u00e9rience avec la mod\u00e9lisation C4.\nExp\u00e9rience de travail dans un environnement de vente au d\u00e9tail ou de commerce \u00e9lectronique\nAdditional Information\nEEO STATEMENT\nWiser Solutions, Inc. is an Equal Opportunity Employer and prohibits Discrimination, Harassment, and Retaliation of any kind. Wiser Solutions, Inc. is committed to the principle of equal employment opportunity for all employees and applicants, providing a work environment free of discrimination, harassment, and retaliation. All employment decisions at Wiser Solutions, Inc. are based on business needs, job requirements, and individual qualifications, without regard to race, color, religion, sex, national origin, family or parental status, disability, genetics, age, sexual orientation, veteran status, or any other status protected by the state, federal, or local law. Wiser Solutions, Inc. will not tolerate discrimination, harassment, or retaliation based on any of these characteristics.\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "Java",
                "R",
                "Go",
                "JavaScript",
                "HTML"
            ],
            "DataBase": [
                "SQL",
                " MongoDB"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [
                "AWS",
                "Google Cloud Platform"
            ],
            "DevTools": [
                "Git"
            ],
            "Os": [
                "Linux"
            ],
            "DBMS": [
                "MySQL"
            ],
            "SoftBigDataProcessing": [],
            "Automation": [
                "Kubernetes"
            ],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [
                "Kubernetes"
            ],
            "Collaboration": [],
            "Other": [
                "ML",
                "Cloud",
                "CI/CD"
            ],
            "FrSoftSkills": [
                "Communication",
                "Collaboration"
            ],
            "EnSoftSkils": [
                "Communication",
                "Collaboration",
                "Initiative"
            ]
        },
        "details": {
            "JobDetail": [
                "Remote"
            ],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s",
                "3",
                "3",
                "3"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "ALTERNANT(E) \u2013 Data Scientist (F/H)",
        "company": "BRED Banque Populaire",
        "location": "Paris, \u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/alternant-e-%E2%80%93-data-scientist-f-h-at-bred-banque-populaire-3892788252?position=4&pageNum=12&refId=VZ0t85WXynm0JJPlCprWOg%3D%3D&trackingId=pUv3Npi5LFEbPJ%2FCBxvcyg%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Description de l'entreprise\nQui sommes-nous ?\nLa banque SANS distance !\nLa BRED Banque Populaire est une banque coop\u00e9rative et r\u00e9gionale d\u00e9tenue par ses soci\u00e9taires et ancr\u00e9e sur ses territoires en Ile-de-France, en Normandie, en Outre-Mer et \u00e0 l\u2019International.\nElle poursuit son d\u00e9veloppement gr\u00e2ce \u00e0 ses 6300 salari\u00e9s qui accompagnent 1,3 million de clients, en s\u2019appuyant sur des valeurs fortes : proximit\u00e9, solidarit\u00e9 et entreprenariat.\nLa BRED affirme sa volont\u00e9 d\u2019\u00eatre une banque responsable et engag\u00e9e en pla\u00e7ant la Responsabilit\u00e9 Soci\u00e9tale des Entreprises (RSE) au c\u0153ur de sa strat\u00e9gie. Elle a obtenu le Label \u00e9galit\u00e9 AFNOR et un \u00ab Sustainability Rating \u00bb A1 par Moody\u2019s ESG Solutions.\nRejoindre la BRED, c\u2019est int\u00e9grer le Groupe BPCE, 2\u00e8me Groupe Bancaire Fran\u00e7ais, sponsor premium des JO Paris 2024\nPoste et missions\nAu sein de la DSI., vous \u00eates directement rattach\u00e9(e) \u00e0 la fili\u00e8re des projets de S\u00e9curit\u00e9 financi\u00e8re & de l\u2019international.\n\u00c0 ce titre, vous prenez en charge un poste de Data Scientist en alternance et vos missions principales sont :\nParticiper \u00e0 l\u2019optimisation de sc\u00e9narios d\u2019alertes lutte anti-blanchiment et financement de terrorisme\nMod\u00e9lisation\nBack Testing\nCr\u00e9ation de dashboards\nAssistance \u00e0 la r\u00e9alisation et validation des datamarts existants et/ou en cours de cr\u00e9ation\nEnvironnement Technique\nDataiku et/ou SAS, Python.\nPower BI.\nProfil et comp\u00e9tences requises\nVous \u00cates Le/la Candidat(e) Id\u00e9al(e) Si\nVous pr\u00e9parez un master dans une fili\u00e8re informatique avec orientation/app\u00e9tence sur la Data, ou une fili\u00e8re scientifique (Statistiques / Data science).\nVous souhaitez acqu\u00e9rir de solides comp\u00e9tences et connaissances dans votre domaine.\nVous \u00eates reconnu(e) pour votre dynamisme, votre rigueur et votre investissement.\nNous rejoindre ? C'est partager nos valeurs : proximit\u00e9, solidarit\u00e9 et entreprenariat et b\u00e9n\u00e9ficier d\u2019un accompagnement personnalis\u00e9 tout au long de votre alternance ainsi que des avantages li\u00e9s \u00e0 notre politique RH :\nUn suivi de carri\u00e8re personnalis\u00e9 tout au long de votre alternance en lien avec votre manager et votre RH.\nUn dispositif de formations innovant : des parcours individualis\u00e9s compl\u00e9t\u00e9s par des applications d\u2019autoformation.\nUn Package Social Attractif\nR\u00e9mun\u00e9ration fixe sup\u00e9rieure au l\u00e9gale\nAccord d\u2019Int\u00e9ressement / Participation attractif, bas\u00e9 sur la volont\u00e9 de partage des r\u00e9sultats avec nos salari\u00e9s\nAccord sur la Qualit\u00e9 de Vie et des Conditions de Travail\nAutres avantages : Cong\u00e9s, RTT, Compte \u00c9pargne Temps, PEE/PERCO, mutuelle, pr\u00e9voyance, retraite suppl\u00e9mentaire, primes de cr\u00e8che et de scolarit\u00e9, Comit\u00e9 d\u2019Entreprise\nChacun a sa place \u00e0 la BRED, la Mission Handicap vous accompagne au quotidien.\nInformations compl\u00e9mentaires sur le poste\nPrise de poste : \u00e0 partir de Septembre/Octobre 2024\nLocalisation : 4 Route de la Pyramide 75012 PARIS (RER A : Joinville-le-Pont).\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "R"
            ],
            "DataBase": [],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [
                "Power BI"
            ],
            "Statistics": [
                "Statistiques"
            ],
            "CloudComputing": [],
            "DevTools": [],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [
                "Statistiques"
            ],
            "FrSoftSkills": [],
            "EnSoftSkils": []
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [],
            "Salary": [
                "2024"
            ],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "Data Scientist (H/F)",
        "company": "Mailinblack",
        "location": "Marseille, Provence-Alpes-C\u00f4te d'Azur, France",
        "link": "https://fr.linkedin.com/jobs/view/data-scientist-h-f-at-mailinblack-3910201495?position=5&pageNum=12&refId=VZ0t85WXynm0JJPlCprWOg%3D%3D&trackingId=ZITE3t6ud6thzQvDDMiWVw%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Cette offre d\u2019emploi est fournie par P\u00f4le emploi\nDescription\nRESPONSABILIT\u00c9S : Ton job ? Rattach\u00e9(e) \u00e0 l'\u00e9quipe Lab R&D, tu travailleras en \u00e9troite collaboration avec les \u00e9quipes techniques et produit. Ton r\u00f4le sera d'am\u00e9liorer la d\u00e9tection des menaces provenant de multiples vecteurs d'attaques (emails, pages web malveillantes) et d'apporter ton expertise en Machine Learning lors du d\u00e9veloppement de nouveaux produits. Tes missions ? - D\u00e9velopper des mod\u00e8les pr\u00e9dictifs afin d'am\u00e9liorer la d\u00e9tection et la pr\u00e9vention des menaces cyber ; - Collaborer avec les \u00e9quipes pour int\u00e9grer les mod\u00e8les et les algorithmes dans les solutions de Mailinblack ; - Concevoir des services de surveillance des r\u00e9sultats des analyses et des pr\u00e9dictions ; - Imaginer et proposer de nouvelles id\u00e9es pour am\u00e9liorer les produits de Mailinblack ou en cr\u00e9er de nouveaux ; - Participer \u00e0 la veille technologique ; Environnement technique : Python, Golang, Scala, Spark, Databricks, Azure (VM, ADLS, Event Hubs, Service Bus, DevOps pipeline), MySQL, Git, Jenkins, Docker, Kubernetes, ELK, API REST, SMTP. PROFIL RECHERCH\u00c9 : Ton profil\u00bf? \u00bf Tr\u00e8s bonne connaissance des algorithmes de Machine Learning : Ma\u00eetrise des techniques de r\u00e9gression, de classification et de clustering, ainsi que des Frameworks courants. Capacit\u00e9 \u00e0 optimiser les mod\u00e8les, \u00e0 \u00e9valuer leur performance et \u00e0 interpr\u00e9ter leurs r\u00e9sultats. \u00bf Comp\u00e9tences en d\u00e9veloppement : Ma\u00eetrise des biblioth\u00e8ques de Python pour la data science. Exp\u00e9rience avec Apache Spark. \u00bf Bases en traitement automatique de langage naturel (NLP) \u00bf Connaissance des syst\u00e8mes de base de donn\u00e9es : Exp\u00e9rience avec les bases de donn\u00e9es relationnelles (SQL) et les bases de donn\u00e9es NoSQL. \ud83c\udf1f Bonus\u00bf:\u00bf - Connaissances dans les domaines de la messagerie (protocole SMTP et m\u00e9thodes de filtrage) et web. - Connaissance des environnements de micro-services (Docker, Kubernetes), compr\u00e9hension des enjeux d'int\u00e9gration de d\u00e9ploiement continu - Exp\u00e9rience en apprentissage non-supervis\u00e9 et/ou end-to-end et/ou analyse d'image - Comp\u00e9tences en traitement \u00e0 grande \u00e9chelle (Big Data) D\u00e9roulement des entretiens \u00bf\u00bf \ud83d\udcf1 Premier \u00e9change de 20 minutes par t\u00e9l\u00e9phone avec Alexandre, notre Talent Acquisition \ud83d\udcac Entretien en visio avec Achraf, Manager de l'\u00e9quipe IA/Data, et Alexandre\u00bf \ud83d\udcbb Test technique \u00bf \ud83d\udc40 Rencontre avec l'\u00e9quipe\u00bfData R\u00e9mun\u00e9ration : 40k \u00e0 50k annuel brut Les + chez Mailinblack : - Des bureaux sympas en plein centre de Marseille, au soleil et \u00e0 deux pas du Vieux Port et des Calanques \u00bf\u00bf \u00bf\u00bf - 7 jours de cong\u00e9s pay\u00e9s suppl\u00e9mentaires - 2 \u00e0 3 jours par semaine en t\u00e9l\u00e9travail - Une culture d'entreprise qui pr\u00f4ne l'autonomie, la responsabilit\u00e9 et la bienveillance - Un plan de d\u00e9veloppement de comp\u00e9tences Et aussi : des ch\u00e8ques vacances, des paniers de fruits dans la cuisine, des repas d'\u00e9quipes, des journ\u00e9es massage sur site et des \u00e9v\u00e9nements canons ! Et bien s\u00fbr une bonne mutuelle (Malakoff), une \u00e9pargne salariale, une participation aux transports en commun (50%) Impatient(e) d'int\u00e9grer une \u00e9quipe soud\u00e9e et une entreprise en pleine \u00e9volution ?\nPROFIL SOUHAIT\u00c9\nExp\u00e9rience\nD\u00e9butant accept\u00e9\nSource: Pole emploi (https://www.pole-emploi.fr)\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "Scala",
                "R",
                "Go"
            ],
            "DataBase": [
                "SQL",
                "NoSQL"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [
                "Spark",
                "Databricks"
            ],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [
                "Azure"
            ],
            "DevTools": [
                "Git",
                "Docker",
                "Jenkins"
            ],
            "Os": [],
            "DBMS": [
                "MySQL"
            ],
            "SoftBigDataProcessing": [],
            "Automation": [
                "Kubernetes"
            ],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [
                "Docker",
                "Kubernetes"
            ],
            "Collaboration": [],
            "Other": [
                "DevOps",
                "Big Data",
                "Machine Learning"
            ],
            "FrSoftSkills": [
                "Collaboration"
            ],
            "EnSoftSkils": [
                "Collaboration"
            ]
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "DATASCIENTIST",
        "company": "GROUPE ALLIANCE",
        "location": "\u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/datascientist-at-groupe-alliance-3916080098?position=6&pageNum=12&refId=VZ0t85WXynm0JJPlCprWOg%3D%3D&trackingId=htIxI%2B6GGy6M0E7NQId0GA%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "SI LA GESTION DES DONNEES EST TON DADA, TU PEUX GAGNER LA COURSE EN LISANT CETTE ANNONCE \u2026\nCe que tu recherches :\nau sein d\u2019une \u00e9quipe dynamique\n\u00e0 des projets innovants d\u2019envergure\ndes d\u00e9fis\nun nouveau souffle \u00e0 ta carri\u00e8re\nAlors nous avons la mission id\u00e9ale pour toi.\nAu sein d\u2019acteurs majeurs du secteur Bancaire, tu participeras des projets d\u2019envergure sur des \u00e9volutions majeures \u00e0 mettre en \u0153uvre dans le SI du client :\ndes besoins, tu feras\ntechniques, tu r\u00e9digeras\net/ou socle technique, tu d\u00e9finiras\npratiques, tu instaureras\nnouvelles fonctionnalit\u00e9s, tu d\u00e9velopperas\nbug, tu laisseras\n\u00e9quipe, tu accompagneras\ninstances de pilotage, tu participeras\nQui tu es :\nde la formation qui va bien\nou d\u00f4t\u00e9(e) d\u2019une exp\u00e9rience de 3 ans minimum\nde la Stack technique machine learning et python\navec les Frameworks et Outils : Ttensorflow, pytorch,scikit-learn, numpy, pandas\nAu-del\u00e0 des comp\u00e9tences techniques, tu es :\n: tu n\u2019aimes pas rester les deux pieds dans le m\u00eame sabot\n: un guide du Routard te suffira\nde synth\u00e8se : tu sais aller \u00e0 l\u2019essentiel\nd\u2019adaptation : tu es un vrai cam\u00e9l\u00e9on\nde la communication : les mots n\u2019ont pas de secret pour toi\nde proposition : tu es l\u2019Aladdin de l\u2019informatique\nd\u2019\u00e9quipe : un pour tous et tous pour un !\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "R"
            ],
            "DataBase": [],
            "DataAnalytics": [
                "Pandas",
                "NumPy",
                "R"
            ],
            "BigData": [],
            "MachingLearning": [
                "Scikit-Learn",
                "TensorFlow",
                "PyTorch"
            ],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [],
            "DevTools": [],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [
                "Machine Learning"
            ],
            "FrSoftSkills": [
                "Communication"
            ],
            "EnSoftSkils": [
                "Communication"
            ]
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s",
                "3",
                "3",
                "3"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "Data Engineer",
        "company": "MindPal",
        "location": "Paris, \u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/data-engineer-at-mindpal-3919800161?position=7&pageNum=12&refId=VZ0t85WXynm0JJPlCprWOg%3D%3D&trackingId=IkkZHJJKzdlSafLf1N%2B9Ag%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "We are looking for\nData Engineer!\nResponsibilities\nDesigning, creating, and maintaining data processing systems\nAnalyzing and optimizing data processing workflows\nCollaborating with the team to ensure data quality and efficiency\nTesting and implementing new solutions\nRequirements\nAt least 2 years of experience in designing and creating data processing systems\nProficiency in tools and programming languages related to data engineering (e.g. Hadoop, Spark, Scala, Python)\nExcellent knowledge of databases and SQL language\nAbility to work in a team and communicate effectively with other departments\nCommunicative English skills\nExperience with AWS/AWS Glue is a plus\nWe Offer\nB2B contract\nFull-time job\nRemote work and flexible hours\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "Scala",
                "R"
            ],
            "DataBase": [
                "SQL"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [
                "Hadoop",
                "Spark"
            ],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [
                "AWS"
            ],
            "DevTools": [],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [],
            "FrSoftSkills": [],
            "EnSoftSkils": []
        },
        "details": {
            "JobDetail": [
                "Remote",
                "Full"
            ],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "Alternance \u2013 Data Scientist",
        "company": "METEOJOB by CleverConnect",
        "location": "Aubervilliers, \u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/alternance-%E2%80%93-data-scientist-at-meteojob-by-cleverconnect-3898720601?position=8&pageNum=12&refId=VZ0t85WXynm0JJPlCprWOg%3D%3D&trackingId=iMftc92gf6YZbkAfz5D8ZQ%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Entreprise\nMAKING THE WORLD A BETTER HOME\n, faire du monde une maison commune, c'est la raison pour laquelle nous existons et c'est notre cap commun.\nPr\u00e9sent dans 75 pays, Saint-Gobain est le leader mondial de la construction durable.\nNotre m\u00e9tier ?\nNous concevons, produisons et distribuons des mat\u00e9riaux et des services pour les march\u00e9s de l'habitat et de l'industrie.\nNos solutions ?\nElles se trouvent partout dans notre vie quotidienne - b\u00e2timents, transports, infrastructures - et apportent confort et durabilit\u00e9.\nNotre ambition ?\nO\u00f9 que vous soyez, laissez votre personnalit\u00e9 briller et nos valeurs vous guider chaque jour pour inventer un monde plus durable.\nSaint-Gobain Glass con\u00e7oit, produit et distribue des mat\u00e9riaux et services pour les march\u00e9s de l'habitat et de l'industrie. Mus par une volont\u00e9 permanente d'adapter nos produits verriers aux besoins et aux r\u00e9alit\u00e9s actuels, nous innovons sans cesse. Nous d\u00e9veloppons ainsi des solutions int\u00e9gr\u00e9es pour la r\u00e9novation des b\u00e2timents publics et priv\u00e9s, la construction l\u00e9g\u00e8re. Par l'innovation, nous avons \u00e9galement \u00e0 c\u0153ur de participer \u00e0 la d\u00e9carbonation du monde de la construction et de l'industrie avec des produits apportant durabilit\u00e9 et performance.\nEn France, Saint-Gobain Glass produit, transforme le verre plat et distribue des solutions verri\u00e8res r\u00e9pondant \u00e0 un large spectre d'applications pour l'habitat r\u00e9sidentiel et tertiaire.\nEn int\u00e9grant Saint-Gobain Glass France, vous rejoindrez la Direction Technologie et Performance Industrielle (DTI) \u00e9tablie \u00e0 Aubervilliers, o\u00f9 vous serez au c\u0153ur des initiatives strat\u00e9giques pour optimiser les performances industrielles et environnementales.\nLes missions principales de la DTI sont d'assurer un accompagnement des pays et m\u00e9tiers du Groupe sur les activit\u00e9s suivantes: feuilles de route industrielles (standards, benchmark, performance, \u00e9nergie, CO2, savings, \u2026), programmes R&D pour les m\u00e9tiers de la Construction, Investissements et Achats strat\u00e9giques, Allocation de capacit\u00e9 entre les pays et Programmes d'excellence op\u00e9rationnelle avec les savings associ\u00e9s (World Class Manufacturing, World Class Supply Chain, 4.0, Applications digitales pour l'Industrie, \u2026).\nDescription Du Poste\nLa Direction Technique Internationale est \u00e0 la recherche d'un(e) alternant(e) - Data science.\nNotre futur(e) alternant(e) collaborera avec les experts de divers domaines pour r\u00e9pondre \u00e0 leurs besoins d'analyse et contribuera activement au d\u00e9veloppement du p\u00f4le \"Data Science\" chez Saint-Gobain Glass.\nIl ou elle sera rattach\u00e9(e) \u00e0 notre Ing\u00e9nieurs Data Scientist\nLes Missions Principales Incluront\nEffectuer des analyses descriptives des donn\u00e9es, telles que le Datamining, les Corr\u00e9lations et les Segmentations.\nIdentifier et collecter les diff\u00e9rentes donn\u00e9es provenant des sources internes ou externes n\u00e9cessaires aux \u00e9tudes.\nManipuler et nettoyer de grandes quantit\u00e9s de donn\u00e9es.\nMettre en place des algorithmes de pr\u00e9diction, tels que la R\u00e9gression, la Classification ou le Deep Learning.\nCollaborer \u00e9troitement avec des experts techniques et des professionnels du domaine pour interpr\u00e9ter les r\u00e9sultats obtenus.\nCr\u00e9er des rapports et des tableaux de bord pr\u00e9sentant divers indicateurs de performance, en utilisant des outils de business intelligence.\nFormation\nDescription du profil :\nNous recherchons des candidat(e)s ayant un niveau d'exp\u00e9rience correspondant \u00e0 un Master 1-2, issu(e)s d'une \u00e9cole d'ing\u00e9nieur.\nComp\u00e9tences Techniques\nUne ma\u00eetrise de Miscrosoft 365 est indispensable.\nCapacit\u00e9 \u00e0 effectuer des analyses de donn\u00e9es sur R et/ou Python.\nLa ma\u00eetrise d'un outil de Business Intelligence est un atout.\nMa\u00eetrise du Fran\u00e7ais et de l'Anglais.\nComp\u00e9tences Relationnelles Et Qualit\u00e9s Requises\nUn fort int\u00e9r\u00eat pour l'analyse de donn\u00e9es.\nDynamisme et sens du service client.\nCapacit\u00e9 \u00e0 travailler de mani\u00e8re autonome et avec rigueur.\nOuverture d'esprit et curiosit\u00e9.\nUn int\u00e9r\u00eat marqu\u00e9 pour le secteur industriel et les nouvelles technologies.\nExigences Du Poste\nEnvironnement multinational et multilingue.\nLocalisation \u00e0 Aubervilliers\nCette offre est accessible \u00e0 tous les talents ! Saint-Gobain s'engage quotidiennement pour l'\u00e9galit\u00e9 des chances. Nous apportons une attention particuli\u00e8re \u00e0 l'inclusion et la diversit\u00e9, https://www.saint-gobain.com/fr/news/agir-durablement\nLa culture Trust Empowerment and Collaboration (TEC) est le socle sur lequel se structure nos actions diversit\u00e9 et inclusion.\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "R",
                " R ",
                "Go"
            ],
            "DataBase": [],
            "DataAnalytics": [
                "R",
                " R "
            ],
            "BigData": [],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [
                "Tableau"
            ],
            "Statistics": [],
            "CloudComputing": [],
            "DevTools": [
                "Git"
            ],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [],
            "FrSoftSkills": [
                "Collaboration"
            ],
            "EnSoftSkils": [
                "Collaboration",
                "Initiative"
            ]
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "Ing\u00e9nieur quantitatif data scientist confirm\u00e9 (H/F) - 1-0007595",
        "company": "Groupe Caisse des D\u00e9p\u00f4ts",
        "location": "Paris, \u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/ing%C3%A9nieur-quantitatif-data-scientist-confirm%C3%A9-h-f-1-0007595-at-groupe-caisse-des-d%C3%A9p%C3%B4ts-3907546129?position=9&pageNum=12&refId=VZ0t85WXynm0JJPlCprWOg%3D%3D&trackingId=EbLnBclNw08uzqPEKVf6FQ%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "La Direction des risques Groupe (DRG) pilote le dispositif de ma\u00eetrise des risques du Groupe. Elle veille \u00e0 sa coh\u00e9rence et \u00e0 son efficacit\u00e9. Au titre de sa fonction d'animation, de coordination et de supervision de la fili\u00e8re \u00ab Risques \u00bb du Groupe, ou \u00ab fonction de gestion des risques \u00bb au sens des nouveaux textes bancaires en vigueur, elle assure un suivi des risques du Groupe adapt\u00e9 \u00e0 l'environnement \u00e9conomique, financier et r\u00e9glementaire, qui contribue au dispositif de pilotage global du Groupe. Rattach\u00e9e au Directeur g\u00e9n\u00e9ral et \u00e0 vocation transversale, elle compte 170 collaborateurs. La Directrice des risques est membre du Comex.\nLa Direction est en charge :\n- du pilotage transverse des risques : analyse et avis sur les risques de bilan, validation des mod\u00e8les, reporting, pilotage des risques des filiales, r\u00e8glementation prudentielle\n- du suivi des risques financiers : analyse financi\u00e8re ing\u00e9nierie financi\u00e8re\n- du suivi des engagements : investisseur, bancaire, pr\u00eateur\n- du pilotage des risques dans les directions r\u00e9gionales\n- du pilotage des comit\u00e9s d'engagements\n- de la s\u00e9curit\u00e9 des SI.\nMissions et activit\u00e9s principales\nDescription d\u00e9taill\u00e9e du poste\nRATTACHEMENT\nLe poste est rattach\u00e9 au responsable du Service Mod\u00e9lisation des risques de cr\u00e9dit de la Direction des Risques du Groupe (DRG).\nLe service est charg\u00e9 de l\u2019\u00e9valuation de la qualit\u00e9 de cr\u00e9dit des contreparties de pr\u00eats (organismes de logements sociaux et collectivit\u00e9s locales notamment) et des contreparties de portefeuilles financiers (grandes banques, groupes industriels et commerciaux, Etats, titrisations) qui \u00e9mettent sur les march\u00e9s de taux. A ce titre, le service est charg\u00e9 de la conception et du management des outils de notation interne et de calibrage des probabilit\u00e9s de d\u00e9fauts et probabilit\u00e9s de recouvrement.\nDESCRIPTION DU POSTE\nAu sein de son service Mod\u00e9lisation des risques de cr\u00e9dit, le service recherche un mod\u00e9lisateur du risque de cr\u00e9dit, dont les principales missions porteront sur :\nLe d\u00e9veloppement de mod\u00e8les de notation bas\u00e9s sur les fondamentaux de l\u2019analyse financi\u00e8re, et le management des mod\u00e8les existants (backtestings annuels, maintenance applicative, etc.) ;\nLe d\u00e9veloppement de mod\u00e8les de probabilit\u00e9s de d\u00e9fauts et de recouvrement (param\u00e8tres b\u00e2lois et IFRS9) et le management des mod\u00e8les existants : PD, LGD et CCF ;\nLe d\u00e9veloppement d\u2019outils de scoring, notation et/ou probabilit\u00e9s de d\u00e9faut pour des \u00e9metteurs non conventionnels (Fonds) ;\nL\u2019adaptation des processus de mod\u00e9lisation aux recommandations r\u00e8glementaires ;\nLa mise en place et/ou la maintenance d\u2019une infrastructure s\u00e9curis\u00e9e et automatis\u00e9e (formalisation et maintenance des bases de donn\u00e9es, travaux statistiques sous SAS et Python) ;\nLa repr\u00e9sentation du service dans le cadre du stress testing transversal, sur le volet cr\u00e9dit ;\nLa diffusion des connaissances r\u00e9glementaires aupr\u00e8s des interlocuteurs de la Direction des Risques du Groupe ;\nLa participation \u00e0 la refonte des syst\u00e8mes d\u2019information et projets transversaux ;\nLa maintenance des outils informatiques : analyse des besoins, \u00e9laboration de cahiers des charges, suivi des r\u00e9alisations informatiques (projets & maintenance) ;\nUne veille scientifique sur les techniques candidates, en lien avec les technologies big bata et machine learning.\nProfil attendu\nLe recrutement \u00e0 la Caisse des D\u00e9p\u00f4ts est fond\u00e9 sur les comp\u00e9tences, sans distinction d'origine, d'\u00e2ge, ni de genre. Tous nos postes sont ouverts aux personnes en situation de handicap.\nA partir de 5 ans d'exp\u00e9rience sur un poste similaire\nBAC+5 de formation math\u00e9matique,\nExp\u00e9rience significative en mod\u00e9lisation statistique, en particulier du risque de cr\u00e9dit,\nBonne ma\u00eetrise d\u2019au moins un des langages de programmation : Python, SAS, R\nConnaissance de la r\u00e9glementation b\u00e2loise,\nExcellent niveau r\u00e9dactionnel,\nRigueur et capacit\u00e9 de synth\u00e8se,\nMotivation, autonomie, esprit d\u2019\u00e9quipe, disponibilit\u00e9.\nVos connaissances financi\u00e8res et votre exp\u00e9rience vous ont permis d'acqu\u00e9rir un bon esprit d'analyse et de synth\u00e8se ainsi que de bonnes qualit\u00e9s r\u00e9dactionnelles. Ouvert(e), vous avez un bon relationnel qui vous permet de vous adapter facilement \u00e0 des environnements divers et exigeants.\nConditions de travail\nPoste \u00e9ligible au t\u00e9l\u00e9travail.\nSitu\u00e9 rue de Lille, Paris 7.\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "R"
            ],
            "DataBase": [],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [
                "Statistiques"
            ],
            "CloudComputing": [],
            "DevTools": [],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [
                "Machine Learning",
                "Statistiques"
            ],
            "FrSoftSkills": [],
            "EnSoftSkils": []
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [],
            "Salary": [],
            "Level": [
                "Bac+5"
            ],
            "Experience": [
                "a",
                "n",
                "s",
                "5",
                "5",
                "5"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "Data Engineer | ML Engineer | Up to 75k | Boulogne",
        "company": "Talent-R",
        "location": "Greater Paris Metropolitan Region",
        "link": "https://fr.linkedin.com/jobs/view/data-engineer-ml-engineer-up-to-75k-boulogne-at-talent-r-3904965048?position=10&pageNum=12&refId=VZ0t85WXynm0JJPlCprWOg%3D%3D&trackingId=V6C4wYZXpjvAwjb%2BUU48Jg%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "\ud83d\udccd\nLocalisation\n: R\u00e9gion Parisienne & Remote Flexible (60%) - CDI\n\ud83d\udd0d\nSeniorit\u00e9\n: Mid/Senior (>4/5 years of Data)\n\ud83d\udcb0\nSalaire\n: Up to 75K\u20ac fixe + Prime de participation, prime vacances et bonus...\nL'entreprise\n\ud83d\udcbc\nLe groupe entre dans une nouvelle \u00e8re gr\u00e2ce \u00e0 la strat\u00e9gie qui place\nL\u2019IA\nau c\u0153ur du business. Acteur incontournable de ce nouveau cycle ils participent activement \u00e0 relever les challenges des\nnouvelles mobilit\u00e9s et de l\u2019industrie 4.0.\nP\u00f4le Architecture et Data :\nL'objectif est de mettre en place les bases de\nla plateforme IA\nafin de r\u00e9pondre aux nouveaux besoins m\u00e9tiers.\nLes missions\n\u2699\ufe0f\nDans ce r\u00f4le, vous travaillerez en \u00e9troite collaboration avec les \u00e9quipes m\u00e9tiers et les autres membres du P\u00f4le Architecture & Data (Data Analysts, Scientists, architectes, etc.), en exploitant des quantit\u00e9s massives de donn\u00e9es (flux d'\u00e9v\u00e9nements en continu, traitements par lots et en temps r\u00e9el, ainsi que les appels aux APIs).\nL'objectif est notamment d'alimenter des mod\u00e8les d'apprentissage automatique pour des t\u00e2ches telles que la segmentation des clients et la d\u00e9tection automatique des pannes des v\u00e9hicules.\nLes avantages\n\ud83d\ude0d\nVariable de 6% (Objectifs individuels / Performance du groupe)\nPrime int\u00e9ressement (\u00e0 peu pr\u00e8s un mois de salaire)\nPrime vacances (1% de salaire annuel)\nTarif pr\u00e9f\u00e9rentiels achats de v\u00e9hicules\nAvantage CE (200 - 400\u20ac de ch\u00e8ques cadeaux)\nT\u00e9l\u00e9 travail : 3 jours / semaine\nMat\u00e9riel IT + participation frais d\u2019internet\n10 jours de RTT\nLe stack technique\n\ud83d\udc49\ud83c\udffb\nGoogle Cloud Platform (BigQuery, PubSub, Dataflow, Vertex AI)\nAirflow\nTerraform\nPython\nLooker\nDataiku\nKubernetes, SQL, Git\nPostulez si et seulement si\nVous disposez d'au moins\n5\nans\nd\u2019exp\u00e9rience en data\nVous disposez d\u2019une solide exp\u00e9rience en d\u00e9veloppement\nPython\net\nframework ML\n(Vertex, Tensorflow, Scikit, PyTorch\u2026)\nVous poss\u00e9dez une exp\u00e9rience de d\u00e9veloppement et orchestration de chaines ETL complexes via\nAirflow\nou \u00e9quivalent\nVous savez utiliser des services cloud (pr\u00e9f\u00e9rablement\nGCP\n)\nVous \u00eates capable d\u2019\u00e9changer en\nanglais\ntechnique \u00e9crit et oral\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "R",
                "Go"
            ],
            "DataBase": [
                "SQL"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [],
            "MachingLearning": [
                "TensorFlow",
                "PyTorch"
            ],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [
                "Google Cloud Platform"
            ],
            "DevTools": [
                "Git"
            ],
            "Os": [],
            "DBMS": [
                "BigQuery"
            ],
            "SoftBigDataProcessing": [],
            "Automation": [
                "Kubernetes",
                "Airflow"
            ],
            "InfrastructureAsCode": [
                "Terraform"
            ],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [
                "Kubernetes"
            ],
            "Collaboration": [],
            "Other": [
                "ML",
                "Cloud"
            ],
            "FrSoftSkills": [
                "Collaboration"
            ],
            "EnSoftSkils": [
                "Collaboration"
            ]
        },
        "details": {
            "JobDetail": [
                "Remote",
                "Senior"
            ],
            "TypeContract": [
                "CDI"
            ],
            "Salary": [
                "75K"
            ],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s",
                "5",
                "5",
                "5"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "Stage Ing\u00e9nieur Machine Learning pour Tomographie H/F",
        "company": "G\u00e9rard Perrier Industrie",
        "location": "Serres-Castet, Nouvelle-Aquitaine, France",
        "link": "https://fr.linkedin.com/jobs/view/stage-ing%C3%A9nieur-machine-learning-pour-tomographie-h-f-at-g%C3%A9rard-perrier-industrie-3767314230?position=1&pageNum=15&refId=UW%2F6rZ%2F9O8vzcgR6IhOXYQ%3D%3D&trackingId=u1xG%2Brl%2F6GrqfnbEvUEMAQ%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Nous recherchons\nun(e) stagiaire Ing\u00e9nieur Machine Learning pour Tomographie H/F\nqui rejoindra nos \u00e9quipes bas\u00e9es \u00e0 Serres-Castet (64) pour son stage d'\u00e9cole d'ing\u00e9nieur.\nNous avons d\u00e9velopp\u00e9 un logiciel de traitement d'images en Python. Ce logiciel se base sur un algorithme et g\u00e9n\u00e8re un rapport de r\u00e9sultats.\nRattach\u00e9(e) au bureau d'\u00e9tude R&D, vous aurez pour sujet l'optimisation d'une proc\u00e9dure de contr\u00f4le tomographique et l'\u00e9tude de nouvelles proc\u00e9dures de d\u00e9tection d'anomalie notamment en utilisant le machine learning.\nDans le cadre de vos missions vous serez emmen\u00e9 \u00e0 :\nPrendre en main le logiciel et comprendre son fonctionnement\nProposer des algorithmes de traitement d'image classique alternatifs \u00e0 l'algorithme actuel\nTester quels mod\u00e8les seraient adapt\u00e9s \u00e0 notre probl\u00e9matique : classification supervis\u00e9e, non-supervis\u00e9e, deep learning\n\u00c9tudier quelles seraient les caract\u00e9ristiques \u00e0 extraire des images pour g\u00e9n\u00e9rer le mod\u00e8le\nSi le temps le permet, d\u00e9velopper les mod\u00e8les et les \u00e9valuer\nVotre Profil\nVous \u00eates en formation Ing\u00e9nieur et souhaitez r\u00e9aliser votre stage dans les domaines du traitement d'image/traitement du signal, programmation et machine learning\nVous disposez de notion en programmation python et des notions de machine Learning\nVous avez des premi\u00e8res connaissance sur le traitement d'images et/ou traitement du signal\nVous \u00eates reconnu(e) pour votre rigueur et votre autonomie\nDynamique, vous \u00eates reconnu(e) pour \u00eatre force de proposition et pour vos capacit\u00e9s \u00e0 remettre en cause et approfondir les sujets\nCe Que Nous Vous Proposons\nUn stage dans une entreprise dynamique et \u00e0 taille humaine situ\u00e9e \u00e0 Serres Castet (64) avec toutes les commodit\u00e9s \u00e0 proximit\u00e9\nUne gratification de stage\nDes titres restaurant et l'acc\u00e8s au restaurant Inter-Entreprises\nVous vous \u00eates reconnu dans notre annonce ?\nPostulez et venez rejoindre nos \u00e9quipes !\nLocalisation du poste: Serres-Castet (64)\nType de contrat: Stage\nR\u00e9mun\u00e9ration : Gratification\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "R",
                "Go"
            ],
            "DataBase": [],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [],
            "DevTools": [],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [
                "Machine Learning"
            ],
            "FrSoftSkills": [],
            "EnSoftSkils": []
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "P&C Data Scientist",
        "company": "JCW Group",
        "location": "Paris, \u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/p-c-data-scientist-at-jcw-group-3916695827?position=2&pageNum=15&refId=UW%2F6rZ%2F9O8vzcgR6IhOXYQ%3D%3D&trackingId=NnKKOEab58BhxKlRFeQmRQ%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "P&C Data Scientist \u2013 Paris\n1. Purpose\nJoin a leading insurance company and be at the forefront of innovation as a P&C Data Scientist in Paris. This role combines actuarial expertise with data science to enhance risk assessment and support strategic decision-making through advanced analytics.\n2. Key Result Areas and Deliverables:\nDevelop strong relationships with actuarial teams, underwriters, and stakeholders to drive innovation and leverage data insights.\nUtilize statistical models, machine learning, and AI solutions to develop inference and predictive analytics, enhancing pricing strategies.\nAnalyze and incorporate external data sources to improve data-driven solutions and analytical models.\nEnhance data collection, management, and transformation capabilities to support pricing optimization and product innovation.\nTransform data into actionable insights, empowering business stakeholders to make informed decisions and drive growth.\n3. Key Competencies:\nGeneric:\nGood interpersonal skills\nCreativity and curiosity\nAttention to detail and analytical mindset\nProactive, flexible, and adaptable\nGood communication skills in English and French\nJob Specific:\nSkilled in Python and SQL\nProficient in data analysis techniques\nP&C insurance and Pricing knowledge\nFamiliarity with Large language Models (LLM)\nFamiliarity with Big Data technologies like Hadoop, Spark, or Kafka\nExperience with R, SAS, and VBA is a plus\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "R",
                "Go"
            ],
            "DataBase": [
                "SQL"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [
                "Hadoop",
                "Spark"
            ],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [],
            "DevTools": [],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [
                "Teams"
            ],
            "Other": [
                "Big Data",
                "Machine Learning"
            ],
            "FrSoftSkills": [
                "Communication"
            ],
            "EnSoftSkils": [
                "Communication",
                "Creativity",
                "Interpersonal Skills"
            ]
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "ALTERNANCE - Data Scientist",
        "company": "Mo\u00ebt Hennessy",
        "location": "Paris, \u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/alternance-data-scientist-at-mo%C3%ABt-hennessy-3840470791?position=3&pageNum=15&refId=UW%2F6rZ%2F9O8vzcgR6IhOXYQ%3D%3D&trackingId=uTE5VKIhqM7PhEVIvQsPgw%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Mo\u00ebt Hennessy est \u00e0 la recherche d'une personne motiv\u00e9e pour rejoindre son Centre d'Expertise (CoE) Data & AI en tant qu'alternant.e Data Scientist.\nDans ce r\u00f4le, vous aurez l'opportunit\u00e9 de contribuer au d\u00e9veloppement d'un \"compliance bridge\" visant \u00e0 valider automatiquement la conformit\u00e9 aux diff\u00e9rentes r\u00e9glementations en vigueur du contenu produit par ou pour Mo\u00ebt Hennessy (texte, image, vid\u00e9o, etc.).\nCela n\u00e9cessitera, notamment, de mettre en \u0153uvre des comp\u00e9tences en Machine Learning (Object Detection, Object Segmentation, NLP, GenAI...).\nEn plus de cette mission principale, vous serez amen\u00e9.e \u00e0 travailler sur d'autres sujets selon les besoins (impl\u00e9mentation de d\u00e9monstrateur IA, acculturation des m\u00e9tiers, veille technologique...).\nLe CoE Data & AI est une \u00e9quipe au sein du d\u00e9partement Data & AI de la DSI de Mo\u00ebt Hennessy. Cette direction a pour mission d'acc\u00e9l\u00e9rer la transformation de nos diff\u00e9rents m\u00e9tiers, de la vigne jusqu'au verre.\nDescriptif du poste\n:\nParticiper au d\u00e9veloppement de la \"couche de conformit\u00e9\" afin d'assurer la conformit\u00e9 du contenu avec les r\u00e9glementations locales (par exemple, la Loi Evin) et les normes internes.\nParticiper aux phases d'id\u00e9ation, d'\u00e9tude de faisabilit\u00e9 et de lancement de projets IA\nParticiper pour ces projets aux phases de mod\u00e9lisation math\u00e9matique\nEffectuer des analyses exploratoires des donn\u00e9es\nContribuer aux activit\u00e9s de pr\u00e9paration des donn\u00e9es (nettoyage de donn\u00e9e, feature engineering, feature selection\u2026)\nSoutenir la conception et la mise en \u0153uvre des mod\u00e8les\nContribuer au design des pipelines de machine learning incluant notamment la mesure de performance des mod\u00e8les et \u00e0 leur monitoring\nContribuer \u00e0 l'industrialisation des mod\u00e8les tout en respectant les normes du groupe et les principes MLOps\nDocumenter les projets d'intelligence artificielle\nContribuer \u00e0 la veille technologique du COE Data & AI\nNous recherchons une personne en alternance inscrite dans un programme master 1 ou master 2 en data science.\nRythme d'alternance souhait\u00e9 :\n15j / 15j de pr\u00e9f\u00e9rence (autres rythmes possibles).\nDur\u00e9e de l'alternance souhait\u00e9e :\n1 an\nComp\u00e9tences recherch\u00e9es :\nMaitrise de Python\nBonne compr\u00e9hension des bonnes pratiques de d\u00e9veloppement logiciel\nConnaissance de Dataiku\nConnaissance des services GCP (en particulier Cloud Run, Vertex AI\nAnglais professionnel\nFran\u00e7ais courant\nAutonomie et pro activit\u00e9\nEsprit de synth\u00e8se\nCapacit\u00e9 de vulgarisation\nQualit\u00e9s relationnelles et r\u00e9dactionnelles\nInformations compl\u00e9mentaires :\nP\u00e9riode : rentr\u00e9e de septembre 2024\nLocalisation g\u00e9ographique de l'offre : PARIS\nD\u00e9placements occasionnels \u00e0 pr\u00e9voir en Champagne (Epernay)\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "R"
            ],
            "DataBase": [],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [],
            "DevTools": [],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [
                "ML",
                "Machine Learning",
                "Cloud"
            ],
            "FrSoftSkills": [],
            "EnSoftSkils": []
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "Senior Machine Learning Engineer With  Computer Vision Engineer",
        "company": "Monk AI",
        "location": "Greater Paris Metropolitan Region",
        "link": "https://fr.linkedin.com/jobs/view/senior-machine-learning-engineer-with-computer-vision-engineer-at-monk-ai-3868031705?position=4&pageNum=15&refId=UW%2F6rZ%2F9O8vzcgR6IhOXYQ%3D%3D&trackingId=PXKUEurOkdOFMHEbd7y93Q%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "About Monk:\nMonk provides visual expertise through Computer Vision and Deep Learning algorithms, today, our AI is able to detect and classify damage on any vehicle, from photos taken by a smartphone. We mostly work on image classification and instance and semantic segmentation but are expanding our scope to topics such as 3D reconstruction. Monk is working with international leading players, such as our parent company ACV Auctions (USA), but also CAT logistics (Europe) Getaround (France), Autobiz (Europe) and Hgreg (Canada). We are looking for a strong individual contributor with rich experiences in deep learning computer vision and solid practical coding skill, to improve our vehicle inspection products with state of the art approaches.\nCome and join us to build the future of vehicle damage detection.\nMissions:\nYou will contribute and to and make significant and high-quality contributions to our deep learning computer vision teams algorithms and PyTorch code\nHelp Monk improve our data lifecycle, in particular our data collection and annotation processes\nProvide technical suggestions to improve for our products and provide technical guidance to junior team members\nYou will also have the opportunity to explore one of our new R&D domains like 3D and video (pose estimation, 3D reconstruction, SFM) or edge computing\nSkills\nAt least 5 years of experience as a Data-Scientist (excluding time spent on internships or in school )\nAt least 2 years of experience as a Senior Computer Vision Scientist/Engineer\nA strong theoretical background\nExperience working and improving a computer vision project\nExperience on collecting and annotating data to drive model improvements\nExperience with an agile methodology\nBonus/nice to have:\nExperience with 3D, video, or edge computing for machine learning\nContract:\nType of contract : CDI\nSalary : \u20ac75-,000.00 -\u20ac85,000.000 -base & performance bonus\nLocation : Paris, France (Hybrid)\nBenefits:\nAt Monk, we\u2019re committed to building an equitable and inclusive global economy. And we can\u2019t do this without our most important asset\u2014You. That\u2019s why we offer benefits to help you thrive in every stage of life. We champion your financial, physical, and mental health by offering valuable benefits and resources to help you care for the whole you.\nWe have great benefits including:\nHybrid work environment\nRestaurant tickets with Swile and sport via Gymlib\nFair and competitive compensation\nHealth Insurance with Alan\nThe premises are at Agoranov and Platform 58: the ecosystem is top notch and super dynamic.\nThe team is ambitious (Profiles: X, CentraleSup\u00e9lec, UTC) and supported by references from AI (professor at l'X in AI, PhD ENS etc.)\nInterview process:\nFit interview (30min)\nTechnical Interview 1 (1h)\nTechnical Interview 2 (1h30)\nExecutive -level interview (30 min)\nOur Company Stack:\nDatabases: SQL Postgres with sqlalchemy\nML: Python, Torch, ClearML, Ray\nInfrastructure: GCP, Kubernetes, CircleCI\nBackend: Python, Flask, Rabbitmq, OpenAPI\nFrontend: JS, TS, React\nWe want you to bring your whole human self to work every day. We accept you for who you are and consider everybody on an equal opportunity basis without regard to race, color, religion, gender, gender identity or expression, sexual orientation, national origin, genetics, disability, age, or veteran status Monk collects your personal data for the purposes of managing Monk's recruitment related activities. Consequently.\nMonk may use your personal data in relation to the evaluation and selection of applicants. Your information will be accessible to Monk and its affiliated entities across the world. By submitting your application, you expressly give your consent to this use and processing of your personal data.\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "R",
                "Go"
            ],
            "DataBase": [
                "SQL"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [],
            "MachingLearning": [
                "PyTorch"
            ],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [],
            "DevTools": [],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [
                "Kubernetes"
            ],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [
                "Kubernetes"
            ],
            "Collaboration": [
                "Teams"
            ],
            "Other": [
                "ML",
                "Machine Learning"
            ],
            "FrSoftSkills": [],
            "EnSoftSkils": []
        },
        "details": {
            "JobDetail": [
                "Junior",
                "Senior"
            ],
            "TypeContract": [
                "CDI"
            ],
            "Salary": [
                "75"
            ],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "Software Engineer",
        "company": "Orange Logic",
        "location": "France",
        "link": "https://fr.linkedin.com/jobs/view/software-engineer-at-orange-logic-3862540191?position=5&pageNum=15&refId=UW%2F6rZ%2F9O8vzcgR6IhOXYQ%3D%3D&trackingId=r4UfWH6VO6XYIbU%2FykQxjA%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "For more than two decades, Orange Logic has empowered a wide range of clients with its digital asset management system, Cortex. We\u2019ve worked with almost every industry, from Finance to NGOs, Media giants to educational institutions, securing and organizing their assets. The Software Engineer will enhance Orange Logic\u2019s software by participating in the design, development, maintenance and testing process.\nWhat you can expect in your role:\nTaking ownership of projects and having the opportunity to further your knowledge by exploring machine learning, security, DevOps, and more.\nDeveloping scalable new features for our software product that exceeds our customer\u2019s needs.\nBuilding architecture for our platform to ensure optimal performance.\nObtaining requirement feedback from internal teams/clients to maintain/support the product development.\nWrite the Unit Tests for robust development.\nPerforming code reviews on other team member\u2019s work.\nYou are:\nProficient with English (both verbal and written).\nHave 3+ years\u2019 practical experience on a web-based application.\nProficient with any backend programming languages (e.g. .NET, Java, Python, etc.).\nA strong fundamental understanding of software development.\nAn understanding of complex algorithms and data structures, as well as a passion for intellectual challenges.\nStrong self-discipline for delivering well-tested, complete features/modules under a tight schedule and the capability for rational thinking.\nExperience with the database management tool SQL is a plus, but not mandatory.\nObtained bachelor\u2019s degree in any relevant major (e.g. Information Technology, Computer Science, etc.).\nPerks of joining the team:\nCompetitive compensation & benefits package\nRemote Work Environment\nHow to get started:\nIf you\u2019re up for the challenge to be part of a growing engineering team we\u2019d like to hear from you. Apply today!\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "Java",
                "Scala",
                "R",
                "Go"
            ],
            "DataBase": [
                "SQL"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [],
            "MachingLearning": [
                "Orange"
            ],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [],
            "DevTools": [
                "Git"
            ],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [
                "Teams"
            ],
            "Other": [
                "DevOps",
                "Machine Learning"
            ],
            "FrSoftSkills": [],
            "EnSoftSkils": []
        },
        "details": {
            "JobDetail": [
                "Remote"
            ],
            "TypeContract": [],
            "Salary": [
                "Package"
            ],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "Data Scientist F/H",
        "company": "ANSSI - Agence nationale de la s\u00e9curit\u00e9 des syst\u00e8mes d'information",
        "location": "Rennes, Brittany, France",
        "link": "https://fr.linkedin.com/jobs/view/data-scientist-f-h-at-anssi-agence-nationale-de-la-s%C3%A9curit%C3%A9-des-syst%C3%A8mes-d-information-3908569591?position=6&pageNum=15&refId=UW%2F6rZ%2F9O8vzcgR6IhOXYQ%3D%3D&trackingId=cbgws5OaScEgGKmjrTqOqw%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "T\u00e9l\u00e9charger en PDF\nDescriptif de l'organisation\nRejoindre l\u2019Agence nationale de la s\u00e9curit\u00e9 des syst\u00e8mes d\u2019information (ANSSI), c\u2019est mettre ses comp\u00e9tences au service de l\u2019int\u00e9r\u00eat g\u00e9n\u00e9ral en participant \u00e0 une mission capitale, d\u2019actualit\u00e9 et porteuse de grandes responsabilit\u00e9s dans un monde o\u00f9 la cybers\u00e9curit\u00e9 est devenue l\u2019affaire de tous !\nAu sein de la Sous-direction-Op\u00e9ration (SDO), se trouve la division-d\u00e9tection (DD) dont le bureau Dispositifs de D\u00e9tection Syst\u00e8me (DDS) met en \u0153uvre la capacit\u00e9 de d\u00e9tection syst\u00e8me, c\u2019est-\u00e0-dire l\u2019ensemble des proc\u00e9d\u00e9s adapt\u00e9s \u00e0 la caract\u00e9risation d\u2019activit\u00e9s malveillantes \u00e0 partir d\u2019\u00e9v\u00e8nements g\u00e9n\u00e9r\u00e9s au niveau des syst\u00e8mes d\u2019exploitation.\nDescriptif des missions\nEn s\u2019appuyant sur les connaissances des ing\u00e9nieurs en cyberd\u00e9fense, vous \u00eates responsable des algorithmes de d\u00e9tection, de la phase de conception \u00e0 la mise en production. Vous avez \u00e0 votre disposition les donn\u00e9es collect\u00e9es par le bureau, issues de journaux d\u2019\u00e9v\u00e9nements de postes de travail ou de serveurs (Windows Security, Sysmon, Auditd\u2026).\nV\u00e9ritable r\u00e9f\u00e9rent au sein de l'\u00e9quipe, vous \u00eates est en mesure de proposer et tester de nouvelles id\u00e9es en liens avec des probl\u00e9matiques concr\u00e8tes, d'am\u00e9liorer des algorithmes existant, mais aussi d'accompagner les analystes dans l'interpr\u00e9tation des r\u00e9sultats.\nLe Caract\u00e8re Op\u00e9rationnel Des Missions Assur\u00e9es Par Le Bureau N\u00e9cessite Que Les Travaux Men\u00e9s R\u00e9pondent \u00e0 Un Fort Enjeu D'exploitabilit\u00e9. A Cette Fin, L\u2019agent Data-Scientiste Aura Pour Missions De\nProposer et mettre en place des algorithmes de d\u00e9tection d\u2019intrusions ;\nAssurer une veille des derniers papiers de recherche sur les sujets de Data Science, en particulier sur la d\u00e9tection d\u2019anomalies et le NLP ;\nTravailler avec d\u2019autres \u00e9quipes expertes en traitement de la donn\u00e9e, et des \u00e9quipes expertes en s\u00e9curit\u00e9 informatique ;\nConcevoir des m\u00e9thodes de r\u00e9duction du taux de faux positifs ;\nPr\u00e9parer et assurer le maintien en condition op\u00e9rationnelle et de s\u00e9curit\u00e9, notamment via l'am\u00e9lioration d'outils de monitoring ;\nR\u00e9diger des documents techniques.\nProfil recherch\u00e9\nVous \u00eates dipl\u00f4m\u00e9(e) d\u2019une formation de type \u00e9cole d\u2019ing\u00e9nieur ou d\u2019un cursus universitaire \u00e9quivalent dans le domaine du traitement de la donn\u00e9e. Une exp\u00e9rience d\u2019au moins 3 ans est souhait\u00e9e.\nComp\u00e9tences Requises\nMaitrise de Python et des principales biblioth\u00e8ques de data science : pandas, numpy, scikit-learn\u2026 ;\nMaitrise des principales m\u00e9thodes de Machine Learning et Deep Learning ;\nConnaissances en NLP ;\nMaitrise des concepts statistiques sous-jacents aux m\u00e9thodes d\u2019analyses de donn\u00e9es, et des biais \u00e9ventuels\nDes connaissances dans les domaines suivants seront des atouts importants :\nScripting PowerShell et Bash ;\nGit, DevSecOps, orchestration de conteneurs ;\nFonctionnement des syst\u00e8mes d\u2019exploitation (Windows, Linux\u2026) ;\nAutonomie, rigueur et capacit\u00e9 \u00e0 travailler seul ou en \u00e9quipe sont des comp\u00e9tences indispensables.\nSavoir \u00catre\nAvoir le sens du service public ;\nAutonomie et capacit\u00e9 d'adaptation ;\nDynamique et rigoureux/euse.\nProcess de recrutement\nSi votre candidature est pr\u00e9s\u00e9lectionn\u00e9e, vous serez contact\u00e9(e) pour appr\u00e9cier vos attentes et vos motivations au cours d'un entretien t\u00e9l\u00e9phonique ou physique.\nDes tests techniques pourront vous \u00eatre propos\u00e9s.\nVous ferez l'objet d'une proc\u00e9dure d'habilitation.\nJe postule\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "R",
                "Go",
                "Bash"
            ],
            "DataBase": [],
            "DataAnalytics": [
                "Pandas",
                "NumPy",
                "R"
            ],
            "BigData": [],
            "MachingLearning": [
                "Scikit-Learn"
            ],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [
                "Statistiques"
            ],
            "CloudComputing": [],
            "DevTools": [
                "Git"
            ],
            "Os": [
                "Linux",
                "Windows"
            ],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [
                "Machine Learning",
                "Statistiques"
            ],
            "FrSoftSkills": [
                "Organisation"
            ],
            "EnSoftSkils": []
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s",
                "3",
                "3",
                "3"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "Data Scientist",
        "company": "SMARTIUM Group",
        "location": "Strasbourg, Grand Est, France",
        "link": "https://fr.linkedin.com/jobs/view/data-scientist-at-smartium-group-3835671392?position=7&pageNum=15&refId=UW%2F6rZ%2F9O8vzcgR6IhOXYQ%3D%3D&trackingId=iX64AGxmDW8c9a8VHxLf0w%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "SMARTIUM Group est une jeune startup bas\u00e9e \u00e0 Starsbourg qui propose des technologies de mesure des rayonnements ionisants dans les domaines de l'industrie, de la sant\u00e9 et de la s\u00e9curit\u00e9. Dans le cadre de notre d\u00e9veloppement nous recherchons\nun(e) Data Scientist\n.\nNos solutions embarqu\u00e9es \u00e0 forte valeur ajout\u00e9e permettent une analyse avanc\u00e9e des dnn\u00e9es fournies par les syst\u00e8mes de mesure et par la mod\u00e9lisation num\u00e9rique (monte carlo).\nIssue de la valorisation des travaux de recherche, SMARTIUM Group b\u00e9n\u00e9ficie d'un lien renforc\u00e9 avec la recherche (CNRS) et les universit\u00e9s.\nVos missions\nVous \u00eates titulaire d'un Bac+5 et/ou doctorat en science de pr\u00e9f\u00e9rence, et vous avez pu d\u00e9velopper des comp\u00e9tences en simulation Monte Carlo (Genat4, MCNP, ...) et/ou en science des donn\u00e9es (analyse statistique, apprentissage automatique, intelligence artificielle). Vous souhaitez valoriser ces comp\u00e9tences dans un environnement professionnel dynamique d'une jeune startup Deeptech en lien direct avec la recherche.\nRattach\u00e9 directement au CEO vous contriburez au d\u00e9veloppement de solutions innovantes vari\u00e9es pour des probl\u00e9matiques sant\u00e9s, industrielles et environnementales.\nVotre implication et votre r\u00e9ussite feront de vous un \u00e9l\u00e9ment cl\u00e9 du d\u00e9veloppement de l'entreprise. Des prerspectives d'encadrement d'\u00e9quipe sont envisag\u00e9es pour les profils faisant preuve de qualit\u00e9s manag\u00e9riales.\nVos comp\u00e9tences\nBac +5 en science/ physique nucl\u00e9aire ; Int\u00e9r\u00eat fort pour la science des donn\u00e9es ; une exp\u00e9rience/formation en simulation Monte Carlo serait un plus ; une ap\u00e9tence pour l'analyse des donn\u00e9es ; des connaissance en Intelligence Artificielle serait un plus ;\nAvantages\nAmbiance startup - Equipe dynamique - Salaire suivant profil + avantages\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "R"
            ],
            "DataBase": [],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [],
            "DevTools": [],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [],
            "FrSoftSkills": [],
            "EnSoftSkils": []
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [],
            "Salary": [
                "Salaire"
            ],
            "Level": [
                "Bac+5"
            ],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "Machine Learning Engineer",
        "company": "Pernod Ricard",
        "location": "Paris, \u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/machine-learning-engineer-at-pernod-ricard-3896432442?position=8&pageNum=15&refId=UW%2F6rZ%2F9O8vzcgR6IhOXYQ%3D%3D&trackingId=I%2BExyuc1CEw%2BhbqoEtypHA%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Want to join a fast-moving company, work among convivial teams and take part in the global growth strategy of one of the most prestigious and comprehensive portfolios in the wine & spirits industry?\nWe are looking for our Machine Learning Engineers\u200b!\nYou will be based at The Island, our office in central Paris.\nIn this role, you\u2019ll have the chance to roll up your sleeves to make the date science models operational.\nYour key missions:\nReport directly to the manager of team Machine Learning Engineers and Research Scientists, you will join our cross-functional team of machine learning engineers, research scientists, data scientists and data engineers to contribute to the KEY DIGITAL PROGRAMS:\n\u00b7 You will contribute to the MLOps process implementation to maintain ML models in production.\n\u00b7 You will collaborate with the team to deploy or improve scalable and efficient ML pipelines using best MLOps practices.\n\u00b7 You will collaborate with the team on production-quality service development with Unit & Integration testing, CI/CD & devOps for these services.\n\u00b7 You will identify new opportunities to improve go-to-production, MLOps processes.\n\u00b7 You will apply software development practices and standards to enhance and ensure the code quality of our applications.\n\u00b7 You will maintain an active role in every part of the software development life cycle.\n\u00b7 You will actively contribute to Data platform community.\nIf you recognize yourself in the description below, don\u2019t wait to apply!\nYour profile:\n\u00b7 You have a master diploma (or equivalent) in Computer Science, Computer Engineering, or quantitative science fields, a PhD is a plus.\n\u00b7 You have more than 2 years implementation experience with high-level languages, such as Python, Scala, Java, C/C++.\n\u00b7 You have knowledge and experience with cloud and deployment technologies. Knowing Microsoft Azure is a plus.\n\u00b7 You have experience in building or improving CI/CD pipelines.\n\u00b7 You have knowledge and experience with container tools such as Docker.\n\u00b7 You are familiar with MLOps practices (Azure ML Studio, Mlfow)\n\u00b7 You have knowledge and experience in designing and building APIs with Python\n\u00b7 You have first experiences in data science and applying machine learning algorithms and libraries (Pandas, Scikit-learn, Pytorch ...)\n\u00b7 You are fluent in English, speaking French is a plus.\nWe will appreciate if you are familiar with:\n\u00b7 Microservices architecture\nYour soft skills:\n\u00b7 You have very good oral and written communication skills\n\u00b7 You have an analytic reasoning and problem-solving skills.\n\u00b7 You are service-oriented, flexible and a team player.\n\u00b7 You have a real attention to detail and a technical intuition.\n\u00b7 You are driven by passion and willingness to learn and explorer.\nIf you don\u2019t fill 100% of the criteria below don\u2019t panic, we expect you to learn with us in this position.\nWait, there\u2019s more\u2026\nWe offer you an outstanding and collaborative workplace that embodies our sharing & conviviality culture, the possibility to work from home (2 days a week), a very complete health insurance, an attractive compensation including profit-sharing, train daily, employee events\u2026\nPernod Ricard values diversity and solidarity within its organization and in its relations with stakeholders. Our recruitment methods focus on skills, and we welcome all types of talents.\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "Java",
                "C++",
                "Scala",
                "R",
                "Go"
            ],
            "DataBase": [],
            "DataAnalytics": [
                "Pandas",
                "R"
            ],
            "BigData": [],
            "MachingLearning": [
                "Scikit-Learn",
                "PyTorch"
            ],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [
                "Azure"
            ],
            "DevTools": [
                "Git",
                "Docker"
            ],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [
                "Docker"
            ],
            "Collaboration": [
                "Teams"
            ],
            "Other": [
                "DevOps",
                "ML",
                "Machine Learning",
                "Cloud",
                "CI/CD"
            ],
            "FrSoftSkills": [
                "Communication"
            ],
            "EnSoftSkils": [
                "Communication",
                "Organization"
            ]
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "Ing\u00e9nieur Data Scientist (H/F) \u00e0 Grenoble",
        "company": "Sully Group",
        "location": "Grenoble, Auvergne-Rh\u00f4ne-Alpes, France",
        "link": "https://fr.linkedin.com/jobs/view/ing%C3%A9nieur-data-scientist-h-f-%C3%A0-grenoble-at-sully-group-3905268593?position=9&pageNum=15&refId=UW%2F6rZ%2F9O8vzcgR6IhOXYQ%3D%3D&trackingId=OJO2eRgzV7BMOheUjjp2dw%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Au sein d'une \u00e9quipe de 6 personnes, vous intervenez en mission chez notre client bas\u00e9 \u00e0 Grenoble comme Data Ing\u00e9nieur.\nVous participerez \u00e0 un nouveau projet orient\u00e9 Intelligence Artificielle appliqu\u00e9e \u00e0 la mobilit\u00e9.\nVos missions\nCollecter, transformer et nettoyer des donn\u00e9es extraites\nCr\u00e9ation de tableaux de bord\nContribuer \u00e0 l\u2019effort d\u2019animation technique, de veille technologique et d\u2019innovation\nParlons de vous\nVous poss\u00e9dez une premi\u00e8re exp\u00e9rience comme Data Scientist\nVous maitrisez Python\nVous avez l'esprit d'\u00e9quipe\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "R"
            ],
            "DataBase": [],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [
                "Tableau"
            ],
            "Statistics": [],
            "CloudComputing": [],
            "DevTools": [],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [],
            "FrSoftSkills": [],
            "EnSoftSkils": []
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "Data scientist F/H",
        "company": "Fnac Darty",
        "location": "Ivry-sur-Seine, \u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/data-scientist-f-h-at-fnac-darty-3805367610?position=10&pageNum=15&refId=UW%2F6rZ%2F9O8vzcgR6IhOXYQ%3D%3D&trackingId=465OVQTP4DsV%2FUslDuz65Q%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Fnac Darty, un leader europ\u00e9en de la distribution omnicanal. Acteur omnicanal et europ\u00e9en, sp\u00e9cialis\u00e9 dans la distribution de produits techniques et d'\u00e9lectrom\u00e9nager, de biens culturels et de loisirs, et leader du service apr\u00e8s-vente : 975 magasins dans le monde, 27 Millions de visiteurs uniques cumul\u00e9s par mois sur nos sites marchands. Nos 25 000 collaborateurs sont notre meilleur atout. Ils font vivre la raison d'\u00eatre du Groupe au quotidien, qui consiste \u00e0 \u00ab s'engager pour un choix \u00e9clair\u00e9 et une consommation durable \u00bb, aupr\u00e8s de nos clients. Fnac Darty recrute partout en France des talents aux profils, formations et exp\u00e9riences tr\u00e8s diverses, que ce soit pour ses magasins, mais aussi dans les domaines de la logistique, de la r\u00e9paration et service apr\u00e8s-vente, de la livraison, de la relation client ou encore pour ses fonctions support. Votre prochain emploi vous attend chez Fnac Darty !\nLe groupe Fnac-Darty acc\u00e9l\u00e8re sa trajectoire dans la data et l\u2019IA.\nVous souhaitez mettre en oeuvre et d\u00e9velopper vos comp\u00e9tences en data science sur des projets \u00e0 fort impact dans un march\u00e9 en \u00e9volution rapide ? Vous voulez travailler dans une \u00e9quipe dynamique aussi passionn\u00e9e que comp\u00e9tente et d\u00e9velopper votre carri\u00e8re ? Alors n\u2019h\u00e9sitez plus et rejoignez-nous au sein du groupe Fnac-Darty !\nVous rejoindrez la direction de la Transformation Data & IA du Groupe au sein du d\u00e9partement Strat\u00e9gie et Transformation et travaillerez sur des sujets-cl\u00e9s visant impact et transformation de nos m\u00e9tiers dans l\u2019ensemble des activit\u00e9s du groupe. Sujets parmi lesquels peuvent figurer par exemple l\u2019am\u00e9lioration de l\u2019exp\u00e9rience client et de l\u2019efficience de nos interactions (service apr\u00e8s-vente,\u2026), l\u2019optimisation de nos budgets promotionnels, le scoring d\u2019app\u00e9tence des utilisateurs, le churn, l\u2019activation d\u2019audiences, la personnalisation des parcours, la d\u00e9tection d\u2019anomalies, etc\u2026\nForts d\u2019une implantation particuli\u00e8rement forte en France et \u00e0 l\u2019international tant via Internet que via nos magasins, experts reconnus et marques appr\u00e9ci\u00e9es, nous agissons sur une gamme de produits, de services et d\u2019\u00e9v\u00e9nements extr\u00eamement large aupr\u00e8s d\u2019une large partie des populations de ces pays. Vous travaillerez donc sur des donn\u00e9es tr\u00e8s riches dans un environnement technologique \u00e0 la pointe.\nVotre profil\nEcole d\u2019ing\u00e9nieurs (Centrale, ENS, Mines, Ecole Polytechnique, etc\u2026) en formation initiale, avec sp\u00e9cialisation en math\u00e9matiques / data science / machine learning\nVous connaissez les math\u00e9matiques derri\u00e8re les algorithmes et \u00eates capable de r\u00e9fl\u00e9chir un algorithme d\u00e9di\u00e9 si besoin et de le mettre en oeuvre\nVous \u00eates exp\u00e9riment\u00e9 sur le cloud, Google Cloud appr\u00e9ci\u00e9 (dont en particulier BigQuery, Compute Engine, Cloud Storage) et vous ma\u00eetrisez les librairies d\u00e9di\u00e9es (command-line + Python) ainsi que les outils de versioning tel git\nBash, SQL et Python sont des langages que vous ma\u00eetrisez \u00e0 un niveau avanc\u00e9\nVous \u00eates capables d\u2019int\u00e9grer les flux de donn\u00e9es n\u00e9cessaires de mani\u00e8re automatique et p\u00e9renne\nVous savez passer vos algorithmes \u00e0 l\u2019\u00e9chelle et mettre en oeuvre un ensemble robuste et stable sur de grosses volum\u00e9tries pour d\u00e9ploiement en production ; mieux, vous pensez le passage \u00e0 l\u2019\u00e9chelle et l\u2019industrialisation d\u00e8s le d\u00e9but du projet\nVous \u00eates capables de construire les analyses et algorithmes pertinents avec une palette large et compl\u00e8te d\u2019outils (librairies Python d\u00e9di\u00e9es ; features GCP exploitables ; BigQuery ; \u2026), mais aussi de construire des visualisations\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "R",
                "Go",
                "Bash"
            ],
            "DataBase": [
                "SQL"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [],
            "DevTools": [
                "Git"
            ],
            "Os": [],
            "DBMS": [
                "BigQuery"
            ],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [
                "Machine Learning",
                "Cloud"
            ],
            "FrSoftSkills": [],
            "EnSoftSkils": []
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    }
]