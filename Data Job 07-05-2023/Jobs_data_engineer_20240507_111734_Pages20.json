[
    {   
		"source": "LinkedIn",
        "title": "DATA ENGINEER (H/F)",
        "company": "SFR",
        "location": "Paris, \u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/data-engineer-h-f-at-sfr-3879318123?position=2&pageNum=0&refId=b67kRduAUeEfaeVnXh9rCA%3D%3D&trackingId=02j4YeDzqfcHedAZ%2BJWgJw%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "En tant que Data Ing\u00e9nieur exp\u00e9riment\u00e9, vous occuperez un r\u00f4le essentiel dans notre \u00e9quipe Data Science.\nVous serez responsable de la conception, du d\u00e9veloppement et de la maintenance des pipelines de donn\u00e9es ainsi que de l'int\u00e9gration de sources de donn\u00e9es multiples.\nVotre expertise sera cruciale pour garantir une gestion efficace des flux de donn\u00e9es, ainsi que pour faciliter l'analyse et la visualisation des donn\u00e9es en plus du support aux data scientists vos missions seront les suivantes :\nArchitecture projet des donn\u00e9es\n: Concevoir et d\u00e9velopper des architectures projet de donn\u00e9es robustes, \u00e9volutives et performantes pour int\u00e9grer et g\u00e9rer de grandes quantit\u00e9s de donn\u00e9es provenant de sources multiples. Assurer la fiabilit\u00e9, l'\u00e9volutivit\u00e9 et la s\u00e9curit\u00e9 des flux de donn\u00e9es entrant d\u2019un projet Data Science.\nInt\u00e9gration des donn\u00e9es\n: \u00c9laborer des pipelines de donn\u00e9es efficaces pour l'extraction, la transformation et le chargement des donn\u00e9es (via notre Framework ELT/ETL interne) provenant de diff\u00e9rentes sources. Mettre en place des processus d'int\u00e9gration automatis\u00e9s et veiller \u00e0 la qualit\u00e9 des donn\u00e9es.\nGestion des bases de donn\u00e9es\n: Concevoir et optimiser des bases de donn\u00e9es pour r\u00e9pondre aux besoins analytiques et de reporting. Assurer la performance, la disponibilit\u00e9 et la s\u00e9curit\u00e9 des bases de donn\u00e9es, ainsi que la gestion efficace des requ\u00eates.\nCollaboration interfonctionnelle\n: Support des Data Scientists, vous travaillerez avec les \u00e9quipes business pour comprendre leurs besoins et fournir des conseils et des recommandations bas\u00e9s sur les donn\u00e9es.\nOptimisation des performances\n: Surveiller et optimiser les performances des pipelines de donn\u00e9es, des bases de donn\u00e9es et des requ\u00eates. Identifier les goulots d'\u00e9tranglement et les points d'optimisation, et proposer des am\u00e9liorations pour garantir des performances optimales.\nS\u00e9curit\u00e9 et conformit\u00e9\n: Veiller \u00e0 ce que les donn\u00e9es soient trait\u00e9es et stock\u00e9es conform\u00e9ment aux normes de s\u00e9curit\u00e9 et de confidentialit\u00e9. Mettre en place des m\u00e9canismes de s\u00e9curit\u00e9 pour prot\u00e9ger les donn\u00e9es sensibles et garantir la conformit\u00e9 aux r\u00e9glementations en vigueur.\nVotre profil :\nVous avez un\nDipl\u00f4me universitaire en informatique, en g\u00e9nie logiciel, en science des donn\u00e9es ou dans un domaine connexe et vous avez \u00e0 minima 5 ans d'exp\u00e9rience en tant que Data Ing\u00e9nieur.\nVous poss\u00e9dez \u00e9galement une solide ma\u00eetrise des technologies et des outils suivants :\nHadoop, Spark, SQL, Kafka, GCP BigQuery,\nDe plus vous avez une bonne compr\u00e9hension des architectures, des mod\u00e8les et des concepts de base de donn\u00e9s avec une exp\u00e9rience avanc\u00e9e dans la mise en \u0153uvre de pipelines ETL et dans la gestion de bases de donn\u00e9es.\nVos connaissances en mati\u00e8re de s\u00e9curit\u00e9 des donn\u00e9es, de conformit\u00e9 aux r\u00e9glementations ainsi que vos comp\u00e9tences en programmation scripting et en d\u00e9veloppement logiciel seront un plus.\nVos excellentes comp\u00e9tences en communication seront des qualit\u00e9s appr\u00e9ci\u00e9es et\nun niveau d'anglais (appliqu\u00e9e au domaine technique) est un plus.\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "R",
                "Go"
            ],
            "DataBase": [
                "SQL"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [
                "Hadoop",
                "Spark"
            ],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [],
            "DevTools": [],
            "Os": [],
            "DBMS": [
                "BigQuery"
            ],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [],
            "FrSoftSkills": [
                "Communication",
                "Collaboration"
            ],
            "EnSoftSkils": [
                "Communication",
                "Collaboration"
            ]
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s",
                "5",
                "5",
                "5"
            ]
        }
    },
    {   
		"source": "LinkedIn",
        "title": "Data Engineer - Lille",
        "company": "Capgemini",
        "location": "Greater Lille Metropolitan Area",
        "link": "https://fr.linkedin.com/jobs/view/data-engineer-lille-at-capgemini-3914228495?position=3&pageNum=0&refId=b67kRduAUeEfaeVnXh9rCA%3D%3D&trackingId=1bNEMjrDx4lwdAM9LaPuxQ%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Capgemini en quelques mots\nChoisir Capgemini, c'est choisir une entreprise o\u00f9 vous serez en mesure de fa\u00e7onner votre carri\u00e8re selon vos aspirations, o\u00f9 vous serez soutenu et inspir\u00e9 par une communaut\u00e9 d\u2019experts dans le monde entier, o\u00f9 vous pourrez r\u00e9\u00e9crire votre futur. Rejoignez-nous pour red\u00e9finir les limites de ce qui est possible, contribuer \u00e0 lib\u00e9rer la valeur de la technologie pour les plus grandes organisations et participez \u00e0 la construction d\u2019un monde plus durable et inclusif.\nVos missions\nVous maitrisez au minimum un langage de programmation appliqu\u00e9 \u00e0 l\u2019analyse de donn\u00e9es\n(Java, Python, Scala et les environnements Spark et / ou Hadoop).\nVous \u00eates passionn\u00e9 par le Big Data et le Machine Learning et l\u2019analyse de donn\u00e9es\nVous concevez et mettez en \u0153uvre des strat\u00e9gies s\u00e9curis\u00e9es d'acquisition et d'int\u00e9gration de donn\u00e9es\nVous configurez des r\u00e9f\u00e9rentiels de donn\u00e9es \u00e0 la pointe de la technologie dans des environnements distribu\u00e9s\nVous construisez des pipelines de donn\u00e9es pour collecter, transformer et traiter des donn\u00e9es en collaboration avec des scientifiques de donn\u00e9es afin de r\u00e9pondre aux exigences de la mod\u00e9lisation de donn\u00e9es d'analyse avanc\u00e9e\nVotre profil\nDipl\u00f4m\u00e9(e) de Bac+5 en informatique\n4 ans d\u2019exp\u00e9rience\n(au sein d\u2019une ESN ou chez un int\u00e9grateur) en conseil client\u00e8le\nUne solide culture technologique\nUn bon niveau d\u2019anglais\n3 raisons de nous rejoindre\nQualit\u00e9 de vie au travail :\naccord de t\u00e9l\u00e9travail en France et \u00e0 l\u2019international, accord sur l\u2019\u00e9galit\u00e9\nprofessionnelle, la parentalit\u00e9, l\u2019\u00e9quilibre des temps et la mobilit\u00e9 durable.\nApprentissage en continu :\ncertifications et formations en libre acc\u00e8s, accompagnement sur mesure avec\nvotre carreer manager, parcours d\u2019int\u00e9gration sur 9 mois.\nAvantages groupe & CSE :\nplan actionnariat, activit\u00e9s \u00e0 tarifs pr\u00e9f\u00e9rentiels, remboursement partiel\nvacances, remboursement de votre abonnement sportif ou culturel\nNos engagements et priorit\u00e9s\nLe groupe Capgemini encourage une\nculture inclusive dans un cadre multiculturel et handi-accueillant.\nEn nous rejoignant, vous int\u00e9grez un collectif qui valorise la diversit\u00e9, d\u00e9veloppe le potentiel de ses talents, s\u2019engage dans des\ninitiatives solidaires avec ses partenaires, et se mobilise pour r\u00e9duire son impact environnemental sur tous ses sites et aupr\u00e8s de ses clients.\nCapgemini\nest un\nleader mondial\n, responsable et multiculturel, regroupant pr\u00e8s de 350 000 personnes dans plus de 50 pays. Fort de\n55 ans d\u2019exp\u00e9rience,\nnous sommes un partenaire strat\u00e9gique des entreprises pour la transformation de leurs activit\u00e9s en tirant profit de toute la puissance de la technologie et des innovations dans les domaines en perp\u00e9tuelle \u00e9volution tels que le\ncloud, la data, l\u2019Intelligence Artificielle, la connectivit\u00e9, les logiciels, l\u2019ing\u00e9nierie digitale ou les plateformes.\nGet The Future You Want* | www.capgemini.com/fr-fr\n*Capgemini, le futur que vous voulez\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "Java",
                "Scala",
                "R"
            ],
            "DataBase": [],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [
                "Hadoop",
                "Spark"
            ],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [],
            "DevTools": [
                "Git"
            ],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [
                "Big Data",
                "Machine Learning",
                "Cloud"
            ],
            "FrSoftSkills": [
                "Collaboration",
                "Organisation"
            ],
            "EnSoftSkils": [
                "Collaboration",
                "Initiative"
            ]
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [],
            "Salary": [],
            "Level": [
                "Bac+5"
            ],
            "Experience": [
                "a",
                "n",
                "s",
                "4",
                "4",
                "4"
            ]
        }
    },
    {   
		"source": "LinkedIn",
        "title": "Data Engineer (F/H)",
        "company": "Thales",
        "location": "V\u00e9lizy-Villacoublay, \u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/data-engineer-f-h-at-thales-3908228180?position=4&pageNum=0&refId=b67kRduAUeEfaeVnXh9rCA%3D%3D&trackingId=p249HvSiTp4FSVBFlTAldQ%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "QUI SOMMES-NOUS ?\nThales est un leader mondial des hautes technologies comptant plus de 81 000 collaborateurs pr\u00e9sents sur tous les continents. Le Groupe investit dans les innovations du num\u00e9rique et de la \u00ab deep tech \u00bb \u2013 big data, intelligence artificielle, connectivit\u00e9, cybers\u00e9curit\u00e9 et quantique \u2013 pour construire un avenir de confiance, essentiel au d\u00e9veloppement de nos soci\u00e9t\u00e9s, en pla\u00e7ant l\u2019humain au c\u0153ur des d\u00e9cisions.\nThales propose des solutions, services et produits qui aident ses clients \u2013 entreprises, organisations, Etats \u2013 dans cinq grands march\u00e9s vitaux pour le fonctionnement de nos soci\u00e9t\u00e9s : identit\u00e9 et s\u00e9curit\u00e9 num\u00e9riques, d\u00e9fense, a\u00e9ronautique, espace, et transport.\nQUI ETES-VOUS ?\nDipl\u00f4m\u00e9 d\u2019un Bac+5 en \u00e9cole d\u2019ing\u00e9nieur ou \u00e9quivalent universitaire avec une sp\u00e9cialisation en informatique, vous avez au moins 3 ans d'exp\u00e9rience dans les technologies Big Data.\nCE QUE NOUS POUVONS ACCOMPLIR ENSEMBLE :\nEn tant que Data Engineer, vous jouerez un r\u00f4le cl\u00e9 dans la conception, le d\u00e9veloppement et la maintenance de notre infrastructure de donn\u00e9es, ainsi que dans la transformation et la gestion des flux de donn\u00e9es.\nVOS MISSIONS :\n\u2022 Concevoir, d\u00e9velopper et d\u00e9ployer des solutions Big Data en utilisant les technologies Hadoop.\n\u2022 Mettre en place des pipelines de donn\u00e9es performants pour l'ingestion, le traitement et le stockage des donn\u00e9es massives.\n\u2022 Collaborer \u00e9troitement avec les \u00e9quipes m\u00e9tier pour comprendre leurs besoins en mati\u00e8re d'analyse de donn\u00e9es et proposer des solutions adapt\u00e9es.\n\u2022 Optimiser les performances des clusters Hadoop pour garantir une exploitation efficace des donn\u00e9es.\n\u2022 Assurer la qualit\u00e9 et la fiabilit\u00e9 des donn\u00e9es trait\u00e9es, en mettant en place des processus de validation et de nettoyage.\n\u2022 Identifier et r\u00e9soudre les probl\u00e8mes li\u00e9s \u00e0 l'infrastructure Big Data et proposer des am\u00e9liorations.\n\u2022 Travailler en \u00e9troite collaboration avec les Data Scientists et les Data Analysts pour fournir des insights pertinents \u00e0 partir des donn\u00e9es.\nInnovation, passion, ambition : rejoignez Thales et cr\u00e9ez le monde de demain, d\u00e8s aujourd\u2019hui.\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "R"
            ],
            "DataBase": [],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [
                "Hadoop"
            ],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [],
            "DevTools": [],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [
                "Big Data"
            ],
            "FrSoftSkills": [
                "Collaboration",
                "Organisation"
            ],
            "EnSoftSkils": [
                "Collaboration"
            ]
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [],
            "Salary": [],
            "Level": [
                "Bac+5"
            ],
            "Experience": [
                "a",
                "n",
                "s",
                "3",
                "3",
                "3"
            ]
        }
    },
    {	
		"source": "LinkedIn",
        "title": "Data Solutions Engineer (Data & AI)",
        "company": "LVMH",
        "location": "Paris, \u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/data-solutions-engineer-data-ai-at-lvmh-3900392289?position=5&pageNum=0&refId=b67kRduAUeEfaeVnXh9rCA%3D%3D&trackingId=eaNM3PFCRsmq1V%2BoOCrajg%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "LVMH is the #1 Luxury group and is currently accelerating rapidly on digitalisation. It is bringing technology and innovation in the core of the established 75+ Maisons by inventing unique and powerful products and services.\nWe are looking for talented solution engineers (Software, Cloud, Data and AI) to join our team and be part of this tech revolution of bringing the Group and its Maisons to the next level.\nIf you believe Data and AI can enhance the retail industry, from the day-to-day operational tasks to the long term customer experience,\nIf you think that the Cloud technologies (we love Google Cloud) is a revolution for Data and AI products,\nIf you like building tech solutions having direct impacts on billion-dollar-valued businesses,\nIf you have good communication skills and like sharing your knowledge,\nApply now, and join us!\nThe mission\nThe Solution Engineer is providing advices and technical assets to the Maisons having Data & AI projects.\nOur team (Group Data team) is building a technical framework for all the Maisons to implement easily and quickly Data and AI use cases. Your mission will be to support the Maisons to convert their use case needs to concrete and production ready technical solutions using our framework and tools.\nYou will cover a portfolio of Maisons, in direct contact with their business analysts, data scientists and IT teams. You will be their dedicated referent on the Data & AI technical topics (Data platform, AI/ML softwares, data transport and transformations, data quality).\nMain responsibilities\nYou will be responsible of providing support and advices to a portfolio of Maisons on Data & AI tech topics (Cloud, Data stacks, Data transformations, Data transfers, ML ops).\nYou will keep a recurrent discussion with the Maisons to accelerate their projects and immediately provide our support when it's needed.\nYou will follow-up the engaged productions in the Maisons and report them to the global group data strategy committees.\nApplying the quality and security standards. Making them evolve if necessary.\nProducing realistic, understandable and documented solutions following the group guidelines.\nSharing and learning from the team by communicating difficulties and successes, taking and bringing honest feedbacks and improving the identified pain points.\nTaking responsibility as member of the team on the product performances (delivery and long term usage)\nRequired expertise and knowledge\nAbility to build technical solutions answering concrete usage (User Stories) and communicate them to the team.\nDimension and evaluate complexity for technical solution productions.\nExtensive knowledge and experience with good learning and sharing abilities.\nEvaluate quickly risks and opportunities about technical choices.\nSolid oral, written, presentation and interpersonal communication and relationship skills.\nProblem-solving skills on Data and AI, coding and software development\nTech lover\nFeedback taker and giver\nTeam player\nKey benefits to join our team\nAttractive packages\nOffices in the 8th arrondissement near the Champs Elys\u00e9es\nFlexibility on the working hours\nRemote work possible (~40%)\n7 weeks of holidays (cong\u00e9s pay\u00e9s + RTT)\nLVMH brands exclusive private sales\nGreat employee committee and health insurance (CE, mutuelle)\nLast generation MacBooks\nPart of a young, motivated and tech savvy team. Get prepared for the Thursday drinks and the tech meet-ups!\nYou\u2019re eligible if\nYou have a strong experience (3+ years) in cloud data architecting or consultancy.\nYou graduated from an engineering (or equivalent) with a master\u2019s degree. Computer Science knowledge is mandatory.\nExperience on data stacks and/or Google Cloud (built in components) is a huge plus.\nFrench and English both written and oral (Maisons are all over the world)\nYou\u2019re thrilled to support the #1 luxury group to get even better.\nHiring Process\nCall with our HR partner dedicated to the Tech Team\nTechnical interview with the Solution Engineering Manager\nTechnical test\nInterview with the Head of Engineering\nStill here? Apply now!!\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "R",
                "Go"
            ],
            "DataBase": [],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [],
            "DevTools": [
                "Git"
            ],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [
                "Teams"
            ],
            "Other": [
                "ML",
                "Cloud"
            ],
            "FrSoftSkills": [
                "Communication"
            ],
            "EnSoftSkils": [
                "Communication",
                "Flexibility"
            ]
        },
        "details": {
            "JobDetail": [
                "Remote"
            ],
            "TypeContract": [],
            "Salary": [
                "40"
            ],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {	
		"source": "LinkedIn",
        "title": "Data Engineer \u2013 Grenoble",
        "company": "Capgemini",
        "location": "Grenoble, Auvergne-Rh\u00f4ne-Alpes, France",
        "link": "https://fr.linkedin.com/jobs/view/data-engineer-%E2%80%93-grenoble-at-capgemini-3905836212?position=6&pageNum=0&refId=b67kRduAUeEfaeVnXh9rCA%3D%3D&trackingId=RnAhVxcz3cUG9tZh23ItbQ%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Choisir Capgemini, c'est choisir une entreprise o\u00f9 vous serez en mesure de fa\u00e7onner votre carri\u00e8re selon vos aspirations. Avec le soutien et l'inspiration d'une communaut\u00e9 d\u2019experts dans le monde entier, vous pourrez r\u00e9\u00e9crire votre futur. Rejoignez-nous pour red\u00e9finir les limites de ce qui est possible, contribuer \u00e0 lib\u00e9rer la valeur de la technologie pour les plus grandes organisations et participer \u00e0 la construction d\u2019un monde plus durable et inclusif.\nVos missions :\nEn tant que Data Engineer au sein d'une \u00e9quipe multidisciplinaire, vos responsabilit\u00e9s principales seront les suivantes :\nIntervenir sur les diff\u00e9rentes phases d'un projet dans un environnement Cloud et Agile.\nContribuer \u00e0 la gestion de la qualit\u00e9 des donn\u00e9es et extraction et analyse de celle-ci, ainsi qu\u2019\u00e0 la pr\u00e9sentation des donn\u00e9es dans leur forme raffin\u00e9e.\nProposer des nouvelles lectures de donn\u00e9es via un travail de fouille sur les gisements d\u2019information, notamment client.\nAdopter une posture de consultant : proposer de nouvelles solutions et accompagner le client dans ses choix.\nVotre profil :\nTitulaire d'un Bac+5 en \u00e9cole d\u2019ing\u00e9nieur ou en universit\u00e9.\nConnaissances approfondies des ETL (Talend, Informatica ou SSIS), du traitement de donn\u00e9es (Spark, Python, Scala) ainsi que des bases de donn\u00e9es (Oracle, SQL Server, Postgres).\nFacult\u00e9 pour se montrer curieux, autonome et proactif dans la r\u00e9alisation de ses t\u00e2ches.\nCapacit\u00e9 \u00e0 faire preuve de rigueur et \u00e0 travailler en \u00e9quipe.\nBon niveau d\u2019anglais (B2 minimum).\n3 raisons de nous rejoindre :\nQualit\u00e9 de vie au travail\n: accord de t\u00e9l\u00e9travail en France et \u00e0 l\u2019international, accord sur l\u2019\u00e9galit\u00e9 professionnelle, la parentalit\u00e9, l\u2019\u00e9quilibre des temps et la mobilit\u00e9 durable.\nApprentissage en continu\n: certifications et formations en libre acc\u00e8s, accompagnement sur mesure avec votre career manager, parcours d\u2019int\u00e9gration sur 9 mois.\nAvantages groupe & CSE\n: plan actionnariat, tarif pr\u00e9f\u00e9rentiels, remboursement partiel vacances, remboursement de votre abonnement sportif ou culturel.\nNos engagements et priorit\u00e9s\n:\nLe groupe Capgemini encourage une culture inclusive dans un cadre multiculturel et handi-accueillant. En nous rejoignant, vous int\u00e9grez un collectif qui valorise la diversit\u00e9, d\u00e9veloppe le potentiel de ses talents, s\u2019engage dans des initiatives solidaires avec ses partenaires, et se mobilise pour r\u00e9duire son impact environnemental sur tous ses sites et aupr\u00e8s de ses clients.\n\u00c0 propos de Capgemini :\nCapgemini est un leader mondial, responsable et multiculturel, regroupant pr\u00e8s de 350 000 personnes dans plus de 50 pays. Fort de 55 ans d\u2019exp\u00e9rience, nous sommes un partenaire strat\u00e9gique des entreprises pour la transformation de leurs activit\u00e9s en tirant profit de toute la puissance de la technologie et des innovations dans les domaines en perp\u00e9tuelle \u00e9volution tels que le cloud, la data, l\u2019Intelligence Artificielle, la connectivit\u00e9, les logiciels, l\u2019ing\u00e9nierie digitale ou les plateformes.\nGet The Future You Want* | www.capgemini.com/fr-fr\n*Capgemini, le futur que vous voulez\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "Scala",
                "R"
            ],
            "DataBase": [
                "SQL"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [
                "Spark"
            ],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [],
            "DevTools": [
                "Git"
            ],
            "Os": [],
            "DBMS": [
                "Oracle",
                "SQL Server"
            ],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [
                "Cloud"
            ],
            "FrSoftSkills": [
                "Organisation"
            ],
            "EnSoftSkils": [
                "Initiative"
            ]
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [],
            "Salary": [],
            "Level": [
                "Bac+5"
            ],
            "Experience": [
                "a",
                "n",
                "s",
                "55",
                "55",
                "55"
            ]
        }
    },
    {	
		"source": "LinkedIn",
        "title": "Data Engineer H/F",
        "company": "Thales",
        "location": "Lyon, Auvergne-Rh\u00f4ne-Alpes, France",
        "link": "https://fr.linkedin.com/jobs/view/data-engineer-h-f-at-thales-3903089036?position=7&pageNum=0&refId=b67kRduAUeEfaeVnXh9rCA%3D%3D&trackingId=w99zOK4aMb4C6eulo3aUbA%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "\ud83d\udce2 Nous recherchons un(e) Data Engineer, bas\u00e9(e) \u00e0 Lyon\n\ud83d\udc49Quelques mots sur les activit\u00e9s num\u00e9riques de Thales Lyon :\nLes activit\u00e9s num\u00e9riques repr\u00e9sentent une entit\u00e9 rattach\u00e9e au groupe Thales, sp\u00e9cialis\u00e9e dans l\u2019IT et pr\u00e9sente au national.\nL\u2019agence de Lyon adresse divers sujets d\u2019expertise : ing\u00e9nierie logiciels, cybers\u00e9curit\u00e9, infog\u00e9rance des infrastructures et transformation digitale.\n\ud83c\udfaf\nVotre r\u00f4le et missions\nEn nous rejoignant, vous int\u00e9grerez le centre de comp\u00e9tences\nAugmented data\n,\nsp\u00e9cialis\u00e9 dans la conception, le d\u00e9veloppement et l\u2019\u00e9volution d\u2019applications data centr\u00e9es. Vous y boosterez votre carri\u00e8re en travaillant sur des technologies telles que\nSpark, Elasticsearch, Kube ...\nle plus souvent dans un environnement\nAgile\n.\nDans le cadre des projets que nous op\u00e9rons aujourd\u2019hui :\n- Vous contribuerez \u00e0 la conception, au maintien, \u00e0 la scalabilit\u00e9 des plateformes d\u2019analyse de donn\u00e9es au travers de votre expertise sur les sujets data (base de donn\u00e9es, gestion de flux, ETL \u2026)\n- Vous contribuerez \u00e0 la conception et \u00e0 la mise en production des pipelines d\u2019analyses et de transformations de donn\u00e9es en veillant \u00e0 leur bonne adaptation aux besoins m\u00e9tiers et aux contraintes techniques du client\n- Vous pourrez intervenir sur des sujets de visualisations, dans le but de notamment accompagn\u00e9es nos clients sur la conception de Dashboard m\u00e9tier intelligent \u2026\n- Vous serez \u00e9galement amen\u00e9es \u00e0 \u00e9changer directement avec des DevOps/Datascientist pour la mise en place, l\u2019int\u00e9gration des pipelines et l\u2019\u00e9laboration des algorithmes de traitements de donn\u00e9es.\n- A l\u2019\u00e9chelle du d\u00e9partement, Vous serez un acteur majeur du d\u00e9veloppement de notre activit\u00e9 et du lancement de nouveaux projets de valorisation de donn\u00e9es.\n\ud83d\ude4b\u200d\u2640\ufe0f \ud83d\ude4b\u200d\u2642\ufe0f\nVotre profil\nDe formation Bac +5 en informatique (\u00e9cole d\u2019ing\u00e9nieur, Master ou \u00e9quivalent), vous justifiez d\u2019une premi\u00e8re exp\u00e9rience r\u00e9ussie sur un projet data ? Vous souhaitez participer \u00e0 la conception et intervenir sur des solutions de r\u00e9cup\u00e9ration et d\u2019exploitation de donn\u00e9es m\u00e9tiers dans des contextes critiques et hautement s\u00e9curis\u00e9s ?\nAutonome, dynamique, organis\u00e9(e) et proactif(ve), vous souhaitez \u00e9voluer au sein d\u2019\u00e9quipes passionn\u00e9es par l\u2019exploration et l\u2019int\u00e9gration des technologies nouvelles au service des m\u00e9tiers de nos clients ?\nVous avez des comp\u00e9tences qui couvrent les domaines suivants :\nMise en place et gestion de base de donn\u00e9es (SQL, Elasticsearch, Clickhouse ...)\nLangages de programmations (Java, Python)\nGestion de flux (Kafka, flink, logstash \u2026)\nEnvironnements big Data (Spark/hadoop )\nPrincipes et outils de type ETL\nVous \u00eates de plus int\u00e9ress\u00e9(e):\nPar les environnements containeris\u00e9s (docker, kubernetes, helm ...)\nLes concepts DevOps (Ansible, CI/CD...)\nLes sujets de Datavisualisation (Vega, Kibana, python librairies...)\nVous aimez travailler en \u00e9quipe ? Vous \u00eates reconnu(e) pour vos qualit\u00e9s relationnelles et vos capacit\u00e9s de vulgarisation ?\nAlors notre poste d\u2019Ing\u00e9nieur(e) Data(H/F) est fait pour vous !\n\ud83d\ude4c\nVotre carri\u00e8re chez Thales\nDiff\u00e9rentes opportunit\u00e9s vous permettront de d\u00e9couvrir d'autres domaines ou sites. Vous pourrez \u00e9voluer et d\u00e9velopper vos comp\u00e9tences dans diff\u00e9rents domaines.\nExplorez un espace attentif au d\u00e9veloppement personnel.\nD\u00e9veloppez vos talents dans un autre domaine du groupe Thales, en d\u00e9couvrant de nouveaux produits, de nouveaux clients, un nouveau pays ou en vous orientant vers une solution plus complexe.\nChoisissez entre une expertise technique ou un parcours de leadership.\nVous travaillerez dans une entreprise r\u00e9solument humaine avec des valeurs fortes comme la s\u00e9curit\u00e9 au travail, l\u2019\u00e9galit\u00e9 Homme/Femme et l\u2019\u00e9quilibre vie personnelle/professionnelle (Accord T\u00e9l\u00e9travail).\nRattach\u00e9(e) \u00e0 la Convention m\u00e9tallurgie, vous b\u00e9n\u00e9ficierez aussi de ses multiples avantages (\u2026)\nVous souhaitez en savoir plus ?\nN\u2019h\u00e9sitez pas \u00e0 contacter notre \u00e9quipe de recrutement ou nos \u00e9quipes directement.\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "Java",
                "Scala",
                "R",
                "Go"
            ],
            "DataBase": [
                "SQL",
                "Elasticsearch"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [
                "Hadoop",
                "Spark",
                "Flink"
            ],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [],
            "DevTools": [
                "Git",
                "Docker"
            ],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [
                "Ansible",
                "Kubernetes"
            ],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [
                "Docker",
                "Kubernetes"
            ],
            "Collaboration": [],
            "Other": [
                "DevOps",
                "Big Data",
                "CI/CD"
            ],
            "FrSoftSkills": [
                "Leadership"
            ],
            "EnSoftSkils": [
                "Leadership"
            ]
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {	
		"source": "LinkedIn",
        "title": "Data Engineer - Nantes",
        "company": "Capgemini",
        "location": "Nantes, Pays de la Loire, France",
        "link": "https://fr.linkedin.com/jobs/view/data-engineer-nantes-at-capgemini-3803998213?position=8&pageNum=0&refId=b67kRduAUeEfaeVnXh9rCA%3D%3D&trackingId=qE%2Ffs1Bymeu3P2TnbkpBiA%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Capgemini\nChoisir Capgemini, c'est choisir une entreprise o\u00f9 vous serez en mesure de fa\u00e7onner votre carri\u00e8re selon vos aspirations, o\u00f9 vous serez soutenu et inspir\u00e9 par une communaut\u00e9 d\u2019experts dans le monde entier, o\u00f9 vous pourrez r\u00e9\u00e9crire votre futur. Rejoignez-nous pour red\u00e9finir les limites de ce qui est possible, contribuer \u00e0 lib\u00e9rer la valeur de la technologie pour les plus grandes organisations et participez \u00e0 la construction d\u2019un monde plus durable et inclusif.\nVos missions :\nInt\u00e9gr\u00e9(e) au sein d'une \u00e9quipe projets intervenant pour des clients dans des secteurs d'activit\u00e9s vari\u00e9es, vous serez notamment en charge des missions suivantes :\nConcevoir et mettre en oeuvre des strat\u00e9gies s\u00e9curis\u00e9es d'acquisition et d'int\u00e9gration de donn\u00e9es,\nConfigurer des r\u00e9f\u00e9rentiels de donn\u00e9es \u00e0 la pointe de la technologie dans des environnements distribu\u00e9s, majoritairement dans le cloud (Google Cloud Platform, Azure Databricks, AWS) et/ou en environnement Hadoop (distribution MapR, Cloudera, Hortonworks),\nConstruire des pipelines de donn\u00e9es pour collecter, transformer et traiter des donn\u00e9es en collaboration avec des scientifiques de donn\u00e9es afin de r\u00e9pondre aux exigences de la mod\u00e9lisation de donn\u00e9es d'analyse avanc\u00e9e.\nVotre profil :\nDipl\u00f4me d\u2019ing\u00e9nieur ou \u00e9quivalent universitaire\nMinimum 3 ans d'exp\u00e9rience\nAnglais courant\nMa\u00eetrise des langages Java, Scala ou Python et expertise sur les framework Spark et/ou Hadoop.\nExpertise sur les services Cloud Data Platform suivants : Azure Data Lake, Azure synapse, Azure Data Factory, Azure Data Explorer, GCP, AWS, Snowflake, Databricks\u2026\n3 raisons de nous rejoindre :\nQualit\u00e9 de vie au travail : accord de t\u00e9l\u00e9travail en France et \u00e0 l\u2019international, accord sur l\u2019\u00e9galit\u00e9\nprofessionnelle, la parentalit\u00e9, l\u2019\u00e9quilibre des temps et la mobilit\u00e9 durable.\nApprentissage en continu : certifications et formations en libre acc\u00e8s, accompagnement sur mesure avec votre carreer manager, parcours d\u2019int\u00e9gration sur 9 mois.\nAvantages groupe & CSE : plan actionnariat, activit\u00e9s \u00e0 tarifs pr\u00e9f\u00e9rentiels, remboursement partiel\nvacances, remboursement de votre abonnement sportif ou culturel.\nNos engagements et priorit\u00e9s :\nLe groupe Capgemini encourage une culture inclusive dans un cadre multiculturel et handi-accueillant. En nous rejoignant, vous int\u00e9grez un collectif qui valorise la diversit\u00e9, d\u00e9veloppe le potentiel de ses talents, s\u2019engage dans des initiatives solidaires avec ses partenaires, et se mobilise pour r\u00e9duire son impact environnemental sur tous ses sites et aupr\u00e8s de ses clients.\nCapgemini\nCapgemini est un leader mondial, responsable et multiculturel, regroupant pr\u00e8s de 350 000 personnes dans plus de 50 pays. Fort de 55 ans d\u2019exp\u00e9rience, nous sommes un partenaire strat\u00e9gique des entreprises pour la transformation de leurs activit\u00e9s en tirant profit de toute la puissance de la technologie et des innovations dans les domaines en perp\u00e9tuelle \u00e9volution tels que le cloud, la data, l\u2019Intelligence Artificielle, la connectivit\u00e9, les logiciels, l\u2019ing\u00e9nierie digitale ou les plateformes.\nGet The Future You Want* | www.capgemini.com/fr-fr\n*Capgemini, le futur que vous voulez\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "Java",
                "Scala",
                "R",
                "Go"
            ],
            "DataBase": [],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [
                "Hadoop",
                "Spark",
                "Databricks"
            ],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [
                "AWS",
                "Azure",
                "Google Cloud Platform"
            ],
            "DevTools": [
                "Git"
            ],
            "Os": [],
            "DBMS": [
                "Snowflake",
                "Snowflake"
            ],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [
                "Cloud"
            ],
            "FrSoftSkills": [
                "Collaboration",
                "Organisation"
            ],
            "EnSoftSkils": [
                "Collaboration",
                "Initiative"
            ]
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s",
                "3",
                "3",
                "3"
            ]
        }
    },
    {	
		"source": "LinkedIn",
        "title": "Data Engineer (H/F)",
        "company": "Technology & Strategy",
        "location": "Lyon, Auvergne-Rh\u00f4ne-Alpes, France",
        "link": "https://fr.linkedin.com/jobs/view/data-engineer-h-f-at-technology-strategy-3881556102?position=9&pageNum=0&refId=b67kRduAUeEfaeVnXh9rCA%3D%3D&trackingId=MKZjIJGEG0En6bgmZVJg5g%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "D\u00e9couvrez Novencia\n:\nExpert en Data et Intelligence Artificielle, nous aidons nos clients \u00e0 exploiter et \u00e0 valoriser leurs donn\u00e9es sous toutes ses formes en les accompagnant sur des projets de Data Analyse, Data Gourvernance, Data Architecture, Data Science, et Data Engineering\u2026\nVous avez une solide exp\u00e9rience de minimum 2 ans dans l'ing\u00e9nierie des donn\u00e9es et vous \u00eates \u00e0 la recherche de nouveaux d\u00e9fis ? Bouclez votre ceinture, la suite est pour vous !\nType de contrat : CDI\nLieu : Lyon\nEn qualit\u00e9 de Data Engineer (H/F), votre r\u00f4le sera :\nConcevoir et proposer les solutions de d\u00e9veloppement r\u00e9pondant aux besoins fonctionnels et techniques des projets big data.\nTu participes \u00e0 la conception de solutions permettant le traitement de volumes importants de pipelines donn\u00e9es.\nR\u00e9aliser ces solutions par l\u2019\u00e9criture de code, en respectant les m\u00e9thodes et proc\u00e9dures qualit\u00e9s d\u00e9finies au sein du d\u00e9partement Technique.\nMise \u00e0 disposition s\u00e9curis\u00e9 et lisible de la data.\nS\u2019assurer de la conformit\u00e9 fonctionnelle et technique de ces r\u00e9alisations en effectuant les tests automatis\u00e9s n\u00e9cessaire et la mise en place de monitoring (syst\u00e8me et qualit\u00e9).\nAssurer la maintenance des applicatifs / plateforme data science\nAssurer une veille technologique\nVous disposez des comp\u00e9tences suivantes :\nMaitrise des plateformes Cloud (AWS, GCP ou Azure), de Scala et de SQL.\nUn.e touche \u00e0 tout : poss\u00e9dant des comp\u00e9tences en langage Python/Spark, de bonnes capacit\u00e9s de mod\u00e9lisation, une forte app\u00e9tence pour le Big Data\nFin.e connaisseur.euse : Data Engineer convaincu, tr\u00e8s peu de secrets pour les clusters et pour les calculs parall\u00e8les\nExplorateur.trice : d\u00e9couvre de nouvelles technos gr\u00e2ce \u00e0 une veille r\u00e9guli\u00e8re\nD\u00e9brouillard.e : rel\u00e8ve de nouveaux d\u00e9fis\nNotre objectif commun est de co-construire votre carri\u00e8re en fonction de vos aspirations et de vos comp\u00e9tences.\nContactez-moi en message priv\u00e9 ou par mail \u00e0 s.ziki@technologyandstrategy.com !\nLet's make it possible #together\n*Nos postes sont ouverts aux personnes b\u00e9n\u00e9ficiant d\u2019une Reconnaissance de la Qualit\u00e9 de Travailleur Handicap\u00e9 (RQTH). T&S Groupe encourage la diversit\u00e9 et l\u2019\u00e9galit\u00e9 sur le lieu de travail. Tous les candidats qualifi\u00e9s H/F/* sont pris en consid\u00e9ration pour un emploi sur un m\u00eame pied d'\u00e9galit\u00e9.\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "Scala",
                "R",
                "Go"
            ],
            "DataBase": [
                "SQL"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [
                "Spark"
            ],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [
                "AWS",
                "Azure"
            ],
            "DevTools": [],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [
                "Big Data",
                "Cloud"
            ],
            "FrSoftSkills": [],
            "EnSoftSkils": []
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [
                "CDI"
            ],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s",
                "2",
                "2",
                "2"
            ]
        }
    },
    {	
		"source": "LinkedIn",
        "title": "Data Engineer",
        "company": "digiRocks recrute \u2705",
        "location": "Paris, \u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/data-engineer-at-digirocks-recrute-%E2%9C%85-3903481080?position=10&pageNum=0&refId=b67kRduAUeEfaeVnXh9rCA%3D%3D&trackingId=M%2Bh%2FZxqWFn8O59EgZBx1GA%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "\ud83d\ude0e Envie d'accompagner des organisations dans leurs strat\u00e9gies, Fan de data?\nRejoins un jeune cabinet de conseil en strat\u00e9gie sp\u00e9cialis\u00e9 en data. Le cabinet a \u00e9t\u00e9 cr\u00e9\u00e9 il y a 4 ans pas des anciens de grands cabinets de conseil en strat\u00e9gie qui ne se reconnaissaient plus dans ce qu'est devenu le \"consulting\". Cependant ils n'ont pas perdu espoir de pouvoir apporter du conseil \u00e0 haute valeur ajout\u00e9e dans une ambiance friendly, fa\u00e7on start-up, sans sacrifier l'excellence.\nJean-Patrick recrute un(e) Consultant Data Engineer \u00e0 Paris en CDI\n\u2705 MISSION :\nVous serez responsable de la mise en \u0153uvre de bout en bout de la pile de donn\u00e9es, de la collecte au reporting, avec un accent sur l'infrastructure et les processus techniques. Vous travaillerez avec des Consultants en Strat\u00e9gie & Data et les soutiendrez dans la r\u00e9solution des d\u00e9fis li\u00e9s aux donn\u00e9es de leurs clients. Vous contribuerez \u00e0 la d\u00e9finition des strat\u00e9gies de donn\u00e9es, \u00e0 la mise en \u0153uvre des syst\u00e8mes de donn\u00e9es et vous soutiendrez l'exploitation des donn\u00e9es dans des projets transformationnels. En g\u00e9n\u00e9ral, vous serez responsable de comprendre intimement les probl\u00e8mes, de concevoir une strat\u00e9gie technique pour les adresser et de faciliter une ex\u00e9cution technique de haute qualit\u00e9.\n\u2705 R\u00c9SULTATS ATTENDUS :\n\ud83d\ude80 R\u00e9sultat 1: Unificateur de Donn\u00e9es : Architecturer, assembler, assimiler, nettoyer et conformer de grands ensembles de donn\u00e9es complexes pour livrer des insights commerciaux et alimenter les exp\u00e9riences de produits de donn\u00e9es.\n\ud83d\ude80 R\u00e9sultat 2: Agent de S\u00e9curit\u00e9 des Donn\u00e9es : Concevoir et construire une infrastructure de donn\u00e9es fiable et \u00e9volutive avec les techniques de confidentialit\u00e9 et de s\u00e9curit\u00e9 de pointe pour prot\u00e9ger les donn\u00e9es.\n\ud83d\ude80 R\u00e9sultat 3: DataOps : Poss\u00e9der la pile de donn\u00e9es de bout en bout, y compris la collecte d'\u00e9v\u00e9nements, la gouvernance des donn\u00e9es, les int\u00e9grations de donn\u00e9es et la mod\u00e9lisation.\n\ud83d\ude80 R\u00e9sultat 4: Gardien des Donn\u00e9es : Assurer la coh\u00e9rence et la qualit\u00e9 de l'environnement technique et de la structure des donn\u00e9es \u00e0 travers des m\u00e9triques, de la documentation, des processus, des tests de donn\u00e9es et de la formation.\nRequirements\n\u2705 PROFIL RECHERCH\u00c9 :\nDipl\u00f4m\u00e9 d'une Grande Ecole de Commerce ou d'ing\u00e9nieur, avec une premi\u00e8re exp\u00e9rience r\u00e9ussie comme Data Engineer, id\u00e9alement dans un contexte similaire au Conseil,\nConnaissance des services de Data Warehouses Cloud. Exp\u00e9rience avec Google BigQuery, Snowflake, AWS Redshift/Athena, Looker, Azure SQL DWH, ou Azure Databricks est tr\u00e8s souhaitable.\nConnaissance des architectures de donn\u00e9es relationnelles et de grandes donn\u00e9es, de l'entreposage de donn\u00e9es, de l'int\u00e9gration de donn\u00e9es, de la mod\u00e9lisation de donn\u00e9es, de l'optimisation de donn\u00e9es et des techniques d'analyse de donn\u00e9es.\nExp\u00e9rience dans la construction de pipelines de donn\u00e9es de bout en bout en utilisant des plateformes de donn\u00e9es sur site ou bas\u00e9es sur le cloud.\nExp\u00e9rience pratique dans la livraison de solutions comprenant des bases de donn\u00e9es, SQL avanc\u00e9 et d\u00e9veloppement logiciel dans des langues telles que Python.\nInt\u00e9ress\u00e9 et connaissant les technologies Big Data et les technologies de l'\u00e9cosyst\u00e8me Apache telles que Beam, Spark, Kafka, Airflow, bases de donn\u00e9es, int\u00e9gration, gestion des donn\u00e9es de r\u00e9f\u00e9rence, assurance qualit\u00e9, manipulation de donn\u00e9es et technologies de gouvernance des donn\u00e9es.\nExp\u00e9rience avec les plateformes cloud publiques et l'infrastructure cloud qui est essentielle.\nExpos\u00e9 aux outils ETL/ELT et de gouvernance.\nInt\u00e9ress\u00e9 par les technologies et principes IA et ML.\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "R",
                "Go"
            ],
            "DataBase": [
                "SQL"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [
                "Spark",
                "Databricks"
            ],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [
                "AWS",
                "Azure"
            ],
            "DevTools": [],
            "Os": [],
            "DBMS": [
                "Snowflake",
                "Snowflake",
                "BigQuery"
            ],
            "SoftBigDataProcessing": [],
            "Automation": [
                "Airflow"
            ],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [
                "Big Data",
                "ML",
                "Cloud"
            ],
            "FrSoftSkills": [
                "Organisation"
            ],
            "EnSoftSkils": []
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [
                "CDI"
            ],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s",
                "4",
                "4",
                "4"
            ]
        }
    },
    {	
		"source": "LinkedIn",
        "title": "Big Data Engineer - Spark & Python - F/H",
        "company": "Orange Business",
        "location": "Lille, Hauts-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/big-data-engineer-spark-python-f-h-at-orange-business-3916552415?position=11&pageNum=0&refId=b67kRduAUeEfaeVnXh9rCA%3D%3D&trackingId=dierIvCJx0KVOvKwp%2FTLFA%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Et si Business & Decision et Orange Business conjuguaient leurs forces pour devenir l\u2019un des leaders europ\u00e9ens de la Data transformation ?\nNous l\u2019avons fait ! Notre alchimie nous positionne comme un\nacteur unique\nintervenant sur toutes les \u00e9tapes du\nvoyage de la donn\u00e9e.\nDepuis 30 ans, Business & Decision, entit\u00e9 de Digital Services s'est impos\u00e9e comme un partenaire strat\u00e9gique pour la transformation Data de nombreux clients, dans des secteurs tr\u00e8s vari\u00e9s. Digital Services est aujourd\u2019hui l\u2019\nESN d\u2019Orange Business\nalliant les expertises historiques Cloud et Digital d\u2019Orange ainsi que le c\u0153ur de m\u00e9tier Data/IA de Business & Decision. Son but est d\u2019accompagner les entreprises et les acteurs publics dans leur transformation gr\u00e2ce aux 4000 experts pr\u00e9sents dans plusieurs grandes villes fran\u00e7aises comme Montpellier, Niort, Lyon, Bordeaux, Lille et Toulouse \u2026\nDescription du poste\nOrange Business, recherche pour son site de Lille, son futur Ing\u00e9nieur Big Data pour rejoindre sa team Data.\nVotre quotidien ?\nEn int\u00e9grant Orange Business, vous pouvez participer \u00e0 une grande diversit\u00e9 d\u2019activit\u00e9s dans la Data. En voici un aper\u00e7u :\nAu d\u00e9marrage du projet :\nRecueillir et analyser les besoins du client\nR\u00e9diger les sp\u00e9cifications fonctionnelles et techniques\nEstimer les charges\nPendant la phase de r\u00e9alisation :\nMod\u00e9liser des datawarehouses et datamart\nD\u00e9velopper les proc\u00e9dures d\u2019alimentation (ETL)\nD\u00e9veloppement SPARK\nen batch et streaming\nD\u00e9velopper les visualisations de donn\u00e9es (DataViz)\nR\u00e9aliser la recette et les tests\nSuivre et mettre en production\nEn fonction de votre \u00e9volution et de nos enjeux, vous pouvez aussi \u00e9voluer sur des missions transverses (conseil, coaching, avant-vente, formation, audit, etc.). La prise d\u2019initiative est toujours la bienvenue !\nQualifications\nVous poss\u00e9dez 5 ans d'exp\u00e9rience ou plus dans la mise en \u0153uvre de projets d\u00e9cisionnels.\nVous avez de solides comp\u00e9tences\nSpark\n(job, scripting, d\u00e9ploiement) ainsi que sur\nPython.\nAvoir des connaissances Kafka sera un plus \u00e9galement.\nEnvie d\u2019apprendre de nouvelles technos ? Vous souhaitez partager vos comp\u00e9tences et b\u00e9n\u00e9ficier des expertises de la Team Orange Business ?\nOutre l\u2019aspect technique, c\u2019est une personnalit\u00e9 qui est recherch\u00e9e !\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "R"
            ],
            "DataBase": [],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [
                "Spark"
            ],
            "MachingLearning": [
                "Orange"
            ],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [],
            "DevTools": [
                "Git"
            ],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [
                "Big Data",
                "Cloud"
            ],
            "FrSoftSkills": [],
            "EnSoftSkils": [
                "Initiative"
            ]
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s",
                "30",
                "30",
                "30"
            ]
        }
    },
    {	
		"source": "LinkedIn",
        "title": "Data Engineer H/F",
        "company": "Chantelle",
        "location": "Cachan, \u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/data-engineer-h-f-at-chantelle-3909775663?position=12&pageNum=0&refId=b67kRduAUeEfaeVnXh9rCA%3D%3D&trackingId=dYJ3VWvHoYOq3%2Bgog2FcIg%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "La Direction des Syst\u00e8mes d'Information et du Digital du groupe Chantelle recherche son/sa futur.e Data Engineer H/F, pour le lancement du grand chantier de r\u00e9novation de l'architecture Data : la bascule de l'int\u00e9gralit\u00e9 de son Data Warehouse vers Google Big Query.\nNous souhaitons recruter un Data Engineer H/F confirm\u00e9.e, charg\u00e9.e de contribuer \u00e0 la d\u00e9finition de la feuille de route de la Chantelle Data Plaform. En tant que Data Engineer vous travaillerez au sein de l'\u00e9quipe Data Int\u00e9gration en charge de la Chantelle Data Platform.\nVos Missions :\n- Mettre en \u0153uvre une infrastructure autour de Google Cloud Platform permettant de collecter (airbyte, API, ...) , transformer (dataform, Bigquery ...), exposer (dataviz, API, applications, ...) et historiser les donn\u00e9es g\u00e9n\u00e9r\u00e9es par l'entreprise.\n- Travailler en \u00e9troite proximit\u00e9 avec les responsables des diff\u00e9rents domaines fonctionnels (R\u00e9f\u00e9rentiels, Supply Chain, Manufacturing, B2B, Retail & e-commerce, Finance, ...), avec notre \u00e9quipe de Data Analysts ainsi qu'avec l'\u00e9quipe technique en charge des infrastructures transverses\n- \u00catre force de proposition sur tous les sujets d'architecture et de mod\u00e9lisation (choix de mise en place de pipeline temps r\u00e9els ou au contraire de flux de donn\u00e9es en mode batch, ou bien encore stockage sur Big Query / Big Table en fonction des cas d'usage).\n- D\u00e9finir les \u00e9l\u00e9ments structurants, en justifiant vos choix, et les mettre en \u0153uvre.\n- Rationaliser et moderniser notre architecture d'int\u00e9gration inter-applicative; se projeter sur la cr\u00e9ation d'un mod\u00e8le de donn\u00e9es de type Datamesh.\n- Faire la refonte de la BI de nombreux use cases tels que le pilotage de nos stocks, personnalisation de nos sites e-commerce en temps r\u00e9el en fonction de nos profils client, etc\u2026\nStack technique : Google Cloud Platform, BigQuery, DataForm, DataFlow, PubSub, Airbyte, Github ...\nBonne ma\u00eetrise des langages Python et SQL\nPourquoi travailler chez Chantelle ?\nUne flexibilit\u00e9 dans votre lieu de travail, selon la politique de t\u00e9l\u00e9travail de l'entreprise.\n11 jours de RTT/an ainsi qu'un 13\u00e8me mois.\nUne culture d'entreprise familiale bas\u00e9e sur des valeurs de respect, de cr\u00e9ativit\u00e9, de durabilit\u00e9 et de transparence\nUne aventure dans laquelle vous pourrez vous \u00e9panouir, apprendre et entreprendre, avec une grande vari\u00e9t\u00e9 de missions et beaucoup d'autonomie\nDes \u00e9quipes ressources humaines et des managers \u00e0 votre \u00e9coute pour vous accompagner dans votre parcours professionnel\nDes r\u00e9ductions sur nos produits et des ventes au personnel\nDes avantages dans votre qualit\u00e9 de vie au travail : une conciergerie compl\u00e8te proposant un large panel de services, des activit\u00e9s en interne, un CSE.\nVous souhaitez rejoindre un Groupe familial, innovant, engag\u00e9 et leader dans son secteur en France comme \u00e0 l'international et vous souhaitez apporter votre expertise et authenticit\u00e9 pour guider votre \u00e9quipe vers le succ\u00e8s : postulez et rejoignez le Groupe Chantelle !\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "R",
                "Go"
            ],
            "DataBase": [
                "SQL"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [
                "Google Cloud Platform"
            ],
            "DevTools": [
                "Git"
            ],
            "Os": [],
            "DBMS": [
                "BigQuery",
                "Big Query"
            ],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [
                "Cloud"
            ],
            "FrSoftSkills": [
                "Cr\u00e9ativit\u00e9",
                "Flexibilit\u00e9"
            ],
            "EnSoftSkils": []
        },
        "details": {
            "JobDetail": [
                "Confirm\u00e9"
            ],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {	
		"source": "LinkedIn",
        "title": "Data Engineer - Mod\u00e9lisation SQL - F/H",
        "company": "Orange Business",
        "location": "Greater Lille Metropolitan Area",
        "link": "https://fr.linkedin.com/jobs/view/data-engineer-mod%C3%A9lisation-sql-f-h-at-orange-business-3916551577?position=13&pageNum=0&refId=b67kRduAUeEfaeVnXh9rCA%3D%3D&trackingId=7BVihBcm8eV8DMPwgcInOw%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Et si Business & Decision et Orange Business conjuguaient leurs forces pour devenir l\u2019un des leaders europ\u00e9ens de la Data transformation ?\nNous l\u2019avons fait ! Notre alchimie nous positionne comme un acteur unique intervenant sur toutes les \u00e9tapes du voyage de la donn\u00e9e.\nDepuis 30 ans, Business & Decision, entit\u00e9 de Digital Services s'est impos\u00e9e comme un partenaire strat\u00e9gique pour la transformation Data de nombreux clients, dans des secteurs tr\u00e8s vari\u00e9s. Digital Services est aujourd\u2019hui l\u2019ESN d\u2019Orange Business alliant les expertises historiques Cloud et Digital d\u2019Orange ainsi que le c\u0153ur de m\u00e9tier Data/IA de Business & Decision. Son but est d\u2019accompagner les entreprises et les acteurs publics dans leur transformation gr\u00e2ce aux 4000 experts pr\u00e9sents dans plusieurs grandes villes fran\u00e7aises comme Montpellier, Niort, Lyon, Bordeaux, Lille et Toulouse \u2026\nDescription du poste\nOrange Business, recherche pour son site de Lille, son futur Data Engineer pour rejoindre sa team Data.\nVotre quotidien ?\nEn int\u00e9grant Orange Business, vous pouvez participer \u00e0 une grande diversit\u00e9 d\u2019activit\u00e9s dans la Data. En voici un aper\u00e7u :\nAu d\u00e9marrage du projet :\nRecueillir et analyser les besoins du client\nR\u00e9diger les sp\u00e9cifications fonctionnelles et techniques\nEstimer les charges\nPendant la phase de r\u00e9alisation :\nMod\u00e9liser des datawarehouses et datamart (int\u00e9gration de flux et consolidation des donn\u00e9es)\nD\u00e9velopper les proc\u00e9dures d\u2019alimentation (ETL)\nD\u00e9velopper en SQL / PLSQL / Shell\nGarantir la qualit\u00e9 des donn\u00e9es et leur disponibilit\u00e9\nR\u00e9aliser la recette et les tests\nSuivre et mettre en production\nEn fonction de votre \u00e9volution et de nos enjeux, vous pouvez aussi \u00e9voluer sur des missions transverses (conseil, coaching, avant-vente, formation, audit, etc.). La prise d\u2019initiative est toujours la bienvenue !\nQualifications\nVous poss\u00e9dez 5 ans d'exp\u00e9rience ou plus dans la mise en \u0153uvre de projets d\u00e9cisionnels et en mod\u00e9lisation.\nVous avez de s\nolides comp\u00e9tences en d\u00e9veloppement SQL\n(job, scripting, d\u00e9ploiement) ainsi que sur Python.\nEnvie d\u2019apprendre de nouvelles technos ? Vous souhaitez partager vos comp\u00e9tences et b\u00e9n\u00e9ficier des expertises de la Team Orange Business ?\nOutre l\u2019aspect technique, c\u2019est une personnalit\u00e9 qui est recherch\u00e9e !\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "R"
            ],
            "DataBase": [
                "SQL"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [],
            "MachingLearning": [
                "Orange"
            ],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [],
            "DevTools": [
                "Git"
            ],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [
                "Cloud"
            ],
            "FrSoftSkills": [],
            "EnSoftSkils": [
                "Initiative"
            ]
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s",
                "30",
                "30",
                "30"
            ]
        }
    },
    {	
		"source": "LinkedIn",
        "title": "Data Engineer \u2013 SQL & GCP - F/H",
        "company": "Orange Business",
        "location": "Greater Lille Metropolitan Area",
        "link": "https://fr.linkedin.com/jobs/view/data-engineer-%E2%80%93-sql-gcp-f-h-at-orange-business-3916557264?position=14&pageNum=0&refId=b67kRduAUeEfaeVnXh9rCA%3D%3D&trackingId=jq%2FJhC7d%2Fp5ECg%2Fs%2FlXO0g%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Et si Business & Decision et Orange Business conjuguaient leurs forces pour devenir l\u2019un des leaders europ\u00e9ens de la Data transformation ?\nNous l\u2019avons fait ! Notre alchimie nous positionne comme un acteur unique intervenant sur toutes les \u00e9tapes du voyage de la donn\u00e9e.\nDepuis 30 ans, Business & Decision, entit\u00e9 de Digital Services s'est impos\u00e9e comme un partenaire strat\u00e9gique pour la transformation Data de nombreux clients, dans des secteurs tr\u00e8s vari\u00e9s. Digital Services est aujourd\u2019hui l\u2019ESN d\u2019Orange Business alliant les expertises historiques Cloud et Digital d\u2019Orange ainsi que le c\u0153ur de m\u00e9tier Data/IA de Business & Decision. Son but est d\u2019accompagner les entreprises et les acteurs publics dans leur transformation gr\u00e2ce aux 4000 experts pr\u00e9sents dans plusieurs grandes villes fran\u00e7aises comme Montpellier, Niort, Lyon, Bordeaux, Lille et Toulouse \u2026\nDescription du poste\nOrange Business, recherche pour son site de Lille, son futur Data Engineer pour rejoindre sa team Data.\nVotre quotidien ?\nEn int\u00e9grant Orange Business, vous pouvez participer \u00e0 une grande diversit\u00e9 d\u2019activit\u00e9s dans la Data. En voici un aper\u00e7u :\nAu d\u00e9marrage du projet :\nRecueillir et analyser les besoins du client\nR\u00e9diger les sp\u00e9cifications fonctionnelles et techniques\nEstimre les charges\nPendant la phase de r\u00e9alisation :\nMod\u00e9liser des datawarehouses et datamart (int\u00e9gration de flux et consolidation des donn\u00e9es)\nD\u00e9velopper les proc\u00e9dures d\u2019alimentation (ETL)\nD\u00e9velopper en SQL\n/ PLSQL / Shell\nGarantir la qualit\u00e9 des donn\u00e9es et leur disponibilit\u00e9\nConcevoir et d\u00e9velopper des solutions frontend BI \u00e0 des fins analytics & dashboarding\nR\u00e9aliser la recette et les tests\nSuivre et mettre en production\nEn fonction de votre \u00e9volution et de nos enjeux, vous pouvez aussi \u00e9voluer sur des missions transverses (conseil, coaching, avant-vente, formation, audit, etc.). La prise d\u2019initiative est toujours la bienvenue !\nQualifications\nVous poss\u00e9dez 3 ans d'exp\u00e9rience ou plus dans la mise en \u0153uvre de projets d\u00e9cisionnels et ing\u00e9nierie ou analyse data.\nVous avez de\nsolides comp\u00e9tences en d\u00e9veloppement SQL\n(job, scripting, d\u00e9ploiement), vous avez l\u2019habitude de travailler dans un\nenvironnement Google Cloud Plateform\nainsi qu\u2019avec\nPower BI\n.\nEnvie d\u2019apprendre de nouvelles technos ? Vous souhaitez partager vos comp\u00e9tences et b\u00e9n\u00e9ficier des expertises de la Team Orange Business ?\nOutre l\u2019aspect technique, c\u2019est une personnalit\u00e9 qui est recherch\u00e9e !\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "R",
                "Go"
            ],
            "DataBase": [
                "SQL"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [],
            "MachingLearning": [
                "Orange"
            ],
            "DataSerialization": [],
            "DataVisualization": [
                "Power BI"
            ],
            "Statistics": [],
            "CloudComputing": [],
            "DevTools": [
                "Git"
            ],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [
                "Cloud"
            ],
            "FrSoftSkills": [],
            "EnSoftSkils": [
                "Initiative"
            ]
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s",
                "30",
                "30",
                "30"
            ]
        }
    },
    {	
		"source": "LinkedIn",
        "title": "Data Engineer",
        "company": "eXalt Value",
        "location": "\u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/data-engineer-at-exalt-value-3897767649?position=15&pageNum=0&refId=b67kRduAUeEfaeVnXh9rCA%3D%3D&trackingId=i%2Fl3myI%2Bj%2FSf1j4kvKCgug%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "eXalt\nest un cabinet de conseil IT\nPure player Data\n& IA bas\u00e9 \u00e0 Paris.\nNotre offre s\u2019articule autour de 4 piliers r\u00e9unis au sein d\u2019une m\u00eame communaut\u00e9 pour un accompagnement \u00e0 360\u00b0 alliant une expertise technique et m\u00e9thodologique \u00e0 une approche conseil m\u00e9tier:\nData Gouvernance & Project\nData Engineering & Big Data\nData Performance & Analytics\nData Science & IA\nFiliale du groupe eXalt, cr\u00e9\u00e9 en 2018,\nregroupant plus de\n950 collaborateurs en France\n(Paris, Lyon, Bordeaux, Lille, Nantes, Marseille)\net \u00e0 l\u2019international\n(Colombie, Etats-Unis, Espagne, Belgique),\neXalt Value\napporte une\nexpertise approfondie\ndans le domaine de la Data & IA et conseille les entreprises dans le d\u00e9ploiement de leurs strat\u00e9gies data-driven.\nB\u00e9n\u00e9ficiant du support du groupe eXalt\n(1er dans la cat\u00e9gorie Conseil & Audit au classement des Champions de la Croissance 2024), eXalt Value\nest en pleine croissance et regroupe aujourd\u2019hui une communaut\u00e9 d\u2019expertise de plus de 60 collaborateurs en r\u00e9gion parisienne.\nNos consultants interviennent sur d\nes projets d\u2019envergure\ndans divers secteurs d\u2019activit\u00e9,\nBanque & Assurance, M\u00e9dias, Transports, Retail, Tourisme, etc.\nNous recherchons un\nData Engineer Confirm\u00e9 H/F (minimum 4 ans d'exp\u00e9rience dans la fonction)\npour rejoindre notre communaut\u00e9 sur le\npilier Data Engineering & Big Data.\nVos missions:\nConcevoir et d\u00e9velopper des pipelines et des flux de donn\u00e9es.\nInt\u00e9grer et transformer des donn\u00e9es provenant de diff\u00e9rentes sources.\nD\u00e9velopper et mettre en \u0153uvre des algorithmes de traitement de donn\u00e9es avanc\u00e9s.\nCollaborer \u00e9troitement avec les \u00e9quipes clients pour comprendre leurs besoins et fournir des solutions adapt\u00e9es.\nAssurer la qualit\u00e9 et la fiabilit\u00e9 des solutions d\u00e9velopp\u00e9es.\nConseiller les \u00e9quipes clients sur les solutions \u00e0 mettre en place.\nLes Pr\u00e9requis :\nTitulaire d'un Bac+5, Ecole d'Ing\u00e9nieur\nMa\u00eetrise d'un ou plusieurs langages de programmation (\nPython, Scala, Spark, etc\n.).\nExp\u00e9rience approfondie des technologies\nBig Data (Hadoop, Spark, Kafka, Talend, etc.)\nExp\u00e9rience av\u00e9r\u00e9e\nen\nenvironnement Cloud (AWS, GCP, ou Azure)\n.\nSolides comp\u00e9tences en conception et en optimisation de pipelines de donn\u00e9es.\nExp\u00e9rience de travail en\nm\u00e9thode Agile\nCapacit\u00e9 \u00e0 travailler de mani\u00e8re autonome et en \u00e9quipe.\nExcellentes comp\u00e9tences en communication et en r\u00e9solution de probl\u00e8mes.\nMa\u00eetrise de l\u2019anglais (oral & \u00e9crit dans un contexte international professionnel).\nVotre environnement eXalt\u00e9:\nUn environnement de travail Collaboratif\nfavorisant les initiatives et projets transverses \u00e0 la Practice Data & IA (Lab IA, Data Hub, etc.).\nUn collectif de consultants passionn\u00e9s,\ns\u2019int\u00e9ressant aux tendances innovantes du secteur.\nUne Practice de proximit\u00e9,\nprivil\u00e9giant la mont\u00e9e en comp\u00e9tence de ses collaborateurs (formations, coachings, mentorats, etc.)\nUn suivi individualis\u00e9 et de proximit\u00e9\npar un.e Data Sales Manager r\u00e9f\u00e9rent du compte client, un.e Charg\u00e9.e RH et un.e Practice Manager\nUne \u00e9quipe ouverte et dynamique,\nqui privil\u00e9gie les moments de partage et de convivialit\u00e9 (s\u00e9minaires, eXaltemps, meet-up, d\u00e9jeuners d\u2019\u00e9quipe, etc.)\nNotre processus de recrutement :\nUn entretien RH avec Estelle,\n\u00e0 la suite duquel vous saurez tout (ou presque) d\u2019eXalt Value,\nUn entretien technique avec un Manager assorti d\u2019un test technique,\nlors duquel vous aurez l\u2019occasion de d\u00e9montrer vos talents mais aussi d\u2019apprendre avant m\u00eame de dire oui,\nUn entretien final avec la Directrice Associ\u00e9e ou le Directeur Op\u00e9rationnel,\npour finir de vous convaincre de nous rejoindre \ud83d\ude0a\nNous avons h\u00e2te de recevoir vos CV, et de faire votre connaissance!\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "Scala",
                "R",
                "Go"
            ],
            "DataBase": [],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [
                "Hadoop",
                "Spark"
            ],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [
                "AWS",
                "Azure"
            ],
            "DevTools": [],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [
                "Big Data",
                "Cloud"
            ],
            "FrSoftSkills": [
                "Communication",
                "R\u00e9solution de probl\u00e8mes"
            ],
            "EnSoftSkils": [
                "Communication",
                "Initiative"
            ]
        },
        "details": {
            "JobDetail": [
                "Confirm\u00e9"
            ],
            "TypeContract": [],
            "Salary": [],
            "Level": [
                "Bac+5"
            ],
            "Experience": [
                "a",
                "n",
                "s",
                "4",
                "4",
                "4"
            ]
        }
    },
    {	
		"source": "LinkedIn",
        "title": "Data Engineer",
        "company": "EarthDaily Agro",
        "location": "Balma, Occitanie, France",
        "link": "https://fr.linkedin.com/jobs/view/data-engineer-at-earthdaily-agro-3883708013?position=16&pageNum=0&refId=b67kRduAUeEfaeVnXh9rCA%3D%3D&trackingId=i4cRUHDtp5y1qiyFUBzepw%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "About Us\nEarthDaily Agro provides space age data and analytics to the organizations and people who feed the planet!\nWith 35 years of industry experience, EarthDaily Agro provides customers with the data, analysis and knowledge they need to make more efficient and effective decisions. B2B services range from global risk management and monitoring of agricultural commodities to the marketing of inputs and precision agriculture consulting, using the latest research in agronomy, information technologies and remote sensing.\nEarthDaily Agro also develops highly customized business solutions for agricultural lenders, insurers, input suppliers and food companies, with easy-to-use analytics, that help reduce the daily risks of agriculture.\nEarthDaily Agro is headquartered in Minneapolis, MN, USA, with offices in France, Brazil, Australia and Switzerland and is a division of EarthDaily Analytics Corp.\nEarthDaily Analytics Corp., a vertically-integrated data processing and analytics company, is launching a new constellation of earth observation satellites. The EarthDaily satellite constellation will significantly enhance geospatial analytics capabilities in agriculture, forestry, environment, financial services, and intelligence, among many other verticals.\nMain Job Tasks And Responsibilities\nAs a EarthDailyAgro Data Engineer, your primary responsibility will be to design, develop, and manage data pipelines and infrastructure specialized for geospatial and remote sensing applications. You will work closely with data scientists, geospatial analysts, remote sensing experts, software engineers, and DevOps teams to ensure the successful deployment and scaling of data pipeline to feed geospatial data machine learning models. Your role will be crucial in optimizing the geospatial machine learning ecosystem and ensuring the seamless integration of AI-driven geospatial solutions into real-world applications.\nYour Responsibilities Include\nCloud-based data pipeline Conceptualization, Development and Scaling: Build up pipeline to ingest large volumes of geospatial data, pre-process them and meet data scientists\u2019 requirements, in terms of accessibility, speed, format, quality.\nAutomation and CI/CD: Industrialization of pipeline deployment, orchestration, workflows, and versioning.\nCost & Speed Optimization: Collaborate with infrastructure team to develop, optimize, and fine-tune pipeline.\nCloud and Containerization: Experience with cloud platforms (e.g., AWS, Azure, GCP) and containerization tools.\nInfrastructure Management: Utilize containerization technologies and cloud-based services to set up and manage infrastructure, enabling seamless deployment and scalability.\nMonitoring and Anomaly Detection: Implement monitoring systems to track pipeline performance and identify anomalies.\nVersion Control and Data Version Control: Proficient with version control systems like Git and DVC.\nSecurity and Compliance: Ensure the security and privacy of geospatial data, adhering to relevant data protection regulations and industry best practices.\nCollaboration and Communication: Collaborate with interdisciplinary teams to integrate data pipeline into existing applications or develop new geospatial products.\nIssue Resolution and Troubleshooting: Identify and resolve promptly technical issues related to geospatial data processing, performance, or infrastructure.\nEducation, Knowledge And Abilities\nRequirements\nEducation: Master's degree in Computer Science, specialisation in Geomatics and/or Remote sensing would be a plus.\nExperience: 3+ years experiences with data pipeline processes and deployment is a must-have. Proven hands-on experience in setting up pipelines and data processes with opensource tools (e.g., MLFlow, Argo, Kubeflow) is desirable.\nProgramming Skills: Proficiency in Python and with data manipulation frameworks (e.g., dataframe, numpy, pandas, xarray, rasterio) and librairies (e.g., Dask).\nProblem-Solving Skills: Autonomous, and strong analytical and problem-solving abilities to address complex geospatial data and analysis challenges.\nCommunication Skills: Excellent communication and interpersonal skills to collaborate effectively with cross-functional teams and stakeholders.\nFrench mandatory (job based in France). Fluent in English (oral and written):\u202fmeetings with internal are mostly in\u202fEnglish.\nPreferred Additional Skills\nExperience with Earth Observation (EO) data analysis and processing.\nExperience with geospatial data formats (e.g., GeoTIFF, Shapefile, NetCDF).\nSpatial Analysis Techniques: Understanding of spatial analysis techniques and algorithms commonly used in geospatial data manipulation.\nRemote Sensing Integration: Knowledge of remote sensing data sources (e.g., STAC catalog, satellite imagery, LiDAR, SAR) integration into data pipelines for accurate and up-to-date geospatial analysis.\nCONDITIONS\nFull time job based in Balma, near Toulouse, France.\nFixed + Bonuses\nTR / \"Family\" insurance / CSE\nPowered by JazzHR\nWrfSXQ5YJg\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "Scala",
                "R",
                "Go"
            ],
            "DataBase": [],
            "DataAnalytics": [
                "Pandas",
                "NumPy",
                "R"
            ],
            "BigData": [],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [
                "AWS",
                "Azure"
            ],
            "DevTools": [
                "Git"
            ],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [
                "Teams"
            ],
            "Other": [
                "DevOps",
                "ML",
                "Machine Learning",
                "Cloud",
                "CI/CD"
            ],
            "FrSoftSkills": [
                "Communication",
                "Collaboration"
            ],
            "EnSoftSkils": [
                "Communication",
                "Collaboration",
                "Organization",
                "Interpersonal Skills"
            ]
        },
        "details": {
            "JobDetail": [
                "Remote",
                "Full"
            ],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {	
		"source": "LinkedIn",
        "title": "Data Engineer (F/H)",
        "company": "Aubay",
        "location": "\u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/data-engineer-f-h-at-aubay-3573871076?position=17&pageNum=0&refId=b67kRduAUeEfaeVnXh9rCA%3D%3D&trackingId=5udQna6j91DvsfDszC3TCA%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Passionn\u00e9 par la Data, tu souhaites rejoindre une communaut\u00e9 d\u2019experts dans le domaine afin de d\u00e9velopper tes comp\u00e9tences en Data Engineering. Aubay renforce ses \u00e9quipes Data et recherche des Data Engineers pour int\u00e9grer des dispositifs de projets pointus et vari\u00e9s.\nTon quotidien en tant que Data Engineer chez Aubay, :\nD\u00e9finition de la strat\u00e9gie de stockage et mise en \u0153uvre des technologie appropri\u00e9es (base de donn\u00e9es SQL, NoSQL, stockage distribu\u00e9,\u2026)\nIngestion des donn\u00e9es (structur\u00e9es, semi-structur\u00e9es ou non-structur\u00e9es) selon diff\u00e9rentes fr\u00e9quences : batch, micro-batch ou temps r\u00e9el\nConception et mise en \u0153uvre de pipelines de donn\u00e9es afin de fournir des donn\u00e9es pr\u00eates \u00e0 l\u2019emploi aux consommateurs : uniformisation, mise en qualit\u00e9, enrichissement, calcul d\u2019indicateurs,\u2026\nConception et d\u00e9veloppement d\u2019API pour exposer les donn\u00e9es aupr\u00e8s d\u2019applications tierces\nAppui aux Data Scientists pour industrialiser et optimiser les algorithmes de Machine Learning\nPr\u00e9paration et animation d\u2019ateliers de travail avec des interlocuteurs vari\u00e9s : recueil/approfondissement des besoins m\u00e9tiers, avancement/restitution des travaux, transfert de comp\u00e9tences,\u2026\nTon profil :\nTu dispose d\u2019une formation niveau BAC+5 (Master 2 ou \u00e9cole d\u2019ing\u00e9nieur) sp\u00e9cialis\u00e9e en informatique\nTu as d\u00e9j\u00e0 une premi\u00e8re exp\u00e9rience significative (a minima 2 ans) en Data Engineering sur des technologies Big Data\nLes technologies telles que Hadoop, Spark ou Kafka sont tes technologies de pr\u00e9dilection\nLa programmation n\u2019a plus de secret pour toi et tu maitrise parfaitement un ou plusieurs langages de programmation suivants : Java, Scala et Python\nTu ma\u00eetrises les tenants et aboutissants de la philosophie DevOps et des outils orient\u00e9s CI/CD\nTu es soucieux de la qualit\u00e9 et de la performance de tes d\u00e9veloppements et tu t'int\u00e9resse \u00e0 l\u2019innovation frugale\nTu es un expert technique dans ton domaine sans pour autant oublier l\u2019importance d\u2019une communication orale et \u00e9crite de qualit\u00e9 et adapt\u00e9e \u00e0 chacun de tes interlocuteurs\nTu travaille au quotidien en mode agile et tu en maitrise les fondements\nCe qui nous caract\u00e9rise :\nDes missions et projets dans le domaine du Data Engineering en nombre et dans des secteurs vari\u00e9s (Banque, Assurance, Telecom, Industrie,\u2026) qui permettent \u00e0 nos collaborateurs de monter en comp\u00e9tences et de devenir des experts Data reconnus\nDe l\u2019apprentissage en continu avec des formations et des certifications sur les technologies Data d\u2019aujourd\u2019hui et de demain\nDes experts Data mobilisables pour accompagner et soutenir techniquement les collaborateurs sur leurs projets\nDes communaut\u00e9s de savoir-faire Data proposant de mani\u00e8re r\u00e9guli\u00e8re aux collaborateurs d\u2019Aubay du contenu et des \u00e9v\u00e8nements de partage (webinar, meetup/afterwork, BBL,\u2026) sur les th\u00e9matiques suivantes : Data Engineering, Data Viz, Data Science/IA, Data Platform & Architecture,\u2026\nAubay encourage la diversit\u00e9 sous toutes ses formes et garantit l'\u00e9galit\u00e9 des chances \u00e0 tous les candidats. Tous nos postes sont ouverts aux personnes en situation de handicap et nous proposons tous les am\u00e9nagements n\u00e9cessaires.\nTa carri\u00e8re chez Aubay :\nTu auras la possibilit\u00e9 de d\u00e9velopper et certifier tes comp\u00e9tences sur les derni\u00e8res technologies Data avec un focus fort sur les plateformes Data Cloud telles qu\u2019Azure Synapse Analytics, Google Cloud Platform, Snowflake et Databricks\nTu pourras rejoindre la BU d\u2019excellence Data et \u00e9voluer au sein d\u2019un environnement humain et professionnel de haut niveau. Tu profiteras d\u2019un management sur-mesure pour t'accompagner dans ta trajectoire de carri\u00e8re\nAu sein de la BU d\u2019excellence, de multiples perspectives s\u2019offriront \u00e0 toi :\nR\u00f4le de \u00ab Lead \u00bb : Vous pourrez gagner en responsabilit\u00e9 sur le plan technologique et devenir un r\u00e9f\u00e9rent aupr\u00e8s de nos clients et des collaborateurs de la communaut\u00e9 Data Engineering\nR\u00f4le de \u00ab Champion \u00bb : Vous repr\u00e9senterez Aubay aupr\u00e8s d\u2019un ou plusieurs de nos partenaires \u00e9diteurs strat\u00e9giques et vous participerez activement \u00e0 l\u2019animation de la relation sur le plan technologique\nR\u00f4le de \u00ab Head \u00bb : Vous pourrez prendre la responsabilit\u00e9 du savoir-faire Data Engineering et de ses offres et en assurer le d\u00e9veloppement au sens large (d\u00e9veloppement business, recrutement, management de collaborateurs, d\u00e9finition de la strat\u00e9gie et animation de la communaut\u00e9 au sein du groupe Aubay,\u2026)\nBesoin d\u2019en savoir plus sur le processus de recrutement ?\nUn \u00e9change macro au niveau RH avec Doriane\nUn entretien technique avec Marius ou Peter, deux de nos r\u00e9f\u00e9rents techniques\nUn \u00e9change manag\u00e9rial avec le Directeur de la BU Modern BI & Data\nA savoir que l\u2019ordre des \u00e9tapes peut varier selon tes envies (ex : \u00e9change manag\u00e9rial avec l\u2019\u00e9change technique)\nAubay encourage la diversit\u00e9 sous toutes ses formes et garantit l'\u00e9galit\u00e9 des chances \u00e0 tous les candidats. Tous nos postes sont ouverts aux personnes en situation de handicap et nous proposons tous les am\u00e9nagements n\u00e9cessaires.\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "Java",
                "Scala",
                "R",
                "Go"
            ],
            "DataBase": [
                "SQL",
                "NoSQL"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [
                "Hadoop",
                "Spark",
                "Databricks"
            ],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [
                "Azure",
                "Google Cloud Platform"
            ],
            "DevTools": [],
            "Os": [],
            "DBMS": [
                "Snowflake",
                "Snowflake"
            ],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [
                "DevOps",
                "Big Data",
                "Machine Learning",
                "Cloud",
                "CI/CD"
            ],
            "FrSoftSkills": [
                "Communication"
            ],
            "EnSoftSkils": [
                "Communication"
            ]
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [],
            "Salary": [],
            "Level": [
                "Bac+5"
            ],
            "Experience": [
                "a",
                "n",
                "s",
                "2",
                "2",
                "2"
            ]
        }
    },
    {	
		"source": "LinkedIn",
        "title": "Data Engineer / D\u00e9veloppeur Big Data # H/F",
        "company": "Air France",
        "location": "Provence-Alpes-C\u00f4te d'Azur, France",
        "link": "https://fr.linkedin.com/jobs/view/data-engineer-d%C3%A9veloppeur-big-data-%23-h-f-at-air-france-3900080172?position=18&pageNum=0&refId=b67kRduAUeEfaeVnXh9rCA%3D%3D&trackingId=U0cfa8nHfasz5xn9vr%2BUqw%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Description du poste\nIntitul\u00e9 du poste\nData Engineer / D\u00e9veloppeur Big Data # H/F\nM\u00e9tier\nSyst\u00e8mes d'informations - D\u00e9veloppement\nCat\u00e9gorie socio-professionnelle\nCadre\nPr\u00e9sentation du contexte\nVous avez peut-\u00eatre d\u00e9j\u00e0 voyag\u00e9 avec nous, mais que connaissez-vous de nos m\u00e9tiers et de la richesse des donn\u00e9es qu\u2019ils g\u00e9n\u00e8rent au quotidien ? Comment le traitement et l\u2019exploitation de ces donn\u00e9es peut contribuer \u00e0 notre strat\u00e9gie de Revenue Management, ou encore aux multiples op\u00e9rations \u00e0 r\u00e9aliser pour permettre \u00e0 un vol de partir \u00e0 l\u2019heure ?\nAir France-KLM fait r\u00eaver 104 millions de passagers par an, en les emmenant vers plus de 250 destinations, gr\u00e2ce \u00e0 une flotte de plus de 500 appareils. Le Groupe emploie 80 000 collaborateurs partout dans le monde :les opportunit\u00e9s sont vastes pour mettre \u00e0 profit ses comp\u00e9tences, apprendre et se d\u00e9velopper !\nLe d\u00e9partement de d\u00e9veloppement DATA, OR & AI d\u2019Air France, au sein de la direction des Syst\u00e8mes d\u2019Information, intervient dans toute la cha\u00eene de captation et de traitement des donn\u00e9es du groupe pour d\u00e9livrer \u00e0 nos m\u00e9tiers des solutions applicatives cl\u00e9s en main.\nLe d\u00e9partement est \u00e9galement en charge de l\u2019ensemble des outils techniques (ETL, DataLakes, DataWarehouses, Data visualisation) et du d\u00e9veloppement des talents et comp\u00e9tences de Data Engineering.\nNotre mission ? Transformer la donn\u00e9e brute en d\u00e9cision intelligente, pour mieux optimiser les m\u00e9tiers d\u2019Air France \u2013 KLM !\nPour cela, nous avons chacun un r\u00f4le essentiel \u00e0 jouer, pourquoi le v\u00f4tre ne serait pas celui de Data Engineer et de d\u00e9veloppeur Big Data ?\nDescription de la mission\nAu sein de notre d\u00e9partement, vous travaillerez main dans la main avec d\u2019autres Data Engineers et d\u00e9veloppeurs Big Data ainsi qu\u2019avec des sp\u00e9cialistes des m\u00e9tiers.\nInt\u00e9gr\u00e9 au sein d\u2019une product team agile passionn\u00e9e et dynamique :\nVous participez \u00e0 l\u2019analyse des besoins m\u00e9tiers du commercial, des op\u00e9rations a\u00e9riennes, de l\u2019exploitation sol en a\u00e9roport, de la maintenance a\u00e9ronautique ou encore du Cargo.\nVous contribuez \u00e0 la d\u00e9finition, au d\u00e9veloppement, \u00e0 l\u2019industrialisation et \u00e0 la maintenance d\u2019applications Big Data ou en Business Intelligence\nVous pr\u00e9sentez la restitution de vos travaux et accompagnez les utilisateurs d\u2019un point de vue fonctionnel ou m\u00e9thodologique\nVous serez en contact avec les directions m\u00e9tier du groupe Air France KLM.\nNous attachons beaucoup d'importance au d\u00e9veloppement des comp\u00e9tences de nos collaborateurs ainsi qu\u2019\u00e0 leur offrir des conditions de travail favorables \u00e0 l\u2019autonomie et aux missions \u00e0 forte valeur ajout\u00e9e. L'ouverture, le respect, la bienveillance et le partage sont des valeurs humaines port\u00e9es par l'entreprise.\nProfil recherch\u00e9\nVous \u00eates dipl\u00f4m\u00e9 de niveau Master ou Ing\u00e9nieur dans les domaines informatiques, vous avez acquis une exp\u00e9rience professionnelle dans le d\u00e9veloppement d\u2019applications.\nVous disposez d\u2019une exp\u00e9rience du d\u00e9veloppement indispensable en Backend / Java\nVous ma\u00eetrisez les bases de donn\u00e9es relationnelles et le langage SQL\nEn Compl\u00e9ment, Vous Avez Une Connaissance Ou Une Exp\u00e9rience Dans Tout Ou Partie Des Concepts Ou Outils Suivants\nEnvironnement Big Data (Spark, Hadoop, Elasticsearch, Kafka, ...)\nBase de donn\u00e9es noSQL (MongoDB, HBase, REDIS) ou Data Warehouse Teradata\nOutil de Datavisualisation (Spotfire, PowerBI, Qlik ou Kibana)\nSolutions de Cloud (GCP) et hybride (GCP / AZURE)\n(Ces comp\u00e9tences compl\u00e9mentaires ou manquantes pouvant aussi s'acqu\u00e9rir \u00e0 travers un parcours de reskilling et de formations aux outils du data engineering dispens\u00e9 en interne).\nVous avez particip\u00e9 \u00e0 des projets organis\u00e9s en Scrum ou Kanban, et avez peut-\u00eatre m\u00eame \u0153uvr\u00e9 comme Scrum-Master, ce qui vous permettra de vous int\u00e9grer ais\u00e9ment au sein d\u2019une Product Team. Votre esprit de synth\u00e8se, votre force de conviction et votre ma\u00eetrise de la communication facilitent les d\u00e9cisions avec l\u2019ensemble des collaborateurs de l\u2019\u00e9quipe, \u00e9ventuellement en langue anglaise, \u00e0 l\u2019\u00e9crit comme \u00e0 l\u2019oral.\nVous \u00eates autonome, rigoureux(se), responsable et curieux(se), vous aimez travailler en \u00e9quipe. Vous poss\u00e9dez de bonnes capacit\u00e9s d'\u00e9coute, d'analyse, de synth\u00e8se et de communication.\nEt bien s\u00fbr, vous \u00eates passionn\u00e9(e), enthousiaste et ing\u00e9nieux(se)\nCe que nous vous offrons\nDe la cr\u00e9ation de valeur pour l\u2019ensemble des m\u00e9tiers d\u2019Air France KLM\nDes challenges et probl\u00e9matiques complexes \u00e0 r\u00e9soudre\nL\u2019opportunit\u00e9 de d\u00e9ployer des solutions Data industrielles \u00e0 l\u2019\u00e9chelle !\nUne grande part de responsabilit\u00e9 dans une structure hi\u00e9rarchique horizontale\nUn important degr\u00e9 de libert\u00e9 pour apprendre et d\u00e9velopper son expertise au sein de l\u2019\u00e9quipe\nOn vous attend le plus rapidement possible ! Et pour une dur\u00e9e ind\u00e9termin\u00e9e ;)\nType de contrat\nCDI\nTemps partiel possible\nNon\nType d'horaires\nAdministratif\nProfil candidat\nNiveau d'\u00e9tudes min. requis\nBac + 5 et plus\nLangue\nAnglais (4 - Confirm\u00e9 / C1)\nLocalisation du poste\nLocalisation du poste\nFrance, Provence-Alpes-C\u00f4te d'Azur, Alpes Maritimes (06)\nSite\nValbonne\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Java",
                "R",
                "Go"
            ],
            "DataBase": [
                "SQL",
                "NoSQL",
                "HBase",
                "Elasticsearch"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [
                "Hadoop",
                "Spark"
            ],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [
                "PowerBI"
            ],
            "Statistics": [],
            "CloudComputing": [
                "Azure"
            ],
            "DevTools": [],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [
                "HBase"
            ],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [
                "Big Data",
                "Cloud"
            ],
            "FrSoftSkills": [
                "Communication"
            ],
            "EnSoftSkils": [
                "Communication"
            ]
        },
        "details": {
            "JobDetail": [
                "Hybride",
                "Confirm\u00e9"
            ],
            "TypeContract": [
                "CDI"
            ],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {	
		"source": "LinkedIn",
        "title": "Junior Data engineer",
        "company": "WA.Technology",
        "location": "Crouseilles, Nouvelle-Aquitaine, France",
        "link": "https://fr.linkedin.com/jobs/view/junior-data-engineer-at-wa-technology-3908458326?position=19&pageNum=0&refId=b67kRduAUeEfaeVnXh9rCA%3D%3D&trackingId=EbGJHiVHkqLvwlLGyNZEhQ%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "WA.Technology\nis a B2B supplier of iGaming solutions with rapidly growing clients and partnerships in emerging markets. We offer a state-of-the-art iGaming platform, turnkey solutions, and standalone products that empower operators to enter or expand into emerging markets quickly and easily.\nThe WA.Platform is a fully scalable and customisable solution, featuring over 75 game providers, 6,400+ games, and support for multiple currencies, along with access to over 80 payment methods. WA. Technology enables operators to build their own casino, sportsbook, lottery, fantasy, or poker business precisely as they envision it.\nAbout The Role,\nWe are seeking a highly skilled and motivated\nData Engineer\nto design, implement, and maintain efficient and scalable data pipelines on the Google Cloud Platform (GCP). In this role, you will be responsible for managing data from MariaDB and Kafka sources, ensuring seamless integration into BigQuery, our primary data destination. Collaboration with cross-functional teams is crucial to understanding and meeting diverse data needs.\nIn this role, you will need to:\nDesign, implement, and maintain robust data pipelines on Google Cloud Platform.\nIntegrate MariaDB and Kafka as primary data sources for seamless data flow into BigQuery.\nCollaborate across departments to address unique data requirements aligned with organizational goals.\nUtilize Dataflow and Dataform for efficient data processing and transformation.\nEnsure data integrity through rigorous validation and cleansing processes.\nOptimize cloud-based infrastructure for speed and scalability.\nImplement monitoring tools for proactive system performance tracking and issue resolution.\nProvide ongoing support for data integrity and availability.\nMaintain comprehensive documentation of data architecture, updating regularly.\nStay informed about the latest data technology trends.\nEvaluate and recommend new technologies/methodologies to enhance processing and analysis capabilities.\nWhat are the key experience and personal attribute requirements?\nBachelor's degree in Computer Science, Information Technology, or a related field.\n2+ Hands-on experience relational database\nProven experience in developing data pipelines and ETL processes.\nStrong SQL skills.\nKnowledge of data modeling and database design.\nExcellent collaboration and communication skills.\nStrong problem-solving and troubleshooting abilities.\nAbility to work independently and as part of a team.\nContinuous learner, keeping up with emerging trends in data engineering.\nWhat are some of the benefits of working at WA Technology?\n100% remote opportunity\nFlexible work environment\nAttractive remuneration package\nOpportunity to work with well-connected industry leaders.\nA leadership approach that fosters innovation, creativity, and trust.\nOpportunity to experience the buzz of highly driven and motivated work colleagues.\nExperience a start-up feel in a fast-paced growth-driven environment.\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Scala",
                "R",
                "Go"
            ],
            "DataBase": [
                "SQL"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [
                "Google Cloud Platform"
            ],
            "DevTools": [],
            "Os": [],
            "DBMS": [
                "BigQuery"
            ],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [
                "Teams"
            ],
            "Other": [
                "ML",
                "Cloud"
            ],
            "FrSoftSkills": [
                "Communication",
                "Leadership",
                "Collaboration"
            ],
            "EnSoftSkils": [
                "Communication",
                "Leadership",
                "Creativity",
                "Collaboration",
                "Organization"
            ]
        },
        "details": {
            "JobDetail": [
                "Remote",
                "Full"
            ],
            "TypeContract": [],
            "Salary": [
                "Package"
            ],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {	
		"source": "LinkedIn",
        "title": "Data Engineer (H/F)",
        "company": "iPepperGroup",
        "location": "Valbonne, Provence-Alpes-C\u00f4te d'Azur, France",
        "link": "https://fr.linkedin.com/jobs/view/data-engineer-h-f-at-ipeppergroup-3894091360?position=20&pageNum=0&refId=b67kRduAUeEfaeVnXh9rCA%3D%3D&trackingId=MXiVBVIb6BxwB0mgaE66rg%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "iPepper recrute pour l'un de ses clients une PME \u00e9diteur de logiciel dans le domaine du voyage, un\nData Engineer (H/F)\npassionn\u00e9(e) et exp\u00e9riment\u00e9(e) pour rejoindre une \u00e9quipe dynamique.\nEn tant qu'Ing\u00e9nieur(e) Data, vous serez en charge d'extraire et de transformer des donn\u00e9es, de construire et d'optimiser des pipelines de donn\u00e9es, ainsi que de concevoir des visualisations de donn\u00e9es intuitives et informatives.\nResponsabilit\u00e9s :\nConcevoir, construire et maintenir des pipelines de donn\u00e9es \u00e9volutifs et efficaces pour transf\u00e9rer des donn\u00e9es entre des bases de donn\u00e9es SQL et NoSQL.\nD\u00e9velopper et mettre en \u0153uvre des processus ETL pour extraire, transformer et charger des donn\u00e9es \u00e0 partir de diff\u00e9rentes sources dans notre entrep\u00f4t de donn\u00e9es.\nCollaborer avec des \u00e9quipes pluridisciplinaires pour comprendre les besoins en donn\u00e9es et garantir la fourniture r\u00e9ussie de solutions de donn\u00e9es.\nOptimiser et ajuster les pipelines de donn\u00e9es existants pour la performance et la fiabilit\u00e9.\nConcevoir et d\u00e9velopper des visualisations de donn\u00e9es et des tableaux de bord pour fournir des insights exploitables aux parties prenantes.\nSurveiller et r\u00e9soudre les probl\u00e8mes de pipelines de donn\u00e9es, en veillant \u00e0 la qualit\u00e9 et \u00e0 l'int\u00e9grit\u00e9 des donn\u00e9es.\nProfil recherch\u00e9 :\nDipl\u00f4me universitaire en informatique, en ing\u00e9nierie ou dans un domaine connexe.\nExp\u00e9rience av\u00e9r\u00e9e en tant que Data Engineer ou dans un r\u00f4le similaire, avec un accent particulier sur la construction de pipelines de donn\u00e9es et de processus ETL.\nCompr\u00e9hension solide des bases de donn\u00e9es\nSQL\net\nNoSQL\n, y compris la mod\u00e9lisation des donn\u00e9es et la conception de sch\u00e9mas.\nMa\u00eetrise des langages de programmation tels que\nPython, Java ou Scala.\nExp\u00e9rience avec des outils de visualisation de donn\u00e9es tels que\nTableau, Power BI.\nSolides comp\u00e9tences en analyse et en r\u00e9solution de probl\u00e8mes, avec la capacit\u00e9 de traduire des donn\u00e9es complexes en insights exploitables.\nExcellentes comp\u00e9tences en communication et en collaboration, avec la capacit\u00e9 de travailler efficacement dans un environnement d'\u00e9quipe pluridisciplinaire.\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "Java",
                "Scala",
                "R"
            ],
            "DataBase": [
                "SQL",
                "NoSQL"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [
                "Tableau",
                "Power BI"
            ],
            "Statistics": [],
            "CloudComputing": [],
            "DevTools": [],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [],
            "FrSoftSkills": [
                "Communication",
                "R\u00e9solution de probl\u00e8mes",
                "Collaboration"
            ],
            "EnSoftSkils": [
                "Communication",
                "Collaboration"
            ]
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {	
		"source": "LinkedIn",
        "title": "Data Engineer - Profils exp\u00e9riment\u00e9s H/F",
        "company": "LCL",
        "location": "Villejuif, \u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/data-engineer-profils-exp%C3%A9riment%C3%A9s-h-f-at-lcl-3888403052?position=21&pageNum=0&refId=b67kRduAUeEfaeVnXh9rCA%3D%3D&trackingId=z4Vl6fiAzW4xQbNi93g%2B9A%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "\ud83c\udfe6 LCL, c\u2019est LA banque urbaine du Groupe Cr\u00e9dit Agricole - avec nous, accompagnez la transformation, le d\u00e9veloppement et le maintien technologiques de nos outils avec une vision business et de satisfaction de nos 6 millions de clients.\nEn tant qu\u2019acteur majeur de la banque de d\u00e9tail, nous nous adaptons chaque jour aux nouveaux modes de consommation et les projets de nos de clients internes et externes tout en garantissant le besoin de s\u00e9curit\u00e9 et de d\u00e9veloppement technologique qu\u2019impliquent nos activit\u00e9s.\n\ud83d\udca1Organis\u00e9es en mode Agile, les 8 squads de la tribu DATA (6 squads M\u00e9tier et 2 squads transverses) \u0153uvrent au quotidien pour r\u00e9pondre \u00e0 un enjeu majeur pour la banque : la collecte, le stockage, la gestion et l\u2019usage de la donn\u00e9e. En interaction permanente avec les autres tribus IT et les m\u00e9tiers, elles \u00e9tudient et proposent les solutions et architectures \u00e0 d\u00e9ployer pour r\u00e9pondre au mieux aux strat\u00e9gies de d\u00e9veloppement et de pilotage de l\u2019ensemble des m\u00e9tiers de la banque.\nRejoignez-nous si vous souhaitez participer aux r\u00e9flexions et au d\u00e9veloppement de la trajectoire technique et DataCentric du SI LCL et plus largement du Groupe CA. Vous c\u00f4toierez et serez au c\u0153ur de l\u2019impl\u00e9mentation de technologies vari\u00e9es telles que les plateformes Teradata, les solutions d\u2019architecture applicative des technologies BigData ou IA, des environnements analytiques ou encore des solutions de datavisualisation. Vous assurerez le traitement de donn\u00e9es en temps r\u00e9el ou en batch et exposerez les donn\u00e9es sous diff\u00e9rentes formes.\nQue vous souhaitiez devenir expert sur les socles technologiques ou relever le challenge de la gestion de projets M\u00e9tier, nous vous aiderons \u00e0 atteindre vos propres objectifs.\nVous rejoindrez une \u00e9quipe pluridisciplinaire, clairement orient\u00e9e vers le d\u00e9veloppement de ses collaborateurs \u00e0 de nouvelles technologies !\n\ud83c\udfaf En tant que Data Engineer :\n\u00b7 Vous aimez analyser les besoins avec les m\u00e9tiers, challenger, identifier les sources de donn\u00e9es dans les diff\u00e9rents univers technologiques, industrialiser des algorithmes, concevoir et d\u00e9velopper des Datalab ou des Datamart sur les plateformes ? Vous saurez relever les challenges propos\u00e9s par les squads m\u00e9tier !\n\u00b7 Vous pr\u00e9f\u00e9rez travailler \u00e0 l\u2019architecture et au d\u00e9ploiement de nouvelles plateformes, \u00e0 la lev\u00e9e de la dette technologique ou encore r\u00e9aliser de la veille au service de notre trajectoire ? La squad Socles Data est faite pour vous !\n\u00b7 Au-del\u00e0 des projets que vous g\u00e9rerez, garant du bon fonctionnement de votre parc applicatif, vous attacherez une grande attention \u00e0 la mise en \u0153uvre de solutions optimis\u00e9es.\n\u00b7 La rigueur, la communication, l\u2019esprit d\u2019\u00e9quipe mais aussi la curiosit\u00e9 et la cr\u00e9ativit\u00e9 font partie de vos soft skills ! ils vous permettront de r\u00e9pondre aux enjeux de s\u00e9curit\u00e9, de qualit\u00e9, de transmission de la connaissance et contribueront \u00e0 l\u2019atteinte des objectifs de l\u2019IT et plus largement de LCL, au service de ses clients.\n\ud83d\udcbb Voici les principales technologies utilis\u00e9es au sein de la tribu, si certaines vous sont famili\u00e8res, nous vous aiderons \u00e0 monter en comp\u00e9tence sur d\u2019autres !\nLangages utilis\u00e9s : SQL, Python, Scala\nSGBD : Teradata et utilitaires (TPT, BTEQ, \u2026)\nStreaming : Kafka\nSearch : ElasticSearch, SolR\nEnvironnement : Unix\nSolutions Big Data : Hadoop Cloudera, DataIku, HDFS, Hive, Impala,\nDevops : GitLab, Jenkins, Nexus\nOutils de visualisation : MS BI (SSIS, SSAS, SSRS) Qlik Sens, BO\nMod\u00e9lisation : MEGA\nOutils collaboratifs : GIT, Jira, Confluence, Teams\n\u26a1Si les nouveaux enjeux bancaires vous int\u00e9ressent, que vous souhaitez int\u00e9grer une \u00e9quipe Agile au service des m\u00e9tiers dans laquelle vous serez force de proposition et que vous aimez travailler dans un environnement motivant et dynamique, rejoignez-nous, cette offre est faite pour vous !\n\ud83d\udd25 Les + de notre entreprise :\nAcc\u00e8s au Plan d\u2019\u00e9pargne Groupe, int\u00e9ressement et participation aux b\u00e9n\u00e9fices de l\u2019entreprise + abondement\nPrix pr\u00e9f\u00e9rentiels bancaires et avantages CSE\nParcours \u00e9volutif dans l\u2019entreprise et/ou dans le Groupe CA.S.A\nT\u00e9l\u00e9travail (jusqu'\u00e0 2 jours de t\u00e9l\u00e9travail par semaine)\nDe multiples commodit\u00e9s sur le campus (restaurants d'entreprise, salle de sport, cr\u00e8che, centre m\u00e9dical, m\u00e9diath\u00e8que...)\nForfait et avantages pratiques \u00ab mobilit\u00e9 durable \u00bb pour les velotafeurs\nDes \u00e9quipes aussi diversifi\u00e9es que structur\u00e9es dans une dynamique de transformation\nLCL s\u2019engage en faveur de la diversit\u00e9 et nous encourageons tout(e) candidat(e) ayant l\u2019exp\u00e9rience requise \u00e0 postuler \u00e0 nos offres. Tous nos postes sont ouverts aux personnes en situation de handicap.\nNous avons encore de nombreuses raisons \u00e0 vous pr\u00e9senter pour vous convaincre de nous rejoindre mais pour cela, il faudra postuler ici !\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "Scala",
                "R",
                "Go"
            ],
            "DataBase": [
                "SQL",
                "Elasticsearch"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [
                "Hadoop"
            ],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [],
            "DevTools": [
                "Git",
                "Jenkins"
            ],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [
                "JIRA",
                "Confluence",
                "Teams"
            ],
            "Other": [
                "DevOps",
                "Big Data",
                "Cloud"
            ],
            "FrSoftSkills": [
                "Communication",
                "Cr\u00e9ativit\u00e9"
            ],
            "EnSoftSkils": [
                "Communication"
            ]
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {	
		"source": "LinkedIn",
        "title": "Data Engineer",
        "company": "Ramify",
        "location": "Greater Paris Metropolitan Region",
        "link": "https://fr.linkedin.com/jobs/view/data-engineer-at-ramify-3896146641?position=22&pageNum=0&refId=b67kRduAUeEfaeVnXh9rCA%3D%3D&trackingId=JnSrc62bk8WQOsZhoPlmmg%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "ABOUT\nRamify\u2019s mission is to help people achieve financial freedom, no matter who they are and how much they have. We are revolutionizing the private wealth management industry by making smart and affordable financial products for everyone.\nNo more standardized solutions, hidden fees and complicated words, Ramify enables everyone to become a smart investor. The team combines elements of its research with technology to design customized investment portfolios composed of world-class financial products.\nThe team comprises around 15 talented individuals. Ramify is looking for talented people in all sectors, who want to have a huge impact, move fast and deliver.\nJOB DESCRIPTION\nThe Quantitative Investment Solutions (QIS) Team is dedicated to designing innovative investment portfolio models and developing cutting-edge investment features within our product suite. Moreover, the QIS Team is at the forefront of driving AI-based solutions for Ramify. This involves conceptualizing and implementing transformative AI solutions tailored to meet the diverse needs of various teams within Ramify.\nAs a Data Engineer on our QIS Team, you will play a pivotal role in shaping the future of investment strategies through data-driven insights and AI-based solutions. Collaborating closely with our talented team of quantitative researchers, and investment experts, your responsibilities will encompass architecting and implementing robust data pipelines. These pipelines will facilitate the seamless integration of diverse data sources, empowering Ramify teams to make informed decision-making.\nKey Responsibilities:\nDesign, build and launch data pipelines at scale to move data across Ramify platform with SQL technologies.\nDesign and implement processes and tools for data onboarding and quality, helping to deliver an industry best-practice solution for managing the data lifecycle.\nProduce stand-alone tools that can be used by other teams to automate data quality and discover faults.\nBuild analytical tools that provide insight into business metrics across Ramify.\nArchitect and lead the implementation of AI based solutions within Ramify\nPREFERRED EXPERIENCE\nWe're looking for people who:\nWant to make a difference. We are a small team effectively reshaping how people look at the industry. We need people who 'get it' and want to play an integral part in helping us accomplish this mission and are persistent in getting the job done.\nSkills we're looking for:\nMaster\u2019s or upper-year undergraduate-level coursework in either Computer Science, Management Information Systems, Business Information Systems, Mathematics or Finance related field.\n2+ years of professional experience in data engineering.\n2+ years of experience with one or more coding languages such as Python (is a must), Java.\nExperience with data modeling and ETL design, implementation and maintenance.\nDemonstrable mastery of industry best practices in the data lifecycle, including data quality automation and tooling.\nExcellent written and verbal communication skills with ability to communicate complex designs and solutions to non-technical and highly technical audiences alike.\nGood attention to detail.\nStrong analytics and strategic thinking skills\nNice-to-haves :\nUnderstanding of ML/ Generative AI technologies and their applications.\nPossess a passion, curiosity, and energy for finance + investing. You understand the ins and outs of the wealth management, trading, and more importantly - know how to explain these concepts simply\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "Java",
                "R",
                "Go"
            ],
            "DataBase": [
                "SQL"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [],
            "DevTools": [],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [
                "Teams"
            ],
            "Other": [
                "ML"
            ],
            "FrSoftSkills": [
                "Communication"
            ],
            "EnSoftSkils": [
                "Communication"
            ]
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {	
		"source": "LinkedIn",
        "title": "Data Engineer",
        "company": "Thales",
        "location": "Ollioules, Provence-Alpes-C\u00f4te d'Azur, France",
        "link": "https://fr.linkedin.com/jobs/view/data-engineer-at-thales-3902424527?position=23&pageNum=0&refId=b67kRduAUeEfaeVnXh9rCA%3D%3D&trackingId=9D9Rc8Bs0%2FSs66SNI5xCGA%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "QUI SOMMES-NOUS ?\nThales est un leader mondial des hautes technologies comptant plus de 81 000 collaborateurs pr\u00e9sents sur tous les continents. Le Groupe investit dans les innovations du num\u00e9rique et de la \u00ab deep tech \u00bb \u2013 big data, intelligence artificielle, connectivit\u00e9, cybers\u00e9curit\u00e9 et quantique \u2013 pour construire un avenir de confiance, essentiel au d\u00e9veloppement de nos soci\u00e9t\u00e9s, en pla\u00e7ant l\u2019humain au c\u0153ur des d\u00e9cisions.\nThales propose des solutions, services et produits qui aident ses clients \u2013 entreprises, organisations, Etats \u2013 dans cinq grands march\u00e9s vitaux pour le fonctionnement de nos soci\u00e9t\u00e9s : identit\u00e9 et s\u00e9curit\u00e9 num\u00e9riques, d\u00e9fense, a\u00e9ronautique, espace, et transport.\nQUI ETES-VOUS ?\nDipl\u00f4m\u00e9 d\u2019un Bac+5 en \u00e9cole d\u2019ing\u00e9nieur ou \u00e9quivalent universitaire avec une sp\u00e9cialisation en informatique, vous avez a\nu moins 3 ans d'exp\u00e9rience\ndans les technologies Big Data.\nPassionn\u00e9 par le\nsecteur de la D\u00e9fense et du Naval.\nCE QUE NOUS POUVONS ACCOMPLIR ENSEMBLE :\nEn tant que\nData Engineer,\nvous jouerez un r\u00f4le cl\u00e9 dans la conception, le d\u00e9veloppement et la maintenance de notre infrastructure de donn\u00e9es, ainsi que dans la transformation et la gestion des flux de donn\u00e9es.\nVOS MISSIONS :\n\u2022 Concevoir, d\u00e9velopper et d\u00e9ployer des solutions Big Data en utilisant les technologies\nHadoop, Spark, Scala\n.\n\u2022 Mettre en place des pipelines de donn\u00e9es performants pour l'ingestion, le traitement et le stockage des donn\u00e9es massives.\n\u2022 Collaborer \u00e9troitement avec les \u00e9quipes m\u00e9tier pour comprendre leurs besoins en mati\u00e8re d'analyse de donn\u00e9es et proposer des solutions adapt\u00e9es.\n\u2022 Optimiser les performances des clusters Hadoop pour garantir une exploitation efficace des donn\u00e9es.\n\u2022 Assurer la qualit\u00e9 et la fiabilit\u00e9 des donn\u00e9es trait\u00e9es, en mettant en place des processus de validation et de nettoyage.\n\u2022 Identifier et r\u00e9soudre les probl\u00e8mes li\u00e9s \u00e0 l'infrastructure Big Data et proposer des am\u00e9liorations.\nInnovation, passion, ambition : rejoignez Thales et cr\u00e9ez le monde de demain, d\u00e8s aujourd\u2019hui.\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Scala",
                "R"
            ],
            "DataBase": [],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [
                "Hadoop",
                "Spark"
            ],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [],
            "DevTools": [],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [
                "Big Data"
            ],
            "FrSoftSkills": [
                "Organisation"
            ],
            "EnSoftSkils": []
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [],
            "Salary": [],
            "Level": [
                "Bac+5"
            ],
            "Experience": [
                "a",
                "n",
                "s",
                "3",
                "3",
                "3"
            ]
        }
    },
    {	
		"source": "LinkedIn",
        "title": "Data Engineer H/F",
        "company": "Inetum",
        "location": "St.-Ouen, \u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/data-engineer-h-f-at-inetum-3843966639?position=24&pageNum=0&refId=b67kRduAUeEfaeVnXh9rCA%3D%3D&trackingId=Q%2Bk6aPwFl6DvxvKp76rWTA%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "D\u00e9tail de l'offre\nInformations g\u00e9n\u00e9rales\nEntit\u00e9 de rattachement\nInetum est un leader europ\u00e9en des services num\u00e9riques. Pour les entreprises, les acteurs publics et la soci\u00e9t\u00e9 dans son ensemble, les 28 000 consultants et sp\u00e9cialistes du groupe visent chaque jour l'impact digital des solutions qui contribuent \u00e0 la performance, \u00e0 l'innovation et au bien commun.\nPr\u00e9sent dans 19 pays au plus pr\u00e8s des territoires, et avec ses grands partenaires \u00e9diteurs de logiciels, Inetum r\u00e9pond aux enjeux de la transformation digitale avec proximit\u00e9 et flexibilit\u00e9.\nPort\u00e9 par son ambition de croissance et d'industrialisation, Inetum a g\u00e9n\u00e9r\u00e9 en 2023 un chiffre d'affaires de 2,5 milliards d'\u20ac.\nPour r\u00e9pondre \u00e0 un march\u00e9 en croissance continue depuis plus de 30ans, Inetum a fait le choix d\u00e9lib\u00e9r\u00e9 de se recentrer sur 4 m\u00e9tiers afin de gagner en puissance et proposer des solutions sur mesure, adapt\u00e9es aux besoins sp\u00e9cifiques de ses clients le conseil (Inetum Consulting), la gestion des infrastructures et applications \u00e0 fa\u00e7on (Inetum Technologies), l'impl\u00e9mentation de progiciels (Inetum Solutions) et sa propre activit\u00e9 d'\u00e9diteur de logiciels (Inetum Software). Inetum a conclu des partenariats strat\u00e9giques avec 4 grands \u00e9diteurs mondiaux - Salesforce, ServiceNow, Microsoft et SAP et poursuit une strat\u00e9gie d'acquisitions d\u00e9di\u00e9e afin d'entrer dans le top 5 europ\u00e9en sur ces technologies et proposer la meilleure expertise \u00e0 ses clients.\nTous nos postes sont ouverts aux personnes en situation de handicap.\nDescription du poste\nM\u00e9tier\nApplications Delivery - Software Development\nIntitul\u00e9 du poste\nData Engineer H/F\nContrat\nCDI\nDescription De La Mission\nLe p\u00f4le BFA de la branche Application Services du groupe INETUM, recherche plusieurs Data Engineers afin d'intervenir aupr\u00e8s de clients grands comptes au sein des march\u00e9s bancaires et de l'assurance.\nAu sein de l'\u00e9quipe Data, en tant que Data Engineer, vous participez \u00e0 la r\u00e9alisation de divers projets et vos missions sont\nApporter votre connaissance en Big Data permettant la manipulation des donn\u00e9es\nConcevoir les plateformes permettant de traiter des volumes de donn\u00e9es importants\nMettre en place des bases de donn\u00e9es\nPr\u00e9parer le pipeline de donn\u00e9es pour que les donn\u00e9es d\u00e9ploy\u00e9es soient s\u00e9curis\u00e9es et claires afin d'\u00eatre analys\u00e9es et transform\u00e9es.\nProfil\nDe formation ing\u00e9nieure en informatique Bac + 5 informatique ou scientifique\nBonne communication orale et \u00e9crite en fran\u00e7ais et niveau d\u2019anglais professionnel\nSavoir- \u00eatre Bon esprit d'analyse et de synth\u00e8se, sens de l'organisation et de la qualit\u00e9, force de proposition, rigueur, travail en \u00e9quipe, adaptabilit\u00e9.\nSi vous vous reconnaissez, n'h\u00e9sitez pas \u00e0 postuler !\nLocalisation du poste\nLocalisation du poste\nFrance\nVille\nSaint-Ouen\nCrit\u00e8res candidat\nNiveau d'\u00e9tudes min. requis\nBac+5\nNiveau d'exp\u00e9rience min. requis\nPlus de 2 ans\nComp\u00e9tences\nSQL\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "R"
            ],
            "DataBase": [
                "SQL"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [],
            "DevTools": [
                "Git"
            ],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [
                "Big Data"
            ],
            "FrSoftSkills": [
                "Communication",
                "Adaptabilit\u00e9",
                "Organisation",
                "Flexibilit\u00e9"
            ],
            "EnSoftSkils": [
                "Communication"
            ]
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [
                "CDI"
            ],
            "Salary": [],
            "Level": [
                "Bac+5"
            ],
            "Experience": [
                "a",
                "n",
                "s",
                "30",
                "30",
                "30"
            ]
        }
    },
    {	
		"source": "LinkedIn",
        "title": "Data Engineer (F/H)",
        "company": "Renault Digital",
        "location": "Boulogne-Billancourt, \u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/data-engineer-f-h-at-renault-digital-3911202728?position=25&pageNum=0&refId=b67kRduAUeEfaeVnXh9rCA%3D%3D&trackingId=xQaI%2FKhtHEWrp1eIaFQ%2Bxg%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Contexte :\nDans le cadre de son programme Industrie 4.0, Renault d\u00e9veloppe depuis 2017 sa propre plateforme pour connecter et agr\u00e9ger les donn\u00e9es industrielles des 22 sites du Groupe et de plus de 2500 machines.\nFort de partenariats strat\u00e9giques sign\u00e9s avec Google Cloud (stack data full GCP), Renault Digital est \u00e0 la recherche d\u2019un(e) Data Engineer au sein du P\u00f4le Architecture et Data pour mettre en place des cha\u00eenes de traitement de donn\u00e9es r\u00e9pondant \u00e0 de nouveaux besoins m\u00e9tiers.\nVous collaborerez au jour le jour avec les \u00e9quipes m\u00e9tiers ainsi qu\u2019avec les autres fonctions du P\u00f4le Architecture & Data (Data Analysts et Scientists, architectes, \u2026), exploitant des t\u00e9raoctets de donn\u00e9es (\u00e9v\u00e9nements en mode streaming, traitements en batch et temps r\u00e9els et les appels aux APIs) afin entre autres d\u2019alimenter des mod\u00e8les de machine learning (segmentation clients, d\u00e9tection automatiquement des pannes des v\u00e9hicules, \u2026).\nResponsabilit\u00e9s principales :\nVous participez aux phases de framing, MVP et release des produits, services et APIs orient\u00e9s data ;\nVous argumentez les choix d\u2019architecture des projets et de la plateforme datalake sur GCP ;\nVous contribuez \u00e0 la valeur m\u00e9tier des produits orient\u00e9s Data s\u2019appuyant sur le Datalake, en mettant en place des cha\u00eenes bout en bout de traitement de la data, de l\u2019ingestion \u00e0 l\u2019exposition d\u2019APIs et \u00e0 la visualisation des donn\u00e9es et des solutions ML/DS ;\nVous \u00eates garant de la qualit\u00e9 des donn\u00e9es transform\u00e9es dans le Datalake, du bon fonctionnement des cha\u00eenes de traitement et de l\u2019optimisation de l\u2019utilisation des ressources des ressources cloud ;\nVous proposez des standards d\u2019architecture et de d\u00e9veloppement ;\nVous \u00eates force de proposition, innovant(e) et bienveillant(e).\nEnvironement technique :\nSpark, Scala, Python, Java, Airflow, SQL, Google Cloud Platform (BigQuery, Cloud Storage, PubSub, Beam, Dataflow, Cloud ML, TensorFlow, Kubernetes), Git, Docker, JSON, Bash, Spotfire\nProfil recherch\u00e9 :\nVous avez minimum 5 ans d\u2019exp\u00e9rience en tant que Data Engineer ;\nVous disposez d\u2019une exp\u00e9rience en d\u00e9veloppement Spark, Scala, Python et requ\u00eatage SQL sur des gros volumes de donn\u00e9es ;\nVous avez une app\u00e9tence pour la data : validation, transformation, analyse, valorisation ;\nVous poss\u00e9dez une exp\u00e9rience de d\u00e9veloppement et orchestration de chaines ETL complexes via Airflow ou \u00e9quivalent ;\nVous pratiquez la m\u00e9thodologie agile (Agile Scrum et/ou Kanban) ;\nVous utilisez les services cloud (pr\u00e9f\u00e9rablement GCP) ;\nVous \u00eates capable d\u2019\u00e9changer en anglais technique \u00e9crit et oral.\nInformations compl\u00e9mentaires :\nVotre poste sera bas\u00e9 \u00e0 Boulogne-Billancourt (France) en CDI (temps plein)\nVous b\u00e9n\u00e9ficiez de 2 \u00e0 3 jours de t\u00e9l\u00e9travail par semaine\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "Java",
                "Scala",
                "R",
                "Go",
                "Bash"
            ],
            "DataBase": [
                "SQL"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [
                "Spark"
            ],
            "MachingLearning": [
                "TensorFlow"
            ],
            "DataSerialization": [
                "Json"
            ],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [
                "Google Cloud Platform"
            ],
            "DevTools": [
                "Git",
                "Docker"
            ],
            "Os": [],
            "DBMS": [
                "BigQuery"
            ],
            "SoftBigDataProcessing": [],
            "Automation": [
                "Kubernetes",
                "Airflow"
            ],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [
                "Docker",
                "Kubernetes"
            ],
            "Collaboration": [],
            "Other": [
                "ML",
                "Machine Learning",
                "Cloud"
            ],
            "FrSoftSkills": [],
            "EnSoftSkils": []
        },
        "details": {
            "JobDetail": [
                "Temps plein",
                "Full"
            ],
            "TypeContract": [
                "CDI"
            ],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s",
                "5",
                "5",
                "5"
            ]
        }
    },
    {	
		"source": "LinkedIn",
        "title": "Data Engineer BI - Nantes",
        "company": "Capgemini",
        "location": "Nantes, Pays de la Loire, France",
        "link": "https://fr.linkedin.com/jobs/view/data-engineer-bi-nantes-at-capgemini-3803963477?position=26&pageNum=0&refId=b67kRduAUeEfaeVnXh9rCA%3D%3D&trackingId=%2Fm%2B%2Bu0YrOQ7XM7%2FjP%2Fx0gg%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Capgemini\nChoisir Capgemini, c'est choisir une entreprise o\u00f9 vous serez en mesure de fa\u00e7onner votre carri\u00e8re selon vos aspirations, o\u00f9 vous serez soutenu et inspir\u00e9 par une communaut\u00e9 d\u2019experts dans le monde entier, o\u00f9 vous pourrez r\u00e9\u00e9crire votre futur. Rejoignez-nous pour red\u00e9finir les limites de ce qui est possible, contribuer \u00e0 lib\u00e9rer la valeur de la technologie pour les plus grandes organisations et participez \u00e0 la construction d\u2019un monde plus durable et inclusif.\nVos missions :\nInt\u00e9gr\u00e9(e) au sein d\u2019une \u00e9quipe projet BI, Big Data ou Data Gouvernance pour des clients intervenant dans des secteurs d'activit\u00e9s divers, vous serez notamment en charge des missions suivantes :\nMener les analyses fonctionnelles destin\u00e9es \u00e0 traduire les besoins du client,\nMener les travaux de conception et de mod\u00e9lisation,\nDiriger le d\u00e9veloppement de la solution / des traitements d'alimentation du DataWareHouse,\nOrganiser et pr\u00e9parer les travaux de recette utilisateurs,\nMettre en place les processus d'industrialisation et mener cette derni\u00e8re.\nVotre profil :\nDipl\u00f4me d\u2019ing\u00e9nieur ou \u00e9quivalent universitaire\nMinimum 3 ans d'exp\u00e9rience\nAnglais courant\nComp\u00e9tences en BI sur SAP BI (Hana, BW, BODS, BI 4), Microsoft BI (SQL Server, SSIS, SSAS, SSRS), Oracle (ODI, OBIEE), Teradata, Informatica (Powercenter), IBM (Datastage, Cognos, TM1), Talend, AB Initio\nMa\u00eetrise d'un ou de plusieurs outils de Dataviz : Microsoft Power BI, Tableau, Qlikview\nConnaissances en Big Data (Ecosyst\u00e8me Hadoop (HIVE, PIG, Mahout\u2026), Cloudera, Pivotal, Spark, HNX) ou en analytics (R, SAS, IBM SPSS)\n3 raisons de nous rejoindre :\nQualit\u00e9 de vie au travail : accord de t\u00e9l\u00e9travail en France et \u00e0 l\u2019international, accord sur l\u2019\u00e9galit\u00e9\nprofessionnelle, la parentalit\u00e9, l\u2019\u00e9quilibre des temps et la mobilit\u00e9 durable.\nApprentissage en continu : certifications et formations en libre acc\u00e8s, accompagnement sur mesure avec votre carreer manager, parcours d\u2019int\u00e9gration sur 9 mois.\nAvantages groupe & CSE : plan actionnariat, activit\u00e9s \u00e0 tarifs pr\u00e9f\u00e9rentiels, remboursement partiel\nvacances, remboursement de votre abonnement sportif ou culturel.\nNos engagements et priorit\u00e9s :\nLe groupe Capgemini encourage une culture inclusive dans un cadre multiculturel et handi-accueillant. En nous rejoignant, vous int\u00e9grez un collectif qui valorise la diversit\u00e9, d\u00e9veloppe le potentiel de ses talents, s\u2019engage dans des initiatives solidaires avec ses partenaires, et se mobilise pour r\u00e9duire son impact environnemental sur tous ses sites et aupr\u00e8s de ses clients.\nCapgemini\nCapgemini est un leader mondial, responsable et multiculturel, regroupant pr\u00e8s de 350 000 personnes dans plus de 50 pays. Fort de 55 ans d\u2019exp\u00e9rience, nous sommes un partenaire strat\u00e9gique des entreprises pour la transformation de leurs activit\u00e9s en tirant profit de toute la puissance de la technologie et des innovations dans les domaines en perp\u00e9tuelle \u00e9volution tels que le cloud, la data, l\u2019Intelligence Artificielle, la connectivit\u00e9, les logiciels, l\u2019ing\u00e9nierie digitale ou les\nplateformes.\nGet The Future You Want* | www.capgemini.com/fr-fr\n*Capgemini, le futur que vous voulez\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "R",
                "Go"
            ],
            "DataBase": [
                "SQL"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [
                "Hadoop",
                "Spark"
            ],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [
                "Tableau",
                "Power BI"
            ],
            "Statistics": [],
            "CloudComputing": [],
            "DevTools": [
                "Git"
            ],
            "Os": [],
            "DBMS": [
                "Oracle",
                "SQL Server"
            ],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [
                "Big Data",
                "Cloud"
            ],
            "FrSoftSkills": [
                "Organisation"
            ],
            "EnSoftSkils": [
                "Initiative"
            ]
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s",
                "3",
                "3",
                "3"
            ]
        }
    },
    {	
		"source": "LinkedIn",
        "title": "Data Engineer (H/F)",
        "company": "Beelix",
        "location": "Antibes, Provence-Alpes-C\u00f4te d'Azur, France",
        "link": "https://fr.linkedin.com/jobs/view/data-engineer-h-f-at-beelix-3838611420?position=27&pageNum=0&refId=b67kRduAUeEfaeVnXh9rCA%3D%3D&trackingId=ueaRofuONErN9s66mmUeUA%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Qui sommes-nous ?\nDepuis 2016, nous accompagnons nos clients sur des probl\u00e9matiques de Product Management, Data et Design Thinking. Beelix contribue \u00e0 fa\u00e7onner le monde de demain en participant aux grandes avanc\u00e9es des secteurs suivants :\n\ud83d\ude97Automobile\n\u26a1Energie\n\ud83d\udce1M\u00e9dias & T\u00e9l\u00e9coms\n\ud83d\udc57Luxe & Retail\n\ud83d\udcb6 Banque, Finance & Assurance\n\u2708\ufe0fD\u00e9fense\nAujourd\u2019hui, Beelix compte plus de 200 collaborateurs motiv\u00e9s et dynamiques. Lab\u00e9lis\u00e9e Great Place To work en 2023, Beelix est aussi une entreprise engag\u00e9e o\u00f9 il fait bon vivre.\nDans le cadre de notre d\u00e9veloppement, nous recherchons un Data Engineer (H/F) pour l'un de nos clients.\nQuelles missions au quotidien ?\n\u00catre le leader de la brique Datalakehouse\nD\u00e9velopper les scripts de transformations de donn\u00e9es et les pipelines d\u2019alimentation\nProposer des \u00e9volutions architecturales ou de fonctionnalit\u00e9s pour am\u00e9liorer le socle technique\n\u00catre le back-up du leader technique sur la partie reporting (Power BI)\nOrientation satisfaction client et r\u00e9sultat final forte mais \u00e9galement sensibilit\u00e9 au \u00ab comment \u00bb\nInnovation et proposition de nouvelles pratiques pour am\u00e9liorer l\u2019environnement et les conditions de travail des \u00e9quipes\nA propos de vous ?\n5 + ann\u00e9es d'exp\u00e9rience en tant que Data Engineer\nMa\u00eetrise des technologies suivantes : Microsoft Azure, Microsoft Azure Synapse Analytics (Spark / Python / Pipeline / Serverless), fichiers parquet / delta, Microsoft Power BI, Microsoft SQL Server, langage SQL, Datawarehousing / Mod\u00e9lisation de donn\u00e9es\nAnalyses et export de donn\u00e9es\nConnaissance de l\u2019ensemble du processus depuis la collecte jusqu\u2019\u00e0 la mise \u00e0 disposition des donn\u00e9es en ayant comme point fort la maitrise de sa transformation et mise en forme\nVous avez un bon niveau d\u2019anglais\nLocalisation : Biot et/ou Carros\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "R"
            ],
            "DataBase": [
                "SQL"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [
                "Spark"
            ],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [
                "Power BI"
            ],
            "Statistics": [],
            "CloudComputing": [
                "Azure"
            ],
            "DevTools": [],
            "Os": [],
            "DBMS": [
                "SQL Server"
            ],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [],
            "FrSoftSkills": [],
            "EnSoftSkils": []
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {	
		"source": "LinkedIn",
        "title": "Data Engineer",
        "company": "Digital Waffle",
        "location": "Paris, \u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/data-engineer-at-digital-waffle-3913824888?position=28&pageNum=0&refId=b67kRduAUeEfaeVnXh9rCA%3D%3D&trackingId=IEl%2FhktPBzJjGw4t%2Fz%2BTrw%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Digital Waffle is proud to have partnered with an innovative tech startup in Paris, who are looking for a talented Data Engineer to join their growing team!\nThey are made up of a powerhouse of experts, combining\ndata engineers, business process gurus, and Project managers\nwho leverage the most advanced solutions available; utilising process mining, automation tools, and smart execution systems.\nLooking for an experienced Data Engineer (3-5 years)\nWhat You'll Do:\nThis is a full-time,\nhybrid role (Paris-based)\nwhere you'll wear many hats: data exploration, system integration, data prep, data modeling, and implementing data solutions.\nExperience:\nExpertise in data engineering, data modeling, and ETL (Extract, Transform, Load) processes\nData warehousing and data analytics skills\nExperience handling large, complex datasets\nProficiency in SQL and programming languages like Python or Java\nStellar problem-solving and analytical skills\nTop-notch communication and collaboration abilities\nBachelor's or Master's in Computer Science, Information Systems, or a similar field (a plus for process mining or intelligent process automation experience)\nIf you are an experienced and driven Data Engineer, please apply here!\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "Java",
                "R"
            ],
            "DataBase": [
                "SQL"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [],
            "DevTools": [
                "Git"
            ],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [],
            "FrSoftSkills": [
                "Communication",
                "Collaboration"
            ],
            "EnSoftSkils": [
                "Communication",
                "Collaboration"
            ]
        },
        "details": {
            "JobDetail": [
                "Full"
            ],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {	
		"source": "LinkedIn",
        "title": "Data Engineer (H/F)",
        "company": "Scalian",
        "location": "Valbonne, Provence-Alpes-C\u00f4te d'Azur, France",
        "link": "https://fr.linkedin.com/jobs/view/data-engineer-h-f-at-scalian-3819563847?position=29&pageNum=0&refId=b67kRduAUeEfaeVnXh9rCA%3D%3D&trackingId=zbaJOj29uyfFAKD4DOxKZA%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Ing\u00e9nieur DATA / Data engineer (H/F)\nValbonne/Sophia-Antipolis\nType : CDI\nLieu : Locaux Scalian Sophia-Antipolis\nT\u00e9l\u00e9travail : En fonction des possibilit\u00e9s\nDate de prise de poste : imm\u00e9diatement ou en fonction de votre pr\u00e9avis\nSalaire : en fonction du profil - entre 40 et 48K Brut annuels (hors avantages Scalian)\nAvantages Scalian : Accord d'entreprise t\u00e9l\u00e9travail, Tickets restaurants, Mutuelle groupe, accord am\u00e9nagement temps de travail, compte \u00e9pargne temps, accord de participation et int\u00e9ressement groupe, programme cooptation et apports d'affaires, accompagnement parentalit\u00e9, avantages CSE\nVous \u00eates data engineer ou vous souhaitez le devenir !\nQuel sera votre r\u00f4le ?\nLa port\u00e9e de la mission comprend (sans toutefois s'y limiter) :\nScience des donn\u00e9es\nIng\u00e9nierie des donn\u00e9es\nAnalyse des donn\u00e9es\nG\u00e9nie logiciel\nCe que cette exp\u00e9rience va vous apporter\nVous \u00eates autonome, vous avez le sens du service et de l\u2019analyse, vous \u00eates impliqu\u00e9, nous vous offrons une ouverture sur des projets complexes et une rapide \u00e9volution de carri\u00e8re. Vous rejoignez notre business unit \u00e0 Sophia Antipolis compos\u00e9e d'environ 50 consultants, avec possibilit\u00e9 de t\u00e9l\u00e9travail en fonction des sujets.\nNous co-construisons votre trajectoire professionnelle et assurons votre mont\u00e9e en comp\u00e9tences.\nNous nous inscrivons ensemble dans la dur\u00e9e, nous assurons votre mont\u00e9e en comp\u00e9tences et disposons d'une vari\u00e9t\u00e9 de sujets passionnants.\nCe que nous recherchons chez vous\nDe formation sup\u00e9rieure (Bac+5, \u00e9cole ou universit\u00e9), vous poss\u00e9dez id\u00e9alement une premi\u00e8re exp\u00e9rience r\u00e9ussie dans ce domaine (d\u00e9butants accept\u00e9s), vous aimez le travail en \u00e9quipe.\nComp\u00e9tences requises\n:\nEtape d\u2019analyse : Comprendre l\u2019architecture technique, les sources de donn\u00e9es, les objectifs fonctionnels.\nEtape de conception : Solution de conception avec un fort centrage sur les pipelines de donn\u00e9es et les mod\u00e8les ML et l\u2019exposition des KPI via API\nMise en \u0153uvre : Apr\u00e8s les phases d\u2019analyse et de conception, proc\u00e9der \u00e0 a mise en \u0153uvre dans des technologies s\u00e9lectionn\u00e9es (Java,Scala,Python,Spark)\nCr\u00e9er un code test\u00e9 et document\u00e9\nTechno : Linux, Shell, Hadoop, Scrum, Python, Spark, Scala\nPourquoi feriez-vous le grand saut ?\nParce que Scalian vous accompagne dans le d\u00e9veloppement de votre carri\u00e8re :\nProgramme d'onboarding complet sur 1 an avec votre manager et votre RH\nProgramme de formation (Scalian Academy, e-learning, webinaires et formations externes)\nCommunaut\u00e9s techniques (Squads, Practices) afin de valoriser et d\u00e9velopper votre expertise\n\u00c9v\u00e9nements internes (Afterworks, Awards Dinner, Kick Off, Live Event du COMEX, Stand Up) et externes (participation \u00e0 des salons et forums sp\u00e9cialis\u00e9s dans nos domaines d\u2019activit\u00e9s\u2026)\nDispositif d\u2019acc\u00e9l\u00e9ration d\u2019acc\u00e8s \u00e0 la mobilit\u00e9 interne et \u00e0 des \u00e9changes internationaux type Erasmus\nParce que Scalian favorise la Qualit\u00e9 de Vie au Travail :\nCertifications Great Place to Work\u00ae et Best Workplaces for Women\u00ae\nPrime de cooptation, prime vacances, prise en charge par l\u2019employeur de 60% des titres-restaurant, Accord t\u00e9l\u00e9travail (jusqu\u2019\u00e0 2,5 jours par semaine indemnis\u00e9s), RTT (dont une partie mon\u00e9tisable), CSE (activit\u00e9s ludiques, ch\u00e8ques-cadeaux, ch\u00e8ques vacances)\nBerceaux en cr\u00e8ches inter-entreprises\nDon ou r\u00e9ception de jours de cong\u00e9s en cas de difficult\u00e9s personnelles\nParce que Scalian d\u00e9veloppe une politique RSE concr\u00e8te et ambitieuse :\nMobilit\u00e9 durable (indemnit\u00e9 kilom\u00e9trique v\u00e9lo, leasing de v\u00e9los \u00e0 assistance \u00e9lectrique)\nActions environnementales (Fresque du Climat, Reforest'Action, Clean Up Day, m\u00e9c\u00e9nat ONF)\nPostes ouverts aux personnes en situation de Handicap\nDiverses politiques de diversit\u00e9, d\u2019inclusion et d\u2019int\u00e9gration mises en place\nScalian c\u2019est aussi :\nUne entreprise en tr\u00e8s forte croissance qui, cr\u00e9\u00e9e en 1989, compte aujourd\u2019hui plus de 5500 personnes\nDes r\u00e9f\u00e9rences clients \u00e0 forte valeur ajout\u00e9e aupr\u00e8s de grands industriels fran\u00e7ais (du CAC40) et internationaux\nUn terrain de jeu o\u00f9 l\u2019expertise se conjugue avec audace, libert\u00e9 d\u2019entreprendre et convivialit\u00e9\nSi vous aspirez \u00e0 un environnement de travail qui valorise autant votre bien-\u00eatre que votre d\u00e9veloppement professionnel,\nrejoignez-nous et exprimez pleinement votre talent !\nEnvie d'\u00e9largir le cadre ?\nJe suis Liza Djehel, Talent Acquisition Officer.\nSi votre CV est retenu, je vous contacte pour un premier \u00e9change t\u00e9l\u00e9phonique de 15 \u00e0 20 minutes.\nNous d\u00e9terminons ensemble si ce poste est en ad\u00e9quation avec vos comp\u00e9tences et surtout, avec vos attentes.\nL'\u00e9change est positif ? Nous convenons d'un entretien de 1h (en pr\u00e9sentiel ou en visio) avec Lucas Daunar, Business Manager \u00e0 Sophia-Antipolis. Cet \u00e9change permet de revenir en d\u00e9tail sur vos comp\u00e9tences, vos attentes, de vous pr\u00e9senter le poste plus en d\u00e9tail, et d'\u00e9voquer d'autres opportunit\u00e9s.\nNous pr\u00e9voyons ensuite un rendez-vous technique de 1h (en pr\u00e9sentiel ou en visio) avec un de nos responsable technique.\nEnfin, nous vous pr\u00e9sentons notre proposition d'embauche.\nNotre processus de recrutement dure entre 15 et 30 jours\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "Java",
                "Scala",
                "R"
            ],
            "DataBase": [],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [
                "Hadoop",
                "Spark"
            ],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [],
            "DevTools": [],
            "Os": [
                "Linux"
            ],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [
                "ML"
            ],
            "FrSoftSkills": [],
            "EnSoftSkils": []
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [
                "CDI"
            ],
            "Salary": [
                "40"
            ],
            "Level": [
                "Bac+5"
            ],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {	
		"source": "LinkedIn",
        "title": "Data Engineer H/F",
        "company": "Ippon Technologies",
        "location": "Greater Nantes Metropolitan Area",
        "link": "https://fr.linkedin.com/jobs/view/data-engineer-h-f-at-ippon-technologies-3902436649?position=30&pageNum=0&refId=b67kRduAUeEfaeVnXh9rCA%3D%3D&trackingId=AsgLBKPObp783Z2tkccsfQ%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Envie de rejoindre la communaut\u00e9 DATA la plus dynamique de France ?\nNotre sp\u00e9cialit\u00e9 est de construire des data platform dans le Cloud public avec les meilleurs technos du moment : Snowflake, Databricks, Matillion, DBT.\nMembre de la Practice Data, le/la futur(e) Data Engineer sera int\u00e9gr\u00e9(e) \u00e0 nos \u00e9quipes de conseil et sera suivi(e) par un(e) mentor qui l\u2019aidera \u00e0 monter en comp\u00e9tences.\nVotre champs d\u2019expertise :\nIntervenir sur les data platforms de nos clients pour d\u00e9velopper de nouveaux pipelines de donn\u00e9es (ingestion, traitement, exposition).\nTravailler en collaboration avec les m\u00e9tiers et les data scientists pour leur fournir un support \u00e0 l\u2019industrialisation de leurs travaux (tests, int\u00e9gration continue, scalabilit\u00e9 des mod\u00e8les, craftsmanship etc\u2026)\nD\u00e9ployer des infrastructures cloud full\ninfra-as-code\n(Terraform, CloudFormation).\nParticiper aux \u00e9v\u00e8nements internes \u00e0 la communaut\u00e9 data (BBL, webinar, datap\u00e9ro interne, meetup, blog, dojos) et externes (Salon du Big Data, GCP Summit, Spark Summit, AWS Summit, Devoxx, workshop partenaire, meetups).\nCapitaliser sur les missions et les diff\u00e9rents \u00e9v\u00e8nements de la communaut\u00e9 au travers d\u2019articles de blogs, REX, BBL interne.\nVos connaissances :\nUn framework de calcul distribu\u00e9 tel que Spark, Storm, Flink.\nUn ou plusieurs langages de programmation (Python, Scala, Java...)\nDiff\u00e9rents syst\u00e8mes de stockage de donn\u00e9es (SQL ou NoSQL) et bien s\u00fbr le langage SQL.\nLa connaissance de Snowflake est bienvenue ;-)\nUn framework de streaming de donn\u00e9es tel que Kafka ou Amazon Kinesis.\nUne exp\u00e9rience sur les technologies Cloud : AWS, GCP, Azure\nLe delivery et les projets en production faisant partie de notre ADN, vous \u00eates capable de livrer du code de qualit\u00e9 dans des environnements agiles.\nDe plus en plus de nos projets se font en remote avec des clients du monde entier, il devient n\u00e9cessaire d\u2019\u00eatre \u00e0 l\u2019aise en Anglais.\nIppon technologies c\u2019est aussi :\n\ud83d\udc4d B\u00e9n\u00e9ficier d'un suivi de proximit\u00e9 r\u00e9alis\u00e9 par votre manager technique : points r\u00e9guliers pour votre suivi en mission, votre formation et votre \u00e9volution de carri\u00e8re\n\u270c\ufe0f Rejoindre une entreprise o\u00f9 les valeurs du sport sont nos leitmotiv : d\u00e9passement de soi, travail en \u00e9quipe, bienveillance.\n\ud83d\uddd2\ufe0f Apprendre via notre programme de formation BlackBelt : https://bit.ly/3ByqcIL\n\ud83d\ude01 Travailler en pair programming ou avec un.e mentor pour gravir les \u00e9chelons !\n\ud83d\udcaa Pouvoir participer \u00e0 une aventure humaine au sein de notre Fondation Ippon pour r\u00e9duire la fracture num\u00e9rique dans le monde !\n\ud83e\udd1d Participer \u00e0 nos ap\u00e9ros et divers \u00e9v\u00e8nements internes pour consolider la coh\u00e9sion d\u2019\u00e9quipe\nEt apr\u00e8s ?\nEt oui alors ? Que se passe-t-il une fois que vous \u00eates convaincu d\u2019avoir lu l\u2019offre d\u2019emploi qui vous correspond bien ?\nNous vous proposons de prendre contact et de nous rencontrer !\nLes Next Steps :\n1 call RH\n1 \u00e9change RH\n1 \u00e9change Technique\nSi le match est bon des deux c\u00f4t\u00e9s : Hadjim\u00e9 ! Vous vous lancerez sur le tatami Ippon !\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "Java",
                "Scala",
                "R"
            ],
            "DataBase": [
                "SQL",
                "NoSQL"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [
                "Spark",
                "Databricks",
                "Flink"
            ],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [
                "AWS",
                "Azure"
            ],
            "DevTools": [],
            "Os": [],
            "DBMS": [
                "Snowflake",
                "Snowflake"
            ],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [
                "Terraform",
                "CloudFormation"
            ],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [
                "Big Data",
                "Cloud"
            ],
            "FrSoftSkills": [
                "Collaboration"
            ],
            "EnSoftSkils": [
                "Collaboration"
            ]
        },
        "details": {
            "JobDetail": [
                "Remote",
                "Full"
            ],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "Data Engineer (H/F)",
        "company": "ternair",
        "location": "Greater Lille Metropolitan Area",
        "link": "https://fr.linkedin.com/jobs/view/data-engineer-h-f-at-ternair-3915757963?position=31&pageNum=0&refId=b67kRduAUeEfaeVnXh9rCA%3D%3D&trackingId=DDZVC8nqVobqpHnmOgDD6g%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "\ud83d\udc68\u200d\ud83d\ude80 MISSION : \ud83d\udc69\u200d\ud83d\ude80\nEn coh\u00e9rence avec la strat\u00e9gie d\u2019entreprise et la roadmap data, vous aurez pour principales missions de :\nEn lien avec l\u2019\u00e9quipe DevOps, construire, maintenir et faire \u00e9voluer la plateforme de donn\u00e9es;\nD\u00e9finir et piloter la coh\u00e9rence de la collecte, la gestion et l\u2019alimentation des donn\u00e9es internes et externes, en diff\u00e9rents modes : batch, streaming, API (architecture micro-services);\nPr\u00e9parer et mettre en qualit\u00e9 les donn\u00e9es pour les rendre disponibles dans les diff\u00e9rents environnements de travail (datalake, datawarehouse, datamart);\nV\u00e9rifier la qualit\u00e9 des donn\u00e9es, de leur bonne et r\u00e9guli\u00e8re ex\u00e9cution ainsi que de leur utilisation ad\u00e9quate (gestion des co\u00fbts);\nTravailler en \u00e9troite collaboration avec les data analysts, scientists et data stewards et business de l\u2019entreprise ;\nEn lien avec l\u2019IT et la s\u00e9curit\u00e9, veiller aux r\u00e8gles d'int\u00e9grit\u00e9 et de s\u00e9curit\u00e9 des donn\u00e9es;\nVeille technologique.\n\ud83e\uddee Les outils :\nPlateforme data : Google Cloud Platform (Big Query, Airflow)\nD\u00e9veloppement : Github/GitLab, Docker, Terraform, Python\nAnalytiques : Qlik\nGestion de projet s: Jira, Confluence, Miro, Drive, Docs, Sheets, Slides\n\ud83e\udd29 Profil recherch\u00e9 : \ud83e\udd29\nExp\u00e9rience d'au moins 4-5 ans (apr\u00e8s \u00e9tudes) en data ing\u00e9nierie (flux, mod\u00e9lisation, run)\nA l\u2019aise avec l\u2019environnement Cloud et les infrastructures digitales\nCommuniquant, p\u00e9dagogue et fortes capacit\u00e9s relationnelles\nAnglais (\u00e0 l\u2019\u00e9crit)\nR\u00e9mun\u00e9ration : 42-60 k\u20ac en package selon exp\u00e9rience\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "R",
                "Go"
            ],
            "DataBase": [],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [
                "Google Cloud Platform"
            ],
            "DevTools": [
                "Git",
                "Docker"
            ],
            "Os": [],
            "DBMS": [
                "Big Query"
            ],
            "SoftBigDataProcessing": [],
            "Automation": [
                "Airflow"
            ],
            "InfrastructureAsCode": [
                "Terraform"
            ],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [
                "Docker"
            ],
            "Collaboration": [
                "JIRA",
                "Confluence"
            ],
            "Other": [
                "DevOps",
                "Cloud"
            ],
            "FrSoftSkills": [
                "Collaboration"
            ],
            "EnSoftSkils": [
                "Collaboration"
            ]
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [],
            "Salary": [
                "Package"
            ],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s",
                "5",
                "5",
                "5"
            ]
        }
    },
    {	
		"source": "LinkedIn",
        "title": "Data Engineer",
        "company": "Shippeo",
        "location": "Greater Paris Metropolitan Region",
        "link": "https://fr.linkedin.com/jobs/view/data-engineer-at-shippeo-3908268236?position=32&pageNum=0&refId=b67kRduAUeEfaeVnXh9rCA%3D%3D&trackingId=SDVf9YZXmr8b1pbHooAYoA%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Founded in 2014, Shippeo is a French based SaaS company providing supply chain visibility. Shippeo has grown from 70 to 220 employees during the last two years and is continuing to rapidly scale after an additional $40M fundraising round in October 2022.\nShippeo is an exceptionally diverse company with colleagues from 27 different nationalities and speaking 29 languages. With offices throughout Europe, North America and recently Asia, Shippeo provides global coverage to all of our clients.\nOur product is composed of a mission critical SaaS web platform (API everywhere), with high traffic inbound/outbound integrations.\nOur mission is to anticipate problems and proactively alert end-customers so they can efficiently manage exceptions. We achieve this by collecting and matching millions of theoretical and real data from different stakeholders.\nThe Data Intelligence Tribe is responsible for leveraging Shippeo\u2019s data from our large shipper and carrier base, to build data products that help our users (shippers and carriers alike) and ML models to provide predictive insights. This tribe\u2019s typical responsibilities are to:\nget accurately alerted in advance of any potential delays on their multimodal flows or anomalies so that they can proactively anticipate any resulting disruptions\nextract the data they need, get direct access to it or analyze it directly on the platform to gain actionable insights that can help them increase their operational performance and the quality and compliance of their tracking\nprovide best-in-class data quality by implementing advanced cleansing & enhancement rules\nAs a Data Engineer at Shippeo, your objective is to ensure that data is available and exploitable by our Data Scientists and Analysts on our different data platforms. You will contribute to the construction and maintenance of Shippeo\u2019s modern data stack that\u2019s composed of different technology blocks:\nData Acquisition (Kafka, KafkaConnect, RabbitMQ),\nBatch data transformation (Airflow, DBT),\nCloud Data Warehousing (Snowflake, BigQuery),\nStream/event data processing (Python, docker, Kubernetes) and all the underlying infrastructure that support these use cases.\nQualifications\nRequired:\nYou have a degree (MSc or equivalent) in Computer Science.\n3+ years of experience as a Data Engineer.\nExperience building, maintaining, testing and optimizing data pipelines and architectures\nProgramming skills in Python and experience with asynchronous event processing (asyncio).\nAdvanced working knowledge of SQL, experience working with relational databases and familiarity with a variety of databases.\nWorking knowledge of message queuing and stream processing.\nKnowledge of Docker and Kubernetes.\nKnowledge of a cloud platform (preferably GCP).\nExperience working with workflow management systems such as Airflow.\nDesired:\nExperience with cloud based data warehouse solutions (BigQuery, Snowflake).\nExperience with Kafka and KafkaConnect (Debezium).\nExperience with Infrastructure as code (Terraform/Terragrunt).\nExperience building and evolving CI/CD pipelines with Github Actions.\nMonitoring and alerting on Grafana / Prometheus.\nExperience working on Apache Nifi.\nInformations suppl\u00e9mentaires\nWe are looking for talents who share our values:\n\ud83d\ude80 Ambition\n\ud83d\udc99 Care\n\ud83c\udfaf Deliver\n\ud83e\udd1d Collaboration\nFind out more about our values in\nOur Culture Book\nIf you identify with our values and enjoy working in a fast-paced and international environment, Shippeo is just the place for you!\nWe are committed to fostering diversity and inclusion within our workplace as we value the unique perspectives and experiences that individuals from all backgrounds bring to our team. We are dedicated to providing equal employment opportunities to all candidates, regardless of their background or abilities, and our commitment to inclusion is reflected in our policies, practices, and workplace culture.\nWe understand that candidates may have unique needs or questions related to disability inclusion. To facilitate this, you can reach our dedicated Disability Advisor at\ninclusion@shippeo.com\nwith any inquiries or requests for accommodations during the application process.\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "R"
            ],
            "DataBase": [
                "SQL"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [],
            "DevTools": [
                "Git",
                "Docker"
            ],
            "Os": [],
            "DBMS": [
                "Snowflake",
                "Snowflake",
                "BigQuery"
            ],
            "SoftBigDataProcessing": [],
            "Automation": [
                "Kubernetes",
                "Airflow"
            ],
            "InfrastructureAsCode": [
                "Terraform"
            ],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [
                "Docker",
                "Kubernetes"
            ],
            "Collaboration": [],
            "Other": [
                "ML",
                "Cloud",
                "CI/CD"
            ],
            "FrSoftSkills": [
                "Collaboration"
            ],
            "EnSoftSkils": [
                "Collaboration"
            ]
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {	
		"source": "LinkedIn",
        "title": "Data engineer - F / H",
        "company": "United Robotics Group",
        "location": "Paris, \u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/data-engineer-f-h-at-united-robotics-group-3891680780?position=33&pageNum=0&refId=b67kRduAUeEfaeVnXh9rCA%3D%3D&trackingId=BOP09wArK5oohNUn%2FG9McA%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Bienvenue chez\nAldebaran\n, leader europ\u00e9en de la robotique\nau sein du groupe\nUnited Robotics Group\n.\nNous concevons et industrialisons des robots innovants avec une vision soci\u00e9tale ambitieuse pour fa\u00e7onner un monde plus humain. Depuis 2005, nous sommes \u00e0 l'avant-garde de l'interaction homme-robot avec des produits embl\u00e9matiques tels que NAO et Pepper.\nNotre dernier-n\u00e9,\nPlato\n,\nincarne notre engagement envers la technologie de pointe et la s\u00e9curit\u00e9,\nfabriqu\u00e9 en France avec des composants europ\u00e9ens.\nRejoignez nos \u00e9quipes multiculturelles et dynamiques pour \u00eatre au c\u0153ur de la r\u00e9volution de la robotique.\nSi vous \u00eates passionn\u00e9.e par la robotique et l'intelligence artificielle, et que vous souhaitez contribuer \u00e0 fa\u00e7onner l'avenir, nous vous offrons une exp\u00e9rience enrichissante et stimulante.\nEn tant que membre de notre \u00e9quipe, vous b\u00e9n\u00e9ficierez d'une culture d'entreprise ax\u00e9e sur le sens de ce que nous faisons et valorisant la responsabilit\u00e9 sociale et environnementale.\nChez Aldebaran, nous valorisons l'innovation, la diversit\u00e9 et l'\u00e9galit\u00e9 et encourageons chacun.e \u00e0 \u00eatre ouvert.e, authentique, courageux.se, responsable et engag\u00e9.e.\nFinalit\u00e9 du poste\nAu sein de l'\u00e9quipe Cloud-Online Services, le Data engineer int\u00e9grera l'\u00e9quipe Data, responsable du d\u00e9veloppement des produits destin\u00e9s \u00e0 la collecte, aux process et \u00e0 l'exploitation des donn\u00e9es de nos robots.\nIl aura pour r\u00f4le de d\u00e9finir et d'impl\u00e9menter des services data, sur une infrastructure Cloud AWS, supportant des services en ligne qui g\u00e8rent les robots du groupe.\nMissions principales\nLe Data engineer aura pour responsabilit\u00e9s de :\n\u00e9valuer les choix d'architecture et de solutions techniques lors de la mise en place de PoC,\nconcevoir et d\u00e9velopper des services Data en respectant la sp\u00e9cification fonctionnelle et la m\u00e9thodologie agile,\nagr\u00e9ger et stocker de grandes quantit\u00e9s de donn\u00e9es,\nmettre en place des solutions de data processing,\nint\u00e9grer/d\u00e9velopper des outils de visualisation de donn\u00e9es et analyser les KPI,\nd\u00e9velopper, tester, s\u00e9lectionner et mettre en production des algorithmes qui permettent de r\u00e9pondre aux besoins,\nr\u00e9aliser des analyses de donn\u00e9es,\nmettre en place des tests de charge et fonctionnels pour les solutions Data,\ninvestiguer et corriger les bugs remont\u00e9s par les utilisateurs,\ncontribuer \u00e0 la mise en place de l'infrastructure et outil de d\u00e9ploiement (CI/CD)\nRejoignez-nous pour faire partie d'une aventure passionnante o\u00f9 Pepper, NAO, Plato et leurs futurs successeurs attendent votre contribution pour repousser les limites de la technologie robotique !\nRequirements\nPour la bonne ex\u00e9cution des missions confi\u00e9es, vous t\u00e9moignez d'au moins 6 ans d'exp\u00e9rience en tant que d\u00e9veloppeur sur des projets data en Cloud en Python et Spark et avec comme Cloud provider AWS.\nComp\u00e9tences demand\u00e9es :\nBonne compr\u00e9hension des technologies d'infrastructure et de d\u00e9ploiement,\nComp\u00e9tences techniques sur les services AWS : IOT core , Glue, lambda, Kinesis, S3, RDS,\nBonne compr\u00e9hension technique dans la mise en place et l'automatisation de tests de charge et fonctionnels,\nBonne maitrise d'outils BI ou de dashboarding (POWER BI, TABLEAU, QUICKSIGHT)\nBonne connaissance et une exp\u00e9rience pratique de Scrum\\Scrumban et des m\u00e9thodes agiles,\nUne certification AWS sera appr\u00e9ci\u00e9e,\nUn niveau de fran\u00e7ais et d'anglais courant est indispensable,\nDes exp\u00e9riences dans des environnements fortement internationaux sont un plus\nBenefits\nNos principaux avantages :\nUne culture du bien-\u00eatre en entreprise qui a fait ses preuves (budget c\u00e9l\u00e9bration et moments de convivialit\u00e9 par \u00e9quipes et directions, restauration collective de qualit\u00e9, environnement de travail agr\u00e9able)\nUn engagement fort en mati\u00e8re de responsabilit\u00e9 sociale et environnementale (promotion de l'\u00e9galit\u00e9 professionnelle, performance de notre plan diversit\u00e9 et inclusion, r\u00e9f\u00e9rent handicap, fresque du num\u00e9rique)\nUne culture du t\u00e9l\u00e9travail encadr\u00e9e de mani\u00e8re appropri\u00e9e !\nTous nos postes sont ouverts aux personnes en situation de handicap.\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "R",
                "Go"
            ],
            "DataBase": [],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [
                "Spark"
            ],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [
                "Tableau",
                "Power BI"
            ],
            "Statistics": [],
            "CloudComputing": [
                "AWS"
            ],
            "DevTools": [],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [
                "Cloud",
                "CI/CD"
            ],
            "FrSoftSkills": [],
            "EnSoftSkils": []
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s",
                "6",
                "6",
                "6"
            ]
        }
    },
    {	
		"source": "LinkedIn",
        "title": "Data Engineer H/F",
        "company": "Neosoft",
        "location": "Lille, Hauts-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/data-engineer-h-f-at-neosoft-3877878521?position=34&pageNum=0&refId=b67kRduAUeEfaeVnXh9rCA%3D%3D&trackingId=5ibIRVZnYxMQyNtqkit%2BIw%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Tous nos postes sont ouverts au t\u00e9l\u00e9travail\nGroupe ind\u00e9pendant de conseil en transformation digitale de pr\u00e8s de 1800 collaborateurs, N\u00e9osoft s\u2019est construit, depuis 2005, sur un mod\u00e8le qui place l\u2019excellence, le d\u00e9passement de soi et la RSE au c\u0153ur de sa strat\u00e9gie.\nEn nous rejoignant, vous int\u00e9grez des communaut\u00e9s d\u2019experts et de talents qui vous permettent de d\u00e9velopper vos comp\u00e9tences et d\u2019offrir \u00e0 nos clients le meilleur accompagnement possible.\nNotre savoir-faire s\u2019articule autour de nos 6 domaines d\u2019expertise :\nConseil & Agilit\u00e9\nCybers\u00e9curit\u00e9\nData\nDevOps\nInfrastructures & Cloud\nSoftware Engineering\nNous recherchons pour int\u00e9grer notre\nagence lilloise\nun(e)\nData Engineer confirm\u00e9(e)\n.\nNous aimerions vous voir rayonner au sein de notre communaut\u00e9 DATA (+100 collaborateurs) anim\u00e9e par Nicolas Huche, son practice leader et Thibaud Blanchard son Technical Officer. Vous aiderez les clients \u00e0 consolider un patrimoine Data responsable.\n\ud83c\udfaf\nVos missions :\nApr\u00e8s une p\u00e9riode d\u2019int\u00e9gration, en tant que\nData Engineer\n, voici \u00e0 quoi ressembleront vos activit\u00e9s dans des contextes clients Retail ou Banque / Assurance / Finance :\nAnalyser et s'approprier les cas d'usages\nAnalyser et valoriser les donn\u00e9es du patrimoine\nMettre en place des flux de transformation de donn\u00e9es\nR\u00e9aliser les tests permettant de s'assurer la qualit\u00e9 du delivery\nContinuer la mise au point de frameworks data\nCr\u00e9er et d\u00e9velopper des modules de d\u00e9ploiement des solutions\nAssurer l'industrialisation de moteurs bas\u00e9s sur l'IA\nAssurer le niveau de performance des pipelines\nImpl\u00e9menter les outils de monitoring du socles de donn\u00e9es\n\ud83d\udcdd\nVotre profil :\nNous vous imaginons avec au moins 4 ans d\u2019exp\u00e9riences sur des projets autour de la\nData\n, une ma\u00eetrise des\nbases de donn\u00e9es (SQL)\n, des outils de transformation de la donn\u00e9e\n(Talend, BigQuery, Airflow)\n, et un socle de comp\u00e9tences solides autours des langages\nPython, Spark, Scala, Hadoop, Java.\n\ud83d\udc49\nVotre carri\u00e8re chez N\u00e9osoft\nDepuis sa cr\u00e9ation, N\u00e9osoft place ses collaborateurs au c\u0153ur de sa strat\u00e9gie. Notre culture pourrait se r\u00e9sumer en un mot : le collectif.\nNos communaut\u00e9s d\u2019experts vous donnent la possibilit\u00e9 d\u2019apprendre, mais aussi de transmettre et de partager vos savoirs pour faire progresser les autres.\nNous veillons \u00e0 ce que chacun b\u00e9n\u00e9ficie d\u2019un accompagnement de proximit\u00e9 et d\u2019un suivi de carri\u00e8re personnalis\u00e9 aupr\u00e8s de votre manager d\u00e9di\u00e9 :\n1 bilan d\u2019activit\u00e9 trimestriel pour suivre le d\u00e9veloppement de vos comp\u00e9tences\n1 entretien d\u2019\u00e9valuation qui a lieu chaque ann\u00e9e pour \u00e9valuer votre performance et d\u00e9terminer vos nouveaux objectifs\n1 entretien annuel aupr\u00e8s de votre RH dans le but de cartographier vos nouvelles comp\u00e9tences pour \u00e9changer sur vos projets professionnels et souhaits de formations\n\ud83d\udc49\nVos avantages\nFormations et d\u00e9veloppement de l\u2019expertise :\nVous disposez de temps allou\u00e9 et r\u00e9mun\u00e9r\u00e9 en contribuant au d\u00e9veloppement de votre expertise technique et de celle du groupe (Participations \u00e0 des Tech days, animation d\u2019une conf\u00e9rence \u00e0 l\u2019interne ou \u00e0 l\u2019externe, r\u00e9daction d\u2019articles, rencontres avec nos candidats en processus de recrutement\u2026)\nUn abonnement illimit\u00e9 LinkedIn Learning offert\nBien-\u00eatre au travail :\nUn accord de t\u00e9l\u00e9travail flexible jusqu\u2019\u00e0 100% de t\u00e9l\u00e9travail et personnalisable\nUn partenariat avec Gymlib qui favorise le sport en entreprise\nDes initiatives locales (afterworks, d\u00e9fis sportifs, team buildings, \u2026)\nEt bien plus encore :\nParce que les meilleurs cooptent les meilleurs, une politique de cooptation attractive r\u00e9mun\u00e9r\u00e9e d\u00e8s l\u2019arriv\u00e9e du collaborateur\nEn plus de votre salaire : participation, compte \u00e9pargne temps, actionnariat...\n\ud83d\udc49\nVotre parcours candidat\nNotre processus de recrutement se compose de deux \u00e9tapes cl\u00e9s :\nUn entretien de recrutement RH avec un Talent Acquisition Sp\u00e9cialiste pour dresser un bilan de votre parcours professionnel et identifier les trajectoires de carri\u00e8re possibles au sein de notre groupe\nUn entretien d\u2019\u00e9valuation technique pour r\u00e9aliser un diagnostic de vos comp\u00e9tences techniques et identifier les comp\u00e9tences sur lesquels poursuivre votre \u00e9volution\nVous aurez \u00e9galement la possibilit\u00e9 de rencontrer pour compl\u00e9ter votre processus un acteur de notre p\u00f4le Business ou un pair de votre m\u00e9tier pour \u00e9changer sur son exp\u00e9rience collaborateur.\nNous avons h\u00e2te de vous rencontrer !\nA bient\u00f4t,\nL\u2019\u00e9quipe N\u00e9osoft \ud83d\udd90\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "Java",
                "Scala",
                "R"
            ],
            "DataBase": [
                "SQL"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [
                "Hadoop",
                "Spark"
            ],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [],
            "DevTools": [
                "Git"
            ],
            "Os": [],
            "DBMS": [
                "BigQuery"
            ],
            "SoftBigDataProcessing": [],
            "Automation": [
                "Airflow"
            ],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [
                "DevOps",
                "ML",
                "Cloud"
            ],
            "FrSoftSkills": [],
            "EnSoftSkils": [
                "Initiative"
            ]
        },
        "details": {
            "JobDetail": [
                "Confirm\u00e9"
            ],
            "TypeContract": [],
            "Salary": [
                "Salaire"
            ],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s",
                "4",
                "4",
                "4"
            ]
        }
    },
    {	
		"source": "LinkedIn",
        "title": "Data & Cloud Engineer (H/F)",
        "company": "fifty-five",
        "location": "Paris, \u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/data-cloud-engineer-h-f-at-fifty-five-3910028674?position=35&pageNum=0&refId=b67kRduAUeEfaeVnXh9rCA%3D%3D&trackingId=goi29nNPD0xfl2sj7aYFrg%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Data & Cloud Engineer\nfifty-five est une data-company d'un genre nouveau qui aide les marques \u00e0 exploiter les donn\u00e9es pour am\u00e9liorer le marketing, les m\u00e9dias et l'exp\u00e9rience client gr\u00e2ce \u00e0 une combinaison de services de conseil et de technologie sp\u00e9cialis\u00e9s.\nEn tant que pilier data et marketing du Brandtech Group, nous offrons des services qui combinent le conseil en strat\u00e9gie, les services de cloud, le conseil en m\u00e9dia et l'exp\u00e9rience client.\nfifty-five, c'est plus de 400 experts du num\u00e9rique. Des digital consultants, des sp\u00e9cialistes du tracking et du m\u00e9dia, des ing\u00e9nieurs et des data scientists, travaillent tous en \u00e9troite collaboration pour fournir des conseils marketing de haut niveau et une assistance technique aux marques, dans tout type d'industrie, partout dans le monde.\nPartenaire des annonceurs de la collecte \u00e0 l'activation et l'exploitation des donn\u00e9es, nous aidons les organisations \u00e0 devenir de v\u00e9ritables entit\u00e9s omnicanales ma\u00eetrisant l'efficacit\u00e9 de leur \u00e9cosyst\u00e8me digital et ses synergies avec le monde physique.\nBas\u00e9 \u00e0 Paris, nous op\u00e9rons sur 3 fuseaux horaires depuis nos 10 bureaux, situ\u00e9s \u00e0 Paris, Londres, Gen\u00e8ve, Milan, Shanghai, Hong Kong, Shenzhen, Taipei, Singapour et New York. fifty-five attache une importance particuli\u00e8re au bien-\u00eatre de ses collaborateurs, ce qui lui a permis de figurer dans le classement Best Workplaces France en 2018.\nContexte :\nL'\u00e9quipe d'ing\u00e9nierie d\u00e9veloppe et met en \u0153uvre les solutions techniques permettant la r\u00e9alisation de pipelines de donn\u00e9es et l'impl\u00e9mentation de data platform pour nos clients : r\u00e9cup\u00e9ration de datas sur de multiples sources de donn\u00e9es (APIs, files, etc.), data cleaning, data processing, automation et monitoring de l'ensemble. L'\u00e9quipe s'appuie sur des technologies r\u00e9centes (docker, kubernetes, terraform, notebooks, etc.) et met en place ses projets dans les diff\u00e9rents clouds du march\u00e9 (GCP, Azure, AWS...).\nMission :\nNous sommes \u00e0 la recherche d'une personne capable de r\u00e9aliser des projets techniques pour r\u00e9pondre aux besoins de nos clients (par exemple: syst\u00e8me de recommandations de produits, d\u00e9tection d'anomalies, ranking). Les activit\u00e9s vont du chiffrage et du sizing technique \u00e0 la mise en \u0153uvre des architectures, en passant par la revue des sp\u00e9cifications fonctionnelles et la production de code. Le Data & Cloud Engineer sera \u00e9paul\u00e9 par un Lead dans ses missions. Il sera \u00e9galement amen\u00e9 \u00e0 participer \u00e0 la R&D et \u00e0 accompagner les \u00e9quipes transverses dans la mise en place d'outils de travail internes (librairies pour les data scientists, environnement Notebooks pour les data analysts et data scientists, d\u00e9veloppement de frameworks sur diff\u00e9rents cloud providers, etc.).\nNous souhaitons trouver la bonne personne pour faire \u00e9voluer ou cr\u00e9er de nouvelles solutions dans ce cadre. Les missions comprennent aussi bien du prototypage rapide pour des d\u00e9monstrateurs, que de la production de code robuste qui tourne en production tous les jours.\nComp\u00e9tences et exp\u00e9riences :\n2 ans d'exp\u00e9rience en tant que Data Engineer\nMa\u00eetrise de Python, SQL\nMa\u00eetrise des environnements Cloud. Id\u00e9alement certifi\u00e9 GCP, Azure ou AWS\nBonne connaissance de Docker/Kubernetes\nBonne connaissance d'au moins un data warehouse (BigQuery, Snowflake, etc)\nConnaissance autour des Notebooks (Jupyter)\nA l'aise avec des concepts li\u00e9s aux APIs (OAuth, REST, etc.)\nA l'aise avec les notions d'Infrastructure as Code (Terraform)\nAu courant des pratiques GitOps et connaissances des concepts autour du CI/CD\nLa ma\u00eetrise d'un orchestrateur, comme Apache Airflow, est un plus\nEsprit d'\u00e9quipe (collaborer aux tests unitaires, revue de code, partage de code, sprints)\nBon niveau en fran\u00e7ais et en anglais\nA d\u00e9j\u00e0 travaill\u00e9 en mode projet avec des interlocuteurs vari\u00e9s (consultant, data analyst, data scientist)\nUne exp\u00e9rience en marketing digital est un plus\nNous proposons :\nun bureau au centre de Paris avec terrasse et jardin\nun environnement multiculturel avec des collaborateurs aux nationalit\u00e9s multiples (France, Royaume-Uni, Etats-Unis, Chine, Tunisie, Italie et plus)\ndes projets avec nos bureaux \u00e0 Londres, Hong Kong, New York, Shanghai, Gen\u00e8ve, Shenzhen et Taipei\ndes TGIF et supers soir\u00e9es\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "R"
            ],
            "DataBase": [
                "SQL"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [
                "Apache Airflow"
            ],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [
                "AWS",
                "Azure"
            ],
            "DevTools": [
                "Git",
                "Docker"
            ],
            "Os": [],
            "DBMS": [
                "Snowflake",
                "Snowflake",
                "BigQuery"
            ],
            "SoftBigDataProcessing": [],
            "Automation": [
                "Kubernetes",
                "Airflow"
            ],
            "InfrastructureAsCode": [
                "Terraform"
            ],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [
                "Docker",
                "Kubernetes"
            ],
            "Collaboration": [],
            "Other": [
                "Cloud",
                "CI/CD"
            ],
            "FrSoftSkills": [
                "Collaboration",
                "Organisation"
            ],
            "EnSoftSkils": [
                "Collaboration"
            ]
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s",
                "2",
                "2",
                "2"
            ]
        }
    },
    {	
		"source": "LinkedIn",
        "title": "Data Engineer",
        "company": "AFD Technologies",
        "location": "Lille, Hauts-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/data-engineer-at-afd-technologies-3899625641?position=36&pageNum=0&refId=b67kRduAUeEfaeVnXh9rCA%3D%3D&trackingId=0XV4X5qxaks0ljefO73%2FRA%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "AFD.TECH part of Accenture\nest le sp\u00e9cialiste du conseil en transformation digitale des grandes entreprises \ud83d\ude80.\nA ce jour, le Groupe est compos\u00e9 de 2.000 talents r\u00e9partis dans 3 pays (France, Belgique & Maroc) \ud83c\udf0e pour un chiffre d\u2019affaires annuel de 125M\u20ac !\nNos Talents d\u2019abord \ud83d\ude0e:\nLes Talents d\u2019AFD.TECH part of Accenture sont au c\u0153ur de la strat\u00e9gie du Groupe et il est primordial pour nous que chaque collaborateur trouve du sens dans son travail.\nAu-del\u00e0 de proposer une carri\u00e8re ambitieuse et personnalis\u00e9e \u00e0 nos Talents, nous avons \u00e0 c\u0153ur de leur offrir un environnement de travail flexible (remote), inclusif et \u00e9panouissant dans tous nos bureaux (Paris, Bruxelles, Rabat, Lyon, Strasbourg, Lille, Nantes, Toulouse, Marseille, Bordeaux et Rennes)\ud83c\udf0d.\nAvec 20% de croissance par an et plus de 20 ans d\u2019existence, AFD.TECH part of Accenture est devenu l\u2019acteur incontournable du march\u00e9 des infrastructures informatiques, r\u00e9seaux et t\u00e9l\u00e9coms.\nNotre proposition de valeur ? Intervenir sur l\u2019ensemble du cycle de vie de projets complexes, pour des clients grands comptes, venant de secteurs tels que la banque, le ferroviaire, les m\u00e9dias, t\u00e9l\u00e9coms, etc (comme la Soci\u00e9t\u00e9 G\u00e9n\u00e9rale, Bouygues Telecom, Orange, Thales et bien d\u2019autres encore !)\ud83d\udc69\ud83c\udffb\u200d\ud83d\udcbb.\nNous rejoindre est une formidable aventure humaine : nous vous proposons un poste un poste de\nData Engineer en CDI\n, au sein de notre agence Lilloise.\nVos missions \u2705:\nEn tant que Data Engineer pour l'un de nos clients grands comptes, votre r\u00f4le s\u2019articulera autour de diff\u00e9rents axes :\nAppr\u00e9hender le contexte et les enjeux m\u00e9tier du client.\nCollaborer avec les \u00e9quipes m\u00e9tier pour comprendre les exigences en mati\u00e8re de donn\u00e9es.\nD\u00e9finir des architectures data.\nConcevoir et mettre en place des pipelines de donn\u00e9es.\nConstruire des flux de donn\u00e9es complexes.\nVous travaillerez dans une mission \u00e0 forte valeur ajout\u00e9e et de longue dur\u00e9e (minimum 1 an et demi).\nVotre profil\u2705:\nVous ma\u00eetrisez le langage SQL, les ETL et les ELT.\nVous aimez automatiser, mettre en place vos data pipelines et ma\u00eetriser les technologies: CI/CD, Terraform, Github, Python, Kafka.\nVous poss\u00e9dez des comp\u00e9tences en data visualisation : Business Objects, Qlikview, Qlik Sense, PowerBI ou Data Studio.\nVous connaissez Google Cloud Platform (GCS, BigQuery).\nVous \u00eates dipl\u00f4m\u00e9(e) d\u2019une formation BAC + 5.\nVous avez une premi\u00e8re exp\u00e9rience significative dans la data engineering (\nminimum 3 ans\n).\nVous projetez votre carri\u00e8re dans un cabinet de conseil exigent et successful, qui vous permettra de d\u00e9velopper votre esprit entrepreneurial et de r\u00e9pondre \u00e0 vos ambitions.\nCe que nous offrons chez AFD.TECH part of Accenture \ud83e\udd17:\nUne politique de flexibilit\u00e9 dans votre organisation et un bon \u00e9quilibre de vie \ud83c\udfc3\u200d\u2642\ufe0f.\nDes avantages plus que comp\u00e9titifs \ud83d\udcb0.\nUn accompagnement et un suivi r\u00e9gulier durant tout votre parcours chez AFD.TECH (Launchpad, Linkers, rookies, etc\u2026).\nUn \u00e9tat d\u2019esprit familial et de la proximit\u00e9 entre tous \ud83d\udc68\u200d\ud83d\udc69\u200d\ud83d\udc67\u200d\ud83d\udc66.\nDes moments de convivialit\u00e9 toute l\u2019ann\u00e9e \ud83c\udf7e (\u00e9vent en \u00e9quipe, s\u00e9minaire annuel, sports collectifs etc.).\nUn parcours d\u2019\u00e9volution sur mesure \ud83d\udd3c.\nA tr\u00e8s bient\u00f4t chez AFD.TECH part of Accenture!\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "R",
                "Go"
            ],
            "DataBase": [
                "SQL"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [],
            "MachingLearning": [
                "Orange"
            ],
            "DataSerialization": [],
            "DataVisualization": [
                "PowerBI"
            ],
            "Statistics": [],
            "CloudComputing": [
                "Google Cloud Platform"
            ],
            "DevTools": [
                "Git"
            ],
            "Os": [],
            "DBMS": [
                "BigQuery"
            ],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [
                "Terraform"
            ],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [
                "Cloud",
                "CI/CD"
            ],
            "FrSoftSkills": [
                "Organisation",
                "Flexibilit\u00e9"
            ],
            "EnSoftSkils": []
        },
        "details": {
            "JobDetail": [
                "Remote"
            ],
            "TypeContract": [
                "CDI"
            ],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s",
                "20",
                "20",
                "20"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "Data engineer H/F",
        "company": "Extia",
        "location": "Paris, \u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/data-engineer-h-f-at-extia-3599188121?position=37&pageNum=0&refId=b67kRduAUeEfaeVnXh9rCA%3D%3D&trackingId=RpAHVod1lg1ca3LwgraXfw%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Vous souhaitez rejoindre une entreprise qui place l\u2019humain au c\u0153ur de ses pr\u00e9occupations ? On vous attend chez\nExtia\n!\nSoci\u00e9t\u00e9 de conseil sp\u00e9cialis\u00e9e dans les m\u00e9tiers de l\u2019IT, de l\u2019ing\u00e9nierie et du digital, Extia privil\u00e9gie depuis sa cr\u00e9ation en 2007 une approche qui allie performance et bien-\u00eatre au travail. Une vision de l\u2019entreprise partag\u00e9e aujourd\u2019hui par plus de 2 500 Extiens en France et \u00e0 l'international et r\u00e9compens\u00e9e par le label Great Place to Work\u00ae depuis 13 ans, notamment en\n2024 o\u00f9 les Extiens se hissent \u00e0 la premi\u00e8re place du palmar\u00e8s Best Workplaces France\n!\nChez Extia, c\u2019est \u00ab D\u2019abord qui, ensuite quoi \u00bb alors, allons-y !\nD'abord qui\nVous \u00eates habitu\u00e9 \u00e0 travailler aussi bien avec des m\u00e9ta-donn\u00e9es qu\u2019avec des donn\u00e9es non-structur\u00e9es. A cet effet vous maitrisez un ou plusieurs des concepts comme l\u2019ETL, le Data mining le Machine learning, les Big data ou encore la Th\u00e9orie des graphes par exemple,\nVous maitrisez les bases de l\u2019analyse statistique,\nVous \u00eates apte \u00e0 r\u00e9diger des scripts en Python et/ou R, et une connaissance d'autres langages de programmation comme Java, Scala ou SAS est un plus,\nVous maitrisez Spark et Hadoop\nVous \u00eates familiaris\u00e9 avec l\u2019environnement Linux,\nUne exp\u00e9rience avec les outils de Stockage de fichiers volumineux (HDFS, Data Lake, S3, stockage Blob), la connaissance des infrastructures cloud AWS ou GCP et des bases en streaming temps r\u00e9el seront aussi de r\u00e9els atouts.\nEnsuite quoi\nVous aurez le r\u00f4le de support technique aux \u00e9quipes d\u2019analyse : structurer les donn\u00e9es, r\u00e9aliser des analyses \u00ab statistiques \u00bb ou \u00ab techniques \u00bb sur les donn\u00e9es, d\u00e9velopper des outils d\u2019analyse\u2026\nVous m\u00e8nerez des \u00e9tudes afin d\u2019\u00e9valuer les nouvelles technologies dans le domaine du Big Data, Data Mining ou Machine Learning afin d\u2019identifier les solutions les plus pertinentes.\nVous serez en charge de :\nParticiper \u00e0 la d\u00e9finition des besoins et \u00e0 la r\u00e9daction des User Stories,\nCollaborer avec les Data Scientists au d\u00e9veloppement des modules d\u2019analyse de donn\u00e9e,\nConcevoir et construire des architectures de donn\u00e9es,\nInt\u00e9grer des sources de donn\u00e9es,\nVous assurez que les donn\u00e9es sont facilement accessibles et que leur exploitation fonctionne comme demand\u00e9, m\u00eame dans des circonstances hautement \u00e9volutives,\nEx\u00e9cuter des processus ETL (extraire / transformer / charger) \u00e0 partir d'ensembles de donn\u00e9es complexes et / ou volumineux\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "Java",
                "Scala",
                "R"
            ],
            "DataBase": [],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [
                "Hadoop",
                "Spark"
            ],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [
                "Statistiques"
            ],
            "CloudComputing": [
                "AWS"
            ],
            "DevTools": [
                "Git"
            ],
            "Os": [
                "Linux"
            ],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [
                "Big Data",
                "Machine Learning",
                "Statistiques",
                "Cloud"
            ],
            "FrSoftSkills": [],
            "EnSoftSkils": []
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s",
                "13",
                "13",
                "13"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "Ing\u00e9nieur Data Spark (F/H)",
        "company": "Thales",
        "location": "V\u00e9lizy-Villacoublay, \u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/ing%C3%A9nieur-data-spark-f-h-at-thales-3890949531?position=38&pageNum=0&refId=b67kRduAUeEfaeVnXh9rCA%3D%3D&trackingId=LyzjWq%2FfgvJpebjvBp057g%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "QUI SOMMES-NOUS ?\nThales est un leader mondial des hautes technologies comptant plus de 81 000 collaborateurs pr\u00e9sents sur tous les continents. Le Groupe investit dans les innovations du num\u00e9rique et de la \u00ab deep tech \u00bb \u2013 big data, intelligence artificielle, connectivit\u00e9, cybers\u00e9curit\u00e9 et quantique \u2013 pour construire un avenir de confiance, essentiel au d\u00e9veloppement de nos soci\u00e9t\u00e9s, en pla\u00e7ant l\u2019humain au c\u0153ur des d\u00e9cisions.\nThales propose des solutions, services et produits qui aident ses clients \u2013 entreprises, organisations, Etats \u2013 dans cinq grands march\u00e9s vitaux pour le fonctionnement de nos soci\u00e9t\u00e9s : identit\u00e9 et s\u00e9curit\u00e9 num\u00e9riques, d\u00e9fense, a\u00e9ronautique, espace, et transport.\nQUI ETES-VOUS ?\nDipl\u00f4m\u00e9 d\u2019un Bac+5 en \u00e9cole d\u2019ing\u00e9nieur ou \u00e9quivalent universitaire avec une sp\u00e9cialisation en informatique, vous avez au moins 3 ans d'exp\u00e9rience dans les technologies Big Data.\nCE QUE NOUS POUVONS ACCOMPLIR ENSEMBLE :\nEn tant que Data Engineer, vous jouerez un r\u00f4le cl\u00e9 dans la conception, le d\u00e9veloppement et la maintenance de notre infrastructure de donn\u00e9es, ainsi que dans la transformation et la gestion des flux de donn\u00e9es.\nVOS MISSIONS :\n\u2022 Concevoir, d\u00e9velopper et d\u00e9ployer des solutions Big Data en utilisant les technologies Spark.\n\u2022 Mettre en place des pipelines de donn\u00e9es performants pour l'ingestion, le traitement et le stockage des donn\u00e9es massives.\n\u2022 Collaborer \u00e9troitement avec les \u00e9quipes m\u00e9tier pour comprendre leurs besoins en mati\u00e8re d'analyse de donn\u00e9es et proposer des solutions adapt\u00e9es.\n\u2022 Optimiser les performances des clusters Hadoop pour garantir une exploitation efficace des donn\u00e9es.\n\u2022 Assurer la qualit\u00e9 et la fiabilit\u00e9 des donn\u00e9es trait\u00e9es, en mettant en place des processus de validation et de nettoyage.\n\u2022 Identifier et r\u00e9soudre les probl\u00e8mes li\u00e9s \u00e0 l'infrastructure Big Data et proposer des am\u00e9liorations.\n\u2022 Travailler en \u00e9troite collaboration avec les Data Scientists et les Data Analysts pour fournir des insights pertinents \u00e0 partir des donn\u00e9es.\nInnovation, passion, ambition : rejoignez Thales et cr\u00e9ez le monde de demain, d\u00e8s aujourd\u2019hui.\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "R"
            ],
            "DataBase": [],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [
                "Hadoop",
                "Spark"
            ],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [],
            "DevTools": [],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [
                "Big Data"
            ],
            "FrSoftSkills": [
                "Collaboration",
                "Organisation"
            ],
            "EnSoftSkils": [
                "Collaboration"
            ]
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [],
            "Salary": [],
            "Level": [
                "Bac+5"
            ],
            "Experience": [
                "a",
                "n",
                "s",
                "3",
                "3",
                "3"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "Alternance - Data Engineer H/F",
        "company": "Herm\u00e8s",
        "location": "Paris, \u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/alternance-data-engineer-h-f-at-herm%C3%A8s-3889716412?position=39&pageNum=0&refId=b67kRduAUeEfaeVnXh9rCA%3D%3D&trackingId=5VSk5nClTgZjL1xgLiAxew%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "El\u00e9ments de contexte\nHerm\u00e8s Digital Ventes et Services recherche pour sa direction Data & Performance :\nUn Alternant Data Engineer (H/F)\nContrat d'alternance de 12 mois\nA partir de Septembre 2024\nBas\u00e9 \u00e0 Paris\nPrincipales activit\u00e9s\nVous \u00eates rattach\u00e9 au Data manager.\nVous avez pour principale mission d\u2019accompagner l\u2019\u00e9quipe Data dans les t\u00e2ches quotidiennes :\nReporting et statistiques de ventes et trafic (notamment via l\u2019outil Google Analytics et Google BigQuery)\nAnalyse des leviers d\u2019acquisition de traffic SEA/SEO/Referral\nCr\u00e9ation de Dashboard via l\u2019outil Google Data Studio\nParticipation aux travaux de CRO (Conversion Rate Optimization) et d\u2019AB testing\nMise en place d\u2019\u00e9tude pr\u00e9dictive sur les donn\u00e9es des sites Ecommerce\nProfil\nEtudiant en \u00e9cole d\u2019ing\u00e9nieur poss\u00e9dant une forte culture Internet et une sensibilit\u00e9 aux probl\u00e9matiques digitales e-commerce, vous avez une premi\u00e8re exp\u00e9rience en entreprise\nProfil technique ou ais\u00e9 avec la technique, une sp\u00e9cialisation en digital est en plus\nOrganis\u00e9, rigoureux, curieux, autonome, bonne expression \u00e9crite et aisance relationnelle\nMa\u00eetrise du Pack Office indispensable, ayant d\u00e9j\u00e0 utilis\u00e9 Google Analytics\nLa connaissance d\u2019outils de BI / Datavisualisation serait appr\u00e9ci\u00e9e (Google Data Studio, Tableau Software, Bime ou QlikView/QlikSense, PowerBI), de Base de Donn\u00e9es (SQL, MySQL, BigQuery)\nUne app\u00e9tence pour la Data, ses languages (Python, R) et ses technologies (Notebooks, mod\u00e9lisation statistique, Machine learning) est fortement appr\u00e9ci\u00e9e.\nAnglais courant souhait\u00e9\nSensible aux produits hauts de gamme, vous souhaitez vous investir dans un stage riche et formateur\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "R",
                "Go"
            ],
            "DataBase": [
                "SQL"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [
                "Tableau",
                "PowerBI"
            ],
            "Statistics": [
                "Statistiques"
            ],
            "CloudComputing": [],
            "DevTools": [
                "Git"
            ],
            "Os": [],
            "DBMS": [
                "MySQL",
                "BigQuery"
            ],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [
                "Machine Learning",
                "Statistiques"
            ],
            "FrSoftSkills": [],
            "EnSoftSkils": []
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "Data Engineer",
        "company": "Coders Connect",
        "location": "Paris, \u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/data-engineer-at-coders-connect-3870419202?position=40&pageNum=0&refId=b67kRduAUeEfaeVnXh9rCA%3D%3D&trackingId=va%2BZHBT8a5zkOnTMbPoLOQ%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Coders Connect and Sanofi are joining forces to bring an electrifying twist to the biopharmaceutical world!\nWork with a rhythm that suits your style (2 days remote and 3 days onsite magic).\nLanguage\n: Proficiency in English is required for this role to ensure effective communication within our diverse, global team.\nAbout Sanofi:\nWe're not just a company; we're a global movement, focused on human health and making a real difference. Our mission? To battle pain, ease suffering, and sprinkle a little bit of magic in the process by developing life-changing medicines and vaccines through breakthrough science and wizard-level technology.\nDigital & Data: The Pulse of Our Mission\nAt the heart of our quest lies our digital and data powerhouse. Think of us as the digital healthcare platform of your dreams, where innovation meets speed, and technology shakes hands with medicine. With our scale, deep-rooted connections in health ecosystems worldwide, and a knack for pushing boundaries, we're here to revolutionise medicine, one digital solution at a time.\nThe Role: Data Engineering Virtuoso\nAs our Data Engineering Virtuoso, you're tasked with designing and orchestrating the data pipelines that power our ambitious data analytics initiatives. You'll ensure our data's integrity and accessibility, laying the groundwork for groundbreaking insights and innovations.\nRequirements\nCloud Platforms: Proficient in AWS services, with Azure & GCP knowledge a plus. Your work involves leveraging cloud solutions for scalable data processing and storage.\nData Modeling & Query Performance: Expertise in crafting data models and optimizing SQL queries to enhance performance. Experience with Snowflake or similar data warehousing solutions is highly valued.\nIntegration Services: Skilled in utilizing Integration Services like IICS and Tibco, you facilitate seamless data flow and integration across various platforms.\nScripting & Development: Proficient in scripting languages such as Python and R, enabling you to automate tasks and manipulate data efficiently. Familiarity with GitHub for source code management underscores your commitment to collaborative development and version control.\nVisualization & Reporting: Knowledgeable in creating insightful data visualizations using tools like PowerBI, Tableau, or similar, turning complex data into actionable insights.\nData Governance & Compliance: A keen understanding of data quality, security, and governance standards, especially in healthcare environments subject to regulations like GxP, SOX, and data privacy laws.\nReal World Data & Standard Models: Experience with Real World Data (e.g., EHR, Claims) and familiarity with standard data models (e.g., OMOP, FHIR) enhance your ability to contribute to our healthcare objectives.\nPipeline Frameworks: Proficiency in using frameworks like Apache Airflow or Kedro for crafting efficient, reliable data pipelines that support our AI and ML initiatives.\nThe Reward:\nA chance to play a crucial role in a collaboration that's redefining healthcare through digital transformation.\nA seat at the round table of diversity and inclusion, where different backgrounds and experiences conjure the richness of our culture.\nAn endless horizon of professional growth, learning opportunities, and the chance to contribute to a future where better health is a global reality.\nThe Call to Adventure:\nIf you're ready to join a quest for better \u2013 better treatments, better outcomes, and better science \u2013 and believe in the magic of bringing diverse talents together to make miracles happen, we want you. Let's embark on this journey together and transform the future of healthcare.\nBetter is out there. Are you ready to find it with us?\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "Scala",
                "R",
                "Go"
            ],
            "DataBase": [
                "SQL"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [
                "Apache Airflow"
            ],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [
                "Tableau",
                "PowerBI"
            ],
            "Statistics": [],
            "CloudComputing": [
                "AWS",
                "Azure"
            ],
            "DevTools": [
                "Git"
            ],
            "Os": [],
            "DBMS": [
                "Snowflake",
                "Snowflake"
            ],
            "SoftBigDataProcessing": [],
            "Automation": [
                "Airflow"
            ],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [
                "ML",
                "Cloud"
            ],
            "FrSoftSkills": [
                "Communication",
                "Collaboration"
            ],
            "EnSoftSkils": [
                "Communication",
                "Collaboration",
                "Initiative"
            ]
        },
        "details": {
            "JobDetail": [
                "Remote"
            ],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "Data Engineer (H/F)",
        "company": "Epsilon France",
        "location": "Paris, \u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/data-engineer-h-f-at-epsilon-france-3912808369?position=41&pageNum=0&refId=b67kRduAUeEfaeVnXh9rCA%3D%3D&trackingId=%2F%2F3ZhY4YKHf7xPyoxJs8AA%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Cette offre d\u2019emploi est fournie par P\u00f4le emploi\nDescription\nDans le cadre du d\u00e9veloppement de notre p\u00f4le Data & IA (cadrage fonctionnel et technique, d\u00e9finition de use-cases, strat\u00e9gie des moyens, accompagnement du changement, mise en \u0153uvre, maintenance et commercialisation de solutions), nous recherchons un(e) Data Engineer qui aura pour missions : - D\u00e9livrer des projets Data Lake / Big Data (ingestion de sources, pipeline de traitements de donn\u00e9es, mod\u00e9lisation, tests, d\u00e9ploiements) dans un contexte de plus en plus DevOps, - Comprendre les besoins des \u00e9quipes digitales, principalement associ\u00e9es aux projets Data Science et leurs technologies / outils (Jupyter, Zeppelin, R, Python, .), - \u00catre capable de faire le lien avec les contraintes techniques (IT, s\u00e9curit\u00e9, acc\u00e8s, outils) d'une DSI, - Assurer la veille technologique sur les composants d'une plateforme Datalake, Cloud - Maintenir les environnements techniques et partager ses connaissances (capitalisation, s\u00e9minaires, formations, KM en ligne), - R\u00e9diger des documents projets (design, r\u00e9alisation, d\u00e9ploiement, .), - G\u00e9rer l'\u00e9volution des solutions propos\u00e9es, et possiblement en assurer la TMA. Qualifications Inscrit en Master 2 informatique ou dans un domaine technique connexe au titre des ann\u00e9es universitaire 2022-2025, Admis dans le cursus d'un CFA (universit\u00e9 ou \u00e9cole d'ing\u00e9nieur), Capacit\u00e9 d'apprendre, de comprendre et de travailler avec des nouvelles technologies, m\u00e9thodologies et des solutions \u00e9mergentes dans l'environnement technologique d'ing\u00e9nierie cloud/donn\u00e9es, Excellentes comp\u00e9tences en communication, organisation, avec une attitude proactive et positive, Passion pour les nouvelles technologies et engagement \u00e0 acqu\u00e9rir de nouvelles comp\u00e9tences. Informations suppl\u00e9mentaires CHOISISSEZ. - Notre expertise reconnue dans le domaine du d\u00e9cisionnel et du Big Data depuis 30 ans, un cadre m\u00e9thodologique et une organisation des comp\u00e9tences anim\u00e9es constamment dans un souci de veille et de progression, - Nos projets innovants et nos missions de conseil en cours de r\u00e9alisation ou r\u00e9alis\u00e9s autour des solutions BI, Big Data et DMP, - Notre diversit\u00e9 de projets et de clients (SNCF, Groupe BPCE, Fnac, La Banque Postale.), - Notre management de proximit\u00e9 et notre souci de d\u00e9veloppement des comp\u00e9tences. Localisation : Paris 11e (Bastille) Contrat : POEI avec l'ecole Simplon et le programme Skills Les + EPSILON France : - Acc\u00e8s Restaurant d'Entreprise (Campus Bastille) - Travail Hybride gr\u00e2ce \u00e0 notre Accord T\u00e9l\u00e9travail qui autorise jusqu'\u00e0 2 jours par semaine - Engag\u00e9 avec le Forfait Mobilit\u00e9 Durable - Dispositif d'Epargne Salariale (Accord d'int\u00e9ressement et de participation)\nPROFIL SOUHAIT\u00c9\nExp\u00e9rience\nD\u00e9butant accept\u00e9\nSavoir-\u00eatre professionnels\nFaire preuve de rigueur et de pr\u00e9cision\nFaire preuve de r\u00e9activit\u00e9\n\u00catre \u00e0 l'\u00e9coute, faire preuve d'empathie\nLangue\nAnglais\nSource: Pole emploi (https://www.pole-emploi.fr)\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "R"
            ],
            "DataBase": [],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [],
            "DevTools": [
                "Git"
            ],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [
                "DevOps",
                "Big Data",
                "Cloud"
            ],
            "FrSoftSkills": [
                "Communication",
                "Empathie",
                "Organisation"
            ],
            "EnSoftSkils": [
                "Communication"
            ]
        },
        "details": {
            "JobDetail": [
                "Hybride"
            ],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s",
                "30",
                "30",
                "30"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "Data Engineer",
        "company": "Airswift",
        "location": "Paris, \u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/data-engineer-at-airswift-3909165766?position=42&pageNum=0&refId=b67kRduAUeEfaeVnXh9rCA%3D%3D&trackingId=6otrrgAHMn%2B2bPRXEycTZg%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Data Engineer\nLocation\n: Paris (Hybrid)\nContract type\n: 12 months +\nYears of Experience\n: 4+\nRecruitment Partner:\nAirswift\nKey Words:\nProject Management | Jira | Digiboard | Banking | Stakeholder Management | Architecture | Cloud | Payments/Credit |ServiceNow | PPM |\nResponsibilities\nDesign, develop, and implement data pipelines to collect, process, and store structured and unstructured data from various sources.\nCollaborate with data scientists, analysts, and other stakeholders to understand data requirements and translate them into technical solutions.\nOptimize and tune data pipelines for performance, scalability, and reliability.\nEnsure data quality and integrity throughout the data lifecycle, implementing data validation and monitoring processes.\nEvaluate and implement new tools and technologies to enhance our data infrastructure and capabilities.\nRequirements\n:\nExtensive experience in Python.\nStrong experience with data processing frameworks and tools such as Apache Spark.\nExperience with cloud platforms such as AWS, Azure, or Google Cloud Platform.\nSolid understanding of data modelling, database design, and SQL\nFrench and English speaking\nFreelancing opportunity\nThe next step\nWe have an exceptional team in place, and we are pleased to be able to appoint a further person to our growing business. We are aware that you may not \u2018tick all the boxes\u2019, but if you believe you can genuinely offer some valuable skills and experience to our business, please in the first instance contact our recruitment partner Airswift.\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "Scala",
                "R",
                "Go"
            ],
            "DataBase": [
                "SQL"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [
                "Spark"
            ],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [
                "AWS",
                "Azure",
                "Google Cloud Platform"
            ],
            "DevTools": [],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [
                "JIRA"
            ],
            "Other": [
                "Cloud"
            ],
            "FrSoftSkills": [],
            "EnSoftSkils": []
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "Data Engineer \u2013 Antibes, France (H/F)",
        "company": "Astek",
        "location": "Antibes, Provence-Alpes-C\u00f4te d'Azur, France",
        "link": "https://fr.linkedin.com/jobs/view/data-engineer-%E2%80%93-antibes-france-h-f-at-astek-3909192086?position=43&pageNum=0&refId=b67kRduAUeEfaeVnXh9rCA%3D%3D&trackingId=BxG7YTWicXtd5pO8ytQ3Sg%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "CDI\nAntibes - France\nPubli\u00e9e il y a 2 semaines\nLe Groupe Astek\nCe Que Nous Allons Accomplir Ensemble :\nIntervenir dans la conception, le d\u00e9veloppement, les tests unitaires, la qualification, l\u2019int\u00e9gration continue et la mise en production d\u2019\u00e9volutions sur les projets du p\u00f4le produits scoring (un p\u00f4le visant \u00e0 d\u00e9velopper des solutions permettant de g\u00e9n\u00e9rer des scores ou des segments d\u2019information pertinents dans divers domaines, notamment : profiling TV, PUB, SAB, MMDM, Voscastview) chez l\u2019un de nos partenaires sp\u00e9cialis\u00e9 dans le secteur des t\u00e9l\u00e9coms.\nVotre Mission, Si Vous L\u2019acceptez :\nEn collaboration avec les autres membres de l\u2019\u00e9quipe, vous devrez prendre en charge le RUN des applications du p\u00f4le produit scoring.\nConception d\u2019une solution se basant sur les d\u00e9veloppements existants et les besoins m\u00e9tiers remont\u00e9s par le Product Owner.\nR\u00e9alisation et d\u00e9veloppement de nouvelles fonctionnalit\u00e9s sur les composants des applications du p\u00f4le produits scoring et environnement CGP.\nVotre Future \u00c9quipe :\nAu sein d\u2019un environnement riche et complexe, vous \u00e9voluerez avec des experts passionn\u00e9s \u00e0 la fois techniques et fonctionnels (Ing\u00e9nieurs sp\u00e9cialis\u00e9s, chef de projet, scrum master, product owner, analystes \u2026).\nVotre stack de jeu\nD ans un environnement SAFE sous cloud GCP, Big Query, OnPrime, Grafana, Python et Ansible.\nVous ?\nDe formation Ing\u00e9nieur, vous justifiez d\u2019une premi\u00e8re exp\u00e9rience sur un poste de Data engineer. Vous poss\u00e9dez des comp\u00e9tences d\u2019autonomie et d\u2019adaptabilit\u00e9 et vous avez une capacit\u00e9 \u00e0 communiquer efficacement au sein d\u2019une \u00e9quipe.\nLe Groupe Astek\nCr\u00e9\u00e9 en France en 1988, Astek est un acteur mondial de l\u2019ing\u00e9nierie et du conseil en technologies. Fort de son expertise dans de nombreux secteurs industriels et tertiaires, Astek accompagne ses clients internationaux dans le d\u00e9ploiement intelligent de leurs produits et de leurs services, et dans la mise en \u0153uvre de leur transformation digitale.\nDepuis sa cr\u00e9ation, le Groupe a fond\u00e9 son d\u00e9veloppement sur une forte culture d\u2019entrepreneuriat et d\u2019innovation, et sur l\u2019accompagnement et la mont\u00e9e en comp\u00e9tence de\nses 7800 collaborateurs\nqui s\u2019engagent chaque jour \u00e0 promouvoir la compl\u00e9mentarit\u00e9 entre les technologies num\u00e9riques et l\u2019ing\u00e9nierie des syst\u00e8mes complexes.\nRejoignez un Groupe en fort d\u00e9veloppement en France et \u00e0 travers le monde ayant r\u00e9alis\u00e9 un chiffre d\u2019affaires de 600 M\u20ac en 2023.\nTous les d\u00e9tails sur le Groupe sur le site https://astekgroup.fr. Et vous pouvez aussi nous suivre sur notre blog : https://blog.groupeastek.com.\nRencontrons-nous\nCr\u00e9\u00e9 en France en 1988, Astek est un acteur mondial de l\u2019ing\u00e9nierie et du conseil en technologies, pr\u00e9sent sur les 5 continents. Fort de son expertise dans de nombreux secteurs industriels et tertiaires, Astek accompagne ses clients internationaux dans le d\u00e9ploiement intelligent de leurs produits et de leurs services, et dans la mise en \u0153uvre de leur transformation digitale.\nDepuis sa cr\u00e9ation, le Groupe a fond\u00e9 son d\u00e9veloppement sur une forte culture d\u2019entrepreneuriat et d\u2019innovation, et sur l\u2019accompagnement et la mont\u00e9e en comp\u00e9tence de ses 7800 collaborateurs qui s\u2019engagent chaque jour \u00e0 promouvoir la compl\u00e9mentarit\u00e9 entre les technologies num\u00e9riques et l\u2019ing\u00e9nierie des syst\u00e8mes complexes.\nRejoignez un Groupe en fort d\u00e9veloppement en France et \u00e0 travers le monde et ayant r\u00e9alis\u00e9 un chiffre d\u2019affaires hors\nacquisitions de 600M\u20ac en 2023.\nTous les d\u00e9tails sur le Groupe sur le site\nNos Plus\nAstek est green et fait b\u00e9n\u00e9ficier ses salari\u00e9s d\u2019une indemnit\u00e9 kilom\u00e9trique v\u00e9lo\nUne politique CARE sur-mesure d\u00e9ploy\u00e9e par nos \u00e9quipes RH pour nos collaborateurs (https://astekgroup.fr/engagements)\nNotre charte de la Diversit\u00e9\nMots-cl\u00e9s :\ning\u00e9nieur \u2013 ing\u00e9nieure \u2013 consultant \u2013 consultante \u2013 Data engineer \u2013 Big Data\nCaract\u00e9ristiques de l'emploi\nCat\u00e9gorie Ing\u00e9nieur\nJob Industry T\u00e9l\u00e9com / M\u00e9dia\nPostuler en ligne\nNom *\nPr\u00e9nom *\nEmail *\nUn email valide est requis.\nT\u00e9l\u00e9phone *\nUn num\u00e9ro de t\u00e9l\u00e9phone valide est requis.\nJoindre un CV *\nMots-cl\u00e9s :\ning\u00e9nieur \u2013 ing\u00e9nieure \u2013 consultant \u2013 consultante \u2013 Data engineer \u2013 Big Data\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "R",
                "Go"
            ],
            "DataBase": [],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [],
            "DevTools": [
                "Git"
            ],
            "Os": [],
            "DBMS": [
                "Big Query"
            ],
            "SoftBigDataProcessing": [],
            "Automation": [
                "Ansible",
                "Chef"
            ],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [
                "Big Data",
                "Cloud"
            ],
            "FrSoftSkills": [
                "Adaptabilit\u00e9",
                "Collaboration"
            ],
            "EnSoftSkils": [
                "Collaboration"
            ]
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [
                "CDI"
            ],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "Data Engineer (H/F)",
        "company": "Web Transition",
        "location": "Lille, Hauts-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/data-engineer-h-f-at-web-transition-3909147172?position=44&pageNum=0&refId=b67kRduAUeEfaeVnXh9rCA%3D%3D&trackingId=4zF8cj0%2Bo0yeJlbJeYrhvA%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Web Transition, c\u2019est qui ?\nFond\u00e9e en 2011,\nWeb transition\nest une entreprise de services num\u00e9riques op\u00e9rant sur le march\u00e9 de l\u2019IT/Digital !\nConstituant une part essentielle de\nMoOngy Digital Lab\n, Web Transition accompagne ses clients grands comptes sur leurs projets de Webmarketing, de Design, Gestion de projet et \u00e9galement en Data !\nNotre objectif : nous implanter comme un acteur principal sur le march\u00e9 de la Transformation Digitale en accompagnant et valorisant les comp\u00e9tences de nos collaborateurs !\nNous sommes convaincus que le succ\u00e8s de MoOngy Digital Lab r\u00e9side dans la somme des potentiels de nos \u00e9quipes \ud83e\udd1d\nTon \u00e9quipe : La tribu Data\nParce qu\u2019il est indispensable que tu puisses partager tes connaissances mais aussi en acqu\u00e9rir de nouvelles, tu feras partie de l\u2019une de nos tribus : celle de la Data. De plus, cela te permettra d\u2019\u00eatre acteur dans le d\u00e9veloppement et la strat\u00e9gie de Web Transition. Ce syst\u00e8me de co-r\u00e9flexion et co-construction est un fondement essentiel chez nous !\nDans cette aventure, tu :\nT\u2019assures\nde la ma\u00eetrise de la donn\u00e9e et est garant de la qualit\u00e9 de son utilisation (r\u00e9f\u00e9rencement, normalisation, et qualification)\nTravailles\n\u00e0 la compr\u00e9hension et l'int\u00e9gration des donn\u00e9es en provenance des diff\u00e9rents formats\ndes interfaces de flux\n\u00e9galement \u00e0 la d\u00e9finition de la politique de la donn\u00e9e et \u00e0 la structuration de son cycle de vie dans le respect des r\u00e9glementations en vigueur\nla supervision et l'int\u00e9gration des donn\u00e9es de diverse nature qui proviennent de ces sources multiples et v\u00e9rifie la qualit\u00e9 des donn\u00e9es qui entrent dans le Data Lake\nGarantis\nl'acc\u00e8s qualitatif aux sources de donn\u00e9es\nFacilites\nl\u2019acc\u00e8s aux donn\u00e9es pour tes coll\u00e8gues (data scientists, data analysts\u2026)\nAssistes\nles autres \u00e9quipes dans l'acc\u00e8s et la compr\u00e9hension des donn\u00e9es des socles.\nRejoins-nous si tu as :\nExp\u00e9rience d\u2019au-moins 4 ans dans la Data\nApp\u00e9tence \u00e0 la qualit\u00e9 des donn\u00e9es.\nConnaissance famili\u00e8re des Datawarehouses.\nMaitrise de Python, Oracle SQL, GCP/Power BI\nAisance avec les indicateurs, tu as une bonne capacit\u00e9 d'analyse et de r\u00e9daction.\nTon savoir-\u00eatre :\nOuvert d\u2019esprit\nRigoureux\nAutonome\nRespectueux des diff\u00e9rences de chacun\nCurieux\nProactif\nAgile\nPar o\u00f9 on commence ?\nUn premier entretien RH d\u20191h pour comprendre ton parcours et tes aspirations\nUn second entretien de 45 minutes avec l\u2019un de nos Business Manager afin de valider tes comp\u00e9tences et qu\u2019il se projette sur l\u2019une des missions qu\u2019il pourrait te proposer\nUn troisi\u00e8me entretien de quelques minutes avec notre responsable d\u2019agence pour te proposer d\u2019int\u00e9grer notre superbe Team Web !\n3 entretiens en peu de temps, si ton profil correspond tu int\u00e8greras tr\u00e8s vite nos \u00e9quipes \ud83d\ude09\nPr\u00eat pour embarquer dans notre grande aventure humaine ? Deviens notre futur Weber en postulant \u00e0 cette offre ! Voici les avantages qui t\u2019attendent en tant que Weber :\n\ud83e\udd29 Des coll\u00e8gues incroyables\n\ud83c\udfc6 Certifi\u00e9e Great Place to Work\n\ud83c\udfae Des bureaux sympas (o\u00f9 vous serez toujours les bienvenus)\n\ud83c\udf89 Des teambuilding et \u00e9vents tous les mois\n\ud83d\udcbb Des tributs m\u00e9tiers pour \u00e9changer entre Weber du m\u00eame m\u00e9tier\nDes missions chez le client qui sont accompagn\u00e9es et coach\u00e9es par ton manager\nUn accompagnement dans ton plan de carri\u00e8re et tes envies de re skilling\n\ud83e\udd13 Un catalogue de formations certifiantes ouvert \u00e0 tous les salari\u00e9s\n\ud83c\udf7d\ufe0f Une carte tickets restaurant MyEdenred\n\u2764\ufe0f Une mutuelle GrasSavoye\n\ud83d\ude8e Une prise en charge des frais de transport \u00e0 100%\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "R",
                "Go"
            ],
            "DataBase": [
                "SQL"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [
                "Power BI"
            ],
            "Statistics": [],
            "CloudComputing": [],
            "DevTools": [
                "Git"
            ],
            "Os": [],
            "DBMS": [
                "Oracle"
            ],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [],
            "FrSoftSkills": [],
            "EnSoftSkils": []
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s",
                "4",
                "4",
                "4"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "Data engineer H/F",
        "company": "Akkodis",
        "location": "Greater Lille Metropolitan Area",
        "link": "https://fr.linkedin.com/jobs/view/data-engineer-h-f-at-akkodis-3890779946?position=45&pageNum=0&refId=b67kRduAUeEfaeVnXh9rCA%3D%3D&trackingId=vC%2BhZztWd%2B8k1rfzefcAEw%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "La ligne de service Consulting & Solutions d\u2019Akkodis France renforce ses \u00e9quipes en r\u00e9gion Hauts-de-France et recrute un\nData engineer H/F\nen\nCDI\nsur la\nm\u00e9tropole lilloise\n:\nDescription de la mission :\nConcevoir, mettre en oeuvre et maintenir des pipelines de donn\u00e9es efficaces et \u00e9volutifs dans un environnement cloud (comme AWS, Azure, Google Cloud Platform\u2026)\nAssurer la qualit\u00e9 des donn\u00e9es et des mod\u00e8les\nD\u00e9finir les bonnes pratiques de d\u00e9veloppement en impl\u00e9mentant des outils de CI/CD\nAssurer une veille technologique sur les technologies Cloud\nCapacit\u00e9 \u00e0 interagir avec des parties prenantes diverses : business analyst, architecte, m\u00e9tier\u2026\nVeiller au bon fonctionnement des pipelines en production\nProfil :\nDe formation\nBac +4/5 en informatique\nou issu d'une\n\u00e9cole d'ing\u00e9nieur\n, vous poss\u00e9dez une exp\u00e9rience de\n3 ans\nminimum en tant que data engineer ainsi que les comp\u00e9tences suivantes :\nUne bonne connaissance des \u00e9cosyst\u00e8mes li\u00e9s \u00e0 la data (Kafka, ETL, base de donn\u00e9es\u2026)\nUne premi\u00e8re exp\u00e9rience sur un cloud provider (AWS, Azure, GCP)\nUne bonne maitrise de langages de programmation tels que SQL, Python, Scala\nAkkodis accompagne ses clients dans la mondialisation de leurs projets, aussi un anglais courant est requis pour l\u2019ensemble de nos collaborateurs.\nProcessus de recrutement :\nUne charg\u00e9e de recrutement vous contacte pour \u00e9changer sur votre projet professionnel\nVous \u00e9changez ensuite avec un.e manager sur les aspects techniques, les projets\nChez Akkodis nous sommes convaincus que de l\u2019intelligence collective na\u00eet le succ\u00e8s. Il n\u2019existe pas qu\u2019un mod\u00e8le, nous valorisons l\u2019agilit\u00e9 et l\u2019excellence, l\u2019audace et la cr\u00e9ativit\u00e9.\nEt si nous parlions ensemble de vos ambitions pour les prochaines ann\u00e9es ?\nAkkodis est une entreprise handi-engag\u00e9e et inclusive. Tous nos postes sont ouverts aux handicaps et \u00e0 la diversit\u00e9. Tous diff\u00e9rents, tous comp\u00e9tents !\nAkkodis, est un acteur mondial de l\u2019ing\u00e9nierie et de l\u2019IT et un leader dans la smart industrie. Nous accompagnons nos clients dans leurs projets de transformation digitale via 4 lignes de service : Consulting, Solutions, Talent et Academy. Akkodis est un partenaire technologique de confiance pour ses clients \u00e0 l\u2019\u00e9chelle internationale. Nous co-cr\u00e9ons et nous imaginons des solutions de pointe pour r\u00e9pondre aux d\u00e9fis majeurs de notre soci\u00e9t\u00e9, qu'il s'agisse d'acc\u00e9l\u00e9rer la transition \u00e9nerg\u00e9tique et de d\u00e9velopper la mobilit\u00e9 verte, ou encore de construire des approches centr\u00e9es sur les utilisateurs.\nDot\u00e9s d\u2019une forte culture de l\u2019inclusion et de la diversit\u00e9, nos 50 000 experts en IT et en ing\u00e9nierie, pr\u00e9sents dans 30 pays, allient les meilleures comp\u00e9tences technologiques \u00e0 une connaissance transverse de toutes les industries pour fa\u00e7onner un futur plus durable. Nous sommes passionn\u00e9s par l\u2019id\u00e9e d\u2019inventer ensemble un avenir meilleur.\nAkkodis en France, ce sont pr\u00e8s de 9.000 experts en IT et en ing\u00e9nierie r\u00e9partis sur l'ensemble du territoire, des collaborateurs partageant des valeurs fortes d'honn\u00eatet\u00e9, de respect, d'\u00e9quit\u00e9 et d'inclusion. Notre engagement : leur permettre au quotidien d'\u00eatre eux-m\u00eames au travail, et acteurs de leur vie et de leur d\u00e9veloppement au sein d'Akkodis.\n*Akkodis est une marque commerciale sous laquelle les entit\u00e9s AKKA et Modis op\u00e8rent\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "Scala",
                "R",
                "Go"
            ],
            "DataBase": [
                "SQL"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [
                "AWS",
                "Azure",
                "Google Cloud Platform"
            ],
            "DevTools": [
                "Git"
            ],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [
                "Cloud",
                "CI/CD"
            ],
            "FrSoftSkills": [
                "Cr\u00e9ativit\u00e9"
            ],
            "EnSoftSkils": []
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [
                "CDI"
            ],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s",
                "3",
                "3",
                "3"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "Data Engineer F/H",
        "company": "Mobilize Financial Services \u2013 France",
        "location": "Noisy-le-Grand, \u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/data-engineer-f-h-at-mobilize-financial-services-%E2%80%93-france-3869637982?position=46&pageNum=0&refId=b67kRduAUeEfaeVnXh9rCA%3D%3D&trackingId=QjY4WuD6jrMpRjEyvVP3dw%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "\ud83d\ude97 En route vers Mobilize !\nA l\u2019\u00e9coute de tous nos clients, nous cr\u00e9ons des services financiers innovants pour construire une mobilit\u00e9 durable pour tous.\nRejoindre Mobilize Financial Services,\nc\u2019est d\u2019abord choisir d\u2019int\u00e9grer un groupe international\n, filiale de Renault Group, une banque de financement solide, partenaire des constructeurs Renault\u2013Nissan\u2013Mitsubishi. Nos 4 000 collaborateurs pr\u00e9sents dans 35 pays, agissent ensemble au service de nos clients.\nNous proposons \u00e0 nos clients - particuliers comme professionnels - les financements et les services les plus adapt\u00e9s pour les v\u00e9hicules neufs et d'occasion.\nNous finan\u00e7ons \u00e9galement l'activit\u00e9 des r\u00e9seaux de concessionnaires des marques de l'Alliance Renault-Nissan-Mitsubishi et nous veillons \u00e0 faciliter leur gestion au quotidien pour leur permettre de d\u00e9velopper leurs ventes et assurer leur p\u00e9rennit\u00e9 financi\u00e8re.\nNotre entreprise se \"MOBILIZE\" en faveur de la diversit\u00e9 culturelle, l'\u00e9galit\u00e9 hommes-femmes et l'int\u00e9gration de personnes en situation de Handicap. Nous favorisons un environnement de travail o\u00f9 les diff\u00e9rences individuelles sont reconnues, appr\u00e9ci\u00e9es, respect\u00e9es et valoris\u00e9es, de fa\u00e7on \u00e0 mettre \u00e0 profit les talents et les forces de chacun.\n\ud83d\ude98Prenez le volant ! Pas de routine, tous nos itin\u00e9raires sont diff\u00e9rents !\nAu sein de la DSI\n,\nvotre\nfutur m\u00e9tier consistera \u00e0 :\nAccompagner l\u2019\u00e9quipe dans la transformation du domaine d\u00e9cisionnel construit sur une architecture type DWH et le porter sur la solution GCP (Google Cloud Platform) de Mobilize FS\nParticiper \u00e0 la construction du projet de transformation vers GCP\nParticiper aux projets d\u2019\u00e9volution de notre plateforme Suite Elastic (ELK - Kibana)\nPiloter des projets en \u00e9troite collaboration avec les directions m\u00e9tier et en accord avec le TBA (Tableau de Bord des Actions).\nAssurer la gestion du budget, du planning, de la tenue des jalons et du respect des engagements sur les projets en responsabilit\u00e9\nAssurer la qualit\u00e9 et le bon fonctionnement du chargement des donn\u00e9es.\nAssurer la mise \u00e0 disposition des donn\u00e9es et des outils de reportings \u00e0 toutes les directions clientes dans le respect des contrats de service\nV\u00e9ritable tout-terrain, vous nous int\u00e9ressez !\nL\u2019esprit d\u2019\u00e9quipe et le sens du service client pour atteindre ensemble les diff\u00e9rents objectifs ambitieux et satisfaire les diff\u00e9rentes parties avec un haut niveau de qualit\u00e9.\nVous avez un bon relationnel, de l\u2019\u00e9coute et une excellente communication afin d\u2019interagir avec des interlocuteurs de diff\u00e9rents niveaux (direction technique et m\u00e9tier) et de travailler en transverse.\nLe sens de l\u2019analyse et de bonnes capacit\u00e9s d\u2019anticipation pour d\u00e9celer les probl\u00e8mes avant la naissance de ces derniers.\nForce de proposition : avec vous il n'y a pas de probl\u00e8mes, que des solutions\nVous avez un niveau d\u2019anglais vous permettant de lire et de comprendre de la documentation technique\n\ud83d\udcbb\ud83d\uddb1 Environnement technique :\nMaitrise des langages Python - SQL / NoSQL\nExp\u00e9rience significative sur Python\nExp\u00e9rience avec Git\nUne exp\u00e9rience avec les outils Nifi, Airflow et GCP (BigQuery / Cloud Function / Cloud Storage \u2026) serait un plus\nGestion de projet, maintenance, \u00e9volution, support\nApp\u00e9tence pour les sujets techniques et fonctionnels : outils de mod\u00e9lisation, exploration de donn\u00e9es, IA, machine learning\nPourquoi nous rejoindre ?\nVotre Pack confort\nest compos\u00e9 de nombreux avantages \ud83d\ude00 :\nRejoindre Mobilize Financial Services c\u2019est int\u00e9grer un grand groupe international qui offre des opportunit\u00e9s de carri\u00e8re\n.\nUn environnement de travail moderne et convivial\n: locaux agr\u00e9ables, salle de sport, terrasse, restaurant d\u2019entreprise, parking avec un CSE dynamique avec de nombreuses offres voyages, sport, famille,\nNous sommes mobilis\u00e9s pour d\u00e9velopper la qualit\u00e9 de vie au travail de nos collaborateurs en faisant \u00e9voluer nos fa\u00e7ons de travailler (m\u00e9thodes, outils, organisation du travail\u2026) et nous sommes fiers d\u2019\u00eatre certifi\u00e9s \u2b50\nGreat Place To Work \u2b50\nPossibilit\u00e9 de t\u00e9l\u00e9travailler 2 jours par semaine\nNous proposons une\nr\u00e9mun\u00e9ration selon profil + Participation + Int\u00e9ressement\nLocaux situ\u00e9s au pied du RER A \u2013 Noisy le Grand Mont d\u2019Est\n\u2757 Mobilize Financial Services d\u00e9m\u00e9nage \u2757 Les postes \u00e0 pourvoir en r\u00e9gion parisienne seront bas\u00e9s \u00e0 Boulogne Billancourt \u00e0 horizon 2026\nPour en savoir plus sur notre entreprise,\nsuivez-nous sur LinkedIn !\nLa route du recrutement ?\n\ud83d\udcde Un rapide entretien t\u00e9l\u00e9phonique,\n\ud83d\uded1\nun premier \u00e9change\navec Marie DE CARLI, Responsable du d\u00e9partement DATA\n\u21aa et un dernier virage avec Agathe GROSBOIS, Responsale des Ressources Humaines\nL\u2019\u00e9quipe Mobilize FS a h\u00e2te de vous recevoir !\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "R",
                "Go"
            ],
            "DataBase": [
                "SQL",
                "NoSQL"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [
                "Tableau"
            ],
            "Statistics": [],
            "CloudComputing": [
                "Google Cloud Platform"
            ],
            "DevTools": [
                "Git"
            ],
            "Os": [],
            "DBMS": [
                "BigQuery"
            ],
            "SoftBigDataProcessing": [],
            "Automation": [
                "Airflow"
            ],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [
                "Machine Learning",
                "Cloud"
            ],
            "FrSoftSkills": [
                "Communication",
                "Collaboration",
                "Organisation"
            ],
            "EnSoftSkils": [
                "Communication",
                "Collaboration"
            ]
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "Data Engineer (H/F)",
        "company": "MP DATA",
        "location": "Toulouse, Occitanie, France",
        "link": "https://fr.linkedin.com/jobs/view/data-engineer-h-f-at-mp-data-3908719610?position=47&pageNum=0&refId=b67kRduAUeEfaeVnXh9rCA%3D%3D&trackingId=ow485J5mRO5KVr5k5FP7Jg%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "MP DATA est une soci\u00e9t\u00e9 sp\u00e9cialis\u00e9e dans l\u2019acquisition, le traitement, et la valorisation des donn\u00e9es.\nDepuis sa cr\u00e9ation en 2015, MP DATA accompagne ses clients, majoritairement industriels, dans le management de leur performance et l\u2019exploitation de leurs donn\u00e9es.\nLes collaborateurs, tous issus de grandes \u00e9coles, incarnent au quotidien les valeurs d\u2019Excellence, de Partage et d\u2019Engagement.\nIls associent savoir-faire technique, m\u00e9thodologie et passion et mettent leurs comp\u00e9tences au service de missions et projets au sein de grands groupes fran\u00e7ais.\nMP DATA accompagne ses clients sur toute la chaine au travers de 3 p\u00f4les d\u2019expertise : Conseil et Strat\u00e9gie, Infrastructure & CloudOPS, Data Science.\nChez MP DATA, les \u00e9quipes commerciales cherchent des missions en fonction des envies des collaborateurs et non pas l\u2019inverse. Les consultants sont accompagn\u00e9s dans tous leurs projets, de la mobilit\u00e9 g\u00e9ographique, au changement de secteur d\u2019activit\u00e9 en passant par le d\u00e9veloppement de nouvelles comp\u00e9tences.\nRejoindre MP DATA, c\u2019est la garantie de travailler sur des sujets passionnants avec un cadre technique fort.\nDescriptif du poste :\nNous recherchons un Data Engineer exp\u00e9riment\u00e9 pour rejoindre notre \u00e9quipe.\nEn tant que Data Engineer, vous serez responsable de la conception, du d\u00e9veloppement et de la mise en \u0153uvre de pipelines de traitement de donn\u00e9es en temps r\u00e9el \u00e0 grande \u00e9chelle.\nVous travaillerez avec des technologies telles que Kafka, Flink, Kinesis et vous utiliserez les services du cloud AWS pour stocker et traiter les donn\u00e9es.\nVos responsabilit\u00e9s :\nUtiliser Kafka pour le traitement de flux de donn\u00e9es en temps r\u00e9el \u00e0 grande \u00e9chelle, en travaillant avec les producteurs, les consommateurs et les topics.\nMettre en \u0153uvre des pipelines de traitement de donn\u00e9es en streaming avec Flink, en appliquant des transformations complexes et en g\u00e9rant les \u00e9tats.\n\u00c9crire du code efficace et maintenable en Java / Python pour manipuler et analyser les donn\u00e9es en temps r\u00e9el.\nUtiliser Kubernetes pour d\u00e9ployer et g\u00e9rer des applications conteneuris\u00e9es \u00e0 grande \u00e9chelle, en assurant la r\u00e9silience et l\u2019\u00e9volutivit\u00e9 des services.\nUtiliser les services AWS tels que Amazon S3, AWS Lambda, Elastic Kubernetes Service (EKS), Elastic Container Service (ECS) et Elastic Compute Cloud (EC2) pour le stockage, le traitement et le calcul des donn\u00e9es en temps r\u00e9el.\nSuivre les meilleures pratiques pour une utilisation efficace du cloud, en assurant la gestion des co\u00fbts, la s\u00e9curit\u00e9 des donn\u00e9es et la disponibilit\u00e9 des services.\nCollaborer avec l\u2019\u00e9quipe de d\u00e9veloppement logiciel et la gestion de projets pour assurer un flux de d\u00e9veloppement fluide et une livraison efficace des fonctionnalit\u00e9s.\nBon \u00e0 savoir :\nCDI / ASAP / Toulouse\nProfil recherch\u00e9:\nNous recherchons un candidat dipl\u00f4m\u00e9 d'une grande \u00e9cole d'Ing\u00e9nieur avec une premi\u00e8re exp\u00e9rience.\nComp\u00e9tences n\u00e9cessaires :\nExp\u00e9rience significative dans un environnement industriel en mode DevOps, avec des outils tels que CICD, gitlab, Jenkins, Sonar, Nexus, XLdeploy, Camunda, etc.\nMa\u00eetrise des langages de programmation tels que Python, Java et expertise dans l\u2019\u00e9criture et l\u2019optimisation du code SQL\nMa\u00eetrise du fran\u00e7ais et bonne maitrise de l\u2019anglais.\nCapacit\u00e9 \u00e0 travailler en \u00e9quipe et esprit d\u2019\u00e9quipe.\nLe processus de recrutement se d\u00e9roule en 3 entretiens :\nPrise de contact\n1er entretien : Pr\u00e9sentation et projet du candidat + pr\u00e9sentation MP DATA\n2\u00e8me entretien : Entretien de qualification technique\n3\u00e8me entretien : Rencontre avec les \u00e9quipes dans les locaux MP DATA + Proposition de collaboration\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "Java",
                "R"
            ],
            "DataBase": [
                "SQL"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [
                "Flink"
            ],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [
                "AWS"
            ],
            "DevTools": [
                "Git",
                "Jenkins"
            ],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [
                "Kubernetes"
            ],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [
                "Kubernetes"
            ],
            "Collaboration": [],
            "Other": [
                "DevOps",
                "Cloud"
            ],
            "FrSoftSkills": [
                "Collaboration"
            ],
            "EnSoftSkils": [
                "Collaboration"
            ]
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [
                "CDI"
            ],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "Data engineer python",
        "company": "FINAXYS",
        "location": "Paris, \u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/data-engineer-python-at-finaxys-3887107285?position=48&pageNum=0&refId=b67kRduAUeEfaeVnXh9rCA%3D%3D&trackingId=vr485KzJPECM8NQIBq1TcQ%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "LE CONTEXTE\nLeader en\nIT\n, dans les domaines Banque\n,\nFinance\net\nAssurance\n,\nFinaxys\nest un cabinet de\nconseil\ncr\u00e9\u00e9 en 2008. Nous accompagnons au quotidien les plus grandes banques du pays sur leur\ntransformation digitale\n(BNP Paribas, Soci\u00e9t\u00e9 G\u00e9n\u00e9rale, Cr\u00e9dit Agricole, Natixis, etc.)\nNos clients bancaires travaillent \u00e9galement dans des contextes Big Data sur des applications centrales rattach\u00e9es aux Datalakes.\nLES MISSIONS\nD\u00e9veloppement et traitements sur des applications Big Data (Python)\n\u00catre force de proposition sur les choix techniques les plus pertinents\nMaintenir la qualit\u00e9 des solutions, mesure de cette qualit\u00e9, alerte sur les non-conformit\u00e9s et validation des solutions d\u00e9finitives.\nAnalyser des risques li\u00e9s aux solutions envisag\u00e9es et proposition des actions de rem\u00e9diation.\nApporter des solutions IT r\u00e9pondant au mieux aux besoins du business port\u00e9 par la/le Product Owner (M\u00e9tiers/Fonctions) en cherchant toujours la maximisation de la valeur g\u00e9n\u00e9r\u00e9e\nAccompagner les \u00e9quipes dans les migrations Cloud\nENVIRONNEMENT TECHNIQUE\nPython\nPandas\nScirpting Big Data\nCulture DevOps (Jenkins, Maven, Ansible)\nPROFIL\nComp\u00e9tences Techniques et Fonctionnelles requises\nMaitrise obligatoire de l\u2019anglais\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "R"
            ],
            "DataBase": [],
            "DataAnalytics": [
                "Pandas",
                "R"
            ],
            "BigData": [],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [],
            "DevTools": [
                "Git",
                "Jenkins"
            ],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [
                "Ansible"
            ],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [
                "DevOps",
                "Big Data",
                "Cloud"
            ],
            "FrSoftSkills": [],
            "EnSoftSkils": []
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "Data engineer",
        "company": "SEVETYS",
        "location": "Paris, \u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/data-engineer-at-sevetys-3905649273?position=49&pageNum=0&refId=b67kRduAUeEfaeVnXh9rCA%3D%3D&trackingId=s9WJPofDRfEwiXXMXYrTmg%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Sevetys, premier groupe fran\u00e7ais de cliniques v\u00e9t\u00e9rinaires, est pr\u00e9sent dans toute la France avec plus de 150 \u00e9tablissements. Cr\u00e9\u00e9 en 2016, le groupe souhaite moderniser le m\u00e9tier et mettre la qualit\u00e9 des soins et la satisfaction client au c\u0153ur de son projet.\nLe projet d\u2019entreprise se caract\u00e9rise par son hyper croissance et une culture de type start-up ax\u00e9e sur le collectif, la coh\u00e9sion, et l\u2019engagement.\nFort de son succ\u00e8s, Sevetys poursuit sa structuration et recrute un / une :\nData Engineer\n\u200bLe\nData Engineer\ntravaille en \u00e9troite collaboration avec une \u00e9quipe Agile pluridisciplinaire pour construire des pipelines de donn\u00e9es de haute qualit\u00e9 permettant de mettre en \u0153uvre des solutions analytiques. Ces solutions g\u00e9n\u00e8reront des informations \u00e0 partir de nos donn\u00e9es collect\u00e9es, permettant de faire progresser les capacit\u00e9s de prise de d\u00e9cision du management de l\u2019entreprise. Ce r\u00f4le n\u00e9cessite une compr\u00e9hension approfondie de l'architecture des donn\u00e9es, de l'ing\u00e9nierie des donn\u00e9es, de l'analyse des donn\u00e9es, du reporting. Le candidat id\u00e9al est un ing\u00e9nieur en donn\u00e9es/logiciel ayant au moins une premi\u00e8re exp\u00e9rience dans la cr\u00e9ation de produits de donn\u00e9es soutenant des solutions analytiques.\nMissions :\nCon\u00e7oit, d\u00e9veloppe, optimise et maintient une architecture de donn\u00e9es et des pipelines qui respectent les objectifs de l'entreprise ;\nR\u00e9sout des probl\u00e8mes de donn\u00e9es afin de fournir des informations qui aident notre entreprise \u00e0 atteindre ses objectifs ;\nCr\u00e9e des jeux de donn\u00e9es pour les membres de l'\u00e9quipe d'analyse afin d'am\u00e9liorer leur productivit\u00e9 ;\nFavorise une culture du partage, de la r\u00e9utilisation, de la stabilit\u00e9 de la conception \u00e0 l'\u00e9chelle et de l'efficacit\u00e9 op\u00e9rationnelle des donn\u00e9es et des solutions analytiques ;\nContribue \u00e0 l'\u00e9valuation, la mise en \u0153uvre et le d\u00e9ploiement d'outils et de processus \u00e9mergents pour l'ing\u00e9nierie des donn\u00e9es analytiques afin d'am\u00e9liorer notre productivit\u00e9 en tant qu'\u00e9quipe ;\n\u00c9labore et met en \u0153uvre des plans de communication/\u00e9ducation sur les capacit\u00e9s, les normes et les processus d'ing\u00e9nierie des donn\u00e9es analytiques ;\nTravaille en partenariat avec des analystes business et des architectes de solutions pour d\u00e9velopper des architectures techniques pour les projets et initiatives strat\u00e9giques de l'entreprise.\nExpertises techniques :\nExp\u00e9rience du d\u00e9veloppement de bases de donn\u00e9es et d'une vari\u00e9t\u00e9 de technologies de bases de donn\u00e9es relationnelles ;\nExp\u00e9rience des entrep\u00f4ts de donn\u00e9es ;\nExpertise en SQL et en analyse de donn\u00e9es ; ma\u00eetrise Python ;\nId\u00e9alement certifi\u00e9 des technologies BI du Cloud Azure (Synapse, Azure Data Factory, PurView) ;\nConnaissance de l'intelligence artificielle, des statistiques et/ou des math\u00e9matiques appliqu\u00e9es ;\nExp\u00e9rience dans le d\u00e9veloppement de solutions sur des services et infrastructures de cloud computing dans le domaine des donn\u00e9es et de l'analyse ;\nExp\u00e9rience du d\u00e9ploiement de Power BI ;\nExp\u00e9rience conceptuelle des donn\u00e9es et de l'analyse, par exemple ETL, mod\u00e9lisation dimensionnelle, outils de reporting, gouvernance des donn\u00e9es, entreposage des donn\u00e9es, donn\u00e9es structur\u00e9es et non structur\u00e9es, qualit\u00e9 de donn\u00e9es ;\nConnaissance CI/CD et GitLab fortement appr\u00e9ci\u00e9.\nExp\u00e9rience agile / Digitale / gouvernance :\nPassionn\u00e9(e) le d\u00e9veloppement bas\u00e9 sur les donn\u00e9es, la fiabilit\u00e9 et l'exp\u00e9rimentation ;\nExp\u00e9rience souhait\u00e9e de travail au sein d'une \u00e9quipe produit Agile collaborative ;\nConnaissance de la gouvernance de la donn\u00e9e.\nSkills Individuels :\nMotiv\u00e9(e) et dot\u00e9(e) de solides comp\u00e9tences en mati\u00e8re de r\u00e9solution de probl\u00e8mes et d'apprentissage ;\nFlexibilit\u00e9 face aux changements d'orientation du travail au fur et \u00e0 mesure de l'\u00e9volution du projet ;\nExcellentes capacit\u00e9s de communication, d'\u00e9coute et de persuasion.\nAttitude attendue :\nSens aigu des chiffres, curiosit\u00e9 intellectuelle et volont\u00e9 d'adapter sa position sur la base d'informations compl\u00e9mentaires ;\nForte \u00e9thique de travail ; capacit\u00e9 \u00e0 travailler \u00e0 un niveau abstrait et \u00e0 obtenir un consensus.\nInformations suppl\u00e9mentaires :\nPoste \u00e0 pourvoir d\u00e8s que possible ;\nRemboursement des frais de transports + Mutuelle ;\nPossibilit\u00e9 de t\u00e9l\u00e9travail jusqu'\u00e0 un jour par semaine.\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "R",
                "Go"
            ],
            "DataBase": [
                "SQL"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [
                "Power BI"
            ],
            "Statistics": [
                "Statistiques"
            ],
            "CloudComputing": [
                "Azure"
            ],
            "DevTools": [
                "Git"
            ],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [
                "Statistiques",
                "Cloud",
                "CI/CD"
            ],
            "FrSoftSkills": [
                "Communication",
                "R\u00e9solution de probl\u00e8mes",
                "Collaboration",
                "Flexibilit\u00e9"
            ],
            "EnSoftSkils": [
                "Communication",
                "Collaboration",
                "Initiative"
            ]
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "DATA ENGINEER",
        "company": "Apside",
        "location": "Nantes, Pays de la Loire, France",
        "link": "https://fr.linkedin.com/jobs/view/data-engineer-at-apside-3909772916?position=50&pageNum=0&refId=b67kRduAUeEfaeVnXh9rCA%3D%3D&trackingId=j2LW3ztW%2Bq%2B5gYaNxbUPPQ%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Offre d'Emploi : DATA ENGINEER H/F chez Apside\nDescription du poste :\nNous sommes \u00e0 la recherche d'un Data Engineer passionn\u00e9 pour rejoindre notre \u00e9quipe dynamique. Si vous avez une expertise dans le Big Data, la Data Science, l'analyse de donn\u00e9es et l'architecture de donn\u00e9es, cette opportunit\u00e9 est faite pour vous. Int\u00e9grer notre communaut\u00e9 Data, c\u2019est l\u2019assurance de progresser, innover, partager, vous certifier et rendre service \u00e0 nos clients.\nVos missions :\nD\u00e9veloppement des jobs Spark pour la collecte et la transformation des donn\u00e9es comptables disponibles dans les bucket S3.\nOptimisation des jobs Spark.\nD\u00e9veloppement des batchs Java et \u00e9criture des donn\u00e9es au formats comptables.\n\u00c9criture et ordonnancement des DAGs Airflow.\nSupport du d\u00e9veloppement Spark Scala.\nMaintenance applicative.\nProduction des \u00e9v\u00e9nements d\u00e9di\u00e9s \u00e0 la plateforme de donn\u00e9es.\n.\nVotre r\u00f4le, vos comp\u00e9tences :\nVous ma\u00eetrisez au minimum un langage de programmation appliqu\u00e9 \u00e0 l\u2019analyse de donn\u00e9es (SQL, Scala, Python, Java).\nVous \u00eates passionn\u00e9 par le Big Data et le Machine Learning.\nVous concevez et mettez en \u0153uvre des strat\u00e9gies s\u00e9curis\u00e9es d'acquisition et d'int\u00e9gration de donn\u00e9es.\nVous configurez des r\u00e9f\u00e9rentiels de donn\u00e9es \u00e0 la pointe de la technologie dans des environnements distribu\u00e9s, majoritairement dans le cloud (Google Cloud Platform, Azure, AWS) et/ou en environnement Hadoop (distribution MapR, Cloudera, Hortonworks).\nEnvironnement technique :\nSQL\nPython/Spark\nCloud AWS: AWS Glue, AWS Lambda (possibilit\u00e9 de vous former sur AWS)\nStockage objet (AWS S3)\nOrchestration et scheduling de t\u00e2ches (Apache Airflow)\nBases analytiques et bases NoSQL (ElasticSearch, AWS Athena)\nVotre profil :\nFort de 4 ann\u00e9es d\u2019exp\u00e9rience en Data Engineer/ DATA ANALYST\nTitulaire d\u2019une formation sup\u00e9rieure IT.\nCapacit\u00e9 \u00e0 s\u2019int\u00e9grer dans un cadre technique client tout en \u00e9tant \u00e0 m\u00eame de proposer des pistes d\u2019am\u00e9liorations pertinentes.\nAutonome dans la gestion des projets.\nCurieux et impliqu\u00e9, vous \u00eates bon communicant avec les clients et les acteurs de culture technique diff\u00e9rente.\nDe bonnes raisons de rejoindre Apside ?\nUn esprit start-up avec la stabilit\u00e9 d\u2019un grand groupe, qui favorise l\u2019agilit\u00e9, le travail d\u2019\u00e9quipe et la proximit\u00e9. Alors qu\u2019Apside ne cesse d\u2019agrandir sa famille d\u00e9j\u00e0 forte de plus de 3000 consultants, nous sommes \u00e0 la recherche de nos nouveaux talents !\nCDI + package salarial avantageux (Mutuelle offerte, RTT, Tickets Restaurant, Int\u00e9ressement ...)\nParticipez et animez nos soir\u00e9es techniques (Project Lab, Test Lab\u2026),\nDevenez speaker (Devoxx, DevFest, NCraft\u2026),\nFormez vous avec l\u2019Academy By Apside (e-learning, formation, certification).\nD\u00e9veloppez votre r\u00e9seau (Soir\u00e9es trimestrielles, Afterwork, Soir\u00e9es d\u2019int\u00e9gration\u2026),\nInt\u00e9grez notre Communaut\u00e9s d\u2019Experts et testez les derni\u00e8res innovations techniques sur notre Bac \u00e0 Sable !\nApside s\u2019engage en faveur de l\u2019emploi des personnes en situation de handicap avec sa filiale Apsid\u2019EA : 1\u00e8re entreprise adapt\u00e9e totalement int\u00e9gr\u00e9e \u00e0 une ESN !\nPour aller plus loin avec APSIDE !\nhttps://www.apside.com/fr/nos-offres-emploi/?_joboffer-agency=17833&_paged=2\nCe poste de DATA ENGINEER est fait pour vous !\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "Java",
                "Scala",
                "R",
                "Go"
            ],
            "DataBase": [
                "SQL",
                "NoSQL",
                "Elasticsearch"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [
                "Hadoop",
                "Spark",
                "Apache Airflow"
            ],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [
                "AWS",
                "Azure",
                "Google Cloud Platform"
            ],
            "DevTools": [],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [
                "Airflow"
            ],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [
                "Big Data",
                "Machine Learning",
                "Cloud"
            ],
            "FrSoftSkills": [],
            "EnSoftSkils": []
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [
                "CDI"
            ],
            "Salary": [
                "17833"
            ],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "Data Engineer Senior",
        "company": "AXA en France",
        "location": "Hauts-de-Seine, \u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/data-engineer-senior-at-axa-en-france-3884386043?position=51&pageNum=0&refId=b67kRduAUeEfaeVnXh9rCA%3D%3D&trackingId=sDPS1GxZYKSqOr7DXdMrjQ%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Environnement\nEn tant que\nSenior Data Engineer F/H\n, vous allez contribuer directement aux projets des directions m\u00e9tier (ex : fraude sant\u00e9, multi\u00e9quipements, pricing IARD, optimisation du lead management, fragilit\u00e9 auto, \u2026) d\u2019AXA France et \u00e0 la construction du socle technique Big Data.\nVous allez int\u00e9grer une \u00e9quipe d'une dizaine de personne compos\u00e9e de Data Engineer et des Tech Lead travaillant en mode Feature Team au sein des tribus m\u00e9tier de la Direction Transformation Digital Tech et DATA (DT2).\nLa Direction Transformation Digital Tech et DATA d'AXA France en quelques mots :\n- Une organisation agile en feature teams : tribus, guildes, squads\n- Des projets sur des applications innovantes \u00e0 fort trafic (web, mobile\u2026)\n- Des m\u00e9thodologies craft (TDD, BDD, clean code, code review\u2026) et DevOps\n- Une communaut\u00e9 de partage de bonnes pratiques (BBL, dojo, meetup, conf\u2026)\nVotre r\u00f4le et vos missions\nVous aurez pour missions principales de d\u00e9velopper les projets Big Data demand\u00e9s par le m\u00e9tier, et notamment :\nPasser de la donn\u00e9e brute \u00e0 de la donn\u00e9e exploitable, expos\u00e9e sous forme de tables requ\u00eatables dans le datalake\nConsolider ces donn\u00e9es au fur et \u00e0 mesure de leur alimentation r\u00e9currente dans le data lake\nLes exploiter pour atteindre la finalit\u00e9 business (exposition de business view, r\u00e9int\u00e9gration des r\u00e9sultats dans le SI, service de scoring, \u2026)\nDe travailler \u00e0 la cr\u00e9ation du socle technique Big Data et industrialiser le cycle de d\u00e9veloppement de l'\u00e9quipe\nDe mettre en place et de garantir le respect dans la dur\u00e9e d'un processus qualit\u00e9 sur l'ensemble du cycle de DEV (documents, tests unitaires / int\u00e9gration / fonctionnels, commentaires, versionning, etc.)\nVotre profil\nVous justifiez de plusieurs exp\u00e9riences significatives (+ de 5 ans) sur du\nd\u00e9veloppement big data, en particulier sur du PySpark.\nComp\u00e9tences techniques :\nConnaissances avanc\u00e9es en d\u00e9veloppement en\nPySpark\n(Spark avec le langage Python)\nMaitrise de l'environnement\nMicrosoft Azure\nConnaissances avanc\u00e9es d'outils de BI comme\nPowerBI\nComp\u00e9tences transverses :\nCapacit\u00e9 \u00e0 interagir avec des parties prenantes diverses : Business analyst, Architectes, M\u00e9tier\nExp\u00e9rience en mode de delivery Agile (Scrum, Kanban, etc...)\nDriver et accompagner des Data Engineer junior sur les aspects technique\nEt Id\u00e9alement :\nDes Connaissances sur Azure DevOps, Azure Pipeline, GIT, JIRA\nMaitrise des Traitements Big Data en mode Streaming\nMaitrise des Bases de donn\u00e9es relationnelles et NoSQL\nUne exp\u00e9rience professionnelle avec des outils comme Azure Databricks, Azure Data Lake Storage ou encore Azure Data Factory\nQui sommes nous ?\nAXA est un des leaders de l\u2019assurance et de la gestion d\u2019actifs dans le monde.\nNous aidons nos 108 millions de clients \u00e0 traverser les petites et grandes difficult\u00e9s de la vie.\nChaque jour, nous agissons ensemble pour inventer la meilleure mani\u00e8re de les prot\u00e9ger et voulons donner \u00e0 chacun les moyens de vivre une vie meilleure.\nUn challenge qui donne le sourire et envie de se lever le matin !\nChez AXA, nous sommes persuad\u00e9s que pour bien prendre soin de nos clients, nous devons commencer par bien prendre soin de nos collaborateurs. C\u2019est pour cette raison que nous menons une politique RH engag\u00e9e qui favorise la diversit\u00e9, qui pr\u00e9serve l\u2019\u00e9quilibre vie priv\u00e9e-vie professionnelle et acc\u00e9l\u00e8re le d\u00e9veloppement des comp\u00e9tences et des carri\u00e8res.\nAinsi, en rejoignant AXA France vous travaillerez dans une entreprise responsable, offrant une v\u00e9ritable culture d\u2019expertise, acc\u00e9l\u00e9rant le d\u00e9veloppement des comp\u00e9tences de chacun et proposant une r\u00e9mun\u00e9ration attractive.\nPourquoi nous rejoindre ?\nVous \u00eates porteur d\u2019id\u00e9es et d\u2019initiatives innovantes ? Vous proposez des solutions et \u00eates au service du client ? Faites partie de notre grande famille en rejoignant\nUn leader mondial offrant des opportunit\u00e9s de carri\u00e8res int\u00e9ressantes\nUne entreprise qui donne une place de choix \u00e0 l\u2019innovation, \u00e0 l\u2019initiative et aux actions solidaires (notamment via l\u2019association AXA Atout C\u0153ur)\nUn environnement inclusif \u00e0 tous les niveaux (mixit\u00e9, handicap, initiatives pour favoriser l\u2019insertion des jeunes, orientation sexuelle, etc.)\nUn acc\u00e8s \u00e0 de multiples avantages (cong\u00e9s, temps partiel, t\u00e9l\u00e9travail, etc.)\nUn cadre stimulant, qui permet de rencontrer des collaborateurs performants et d\u2019enrichir ses comp\u00e9tences\nVictime ou t\u00e9moin, en cas de discrimination, vous pouvez adresser vos signalements et/ou alertes discrimination \u00e0 alerte.discrimination.harcelement@axa.fr\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "R"
            ],
            "DataBase": [
                "SQL",
                "NoSQL"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [
                "Spark",
                "Databricks"
            ],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [
                "PowerBI"
            ],
            "Statistics": [],
            "CloudComputing": [
                "Azure"
            ],
            "DevTools": [
                "Git"
            ],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [
                "JIRA",
                "Teams"
            ],
            "Other": [
                "DevOps",
                "Big Data"
            ],
            "FrSoftSkills": [
                "Organisation"
            ],
            "EnSoftSkils": [
                "Initiative"
            ]
        },
        "details": {
            "JobDetail": [
                "Junior",
                "Senior"
            ],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s",
                "5",
                "5",
                "5"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "Data Engineer",
        "company": "Beelix",
        "location": "Paris, \u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/data-engineer-at-beelix-3865239426?position=52&pageNum=0&refId=b67kRduAUeEfaeVnXh9rCA%3D%3D&trackingId=RbppPHyc%2Ba%2B6Xq1WS%2FNoKQ%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Qui sommes-nous ?\nDepuis 2016, nous accompagnons nos clients sur des probl\u00e9matiques de Product Management, Data et Design Thinking. Beelix contribue \u00e0 fa\u00e7onner le monde de demain en participant aux grandes avanc\u00e9es des secteurs suivants:\n\ud83d\ude97Automobile\n\u26a1Energie\n\ud83d\udce1M\u00e9dias & T\u00e9l\u00e9coms\n\ud83d\udc57Luxe & Retail\n\ud83d\udcb6 Banque, Finance & Assurance\n\u2708\ufe0fD\u00e9fense\nAujourd\u2019hui, Beelix compte plus de 200 collaborateurs motiv\u00e9s et dynamiques. Lab\u00e9lis\u00e9e Great Place To work en 2023, Beelix est aussi une entreprise engag\u00e9e o\u00f9 il fait bon vivre.\nDans le cadre de notre d\u00e9veloppement, nous recherchons un Data Engineer en \u00cele-de-France.\nQuelles missions au quotidien ?\nVous aurez pour missions principales de d\u00e9velopper les projets Big Data demand\u00e9s par le m\u00e9tier, et notamment :\nPasser de la donn\u00e9e brute \u00e0 de la donn\u00e9e exploitable, expos\u00e9e sous forme de tables requ\u00eatables dans le Datalake\nConsolider ces donn\u00e9es au fur et \u00e0 mesure de leur alimentation r\u00e9currente dans le Datalake\nLes exploiter pour atteindre la finalit\u00e9 business (exposition de Business View, r\u00e9int\u00e9gration des r\u00e9sultats dans le SI, service de scoring, \u2026)\nDe mettre en place et de garantir le respect dans la dur\u00e9e d'un processus qualit\u00e9 sur l'ensemble du cycle de DEV (documents, tests unitaires / int\u00e9gration / fonctionnels, commentaires, versionning, etc.)\nAccompagner les Data Engineers sur son p\u00e9rim\u00e8tre pour garantir la qualit\u00e9 des livrables\nExpertise souhait\u00e9e\nExpertise en SPARK et PySpark\nExpertise sur Databricks\nUne exp\u00e9rience sur un cloud provider public comme Azure (id\u00e9alement), AWS, ou GCP\nConnaissances avanc\u00e9es d'outils de BI comme PowerBI (id\u00e9alement) ou Spotfire\nCapacit\u00e9 \u00e0 interagir avec des parties prenantes diverses : Business analyst, Architectes, M\u00e9tier\nEtre expert dans les pratiques du Software Craftsmanship (Test Driven Development, Behavior Driven Development, Clean Code, Code Reviews, etc.)\nDes Connaissances sur Azure DevOps, Azure Pipeline, GIT\nMaitrise des Traitements Big Data en mode Streaming\nMaitrise des Bases de donn\u00e9es relationnelles et NoSQL\nUne exp\u00e9rience professionnelle avec des outils comme Azure Databricks, Azure Data Lake Storage ou encore Azure Data Factory\nA propos de vous ?\nDipl\u00f4m\u00e9 d'une \u00e9cole d'ing\u00e9nieurs ou \u00e9quivalent\nAu moins 3 ans d'exp\u00e9rience en tant que Data Engineer\nExp\u00e9rience en mode de Delivery Agile (Scrum, Kanban, etc.\u2026)\nVous avez un bon niveau d\u2019anglais tant \u00e0 l\u2019\u00e9crit qu\u2019\u00e0 l\u2019oral\nPourquoi nous rejoindre ?\nUn suivi et un accompagnement au quotidien\nUn organisme de formation certifi\u00e9 Qualiopi, un abonnement linkedin learning pour chaque salari\u00e9 et des partenariats avec des sp\u00e9cialistes pour d\u2019autres expertises\nDe nombreux \u00e9v\u00e9nements : Afterworks, Communaut\u00e9s m\u00e9tiers, Happy talks\u2026\nune Exp\u00e9rience personnalis\u00e9e bas\u00e9e sur vos besoins gr\u00e2ce au Pr\u00e9dictive Index\nNotre package \u00ab unBeelievable \u00bb : 100% du titre de transport, Tickets restaurants, CSE, Prime de participation ...\nNombreux \u00e9v\u00e8nements (afterworks, sport, etc) et des communaut\u00e9s m\u00e9tiers dynamiques\nLe processus de recrutement ?\n\u00c9change t\u00e9l\u00e9phonique (15 min)\nEntretien 1 RH pour apprendre \u00e0 vous conna\u00eetre\nEntretien 2 avec votre futur N+1 pour appr\u00e9hender la relation manag\u00e9riale\nEntretien 3 avec un Responsable commercial pour avoir la vision strat\u00e9gique\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "R"
            ],
            "DataBase": [
                "SQL",
                "NoSQL"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [
                "Spark",
                "Databricks"
            ],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [
                "PowerBI"
            ],
            "Statistics": [],
            "CloudComputing": [
                "AWS",
                "Azure"
            ],
            "DevTools": [
                "Git"
            ],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [
                "DevOps",
                "Big Data",
                "Cloud"
            ],
            "FrSoftSkills": [],
            "EnSoftSkils": []
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [],
            "Salary": [
                "100"
            ],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s",
                "3",
                "3",
                "3"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "Data Engineer",
        "company": "CGI",
        "location": "Niort, Nouvelle-Aquitaine, France",
        "link": "https://fr.linkedin.com/jobs/view/data-engineer-at-cgi-3902057928?position=53&pageNum=0&refId=b67kRduAUeEfaeVnXh9rCA%3D%3D&trackingId=yvn5h2BSifUPF6%2FPZkJ7xg%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Description de poste\nBig Data, Data Science, Data analyse, Data architecture ... \u00c7a n\u2019a pas de secret pour vous ?\nQue vous commenciez votre carri\u00e8re professionnelle ou que vous soyez sp\u00e9cialiste de l\u2019une de ces disciplines, int\u00e9grer notre communaut\u00e9 Data, c\u2019est l\u2019assurance de progresser, innover, partager, vous certifier et rendre service \u00e0 nos clients.\nSi vous souhaitez int\u00e9grer nos \u00e9quipes \u00e0 Niort et accompagner les plus grands acteurs du secteur des Assurances, cette annonce est susceptible de vous int\u00e9resser.\nEn tant que Data Engineer, vous serez responsable de la conception, du d\u00e9veloppement, de la gestion et de l'int\u00e9gration des syst\u00e8mes bas\u00e9s sur les technologies AWS, Terraform, OpenShift, Kafka et Hadoop. Ce r\u00f4le implique la mise en place d'architectures \u00e9volutives et hautement disponibles pour r\u00e9pondre aux besoins de traitement et de stockage de donn\u00e9es de l'entreprise.\nFonctions et responsabilit\u00e9s\nVos responsabilit\u00e9s seront les suivantes:\n-Maintenir et d\u00e9velopper des solutions bas\u00e9es sur les services AWS pour le stockage, le traitement et l'analyse de donn\u00e9es\n-Utiliser les services AWS appropri\u00e9s tels que Amazon EC2, S3, RDS, Lambda, etc., pour r\u00e9pondre aux exigences du projet.\n-Cr\u00e9er et maintenir les configurations Terraform pour la gestion de l'infrastructure en tant que code (IaC) sur AWS\n-Participer \u00e0 la maintenance et \u00e0 la mise en place d'environnements OpenShift pour l'h\u00e9bergement d'applications et de services\n-G\u00e9rer et administrer les clusters Kafka pour garantir la disponibilit\u00e9, la performance et la s\u00e9curit\u00e9 du syst\u00e8me de messagerie\nParticiper \u00e0 l\u2019assistance utilisateurs sur les briques de la plateforme Hadoop Cloudera Data\n-Travailler avec les projets et les devOps pour assurer un traitement efficace des donn\u00e9es\nEn rejoignant CGI, vous b\u00e9n\u00e9ficiez notamment d\u2019une offre compl\u00e8te de formations (techniques, m\u00e9tiers, d\u00e9veloppement personnel,\u2026), de flexibilit\u00e9 gr\u00e2ce \u00e0 notre accord t\u00e9l\u00e9travail (jusqu\u2019\u00e0 3 jours de t\u00e9l\u00e9travail par semaine), d\u2019une politique de cong\u00e9s avantageuse (27 jours de cong\u00e9s pay\u00e9s, RTT, cong\u00e9s anciennet\u00e9 et enfant malade,\u2026) et d\u2019un package d\u2019avantages int\u00e9ressant (r\u00e9gime d\u2019achats d\u2019actions, participation, CSE,...).\nQualit\u00e9s requises pour r\u00e9ussir dans ce r\u00f4le\nAyant une premi\u00e8re exp\u00e9rience en tant que Data Engineer, vous avez une premi\u00e8re exp\u00e9rience relative aux points suivants:\n-D\u00e9veloppement et int\u00e9gration sur les technologies AWS, Terraform, OpenShift, Kafka et Hadoop\n-Connaissance avanc\u00e9e de l'administration Kafka, y compris la configuration, la gestion et la r\u00e9solution des probl\u00e8mes\n-Mise en \u0153uvre de l'infrastructure en tant que code \u00e0 l'aide de Terraform\n-Bonne compr\u00e9hension des bonnes pratiques de s\u00e9curit\u00e9 pour les syst\u00e8mes cloud, les clusters Kafka et les plateformes Hadoop\nCGI est un employeur inclusif et attentif aux candidatures des personnes en situation de handicap, \u00e0 l\u2019\u00e9volution de carri\u00e8res des hommes et des femmes et au bien-\u00eatre de nos salari\u00e9s LGBT+. Dans un souci d\u2019accessibilit\u00e9 et de clart\u00e9, le point m\u00e9dian n\u2019est pas utilis\u00e9 dans cette annonce. Tous les termes employ\u00e9s se r\u00e9f\u00e8rent aussi bien au genre f\u00e9minin que masculin.\nEnsemble, en tant que propri\u00e9taires, mettons notre savoir-faire \u00e0 l\u2019\u0153uvre.\nLa vie chez CGI est ancr\u00e9e dans l\u2019actionnariat, le travail d\u2019\u00e9quipe, le respect et un sentiment d\u2019appartenance. Chez nous, vous pourrez exploiter votre plein potentiel parce que\u2026\nNous vous invitons \u00e0 devenir propri\u00e9taire d\u00e8s le jour 1 alors que nous travaillons ensemble \u00e0 faire de notre r\u00eave une r\u00e9alit\u00e9. C\u2019est pourquoi nous nous d\u00e9signons comme associ\u00e9s de CGI, plut\u00f4t que comme employ\u00e9s. Nous tirons profit des retomb\u00e9es de notre succ\u00e8s collectif et contribuons activement \u00e0 l\u2019orientation et \u00e0 la strat\u00e9gie de notre entreprise.\nVotre travail cr\u00e9e de la valeur. Vous \u00e9laborerez des solutions novatrices et d\u00e9velopperez des relations durables avec vos coll\u00e8gues et clients, tout en ayant acc\u00e8s \u00e0 des capacit\u00e9s mondiales pour concr\u00e9tiser vos id\u00e9es, saisir de nouvelles opportunit\u00e9s, et b\u00e9n\u00e9ficier d\u2019une expertise sectorielle et technologique de pointe.\nVous ferez \u00e9voluer votre carri\u00e8re en vous joignant \u00e0 une entreprise b\u00e2tie pour cro\u00eetre et durer. Vous serez soutenus par des leaders qui ont votre sant\u00e9 et bien-\u00eatre \u00e0 c\u0153ur et qui vous permettront de saisir des occasions afin de parfaire vos comp\u00e9tences et \u00e9largir les horizons.\nJoignez-vous \u00e0 nous, l\u2019une des plus importantes entreprises de conseil en technologie de l\u2019information (TI) et en management au monde.\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "R"
            ],
            "DataBase": [],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [
                "Hadoop"
            ],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [
                "AWS"
            ],
            "DevTools": [],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [
                "Terraform"
            ],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [
                "OpenShift"
            ],
            "Collaboration": [],
            "Other": [
                "DevOps",
                "Big Data",
                "Cloud"
            ],
            "FrSoftSkills": [
                "Flexibilit\u00e9"
            ],
            "EnSoftSkils": []
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [],
            "Salary": [
                "1"
            ],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "Data Engineer",
        "company": "PROXIAD",
        "location": "Greater Nice Metropolitan Area",
        "link": "https://fr.linkedin.com/jobs/view/data-engineer-at-proxiad-3901014428?position=54&pageNum=0&refId=b67kRduAUeEfaeVnXh9rCA%3D%3D&trackingId=oOSHoRrWkL6odgpXOOrPXg%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Contexte\nEn tant que Data Engineer, votre r\u00f4le consistera \u00e0 r\u00e9aliser la conception, le d\u00e9veloppement, les tests unitaires, la qualification, l'int\u00e9gration continue et la mise en production d'\u00e9volutions sur les projets du p\u00f4le produits scoring.\nCes projets Big Data GCP ont pour objet de d\u00e9velopper des traitements de croisement de donn\u00e9es, exploration data en mode agile (scrum et Safe), industriel (respect de normes), sur l'environnement Google Cloud Platform.\n1 : Conception\nSp\u00e9cification et conception d'une solution se basant sur les d\u00e9veloppements existants.\nMettre en question les choix techniques dans le but de concevoir un logiciel r\u00e9pondant au mieux \u00e0 la demande au moindre co\u00fbt et avec la qualit\u00e9 demand\u00e9e.\nConception de l'expression de besoins, de la r\u00e9ponse \u00e0 l'expression de besoins \u00e0 l'aide des besoins m\u00e9tiers remont\u00e9s par le Product Owner.\n2 : R\u00e9alisation\nD\u00e9veloppement de nouvelles fonctionnalit\u00e9s sur les composants des applications du p\u00f4le produits scoring en environnement GCP (DataProc, GCS, BigQuery, Airflow...)\nTests des d\u00e9veloppements r\u00e9alis\u00e9s\nRevue de code des d\u00e9veloppements des autres d\u00e9veloppeurs\nMise en production via CICD des d\u00e9veloppements\n3 : Suivi du RUN applicatif\nPrendre en charge avec les autres membres de l'\u00e9quipe le RUN des applications du p\u00f4le produits scoring. Cela inclus les t\u00e2ches de rapport quotidien, la gestion des probl\u00e8mes applicatifs, le soutien aux utilisateurs.\nComp\u00e9tences attendues\nMa\u00eetrise op\u00e9rationnelle :\nConfluence\nImpl\u00e9mentation de l\u2019int\u00e9gration continue (Utilisation de la chaine CI/CD existante )\nConnaissance des principes DevOps\nJira\nAnglais (lu, \u00e9crit)\nMa\u00eetrise avanc\u00e9e :\nElaborer un cahier de recette\nBig Query\nSp\u00e9cifications technique et documentation\nD\u00e9veloppement :Python, SQL, Scala, Javascript, GitLab\nExpertise\nGCP : Exp\u00e9rience significative en tant que Data Engineer Cloud. Mise en pratique des produits GCP et en particulier Dataproc, Big Query, composer, workflow, PubSub\nD\u00e9veloppement : Java\nCompr\u00e9hension g\u00e9n\u00e9rale des travaux BigData et du profiling\nInformations compl\u00e9mentaires :\nT\u00e9l\u00e9travail 2 jours par semaines\nR\u00e9mun\u00e9ration aux alentours des 45K\u20ac\nExp\u00e9rience requise : 6 ans\nLocalisation : Mougins\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "Java",
                "Scala",
                "R",
                "Go",
                "JavaScript"
            ],
            "DataBase": [
                "SQL"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [
                "Google Cloud Platform"
            ],
            "DevTools": [
                "Git"
            ],
            "Os": [],
            "DBMS": [
                "BigQuery",
                "Big Query"
            ],
            "SoftBigDataProcessing": [],
            "Automation": [
                "Airflow"
            ],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [
                "JIRA",
                "Confluence"
            ],
            "Other": [
                "DevOps",
                "Big Data",
                "Cloud",
                "CI/CD"
            ],
            "FrSoftSkills": [],
            "EnSoftSkils": []
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s",
                "6",
                "6",
                "6"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "CDI - DATA ENGINEER SPARK SCALA JUNIOR - H/F",
        "company": "ITNOVEM.",
        "location": "Paris, \u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/cdi-data-engineer-spark-scala-junior-h-f-at-itnovem-3899544280?position=55&pageNum=0&refId=b67kRduAUeEfaeVnXh9rCA%3D%3D&trackingId=AJXOr6PxIG7iPzlY%2F0%2FWWA%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "ITNOVEM, qui sommes-nous ?\nFiliale technologique du groupe SNCF, int\u00e9gr\u00e9e \u00e0 la Direction du Digital et des Syst\u00e8mes d\u2019information, Itnovem\n.\nse positionne comme expert de l\u2019Internet Industriel. Porteuse de grands projets de la r\u00e9volution digitale, notre soci\u00e9t\u00e9 est en constante recherche de profils pour rejoindre la grande aventure de l\u2019Internet des objets, de la data science et de l\u2019accompagnement des projets digitaux.\nQu\u2019il s\u2019agisse de maintenance pr\u00e9dictive, d\u2019aide \u00e0 la d\u00e9cision sur la maintenance des infrastructures, de gare 4.0, d\u2019usine du futur, ou de s\u00e9curisation des assets, nos \u00e9quipes font valoir \u00e0 la fois une exp\u00e9rience m\u00e9tier et une expertise technique sans cesse renouvel\u00e9e, dans le respect des valeurs du groupe :\nExcellence\n,\nInnovation\n,\nCollectif\n,\nAgile\n,\nEngagement.\nCONTEXTE\nAu sein du p\u00f4le Factory Data & IA et dans le cadre de la mont\u00e9e en charge des projets, nous sommes \u00e0 la recherche d'un\u00b7e data engineer Scala/Spark junior.\nRattach\u00e9\u00b7e aux \u00e9quipes Data Engineering et en collaboration avec les membres de l\u2019\u00e9quipe, son r\u00f4le sera de contribuer aux projets data sur stack Scala/Spark et \u00e0 l\u2019am\u00e9lioration de l\u2019outillage et des process internes.\nLe recrutement intervient dans le cadre de la cr\u00e9ation d\u2019un plateau projet d\u00e9di\u00e9 \u00e0 l\u2019activit\u00e9 TGV sur Nantes.\nMISSIONS\nParticiper au d\u00e9veloppement des projets data sur stack Scala/Spark\nEtre acteur de la mise en place de bonnes pratiques de communication entre les plateaux nantais et parisiens\nAvec l\u2019appui de l\u2019\u00e9quipe, \u00eatre impliqu\u00e9\u00b7e dans la roadmap technologique (pratiques, outils) et de l\u2019am\u00e9lioration continue du p\u00e9rim\u00e8tre Scala/Spark\nContribuer proactivement \u00e0 la qualit\u00e9 et aux comp\u00e9tences des \u00e9quipes Data Science et Engineering : veille techno, capitalisation\u2026\nLE PROFIL RECHERCHE\nComp\u00e9tences m\u00e9tiers & outils :\nExp\u00e9rience professionnelle (alternance, stage) ou acad\u00e9mique sur le langage Scala et le d\u00e9veloppement d\u2019applications Spark\nConnaissances autour du SQL (principes, langage, mod\u00e9lisation)\nApp\u00e9tence sur les aspects fonctionnels et m\u00e9tiers d\u2019un projet\nNotions de CI/CD (notre stack : Maven, Gitlab, Jenkins, Artifactory, Ansible)\nComp\u00e9tences transverses :\nInt\u00e9r\u00eat prononc\u00e9 pour le software engineering\nAisance relationnelle\nProactivit\u00e9 et clart\u00e9 dans la communication\nRigueur et organisation\nForce de proposition\nBonne communication \u00e9crite et orale\nExp\u00e9riences et formations\nTitulaire d\u2019un bac+5 sp\u00e9cialis\u00e9 g\u00e9nie logiciel / d\u00e9veloppement ou exp\u00e9rience \u00e9quivalente.\nVous venez d\u2019obtenir votre dipl\u00f4me ou occupez d\u00e9j\u00e0 votre premier poste dans le domaine du d\u00e9veloppement de pipelines Data.\nLocalisation\nPoste bas\u00e9 \u00e0 Saint Denis, possiblement \u00e0 Lyon\nT\u00e9l\u00e9travail jusqu\u2019\u00e0 3 jours par semaine.\nD\u2019autres raisons de rejoindre ITNOVEM !\n\ud83d\ude80 En tant que filiale SNCF, des opportunit\u00e9s de carri\u00e8res internes vous sont offertes.\n\ud83d\udcda ITNOVEM croit en la formation continue de ses collaborateurs et leur donne l\u2019opportunit\u00e9 de s\u2019inscrire \u00e0 une formation par an minimum.\n\ud83d\ude8a Vos titres de transport sont pris en charge \u00e0 hauteur de 75%.\n\ud83c\udf7d\ufe0f Via la carte titres-restaurant Swile, vous b\u00e9n\u00e9ficiez de 9,25 \u20ac par jour dont 60% pris en charge par ITNOVEM.\n\ud83d\udcbb Chez ITNOVEM, vous b\u00e9n\u00e9ficiez jusqu\u2019\u00e0 3 jours de t\u00e9l\u00e9travail par semaine.\n\ud83c\udfd6\ufe0f ITNOVEM vous permet de profiter de 28 cong\u00e9s et de 16 RTT pour les cadres et 10 pour les non-cadres. Par ailleurs, 2 des 3 jours de cong\u00e9s pour enfant malade sont r\u00e9mun\u00e9r\u00e9s.\n\ud83d\udc6b La mise en \u0153uvre de l\u2019\u00e9galit\u00e9 professionnelle femmes/hommes est primordiale chez ITNOVEM. A chaque nouvelle embauche, l'entreprise s'engage \u00e0 proposer une r\u00e9mun\u00e9ration \u00e9quivalente tant aux femmes qu'aux hommes.\n\u267b\ufe0f ITNOVEM incite tous les collaborateurs \u00e0 trier leurs d\u00e9chets et les gobelets ont \u00e9t\u00e9 bannis. Par ailleurs, chaque ann\u00e9e, ITNOVEM participe \u00e0 \u00ab La grande collecte \u00bb, une initiative SNCF qui permet de collecter les PC devenus obsol\u00e8tes en leur offrant une seconde vie\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Scala",
                "R",
                "Go"
            ],
            "DataBase": [
                "SQL"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [
                "Spark"
            ],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [],
            "DevTools": [
                "Git",
                "Jenkins"
            ],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [
                "Ansible"
            ],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [
                "CI/CD"
            ],
            "FrSoftSkills": [
                "Communication",
                "Collaboration",
                "Organisation"
            ],
            "EnSoftSkils": [
                "Communication",
                "Collaboration",
                "Initiative"
            ]
        },
        "details": {
            "JobDetail": [
                "Junior"
            ],
            "TypeContract": [],
            "Salary": [],
            "Level": [
                "Bac+5"
            ],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "Junior Data Engineer (H/F/N)",
        "company": "Ekimetrics",
        "location": "Paris, \u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/junior-data-engineer-h-f-n-at-ekimetrics-3903416527?position=56&pageNum=0&refId=b67kRduAUeEfaeVnXh9rCA%3D%3D&trackingId=hLcIMdf1paDtm%2BnDr8qtJg%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Ekimetrics\nest leader en data science et fournisseur de solutions AI. Depuis 2006, nous utilisons la data science au service de l\u2019optimisation de performance marketing, business, et de la transition vers une performance plus durable.\nSi vous \u00eates passionn\u00e9.e de data, ou de technologie en g\u00e9n\u00e9ral, et que vous avez envie d\u2019\u00eatre acteur.rice de votre avenir professionnel, votre place est s\u00fbrement chez Ekimetrics !\n\ud83d\udccaEkimetrics, c\u2019est:\n\u2022 400 expert.e.s en data science\n\u2022 1000 projets divers et vari\u00e9s pour plus de 350 clients\n\u2022 4 bureaux : Paris, Hong Kong, Londres et New York\n\u2022 1 milliard de $ de profits g\u00e9n\u00e9r\u00e9s pour nos clients depuis 2006\n\u2022 7000 tonnes de CO2 \u00e9vit\u00e9es pour nos clients en 2022\n\ud83c\udf31Chez Ekimetrics, nous avons l\u2019ambition d\u2019accompagner nos clients \u00e0 repenser leur business model, en r\u00e9conciliant performance \u00e9conomique, environnementale et sociale, gr\u00e2ce \u00e0 la data science.\nC\u2019est pourquoi nous avons en interne toutes les comp\u00e9tences nous permettant de r\u00e9pondre aux besoins de nos clients: Product Managers, Product Designers, Data Architects, Data Engineers, DevOps Engineers, Data Scientists.\nPourquoi recrutons-nous ?\nEn tant que Data Engineer, vous serez impliqu\u00e9 dans des projets stimulants avec des clients internationaux de premier plan dans des industries diverses, en construisant des solutions analytiques sur mesure pour r\u00e9pondre aux enjeux de nos clients. Vous travaillerez en \u00e9quipe, avec d'autres consultants Ekimetrics (data engineers, data scientists, software engineers) sur 1 ou 2 projets simultan\u00e9ment. Vous b\u00e9n\u00e9ficierez de nos partenariats technologiques et d\u2019une offre de formation pour vous accompagner dans votre mont\u00e9e en comp\u00e9tences.\nPlus particuli\u00e8rement vos responsabilit\u00e9s seront de\n:\n\u2022 Concevoir et d\u00e9velopper des solutions permettant de collecter et pr\u00e9parer la donn\u00e9e ;\n\u2022 Impl\u00e9menter et industrialiser des pipelines de donn\u00e9es dans des environnements Cloud (Azure, GCP, AWS, Databricks, Snowflake) ;\n\u2022 D\u00e9velopper des outils destin\u00e9s \u00e0 faciliter l\u2019ex\u00e9cution et le d\u00e9ploiementdes pipelines de donn\u00e9es (CICD, DevOps, MLOps) ;\n\u2022 Approfondir vos connaissances en GenAI, Machine Learning, MMO ;\n\u2022 Participer aux activit\u00e9s de R&D. (Veille, formations, animation de Meetups, Hackathons, etc.)\nLe profil et les comp\u00e9tences recherch\u00e9es\n:\n\u2022 Bac+ 5 Ecole d'ing\u00e9nieur ou \u00c9quivalent ;\n\u2022 Premi\u00e8re exp\u00e9rience sur des sujets Big Data (Projet ou exp\u00e9rience professionnelle) ;\n\u2022 Connaissances avanc\u00e9es en base de donn\u00e9es et en d\u00e9veloppement (Python, SQL, Spark) ;\n\u2022 Exp\u00e9rience dans un environnement Cloud ;\n\u2022 Connaissances avanc\u00e9es en acquisition de donn\u00e9es ;\n\u2022 App\u00e9tence pour la Data Science.\n\ud83e\udd1d Pourquoi nous rejoindre ?\nRejoindre Ekimetrics, c\u2019est int\u00e9grer une entreprise dont les valeurs s\u2019appliquent au quotidien :\n\u2022 Evoluer dans un environnement entrepreneurial et non traditionnel (\n#curiosit\u00e9)\n\u2022 \u00catre capable de donner et recevoir du feedback pour s\u2019am\u00e9liorer en continu (\n#excellence\n)\n\u2022 Se former d\u00e8s son arriv\u00e9e et en continu gr\u00e2ce \u00e0 une exp\u00e9rience apprenante unique, riche de nombreuses ressources (internes, externes, live et digital) alliant savoirs techniques, savoir-\u00eatre et savoir-faire (\n#transmission\n)\n\u2022 Faire partie d\u2019une communaut\u00e9 accueillante et soud\u00e9e(\n#plaisir\n)\n\u2022 Imaginer des solutions inattendues & sortir de sa zone de confort (\n#cr\u00e9ativit\u00e9\n)\nEn 2023, Ekimetrics a obtenu le statut d\u2019entreprise \u00e0 mission qui t\u00e9moigne de notre ambition forte en mati\u00e8re de RSE. Notre raison d\u2019\u00eatre: Faire de la data science et de l\u2019intelligence artificielle l\u2019acc\u00e9l\u00e9rateur de la transformation durable des organisations.\nNous sommes \u00e9galement certifi\u00e9s Great Place to Work\u00a9 en France, au Royaume-Uni et aux Etats-Unis, et notre bureau de Hong Kong a re\u00e7u le prix Best Companies to Work for in Asia 2023\u00a9.\n\ud83e\udd29 Vous aurez acc\u00e8s \u00e0\u2026\n\u2022 Au catalogue de formation Eki.Academy qui contient des programmes qui vous feront monter en comp\u00e9tences sur nos solutions et nos m\u00e9tiers, des parcours apprenants sur notre plateforme digitale ainsi que des programmes d\u00e9di\u00e9s \u00e0 nos enjeux prioritaires, dont la sensibilisation aux sujets environnementaux avec la Climate School ;\n\u2022 Une vie sportive, artistique, musicale, ludique, caritative et engag\u00e9e : de notre salle de sport privatis\u00e9e \u00e0 nos expositions d\u2019art, en passant par des jeux vid\u00e9o et des concerts, ou encore les d\u00e9fis RSE sur la plateforme Vendredi. Toutes ces initiatives sont port\u00e9es par nos Eki.People ;\n\u2022 De nombreux \u00e9v\u00e8nements et s\u00e9minaires pour rester proche de votre communaut\u00e9 ;\n\u2022 Des locaux modernes dans un quartier dynamique au c\u0153ur de Paris (Grands boulevards) ;\n\u2022 Une politique de t\u00e9l\u00e9travail flexible.\n\ud83d\udd04Notre processus recrutement :\n\ud83d\udd38Un entretien RH avec un.e recruteur.se\n\ud83d\udd38Un test technique ou\npeer-to-peer\ninterview selon profil\n\ud83d\udd38Une \u00e9tude de cas avec un.e consultant.e\n\ud83d\udd38Un entretien final avec un.e Manager ou Partner\nNous serions ravi.e.s de vous donner de plus amples informations lors d\u2019un entretien et attendons votre candidature avec impatience!\nEn tant qu\u2019employeur, Ekimetrics offre \u00e0 tous les m\u00eames opportunit\u00e9s d\u2019acc\u00e8s \u00e0 l\u2019emploi sans distinction de genre, ethnicit\u00e9, religion, orientation sexuelle, statut social, handicap et d\u2019\u00e2ge. Ekimetrics veille \u00e0 d\u00e9velopper un environnement de travail inclusif qui refl\u00e8te la diversit\u00e9 dans ses \u00e9quipes.\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "R"
            ],
            "DataBase": [
                "SQL"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [
                "Spark",
                "Databricks"
            ],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [
                "AWS",
                "Azure"
            ],
            "DevTools": [
                "Git"
            ],
            "Os": [],
            "DBMS": [
                "Snowflake",
                "Snowflake"
            ],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [
                "DevOps",
                "Big Data",
                "ML",
                "Machine Learning",
                "Cloud"
            ],
            "FrSoftSkills": [
                "Cr\u00e9ativit\u00e9",
                "Organisation"
            ],
            "EnSoftSkils": [
                "Initiative"
            ]
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "Data Engineer confirm\u00e9 (H/F)",
        "company": "BforBank",
        "location": "Greater Paris Metropolitan Region",
        "link": "https://fr.linkedin.com/jobs/view/data-engineer-confirm%C3%A9-h-f-at-bforbank-3918327555?position=57&pageNum=0&refId=b67kRduAUeEfaeVnXh9rCA%3D%3D&trackingId=LptYbqbw0Nw1VKBD9c1ANw%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Sur le mod\u00e8le d'une\n\"Tech company\",\nBforBank place\nl'humain et le digital\nau c\u0153ur de sa transformation. Notre mission,\noffrir \u00e0 nos clients une exp\u00e9rience bancaire incomparable\npour r\u00e9pondre \u00e0 leurs besoins et usages mobile. \ud83c\udf1f \ud83d\udcf1\nRejoindre BforBank c\u2019est\nrejoindre une \u00e9quipe engag\u00e9e\ndans un\ngrand projet de d\u00e9veloppement strat\u00e9gique en France et en Europe.\nNous sommes aujourd\u2019hui 350 passionn\u00e9(e)s et\nrecherchons nos talents pour construire la banque de demain\n. \ud83d\ude80\nNous croyons en la force du collectif, chaque jour rassembl\u00e9s autour de nos valeurs, de simplicit\u00e9, d'optimisme et d\u2019engagement, encourageant chacun \u00e0 oser, essayer et accepter d\u2019\u00e9chouer.\n\ud83c\udfaf Au sein de la Direction Technologie, la Data Factory a pour objectifs de piloter, d\u00e9finir, d\u00e9ployer et op\u00e9rer les meilleures solutions technologiques r\u00e9pondant aux cas d\u2019usage data et d\u2019automatisations de processus de la banque au travers de plateformes. \u00c9galement, la Data Factory contribue au d\u00e9veloppement des produits, \u00e0 la cristallisation et \u00e0 la diffusion des pratiques au sein des Squads BforBank sur les usages data dans la banque.\nTu rejoindras une squad en charge de r\u00e9soudre des probl\u00e9matiques m\u00e9tiers en cr\u00e9ant des solutions applicatives utilisant les donn\u00e9es, des data products, avec pour finalit\u00e9s la prise de d\u00e9cision via des moteurs de calcul ou des dashboards, la cr\u00e9ation de flux r\u00e9glementaires, la cr\u00e9ation de data layer ou de reportings.\n\ud83d\ude80 Tes missions principales sont les suivantes :\n\u00b7 Participer aux analyses, \u00e9tudes d\u2019impacts et cadrage techniques\n\u00b7 Concevoir des solutions en respectant les bonnes pratiques d\u2019architecture data et d\u00e9veloppement\n\u00b7 R\u00e9aliser le d\u00e9veloppement de nouveaux data products et assurer la maintenance \u00e9volutive et corrective des data products existants\n\u00b7 R\u00e9diger la documentation technique des data products\n\u00b7 Assurer un support aux testeurs\n\u00b7 Reporter de ton activit\u00e9 \u00e0 ta Squad et travailler dans une d\u00e9marche d\u2019efficacit\u00e9 collective\nConcr\u00e8tement tu seras amen\u00e9(e) \u00e0 produire les livrables suivants :\n\u00b7 R\u00e9aliser du code applicatif \u00e0 l\u2019\u00e9tat de l\u2019art sur notre nouvelle Data Platform\n\u00b7 Cr\u00e9er des data layer et des rapports sur notre outil de Data Visualisation\n\u00b7 R\u00e9diger les documentations techniques li\u00e9es \u00e0 ta solution, incluant le mod\u00e8le de donn\u00e9es, les proc\u00e9dures, l\u2019ordonnancement\nCe que tu ma\u00eetrises :\n\u00b7 Maitrise des services manag\u00e9s de GCP (BigQuery, dataproc, dataflow, CloudSQL \u2026)\n\u00b7 Maitrise du langage Python, Pandas, Spark\n\u00b7 Maitrise de la mod\u00e9lisation de base de donn\u00e9es et du langage SQL\n\u00b7 Maitrise d\u2019une chaine CI/CD (GitLab\u2026)\n\u00b7 Bonne connaissance de Kafka\n\u00b7 Bonne connaissance d\u2019un outil d\u2019int\u00e9gration de donn\u00e9es type ETL (Informatica\u2026)\n\u00b7 Connaissance de l\u2019infra as code (Terraform)\n\u00b7 Connaissance d\u2019un outil de reporting (Looker, BO\u2026)\n\ud83e\udd1d Ce poste est fait pour toi si :\n\u00b7 Tu es passionn\u00e9(e) par la Data et leurs usages\n\u00b7 Tu es orient\u00e9 r\u00e9solution de probl\u00e8me, est curieux(se) et force de proposition\n\u00b7 Tu appr\u00e9cies le travail en \u00e9quipe\n\u00b7 Tu as un bon relationnel et est rigoureux(se)\n\u00b7 Tu as une bonne capacit\u00e9 d\u2019analyse et r\u00e9dactionnelle\n\u00b7 Tu t\u2019adaptes rapidement aux changements\n\ud83c\udf93\nFormation :\nTu es dipl\u00f4m\u00e9(e) d\u2019un master en \u00e9cole de commerce, \u00e9cole d\u2019ing\u00e9nieur ou \u00e9quivalent.\nChez BforBank nous recherchons avant tout des comp\u00e9tences. Tu ne disposes pas du dipl\u00f4me requis mais as des exp\u00e9riences \u00e9quivalentes ? N'h\u00e9site pas \u00e0 postuler !\n\ud83d\udcbc\nExp\u00e9rience :\nExp\u00e9rience confirm\u00e9e de 3 ans en tant que Data Engineer.\nEn rejoignant BforBank tu trouveras\u2026\n\u00b7 Un projet ambitieux de transformation digitale et culturelle \u00e0 l\u2019\u00e9chelon europ\u00e9en, terrain d\u2019innovation et d\u2019ouverture d\u2019esprit\n\u00b7 Une organisation apprenante, proposant un large choix de formations toute l\u2019ann\u00e9e, et qui favorise l\u2019\u00e9change avec les autres marques du Groupe\n\u00b7 Une promo RSE multi-m\u00e9tiers qui fait \u00e9voluer en continu les actions de BforBank vers une banque plus responsable\n\u00b7 Une organisation du travail en mode Agile, impliquant un degr\u00e9 \u00e9lev\u00e9 de collaboration et d'autonomie tout en travaillant avec un groupe de pairs diversifi\u00e9s.\n\u00b7 Une Direction Technologie en pleine expansion, porteuse de nombreux d\u00e9fis strat\u00e9giques\nMais aussi\u2026\nDe 2 jours \u00e0 5 jours de t\u00e9l\u00e9travail modulables par semaine, dans la limite de 84 jours par an (frais de fonctionnement pris en charge)\n25 jours de cong\u00e9s + 16 jours de RTT\n80% du co\u00fbt de la mutuelle d\u2019entreprise pris en charge / couvert\nAvantages collaborateurs Cr\u00e9dit Agricole : taux et tarifs pr\u00e9f\u00e9rentiels\nDes frais de transports rembours\u00e9s \u00e0 75%\nUn restaurant d\u2019entreprise\nDes douches pour les sportifs et un tarif avantageux aupr\u00e8s d\u2019une salle de sport toute proche\n\ud83d\udccd Le poste est bas\u00e9 \u00e0 La D\u00e9fense, dans des locaux flambant neufs !\nBforBank s'engage \u00e0 garantir l'\u00e9galit\u00e9 des chances aux candidats car nous sommes convaincus de la richesse apport\u00e9e par la diversit\u00e9 et l'inclusion dans nos \u00e9quipes.\nRencontrons-nous !\nLe processus de recrutement se d\u00e9roule en 4 \u00e9tapes :\n\ud83e\uddd1\ud83c\udffc\u200d\ud83d\udcbb\nCall de 30 minutes avec notre \u00e9quipe Talent Acquisition\nEchange avec le Data Factory Manager et notre \u00e9quipe Talent Acquisition (pr\u00e9sentiel)\nEchange avec une personne de l\u2019\u00e9quipe avec qui tu seras amen\u00e9 \u00e0 travailler (visio)\nEchange avec le CTO (visio ou pr\u00e9sentiel)\nNotre processus de recrutement dure en moyenne 3 semaines et l\u2019\u00e9quipe Talent Acquisition se tiendra \u00e0 ta disposition pour te donner un maximum de visibilit\u00e9 sur l\u2019avanc\u00e9e du process.\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "R",
                "Go"
            ],
            "DataBase": [
                "SQL"
            ],
            "DataAnalytics": [
                "Pandas",
                "R"
            ],
            "BigData": [
                "Spark"
            ],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [],
            "DevTools": [
                "Git"
            ],
            "Os": [],
            "DBMS": [
                "BigQuery"
            ],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [
                "Terraform"
            ],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [
                "Cloud",
                "CI/CD"
            ],
            "FrSoftSkills": [
                "Collaboration",
                "Organisation"
            ],
            "EnSoftSkils": [
                "Collaboration"
            ]
        },
        "details": {
            "JobDetail": [
                "Confirm\u00e9"
            ],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s",
                "3",
                "3",
                "3"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "(Senior) Data Engineer",
        "company": "Mirakl",
        "location": "Paris, \u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/senior-data-engineer-at-mirakl-3904071960?position=58&pageNum=0&refId=b67kRduAUeEfaeVnXh9rCA%3D%3D&trackingId=bdr9XDUp3RnH9V7yglXQrg%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Mirakl, leader et pionnier de l\u2019\u00e9conomie de plateforme, propose aux entreprises une suite unique de solutions leur permettant de transformer significativement leur e-commerce afin d'acc\u00e9l\u00e9rer de fa\u00e7on durable et rentable leur croissance. Depuis 2012, Mirakl accompagne les entreprises B2C et B2B avec la technologie la plus avanc\u00e9e, s\u00e9curis\u00e9e et \u00e9volutive leur permettant de digitaliser leur activit\u00e9 et d'\u00e9largir leur offre via la marketplace ou le dropship, faciliter la gestion des catalogues et des paiements de leurs fournisseurs pour plus d'efficacit\u00e9, offrir une exp\u00e9rience d'achat personnalis\u00e9e \u00e0 leurs clients, et augmenter leurs profits gr\u00e2ce au retail media. Bas\u00e9e \u00e0 Paris et Boston, Mirakl est certifi\u00e9e Great Place to Work.\nA propos de Mirakl Labs\nNos \u00e9quipes techniques et produits, nomm\u00e9es Mirakl Labs, sont principalement r\u00e9parties entre nos 2 hubs situ\u00e9s \u00e0 Paris et \u00e0 Bordeaux. Elles collaborent au quotidien afin d'adresser les probl\u00e9matiques de nos clients et utilisateurs en r\u00e9pondant \u00e0 diff\u00e9rents challenges li\u00e9s aux nouvelles fonctionnalit\u00e9s, \u00e0 la scalabilit\u00e9, la s\u00e9curit\u00e9 et l\u2019ergonomie\u2026\nElles op\u00e8rent en mode agile et s'organisent en Squads compos\u00e9es d'un Squad Lead, de 5 d\u00e9veloppeurs, d'un Product Manager et d'un QA. Chaque Squad est sp\u00e9cialis\u00e9e sur un scope fonctionnel afin de concevoir et r\u00e9aliser de nouvelles features, leurs \u00e9volutions et des APIs (avec un d\u00e9coupage en micro-services). Nos \u00e9quipes Infrastructure, Architecture, S\u00e9curit\u00e9, Documentation, Product Design, Data et Support op\u00e8rent en transverse en apportant leur expertise et de la coh\u00e9rence sur l\u2019ensemble des produits.\nToutes les \u00e9quipes sont responsables de leur p\u00e9rim\u00e8tre et chacun des collaborateurs apporte son exp\u00e9rience et ses id\u00e9es. Innovation, feedback et implication dans les prises de d\u00e9cision sont au c\u0153ur de notre philosophie.\nEt pour favoriser ce partage avec d\u2019autres passionn\u00e9s, nous sommes sponsors, speakers, et h\u00f4tes de diff\u00e9rents \u00e9v\u00e9nements, meetups, et associations de la sc\u00e8ne Tech en France. Au cours des derni\u00e8res ann\u00e9es, nous avons particip\u00e9 \u00e0 des \u00e9v\u00e9nements tels que Devoxx, ReactEurope, ProductConf et Flupa UX Days.\nA propos du job\nLa solution SaaS Mirakl est le moteur des marketplaces des plus importants e-commer\u00e7ants \u00e0 travers le monde. Cette solution g\u00e8re et produit de gros volumes de donn\u00e9es qui pr\u00e9sentent des challenges extr\u00eamement int\u00e9ressants pour les sp\u00e9cialistes de la donn\u00e9e (produits, commandes, clients, niveaux de stock, prix, messages, appels API, donn\u00e9es de navigation, s\u00e9ries temporelles, donn\u00e9es g\u00e9olocalis\u00e9es etc.).\nEn tant que (Senior) Data Engineer au sein de l\u2019\u00e9quipe Data Mirakl, vos principales missions seront de :\ncontribuer \u00e0 l'enrichissement de la Data Platform (ETL)\nam\u00e9liorer la robustesse de nos pipelines de production pour nos applications Machine Learning (inf\u00e9rence real time etc.)\nInt\u00e9gr\u00e9(e) dans une \u00e9quipe de sp\u00e9cialistes de la donn\u00e9e (data engineers, machine learning engineers, data scientists, data analysts), vous \u00eates un des acteurs cl\u00e9s pour garantir la place de Mirakl comme solution dominante sur son march\u00e9.\nNotre stack et nos outils\nApache Spark, Kafka, AWS, Databricks, Python, Airflow, Mlflow, Tensorflow, Delta lake, Superset, Kubernetes, Redshift, SQL, Terraform, Ansible\nAu quotidien, vous allez :\nParticiper \u00e0 la d\u00e9finition et \u00e0 l\u2019impl\u00e9mentation d\u2019une architecture performante, robuste, scalable et aux co\u00fbts ma\u00eetris\u00e9s pour nos applications Spark ainsi que pour nos pipelines de production de Machine Learning (\u00e9valuation des feature stores, refactoring de DAG Airflow)\nAccompagner les Data Scientists lors de leur mise en production (relecture de code, pair programming) et mettre en place les best practices\nOptimiser et am\u00e9liorer la CI/CD de l\u2019\u00e9quipe en collaboration avec l\u2019\u00e9quipe SRE\nAssurer la mont\u00e9e en comp\u00e9tence des membres de l\u2019\u00e9quipe sur les sujets de MLOps et Data Engineering\nR\u00e9fl\u00e9chir \u00e0 la meilleure fa\u00e7on d'int\u00e9grer les donn\u00e9es Google Analytics dans la data platform\nPartager ses connaissances et pr\u00e9senter les travaux devant toutes les \u00e9quipes Labs\nCe qu\u2019on peut vous apporter :\nDes projets data driven, divers et vari\u00e9s (traitements massifs d\u2019images, de textes, time series etc.) pour des produits diff\u00e9rents de Mirakl\nUne culture orient\u00e9e sur la veille technologique\nDes projets qui ont un vrai impact business devant \u00eatre d\u00e9ploy\u00e9s sur des centaines de clients dans un contexte multilingue\nQuelques exemples de sujets en cours :\nEnrichissement des donn\u00e9es produit \u00e0 partir des images et des descriptions\nMod\u00e9ration automatique des produits\nMapping automatique des donn\u00e9es produit\nIdentification des produits \u00e0 fort potentiels\nD\u00e9tection de comportements frauduleux\nSentiment analysis sur les messages \u00e9chang\u00e9s entre clients et vendeurs et dans les \u00e9valuations\nD\u00e9termination de prix optimaux\nMonitoring de la qualit\u00e9 de service des vendeurs\nDes applications d\u2019inf\u00e9rence en synchrone de nos mod\u00e8les de ML\nVous aimerez ce job si :\nVous \u00eates passionn\u00e9(e) par la data et les technologies modernes permettant d'en tirer partie\nVous vous int\u00e9ressez \u00e0 la data science et avez des connaissances g\u00e9n\u00e9rales sur les algorithmes de Machine Learning\nVous avez un background en d\u00e9veloppement et avez \u00e9volu\u00e9 dans un environnement Data\nVous avez a minima 4 ans d\u2019exp\u00e9rience en environnement Machine Learning et/ou Data\nVous avez mis en production avec succ\u00e8s des applications Big Data faisant appel \u00e0 du Machine Learning, du NLP, du traitement d\u2019images dans des projets d'envergure, \u00e0 fort volume de donn\u00e9es\nVotre ma\u00eetrisez Python, \u00eates un pro des frameworks data de la fondation Apache et \u00eates \u00e0 l'aise dans un environnement AWS\nVous ma\u00eetrisez au moins un outil d\u2019orchestration (Airflow, Data Pipeline ou tout autre outil similaire)\nVous pr\u00e9sentez vos travaux de mani\u00e8re simple et accessible\nVous fa\u00eetes preuve d'un bon relationnel et vous aimez mentorer des collaborateurs\nVous parlez couramment anglais et fran\u00e7ais\nLes plus pour le poste :\nVous avez une exp\u00e9rience significative dans le domaine du e-commerce\nVous avez d\u00e9j\u00e0 mis en place un Data Lake, Data Warehouse ou une Data Platform\nVous avez d\u00e9ploy\u00e9 des applicatifs en environnement Kubernetes\nVous avez mis en place des pipelines d'ingestion de donn\u00e9es avec une approche CDC \u00e0 l'aide de Debezium ou autre\nVous ma\u00eetrisez Java/Scala\nMirakl est engag\u00e9e en faveur de la diversit\u00e9, de l\u2019\u00e9galit\u00e9 des chances et de l\u2019inclusion. Nous c\u00e9l\u00e9brons nos diff\u00e9rences car nous sommes convaincus que les qualit\u00e9s visibles et invisibles de chaque Mirakl Worker sont une source de force et d\u2019innovation. Dans le cadre de cet engagement, nous \u00e9tudions toutes les candidatures sans distinction de : genre, ethnicit\u00e9, religion, orientation sexuelle, handicap, \u00e2ge ou toute autre caract\u00e9ristique prot\u00e9g\u00e9e par la loi.\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "Java",
                "Scala",
                "R",
                "Go"
            ],
            "DataBase": [
                "SQL"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [
                "Spark",
                "Databricks"
            ],
            "MachingLearning": [
                "TensorFlow"
            ],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [
                "AWS"
            ],
            "DevTools": [
                "Git"
            ],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [
                "Ansible",
                "Kubernetes",
                "Airflow"
            ],
            "InfrastructureAsCode": [
                "Terraform"
            ],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [
                "Kubernetes"
            ],
            "Collaboration": [],
            "Other": [
                "Big Data",
                "ML",
                "Machine Learning",
                "CI/CD"
            ],
            "FrSoftSkills": [
                "Collaboration"
            ],
            "EnSoftSkils": [
                "Collaboration"
            ]
        },
        "details": {
            "JobDetail": [
                "Senior"
            ],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s",
                "4",
                "4",
                "4"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "Data Engineer | Python - Azure | IA & Machine Learning  | Paris ou Remote Partiel",
        "company": "Octopus IT - Expert du recrutement tech",
        "location": "Paris, \u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/data-engineer-python-azure-ia-machine-learning-paris-ou-remote-partiel-at-octopus-it-expert-du-recrutement-tech-3664568765?position=59&pageNum=0&refId=b67kRduAUeEfaeVnXh9rCA%3D%3D&trackingId=lfoaC1fMJXcvWcFxm77Xmg%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "La soci\u00e9t\u00e9\nCr\u00e9\u00e9e il y a plus de 2 ans, cette startup est la premi\u00e8re base de connaissance intelligente d\u00e9di\u00e9e aux services clients. Leur mission ? En finir avec la frustration lorsque l'on contact un Help Desk.\nPour cela, elle propose aux entreprises la possibilit\u00e9 de d\u00e9livrer une exp\u00e9rience client d'exception : rapide et de qualit\u00e9. Gr\u00e2ce \u00e0 leur moteur de recherche intelligent, cette entreprise est capable de centraliser toute la connaissance interne de l'entreprise (proc\u00e9dures, produits, modes op\u00e9ratoires, etc.) et la diffuse intelligemment dans les outils de production des conseillers de service client.\nR\u00e9sultat :\nPlus besoin de chercher l'information\nDes r\u00e9ponses instantan\u00e9es et de meilleures qualit\u00e9es\nUne autonomie totale des collaborateurs\nApr\u00e8s une croissance fulgurante, elle a su s\u00e9duire \u00e0 la fois de nombreuses scale up (Luko, OpenClassrooms, Japhy...) et grands groupes (BNP Paribas, La Poste, Fnac Darty...).\nApr\u00e8s le recrutement de leur Lead Data (r\u00e9aliser ensemble) et suite \u00e0 l'annonce de leur lev\u00e9e de 2,5M\u20ac pour tripler la taille de ses \u00e9quipes, le but est maintenant de s'imposer tr\u00e8s vite comme la base de connaissance de r\u00e9f\u00e9rence en France et en Europe. Pour ce faire, nous recherchons un Data Engineer.\nLe poste\nEn travaillant main dans la main avec le Lead Data, ta mission sera de d\u00e9velopper et de maintenir des flux de donn\u00e9es complexes et robustes. La donn\u00e9e \u00e9tant au coeur de l' entreprise, dans le produit comme dans la strat\u00e9gie, tu seras amen\u00e9 \u00e0 travailler avec un panel d\u2019interlocuteurs tr\u00e8s vari\u00e9s :\nData Scientists sur des sujets comme le monitoring des mod\u00e8les de production et l\u2019enrichissement des donn\u00e9es d\u2019entrainement.\nProduct Team sur des sujets de performance et d\u2019acheminement de donn\u00e9es au service de fonctionnalit\u00e9s produit telles que le dashboard d\u2019analytics \u00e0 destination de nos clients.\nCustomer Success / Strategy sur des sujets de pilotage comme le suivi de l\u2019utilisation de notre plateforme ou la mise en place de KPIs de performance.\nTu travailleras sur les probl\u00e9matiques suivantes :\nTu seras responsable de notre architecture de donn\u00e9es et de son outillage, mais aussi de la mise en place de pipelines de donn\u00e9es complexes et robustes.\nTu seras amen\u00e9 \u00e0 mettre en place des outils de monitoring et d\u2019alerting pour suivre de pr\u00e8s nos nombreuses pipelines de donn\u00e9e.\nTu seras garant de la qualit\u00e9 de nos donn\u00e9es en assurant l\u2019application des guidelines de code et des tests automatis\u00e9s pour chacune de nos pipelines.\nTu seras amen\u00e9 \u00e0 mettre en place des outils de reporting / insights \u00e0 destination d\u2019interlocuteurs vari\u00e9s (Data Science, Product, Customer Success, Clients, etc.).\nTu cr\u00e9eras et d\u00e9velopperas des pipelines de donn\u00e9es avec des outils de scheduling et d\u2019orchestration.\nLa stack sur laquelle vous travaillerez :\nLangage : Python, Javascript\nFramework data : PyTorch, Transformers (Hugging Face), FastAPI\nDatabase : PostgreSQL, MongoDB, ElasticSearch, Redis\nInfrastructure : Azure, Docker, Kubernetes, Spark, RabbitMQ, Serverless, Terraform\nEnvironnement / Test : PyTest, Gitlab (git + ci/cd)\nBI : Metabase, Superset\nVotre profil\nEntre 1 et 3 ans d'exp\u00e9rience en CDI\nTu as une exp\u00e9rience significative sur des probl\u00e9matiques de Data engineering\nTu es quelqu'un de pragmatique\nUn tr\u00e8s bon niveau en Python et une tr\u00e8s bonne rigueur dans le code\nBonne pratique de dev : clean code, TDD, BDD\nUne bonne culture Ops\nUne logique cloud (Aws, GCP ou Azure)\nLe salaire & avantages\n50-7O K\u20ac selon exp\u00e9rience\nRTT\nCarte Swile & Mutuelle\n2/3 jours de t\u00e9l\u00e9travail par semaine\nEt plus encore\u2026\nCe qu\u2019on pr\u00e9f\u00e8re\n\u00catre impliqu\u00e9 \u00e0 fond dans une aventure avec de nombreux challenges techniques\nBelles opportunit\u00e9s d'\u00e9volutions sur des postes d'Architecte, de Lead ou de Ml Ops\nBeaucoup de workshops en interne et catalogue de formations \u00e0 votre guise\nUne opportunit\u00e9 de travailler sur un produit unique qui a d\u00e9j\u00e0 s\u00e9duit de tr\u00e8s beaux clients (BNP Paribas, Fnac Darty, Luko, OpenClassrooms)\nLa possibilit\u00e9 de travailler sur une stack tr\u00e8s moderne, des probl\u00e9matiques complexes aussi bien en traitement de donn\u00e9es, qu'en DevOps\nUn plan de BSPCE (actions de l'entreprise) tr\u00e8s int\u00e9ressant et motivant !\nUne culture d'entreprise fond\u00e9e sur l'apprentissage, l'autonomie, la bienveillance et l'exigence\nLe fait de travailler au quotidien avec des fondateurs passionn\u00e9s par leur domaine d'expertise\nCe poste a \u00e9t\u00e9 soigneusement choisi par votre coach. Powered by Octopus IT, cabinet d\u2019Experts en Recrutement Tech (CDI et clients finaux uniquement) \u2013 Visitez nous pour plus d\u2019opportunit\u00e9s :\nwww.octopusit.fr\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "Java",
                "R",
                "Go",
                "JavaScript"
            ],
            "DataBase": [
                "SQL",
                " MongoDB",
                "Elasticsearch"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [
                "Spark"
            ],
            "MachingLearning": [
                "PyTorch"
            ],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [
                "AWS",
                "Azure"
            ],
            "DevTools": [
                "Git",
                "Docker"
            ],
            "Os": [],
            "DBMS": [
                "PostgreSQL"
            ],
            "SoftBigDataProcessing": [],
            "Automation": [
                "Kubernetes"
            ],
            "InfrastructureAsCode": [
                "Terraform"
            ],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [
                "Docker",
                "Kubernetes"
            ],
            "Collaboration": [],
            "Other": [
                "DevOps",
                "ML",
                "Cloud",
                "CI/CD"
            ],
            "FrSoftSkills": [],
            "EnSoftSkils": []
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [
                "CDI"
            ],
            "Salary": [
                "50"
            ],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s",
                "2",
                "2",
                "2"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "Data Engineer (H/F) - Lille",
        "company": "Logic@l Conseils",
        "location": "Lille, Hauts-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/data-engineer-h-f-lille-at-logic%40l-conseils-3811575649?position=60&pageNum=0&refId=b67kRduAUeEfaeVnXh9rCA%3D%3D&trackingId=7mvmlHBKdLio1X1VzQ1izQ%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Dans le cadre du d\u00e9veloppement de nos activit\u00e9s sur la m\u00e9tropole Lilloise, nous recherchons un\nconsultant data engineer\n(H/F) pour intervenir chez l'un de nos grands comptes clients.\nVos missions :\nRecueillir\nles besoins m\u00e9tiers et des \u00e9quipes data\nConcevoir et mettre en place les\ntraitements de donn\u00e9es\nR\u00e9aliser les\ntests de validation\nAssurer\nl\u2019alimentation du dataware\nR\u00e9aliser les\nordonnancements des traitements\nEtre garant de la\nmise en place\n, du\nsuivi\net de l\u2019\nexploitation\ndes outils d\u00e9ploy\u00e9s\nAssurer\nune veille technologique\nr\u00e9guli\u00e8re\nEnvironnement technique :\nD\u00e9veloppement :\nPython, Scala, R, Java,\nFramework :\nSpark,\nHadoop,\nOutils Big data :\nYarn, Pig, Hive, Kafka, Splunk\nBases de donn\u00e9es :\nMongoDB, HBase, Cassandra\nETL :\nTalend, Stambia\nPlateforme :\nHortonworks, Cloudera, Map Reduce\n,\nAWS, GCP, Azure\nVotre profil :\nVous disposez d\u2019une exp\u00e9rience\nd\u2019au moins 2 ans en tant que data engineer\nou dans le domaine de l\u2019analyse et du traitement de donn\u00e9es.\nV\u00e9ritable\npassionn\u00e9 de la data\n, vous \u00eates\nforce de proposition\nsur les solutions techniques \u00e0 mettre en \u0153uvre. Vous maitrisez l\u2019anglais dans un contexte professionnel.\nComp\u00e9tences requises :\nAnalyses qualitatives et quantitatives (Interm\u00e9diaire)\nAnglais (Interm\u00e9diaire)\nArchitecture fonctionnelle SI (D\u00e9butant)\nD\u00e9veloppement d'ouvrages, produits ou \u00e9v\u00e9nements (D\u00e9butant)\nGestion des contr\u00f4les, tests et diagnostics (D\u00e9butant)\nGestion des risques (Interm\u00e9diaire)\nMa\u00eetrise des logiciels (Interm\u00e9diaire)\nMise en exploitation / Production et maintenance (D\u00e9butant)\nNos valeurs\nNous avons d\u00e9cid\u00e9 de renverser la pyramide du management pour placer nos collaborateurs en t\u00eate des priorit\u00e9s de l\u2019entreprise.\nEn effet, attach\u00e9 \u00e0 des valeurs fortes, telles que la proximit\u00e9, la sinc\u00e9rit\u00e9, la fid\u00e9lit\u00e9, la confiance et le respect, nous sommes persuad\u00e9s que la r\u00e9ussite r\u00e9side dans le bien-\u00eatre de nos collaborateurs.\nCela se traduit par un accompagnement de proximit\u00e9, de la transparence sans langue de bois, des \u00e9changes r\u00e9guliers avec les managers r\u00e9f\u00e9rents, un accompagnement dans le d\u00e9veloppement de carri\u00e8re qui est construit et jalonn\u00e9 avec les formations et certifications n\u00e9cessaires et les missions en ad\u00e9quation, pour mener \u00e0 bien l\u2019\u00e9volution de carri\u00e8re.\nPour vous convaincre de nous rejoindre, nos avantages salari\u00e9s compl\u00e9mentaires :\nEnvironnement bienveillant et stimulant au sein de 3 p\u00f4les d\u2019expertises\nFormations et Certifications \u00e0 la demande\nTickets restaurants : 13\u20ac par ticket\nRemboursement \u00e0 100 % des abonnements de transports en commun\nMutuelle frais de sant\u00e9 avec de hautes garanties\nPrise en charge \u00e0 100% de l\u2019assurance Pr\u00e9voyance\nCh\u00e8que Cadeau Culture 120 \u20ac\nCompte CSE avec une cagnotte de 390 \u20ac\nCompte CE : billetterie, voyages, culture, sorties, \u00e0 des tarifs pr\u00e9f\u00e9rentiels\nDes \u00e9v\u00e8nements chaque mois : activit\u00e9s associatives, sportives, afterwork, s\u00e9minaire,\nPartenariat Losc (participation aux match dans la loge VIP logical conseils \u2013 (Une Vingtaine de match par an)\nPossibilit\u00e9 de t\u00e9l\u00e9travail\nEn int\u00e9grant Logic@l Conseils, vous participez \u00e0 une r\u00e9elle aventure humaine, alors pour postuler, il suffit de cliquer ci-dessous !\nTous nos postes sont ouverts, \u00e0 comp\u00e9tences \u00e9gales, aux personnes en situation de handicap.\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "Java",
                "Scala",
                "R",
                "Go"
            ],
            "DataBase": [
                "Cassandra",
                "HBase"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [
                "Hadoop",
                "Spark"
            ],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [
                "AWS",
                "Azure"
            ],
            "DevTools": [],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [
                "HBase"
            ],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [
                "Big Data",
                "Cloud"
            ],
            "FrSoftSkills": [],
            "EnSoftSkils": []
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s",
                "2",
                "2",
                "2"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "Data Engineer BI - Nantes",
        "company": "Capgemini",
        "location": "Nantes, Pays de la Loire, France",
        "link": "https://fr.linkedin.com/jobs/view/data-engineer-bi-nantes-at-capgemini-3803963477?position=1&pageNum=2&refId=5U0uFfx%2F5Nb5dx3Ih9znKA%3D%3D&trackingId=7SpGJA5uenzj7a4NzhHATw%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Capgemini\nChoisir Capgemini, c'est choisir une entreprise o\u00f9 vous serez en mesure de fa\u00e7onner votre carri\u00e8re selon vos aspirations, o\u00f9 vous serez soutenu et inspir\u00e9 par une communaut\u00e9 d\u2019experts dans le monde entier, o\u00f9 vous pourrez r\u00e9\u00e9crire votre futur. Rejoignez-nous pour red\u00e9finir les limites de ce qui est possible, contribuer \u00e0 lib\u00e9rer la valeur de la technologie pour les plus grandes organisations et participez \u00e0 la construction d\u2019un monde plus durable et inclusif.\nVos missions :\nInt\u00e9gr\u00e9(e) au sein d\u2019une \u00e9quipe projet BI, Big Data ou Data Gouvernance pour des clients intervenant dans des secteurs d'activit\u00e9s divers, vous serez notamment en charge des missions suivantes :\nMener les analyses fonctionnelles destin\u00e9es \u00e0 traduire les besoins du client,\nMener les travaux de conception et de mod\u00e9lisation,\nDiriger le d\u00e9veloppement de la solution / des traitements d'alimentation du DataWareHouse,\nOrganiser et pr\u00e9parer les travaux de recette utilisateurs,\nMettre en place les processus d'industrialisation et mener cette derni\u00e8re.\nVotre profil :\nDipl\u00f4me d\u2019ing\u00e9nieur ou \u00e9quivalent universitaire\nMinimum 3 ans d'exp\u00e9rience\nAnglais courant\nComp\u00e9tences en BI sur SAP BI (Hana, BW, BODS, BI 4), Microsoft BI (SQL Server, SSIS, SSAS, SSRS), Oracle (ODI, OBIEE), Teradata, Informatica (Powercenter), IBM (Datastage, Cognos, TM1), Talend, AB Initio\nMa\u00eetrise d'un ou de plusieurs outils de Dataviz : Microsoft Power BI, Tableau, Qlikview\nConnaissances en Big Data (Ecosyst\u00e8me Hadoop (HIVE, PIG, Mahout\u2026), Cloudera, Pivotal, Spark, HNX) ou en analytics (R, SAS, IBM SPSS)\n3 raisons de nous rejoindre :\nQualit\u00e9 de vie au travail : accord de t\u00e9l\u00e9travail en France et \u00e0 l\u2019international, accord sur l\u2019\u00e9galit\u00e9\nprofessionnelle, la parentalit\u00e9, l\u2019\u00e9quilibre des temps et la mobilit\u00e9 durable.\nApprentissage en continu : certifications et formations en libre acc\u00e8s, accompagnement sur mesure avec votre carreer manager, parcours d\u2019int\u00e9gration sur 9 mois.\nAvantages groupe & CSE : plan actionnariat, activit\u00e9s \u00e0 tarifs pr\u00e9f\u00e9rentiels, remboursement partiel\nvacances, remboursement de votre abonnement sportif ou culturel.\nNos engagements et priorit\u00e9s :\nLe groupe Capgemini encourage une culture inclusive dans un cadre multiculturel et handi-accueillant. En nous rejoignant, vous int\u00e9grez un collectif qui valorise la diversit\u00e9, d\u00e9veloppe le potentiel de ses talents, s\u2019engage dans des initiatives solidaires avec ses partenaires, et se mobilise pour r\u00e9duire son impact environnemental sur tous ses sites et aupr\u00e8s de ses clients.\nCapgemini\nCapgemini est un leader mondial, responsable et multiculturel, regroupant pr\u00e8s de 350 000 personnes dans plus de 50 pays. Fort de 55 ans d\u2019exp\u00e9rience, nous sommes un partenaire strat\u00e9gique des entreprises pour la transformation de leurs activit\u00e9s en tirant profit de toute la puissance de la technologie et des innovations dans les domaines en perp\u00e9tuelle \u00e9volution tels que le cloud, la data, l\u2019Intelligence Artificielle, la connectivit\u00e9, les logiciels, l\u2019ing\u00e9nierie digitale ou les\nplateformes.\nGet The Future You Want* | www.capgemini.com/fr-fr\n*Capgemini, le futur que vous voulez\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "R",
                "Go"
            ],
            "DataBase": [
                "SQL"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [
                "Hadoop",
                "Spark"
            ],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [
                "Tableau",
                "Power BI"
            ],
            "Statistics": [],
            "CloudComputing": [],
            "DevTools": [
                "Git"
            ],
            "Os": [],
            "DBMS": [
                "Oracle",
                "SQL Server"
            ],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [
                "Big Data",
                "Cloud"
            ],
            "FrSoftSkills": [
                "Organisation"
            ],
            "EnSoftSkils": [
                "Initiative"
            ]
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s",
                "3",
                "3",
                "3"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "Data Engineer (H/F)",
        "company": "Beelix",
        "location": "Antibes, Provence-Alpes-C\u00f4te d'Azur, France",
        "link": "https://fr.linkedin.com/jobs/view/data-engineer-h-f-at-beelix-3838611420?position=2&pageNum=2&refId=5U0uFfx%2F5Nb5dx3Ih9znKA%3D%3D&trackingId=sfIXeaz3U1LEHTkwKKru%2BQ%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Qui sommes-nous ?\nDepuis 2016, nous accompagnons nos clients sur des probl\u00e9matiques de Product Management, Data et Design Thinking. Beelix contribue \u00e0 fa\u00e7onner le monde de demain en participant aux grandes avanc\u00e9es des secteurs suivants :\n\ud83d\ude97Automobile\n\u26a1Energie\n\ud83d\udce1M\u00e9dias & T\u00e9l\u00e9coms\n\ud83d\udc57Luxe & Retail\n\ud83d\udcb6 Banque, Finance & Assurance\n\u2708\ufe0fD\u00e9fense\nAujourd\u2019hui, Beelix compte plus de 200 collaborateurs motiv\u00e9s et dynamiques. Lab\u00e9lis\u00e9e Great Place To work en 2023, Beelix est aussi une entreprise engag\u00e9e o\u00f9 il fait bon vivre.\nDans le cadre de notre d\u00e9veloppement, nous recherchons un Data Engineer (H/F) pour l'un de nos clients.\nQuelles missions au quotidien ?\n\u00catre le leader de la brique Datalakehouse\nD\u00e9velopper les scripts de transformations de donn\u00e9es et les pipelines d\u2019alimentation\nProposer des \u00e9volutions architecturales ou de fonctionnalit\u00e9s pour am\u00e9liorer le socle technique\n\u00catre le back-up du leader technique sur la partie reporting (Power BI)\nOrientation satisfaction client et r\u00e9sultat final forte mais \u00e9galement sensibilit\u00e9 au \u00ab comment \u00bb\nInnovation et proposition de nouvelles pratiques pour am\u00e9liorer l\u2019environnement et les conditions de travail des \u00e9quipes\nA propos de vous ?\n5 + ann\u00e9es d'exp\u00e9rience en tant que Data Engineer\nMa\u00eetrise des technologies suivantes : Microsoft Azure, Microsoft Azure Synapse Analytics (Spark / Python / Pipeline / Serverless), fichiers parquet / delta, Microsoft Power BI, Microsoft SQL Server, langage SQL, Datawarehousing / Mod\u00e9lisation de donn\u00e9es\nAnalyses et export de donn\u00e9es\nConnaissance de l\u2019ensemble du processus depuis la collecte jusqu\u2019\u00e0 la mise \u00e0 disposition des donn\u00e9es en ayant comme point fort la maitrise de sa transformation et mise en forme\nVous avez un bon niveau d\u2019anglais\nLocalisation : Biot et/ou Carros\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "R"
            ],
            "DataBase": [
                "SQL"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [
                "Spark"
            ],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [
                "Power BI"
            ],
            "Statistics": [],
            "CloudComputing": [
                "Azure"
            ],
            "DevTools": [],
            "Os": [],
            "DBMS": [
                "SQL Server"
            ],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [],
            "FrSoftSkills": [],
            "EnSoftSkils": []
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "Data Engineer",
        "company": "Digital Waffle",
        "location": "Paris, \u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/data-engineer-at-digital-waffle-3913824888?position=3&pageNum=2&refId=5U0uFfx%2F5Nb5dx3Ih9znKA%3D%3D&trackingId=fba8MFee7aoxkZLGja%2BWZg%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Digital Waffle is proud to have partnered with an innovative tech startup in Paris, who are looking for a talented Data Engineer to join their growing team!\nThey are made up of a powerhouse of experts, combining\ndata engineers, business process gurus, and Project managers\nwho leverage the most advanced solutions available; utilising process mining, automation tools, and smart execution systems.\nLooking for an experienced Data Engineer (3-5 years)\nWhat You'll Do:\nThis is a full-time,\nhybrid role (Paris-based)\nwhere you'll wear many hats: data exploration, system integration, data prep, data modeling, and implementing data solutions.\nExperience:\nExpertise in data engineering, data modeling, and ETL (Extract, Transform, Load) processes\nData warehousing and data analytics skills\nExperience handling large, complex datasets\nProficiency in SQL and programming languages like Python or Java\nStellar problem-solving and analytical skills\nTop-notch communication and collaboration abilities\nBachelor's or Master's in Computer Science, Information Systems, or a similar field (a plus for process mining or intelligent process automation experience)\nIf you are an experienced and driven Data Engineer, please apply here!\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "Java",
                "R"
            ],
            "DataBase": [
                "SQL"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [],
            "DevTools": [
                "Git"
            ],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [],
            "FrSoftSkills": [
                "Communication",
                "Collaboration"
            ],
            "EnSoftSkils": [
                "Communication",
                "Collaboration"
            ]
        },
        "details": {
            "JobDetail": [
                "Full"
            ],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "Data Engineer (H/F)",
        "company": "Scalian",
        "location": "Valbonne, Provence-Alpes-C\u00f4te d'Azur, France",
        "link": "https://fr.linkedin.com/jobs/view/data-engineer-h-f-at-scalian-3819563847?position=4&pageNum=2&refId=5U0uFfx%2F5Nb5dx3Ih9znKA%3D%3D&trackingId=8DPeW3FeRfB3CDPMsZLmIw%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Ing\u00e9nieur DATA / Data engineer (H/F)\nValbonne/Sophia-Antipolis\nType : CDI\nLieu : Locaux Scalian Sophia-Antipolis\nT\u00e9l\u00e9travail : En fonction des possibilit\u00e9s\nDate de prise de poste : imm\u00e9diatement ou en fonction de votre pr\u00e9avis\nSalaire : en fonction du profil - entre 40 et 48K Brut annuels (hors avantages Scalian)\nAvantages Scalian : Accord d'entreprise t\u00e9l\u00e9travail, Tickets restaurants, Mutuelle groupe, accord am\u00e9nagement temps de travail, compte \u00e9pargne temps, accord de participation et int\u00e9ressement groupe, programme cooptation et apports d'affaires, accompagnement parentalit\u00e9, avantages CSE\nVous \u00eates data engineer ou vous souhaitez le devenir !\nQuel sera votre r\u00f4le ?\nLa port\u00e9e de la mission comprend (sans toutefois s'y limiter) :\nScience des donn\u00e9es\nIng\u00e9nierie des donn\u00e9es\nAnalyse des donn\u00e9es\nG\u00e9nie logiciel\nCe que cette exp\u00e9rience va vous apporter\nVous \u00eates autonome, vous avez le sens du service et de l\u2019analyse, vous \u00eates impliqu\u00e9, nous vous offrons une ouverture sur des projets complexes et une rapide \u00e9volution de carri\u00e8re. Vous rejoignez notre business unit \u00e0 Sophia Antipolis compos\u00e9e d'environ 50 consultants, avec possibilit\u00e9 de t\u00e9l\u00e9travail en fonction des sujets.\nNous co-construisons votre trajectoire professionnelle et assurons votre mont\u00e9e en comp\u00e9tences.\nNous nous inscrivons ensemble dans la dur\u00e9e, nous assurons votre mont\u00e9e en comp\u00e9tences et disposons d'une vari\u00e9t\u00e9 de sujets passionnants.\nCe que nous recherchons chez vous\nDe formation sup\u00e9rieure (Bac+5, \u00e9cole ou universit\u00e9), vous poss\u00e9dez id\u00e9alement une premi\u00e8re exp\u00e9rience r\u00e9ussie dans ce domaine (d\u00e9butants accept\u00e9s), vous aimez le travail en \u00e9quipe.\nComp\u00e9tences requises\n:\nEtape d\u2019analyse : Comprendre l\u2019architecture technique, les sources de donn\u00e9es, les objectifs fonctionnels.\nEtape de conception : Solution de conception avec un fort centrage sur les pipelines de donn\u00e9es et les mod\u00e8les ML et l\u2019exposition des KPI via API\nMise en \u0153uvre : Apr\u00e8s les phases d\u2019analyse et de conception, proc\u00e9der \u00e0 a mise en \u0153uvre dans des technologies s\u00e9lectionn\u00e9es (Java,Scala,Python,Spark)\nCr\u00e9er un code test\u00e9 et document\u00e9\nTechno : Linux, Shell, Hadoop, Scrum, Python, Spark, Scala\nPourquoi feriez-vous le grand saut ?\nParce que Scalian vous accompagne dans le d\u00e9veloppement de votre carri\u00e8re :\nProgramme d'onboarding complet sur 1 an avec votre manager et votre RH\nProgramme de formation (Scalian Academy, e-learning, webinaires et formations externes)\nCommunaut\u00e9s techniques (Squads, Practices) afin de valoriser et d\u00e9velopper votre expertise\n\u00c9v\u00e9nements internes (Afterworks, Awards Dinner, Kick Off, Live Event du COMEX, Stand Up) et externes (participation \u00e0 des salons et forums sp\u00e9cialis\u00e9s dans nos domaines d\u2019activit\u00e9s\u2026)\nDispositif d\u2019acc\u00e9l\u00e9ration d\u2019acc\u00e8s \u00e0 la mobilit\u00e9 interne et \u00e0 des \u00e9changes internationaux type Erasmus\nParce que Scalian favorise la Qualit\u00e9 de Vie au Travail :\nCertifications Great Place to Work\u00ae et Best Workplaces for Women\u00ae\nPrime de cooptation, prime vacances, prise en charge par l\u2019employeur de 60% des titres-restaurant, Accord t\u00e9l\u00e9travail (jusqu\u2019\u00e0 2,5 jours par semaine indemnis\u00e9s), RTT (dont une partie mon\u00e9tisable), CSE (activit\u00e9s ludiques, ch\u00e8ques-cadeaux, ch\u00e8ques vacances)\nBerceaux en cr\u00e8ches inter-entreprises\nDon ou r\u00e9ception de jours de cong\u00e9s en cas de difficult\u00e9s personnelles\nParce que Scalian d\u00e9veloppe une politique RSE concr\u00e8te et ambitieuse :\nMobilit\u00e9 durable (indemnit\u00e9 kilom\u00e9trique v\u00e9lo, leasing de v\u00e9los \u00e0 assistance \u00e9lectrique)\nActions environnementales (Fresque du Climat, Reforest'Action, Clean Up Day, m\u00e9c\u00e9nat ONF)\nPostes ouverts aux personnes en situation de Handicap\nDiverses politiques de diversit\u00e9, d\u2019inclusion et d\u2019int\u00e9gration mises en place\nScalian c\u2019est aussi :\nUne entreprise en tr\u00e8s forte croissance qui, cr\u00e9\u00e9e en 1989, compte aujourd\u2019hui plus de 5500 personnes\nDes r\u00e9f\u00e9rences clients \u00e0 forte valeur ajout\u00e9e aupr\u00e8s de grands industriels fran\u00e7ais (du CAC40) et internationaux\nUn terrain de jeu o\u00f9 l\u2019expertise se conjugue avec audace, libert\u00e9 d\u2019entreprendre et convivialit\u00e9\nSi vous aspirez \u00e0 un environnement de travail qui valorise autant votre bien-\u00eatre que votre d\u00e9veloppement professionnel,\nrejoignez-nous et exprimez pleinement votre talent !\nEnvie d'\u00e9largir le cadre ?\nJe suis Liza Djehel, Talent Acquisition Officer.\nSi votre CV est retenu, je vous contacte pour un premier \u00e9change t\u00e9l\u00e9phonique de 15 \u00e0 20 minutes.\nNous d\u00e9terminons ensemble si ce poste est en ad\u00e9quation avec vos comp\u00e9tences et surtout, avec vos attentes.\nL'\u00e9change est positif ? Nous convenons d'un entretien de 1h (en pr\u00e9sentiel ou en visio) avec Lucas Daunar, Business Manager \u00e0 Sophia-Antipolis. Cet \u00e9change permet de revenir en d\u00e9tail sur vos comp\u00e9tences, vos attentes, de vous pr\u00e9senter le poste plus en d\u00e9tail, et d'\u00e9voquer d'autres opportunit\u00e9s.\nNous pr\u00e9voyons ensuite un rendez-vous technique de 1h (en pr\u00e9sentiel ou en visio) avec un de nos responsable technique.\nEnfin, nous vous pr\u00e9sentons notre proposition d'embauche.\nNotre processus de recrutement dure entre 15 et 30 jours\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "Java",
                "Scala",
                "R"
            ],
            "DataBase": [],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [
                "Hadoop",
                "Spark"
            ],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [],
            "DevTools": [],
            "Os": [
                "Linux"
            ],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [
                "ML"
            ],
            "FrSoftSkills": [],
            "EnSoftSkils": []
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [
                "CDI"
            ],
            "Salary": [
                "40"
            ],
            "Level": [
                "Bac+5"
            ],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "Data Engineer H/F",
        "company": "Ippon Technologies",
        "location": "Greater Nantes Metropolitan Area",
        "link": "https://fr.linkedin.com/jobs/view/data-engineer-h-f-at-ippon-technologies-3902436649?position=5&pageNum=2&refId=5U0uFfx%2F5Nb5dx3Ih9znKA%3D%3D&trackingId=igIUAipWQogxha%2BnVVMT3g%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Envie de rejoindre la communaut\u00e9 DATA la plus dynamique de France ?\nNotre sp\u00e9cialit\u00e9 est de construire des data platform dans le Cloud public avec les meilleurs technos du moment : Snowflake, Databricks, Matillion, DBT.\nMembre de la Practice Data, le/la futur(e) Data Engineer sera int\u00e9gr\u00e9(e) \u00e0 nos \u00e9quipes de conseil et sera suivi(e) par un(e) mentor qui l\u2019aidera \u00e0 monter en comp\u00e9tences.\nVotre champs d\u2019expertise :\nIntervenir sur les data platforms de nos clients pour d\u00e9velopper de nouveaux pipelines de donn\u00e9es (ingestion, traitement, exposition).\nTravailler en collaboration avec les m\u00e9tiers et les data scientists pour leur fournir un support \u00e0 l\u2019industrialisation de leurs travaux (tests, int\u00e9gration continue, scalabilit\u00e9 des mod\u00e8les, craftsmanship etc\u2026)\nD\u00e9ployer des infrastructures cloud full\ninfra-as-code\n(Terraform, CloudFormation).\nParticiper aux \u00e9v\u00e8nements internes \u00e0 la communaut\u00e9 data (BBL, webinar, datap\u00e9ro interne, meetup, blog, dojos) et externes (Salon du Big Data, GCP Summit, Spark Summit, AWS Summit, Devoxx, workshop partenaire, meetups).\nCapitaliser sur les missions et les diff\u00e9rents \u00e9v\u00e8nements de la communaut\u00e9 au travers d\u2019articles de blogs, REX, BBL interne.\nVos connaissances :\nUn framework de calcul distribu\u00e9 tel que Spark, Storm, Flink.\nUn ou plusieurs langages de programmation (Python, Scala, Java...)\nDiff\u00e9rents syst\u00e8mes de stockage de donn\u00e9es (SQL ou NoSQL) et bien s\u00fbr le langage SQL.\nLa connaissance de Snowflake est bienvenue ;-)\nUn framework de streaming de donn\u00e9es tel que Kafka ou Amazon Kinesis.\nUne exp\u00e9rience sur les technologies Cloud : AWS, GCP, Azure\nLe delivery et les projets en production faisant partie de notre ADN, vous \u00eates capable de livrer du code de qualit\u00e9 dans des environnements agiles.\nDe plus en plus de nos projets se font en remote avec des clients du monde entier, il devient n\u00e9cessaire d\u2019\u00eatre \u00e0 l\u2019aise en Anglais.\nIppon technologies c\u2019est aussi :\n\ud83d\udc4d B\u00e9n\u00e9ficier d'un suivi de proximit\u00e9 r\u00e9alis\u00e9 par votre manager technique : points r\u00e9guliers pour votre suivi en mission, votre formation et votre \u00e9volution de carri\u00e8re\n\u270c\ufe0f Rejoindre une entreprise o\u00f9 les valeurs du sport sont nos leitmotiv : d\u00e9passement de soi, travail en \u00e9quipe, bienveillance.\n\ud83d\uddd2\ufe0f Apprendre via notre programme de formation BlackBelt : https://bit.ly/3ByqcIL\n\ud83d\ude01 Travailler en pair programming ou avec un.e mentor pour gravir les \u00e9chelons !\n\ud83d\udcaa Pouvoir participer \u00e0 une aventure humaine au sein de notre Fondation Ippon pour r\u00e9duire la fracture num\u00e9rique dans le monde !\n\ud83e\udd1d Participer \u00e0 nos ap\u00e9ros et divers \u00e9v\u00e8nements internes pour consolider la coh\u00e9sion d\u2019\u00e9quipe\nEt apr\u00e8s ?\nEt oui alors ? Que se passe-t-il une fois que vous \u00eates convaincu d\u2019avoir lu l\u2019offre d\u2019emploi qui vous correspond bien ?\nNous vous proposons de prendre contact et de nous rencontrer !\nLes Next Steps :\n1 call RH\n1 \u00e9change RH\n1 \u00e9change Technique\nSi le match est bon des deux c\u00f4t\u00e9s : Hadjim\u00e9 ! Vous vous lancerez sur le tatami Ippon !\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "Java",
                "Scala",
                "R"
            ],
            "DataBase": [
                "SQL",
                "NoSQL"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [
                "Spark",
                "Databricks",
                "Flink"
            ],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [
                "AWS",
                "Azure"
            ],
            "DevTools": [],
            "Os": [],
            "DBMS": [
                "Snowflake",
                "Snowflake"
            ],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [
                "Terraform",
                "CloudFormation"
            ],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [
                "Big Data",
                "Cloud"
            ],
            "FrSoftSkills": [
                "Collaboration"
            ],
            "EnSoftSkils": [
                "Collaboration"
            ]
        },
        "details": {
            "JobDetail": [
                "Remote",
                "Full"
            ],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "Data Engineer (H/F)",
        "company": "ternair",
        "location": "Greater Lille Metropolitan Area",
        "link": "https://fr.linkedin.com/jobs/view/data-engineer-h-f-at-ternair-3915757963?position=6&pageNum=2&refId=5U0uFfx%2F5Nb5dx3Ih9znKA%3D%3D&trackingId=A01wsYYAG%2FYIpqiFBcjvNA%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "\ud83d\udc68\u200d\ud83d\ude80 MISSION : \ud83d\udc69\u200d\ud83d\ude80\nEn coh\u00e9rence avec la strat\u00e9gie d\u2019entreprise et la roadmap data, vous aurez pour principales missions de :\nEn lien avec l\u2019\u00e9quipe DevOps, construire, maintenir et faire \u00e9voluer la plateforme de donn\u00e9es;\nD\u00e9finir et piloter la coh\u00e9rence de la collecte, la gestion et l\u2019alimentation des donn\u00e9es internes et externes, en diff\u00e9rents modes : batch, streaming, API (architecture micro-services);\nPr\u00e9parer et mettre en qualit\u00e9 les donn\u00e9es pour les rendre disponibles dans les diff\u00e9rents environnements de travail (datalake, datawarehouse, datamart);\nV\u00e9rifier la qualit\u00e9 des donn\u00e9es, de leur bonne et r\u00e9guli\u00e8re ex\u00e9cution ainsi que de leur utilisation ad\u00e9quate (gestion des co\u00fbts);\nTravailler en \u00e9troite collaboration avec les data analysts, scientists et data stewards et business de l\u2019entreprise ;\nEn lien avec l\u2019IT et la s\u00e9curit\u00e9, veiller aux r\u00e8gles d'int\u00e9grit\u00e9 et de s\u00e9curit\u00e9 des donn\u00e9es;\nVeille technologique.\n\ud83e\uddee Les outils :\nPlateforme data : Google Cloud Platform (Big Query, Airflow)\nD\u00e9veloppement : Github/GitLab, Docker, Terraform, Python\nAnalytiques : Qlik\nGestion de projet s: Jira, Confluence, Miro, Drive, Docs, Sheets, Slides\n\ud83e\udd29 Profil recherch\u00e9 : \ud83e\udd29\nExp\u00e9rience d'au moins 4-5 ans (apr\u00e8s \u00e9tudes) en data ing\u00e9nierie (flux, mod\u00e9lisation, run)\nA l\u2019aise avec l\u2019environnement Cloud et les infrastructures digitales\nCommuniquant, p\u00e9dagogue et fortes capacit\u00e9s relationnelles\nAnglais (\u00e0 l\u2019\u00e9crit)\nR\u00e9mun\u00e9ration : 42-60 k\u20ac en package selon exp\u00e9rience\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "R",
                "Go"
            ],
            "DataBase": [],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [
                "Google Cloud Platform"
            ],
            "DevTools": [
                "Git",
                "Docker"
            ],
            "Os": [],
            "DBMS": [
                "Big Query"
            ],
            "SoftBigDataProcessing": [],
            "Automation": [
                "Airflow"
            ],
            "InfrastructureAsCode": [
                "Terraform"
            ],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [
                "Docker"
            ],
            "Collaboration": [
                "JIRA",
                "Confluence"
            ],
            "Other": [
                "DevOps",
                "Cloud"
            ],
            "FrSoftSkills": [
                "Collaboration"
            ],
            "EnSoftSkils": [
                "Collaboration"
            ]
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [],
            "Salary": [
                "Package"
            ],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s",
                "5",
                "5",
                "5"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "Data Engineer",
        "company": "Shippeo",
        "location": "Greater Paris Metropolitan Region",
        "link": "https://fr.linkedin.com/jobs/view/data-engineer-at-shippeo-3908268236?position=7&pageNum=2&refId=5U0uFfx%2F5Nb5dx3Ih9znKA%3D%3D&trackingId=Qkp3nd%2B7kuHYXRYFNEMI%2Bg%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Founded in 2014, Shippeo is a French based SaaS company providing supply chain visibility. Shippeo has grown from 70 to 220 employees during the last two years and is continuing to rapidly scale after an additional $40M fundraising round in October 2022.\nShippeo is an exceptionally diverse company with colleagues from 27 different nationalities and speaking 29 languages. With offices throughout Europe, North America and recently Asia, Shippeo provides global coverage to all of our clients.\nOur product is composed of a mission critical SaaS web platform (API everywhere), with high traffic inbound/outbound integrations.\nOur mission is to anticipate problems and proactively alert end-customers so they can efficiently manage exceptions. We achieve this by collecting and matching millions of theoretical and real data from different stakeholders.\nThe Data Intelligence Tribe is responsible for leveraging Shippeo\u2019s data from our large shipper and carrier base, to build data products that help our users (shippers and carriers alike) and ML models to provide predictive insights. This tribe\u2019s typical responsibilities are to:\nget accurately alerted in advance of any potential delays on their multimodal flows or anomalies so that they can proactively anticipate any resulting disruptions\nextract the data they need, get direct access to it or analyze it directly on the platform to gain actionable insights that can help them increase their operational performance and the quality and compliance of their tracking\nprovide best-in-class data quality by implementing advanced cleansing & enhancement rules\nAs a Data Engineer at Shippeo, your objective is to ensure that data is available and exploitable by our Data Scientists and Analysts on our different data platforms. You will contribute to the construction and maintenance of Shippeo\u2019s modern data stack that\u2019s composed of different technology blocks:\nData Acquisition (Kafka, KafkaConnect, RabbitMQ),\nBatch data transformation (Airflow, DBT),\nCloud Data Warehousing (Snowflake, BigQuery),\nStream/event data processing (Python, docker, Kubernetes) and all the underlying infrastructure that support these use cases.\nQualifications\nRequired:\nYou have a degree (MSc or equivalent) in Computer Science.\n3+ years of experience as a Data Engineer.\nExperience building, maintaining, testing and optimizing data pipelines and architectures\nProgramming skills in Python and experience with asynchronous event processing (asyncio).\nAdvanced working knowledge of SQL, experience working with relational databases and familiarity with a variety of databases.\nWorking knowledge of message queuing and stream processing.\nKnowledge of Docker and Kubernetes.\nKnowledge of a cloud platform (preferably GCP).\nExperience working with workflow management systems such as Airflow.\nDesired:\nExperience with cloud based data warehouse solutions (BigQuery, Snowflake).\nExperience with Kafka and KafkaConnect (Debezium).\nExperience with Infrastructure as code (Terraform/Terragrunt).\nExperience building and evolving CI/CD pipelines with Github Actions.\nMonitoring and alerting on Grafana / Prometheus.\nExperience working on Apache Nifi.\nInformations suppl\u00e9mentaires\nWe are looking for talents who share our values:\n\ud83d\ude80 Ambition\n\ud83d\udc99 Care\n\ud83c\udfaf Deliver\n\ud83e\udd1d Collaboration\nFind out more about our values in\nOur Culture Book\nIf you identify with our values and enjoy working in a fast-paced and international environment, Shippeo is just the place for you!\nWe are committed to fostering diversity and inclusion within our workplace as we value the unique perspectives and experiences that individuals from all backgrounds bring to our team. We are dedicated to providing equal employment opportunities to all candidates, regardless of their background or abilities, and our commitment to inclusion is reflected in our policies, practices, and workplace culture.\nWe understand that candidates may have unique needs or questions related to disability inclusion. To facilitate this, you can reach our dedicated Disability Advisor at\ninclusion@shippeo.com\nwith any inquiries or requests for accommodations during the application process.\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "R"
            ],
            "DataBase": [
                "SQL"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [],
            "DevTools": [
                "Git",
                "Docker"
            ],
            "Os": [],
            "DBMS": [
                "Snowflake",
                "Snowflake",
                "BigQuery"
            ],
            "SoftBigDataProcessing": [],
            "Automation": [
                "Kubernetes",
                "Airflow"
            ],
            "InfrastructureAsCode": [
                "Terraform"
            ],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [
                "Docker",
                "Kubernetes"
            ],
            "Collaboration": [],
            "Other": [
                "ML",
                "Cloud",
                "CI/CD"
            ],
            "FrSoftSkills": [
                "Collaboration"
            ],
            "EnSoftSkils": [
                "Collaboration"
            ]
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "Data engineer - F / H",
        "company": "United Robotics Group",
        "location": "Paris, \u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/data-engineer-f-h-at-united-robotics-group-3891680780?position=8&pageNum=2&refId=5U0uFfx%2F5Nb5dx3Ih9znKA%3D%3D&trackingId=oVJtK1t11uimHlb7BlJr8w%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Bienvenue chez\nAldebaran\n, leader europ\u00e9en de la robotique\nau sein du groupe\nUnited Robotics Group\n.\nNous concevons et industrialisons des robots innovants avec une vision soci\u00e9tale ambitieuse pour fa\u00e7onner un monde plus humain. Depuis 2005, nous sommes \u00e0 l'avant-garde de l'interaction homme-robot avec des produits embl\u00e9matiques tels que NAO et Pepper.\nNotre dernier-n\u00e9,\nPlato\n,\nincarne notre engagement envers la technologie de pointe et la s\u00e9curit\u00e9,\nfabriqu\u00e9 en France avec des composants europ\u00e9ens.\nRejoignez nos \u00e9quipes multiculturelles et dynamiques pour \u00eatre au c\u0153ur de la r\u00e9volution de la robotique.\nSi vous \u00eates passionn\u00e9.e par la robotique et l'intelligence artificielle, et que vous souhaitez contribuer \u00e0 fa\u00e7onner l'avenir, nous vous offrons une exp\u00e9rience enrichissante et stimulante.\nEn tant que membre de notre \u00e9quipe, vous b\u00e9n\u00e9ficierez d'une culture d'entreprise ax\u00e9e sur le sens de ce que nous faisons et valorisant la responsabilit\u00e9 sociale et environnementale.\nChez Aldebaran, nous valorisons l'innovation, la diversit\u00e9 et l'\u00e9galit\u00e9 et encourageons chacun.e \u00e0 \u00eatre ouvert.e, authentique, courageux.se, responsable et engag\u00e9.e.\nFinalit\u00e9 du poste\nAu sein de l'\u00e9quipe Cloud-Online Services, le Data engineer int\u00e9grera l'\u00e9quipe Data, responsable du d\u00e9veloppement des produits destin\u00e9s \u00e0 la collecte, aux process et \u00e0 l'exploitation des donn\u00e9es de nos robots.\nIl aura pour r\u00f4le de d\u00e9finir et d'impl\u00e9menter des services data, sur une infrastructure Cloud AWS, supportant des services en ligne qui g\u00e8rent les robots du groupe.\nMissions principales\nLe Data engineer aura pour responsabilit\u00e9s de :\n\u00e9valuer les choix d'architecture et de solutions techniques lors de la mise en place de PoC,\nconcevoir et d\u00e9velopper des services Data en respectant la sp\u00e9cification fonctionnelle et la m\u00e9thodologie agile,\nagr\u00e9ger et stocker de grandes quantit\u00e9s de donn\u00e9es,\nmettre en place des solutions de data processing,\nint\u00e9grer/d\u00e9velopper des outils de visualisation de donn\u00e9es et analyser les KPI,\nd\u00e9velopper, tester, s\u00e9lectionner et mettre en production des algorithmes qui permettent de r\u00e9pondre aux besoins,\nr\u00e9aliser des analyses de donn\u00e9es,\nmettre en place des tests de charge et fonctionnels pour les solutions Data,\ninvestiguer et corriger les bugs remont\u00e9s par les utilisateurs,\ncontribuer \u00e0 la mise en place de l'infrastructure et outil de d\u00e9ploiement (CI/CD)\nRejoignez-nous pour faire partie d'une aventure passionnante o\u00f9 Pepper, NAO, Plato et leurs futurs successeurs attendent votre contribution pour repousser les limites de la technologie robotique !\nRequirements\nPour la bonne ex\u00e9cution des missions confi\u00e9es, vous t\u00e9moignez d'au moins 6 ans d'exp\u00e9rience en tant que d\u00e9veloppeur sur des projets data en Cloud en Python et Spark et avec comme Cloud provider AWS.\nComp\u00e9tences demand\u00e9es :\nBonne compr\u00e9hension des technologies d'infrastructure et de d\u00e9ploiement,\nComp\u00e9tences techniques sur les services AWS : IOT core , Glue, lambda, Kinesis, S3, RDS,\nBonne compr\u00e9hension technique dans la mise en place et l'automatisation de tests de charge et fonctionnels,\nBonne maitrise d'outils BI ou de dashboarding (POWER BI, TABLEAU, QUICKSIGHT)\nBonne connaissance et une exp\u00e9rience pratique de Scrum\\Scrumban et des m\u00e9thodes agiles,\nUne certification AWS sera appr\u00e9ci\u00e9e,\nUn niveau de fran\u00e7ais et d'anglais courant est indispensable,\nDes exp\u00e9riences dans des environnements fortement internationaux sont un plus\nBenefits\nNos principaux avantages :\nUne culture du bien-\u00eatre en entreprise qui a fait ses preuves (budget c\u00e9l\u00e9bration et moments de convivialit\u00e9 par \u00e9quipes et directions, restauration collective de qualit\u00e9, environnement de travail agr\u00e9able)\nUn engagement fort en mati\u00e8re de responsabilit\u00e9 sociale et environnementale (promotion de l'\u00e9galit\u00e9 professionnelle, performance de notre plan diversit\u00e9 et inclusion, r\u00e9f\u00e9rent handicap, fresque du num\u00e9rique)\nUne culture du t\u00e9l\u00e9travail encadr\u00e9e de mani\u00e8re appropri\u00e9e !\nTous nos postes sont ouverts aux personnes en situation de handicap.\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "R",
                "Go"
            ],
            "DataBase": [],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [
                "Spark"
            ],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [
                "Tableau",
                "Power BI"
            ],
            "Statistics": [],
            "CloudComputing": [
                "AWS"
            ],
            "DevTools": [],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [
                "Cloud",
                "CI/CD"
            ],
            "FrSoftSkills": [],
            "EnSoftSkils": []
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s",
                "6",
                "6",
                "6"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "Data Engineer H/F",
        "company": "Neosoft",
        "location": "Lille, Hauts-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/data-engineer-h-f-at-neosoft-3877878521?position=9&pageNum=2&refId=5U0uFfx%2F5Nb5dx3Ih9znKA%3D%3D&trackingId=E0uvNqbx3ExrbNpYFJTgWA%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Tous nos postes sont ouverts au t\u00e9l\u00e9travail\nGroupe ind\u00e9pendant de conseil en transformation digitale de pr\u00e8s de 1800 collaborateurs, N\u00e9osoft s\u2019est construit, depuis 2005, sur un mod\u00e8le qui place l\u2019excellence, le d\u00e9passement de soi et la RSE au c\u0153ur de sa strat\u00e9gie.\nEn nous rejoignant, vous int\u00e9grez des communaut\u00e9s d\u2019experts et de talents qui vous permettent de d\u00e9velopper vos comp\u00e9tences et d\u2019offrir \u00e0 nos clients le meilleur accompagnement possible.\nNotre savoir-faire s\u2019articule autour de nos 6 domaines d\u2019expertise :\nConseil & Agilit\u00e9\nCybers\u00e9curit\u00e9\nData\nDevOps\nInfrastructures & Cloud\nSoftware Engineering\nNous recherchons pour int\u00e9grer notre\nagence lilloise\nun(e)\nData Engineer confirm\u00e9(e)\n.\nNous aimerions vous voir rayonner au sein de notre communaut\u00e9 DATA (+100 collaborateurs) anim\u00e9e par Nicolas Huche, son practice leader et Thibaud Blanchard son Technical Officer. Vous aiderez les clients \u00e0 consolider un patrimoine Data responsable.\n\ud83c\udfaf\nVos missions :\nApr\u00e8s une p\u00e9riode d\u2019int\u00e9gration, en tant que\nData Engineer\n, voici \u00e0 quoi ressembleront vos activit\u00e9s dans des contextes clients Retail ou Banque / Assurance / Finance :\nAnalyser et s'approprier les cas d'usages\nAnalyser et valoriser les donn\u00e9es du patrimoine\nMettre en place des flux de transformation de donn\u00e9es\nR\u00e9aliser les tests permettant de s'assurer la qualit\u00e9 du delivery\nContinuer la mise au point de frameworks data\nCr\u00e9er et d\u00e9velopper des modules de d\u00e9ploiement des solutions\nAssurer l'industrialisation de moteurs bas\u00e9s sur l'IA\nAssurer le niveau de performance des pipelines\nImpl\u00e9menter les outils de monitoring du socles de donn\u00e9es\n\ud83d\udcdd\nVotre profil :\nNous vous imaginons avec au moins 4 ans d\u2019exp\u00e9riences sur des projets autour de la\nData\n, une ma\u00eetrise des\nbases de donn\u00e9es (SQL)\n, des outils de transformation de la donn\u00e9e\n(Talend, BigQuery, Airflow)\n, et un socle de comp\u00e9tences solides autours des langages\nPython, Spark, Scala, Hadoop, Java.\n\ud83d\udc49\nVotre carri\u00e8re chez N\u00e9osoft\nDepuis sa cr\u00e9ation, N\u00e9osoft place ses collaborateurs au c\u0153ur de sa strat\u00e9gie. Notre culture pourrait se r\u00e9sumer en un mot : le collectif.\nNos communaut\u00e9s d\u2019experts vous donnent la possibilit\u00e9 d\u2019apprendre, mais aussi de transmettre et de partager vos savoirs pour faire progresser les autres.\nNous veillons \u00e0 ce que chacun b\u00e9n\u00e9ficie d\u2019un accompagnement de proximit\u00e9 et d\u2019un suivi de carri\u00e8re personnalis\u00e9 aupr\u00e8s de votre manager d\u00e9di\u00e9 :\n1 bilan d\u2019activit\u00e9 trimestriel pour suivre le d\u00e9veloppement de vos comp\u00e9tences\n1 entretien d\u2019\u00e9valuation qui a lieu chaque ann\u00e9e pour \u00e9valuer votre performance et d\u00e9terminer vos nouveaux objectifs\n1 entretien annuel aupr\u00e8s de votre RH dans le but de cartographier vos nouvelles comp\u00e9tences pour \u00e9changer sur vos projets professionnels et souhaits de formations\n\ud83d\udc49\nVos avantages\nFormations et d\u00e9veloppement de l\u2019expertise :\nVous disposez de temps allou\u00e9 et r\u00e9mun\u00e9r\u00e9 en contribuant au d\u00e9veloppement de votre expertise technique et de celle du groupe (Participations \u00e0 des Tech days, animation d\u2019une conf\u00e9rence \u00e0 l\u2019interne ou \u00e0 l\u2019externe, r\u00e9daction d\u2019articles, rencontres avec nos candidats en processus de recrutement\u2026)\nUn abonnement illimit\u00e9 LinkedIn Learning offert\nBien-\u00eatre au travail :\nUn accord de t\u00e9l\u00e9travail flexible jusqu\u2019\u00e0 100% de t\u00e9l\u00e9travail et personnalisable\nUn partenariat avec Gymlib qui favorise le sport en entreprise\nDes initiatives locales (afterworks, d\u00e9fis sportifs, team buildings, \u2026)\nEt bien plus encore :\nParce que les meilleurs cooptent les meilleurs, une politique de cooptation attractive r\u00e9mun\u00e9r\u00e9e d\u00e8s l\u2019arriv\u00e9e du collaborateur\nEn plus de votre salaire : participation, compte \u00e9pargne temps, actionnariat...\n\ud83d\udc49\nVotre parcours candidat\nNotre processus de recrutement se compose de deux \u00e9tapes cl\u00e9s :\nUn entretien de recrutement RH avec un Talent Acquisition Sp\u00e9cialiste pour dresser un bilan de votre parcours professionnel et identifier les trajectoires de carri\u00e8re possibles au sein de notre groupe\nUn entretien d\u2019\u00e9valuation technique pour r\u00e9aliser un diagnostic de vos comp\u00e9tences techniques et identifier les comp\u00e9tences sur lesquels poursuivre votre \u00e9volution\nVous aurez \u00e9galement la possibilit\u00e9 de rencontrer pour compl\u00e9ter votre processus un acteur de notre p\u00f4le Business ou un pair de votre m\u00e9tier pour \u00e9changer sur son exp\u00e9rience collaborateur.\nNous avons h\u00e2te de vous rencontrer !\nA bient\u00f4t,\nL\u2019\u00e9quipe N\u00e9osoft \ud83d\udd90\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "Java",
                "Scala",
                "R"
            ],
            "DataBase": [
                "SQL"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [
                "Hadoop",
                "Spark"
            ],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [],
            "DevTools": [
                "Git"
            ],
            "Os": [],
            "DBMS": [
                "BigQuery"
            ],
            "SoftBigDataProcessing": [],
            "Automation": [
                "Airflow"
            ],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [
                "DevOps",
                "ML",
                "Cloud"
            ],
            "FrSoftSkills": [],
            "EnSoftSkils": [
                "Initiative"
            ]
        },
        "details": {
            "JobDetail": [
                "Confirm\u00e9"
            ],
            "TypeContract": [],
            "Salary": [
                "Salaire"
            ],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s",
                "4",
                "4",
                "4"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "Data & Cloud Engineer (H/F)",
        "company": "fifty-five",
        "location": "Paris, \u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/data-cloud-engineer-h-f-at-fifty-five-3910028674?position=10&pageNum=2&refId=5U0uFfx%2F5Nb5dx3Ih9znKA%3D%3D&trackingId=o9htNm8KQ7fNkBtS4SPmyQ%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Data & Cloud Engineer\nfifty-five est une data-company d'un genre nouveau qui aide les marques \u00e0 exploiter les donn\u00e9es pour am\u00e9liorer le marketing, les m\u00e9dias et l'exp\u00e9rience client gr\u00e2ce \u00e0 une combinaison de services de conseil et de technologie sp\u00e9cialis\u00e9s.\nEn tant que pilier data et marketing du Brandtech Group, nous offrons des services qui combinent le conseil en strat\u00e9gie, les services de cloud, le conseil en m\u00e9dia et l'exp\u00e9rience client.\nfifty-five, c'est plus de 400 experts du num\u00e9rique. Des digital consultants, des sp\u00e9cialistes du tracking et du m\u00e9dia, des ing\u00e9nieurs et des data scientists, travaillent tous en \u00e9troite collaboration pour fournir des conseils marketing de haut niveau et une assistance technique aux marques, dans tout type d'industrie, partout dans le monde.\nPartenaire des annonceurs de la collecte \u00e0 l'activation et l'exploitation des donn\u00e9es, nous aidons les organisations \u00e0 devenir de v\u00e9ritables entit\u00e9s omnicanales ma\u00eetrisant l'efficacit\u00e9 de leur \u00e9cosyst\u00e8me digital et ses synergies avec le monde physique.\nBas\u00e9 \u00e0 Paris, nous op\u00e9rons sur 3 fuseaux horaires depuis nos 10 bureaux, situ\u00e9s \u00e0 Paris, Londres, Gen\u00e8ve, Milan, Shanghai, Hong Kong, Shenzhen, Taipei, Singapour et New York. fifty-five attache une importance particuli\u00e8re au bien-\u00eatre de ses collaborateurs, ce qui lui a permis de figurer dans le classement Best Workplaces France en 2018.\nContexte :\nL'\u00e9quipe d'ing\u00e9nierie d\u00e9veloppe et met en \u0153uvre les solutions techniques permettant la r\u00e9alisation de pipelines de donn\u00e9es et l'impl\u00e9mentation de data platform pour nos clients : r\u00e9cup\u00e9ration de datas sur de multiples sources de donn\u00e9es (APIs, files, etc.), data cleaning, data processing, automation et monitoring de l'ensemble. L'\u00e9quipe s'appuie sur des technologies r\u00e9centes (docker, kubernetes, terraform, notebooks, etc.) et met en place ses projets dans les diff\u00e9rents clouds du march\u00e9 (GCP, Azure, AWS...).\nMission :\nNous sommes \u00e0 la recherche d'une personne capable de r\u00e9aliser des projets techniques pour r\u00e9pondre aux besoins de nos clients (par exemple: syst\u00e8me de recommandations de produits, d\u00e9tection d'anomalies, ranking). Les activit\u00e9s vont du chiffrage et du sizing technique \u00e0 la mise en \u0153uvre des architectures, en passant par la revue des sp\u00e9cifications fonctionnelles et la production de code. Le Data & Cloud Engineer sera \u00e9paul\u00e9 par un Lead dans ses missions. Il sera \u00e9galement amen\u00e9 \u00e0 participer \u00e0 la R&D et \u00e0 accompagner les \u00e9quipes transverses dans la mise en place d'outils de travail internes (librairies pour les data scientists, environnement Notebooks pour les data analysts et data scientists, d\u00e9veloppement de frameworks sur diff\u00e9rents cloud providers, etc.).\nNous souhaitons trouver la bonne personne pour faire \u00e9voluer ou cr\u00e9er de nouvelles solutions dans ce cadre. Les missions comprennent aussi bien du prototypage rapide pour des d\u00e9monstrateurs, que de la production de code robuste qui tourne en production tous les jours.\nComp\u00e9tences et exp\u00e9riences :\n2 ans d'exp\u00e9rience en tant que Data Engineer\nMa\u00eetrise de Python, SQL\nMa\u00eetrise des environnements Cloud. Id\u00e9alement certifi\u00e9 GCP, Azure ou AWS\nBonne connaissance de Docker/Kubernetes\nBonne connaissance d'au moins un data warehouse (BigQuery, Snowflake, etc)\nConnaissance autour des Notebooks (Jupyter)\nA l'aise avec des concepts li\u00e9s aux APIs (OAuth, REST, etc.)\nA l'aise avec les notions d'Infrastructure as Code (Terraform)\nAu courant des pratiques GitOps et connaissances des concepts autour du CI/CD\nLa ma\u00eetrise d'un orchestrateur, comme Apache Airflow, est un plus\nEsprit d'\u00e9quipe (collaborer aux tests unitaires, revue de code, partage de code, sprints)\nBon niveau en fran\u00e7ais et en anglais\nA d\u00e9j\u00e0 travaill\u00e9 en mode projet avec des interlocuteurs vari\u00e9s (consultant, data analyst, data scientist)\nUne exp\u00e9rience en marketing digital est un plus\nNous proposons :\nun bureau au centre de Paris avec terrasse et jardin\nun environnement multiculturel avec des collaborateurs aux nationalit\u00e9s multiples (France, Royaume-Uni, Etats-Unis, Chine, Tunisie, Italie et plus)\ndes projets avec nos bureaux \u00e0 Londres, Hong Kong, New York, Shanghai, Gen\u00e8ve, Shenzhen et Taipei\ndes TGIF et supers soir\u00e9es\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "R"
            ],
            "DataBase": [
                "SQL"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [
                "Apache Airflow"
            ],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [
                "AWS",
                "Azure"
            ],
            "DevTools": [
                "Git",
                "Docker"
            ],
            "Os": [],
            "DBMS": [
                "Snowflake",
                "Snowflake",
                "BigQuery"
            ],
            "SoftBigDataProcessing": [],
            "Automation": [
                "Kubernetes",
                "Airflow"
            ],
            "InfrastructureAsCode": [
                "Terraform"
            ],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [
                "Docker",
                "Kubernetes"
            ],
            "Collaboration": [],
            "Other": [
                "Cloud",
                "CI/CD"
            ],
            "FrSoftSkills": [
                "Collaboration",
                "Organisation"
            ],
            "EnSoftSkils": [
                "Collaboration"
            ]
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s",
                "2",
                "2",
                "2"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "Data Engineer Senior",
        "company": "AXA en France",
        "location": "Hauts-de-Seine, \u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/data-engineer-senior-at-axa-en-france-3884386043?position=1&pageNum=5&refId=T%2B%2BV0JbclKMpVoA2J23Itg%3D%3D&trackingId=bodYRty8CHMU9PuiSRGKTA%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Environnement\nEn tant que\nSenior Data Engineer F/H\n, vous allez contribuer directement aux projets des directions m\u00e9tier (ex : fraude sant\u00e9, multi\u00e9quipements, pricing IARD, optimisation du lead management, fragilit\u00e9 auto, \u2026) d\u2019AXA France et \u00e0 la construction du socle technique Big Data.\nVous allez int\u00e9grer une \u00e9quipe d'une dizaine de personne compos\u00e9e de Data Engineer et des Tech Lead travaillant en mode Feature Team au sein des tribus m\u00e9tier de la Direction Transformation Digital Tech et DATA (DT2).\nLa Direction Transformation Digital Tech et DATA d'AXA France en quelques mots :\n- Une organisation agile en feature teams : tribus, guildes, squads\n- Des projets sur des applications innovantes \u00e0 fort trafic (web, mobile\u2026)\n- Des m\u00e9thodologies craft (TDD, BDD, clean code, code review\u2026) et DevOps\n- Une communaut\u00e9 de partage de bonnes pratiques (BBL, dojo, meetup, conf\u2026)\nVotre r\u00f4le et vos missions\nVous aurez pour missions principales de d\u00e9velopper les projets Big Data demand\u00e9s par le m\u00e9tier, et notamment :\nPasser de la donn\u00e9e brute \u00e0 de la donn\u00e9e exploitable, expos\u00e9e sous forme de tables requ\u00eatables dans le datalake\nConsolider ces donn\u00e9es au fur et \u00e0 mesure de leur alimentation r\u00e9currente dans le data lake\nLes exploiter pour atteindre la finalit\u00e9 business (exposition de business view, r\u00e9int\u00e9gration des r\u00e9sultats dans le SI, service de scoring, \u2026)\nDe travailler \u00e0 la cr\u00e9ation du socle technique Big Data et industrialiser le cycle de d\u00e9veloppement de l'\u00e9quipe\nDe mettre en place et de garantir le respect dans la dur\u00e9e d'un processus qualit\u00e9 sur l'ensemble du cycle de DEV (documents, tests unitaires / int\u00e9gration / fonctionnels, commentaires, versionning, etc.)\nVotre profil\nVous justifiez de plusieurs exp\u00e9riences significatives (+ de 5 ans) sur du\nd\u00e9veloppement big data, en particulier sur du PySpark.\nComp\u00e9tences techniques :\nConnaissances avanc\u00e9es en d\u00e9veloppement en\nPySpark\n(Spark avec le langage Python)\nMaitrise de l'environnement\nMicrosoft Azure\nConnaissances avanc\u00e9es d'outils de BI comme\nPowerBI\nComp\u00e9tences transverses :\nCapacit\u00e9 \u00e0 interagir avec des parties prenantes diverses : Business analyst, Architectes, M\u00e9tier\nExp\u00e9rience en mode de delivery Agile (Scrum, Kanban, etc...)\nDriver et accompagner des Data Engineer junior sur les aspects technique\nEt Id\u00e9alement :\nDes Connaissances sur Azure DevOps, Azure Pipeline, GIT, JIRA\nMaitrise des Traitements Big Data en mode Streaming\nMaitrise des Bases de donn\u00e9es relationnelles et NoSQL\nUne exp\u00e9rience professionnelle avec des outils comme Azure Databricks, Azure Data Lake Storage ou encore Azure Data Factory\nQui sommes nous ?\nAXA est un des leaders de l\u2019assurance et de la gestion d\u2019actifs dans le monde.\nNous aidons nos 108 millions de clients \u00e0 traverser les petites et grandes difficult\u00e9s de la vie.\nChaque jour, nous agissons ensemble pour inventer la meilleure mani\u00e8re de les prot\u00e9ger et voulons donner \u00e0 chacun les moyens de vivre une vie meilleure.\nUn challenge qui donne le sourire et envie de se lever le matin !\nChez AXA, nous sommes persuad\u00e9s que pour bien prendre soin de nos clients, nous devons commencer par bien prendre soin de nos collaborateurs. C\u2019est pour cette raison que nous menons une politique RH engag\u00e9e qui favorise la diversit\u00e9, qui pr\u00e9serve l\u2019\u00e9quilibre vie priv\u00e9e-vie professionnelle et acc\u00e9l\u00e8re le d\u00e9veloppement des comp\u00e9tences et des carri\u00e8res.\nAinsi, en rejoignant AXA France vous travaillerez dans une entreprise responsable, offrant une v\u00e9ritable culture d\u2019expertise, acc\u00e9l\u00e9rant le d\u00e9veloppement des comp\u00e9tences de chacun et proposant une r\u00e9mun\u00e9ration attractive.\nPourquoi nous rejoindre ?\nVous \u00eates porteur d\u2019id\u00e9es et d\u2019initiatives innovantes ? Vous proposez des solutions et \u00eates au service du client ? Faites partie de notre grande famille en rejoignant\nUn leader mondial offrant des opportunit\u00e9s de carri\u00e8res int\u00e9ressantes\nUne entreprise qui donne une place de choix \u00e0 l\u2019innovation, \u00e0 l\u2019initiative et aux actions solidaires (notamment via l\u2019association AXA Atout C\u0153ur)\nUn environnement inclusif \u00e0 tous les niveaux (mixit\u00e9, handicap, initiatives pour favoriser l\u2019insertion des jeunes, orientation sexuelle, etc.)\nUn acc\u00e8s \u00e0 de multiples avantages (cong\u00e9s, temps partiel, t\u00e9l\u00e9travail, etc.)\nUn cadre stimulant, qui permet de rencontrer des collaborateurs performants et d\u2019enrichir ses comp\u00e9tences\nVictime ou t\u00e9moin, en cas de discrimination, vous pouvez adresser vos signalements et/ou alertes discrimination \u00e0 alerte.discrimination.harcelement@axa.fr\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "R"
            ],
            "DataBase": [
                "SQL",
                "NoSQL"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [
                "Spark",
                "Databricks"
            ],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [
                "PowerBI"
            ],
            "Statistics": [],
            "CloudComputing": [
                "Azure"
            ],
            "DevTools": [
                "Git"
            ],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [
                "JIRA",
                "Teams"
            ],
            "Other": [
                "DevOps",
                "Big Data"
            ],
            "FrSoftSkills": [
                "Organisation"
            ],
            "EnSoftSkils": [
                "Initiative"
            ]
        },
        "details": {
            "JobDetail": [
                "Junior",
                "Senior"
            ],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s",
                "5",
                "5",
                "5"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "Data Engineer",
        "company": "Beelix",
        "location": "Paris, \u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/data-engineer-at-beelix-3865239426?position=2&pageNum=5&refId=T%2B%2BV0JbclKMpVoA2J23Itg%3D%3D&trackingId=At6zkzF%2BwCiC%2FjDzU74g7g%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Qui sommes-nous ?\nDepuis 2016, nous accompagnons nos clients sur des probl\u00e9matiques de Product Management, Data et Design Thinking. Beelix contribue \u00e0 fa\u00e7onner le monde de demain en participant aux grandes avanc\u00e9es des secteurs suivants:\n\ud83d\ude97Automobile\n\u26a1Energie\n\ud83d\udce1M\u00e9dias & T\u00e9l\u00e9coms\n\ud83d\udc57Luxe & Retail\n\ud83d\udcb6 Banque, Finance & Assurance\n\u2708\ufe0fD\u00e9fense\nAujourd\u2019hui, Beelix compte plus de 200 collaborateurs motiv\u00e9s et dynamiques. Lab\u00e9lis\u00e9e Great Place To work en 2023, Beelix est aussi une entreprise engag\u00e9e o\u00f9 il fait bon vivre.\nDans le cadre de notre d\u00e9veloppement, nous recherchons un Data Engineer en \u00cele-de-France.\nQuelles missions au quotidien ?\nVous aurez pour missions principales de d\u00e9velopper les projets Big Data demand\u00e9s par le m\u00e9tier, et notamment :\nPasser de la donn\u00e9e brute \u00e0 de la donn\u00e9e exploitable, expos\u00e9e sous forme de tables requ\u00eatables dans le Datalake\nConsolider ces donn\u00e9es au fur et \u00e0 mesure de leur alimentation r\u00e9currente dans le Datalake\nLes exploiter pour atteindre la finalit\u00e9 business (exposition de Business View, r\u00e9int\u00e9gration des r\u00e9sultats dans le SI, service de scoring, \u2026)\nDe mettre en place et de garantir le respect dans la dur\u00e9e d'un processus qualit\u00e9 sur l'ensemble du cycle de DEV (documents, tests unitaires / int\u00e9gration / fonctionnels, commentaires, versionning, etc.)\nAccompagner les Data Engineers sur son p\u00e9rim\u00e8tre pour garantir la qualit\u00e9 des livrables\nExpertise souhait\u00e9e\nExpertise en SPARK et PySpark\nExpertise sur Databricks\nUne exp\u00e9rience sur un cloud provider public comme Azure (id\u00e9alement), AWS, ou GCP\nConnaissances avanc\u00e9es d'outils de BI comme PowerBI (id\u00e9alement) ou Spotfire\nCapacit\u00e9 \u00e0 interagir avec des parties prenantes diverses : Business analyst, Architectes, M\u00e9tier\nEtre expert dans les pratiques du Software Craftsmanship (Test Driven Development, Behavior Driven Development, Clean Code, Code Reviews, etc.)\nDes Connaissances sur Azure DevOps, Azure Pipeline, GIT\nMaitrise des Traitements Big Data en mode Streaming\nMaitrise des Bases de donn\u00e9es relationnelles et NoSQL\nUne exp\u00e9rience professionnelle avec des outils comme Azure Databricks, Azure Data Lake Storage ou encore Azure Data Factory\nA propos de vous ?\nDipl\u00f4m\u00e9 d'une \u00e9cole d'ing\u00e9nieurs ou \u00e9quivalent\nAu moins 3 ans d'exp\u00e9rience en tant que Data Engineer\nExp\u00e9rience en mode de Delivery Agile (Scrum, Kanban, etc.\u2026)\nVous avez un bon niveau d\u2019anglais tant \u00e0 l\u2019\u00e9crit qu\u2019\u00e0 l\u2019oral\nPourquoi nous rejoindre ?\nUn suivi et un accompagnement au quotidien\nUn organisme de formation certifi\u00e9 Qualiopi, un abonnement linkedin learning pour chaque salari\u00e9 et des partenariats avec des sp\u00e9cialistes pour d\u2019autres expertises\nDe nombreux \u00e9v\u00e9nements : Afterworks, Communaut\u00e9s m\u00e9tiers, Happy talks\u2026\nune Exp\u00e9rience personnalis\u00e9e bas\u00e9e sur vos besoins gr\u00e2ce au Pr\u00e9dictive Index\nNotre package \u00ab unBeelievable \u00bb : 100% du titre de transport, Tickets restaurants, CSE, Prime de participation ...\nNombreux \u00e9v\u00e8nements (afterworks, sport, etc) et des communaut\u00e9s m\u00e9tiers dynamiques\nLe processus de recrutement ?\n\u00c9change t\u00e9l\u00e9phonique (15 min)\nEntretien 1 RH pour apprendre \u00e0 vous conna\u00eetre\nEntretien 2 avec votre futur N+1 pour appr\u00e9hender la relation manag\u00e9riale\nEntretien 3 avec un Responsable commercial pour avoir la vision strat\u00e9gique\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "R"
            ],
            "DataBase": [
                "SQL",
                "NoSQL"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [
                "Spark",
                "Databricks"
            ],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [
                "PowerBI"
            ],
            "Statistics": [],
            "CloudComputing": [
                "AWS",
                "Azure"
            ],
            "DevTools": [
                "Git"
            ],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [
                "DevOps",
                "Big Data",
                "Cloud"
            ],
            "FrSoftSkills": [],
            "EnSoftSkils": []
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [],
            "Salary": [
                "100"
            ],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s",
                "3",
                "3",
                "3"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "Data Engineer",
        "company": "CGI",
        "location": "Niort, Nouvelle-Aquitaine, France",
        "link": "https://fr.linkedin.com/jobs/view/data-engineer-at-cgi-3902057928?position=3&pageNum=5&refId=T%2B%2BV0JbclKMpVoA2J23Itg%3D%3D&trackingId=IMZKLUIu9KltYvuQgJMBZg%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Description de poste\nBig Data, Data Science, Data analyse, Data architecture ... \u00c7a n\u2019a pas de secret pour vous ?\nQue vous commenciez votre carri\u00e8re professionnelle ou que vous soyez sp\u00e9cialiste de l\u2019une de ces disciplines, int\u00e9grer notre communaut\u00e9 Data, c\u2019est l\u2019assurance de progresser, innover, partager, vous certifier et rendre service \u00e0 nos clients.\nSi vous souhaitez int\u00e9grer nos \u00e9quipes \u00e0 Niort et accompagner les plus grands acteurs du secteur des Assurances, cette annonce est susceptible de vous int\u00e9resser.\nEn tant que Data Engineer, vous serez responsable de la conception, du d\u00e9veloppement, de la gestion et de l'int\u00e9gration des syst\u00e8mes bas\u00e9s sur les technologies AWS, Terraform, OpenShift, Kafka et Hadoop. Ce r\u00f4le implique la mise en place d'architectures \u00e9volutives et hautement disponibles pour r\u00e9pondre aux besoins de traitement et de stockage de donn\u00e9es de l'entreprise.\nFonctions et responsabilit\u00e9s\nVos responsabilit\u00e9s seront les suivantes:\n-Maintenir et d\u00e9velopper des solutions bas\u00e9es sur les services AWS pour le stockage, le traitement et l'analyse de donn\u00e9es\n-Utiliser les services AWS appropri\u00e9s tels que Amazon EC2, S3, RDS, Lambda, etc., pour r\u00e9pondre aux exigences du projet.\n-Cr\u00e9er et maintenir les configurations Terraform pour la gestion de l'infrastructure en tant que code (IaC) sur AWS\n-Participer \u00e0 la maintenance et \u00e0 la mise en place d'environnements OpenShift pour l'h\u00e9bergement d'applications et de services\n-G\u00e9rer et administrer les clusters Kafka pour garantir la disponibilit\u00e9, la performance et la s\u00e9curit\u00e9 du syst\u00e8me de messagerie\nParticiper \u00e0 l\u2019assistance utilisateurs sur les briques de la plateforme Hadoop Cloudera Data\n-Travailler avec les projets et les devOps pour assurer un traitement efficace des donn\u00e9es\nEn rejoignant CGI, vous b\u00e9n\u00e9ficiez notamment d\u2019une offre compl\u00e8te de formations (techniques, m\u00e9tiers, d\u00e9veloppement personnel,\u2026), de flexibilit\u00e9 gr\u00e2ce \u00e0 notre accord t\u00e9l\u00e9travail (jusqu\u2019\u00e0 3 jours de t\u00e9l\u00e9travail par semaine), d\u2019une politique de cong\u00e9s avantageuse (27 jours de cong\u00e9s pay\u00e9s, RTT, cong\u00e9s anciennet\u00e9 et enfant malade,\u2026) et d\u2019un package d\u2019avantages int\u00e9ressant (r\u00e9gime d\u2019achats d\u2019actions, participation, CSE,...).\nQualit\u00e9s requises pour r\u00e9ussir dans ce r\u00f4le\nAyant une premi\u00e8re exp\u00e9rience en tant que Data Engineer, vous avez une premi\u00e8re exp\u00e9rience relative aux points suivants:\n-D\u00e9veloppement et int\u00e9gration sur les technologies AWS, Terraform, OpenShift, Kafka et Hadoop\n-Connaissance avanc\u00e9e de l'administration Kafka, y compris la configuration, la gestion et la r\u00e9solution des probl\u00e8mes\n-Mise en \u0153uvre de l'infrastructure en tant que code \u00e0 l'aide de Terraform\n-Bonne compr\u00e9hension des bonnes pratiques de s\u00e9curit\u00e9 pour les syst\u00e8mes cloud, les clusters Kafka et les plateformes Hadoop\nCGI est un employeur inclusif et attentif aux candidatures des personnes en situation de handicap, \u00e0 l\u2019\u00e9volution de carri\u00e8res des hommes et des femmes et au bien-\u00eatre de nos salari\u00e9s LGBT+. Dans un souci d\u2019accessibilit\u00e9 et de clart\u00e9, le point m\u00e9dian n\u2019est pas utilis\u00e9 dans cette annonce. Tous les termes employ\u00e9s se r\u00e9f\u00e8rent aussi bien au genre f\u00e9minin que masculin.\nEnsemble, en tant que propri\u00e9taires, mettons notre savoir-faire \u00e0 l\u2019\u0153uvre.\nLa vie chez CGI est ancr\u00e9e dans l\u2019actionnariat, le travail d\u2019\u00e9quipe, le respect et un sentiment d\u2019appartenance. Chez nous, vous pourrez exploiter votre plein potentiel parce que\u2026\nNous vous invitons \u00e0 devenir propri\u00e9taire d\u00e8s le jour 1 alors que nous travaillons ensemble \u00e0 faire de notre r\u00eave une r\u00e9alit\u00e9. C\u2019est pourquoi nous nous d\u00e9signons comme associ\u00e9s de CGI, plut\u00f4t que comme employ\u00e9s. Nous tirons profit des retomb\u00e9es de notre succ\u00e8s collectif et contribuons activement \u00e0 l\u2019orientation et \u00e0 la strat\u00e9gie de notre entreprise.\nVotre travail cr\u00e9e de la valeur. Vous \u00e9laborerez des solutions novatrices et d\u00e9velopperez des relations durables avec vos coll\u00e8gues et clients, tout en ayant acc\u00e8s \u00e0 des capacit\u00e9s mondiales pour concr\u00e9tiser vos id\u00e9es, saisir de nouvelles opportunit\u00e9s, et b\u00e9n\u00e9ficier d\u2019une expertise sectorielle et technologique de pointe.\nVous ferez \u00e9voluer votre carri\u00e8re en vous joignant \u00e0 une entreprise b\u00e2tie pour cro\u00eetre et durer. Vous serez soutenus par des leaders qui ont votre sant\u00e9 et bien-\u00eatre \u00e0 c\u0153ur et qui vous permettront de saisir des occasions afin de parfaire vos comp\u00e9tences et \u00e9largir les horizons.\nJoignez-vous \u00e0 nous, l\u2019une des plus importantes entreprises de conseil en technologie de l\u2019information (TI) et en management au monde.\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "R"
            ],
            "DataBase": [],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [
                "Hadoop"
            ],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [
                "AWS"
            ],
            "DevTools": [],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [
                "Terraform"
            ],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [
                "OpenShift"
            ],
            "Collaboration": [],
            "Other": [
                "DevOps",
                "Big Data",
                "Cloud"
            ],
            "FrSoftSkills": [
                "Flexibilit\u00e9"
            ],
            "EnSoftSkils": []
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [],
            "Salary": [
                "1"
            ],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "Data Engineer",
        "company": "PROXIAD",
        "location": "Greater Nice Metropolitan Area",
        "link": "https://fr.linkedin.com/jobs/view/data-engineer-at-proxiad-3901014428?position=4&pageNum=5&refId=T%2B%2BV0JbclKMpVoA2J23Itg%3D%3D&trackingId=akF4kKw%2FOHmdQHXCvd6JKA%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Contexte\nEn tant que Data Engineer, votre r\u00f4le consistera \u00e0 r\u00e9aliser la conception, le d\u00e9veloppement, les tests unitaires, la qualification, l'int\u00e9gration continue et la mise en production d'\u00e9volutions sur les projets du p\u00f4le produits scoring.\nCes projets Big Data GCP ont pour objet de d\u00e9velopper des traitements de croisement de donn\u00e9es, exploration data en mode agile (scrum et Safe), industriel (respect de normes), sur l'environnement Google Cloud Platform.\n1 : Conception\nSp\u00e9cification et conception d'une solution se basant sur les d\u00e9veloppements existants.\nMettre en question les choix techniques dans le but de concevoir un logiciel r\u00e9pondant au mieux \u00e0 la demande au moindre co\u00fbt et avec la qualit\u00e9 demand\u00e9e.\nConception de l'expression de besoins, de la r\u00e9ponse \u00e0 l'expression de besoins \u00e0 l'aide des besoins m\u00e9tiers remont\u00e9s par le Product Owner.\n2 : R\u00e9alisation\nD\u00e9veloppement de nouvelles fonctionnalit\u00e9s sur les composants des applications du p\u00f4le produits scoring en environnement GCP (DataProc, GCS, BigQuery, Airflow...)\nTests des d\u00e9veloppements r\u00e9alis\u00e9s\nRevue de code des d\u00e9veloppements des autres d\u00e9veloppeurs\nMise en production via CICD des d\u00e9veloppements\n3 : Suivi du RUN applicatif\nPrendre en charge avec les autres membres de l'\u00e9quipe le RUN des applications du p\u00f4le produits scoring. Cela inclus les t\u00e2ches de rapport quotidien, la gestion des probl\u00e8mes applicatifs, le soutien aux utilisateurs.\nComp\u00e9tences attendues\nMa\u00eetrise op\u00e9rationnelle :\nConfluence\nImpl\u00e9mentation de l\u2019int\u00e9gration continue (Utilisation de la chaine CI/CD existante )\nConnaissance des principes DevOps\nJira\nAnglais (lu, \u00e9crit)\nMa\u00eetrise avanc\u00e9e :\nElaborer un cahier de recette\nBig Query\nSp\u00e9cifications technique et documentation\nD\u00e9veloppement :Python, SQL, Scala, Javascript, GitLab\nExpertise\nGCP : Exp\u00e9rience significative en tant que Data Engineer Cloud. Mise en pratique des produits GCP et en particulier Dataproc, Big Query, composer, workflow, PubSub\nD\u00e9veloppement : Java\nCompr\u00e9hension g\u00e9n\u00e9rale des travaux BigData et du profiling\nInformations compl\u00e9mentaires :\nT\u00e9l\u00e9travail 2 jours par semaines\nR\u00e9mun\u00e9ration aux alentours des 45K\u20ac\nExp\u00e9rience requise : 6 ans\nLocalisation : Mougins\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "Java",
                "Scala",
                "R",
                "Go",
                "JavaScript"
            ],
            "DataBase": [
                "SQL"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [
                "Google Cloud Platform"
            ],
            "DevTools": [
                "Git"
            ],
            "Os": [],
            "DBMS": [
                "BigQuery",
                "Big Query"
            ],
            "SoftBigDataProcessing": [],
            "Automation": [
                "Airflow"
            ],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [
                "JIRA",
                "Confluence"
            ],
            "Other": [
                "DevOps",
                "Big Data",
                "Cloud",
                "CI/CD"
            ],
            "FrSoftSkills": [],
            "EnSoftSkils": []
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s",
                "6",
                "6",
                "6"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "CDI - DATA ENGINEER SPARK SCALA JUNIOR - H/F",
        "company": "ITNOVEM.",
        "location": "Paris, \u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/cdi-data-engineer-spark-scala-junior-h-f-at-itnovem-3899544280?position=5&pageNum=5&refId=T%2B%2BV0JbclKMpVoA2J23Itg%3D%3D&trackingId=Z77%2B2%2BZ%2F6%2B2HP48vuwZ0vg%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "ITNOVEM, qui sommes-nous ?\nFiliale technologique du groupe SNCF, int\u00e9gr\u00e9e \u00e0 la Direction du Digital et des Syst\u00e8mes d\u2019information, Itnovem\n.\nse positionne comme expert de l\u2019Internet Industriel. Porteuse de grands projets de la r\u00e9volution digitale, notre soci\u00e9t\u00e9 est en constante recherche de profils pour rejoindre la grande aventure de l\u2019Internet des objets, de la data science et de l\u2019accompagnement des projets digitaux.\nQu\u2019il s\u2019agisse de maintenance pr\u00e9dictive, d\u2019aide \u00e0 la d\u00e9cision sur la maintenance des infrastructures, de gare 4.0, d\u2019usine du futur, ou de s\u00e9curisation des assets, nos \u00e9quipes font valoir \u00e0 la fois une exp\u00e9rience m\u00e9tier et une expertise technique sans cesse renouvel\u00e9e, dans le respect des valeurs du groupe :\nExcellence\n,\nInnovation\n,\nCollectif\n,\nAgile\n,\nEngagement.\nCONTEXTE\nAu sein du p\u00f4le Factory Data & IA et dans le cadre de la mont\u00e9e en charge des projets, nous sommes \u00e0 la recherche d'un\u00b7e data engineer Scala/Spark junior.\nRattach\u00e9\u00b7e aux \u00e9quipes Data Engineering et en collaboration avec les membres de l\u2019\u00e9quipe, son r\u00f4le sera de contribuer aux projets data sur stack Scala/Spark et \u00e0 l\u2019am\u00e9lioration de l\u2019outillage et des process internes.\nLe recrutement intervient dans le cadre de la cr\u00e9ation d\u2019un plateau projet d\u00e9di\u00e9 \u00e0 l\u2019activit\u00e9 TGV sur Nantes.\nMISSIONS\nParticiper au d\u00e9veloppement des projets data sur stack Scala/Spark\nEtre acteur de la mise en place de bonnes pratiques de communication entre les plateaux nantais et parisiens\nAvec l\u2019appui de l\u2019\u00e9quipe, \u00eatre impliqu\u00e9\u00b7e dans la roadmap technologique (pratiques, outils) et de l\u2019am\u00e9lioration continue du p\u00e9rim\u00e8tre Scala/Spark\nContribuer proactivement \u00e0 la qualit\u00e9 et aux comp\u00e9tences des \u00e9quipes Data Science et Engineering : veille techno, capitalisation\u2026\nLE PROFIL RECHERCHE\nComp\u00e9tences m\u00e9tiers & outils :\nExp\u00e9rience professionnelle (alternance, stage) ou acad\u00e9mique sur le langage Scala et le d\u00e9veloppement d\u2019applications Spark\nConnaissances autour du SQL (principes, langage, mod\u00e9lisation)\nApp\u00e9tence sur les aspects fonctionnels et m\u00e9tiers d\u2019un projet\nNotions de CI/CD (notre stack : Maven, Gitlab, Jenkins, Artifactory, Ansible)\nComp\u00e9tences transverses :\nInt\u00e9r\u00eat prononc\u00e9 pour le software engineering\nAisance relationnelle\nProactivit\u00e9 et clart\u00e9 dans la communication\nRigueur et organisation\nForce de proposition\nBonne communication \u00e9crite et orale\nExp\u00e9riences et formations\nTitulaire d\u2019un bac+5 sp\u00e9cialis\u00e9 g\u00e9nie logiciel / d\u00e9veloppement ou exp\u00e9rience \u00e9quivalente.\nVous venez d\u2019obtenir votre dipl\u00f4me ou occupez d\u00e9j\u00e0 votre premier poste dans le domaine du d\u00e9veloppement de pipelines Data.\nLocalisation\nPoste bas\u00e9 \u00e0 Saint Denis, possiblement \u00e0 Lyon\nT\u00e9l\u00e9travail jusqu\u2019\u00e0 3 jours par semaine.\nD\u2019autres raisons de rejoindre ITNOVEM !\n\ud83d\ude80 En tant que filiale SNCF, des opportunit\u00e9s de carri\u00e8res internes vous sont offertes.\n\ud83d\udcda ITNOVEM croit en la formation continue de ses collaborateurs et leur donne l\u2019opportunit\u00e9 de s\u2019inscrire \u00e0 une formation par an minimum.\n\ud83d\ude8a Vos titres de transport sont pris en charge \u00e0 hauteur de 75%.\n\ud83c\udf7d\ufe0f Via la carte titres-restaurant Swile, vous b\u00e9n\u00e9ficiez de 9,25 \u20ac par jour dont 60% pris en charge par ITNOVEM.\n\ud83d\udcbb Chez ITNOVEM, vous b\u00e9n\u00e9ficiez jusqu\u2019\u00e0 3 jours de t\u00e9l\u00e9travail par semaine.\n\ud83c\udfd6\ufe0f ITNOVEM vous permet de profiter de 28 cong\u00e9s et de 16 RTT pour les cadres et 10 pour les non-cadres. Par ailleurs, 2 des 3 jours de cong\u00e9s pour enfant malade sont r\u00e9mun\u00e9r\u00e9s.\n\ud83d\udc6b La mise en \u0153uvre de l\u2019\u00e9galit\u00e9 professionnelle femmes/hommes est primordiale chez ITNOVEM. A chaque nouvelle embauche, l'entreprise s'engage \u00e0 proposer une r\u00e9mun\u00e9ration \u00e9quivalente tant aux femmes qu'aux hommes.\n\u267b\ufe0f ITNOVEM incite tous les collaborateurs \u00e0 trier leurs d\u00e9chets et les gobelets ont \u00e9t\u00e9 bannis. Par ailleurs, chaque ann\u00e9e, ITNOVEM participe \u00e0 \u00ab La grande collecte \u00bb, une initiative SNCF qui permet de collecter les PC devenus obsol\u00e8tes en leur offrant une seconde vie\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Scala",
                "R",
                "Go"
            ],
            "DataBase": [
                "SQL"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [
                "Spark"
            ],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [],
            "DevTools": [
                "Git",
                "Jenkins"
            ],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [
                "Ansible"
            ],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [
                "CI/CD"
            ],
            "FrSoftSkills": [
                "Communication",
                "Collaboration",
                "Organisation"
            ],
            "EnSoftSkils": [
                "Communication",
                "Collaboration",
                "Initiative"
            ]
        },
        "details": {
            "JobDetail": [
                "Junior"
            ],
            "TypeContract": [],
            "Salary": [],
            "Level": [
                "Bac+5"
            ],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "Junior Data Engineer (H/F/N)",
        "company": "Ekimetrics",
        "location": "Paris, \u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/junior-data-engineer-h-f-n-at-ekimetrics-3903416527?position=6&pageNum=5&refId=T%2B%2BV0JbclKMpVoA2J23Itg%3D%3D&trackingId=rKkK5yorfgP2vq5BIs0%2BJQ%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Ekimetrics\nest leader en data science et fournisseur de solutions AI. Depuis 2006, nous utilisons la data science au service de l\u2019optimisation de performance marketing, business, et de la transition vers une performance plus durable.\nSi vous \u00eates passionn\u00e9.e de data, ou de technologie en g\u00e9n\u00e9ral, et que vous avez envie d\u2019\u00eatre acteur.rice de votre avenir professionnel, votre place est s\u00fbrement chez Ekimetrics !\n\ud83d\udccaEkimetrics, c\u2019est:\n\u2022 400 expert.e.s en data science\n\u2022 1000 projets divers et vari\u00e9s pour plus de 350 clients\n\u2022 4 bureaux : Paris, Hong Kong, Londres et New York\n\u2022 1 milliard de $ de profits g\u00e9n\u00e9r\u00e9s pour nos clients depuis 2006\n\u2022 7000 tonnes de CO2 \u00e9vit\u00e9es pour nos clients en 2022\n\ud83c\udf31Chez Ekimetrics, nous avons l\u2019ambition d\u2019accompagner nos clients \u00e0 repenser leur business model, en r\u00e9conciliant performance \u00e9conomique, environnementale et sociale, gr\u00e2ce \u00e0 la data science.\nC\u2019est pourquoi nous avons en interne toutes les comp\u00e9tences nous permettant de r\u00e9pondre aux besoins de nos clients: Product Managers, Product Designers, Data Architects, Data Engineers, DevOps Engineers, Data Scientists.\nPourquoi recrutons-nous ?\nEn tant que Data Engineer, vous serez impliqu\u00e9 dans des projets stimulants avec des clients internationaux de premier plan dans des industries diverses, en construisant des solutions analytiques sur mesure pour r\u00e9pondre aux enjeux de nos clients. Vous travaillerez en \u00e9quipe, avec d'autres consultants Ekimetrics (data engineers, data scientists, software engineers) sur 1 ou 2 projets simultan\u00e9ment. Vous b\u00e9n\u00e9ficierez de nos partenariats technologiques et d\u2019une offre de formation pour vous accompagner dans votre mont\u00e9e en comp\u00e9tences.\nPlus particuli\u00e8rement vos responsabilit\u00e9s seront de\n:\n\u2022 Concevoir et d\u00e9velopper des solutions permettant de collecter et pr\u00e9parer la donn\u00e9e ;\n\u2022 Impl\u00e9menter et industrialiser des pipelines de donn\u00e9es dans des environnements Cloud (Azure, GCP, AWS, Databricks, Snowflake) ;\n\u2022 D\u00e9velopper des outils destin\u00e9s \u00e0 faciliter l\u2019ex\u00e9cution et le d\u00e9ploiementdes pipelines de donn\u00e9es (CICD, DevOps, MLOps) ;\n\u2022 Approfondir vos connaissances en GenAI, Machine Learning, MMO ;\n\u2022 Participer aux activit\u00e9s de R&D. (Veille, formations, animation de Meetups, Hackathons, etc.)\nLe profil et les comp\u00e9tences recherch\u00e9es\n:\n\u2022 Bac+ 5 Ecole d'ing\u00e9nieur ou \u00c9quivalent ;\n\u2022 Premi\u00e8re exp\u00e9rience sur des sujets Big Data (Projet ou exp\u00e9rience professionnelle) ;\n\u2022 Connaissances avanc\u00e9es en base de donn\u00e9es et en d\u00e9veloppement (Python, SQL, Spark) ;\n\u2022 Exp\u00e9rience dans un environnement Cloud ;\n\u2022 Connaissances avanc\u00e9es en acquisition de donn\u00e9es ;\n\u2022 App\u00e9tence pour la Data Science.\n\ud83e\udd1d Pourquoi nous rejoindre ?\nRejoindre Ekimetrics, c\u2019est int\u00e9grer une entreprise dont les valeurs s\u2019appliquent au quotidien :\n\u2022 Evoluer dans un environnement entrepreneurial et non traditionnel (\n#curiosit\u00e9)\n\u2022 \u00catre capable de donner et recevoir du feedback pour s\u2019am\u00e9liorer en continu (\n#excellence\n)\n\u2022 Se former d\u00e8s son arriv\u00e9e et en continu gr\u00e2ce \u00e0 une exp\u00e9rience apprenante unique, riche de nombreuses ressources (internes, externes, live et digital) alliant savoirs techniques, savoir-\u00eatre et savoir-faire (\n#transmission\n)\n\u2022 Faire partie d\u2019une communaut\u00e9 accueillante et soud\u00e9e(\n#plaisir\n)\n\u2022 Imaginer des solutions inattendues & sortir de sa zone de confort (\n#cr\u00e9ativit\u00e9\n)\nEn 2023, Ekimetrics a obtenu le statut d\u2019entreprise \u00e0 mission qui t\u00e9moigne de notre ambition forte en mati\u00e8re de RSE. Notre raison d\u2019\u00eatre: Faire de la data science et de l\u2019intelligence artificielle l\u2019acc\u00e9l\u00e9rateur de la transformation durable des organisations.\nNous sommes \u00e9galement certifi\u00e9s Great Place to Work\u00a9 en France, au Royaume-Uni et aux Etats-Unis, et notre bureau de Hong Kong a re\u00e7u le prix Best Companies to Work for in Asia 2023\u00a9.\n\ud83e\udd29 Vous aurez acc\u00e8s \u00e0\u2026\n\u2022 Au catalogue de formation Eki.Academy qui contient des programmes qui vous feront monter en comp\u00e9tences sur nos solutions et nos m\u00e9tiers, des parcours apprenants sur notre plateforme digitale ainsi que des programmes d\u00e9di\u00e9s \u00e0 nos enjeux prioritaires, dont la sensibilisation aux sujets environnementaux avec la Climate School ;\n\u2022 Une vie sportive, artistique, musicale, ludique, caritative et engag\u00e9e : de notre salle de sport privatis\u00e9e \u00e0 nos expositions d\u2019art, en passant par des jeux vid\u00e9o et des concerts, ou encore les d\u00e9fis RSE sur la plateforme Vendredi. Toutes ces initiatives sont port\u00e9es par nos Eki.People ;\n\u2022 De nombreux \u00e9v\u00e8nements et s\u00e9minaires pour rester proche de votre communaut\u00e9 ;\n\u2022 Des locaux modernes dans un quartier dynamique au c\u0153ur de Paris (Grands boulevards) ;\n\u2022 Une politique de t\u00e9l\u00e9travail flexible.\n\ud83d\udd04Notre processus recrutement :\n\ud83d\udd38Un entretien RH avec un.e recruteur.se\n\ud83d\udd38Un test technique ou\npeer-to-peer\ninterview selon profil\n\ud83d\udd38Une \u00e9tude de cas avec un.e consultant.e\n\ud83d\udd38Un entretien final avec un.e Manager ou Partner\nNous serions ravi.e.s de vous donner de plus amples informations lors d\u2019un entretien et attendons votre candidature avec impatience!\nEn tant qu\u2019employeur, Ekimetrics offre \u00e0 tous les m\u00eames opportunit\u00e9s d\u2019acc\u00e8s \u00e0 l\u2019emploi sans distinction de genre, ethnicit\u00e9, religion, orientation sexuelle, statut social, handicap et d\u2019\u00e2ge. Ekimetrics veille \u00e0 d\u00e9velopper un environnement de travail inclusif qui refl\u00e8te la diversit\u00e9 dans ses \u00e9quipes.\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "R"
            ],
            "DataBase": [
                "SQL"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [
                "Spark",
                "Databricks"
            ],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [
                "AWS",
                "Azure"
            ],
            "DevTools": [
                "Git"
            ],
            "Os": [],
            "DBMS": [
                "Snowflake",
                "Snowflake"
            ],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [
                "DevOps",
                "Big Data",
                "ML",
                "Machine Learning",
                "Cloud"
            ],
            "FrSoftSkills": [
                "Cr\u00e9ativit\u00e9",
                "Organisation"
            ],
            "EnSoftSkils": [
                "Initiative"
            ]
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "Data Engineer confirm\u00e9 (H/F)",
        "company": "BforBank",
        "location": "Greater Paris Metropolitan Region",
        "link": "https://fr.linkedin.com/jobs/view/data-engineer-confirm%C3%A9-h-f-at-bforbank-3918327555?position=7&pageNum=5&refId=T%2B%2BV0JbclKMpVoA2J23Itg%3D%3D&trackingId=EDXCCYjnmeSErR6yzcCRGQ%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Sur le mod\u00e8le d'une\n\"Tech company\",\nBforBank place\nl'humain et le digital\nau c\u0153ur de sa transformation. Notre mission,\noffrir \u00e0 nos clients une exp\u00e9rience bancaire incomparable\npour r\u00e9pondre \u00e0 leurs besoins et usages mobile. \ud83c\udf1f \ud83d\udcf1\nRejoindre BforBank c\u2019est\nrejoindre une \u00e9quipe engag\u00e9e\ndans un\ngrand projet de d\u00e9veloppement strat\u00e9gique en France et en Europe.\nNous sommes aujourd\u2019hui 350 passionn\u00e9(e)s et\nrecherchons nos talents pour construire la banque de demain\n. \ud83d\ude80\nNous croyons en la force du collectif, chaque jour rassembl\u00e9s autour de nos valeurs, de simplicit\u00e9, d'optimisme et d\u2019engagement, encourageant chacun \u00e0 oser, essayer et accepter d\u2019\u00e9chouer.\n\ud83c\udfaf Au sein de la Direction Technologie, la Data Factory a pour objectifs de piloter, d\u00e9finir, d\u00e9ployer et op\u00e9rer les meilleures solutions technologiques r\u00e9pondant aux cas d\u2019usage data et d\u2019automatisations de processus de la banque au travers de plateformes. \u00c9galement, la Data Factory contribue au d\u00e9veloppement des produits, \u00e0 la cristallisation et \u00e0 la diffusion des pratiques au sein des Squads BforBank sur les usages data dans la banque.\nTu rejoindras une squad en charge de r\u00e9soudre des probl\u00e9matiques m\u00e9tiers en cr\u00e9ant des solutions applicatives utilisant les donn\u00e9es, des data products, avec pour finalit\u00e9s la prise de d\u00e9cision via des moteurs de calcul ou des dashboards, la cr\u00e9ation de flux r\u00e9glementaires, la cr\u00e9ation de data layer ou de reportings.\n\ud83d\ude80 Tes missions principales sont les suivantes :\n\u00b7 Participer aux analyses, \u00e9tudes d\u2019impacts et cadrage techniques\n\u00b7 Concevoir des solutions en respectant les bonnes pratiques d\u2019architecture data et d\u00e9veloppement\n\u00b7 R\u00e9aliser le d\u00e9veloppement de nouveaux data products et assurer la maintenance \u00e9volutive et corrective des data products existants\n\u00b7 R\u00e9diger la documentation technique des data products\n\u00b7 Assurer un support aux testeurs\n\u00b7 Reporter de ton activit\u00e9 \u00e0 ta Squad et travailler dans une d\u00e9marche d\u2019efficacit\u00e9 collective\nConcr\u00e8tement tu seras amen\u00e9(e) \u00e0 produire les livrables suivants :\n\u00b7 R\u00e9aliser du code applicatif \u00e0 l\u2019\u00e9tat de l\u2019art sur notre nouvelle Data Platform\n\u00b7 Cr\u00e9er des data layer et des rapports sur notre outil de Data Visualisation\n\u00b7 R\u00e9diger les documentations techniques li\u00e9es \u00e0 ta solution, incluant le mod\u00e8le de donn\u00e9es, les proc\u00e9dures, l\u2019ordonnancement\nCe que tu ma\u00eetrises :\n\u00b7 Maitrise des services manag\u00e9s de GCP (BigQuery, dataproc, dataflow, CloudSQL \u2026)\n\u00b7 Maitrise du langage Python, Pandas, Spark\n\u00b7 Maitrise de la mod\u00e9lisation de base de donn\u00e9es et du langage SQL\n\u00b7 Maitrise d\u2019une chaine CI/CD (GitLab\u2026)\n\u00b7 Bonne connaissance de Kafka\n\u00b7 Bonne connaissance d\u2019un outil d\u2019int\u00e9gration de donn\u00e9es type ETL (Informatica\u2026)\n\u00b7 Connaissance de l\u2019infra as code (Terraform)\n\u00b7 Connaissance d\u2019un outil de reporting (Looker, BO\u2026)\n\ud83e\udd1d Ce poste est fait pour toi si :\n\u00b7 Tu es passionn\u00e9(e) par la Data et leurs usages\n\u00b7 Tu es orient\u00e9 r\u00e9solution de probl\u00e8me, est curieux(se) et force de proposition\n\u00b7 Tu appr\u00e9cies le travail en \u00e9quipe\n\u00b7 Tu as un bon relationnel et est rigoureux(se)\n\u00b7 Tu as une bonne capacit\u00e9 d\u2019analyse et r\u00e9dactionnelle\n\u00b7 Tu t\u2019adaptes rapidement aux changements\n\ud83c\udf93\nFormation :\nTu es dipl\u00f4m\u00e9(e) d\u2019un master en \u00e9cole de commerce, \u00e9cole d\u2019ing\u00e9nieur ou \u00e9quivalent.\nChez BforBank nous recherchons avant tout des comp\u00e9tences. Tu ne disposes pas du dipl\u00f4me requis mais as des exp\u00e9riences \u00e9quivalentes ? N'h\u00e9site pas \u00e0 postuler !\n\ud83d\udcbc\nExp\u00e9rience :\nExp\u00e9rience confirm\u00e9e de 3 ans en tant que Data Engineer.\nEn rejoignant BforBank tu trouveras\u2026\n\u00b7 Un projet ambitieux de transformation digitale et culturelle \u00e0 l\u2019\u00e9chelon europ\u00e9en, terrain d\u2019innovation et d\u2019ouverture d\u2019esprit\n\u00b7 Une organisation apprenante, proposant un large choix de formations toute l\u2019ann\u00e9e, et qui favorise l\u2019\u00e9change avec les autres marques du Groupe\n\u00b7 Une promo RSE multi-m\u00e9tiers qui fait \u00e9voluer en continu les actions de BforBank vers une banque plus responsable\n\u00b7 Une organisation du travail en mode Agile, impliquant un degr\u00e9 \u00e9lev\u00e9 de collaboration et d'autonomie tout en travaillant avec un groupe de pairs diversifi\u00e9s.\n\u00b7 Une Direction Technologie en pleine expansion, porteuse de nombreux d\u00e9fis strat\u00e9giques\nMais aussi\u2026\nDe 2 jours \u00e0 5 jours de t\u00e9l\u00e9travail modulables par semaine, dans la limite de 84 jours par an (frais de fonctionnement pris en charge)\n25 jours de cong\u00e9s + 16 jours de RTT\n80% du co\u00fbt de la mutuelle d\u2019entreprise pris en charge / couvert\nAvantages collaborateurs Cr\u00e9dit Agricole : taux et tarifs pr\u00e9f\u00e9rentiels\nDes frais de transports rembours\u00e9s \u00e0 75%\nUn restaurant d\u2019entreprise\nDes douches pour les sportifs et un tarif avantageux aupr\u00e8s d\u2019une salle de sport toute proche\n\ud83d\udccd Le poste est bas\u00e9 \u00e0 La D\u00e9fense, dans des locaux flambant neufs !\nBforBank s'engage \u00e0 garantir l'\u00e9galit\u00e9 des chances aux candidats car nous sommes convaincus de la richesse apport\u00e9e par la diversit\u00e9 et l'inclusion dans nos \u00e9quipes.\nRencontrons-nous !\nLe processus de recrutement se d\u00e9roule en 4 \u00e9tapes :\n\ud83e\uddd1\ud83c\udffc\u200d\ud83d\udcbb\nCall de 30 minutes avec notre \u00e9quipe Talent Acquisition\nEchange avec le Data Factory Manager et notre \u00e9quipe Talent Acquisition (pr\u00e9sentiel)\nEchange avec une personne de l\u2019\u00e9quipe avec qui tu seras amen\u00e9 \u00e0 travailler (visio)\nEchange avec le CTO (visio ou pr\u00e9sentiel)\nNotre processus de recrutement dure en moyenne 3 semaines et l\u2019\u00e9quipe Talent Acquisition se tiendra \u00e0 ta disposition pour te donner un maximum de visibilit\u00e9 sur l\u2019avanc\u00e9e du process.\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "R",
                "Go"
            ],
            "DataBase": [
                "SQL"
            ],
            "DataAnalytics": [
                "Pandas",
                "R"
            ],
            "BigData": [
                "Spark"
            ],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [],
            "DevTools": [
                "Git"
            ],
            "Os": [],
            "DBMS": [
                "BigQuery"
            ],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [
                "Terraform"
            ],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [
                "Cloud",
                "CI/CD"
            ],
            "FrSoftSkills": [
                "Collaboration",
                "Organisation"
            ],
            "EnSoftSkils": [
                "Collaboration"
            ]
        },
        "details": {
            "JobDetail": [
                "Confirm\u00e9"
            ],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s",
                "3",
                "3",
                "3"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "(Senior) Data Engineer",
        "company": "Mirakl",
        "location": "Paris, \u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/senior-data-engineer-at-mirakl-3904071960?position=8&pageNum=5&refId=T%2B%2BV0JbclKMpVoA2J23Itg%3D%3D&trackingId=yt%2BOLeejTmunadfgqcN3%2FQ%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Mirakl, leader et pionnier de l\u2019\u00e9conomie de plateforme, propose aux entreprises une suite unique de solutions leur permettant de transformer significativement leur e-commerce afin d'acc\u00e9l\u00e9rer de fa\u00e7on durable et rentable leur croissance. Depuis 2012, Mirakl accompagne les entreprises B2C et B2B avec la technologie la plus avanc\u00e9e, s\u00e9curis\u00e9e et \u00e9volutive leur permettant de digitaliser leur activit\u00e9 et d'\u00e9largir leur offre via la marketplace ou le dropship, faciliter la gestion des catalogues et des paiements de leurs fournisseurs pour plus d'efficacit\u00e9, offrir une exp\u00e9rience d'achat personnalis\u00e9e \u00e0 leurs clients, et augmenter leurs profits gr\u00e2ce au retail media. Bas\u00e9e \u00e0 Paris et Boston, Mirakl est certifi\u00e9e Great Place to Work.\nA propos de Mirakl Labs\nNos \u00e9quipes techniques et produits, nomm\u00e9es Mirakl Labs, sont principalement r\u00e9parties entre nos 2 hubs situ\u00e9s \u00e0 Paris et \u00e0 Bordeaux. Elles collaborent au quotidien afin d'adresser les probl\u00e9matiques de nos clients et utilisateurs en r\u00e9pondant \u00e0 diff\u00e9rents challenges li\u00e9s aux nouvelles fonctionnalit\u00e9s, \u00e0 la scalabilit\u00e9, la s\u00e9curit\u00e9 et l\u2019ergonomie\u2026\nElles op\u00e8rent en mode agile et s'organisent en Squads compos\u00e9es d'un Squad Lead, de 5 d\u00e9veloppeurs, d'un Product Manager et d'un QA. Chaque Squad est sp\u00e9cialis\u00e9e sur un scope fonctionnel afin de concevoir et r\u00e9aliser de nouvelles features, leurs \u00e9volutions et des APIs (avec un d\u00e9coupage en micro-services). Nos \u00e9quipes Infrastructure, Architecture, S\u00e9curit\u00e9, Documentation, Product Design, Data et Support op\u00e8rent en transverse en apportant leur expertise et de la coh\u00e9rence sur l\u2019ensemble des produits.\nToutes les \u00e9quipes sont responsables de leur p\u00e9rim\u00e8tre et chacun des collaborateurs apporte son exp\u00e9rience et ses id\u00e9es. Innovation, feedback et implication dans les prises de d\u00e9cision sont au c\u0153ur de notre philosophie.\nEt pour favoriser ce partage avec d\u2019autres passionn\u00e9s, nous sommes sponsors, speakers, et h\u00f4tes de diff\u00e9rents \u00e9v\u00e9nements, meetups, et associations de la sc\u00e8ne Tech en France. Au cours des derni\u00e8res ann\u00e9es, nous avons particip\u00e9 \u00e0 des \u00e9v\u00e9nements tels que Devoxx, ReactEurope, ProductConf et Flupa UX Days.\nA propos du job\nLa solution SaaS Mirakl est le moteur des marketplaces des plus importants e-commer\u00e7ants \u00e0 travers le monde. Cette solution g\u00e8re et produit de gros volumes de donn\u00e9es qui pr\u00e9sentent des challenges extr\u00eamement int\u00e9ressants pour les sp\u00e9cialistes de la donn\u00e9e (produits, commandes, clients, niveaux de stock, prix, messages, appels API, donn\u00e9es de navigation, s\u00e9ries temporelles, donn\u00e9es g\u00e9olocalis\u00e9es etc.).\nEn tant que (Senior) Data Engineer au sein de l\u2019\u00e9quipe Data Mirakl, vos principales missions seront de :\ncontribuer \u00e0 l'enrichissement de la Data Platform (ETL)\nam\u00e9liorer la robustesse de nos pipelines de production pour nos applications Machine Learning (inf\u00e9rence real time etc.)\nInt\u00e9gr\u00e9(e) dans une \u00e9quipe de sp\u00e9cialistes de la donn\u00e9e (data engineers, machine learning engineers, data scientists, data analysts), vous \u00eates un des acteurs cl\u00e9s pour garantir la place de Mirakl comme solution dominante sur son march\u00e9.\nNotre stack et nos outils\nApache Spark, Kafka, AWS, Databricks, Python, Airflow, Mlflow, Tensorflow, Delta lake, Superset, Kubernetes, Redshift, SQL, Terraform, Ansible\nAu quotidien, vous allez :\nParticiper \u00e0 la d\u00e9finition et \u00e0 l\u2019impl\u00e9mentation d\u2019une architecture performante, robuste, scalable et aux co\u00fbts ma\u00eetris\u00e9s pour nos applications Spark ainsi que pour nos pipelines de production de Machine Learning (\u00e9valuation des feature stores, refactoring de DAG Airflow)\nAccompagner les Data Scientists lors de leur mise en production (relecture de code, pair programming) et mettre en place les best practices\nOptimiser et am\u00e9liorer la CI/CD de l\u2019\u00e9quipe en collaboration avec l\u2019\u00e9quipe SRE\nAssurer la mont\u00e9e en comp\u00e9tence des membres de l\u2019\u00e9quipe sur les sujets de MLOps et Data Engineering\nR\u00e9fl\u00e9chir \u00e0 la meilleure fa\u00e7on d'int\u00e9grer les donn\u00e9es Google Analytics dans la data platform\nPartager ses connaissances et pr\u00e9senter les travaux devant toutes les \u00e9quipes Labs\nCe qu\u2019on peut vous apporter :\nDes projets data driven, divers et vari\u00e9s (traitements massifs d\u2019images, de textes, time series etc.) pour des produits diff\u00e9rents de Mirakl\nUne culture orient\u00e9e sur la veille technologique\nDes projets qui ont un vrai impact business devant \u00eatre d\u00e9ploy\u00e9s sur des centaines de clients dans un contexte multilingue\nQuelques exemples de sujets en cours :\nEnrichissement des donn\u00e9es produit \u00e0 partir des images et des descriptions\nMod\u00e9ration automatique des produits\nMapping automatique des donn\u00e9es produit\nIdentification des produits \u00e0 fort potentiels\nD\u00e9tection de comportements frauduleux\nSentiment analysis sur les messages \u00e9chang\u00e9s entre clients et vendeurs et dans les \u00e9valuations\nD\u00e9termination de prix optimaux\nMonitoring de la qualit\u00e9 de service des vendeurs\nDes applications d\u2019inf\u00e9rence en synchrone de nos mod\u00e8les de ML\nVous aimerez ce job si :\nVous \u00eates passionn\u00e9(e) par la data et les technologies modernes permettant d'en tirer partie\nVous vous int\u00e9ressez \u00e0 la data science et avez des connaissances g\u00e9n\u00e9rales sur les algorithmes de Machine Learning\nVous avez un background en d\u00e9veloppement et avez \u00e9volu\u00e9 dans un environnement Data\nVous avez a minima 4 ans d\u2019exp\u00e9rience en environnement Machine Learning et/ou Data\nVous avez mis en production avec succ\u00e8s des applications Big Data faisant appel \u00e0 du Machine Learning, du NLP, du traitement d\u2019images dans des projets d'envergure, \u00e0 fort volume de donn\u00e9es\nVotre ma\u00eetrisez Python, \u00eates un pro des frameworks data de la fondation Apache et \u00eates \u00e0 l'aise dans un environnement AWS\nVous ma\u00eetrisez au moins un outil d\u2019orchestration (Airflow, Data Pipeline ou tout autre outil similaire)\nVous pr\u00e9sentez vos travaux de mani\u00e8re simple et accessible\nVous fa\u00eetes preuve d'un bon relationnel et vous aimez mentorer des collaborateurs\nVous parlez couramment anglais et fran\u00e7ais\nLes plus pour le poste :\nVous avez une exp\u00e9rience significative dans le domaine du e-commerce\nVous avez d\u00e9j\u00e0 mis en place un Data Lake, Data Warehouse ou une Data Platform\nVous avez d\u00e9ploy\u00e9 des applicatifs en environnement Kubernetes\nVous avez mis en place des pipelines d'ingestion de donn\u00e9es avec une approche CDC \u00e0 l'aide de Debezium ou autre\nVous ma\u00eetrisez Java/Scala\nMirakl est engag\u00e9e en faveur de la diversit\u00e9, de l\u2019\u00e9galit\u00e9 des chances et de l\u2019inclusion. Nous c\u00e9l\u00e9brons nos diff\u00e9rences car nous sommes convaincus que les qualit\u00e9s visibles et invisibles de chaque Mirakl Worker sont une source de force et d\u2019innovation. Dans le cadre de cet engagement, nous \u00e9tudions toutes les candidatures sans distinction de : genre, ethnicit\u00e9, religion, orientation sexuelle, handicap, \u00e2ge ou toute autre caract\u00e9ristique prot\u00e9g\u00e9e par la loi.\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "Java",
                "Scala",
                "R",
                "Go"
            ],
            "DataBase": [
                "SQL"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [
                "Spark",
                "Databricks"
            ],
            "MachingLearning": [
                "TensorFlow"
            ],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [
                "AWS"
            ],
            "DevTools": [
                "Git"
            ],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [
                "Ansible",
                "Kubernetes",
                "Airflow"
            ],
            "InfrastructureAsCode": [
                "Terraform"
            ],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [
                "Kubernetes"
            ],
            "Collaboration": [],
            "Other": [
                "Big Data",
                "ML",
                "Machine Learning",
                "CI/CD"
            ],
            "FrSoftSkills": [
                "Collaboration"
            ],
            "EnSoftSkils": [
                "Collaboration"
            ]
        },
        "details": {
            "JobDetail": [
                "Senior"
            ],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s",
                "4",
                "4",
                "4"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "Data Engineer | Python - Azure | IA & Machine Learning  | Paris ou Remote Partiel",
        "company": "Octopus IT - Expert du recrutement tech",
        "location": "Paris, \u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/data-engineer-python-azure-ia-machine-learning-paris-ou-remote-partiel-at-octopus-it-expert-du-recrutement-tech-3664568765?position=9&pageNum=5&refId=T%2B%2BV0JbclKMpVoA2J23Itg%3D%3D&trackingId=VOh7imz%2B%2FpNP0UBJ9b97qQ%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "La soci\u00e9t\u00e9\nCr\u00e9\u00e9e il y a plus de 2 ans, cette startup est la premi\u00e8re base de connaissance intelligente d\u00e9di\u00e9e aux services clients. Leur mission ? En finir avec la frustration lorsque l'on contact un Help Desk.\nPour cela, elle propose aux entreprises la possibilit\u00e9 de d\u00e9livrer une exp\u00e9rience client d'exception : rapide et de qualit\u00e9. Gr\u00e2ce \u00e0 leur moteur de recherche intelligent, cette entreprise est capable de centraliser toute la connaissance interne de l'entreprise (proc\u00e9dures, produits, modes op\u00e9ratoires, etc.) et la diffuse intelligemment dans les outils de production des conseillers de service client.\nR\u00e9sultat :\nPlus besoin de chercher l'information\nDes r\u00e9ponses instantan\u00e9es et de meilleures qualit\u00e9es\nUne autonomie totale des collaborateurs\nApr\u00e8s une croissance fulgurante, elle a su s\u00e9duire \u00e0 la fois de nombreuses scale up (Luko, OpenClassrooms, Japhy...) et grands groupes (BNP Paribas, La Poste, Fnac Darty...).\nApr\u00e8s le recrutement de leur Lead Data (r\u00e9aliser ensemble) et suite \u00e0 l'annonce de leur lev\u00e9e de 2,5M\u20ac pour tripler la taille de ses \u00e9quipes, le but est maintenant de s'imposer tr\u00e8s vite comme la base de connaissance de r\u00e9f\u00e9rence en France et en Europe. Pour ce faire, nous recherchons un Data Engineer.\nLe poste\nEn travaillant main dans la main avec le Lead Data, ta mission sera de d\u00e9velopper et de maintenir des flux de donn\u00e9es complexes et robustes. La donn\u00e9e \u00e9tant au coeur de l' entreprise, dans le produit comme dans la strat\u00e9gie, tu seras amen\u00e9 \u00e0 travailler avec un panel d\u2019interlocuteurs tr\u00e8s vari\u00e9s :\nData Scientists sur des sujets comme le monitoring des mod\u00e8les de production et l\u2019enrichissement des donn\u00e9es d\u2019entrainement.\nProduct Team sur des sujets de performance et d\u2019acheminement de donn\u00e9es au service de fonctionnalit\u00e9s produit telles que le dashboard d\u2019analytics \u00e0 destination de nos clients.\nCustomer Success / Strategy sur des sujets de pilotage comme le suivi de l\u2019utilisation de notre plateforme ou la mise en place de KPIs de performance.\nTu travailleras sur les probl\u00e9matiques suivantes :\nTu seras responsable de notre architecture de donn\u00e9es et de son outillage, mais aussi de la mise en place de pipelines de donn\u00e9es complexes et robustes.\nTu seras amen\u00e9 \u00e0 mettre en place des outils de monitoring et d\u2019alerting pour suivre de pr\u00e8s nos nombreuses pipelines de donn\u00e9e.\nTu seras garant de la qualit\u00e9 de nos donn\u00e9es en assurant l\u2019application des guidelines de code et des tests automatis\u00e9s pour chacune de nos pipelines.\nTu seras amen\u00e9 \u00e0 mettre en place des outils de reporting / insights \u00e0 destination d\u2019interlocuteurs vari\u00e9s (Data Science, Product, Customer Success, Clients, etc.).\nTu cr\u00e9eras et d\u00e9velopperas des pipelines de donn\u00e9es avec des outils de scheduling et d\u2019orchestration.\nLa stack sur laquelle vous travaillerez :\nLangage : Python, Javascript\nFramework data : PyTorch, Transformers (Hugging Face), FastAPI\nDatabase : PostgreSQL, MongoDB, ElasticSearch, Redis\nInfrastructure : Azure, Docker, Kubernetes, Spark, RabbitMQ, Serverless, Terraform\nEnvironnement / Test : PyTest, Gitlab (git + ci/cd)\nBI : Metabase, Superset\nVotre profil\nEntre 1 et 3 ans d'exp\u00e9rience en CDI\nTu as une exp\u00e9rience significative sur des probl\u00e9matiques de Data engineering\nTu es quelqu'un de pragmatique\nUn tr\u00e8s bon niveau en Python et une tr\u00e8s bonne rigueur dans le code\nBonne pratique de dev : clean code, TDD, BDD\nUne bonne culture Ops\nUne logique cloud (Aws, GCP ou Azure)\nLe salaire & avantages\n50-7O K\u20ac selon exp\u00e9rience\nRTT\nCarte Swile & Mutuelle\n2/3 jours de t\u00e9l\u00e9travail par semaine\nEt plus encore\u2026\nCe qu\u2019on pr\u00e9f\u00e8re\n\u00catre impliqu\u00e9 \u00e0 fond dans une aventure avec de nombreux challenges techniques\nBelles opportunit\u00e9s d'\u00e9volutions sur des postes d'Architecte, de Lead ou de Ml Ops\nBeaucoup de workshops en interne et catalogue de formations \u00e0 votre guise\nUne opportunit\u00e9 de travailler sur un produit unique qui a d\u00e9j\u00e0 s\u00e9duit de tr\u00e8s beaux clients (BNP Paribas, Fnac Darty, Luko, OpenClassrooms)\nLa possibilit\u00e9 de travailler sur une stack tr\u00e8s moderne, des probl\u00e9matiques complexes aussi bien en traitement de donn\u00e9es, qu'en DevOps\nUn plan de BSPCE (actions de l'entreprise) tr\u00e8s int\u00e9ressant et motivant !\nUne culture d'entreprise fond\u00e9e sur l'apprentissage, l'autonomie, la bienveillance et l'exigence\nLe fait de travailler au quotidien avec des fondateurs passionn\u00e9s par leur domaine d'expertise\nCe poste a \u00e9t\u00e9 soigneusement choisi par votre coach. Powered by Octopus IT, cabinet d\u2019Experts en Recrutement Tech (CDI et clients finaux uniquement) \u2013 Visitez nous pour plus d\u2019opportunit\u00e9s :\nwww.octopusit.fr\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "Java",
                "R",
                "Go",
                "JavaScript"
            ],
            "DataBase": [
                "SQL",
                " MongoDB",
                "Elasticsearch"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [
                "Spark"
            ],
            "MachingLearning": [
                "PyTorch"
            ],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [
                "AWS",
                "Azure"
            ],
            "DevTools": [
                "Git",
                "Docker"
            ],
            "Os": [],
            "DBMS": [
                "PostgreSQL"
            ],
            "SoftBigDataProcessing": [],
            "Automation": [
                "Kubernetes"
            ],
            "InfrastructureAsCode": [
                "Terraform"
            ],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [
                "Docker",
                "Kubernetes"
            ],
            "Collaboration": [],
            "Other": [
                "DevOps",
                "ML",
                "Cloud",
                "CI/CD"
            ],
            "FrSoftSkills": [],
            "EnSoftSkils": []
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [
                "CDI"
            ],
            "Salary": [
                "50"
            ],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s",
                "2",
                "2",
                "2"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "Data Engineer (H/F) - Lille",
        "company": "Logic@l Conseils",
        "location": "Lille, Hauts-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/data-engineer-h-f-lille-at-logic%40l-conseils-3811575649?position=10&pageNum=5&refId=T%2B%2BV0JbclKMpVoA2J23Itg%3D%3D&trackingId=11TBdmq9Jr5Wm4NJ8JV1bg%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Dans le cadre du d\u00e9veloppement de nos activit\u00e9s sur la m\u00e9tropole Lilloise, nous recherchons un\nconsultant data engineer\n(H/F) pour intervenir chez l'un de nos grands comptes clients.\nVos missions :\nRecueillir\nles besoins m\u00e9tiers et des \u00e9quipes data\nConcevoir et mettre en place les\ntraitements de donn\u00e9es\nR\u00e9aliser les\ntests de validation\nAssurer\nl\u2019alimentation du dataware\nR\u00e9aliser les\nordonnancements des traitements\nEtre garant de la\nmise en place\n, du\nsuivi\net de l\u2019\nexploitation\ndes outils d\u00e9ploy\u00e9s\nAssurer\nune veille technologique\nr\u00e9guli\u00e8re\nEnvironnement technique :\nD\u00e9veloppement :\nPython, Scala, R, Java,\nFramework :\nSpark,\nHadoop,\nOutils Big data :\nYarn, Pig, Hive, Kafka, Splunk\nBases de donn\u00e9es :\nMongoDB, HBase, Cassandra\nETL :\nTalend, Stambia\nPlateforme :\nHortonworks, Cloudera, Map Reduce\n,\nAWS, GCP, Azure\nVotre profil :\nVous disposez d\u2019une exp\u00e9rience\nd\u2019au moins 2 ans en tant que data engineer\nou dans le domaine de l\u2019analyse et du traitement de donn\u00e9es.\nV\u00e9ritable\npassionn\u00e9 de la data\n, vous \u00eates\nforce de proposition\nsur les solutions techniques \u00e0 mettre en \u0153uvre. Vous maitrisez l\u2019anglais dans un contexte professionnel.\nComp\u00e9tences requises :\nAnalyses qualitatives et quantitatives (Interm\u00e9diaire)\nAnglais (Interm\u00e9diaire)\nArchitecture fonctionnelle SI (D\u00e9butant)\nD\u00e9veloppement d'ouvrages, produits ou \u00e9v\u00e9nements (D\u00e9butant)\nGestion des contr\u00f4les, tests et diagnostics (D\u00e9butant)\nGestion des risques (Interm\u00e9diaire)\nMa\u00eetrise des logiciels (Interm\u00e9diaire)\nMise en exploitation / Production et maintenance (D\u00e9butant)\nNos valeurs\nNous avons d\u00e9cid\u00e9 de renverser la pyramide du management pour placer nos collaborateurs en t\u00eate des priorit\u00e9s de l\u2019entreprise.\nEn effet, attach\u00e9 \u00e0 des valeurs fortes, telles que la proximit\u00e9, la sinc\u00e9rit\u00e9, la fid\u00e9lit\u00e9, la confiance et le respect, nous sommes persuad\u00e9s que la r\u00e9ussite r\u00e9side dans le bien-\u00eatre de nos collaborateurs.\nCela se traduit par un accompagnement de proximit\u00e9, de la transparence sans langue de bois, des \u00e9changes r\u00e9guliers avec les managers r\u00e9f\u00e9rents, un accompagnement dans le d\u00e9veloppement de carri\u00e8re qui est construit et jalonn\u00e9 avec les formations et certifications n\u00e9cessaires et les missions en ad\u00e9quation, pour mener \u00e0 bien l\u2019\u00e9volution de carri\u00e8re.\nPour vous convaincre de nous rejoindre, nos avantages salari\u00e9s compl\u00e9mentaires :\nEnvironnement bienveillant et stimulant au sein de 3 p\u00f4les d\u2019expertises\nFormations et Certifications \u00e0 la demande\nTickets restaurants : 13\u20ac par ticket\nRemboursement \u00e0 100 % des abonnements de transports en commun\nMutuelle frais de sant\u00e9 avec de hautes garanties\nPrise en charge \u00e0 100% de l\u2019assurance Pr\u00e9voyance\nCh\u00e8que Cadeau Culture 120 \u20ac\nCompte CSE avec une cagnotte de 390 \u20ac\nCompte CE : billetterie, voyages, culture, sorties, \u00e0 des tarifs pr\u00e9f\u00e9rentiels\nDes \u00e9v\u00e8nements chaque mois : activit\u00e9s associatives, sportives, afterwork, s\u00e9minaire,\nPartenariat Losc (participation aux match dans la loge VIP logical conseils \u2013 (Une Vingtaine de match par an)\nPossibilit\u00e9 de t\u00e9l\u00e9travail\nEn int\u00e9grant Logic@l Conseils, vous participez \u00e0 une r\u00e9elle aventure humaine, alors pour postuler, il suffit de cliquer ci-dessous !\nTous nos postes sont ouverts, \u00e0 comp\u00e9tences \u00e9gales, aux personnes en situation de handicap.\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "Java",
                "Scala",
                "R",
                "Go"
            ],
            "DataBase": [
                "Cassandra",
                "HBase"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [
                "Hadoop",
                "Spark"
            ],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [
                "AWS",
                "Azure"
            ],
            "DevTools": [],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [
                "HBase"
            ],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [
                "Big Data",
                "Cloud"
            ],
            "FrSoftSkills": [],
            "EnSoftSkils": []
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s",
                "2",
                "2",
                "2"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "Data Engineer",
        "company": "Mobiskill | WEFY Group",
        "location": "Paris, \u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/data-engineer-at-mobiskill-wefy-group-3907393935?position=1&pageNum=7&refId=2YID7uch9sWjo1I7wCmyNQ%3D%3D&trackingId=gPwfRZiToccoAQLQfsQAHQ%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "La soci\u00e9t\u00e9 :\nLe produit repose sur la data, leur solution bas\u00e9e sur de l\u2019intelligence artificielle permet de personnaliser le monde de la promotion et de la fid\u00e9lisation. Ils viennent d'\u00eatre rachet\u00e9s et ont une forte ambition pour leur expansion internationale.\nLes missions :\n- Travailler avec les data scientists pour apporter des solutions\n- Industrialiser les mod\u00e8les\n- Optimiser la performance du produit\n- D\u00e9velopper des outils big data pour scaler\n- Mentorer des profils plus juniors\nStack :\n- Scala\n- Spark / Spark Streaming\n- Kafka\n- GCP\n- Cassandra\n- Docker\nProfil recherch\u00e9 :\n- Entre 3 et 5 ans d'exp\u00e9rience dans le Data Engineering\n- Exp\u00e9rience en Scala/Spark\n- Exp\u00e9rience sur cloud (tr\u00e8s id\u00e9alement GCP)\n- Pr\u00eat \u00e0 faire des missions polyvalentes\n- Ouvert \u00e0 d'autres technos (ils ont pour objectif d'impl\u00e9menter prochainement des outils en Python)\nPourquoi les rejoindre :\n- Expansion internationale : USA, Br\u00e9sil, Russie, Espagne\u2026\n- Une stack \u00e0 la pointe et un champs d\u2019action pour POCer de nouvelles technos si il y a un int\u00e9r\u00eat business\n- Un encadrement bienveillant : les 2 leads techniques sont deux excellents techs ET d\u2019excellents mentors avec qui \u00e9changer sur comment faire avancer la soci\u00e9t\u00e9 (tu serais le troisi\u00e8me maillons de la chaine).\n- Politique remote hybride\n- Des bureaux dans Paris intra-Muros\n- Une r\u00e9mun\u00e9ration pouvant d\u00e9passer 70k (avec package)\n- Une entreprise tr\u00e8s tech, particuli\u00e8rement orient\u00e9e Data\nH\u00e2te de vous en dire plus rapidement !\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "Scala",
                "R"
            ],
            "DataBase": [
                "Cassandra"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [
                "Spark"
            ],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [],
            "DevTools": [
                "Docker"
            ],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [
                "Docker"
            ],
            "Collaboration": [],
            "Other": [
                "Big Data",
                "Cloud"
            ],
            "FrSoftSkills": [],
            "EnSoftSkils": []
        },
        "details": {
            "JobDetail": [
                "Hybride",
                "Remote",
                "Junior"
            ],
            "TypeContract": [],
            "Salary": [
                "Package"
            ],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s",
                "5",
                "5",
                "5"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "Data Engineer",
        "company": "ALFI : Financial Markets Consultancy Services",
        "location": "Paris, \u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/data-engineer-at-alfi-financial-markets-consultancy-services-3916552424?position=2&pageNum=7&refId=2YID7uch9sWjo1I7wCmyNQ%3D%3D&trackingId=xN%2Fs023Ps5wbxsXxbzaCfw%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Le Data Engineer intervient au sein de l\u2019\u00e9quipe Engineering Open Big Data du D\u00e9partement Guilde Data, qui regroupe l\u2019ensemble des expertises technologiques li\u00e9es \u00e0 l\u2019ing\u00e9nierie de la donn\u00e9e, de l\u2019automatisation et \u00e0 l\u2019exploitation des mod\u00e8les de Machine Learning.\nVotre r\u00f4le et vos missions :\nVous aurez pour missions principales de d\u00e9velopper les projets Big Data demand\u00e9s par le m\u00e9tier, et notamment :\nPasser de la donn\u00e9e brute \u00e0 de la donn\u00e9e exploitable, expos\u00e9e sous forme de tables requ\u00eatables dans le Datalake\nConsolider ces donn\u00e9es au fur et \u00e0 mesure de leur alimentation r\u00e9currente dans le Datalake\nLes exploiter pour atteindre la finalit\u00e9 business (exposition de Business View, r\u00e9int\u00e9gration des r\u00e9sultats dans le SI, service de scoring, \u2026)\nDe mettre en place et de garantir le respect dans la dur\u00e9e d'un processus qualit\u00e9 sur l'ensemble du cycle de DEV (documents, tests unitaires / int\u00e9gration / fonctionnels, commentaires, versionning, etc.)\nAccompagner les Data Engineers sur son p\u00e9rim\u00e8tre pour garantier la qualit\u00e9 des livrables\nExpertise souhait\u00e9e\nComp\u00e9tences techniques :\nExpertise en SPARK et PySpark\nExpertise sur Databricks\nUne exp\u00e9rience sur un cloud provider public comme Azure (id\u00e9alement), AWS, ou GCP\nConnaissances avanc\u00e9es d'outils de BI comme PowerBI (id\u00e9alement) ou Spotfire\nComp\u00e9tences transverses :\nCapacit\u00e9 \u00e0 interagir avec des parties prenantes diverses : Business analyst, Architectes, M\u00e9tier\nExp\u00e9rience en mode de Delivery Agile (Scrum, Kanban, etc.\u2026)\nEtre expert dans les pratiques du Software Craftsmanship (Test Driven Development, Behavior Driven Development, Clean Code, Code Reviews, etc.)\nEt :\nDes Connaissances sur Azure DevOps, Azure Pipeline, GIT\nMaitrise des Traitements Big Data en mode Streaming\nMaitrise des Bases de donn\u00e9es relationnelles et NoSQL\nUne exp\u00e9rience professionnelle avec des outils comme Azure Databricks, Azure Data Lake Storage ou encore Azure Data Factory\nConform\u00e9ment \u00e0 la r\u00e8glementation, et \u00e0 notre politique d\u2019\u00e9galit\u00e9 professionnelle, tous nos postes sont ouverts aux personnes en situation de handicap.\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "R"
            ],
            "DataBase": [
                "SQL",
                "NoSQL"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [
                "Spark",
                "Databricks"
            ],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [
                "PowerBI"
            ],
            "Statistics": [],
            "CloudComputing": [
                "AWS",
                "Azure"
            ],
            "DevTools": [
                "Git"
            ],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [
                "DevOps",
                "Big Data",
                "Machine Learning",
                "Cloud"
            ],
            "FrSoftSkills": [],
            "EnSoftSkils": []
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "Data Engineer H/F",
        "company": "Lincoln France",
        "location": "Hauts-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/data-engineer-h-f-at-lincoln-france-3829857168?position=3&pageNum=7&refId=2YID7uch9sWjo1I7wCmyNQ%3D%3D&trackingId=JgE3YnfQ5DjhRTX3PNYJ6Q%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "DATA ENGINEER H/F\nCDI\n3 ans minimum\nChez Lincoln\n, nous formons une communaut\u00e9 d'innovateurs passionn\u00e9s qui red\u00e9finissent l'analyse de donn\u00e9es depuis\nplus de 30 ans\n. En tant que\nPure Player Data\n, notre expertise est reconnue dans les domaines\nde la Modern BI, du Big Data et de la Science des donn\u00e9es\n.\nNotre mission ?\nTransformer les donn\u00e9es en solutions concr\u00e8tes pour nos clients grands comptes dans divers secteurs tels que la banque, le retail, les t\u00e9l\u00e9coms, l'industrie, la sant\u00e9, etc.\nDescription de poste\nNous recherchons un\nData Engineer H/F\npour accompagner nos clients dans leurs projets strat\u00e9giques.\nVos missions :\nConcevoir et d\u00e9velopper des pipelines de donn\u00e9es robustes et \u00e9volutifs.\nInt\u00e9grer et transformer des donn\u00e9es provenant de diff\u00e9rentes sources.\nD\u00e9velopper et mettre en \u0153uvre des algorithmes de traitement de donn\u00e9es avanc\u00e9s.\nCollaborer \u00e9troitement avec les \u00e9quipes clients pour comprendre leurs besoins et fournir des solutions adapt\u00e9es.\nAssurer la qualit\u00e9 et la fiabilit\u00e9 des solutions d\u00e9velopp\u00e9es.\nPr\u00e9requis :\nMa\u00eetrise des langages de programmation (\nPython, Scala, etc\n.).\nConnaissance approfondie des bases de donn\u00e9es et des technologies\nCloud (GCP, AWS, Azure, Snowflake, etc.)\nExp\u00e9rience avec\nMySQL, PostgreSQL, MongoDB.\nMaitrise ETL/ELT (Talend, Stambia, etc.)\nSolides comp\u00e9tences en conception et en optimisation de pipelines de donn\u00e9es.\nExp\u00e9rience de travail en\nm\u00e9thode Agile\npour la gestion de projet et le d\u00e9veloppement de solutions.\nCapacit\u00e9 \u00e0 travailler de mani\u00e8re autonome et en \u00e9quipe.\nExcellentes comp\u00e9tences en communication et en r\u00e9solution de probl\u00e8mes.\nLes plus du poste :\nEnvironnement Collaboratif\n: projets innovants favorisant le partage des connaissances.\nAccompagnement individualis\u00e9 et de proximit\u00e9\n: formations certifiantes, attribution d\u2019un Career Manager pour vous orienter dans votre trajectoire professionnelle, opportunit\u00e9s d\u2019\u00e9volution de carri\u00e8re.\nFlexibilit\u00e9 du Travail\n: T\u00e9l\u00e9travail et horaires flexibles pour votre \u00e9quilibre vie professionnelle-personnelle.\nR\u00e9mun\u00e9ration Comp\u00e9titive\n: Salaire comp\u00e9titif avec des avantages sociaux attrayants.\nMobilit\u00e9\n: Possibilit\u00e9 de mobilit\u00e9 \u00e0 Paris, Lyon ou Aix-en-Provence offrant des exp\u00e9riences diversifi\u00e9es au sein de Lincoln.\nNotre processus de recrutement :\nun entretien RH (1h) et entretien technique (1h)\nCette annonce n\u2019est pas faite pour vous si :\nVous \u00eates freelance et vous comptez le rester !\nToujours l\u00e0 ? Postulez et rejoignez nos\n400 experts en Data\n\ud83d\ude09.\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "Scala",
                "R",
                "Go"
            ],
            "DataBase": [
                "SQL",
                " MongoDB"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [
                "AWS",
                "Azure"
            ],
            "DevTools": [],
            "Os": [],
            "DBMS": [
                "MySQL",
                "PostgreSQL",
                "Snowflake",
                "Snowflake"
            ],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [
                "Big Data",
                "Cloud"
            ],
            "FrSoftSkills": [
                "Communication",
                "R\u00e9solution de probl\u00e8mes",
                "Flexibilit\u00e9"
            ],
            "EnSoftSkils": [
                "Communication"
            ]
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [
                "CDI"
            ],
            "Salary": [
                "400"
            ],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s",
                "3",
                "3",
                "3"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "Data Engineer & Analyst - Paris - F/H/X - CDI",
        "company": "Partoo",
        "location": "Paris, \u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/data-engineer-analyst-paris-f-h-x-cdi-at-partoo-3892387658?position=4&pageNum=7&refId=2YID7uch9sWjo1I7wCmyNQ%3D%3D&trackingId=2e4pIaI4dkTrxrF9KildUg%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Partoo, who are we? \ud83d\udc40\nPartoo est une scale-up saas B2B qui a \u00e0 c\u0153ur d\u2019aider les commerces locaux, grandes entreprises ou PME \u00e0 se rapprocher de leurs clients. Pour cela, ils ont d\u00e9velopp\u00e9 une plateforme tout-en-un et diff\u00e9rentes solutions qui s\u2019articulent autour de 3 propositions de valeur : Get found, Get chosen & Get clients.\n\u00c0 travers ces 3 propositions, ils ont d\u00e9velopp\u00e9 plusieurs produits qui s\u2019adaptent aux \u00e9volutions du parcours d\u2019achat des clients :\n\ud83d\udd0e Get found\nPresence: Synchroniser les informations des magasins sur les principales plateformes (Google, Facebook, Waze, etc.), annuaires et GPS\nStore Locator: Aider les clients \u00e0 trouver le magasin qui leur convient gr\u00e2ce \u00e0 des donn\u00e9es locales actualis\u00e9es et des filtres d\u00e9di\u00e9s sur les sites web des enseignes\nR\u00e9seaux sociaux: G\u00e9rer les publications sur Facebook, Google, Instagram, etc\n\ud83c\udfaf Get chosen\nReview: Centraliser, r\u00e9pondre et analyser les avis clients re\u00e7us sur Google et Facebook\nBooster: Obtenir des avis positifs suppl\u00e9mentaires sur Google par le biais de SMS et de QR codes\n\ud83e\udd17 Get clients\nMessages: Centraliser et r\u00e9pondre \u00e0 tous les messages de chat re\u00e7us via Google Business Messages, Messenger et bient\u00f4t aussi via Instagram, whatsapp, etc. (templates messages, conversations starter, appels manqu\u00e9s...)\nQuelques chiffres \ud83d\udddd\ufe0f\n> Un label Happy at Work et l'une des meilleures notes Glassdoor de l'\u00e9cosyst\u00e8me avec 4.6/5 pour plus de 260 avis\u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f \ufe0f\ufe0f\ufe0f\ufe0f\ufe0f\ufe0f\n> 450+ employ\u00e9s heureux, 37 nationalit\u00e9s diff\u00e9rentes, des bureaux \u00e0 Paris et Barcelone \ud83d\ude80\n> Ils g\u00e8rent 300 000 points de vente et travaillent de mani\u00e8re transversale avec +1000 cha\u00eenes (Carrefour, Generali, Toyota, D\u00e9cathlon, Leroy Merlin etc.) et +6000 pme dans environ 150 pays\nNotre m\u00e9mo 2024: le mot du CEO (https://www.partoo.co/fr/blog/memo-2024/)\nIMPACT \ud83d\udca5\nPartoo compte aujourd\u2019hui pas moins de 400 collaborateurs, qui \u0153uvrent au quotidien \u00e0 maintenir une croissance saine, en phase avec les enjeux et challenges \u00e9conomiques du moment.\nUne des composantes clefs pour y parvenir r\u00e9side en notre capacit\u00e9 \u00e0 d\u00e9velopper et maintenir un haut niveau d\u2019efficacit\u00e9 op\u00e9rationnelle. Dans cette logique, am\u00e9liorer notre capacit\u00e9 \u00e0 exploiter et utiliser la donn\u00e9e pr\u00e9sente dans nos syst\u00e8mes est indispensable. Si nous avons d\u00e9j\u00e0 une \u00e9quipe Data en place, celle-ci est aujourd\u2019hui mobilis\u00e9e presque exclusivement sur les th\u00e9matiques data relatives au fonctionnement de notre application ainsi qu\u2019\u00e0 la construction d\u2019\u00e9l\u00e9ments de visibilit\u00e9 pour nos clients.\nNous souhaitons donc recruter un Data Engineer & Analyst dont l\u2019objectif principal sera de permettre aux \u00e9quipes Op\u00e9rations et client-facing de visibiliser et tirer le meilleur parti d\u2019une donn\u00e9e aujourd\u2019hui difficile d\u2019acc\u00e8s.\nManager : Adel Adman (cc. Cl\u00e9ment Bouillaud, en charge de la team Operations)\nTEAM \ud83d\udc99\nMeetings r\u00e9current avec les membres de Partoo :\nMembre \u00e0 part enti\u00e8re de l\u2019\u00e9quipe Data (elle-m\u00eame int\u00e9gr\u00e9e dans l\u2019\u00e9quipe Produit), tu seras n\u00e9anmoins en contact r\u00e9gulier avec les \u00e9quipes Op\u00e9rations, qui seront tes principales interlocutrices.\nEn d\u2019autres termes, tu seras le pilier central entre les \u00e9quipes Ops et Data.\nDans un premier temps, tu auras un meeting hebdomadaire avec Adel (Lead Data) et avec Cl\u00e9ment (COO), le temps de cadrer tes premi\u00e8res priorit\u00e9s et de trouver la bonne r\u00e9currence de rencontre avec les \u00e9quipes Op\u00e9rations.\nMISSIONS \ud83d\udd25\nTon principal objectif consiste \u00e0 faire en sorte que chaque personne, des \u00e9quipes Op\u00e9rations comme des \u00e9quipes client-facing, ait acc\u00e8s \u00e0 la donn\u00e9e dont elle a besoin, au moment o\u00f9 elle en a besoin, sur le support le plus ad\u00e9quat. Pour y parvenir, plusieurs missions seront tiennes :\nArchitecture\n:\nCr\u00e9er des architectures de donn\u00e9es robustes et \u00e9volutives pour collecter, stocker et analyser de grandes quantit\u00e9s de donn\u00e9es provenant de diverses sources (Salesforce, Intercom, Chargebee, back office de Partoo, etc.)\nAnalyser et am\u00e9liorer continuellement le mod\u00e8le de donn\u00e9es Salesforce (SF), en accompagnant l'\u00e9quipe Ops dans le monitoring des anomalies et l'optimisation des performances\nInt\u00e9grations et flux\n:\nD\u00e9velopper et optimiser des pipelines de donn\u00e9es, assurant l'int\u00e9gration fluide des donn\u00e9es dans notre Data Warehouse depuis diff\u00e9rentes sources, et inversement\nTransformation & analyse\n:\nConcevoir et ex\u00e9cuter des requ\u00eates SQL complexes pour l'analyse de donn\u00e9es, permettant de soutenir les d\u00e9cisions business\nIdentifier et construire des KPI cruciaux, fournissant des insights pr\u00e9cieux aux \u00e9quipes business\nVisualisation\n:\nFournir aux \u00e9quipes Ops et client-facing des outils de visualisation de donn\u00e9es (Looker Studio, embedding, etc.), cl\u00e9s dans l'optimisation de notre gestion de client\u00e8le.\nFormation\n:\nFormer les \u00e9quipes Op\u00e9rations sur l\u2019exploitation des tables de notre Datawarehouse ainsi que sur l\u2019usage de Looker Studio et propager les principales best practices associ\u00e9es. Tout \u00e7a, en collaboration au quotidien avec les \u00e9quipes Ops !\nDESIRED PROFILE \ud83c\udfaf\nComp\u00e9tences recherch\u00e9es :\nUne tr\u00e8s bonne connaissance du langage SQL, notamment PostgreSQL et BigQuery.\nMa\u00eetrise du scripting Python et des notebooks pour l'analyse de donn\u00e9es\nD\u2019excellentes capacit\u00e9s d'analyse pour comprendre les besoins business, identifier les anomalies dans les donn\u00e9es et proposer des am\u00e9liorations pertinentes\nUne bonne aptitude \u00e0 manipuler et analyser de grands ensembles de donn\u00e9es et en extraire des insights actionnables\nUne tr\u00e8s bonne ma\u00eetrise d'au moins un outil de business intelligence tel que Looker Studio, PowerBI ou Tableau\nProfils recherch\u00e9 :\nTu as plus de 3 ans d'exp\u00e9rience en Data Engineering /Advanced Data Analysis\nTu ma\u00eetrises les stacks de data les plus r\u00e9centes (dbt, Airflow, Airbyte, etc.) et les meilleures pratiques en mati\u00e8re de donn\u00e9es (ETL, reverse-ETL, etc.)\nTu es orient\u00e9(e) utilisateur et sais convertir les besoins commerciaux en solutions techniques\nTu sais communiquer avec les \u00e9quipes et t'assurer que les meilleures pratiques sont adopt\u00e9es\nTu es un team player !\nTu souhaites apprendre et grandir avec nous\nRECRUITMENT PROCESS \ud83d\udee0\ufe0f\nA first video call with Marine, Talent Acquisition Specialist, 45 min\nInterview with Adel, Lead Data Engineer, 1h\nCase Study\nInterview with Cl\u00e9ment, Chief Operations Officer, 1h\n\u00c0 comp\u00e9tences \u00e9gales, ce poste est ouvert aux travailleurs et travailleuses en situation de handicap ou assimil\u00e9s au sens de l\u2019article L5212-13 du Code du travail. Partoo s\u2019engage en faveur de la diversit\u00e9, l\u2019\u00e9galit\u00e9 professionnelle, l\u2019emploi des travailleurs handicap\u00e9s.\nWith equal skills, this position is open to disabled workers or those considered to be disabled within the meaning of Article L5212-13 of the French Labour Code. Partoo is committed to diversity, professional equality and the employment of disabled workers.\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "R",
                "Go"
            ],
            "DataBase": [
                "SQL"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [
                "Tableau",
                "PowerBI"
            ],
            "Statistics": [],
            "CloudComputing": [],
            "DevTools": [],
            "Os": [],
            "DBMS": [
                "PostgreSQL",
                "BigQuery"
            ],
            "SoftBigDataProcessing": [],
            "Automation": [
                "Airflow"
            ],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [],
            "FrSoftSkills": [
                "Collaboration"
            ],
            "EnSoftSkils": [
                "Collaboration"
            ]
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s",
                "3",
                "3",
                "3"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "Data Engineer",
        "company": "RSight\u00ae",
        "location": "\u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/data-engineer-at-rsight%C2%AE-3856216625?position=5&pageNum=7&refId=2YID7uch9sWjo1I7wCmyNQ%3D%3D&trackingId=8Zpi5qSzXdHWTRv3cLq8Zg%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Nous recherchons pour notre client, un\nleader mondial des services et conseils en technologies\n, un\ning\u00e9nieur Databricks et Data Factory\nqui rejoindra une \u00e9quipe qui combine des comp\u00e9tences m\u00e9tiers avec une forte expertise data, analytique et d\u2019intelligence artificielle pour mettre en \u0153uvre des solutions qui visent \u00e0 am\u00e9liorer la gestion et la valorisation des donn\u00e9es.\nDescriptif des missions:\nVous \u00eates int\u00e9ress\u00e9 \u00e0 travailler sur une solution ayant un impact direct sur les ambitions de notre client en mati\u00e8re de data (datadriven, data d\u00e9mocratisation) ? Alors devenez membre de l\u2019\u00e9quipe Corporate Data Lake de notre client ! Comme tout autre membre de l'\u00e9quipe, vous :\nParticiper \u00e0 la d\u00e9finition des composants informatiques supportant la fourniture de services\nD\u00e9velopper, tester, industrialiser et d\u00e9ployer des composants en minimisant les impacts sur les utilisateurs (automatisation, 0 temps d'arr\u00eat,...)\nDocumenter la bonne utilisation des services\nD\u00e9ployer et supporter nos fonctionnalit\u00e9s sur la plateforme\nApporter assistance et conseils aux utilisateurs m\u00e9tiers\nOp\u00e9rer la solution en op\u00e9ration courante (incluant le suivi de la qualit\u00e9 des services) et intervenir dans la r\u00e9solution des incidents\nParticiper activement \u00e0 l'am\u00e9lioration continue des activit\u00e9s de l'\u00e9quipe\nExpliquer aux collaborateurs ce que le Corporate Data Lake peut faire pour eux\nConfigurer des espaces de travail pour eux\nFournir du coaching et de l'expertise lors de r\u00e9unions en face \u00e0 face ou sur les canaux communautaires\nParticiper \u00e0 l'effort de support de la plateforme dans une approche \"vous la construisez, vous l'ex\u00e9cutez\"\nContribuer aux premi\u00e8res phases de conception d\u00e9finissant l'avenir du Corporate Data Lake\nComp\u00e9tences:\n1er exp\u00e9rience Azure (PaaS et IaaS)\nConnaissance de Databricks et Data Factory\nMa\u00eetrise d'un ou plusieurs langages parmi : Python, Scala, Spark, PowerShell\nInt\u00e9gration et livraison continues (Jenkins, Azure Devops, GIT Lab CI, \u2026)\nPratique des fondamentaux du g\u00e9nie logiciel (Gestion de Configuration, Tests,...)\nAnglais : \u00e0 l'aise pour assister \u00e0 une r\u00e9union et r\u00e9diger de la documentation technique\nBonne capacit\u00e9 d'\u00e9coute, orientation client/utilisateur\nExpression orale et \u00e9crite adapt\u00e9e \u00e0 l'interlocuteur\nCuriosit\u00e9 et adaptation aux changements technologiques\nB\u00e9n\u00e9fices:\nUn processus de recrutement court, un accompagnement personnalis\u00e9, une \u00e9volution qui s'adapte \u00e0 votre trajectoire de carri\u00e8re.\nEn plus de votre quotidien li\u00e9 \u00e0 votre mission, vous pourrez entreprendre, \u00eatre form\u00e9, passer des certifications.\nPlan d'\u00e9pargne pour la retraite collectif, mutuelle, tickets restaurant, des cong\u00e9s d'anciennet\u00e9, un catalogue CE, des accords d\u2019entreprise relatifs au t\u00e9l\u00e9travail et \u00e0 la parentalit\u00e9 et autres avantages.\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "Scala",
                "R"
            ],
            "DataBase": [],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [
                "Spark",
                "Databricks"
            ],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [
                "Azure"
            ],
            "DevTools": [
                "Git",
                "Jenkins"
            ],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [
                "DevOps"
            ],
            "FrSoftSkills": [],
            "EnSoftSkils": []
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "Stage - Data Engineer - ML (H/F)",
        "company": "Withings",
        "location": "Issy-les-Moulineaux, \u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/stage-data-engineer-ml-h-f-at-withings-3613476264?position=6&pageNum=7&refId=2YID7uch9sWjo1I7wCmyNQ%3D%3D&trackingId=DoyNgT9yj6tnq%2BmyCF3KHQ%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Chez Withings, nous d\u00e9veloppons des appareils de sant\u00e9 connect\u00e9e : nos balances connect\u00e9es, montres hybrides, tensiom\u00e8tres, moniteurs de sommeil et tous les dispositifs de notre gamme sont aujourd'hui utilis\u00e9s par des millions d'utilisateurs. Notre objectif est de permettre la pr\u00e9vention, le d\u00e9pistage et l'accompagnement d'un certain nombre de maladies chroniques via des produits et des services innovants afin de r\u00e9volutionner la mani\u00e8re dont on prend soin de notre sant\u00e9.\nAu sein de l'\u00e9quipe Machine Learning, nous d\u00e9veloppons des algorithmes pour extraire des informations physiologiques et m\u00e9dicales pour nos utilisateurs tels que le SPO2, la fr\u00e9quence cardiaque, la d\u00e9tection de diverses pathologies comme la fibrillation atriale, l'apn\u00e9e du sommeil...\nInt\u00e9gr\u00e9.e au sein de l'\u00e9quipe Machine Learning, tu auras une ou plusieurs des responsabilit\u00e9s suivantes :\nD\u00e9velopper un outil de monitoring de la dette technique, des mauvaises pratiques de code, des failles de s\u00e9curit\u00e9 ;\nConstruire des dashboards de visualisation ;\nConstruire un syst\u00e8me d'alerte pour notifier les contributeurs d'\u00e9ventuels probl\u00e8mes ;\nD\u00e9velopper des outils permettant de corriger les \u00e9ventuels probl\u00e8mes de fa\u00e7on automatis\u00e9e ;\nRequirements\n\u00c0 la recherche d'un stage d'une dur\u00e9e de 3 \u00e0 6 mois ;\nPr\u00e9paration d'un Master en \u00e9cole d'ing\u00e9nieur ou \u00e9quivalent / ann\u00e9e de c\u00e9sure possible ;\nMa\u00eetrise de Python ;\nMa\u00eetrise de Debian ou de Ubuntu, de Shell et de l'environnement Linux ;\nPremi\u00e8re exp\u00e9rience sur du d\u00e9veloppement logiciel ;\nCulture DevOps (omnipr\u00e9sence du monitoring, automatisation des t\u00e2ches, ...)\nCompr\u00e9hension de la culture et des besoins des diff\u00e9rents membres de l'\u00e9quipe ;\nRigueur, autonomie, prise d'initiative, curiosit\u00e9\nBenefits\nRejoindre l'aventure Withings, c'est :\nInt\u00e9grer un des pionniers et leaders mondiaux de la sant\u00e9 connect\u00e9e, plusieurs fois prim\u00e9 au Consumer Electronic Show\nContribuer \u00e0 des projets innovants et ambitieux pour la sant\u00e9 de demain dans un environnement agile et en constante \u00e9volution\nInt\u00e9grer une entreprise internationale, membre de la FrenchTech 120, dont les \u00e9quipes sont bas\u00e9es \u00e0 Issy-les-Moulineaux, Boston, Hong-Kong et Shenzhen\nParticiper \u00e0 l'am\u00e9lioration continue de nos produits et services en les b\u00eata-testant avant leur sortie, notamment lors de nos nombreuses sessions sportives entre coll\u00e8gues\nParticiper \u00e0 la Withings Med Academy en assistant \u00e0 des conf\u00e9rences de professionnels de sant\u00e9 afin de renforcer ses connaissances dans le domaine m\u00e9dical\nCollaborer avec des coll\u00e8gues passionn\u00e9s et c\u00e9l\u00e9brer ensemble chacune de nos r\u00e9ussites !\nToutes les candidatures re\u00e7ues sont \u00e9tudi\u00e9es ind\u00e9pendamment de l'origine ethnique, des croyances, de la religion, du genre, de l'orientation sexuelle ou de la sant\u00e9 des candidats. Withings aspire \u00e0 offrir et garantir l'\u00e9galit\u00e9 des chances aux candidats et seules les personnes habilit\u00e9es (RH et Management) auront acc\u00e8s aux informations concernant votre candidature.\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "R",
                "Go"
            ],
            "DataBase": [],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [],
            "DevTools": [],
            "Os": [
                "Linux"
            ],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [
                "DevOps",
                "Machine Learning"
            ],
            "FrSoftSkills": [],
            "EnSoftSkils": [
                "Initiative"
            ]
        },
        "details": {
            "JobDetail": [
                "Hybride"
            ],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "Stage - Data Engineer",
        "company": "Exotec",
        "location": "Lille, Hauts-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/stage-data-engineer-at-exotec-3918170659?position=7&pageNum=7&refId=2YID7uch9sWjo1I7wCmyNQ%3D%3D&trackingId=WBU9RcALIUZp84dp5t1Vfw%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Chez Exotec, nous mettons l'excellence technologique au service de la red\u00e9finition des relations entre humains et robots. A travers le monde, nos solutions r\u00e9volutionnent la fa\u00e7on dont nos clients d\u00e9livrent leurs produits aux consommateurs finaux. Nous contribuons au succ\u00e8s des plus grandes marques du commerce et de l'industrie, tout en am\u00e9liorant les conditions de travail de leurs salari\u00e9s.\nPar l'alliance de l'intelligence artificielle et d'un hardware performant, nos robots sont d\u00e9sormais d\u00e9ploy\u00e9s dans le monde entier et leur succ\u00e8s a fait de nous la premi\u00e8re licorne industrielle fran\u00e7aise.\nRejoindre Exotec, c'est l'opportunit\u00e9 de donner du sens \u00e0 vos comp\u00e9tences. Grandissez avec plus de 800 ExoPeople dans le monde entier pour faire de vos id\u00e9es des r\u00e9alit\u00e9s.\nLa r\u00e9volution robotique port\u00e9e par Exotec ne fait que commencer, vous en \u00eates ?\nAu sein du p\u00f4le Data, de la DSI d'Exotec, votre r\u00f4le sera de participer au d\u00e9veloppement de l'environnement et de l'infrastructure Data d'Exotec.\nPour cela :\nVous participez \u00e0 la mise en \u0153uvre des composants techniques de la plateforme de donn\u00e9es d'Exotec\nVous travaillez sur la collecte dans la plateforme de donn\u00e9es provenant de sources multiples : Salesforce, ERP, logiciels d\u00e9velopp\u00e9s en interne\nVous nettoyez, mettez en qualit\u00e9 et pr\u00e9parez les donn\u00e9es afin de les rendre disponibles pour les diff\u00e9rents cas d'usage qui en ont besoin\nVous migrez des reportings existants vers la plateforme de donn\u00e9es et mettez en \u0153uvre de nouveaux cas d'usage pour r\u00e9pondre aux besoins de l'entreprise\nVous travaillerez au sein de l'\u00e9quipe data et en \u00e9troite collaboration avec la software factory, ainsi qu'avec les utilisateurs des m\u00e9tiers qui ont besoin de rendre intelligibles les donn\u00e9es disponibles\nRequirements\nVous \u00eates \u00e9tudiant(e) d'une \u00e9cole d'Ing\u00e9nieur g\u00e9n\u00e9raliste avec une sp\u00e9cialisation programmation ou informatique\nVous recherchez un stage de fin d'\u00e9tudes d'une dur\u00e9e de 4 \u00e0 6 mois\nVous avez id\u00e9alement une premi\u00e8re exp\u00e9rience en Data Engineering et le d\u00e9veloppement de pipeline de donn\u00e9es\nVous maitrisez Python, l'ETL et SQL,\nCurieux(se) et rigoureux(se), vous souhaitez rejoindre une \u00e9quipe jeune et dynamique ainsi que vous investir dans des projets complexes et excitants\nVous avez un niveau d'anglais courant\nChez Exotec, nous garantissons l'\u00e9galit\u00e9 des chances dans notre processus de recrutement. L'ensemble des candidatures re\u00e7ues sont \u00e9tudi\u00e9es ind\u00e9pendamment de l'\u00e2ge, du genre, de l'origine, de la religion, de la couleur de peau, de la nationalit\u00e9, du sexe, du handicap, de l'orientation sexuelle ou de toute autre distinction prot\u00e9g\u00e9e par la loi. Nous mettons en place un environnement de travail inclusif et respectueux de toutes les diff\u00e9rences. En rejoignant le Pacte Parit\u00e9, Exotec s'engage pour un \u00e9cosyst\u00e8me French Tech plus paritaire.\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "R",
                "Go"
            ],
            "DataBase": [
                "SQL"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [],
            "DevTools": [],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [],
            "FrSoftSkills": [
                "Collaboration"
            ],
            "EnSoftSkils": [
                "Collaboration"
            ]
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "Data Engineer",
        "company": "StackEase",
        "location": "Marseille, Provence-Alpes-C\u00f4te d'Azur, France",
        "link": "https://fr.linkedin.com/jobs/view/data-engineer-at-stackease-3906618983?position=8&pageNum=7&refId=2YID7uch9sWjo1I7wCmyNQ%3D%3D&trackingId=dus3QZepxedeM%2FgZcg7KtA%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Context :\nIt is challenging in many ways to develop a net zero electricity grid. Adding renewable energies means more need for storage and for grid balancing. Grid-scale batteries handle these issues but their operation is not quite simple.\nA battery has access to many different revenue streams, each being specific. No revenue alone is enough to make it economically viable. All revenues stacked and optimized together ensure profitability in the long run and a fast deployment.\nStackEase\u2019s ambition is to develop optimization and trading algorithms that merge the battery revenue streams and ensure their sustainable development. The final tool will be an autopilot that makes the best decisions in real time, controls the battery accordingly and sends the corresponding orders to\u00a0 the market.\nAbout StackEase:\nStackEase is a deeptech spinoff from the INRIA (French Institute for Research in Computer Science). It was created in August 2023 and secured its first fundings. Members are located in Marseille and Paris.\nOur values are innovation, customer satisfaction, merit and sustainability. The company's purpose is to leverage Machine Learning and Mathematical Optimization to accelerate the energy transition.\nMissions :\nDefine and develop the backend architecture of StackEase\nSet up databases and data pipelines collecting battery and market data\nDeploy and maintain optimisation algorithms and forecasts\nDevelop a robust and scalable SaaS platform for 24/7 battery management with high cyber standards\nParticipate in the UI/UX product definition\nSkills Wishlist :\nScientific BS/MS/PhD with 2+ years of experience in software engineering\nExperience with the common backend tools: Python, Git, Kubernetes, SQL/NoSQL \u2026 Knowledge of the AWS environment is a plus\nEnthusiastic, rigorous, autonomous and willing to be involved in major technical decisions\nKnowledge/Interest in the energy sector and ancillary services\nCompensation :\n45k\u20ac - 60k\u20ac salary range (incl. healthcare, unemployment rate, vacations, \u2026)\nFlexible remote work policies\nYou do not need to meet 100% of the requirements to apply, we will study all applications: please send your resume to jobs@stackease.fr. References and a cover letter are also welcome but not mandatory.\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "Scala",
                "R",
                "Go"
            ],
            "DataBase": [
                "SQL",
                "NoSQL"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [
                "AWS"
            ],
            "DevTools": [
                "Git"
            ],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [
                "Kubernetes"
            ],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [
                "Kubernetes"
            ],
            "Collaboration": [],
            "Other": [
                "Machine Learning"
            ],
            "FrSoftSkills": [],
            "EnSoftSkils": []
        },
        "details": {
            "JobDetail": [
                "Remote"
            ],
            "TypeContract": [],
            "Salary": [
                "100"
            ],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "Data Engineer / Big Data",
        "company": "ALTEN",
        "location": "Antibes, Provence-Alpes-C\u00f4te d'Azur, France",
        "link": "https://fr.linkedin.com/jobs/view/data-engineer-big-data-at-alten-3896177673?position=9&pageNum=7&refId=2YID7uch9sWjo1I7wCmyNQ%3D%3D&trackingId=9KPNQINsEC%2BkKrRJPbAmCQ%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Alten is one of the 3 main consulting societies in France. It is present in more than 30 countries in the word. Sophia-Antipolis is the first and largest technopole in Europe, located in the South of France between Nice and Cannes, near Antibes. It\u2019s also called the European Silicon Valley.\nReporting to our consulting team, you will work in an IT environment as an IT Business Analyst, taking part in projects in an Agile environment.\nJob Description\nThe mission consists in taking part toprojectsthat are collecting, processing, and converting raw data into information (Flat Data + KPIs) that can be interpreted by data/business analysts.\nTheData accessibilityis the ultimate goal of this mission, by enabling the Digital data users to utilize data for their business decisions.\nThis role is more Pipeline-centric, for which you need in-depth knowledge of distributed systems and computer science.\nThe mission scope will encompass the design and delivery of some key components of the Digital Data platform(Spark environment, Scala language) including following activities:\nParticipate to specifications reviews, propose technical solutions and perform feasibility studies.\nAcquire datasets that align with business needs.\nDevelop algorithms to transform data into useful, actionable information.\nDevelop, construct, test, and maintain optimal data pipeline architectures.\nCreate new data validation methods and data analysis tools.\nEnsure compliance with data governance and security policies.\nIdentify ways to improve data reliability, efficiency, and quality.\nIdentify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.\nPrepare data for predictive and prescriptive modeling.\nWork with data and analytics experts to strive for greater functionality in our data systems; which requires a closed collaboration with the other trains.\nDevelop software according to Amadeus Standards, including documentation\nPerform code reviews in line with Amadeus quality standards.\nConduct unit, package and performance tests of the software and ensure a level of quality in line with the Amadeus guidelines.\nParticipate in the validation / acceptance phase of the product cycle ensuring the fine-tuning necessary to finalize the product.\nProduce software documentation necessary for the application and issue it to the requesting departments.\nSupport the end user in the Production phase by debugging existing software solutions in response to Problem Tracking Records (PTR) and Change Requests (CR) issued from Product Management or Product Definition.\nAs part of the team, the consultant will, as well, work as DevOps, releasing the software load to production, monitoring jobs and being involved in maintenance activities. Quality analyst activities are also handled by the Devs.\nOur current data platform is a MapR architecture, and we are in the process to migrate the whole platform to the Azure cloud., which is one of the key focuses for the team in the upcoming months. This will trigger easier adoption of data and foster collaboration within Amadeus around data.\nQualifications\nTechnical skills:\nPrevious experience as a data engineer or in a similar role\nExperience building or optimizing \u201cbig data\u201d data pipelines, architectures and data sets.\nHands-on experience with Scala (>2 years or a strong experience with Java/C++ with a good knowledge level of Scala)\nExperience with big data tool: Spark, Kafka, MapR , Hadoop\nUnderstanding extract, transform, and load ETL systems\nKnowledge of cloud services: MS Azure\nSoft skills:\nAgile Mindset: must be comfortable working with Agile values and artifacts\nFast learning: must be able to adapt quickly to the existing environment and new changes\nAnalytical thinking and problem-solving mindset: must be able to quickly identify, implement work-around to solve incidents and work on long term data solutions\nTeam spirit, knowledge sharing, Empathy: must be able to work in a team and to communicate clearly with the other team members and users\nPro-activity, Professionalism, Opennessand Innovative mindset\nVarious:\nEnglish: professional level\nKnowledge of Scrum framework and Agile methodologies.\nKnowledge of airline business is a plus\nAdditional Information\nALTEN places the career development of the Engineers at the heart of its model and allows you to quickly take on responsibilities and evolve in line with your professional objective. It's the promise of growing your skills on concrete subjects in a project team, with a permanent contract as an ALTEN consultant!\nDo you recognize yourself in this description? Then send us your CV.\nOur teams will be delighted to study your application and meet you!\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Java",
                "C++",
                "Scala",
                "R",
                "Go"
            ],
            "DataBase": [],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [
                "Hadoop",
                "Spark"
            ],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [
                "Azure"
            ],
            "DevTools": [
                "Git"
            ],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [
                "Teams"
            ],
            "Other": [
                "DevOps",
                "Big Data",
                "Cloud"
            ],
            "FrSoftSkills": [
                "Collaboration"
            ],
            "EnSoftSkils": [
                "Empathy",
                "Collaboration"
            ]
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [],
            "Salary": [
                "2"
            ],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "Data Engineer",
        "company": "ASTRELYA",
        "location": "Greater Paris Metropolitan Region",
        "link": "https://fr.linkedin.com/jobs/view/data-engineer-at-astrelya-3910760230?position=10&pageNum=7&refId=2YID7uch9sWjo1I7wCmyNQ%3D%3D&trackingId=v8lA3BhOGBaAvAsiUoQ%2FXA%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "ASTRELYA est un groupe de conseil et d\u2019expertise IT fond\u00e9 en 2017, pr\u00e9sent en France (Paris et r\u00e9gions) et en Suisse (Gen\u00e8ve). Aujourd'hui plus de 280 collaborateurs accompagnent nos clients dans l\u2019acc\u00e9l\u00e9ration et la transformation de leurs organisations.\nDans le cadre de notre d\u00e9veloppement, nous recherchons un\nData Engineeer F/H\n.\nVos r\u00f4les et responsabilit\u00e9s :\nD\u00e9veloppements Java Spark\nOptimisation et gestion des \u00e9volutions de l&#39;architecture pour int\u00e9grer des calculs sur des volum\u00e9tries de plus en plus importantes\nSupport technique aupr\u00e8s des \u00e9quipes de d\u00e9veloppement et du responsable applicatif\nConception des solutions applicatives coh\u00e9rentes avec l&#39;ensemble du SI et avec les normes et standards\nD\u00e9velopper et garantir les pratiques de d\u00e9veloppement et de documentation associ\u00e9s (DevOps\nL\u2019environnement technique dans lequel vous \u00e9voluerez :\nJava, Scala, Spark, \u00e9cosyst\u00e8me Hadoop, environnement DevOps\nLes comp\u00e9tences recherch\u00e9es :\nFormation : \u00c9cole d\u2019ing\u00e9nieur ou \u00e9quivalent Bac+5\nExp\u00e9riences : Minimum 5 ans d\u2019exp\u00e9rience\nLangues : Anglais technique\nExcellent relationnel, force de proposition, autonome\nPourquoi rejoindre ASTRELYA ?\nUne gestion de carri\u00e8re personnalis\u00e9e et un management de proximit\u00e9\nUne politique active de formations / certifications (technique, m\u00e9tier, leadership)\nUne offre vari\u00e9e de missions d\u2019expertise\nUn engagement RSE fort : Ecovadis Gold, Signataire de la charte pour la diversit\u00e9, du Pacte des Nations Unies et mise en place du M\u00e9c\u00e9nat de comp\u00e9tences\nUn programme de cooptation attractif\nAfterworks, conf\u00e9rences techniques et activit\u00e9s sportives r\u00e9guliers\nCette annonce vous correspond ? Postulez !\n\ud83d\ude80\nTous nos postes sont ouverts aux personnes en situation de handicap.\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Java",
                "Scala",
                "R",
                "Go"
            ],
            "DataBase": [],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [
                "Hadoop",
                "Spark"
            ],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [],
            "DevTools": [],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [
                "DevOps"
            ],
            "FrSoftSkills": [
                "Leadership",
                "Organisation"
            ],
            "EnSoftSkils": [
                "Leadership"
            ]
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [],
            "Salary": [],
            "Level": [
                "Bac+5"
            ],
            "Experience": [
                "a",
                "n",
                "s",
                "5",
                "5",
                "5"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "Int\u00e9grateur/Data Engineer",
        "company": "Apollo Plus",
        "location": "Paris, \u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/int%C3%A9grateur-data-engineer-at-apollo-plus-3915774077?position=1&pageNum=10&refId=YRlmHfDXD2q8y%2FLEi2ngtQ%3D%3D&trackingId=auvz94%2F%2BKdvLumd1UTOF%2FA%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Nous, c'est Apollo Plus.\nNotre ambition ? Devenir La solution SaaS bas\u00e9e sur l\u2019IA, d'aide \u00e0 la d\u00e9cision et de pr\u00e9dictions de la demande dans les secteurs du tourisme, de l\u2019h\u00f4tellerie et du retail.\nDepuis notre lancement sur ce march\u00e9 en 2017, nous n'avons pas arr\u00eat\u00e9 de grandir et d'enrichir notre application pour accompagner nos clients dans leurs diff\u00e9rents challenges et questionnements :\nEst-il possible de pr\u00e9dire l\u2019intention et le comportement des visiteurs ?\nQuelle segmentation des visiteurs construire \u00e0 partir de nombreuses sources ?\nO\u00f9 et pour quelle offre g\u00e9n\u00e9rer de l\u2019affluence suppl\u00e9mentaire ?\nQuelle est l\u2019\u00e9lasticit\u00e9 prix et la disponibilit\u00e9 \u00e0 payer de nos clients ?\nComment enrichir nos donn\u00e9es avec de l'open data pertinente ?\nComment pouvons-nous am\u00e9liorer la connaissance de nos visiteurs ?\nComment mesurer les campagnes marketing et les plans de communication ?\nApollo Plus est pr\u00e9sent sur les march\u00e9s fran\u00e7ais, allemand, espagnol, belge et am\u00e9ricain.\nLe p\u00e9rim\u00e8tre du poste concerne essentiellement le parcours et la transformation des donn\u00e9es depuis leur stockage chez un client jusque dans nos bases de donn\u00e9es.\nMissions\nInt\u00e9grer de nouveaux clients : traduire les besoins m\u00e9tier en pipelines de traitement de donn\u00e9es, cod\u00e9s en Python\nImpl\u00e9menter de nouveaux connecteurs pour r\u00e9cup\u00e9rer les donn\u00e9es (solutions de billetterie, de paiement, de r\u00e9servations, de gestion h\u00f4teli\u00e8re, etc.)\nImpl\u00e9menter de nouvelles features d'analytiques (KPIs, granularit\u00e9 des chiffres, etc.)\nParticiper \u00e0 l'\u00e9volution et au maintien de nos pipelines de traitement de donn\u00e9es\nAm\u00e9liorer l'impl\u00e9mentation, le test et le backtesting de nos algorithmes de ML\nAm\u00e9liorer la configurabilit\u00e9 (par ex. permettre aux \u00e9quipes m\u00e9tier de configurer directement les r\u00e8gles de calcul)\nAm\u00e9liorer l'outillage (CI/CD, tests, monitoring)\nStack technique\nReact, GraphQL\nDjango, Graphene-Django, DRF\npandas, scikit-learn, SQLAlchemy\nPostgreSQL, ClickHouse\nprefect\nAzure, Azure Devops (\u00e9quivalent GitHub), Docker, Linux\nComp\u00e9tences requises\nBonne connaissance du langage Python et du SQL\nExp\u00e9rience avec la manipulation de dataframes (par ex. avec pandas, spark)\nMa\u00eetrise pratique de git\nComp\u00e9tences appr\u00e9ci\u00e9es\nFamiliarit\u00e9 avec l'algorithmique\nFamiliarit\u00e9 avec les bases des OS : process, thread, m\u00e9moire, r\u00e9seau...\nExp\u00e9rience avec un cloud provider (Azure, AWS, ...)\nExp\u00e9rience en infra (VM, SSH, containerisation, ...)\nExp\u00e9rience avec un outil d'orchestration de workflow (Prefect, Airflow, ...)\nAnglais professionnel\nProcessus de recrutement\nRencontre RH (Google Meet - 30 minutes maximum) pour \u00e9changer sur votre parcours et vos aspirations ainsi que notre trajectoire et nos besoins\nTech interview (Google Meet - 30 minutes maximum) pour pr\u00e9ciser l'ad\u00e9quation comp\u00e9tences/besoins\nCase Study (\u00e0 distance ou en pr\u00e9sentiel) suite \u00e0 l'\u00e9change Tech\nDebrief (en pr\u00e9sentiel - peut-\u00eatre fait \u00e0 la suite du Case Study) avec le CTO et RH et remise d'offre\nInformations compl\u00e9mentaires\nType de contrat :\nCDI\nDate de d\u00e9but :\n20 mai 2024\nLieu :\nParis\nExp\u00e9rience :\n> 6 mois\nT\u00e9l\u00e9travail ponctuel autoris\u00e9\nSalaire :\nentre 36000\u20ac et 45000\u20ac / an\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "R",
                "Go"
            ],
            "DataBase": [
                "SQL"
            ],
            "DataAnalytics": [
                "Pandas",
                "R"
            ],
            "BigData": [
                "Spark"
            ],
            "MachingLearning": [
                "Scikit-Learn"
            ],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [
                "AWS",
                "Azure"
            ],
            "DevTools": [
                "Git",
                "Docker"
            ],
            "Os": [
                "Linux"
            ],
            "DBMS": [
                "PostgreSQL"
            ],
            "SoftBigDataProcessing": [],
            "Automation": [
                "Airflow"
            ],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [
                "Docker"
            ],
            "Collaboration": [],
            "Other": [
                "DevOps",
                "ML",
                "Cloud",
                "CI/CD"
            ],
            "FrSoftSkills": [
                "Communication"
            ],
            "EnSoftSkils": [
                "Communication"
            ]
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [
                "CDI"
            ],
            "Salary": [
                "36000"
            ],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "Data Engineer (F/H/X)",
        "company": "Goaheadspace",
        "location": "Pantin, \u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/data-engineer-f-h-x-at-goaheadspace-3915359112?position=2&pageNum=10&refId=YRlmHfDXD2q8y%2FLEi2ngtQ%3D%3D&trackingId=xUgTcqgGkUmSsyChPhHiIA%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "MFG Labs est une soci\u00e9t\u00e9 de conseil et r\u00e9alisation experte en data, qui aide les entreprises \u00e0 am\u00e9liorer leurs prises de d\u00e9cision, \u00e0 automatiser leurs processus et \u00e0 cr\u00e9er de nouveaux services gr\u00e2ce \u00e0 la data science, au design et \u00e0 l'utilisation des derni\u00e8res technologies.\nMFG Labs intervient \u00e0 toutes les \u00e9tapes de votre transformation data : de la cr\u00e9ation d'une feuille de route de projets data, \u00e0 la d\u00e9couverte d'insights, \u00e0 la mod\u00e9lisation de probl\u00e9matiques complexes, de la cr\u00e9ation d'un mod\u00e8le pr\u00e9dictif \u00e0 l'impl\u00e9mentation technique d'une solution data sur-mesure\nMFG Labs accompagne ses clients de diff\u00e9rentes mani\u00e8res :\nStrat\u00e9gie\nSolutions\nFondations\nMFG Labs d\u00e9ploie une approche holistique pluridisciplinaire, en m\u00ealant des data scientists, des designers, des data engineers et des consultants, afin d'apporter des solutions compl\u00e8tes de bout en bout \u00e0 des probl\u00e9matiques complexes.\nDans le cadre du d\u00e9veloppement de l\u2019\u00e9quipe, nous recherchons un.e Data Engineer \u00e0\nPantin (magasins g\u00e9n\u00e9raux).\nAu sein de l\u2019\u00e9quipe Data Technology, vous aurez pour mission de travailler sur des probl\u00e9matiques de collecte de la donn\u00e9e sur tout type de support digital : web, mobile, application, voire IoT.\nVotre r\u00f4le au sein de l\u2019\u00e9quipe :\nFaire partie d\u2019une \u00e9quipe pluridisciplinaire avec des talents en Design de Service, Consulting et Data science.\nD\u00e9velopper des applications de production int\u00e9grant diff\u00e9rents outils : des Math\u00e9matiques Appliqu\u00e9s, Machine (Deep) Learning, Recherche Op\u00e9rationnelle, Statistiques.\nD\u00e9velopper des pipelines de traitement de donn\u00e9es avec l\u2019\u00e9quipe de Data Science pour : ing\u00e9rer, transformer et d\u00e9livrer des donn\u00e9es et mod\u00e8les \u00e0 nos applications.\nD\u00e9ployer des applications utilisant les derniers outils mis \u00e0 disposition par les diff\u00e9rents Clouds publics.\n\u00c0 propos de vous :\nVous \u00eates titulaire d'un niveau Bac +4/Bac +5 d'une \u00e9cole d'ing\u00e9nieur\nVous avez au minimum deux ans d'exp\u00e9rience hors stage ou alternance\nVous \u00eates rigoureux\u00b7se vis-\u00e0-vis de vous-m\u00eame et des autres quant \u00e0 la qualit\u00e9 du code.\nVous avez quelques connaissances et comp\u00e9tences solides en d\u00e9veloppement et en en Data Ing\u00e9nierie au sens large.\nEn\nd\u00e9veloppement\nPython 3 et SQL\nFramework de traitement de donn\u00e9es (Spark ou \u00e9quivalent)\nDocker\nGIT\nEn +\nFramework permettant de d\u00e9ployer des APIs (Flask ou \u00e9quivalent)\nCI/CD\nLa pratique d'au moins un cloud (AWS, GCP ou Azure) est appr\u00e9ci\u00e9e\nEn Data Ing\u00e9nierie\nDatawarehouse ou Datalake\nData Pipelines Batch et/ou Straming\nEn +\nOutils de BI (Tableau, Power BI\u2026)\nOutils MLOps (Sagemaker, VertexAI, etc.)\nSi vous vous reconnaissez dans cette annonce, n'h\u00e9sitez pas \u00e0 postuler !\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "R",
                "Go"
            ],
            "DataBase": [
                "SQL"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [
                "Spark"
            ],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [
                "Tableau",
                "Power BI"
            ],
            "Statistics": [
                "Statistiques"
            ],
            "CloudComputing": [
                "AWS",
                "Azure"
            ],
            "DevTools": [
                "Git",
                "Docker"
            ],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [
                "Docker"
            ],
            "Collaboration": [],
            "Other": [
                "ML",
                "Statistiques",
                "Cloud",
                "CI/CD"
            ],
            "FrSoftSkills": [],
            "EnSoftSkils": []
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "Data Engineer H/F",
        "company": "Dalkia",
        "location": "Angers, Pays de la Loire, France",
        "link": "https://fr.linkedin.com/jobs/view/data-engineer-h-f-at-dalkia-3907349741?position=3&pageNum=10&refId=YRlmHfDXD2q8y%2FLEi2ngtQ%3D%3D&trackingId=5wEEPPCD7CRNwrkdwQtzoQ%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Descriptif du poste\nEt si vous faisiez \u00e9quipe avec nous ? Rejoindre Dalkia, c'est plus de sens et d'implication contre le r\u00e9chauffement climatique ; plus de relations humaines, avec un m\u00e9tier de service anim\u00e9 par l'esprit d'\u00e9quipe ; plus de technicit\u00e9, avec des projets ambitieux et innovants fond\u00e9s sur nos expertises ; plus d'employabilit\u00e9, avec des parcours diversifi\u00e9s et individualis\u00e9s. Rejoindre Dalkia, c'est rejoindre plus qu'une entreprise : un collectif de 20 000 collaborateurs engag\u00e9s en faveur de la transition \u00e9nerg\u00e9tique.\nDalkia Froid Solutions, acteur majeur de la r\u00e9frig\u00e9ration, sp\u00e9cialis\u00e9 dans les services \u00e9nerg\u00e9tiques pour les process industriels et tertiaires, recherche un(e) Data Engineer\n(H/F)\n. Rattach\u00e9 (e) au Responsable Data au sein de la Direction des Syst\u00e8mes D'Informations, vous \u00eates le garant du bon d\u00e9roulement des d\u00e9veloppements de flux de donn\u00e9es et de leur pr\u00e9paration pour leur analyse. Vous aurez l'opportunit\u00e9 de rejoindre une \u00e9quipe en construction.\nCandidater chez Dalkia Froid Solutions, c\u2019est avoir l\u2019envie d\u2019int\u00e9grer un grand groupe \u00e0 l\u2019esprit familial. L\u2019humain est au c\u0153ur de nos m\u00e9tiers, nous donnons la chance \u00e0 tous, afin de d\u00e9couvrir nos talents de demain. Venez renforcer notre Direction des Syst\u00e8mes d'Informations et contribuez \u00e0 l'optimisation \u00e9nerg\u00e9tique \u00e0 travers la data !\nVos Principales Missions\nD\u00e9finir l'architecture ETL et d\u00e9velopper les jobs d'int\u00e9gration de donn\u00e9es pour notre environnement Big Data.\nAssurer le monitoring quotidien des jobs et optimiser les performances de traitement.\nGarantir la qualit\u00e9 et l'int\u00e9grit\u00e9 des donn\u00e9es en industrialisant leur nettoyage.\nAdapter les DataMarts pour le reporting en collaboration avec les \u00e9quipes m\u00e9tiers : comprendre et analyser les besoins utilisateurs, et r\u00e9diger les sp\u00e9cifications fonctionnelles et techniques.\nVous serez \u00e9galement ammen\u00e9 \u00e0 collaborer avec l'\u00e9quipe Infrastructure pour d\u00e9finir les besoins techniques et planifier les investissements. En lien avec votre \u00e9quipe vous conduirez des projets vari\u00e9s et participerez \u00e0 la mise en oeuvre de rapports BI et de mod\u00e8les de machine learning.\nLieu :\nSi\u00e8ge Social - Angers / T\u00e9l\u00e9travail possible \u00e0 raison de 2 jours par semaine apr\u00e8s p\u00e9riode d'essaie\nVotre profil\nDipl\u00f4m\u00e9 (e) d'un bac + 5 minimum sp\u00e9cialis\u00e9 en Data Engineer ,vous avez de bonnes qualit\u00e9s relationnelles afin d'accompagner le d\u00e9ploiement des projets. Votre rigueur et votre logique sont incontestables. Vous aimez travailler en \u00e9quipe pour accompagner l'entreprise vers l'excellence op\u00e9rationnelle.\nC\u00f4t\u00e9 Outils ? Vous maitrisez les langages SQL et Pyhton et vous avez d\u00e9j\u00e0 pratiqu\u00e9 les outils DBT et GitLab. Une premi\u00e8re exp\u00e9rience avec un outil de BI/Datavisualisation est souhait\u00e9e.\nLa connaissance des outils Qlik Sense ou Talend serait un plus!\nPr\u00eat(e) \u00e0 faire une diff\u00e9rence avec nous ? Postulez d\u00e8s maintenant !\nEnsemble, nous contribuons collectivement \u00e0 la transition \u00e9nerg\u00e9tique. C'est pourquoi chez Dalkia Froid Solutions, nous sommes convaincus que chacun peut participer \u00e0 relever ce d\u00e9fi. De ce fait, chaque candidature recevra la m\u00eame attention.\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "R"
            ],
            "DataBase": [
                "SQL"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [],
            "DevTools": [
                "Git"
            ],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [
                "Big Data",
                "Machine Learning"
            ],
            "FrSoftSkills": [
                "Collaboration"
            ],
            "EnSoftSkils": [
                "Collaboration"
            ]
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "Analytics Engineer",
        "company": "Vestiaire Collective",
        "location": "Paris, \u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/analytics-engineer-at-vestiaire-collective-3875996826?position=4&pageNum=10&refId=YRlmHfDXD2q8y%2FLEi2ngtQ%3D%3D&trackingId=8vuJPLbUeY03j4erAEmiMw%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Vestiaire Collective is the leading global online marketplace for desirable pre-loved fashion. Our mission is to transform the fashion industry for a more sustainable future by empowering our community to promote the circular fashion movement. Vestiaire was founded in 2009 and is headquartered in Paris with offices in London, Berlin, New York, Singapore, Ho Chi Minh and Hong Kong and warehouses in Tourcoing (France), Crawley (UK), Hong Kong and New York.\nWe currently have a diverse global team of 700 employees representing more than 50 nationalities. Our values are Activism, Transparency, Dedication and Greatness and Collective. We are proud to be a BCorp.\nAbout The Role\nThis role is central to our data strategy and requires a balance of technical expertise and business acumen. As a Junior Analytics Engineer, you will be at the heart of our data-driven initiatives, working closely with cross-functional teams to transform raw data into a single source of truth data mart. Your work will directly influence key decisions in finance, payment systems and business performance.\nWhat You'll Do\nDesign, implement, and maintain efficient and reliable data pipelines using a modern data stack: Airflow, Snowflake, DBT\nDevelop advanced data models to support complex analytics, including financial reconciliations, cost effectiveness and profitability models. Collaborate with finance, payments and tech teams to understand their data requirements and translate these into sophisticated technical solutions\nEnsure scalability and performance of our data infrastructure to handle large-scale, multi-faceted data sets from diverse sources\nImplement and maintain data quality checks and monitoring systems for accuracy and consistency\nInnovate and integrate new technologies and methodologies to enhance data capabilities across finance domains\nAssist the finance team in building key dashboards in Tableau to enable data driven decision making\nWho You Are\nRequired Qualifications:\nBachelor\u2019s/Master\u2019s in Computer Science, Engineering, Statistics, or related field\nAt least one previous experience in analytics engineering, with strong skills in ETL and data modeling, an awareness of data warehousing and dataOps practices\nProficient in SQL and programming languages like Python or R\nExperience with cloud data technologies and big data tools\nDesirable Skills:\nApache Airflow: an understanding of workflow management\nGit: Solid knowledge in version control and CI/CD integration\nCloud Service: AWS, Snowflake or similar cloud experience\nData Visualization Tools: Proficiency in tools like Tableau, Looker, Snowsight\nPrevious experience in DBT for data modeling\nWhat we offer\n\ud83c\udf81\nA meaningful job with an impact on the way people consume fashion and promote sustainability\nFlexible work possibilities\nThe opportunity to do career-defining work in a fast-growing French-born scale up\nThe possibility to work as part of a globally diverse team with more than 50 nationalities\nTwo days to help Project - reinforcing your activist journey and volunteer for an association\nSignificant investment in your learning and growth\nCompetitive Compensation And Benefits Package\nAs full member of our entrepreneurial project, you will be eligible to free shares\nVestiaire Collective is an equal opportunities employer\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "Scala",
                "R"
            ],
            "DataBase": [
                "SQL"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [
                "Apache Airflow"
            ],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [
                "Tableau"
            ],
            "Statistics": [
                "Statistics"
            ],
            "CloudComputing": [
                "AWS"
            ],
            "DevTools": [
                "Git"
            ],
            "Os": [],
            "DBMS": [
                "Snowflake",
                "Snowflake"
            ],
            "SoftBigDataProcessing": [],
            "Automation": [
                "Airflow"
            ],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [
                "Teams"
            ],
            "Other": [
                "Big Data",
                "Cloud",
                "CI/CD"
            ],
            "FrSoftSkills": [],
            "EnSoftSkils": [
                "Initiative"
            ]
        },
        "details": {
            "JobDetail": [
                "Full",
                "Junior"
            ],
            "TypeContract": [],
            "Salary": [
                "Package"
            ],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "Data Engineer (F/H) - Alternance",
        "company": "Vertbaudet",
        "location": "Tourcoing, Hauts-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/data-engineer-f-h-alternance-at-vertbaudet-3853542017?position=5&pageNum=10&refId=YRlmHfDXD2q8y%2FLEi2ngtQ%3D%3D&trackingId=BlTZ4D5w5ZRpcFiIPssV8A%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "A PROPOS DE NOUS !\nVertbaudet est le pure-player leader europ\u00e9en du monde de l'enfant, au travers de 10 sites web adapt\u00e9s aux besoins de chaque march\u00e9 (France, Allemagne, Suisse, Royaume-Uni, Belgique, Pays-Bas, Espagne, Portugal, Autriche et .com pour le reste du monde). En France, Vertbaudet est \u00e9galement pr\u00e9sent dans 72 magasins.\nVertbaudet s\u2019appuie sur une communaut\u00e9 de plus de 3 millions de parents, clients actifs de nos sites qui b\u00e9n\u00e9ficient d\u2019une exp\u00e9rience d\u2019achat personnalis\u00e9e.\nVertbaudet d\u00e9veloppe \u00e0 la fois une offre exclusive au travers de sa marque propre et propose \u00e9galement des marques leaders ou innovantes.\nPar son expertise et sa cr\u00e9ativit\u00e9, Vertbaudet r\u00e9pond \u00e0 tous les besoins des parents pour leurs enfants de 0 \u00e0 12 ans en Mode, Chaussures, Maison, Pu\u00e9riculture et Jouets.\nCr\u00e9\u00e9 en 1963, Vertbaudet emploie plus de 1000 personnes en France et a g\u00e9n\u00e9r\u00e9 un chiffre d\u2019affaires sup\u00e9rieur \u00e0 330 millions \u20ac HT en 2023.\nPoste:\nRattach\u00e9(e) \u00e0 notre Direction Informatique, tu rejoins le d\u00e9partement Intelligence Clients et plus particuli\u00e8rement \u00ab la team \u00bb de Florent, notre Responsable Data DSI. Notre mission est d\u2019optimiser la valeur de nos clients par la bonne connaissance de leurs profils et de leur activit\u00e9\nTu int\u00e9greras une \u00e9quipe de Data Engineers pour apprendre \u00e0 leur c\u00f4t\u00e9 et participer \u00e0 nos projets : construction de flux de donn\u00e9es, maintenance d\u2019une plateforme Data moderne, d\u00e9veloppements d\u2019algorithmes complexes, mise en place de r\u00e8gles DataQuality \u2026\nTu manipuleras des outils et des m\u00e9thodes vari\u00e9s : Stambia, SQL, CI/CD, Snowflake, Airflow, Cloud Azure \u2026\nTu seras accompagn\u00e9(e) par un Data Engineer Senior qui saura te faire grandir et te permettre de d\u00e9livrer de la valeur pour notre \u00e9quipe et l\u2019entreprise.\nPour cela, tu dois avoir l\u2019envie d\u2019apprendre de nouveaux langages et de nouveaux outils, de perfectionner ta connaissance du SQL, de la rigueur. Tu auras l\u2019occasion de d\u00e9couvrir des domaines m\u00e9tiers diff\u00e9rents : Marketing, Produit, Finance, Logistique.\nProfil:\nVraiment sympathique toutes ces missions, non ? Alors, si tu es en formation type Bac+5 ing\u00e9nieur ou \u00e9quivalent universitaire avec une sp\u00e9cialisation en data/statistique (ex : ENSAI, Polytech, Master Siad, ISN, Econom\u00e9trie...), tu es peut-\u00eatre la personne qu'il nous faut !\nLe SQL n\u2019a plus de secret pour toi ?\nTu es capable d\u2019extraire de la donn\u00e9e et de la manipuler ais\u00e9ment ?\nTon anglais\nis good enough\npour collaborer avec nos filiales internationales ?\nTu n\u2019as pas peur de param\u00e9trer un cluster Azure ?\nEnvoie-nous vite ta candidature !\nPlus que tes exp\u00e9riences professionnelles, nous nous attacherons \u00e0 ta passion, ta compr\u00e9hension de la marque, ton envie de t'immerger dans notre univers. Concr\u00e8tement, nous recherchons un(e) v\u00e9ritable passionn\u00e9(e), quelqu'un qui n'a pas peur de s'investir dans ses missions, quelqu'un de fiable, de r\u00e9actif, qui comprend les enjeux du business digital et qui poss\u00e8de une sensibilit\u00e9 client.\nTu es disponible pour une alternance de 24 mois \u00e0 partir de Septembre 2024\nPour faciliter le traitement de ta candidature,\nmerci d'indiquer sur ton CV le rythme d'alternance que propose ton \u00e9cole\nLieu : TOURCOING (59)\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "R",
                "Go"
            ],
            "DataBase": [
                "SQL"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [
                "Azure"
            ],
            "DevTools": [
                "Git"
            ],
            "Os": [],
            "DBMS": [
                "Snowflake",
                "Snowflake"
            ],
            "SoftBigDataProcessing": [],
            "Automation": [
                "Airflow"
            ],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [
                "Cloud",
                "CI/CD"
            ],
            "FrSoftSkills": [
                "Cr\u00e9ativit\u00e9"
            ],
            "EnSoftSkils": []
        },
        "details": {
            "JobDetail": [
                "Senior"
            ],
            "TypeContract": [],
            "Salary": [],
            "Level": [
                "Bac+5"
            ],
            "Experience": [
                "a",
                "n",
                "s",
                "12",
                "12",
                "12"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "Data Engineer",
        "company": "Harnham",
        "location": "Paris, \u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/data-engineer-at-harnham-3901400227?position=6&pageNum=10&refId=YRlmHfDXD2q8y%2FLEi2ngtQ%3D%3D&trackingId=ziWhFh8xzvynvlEVy14t8w%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "DATA ENGINEER\nLA DEFENSE (92)\n56K EUR\nRejoignez une \u00e9quipe en tant que Data Engineer au sein d\u2019une start-up orient\u00e9e Intelligence Artificiel, et aidez \u00e0 fa\u00e7onner l\u2019avenir technologique. C\u2019est votre chance de mettre en pratique vos comp\u00e9tences techniques et de jouer un r\u00f4le dans le futur du domaine des donn\u00e9es.\nVOTRE MISSION :\nConcevoir et d\u00e9velopper des pipelines de donn\u00e9es pour assurer la collecte, le traitement, et le stockage efficaces des donn\u00e9es pour comprendre les besoins.\nCollaboration avec les \u00e9quipes m\u00e9tiers\nElaborer des processus de validation des donn\u00e9es et mettre en place des tests automatis\u00e9s\nConcevoir et impl\u00e9menter des mod\u00e8les de donn\u00e9es\nVOTRE PROFIL :\nAu moins 6 mois de stage en tant que Data Engineer\nDipl\u00f4m\u00e9 d\u2019un Master (2 ans minimum)\nMaitrise d'un ou plusieurs Clouds Publics (AWS; GCP; Azure)\nMaitrise d'outils classiques (Python, Spark, SQL)\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "R"
            ],
            "DataBase": [
                "SQL"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [
                "Spark"
            ],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [
                "AWS",
                "Azure"
            ],
            "DevTools": [],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [
                "Cloud"
            ],
            "FrSoftSkills": [
                "Collaboration"
            ],
            "EnSoftSkils": [
                "Collaboration"
            ]
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s",
                "2",
                "2",
                "2"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "Big Data Engineer Databricks Senior - H/F - CDI",
        "company": "Talan",
        "location": "Paris, \u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/big-data-engineer-databricks-senior-h-f-cdi-at-talan-3909664424?position=7&pageNum=10&refId=YRlmHfDXD2q8y%2FLEi2ngtQ%3D%3D&trackingId=9Jk4wfhD6YOUymiIHt4IyA%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Talan est un groupe international de conseil en transformation et en innovation par la technologie, cr\u00e9\u00e9 en 2002.\nNos 5000 consultantes et consultants partagent \u00e0 travers le monde l\u2019audace d\u2019innover, le go\u00fbt de l\u2019excellence, et l\u2019envie de relever les d\u00e9fis les plus complexes.\nNous accompagnons les entreprises dans des secteurs vari\u00e9s\u202f: \u00e9nergie, industrie, transport, finance, luxe\u2026 \u00e0 travers 3 grandes expertises\u202f:\nLe Conseil en Management et Innovation (320 Consultants en France)\nLa valorisation des donn\u00e9es, leurs structurations, et leurs usages (Data et Technologies)\nL\u2019int\u00e9gration de solutions logicielles (Cloud et Applications Services)\nNos valeurs\u202f: engagement, respect, partage, esprit d\u2019\u00e9quipe et optimisme.\nTalan est une entreprise responsable, reconnue par ses collaborateurs et attach\u00e9e \u00e0 la diversit\u00e9. Des am\u00e9nagements peuvent \u00eatre propos\u00e9s si vous \u00eates en situation de handicap.\nRetrouvez nos engagements RSEiciet nos actions en faveur de la diversit\u00e9ici\nJob Description\nNous sommes \u00e0 la recherche d\u2019un Big Data Engineer Databricks S\u00e9nior qui sera en charge de l\u2019int\u00e9gration des donn\u00e9es: acquisition, pr\u00e9paration, mod\u00e9lisation et stockage, exposition, . Vous devrez faire preuve d\u2019un \u00e9tat d\u2019esprit \u00e0 la fois innovant, m\u00e9thodique, orient\u00e9 solution (et non probl\u00e8me!), et communiquant.\nResponsabilit\u00e9s\nManager des Big Data Engineer et Cloud Engineer\nCoacher techniquement les membres de l\u2019\u00e9quipe: solution et code review sur site, recommandation sur les formations \u00e0 suivre, certifications \u00e0 r\u00e9aliser, \u2026\nAnalyse des besoins techniques m\u00e9tiers, d\u00e9finition de l\u2019architecture solution et logiciel, r\u00e9f\u00e9rent technique, d\u00e9veloppement et optimisation, code review, maintenir les pratiques Devops \u201cYou build IT, You run IT\u201d, support \u00e0 recette et mise en production, documentation, et parfois assumer le r\u00f4le de Scrum Master,\u2026\nBenchmark de solutions et conseil aupr\u00e8s de notre client sur les solutions technologiques \u00e0 adopter, en lien avec leurs besoins\nPartage de connaissances et formations interne\nQualifications\nIssu(e) d\u2019une formation sup\u00e9rieure (\u00e9cole d\u2019ing\u00e9nieur, master,\u2026)\nVous disposez d\u2019au moins 4 ann\u00e9es d\u2019exp\u00e9rience dans le domaine du Big Data (et particuli\u00e8rement sur le framework Spark), et au moins 6 ann\u00e9es d\u2019exp\u00e9rience dans le d\u00e9veloppement logiciel\nVous ma\u00eetrisez led\u00e9veloppement logiciel (Scala, Python \u2026), et vous disposez de solides exp\u00e9riences dans la mise en place de pipelines de donn\u00e9es\nVous ma\u00eetrisez leFramework Spark (id\u00e9alement sur Databricks) etson optimisation\nExp\u00e9rience sur une plateforme Cloud serait un plus et id\u00e9alement AWS\nExp\u00e9rience sur des flux temps r\u00e9elserait un plus : Kafka + Spark Streaming\nVous ma\u00eetrisez les bases de donn\u00e9es SQL et le langage SQL\nVous avez de l'exp\u00e9rience sur les m\u00e9thodes de stockage: HDFS, S3,,\u2026\nVous avez de bonnes connaissances en devOps : Jenkins, Gitlab, Maven, \u2026\nLa connaissance des concepts suivants serait un +: DataOps, DataVault, DataMesh..\nConnaissance de l\u2019Agilit\u00e9\nAutonome\nOrganis\u00e9(e)\nSens du partage\nBonne communication\nOrientation produit et solution\nAdditional Information\nAVANTAGES\n:\nPlan de formation pour accompagner votre carri\u00e8re (formations \u00e9diteurs, certifications) gr\u00e2ce \u00e0 nos partenariats nous accordant une position de partenaire privil\u00e9gi\u00e9, et management de proximit\u00e9 par des experts\nLocaux modernes en centre-ville\nTop 5 du Palmar\u00e8s Great Place to Work\nT\u00e9l\u00e9travail jusqu\u2019\u00e0 5 jours selon les missions, prime d\u2019\u00e9quipement de 100\u20ac\nMobilit\u00e9 en France et \u00e0 l\u2019\u00e9tranger\nTop 1% des entreprises \u00e9valu\u00e9es par Ecovadis dans le domaine social, environnemental et \u00e9thique\nTickets restaurant, prime vacances, 50% transport (abonnement transport public), mutuelle\nPermanence handicap (consultant d\u00e9di\u00e9 aux collaborateurs en situation de handicap et aux proches aidants)\nActionnariat salari\u00e9\nPrime de cooptations\nRTT\nPROCESS RECRUTEMENT\n:\nL\u2019\u00e9quipe recrutement s\u2019engage \u00e0 vous proposer un processus de recrutement rapide et fluide\n1 entretien RHpar Teams (45min)\n1 test technique\n1 entretien technique par Teams (1heure)\n1 entretien op\u00e9rationnel avec le responsable de domaine, au si\u00e8ge (1heure)\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "Scala",
                "R",
                "Go"
            ],
            "DataBase": [
                "SQL"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [
                "Spark",
                "Databricks"
            ],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [
                "AWS"
            ],
            "DevTools": [
                "Git",
                "Jenkins"
            ],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [
                "Teams"
            ],
            "Other": [
                "DevOps",
                "Big Data",
                "Cloud"
            ],
            "FrSoftSkills": [
                "Communication"
            ],
            "EnSoftSkils": [
                "Communication"
            ]
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "Alternance - Data Engineer H/F",
        "company": "METEOJOB by CleverConnect",
        "location": "Villeneuve-d\u2019Ascq, Hauts-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/alternance-data-engineer-h-f-at-meteojob-by-cleverconnect-3891237691?position=8&pageNum=10&refId=YRlmHfDXD2q8y%2FLEi2ngtQ%3D%3D&trackingId=7%2FvZRxNxZ9KZ0pZ0CaSZ5A%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Description Du Poste\nAu sein du groupe Auchan, les \u00e9quipes d'Auchan Retail International sont au service des diff\u00e9rents pays dans lesquels Auchan est implant\u00e9.\nExperts des m\u00e9tiers du Digital, de la Finance, du Juridique, des Ressources Humaines et de la gestion d'entreprise, leur mission est d'accompagner les entit\u00e9s Auchan pays \u00e0 se construire, se structurer et se d\u00e9velopper.\nNous recherchons aujourd'hui\nun(e) alternant(e) Data Engineer\n(H/F).\nLa mission sera de concevoir et d\u00e9velopper les nouveaux flux de donn\u00e9es (batch et temps r\u00e9el) en \u00e9troite collaboration avec l'\u00e9quipe actuelle de Data Engineer, Data Scientist et les \u00e9quipes m\u00e9tiers.\nLes Principales Missions Seront Les Suivantes\nAnalyser les besoins des m\u00e9tiers et les traduire en sp\u00e9cifications techniques (en contribuant \u00e9galement \u00e0 l'\u00e9laboration des contrats d'interface et \u00e0 la mod\u00e9lisation physique)\nD\u00e9velopper des pipelines de donn\u00e9es au sein de son p\u00e9rim\u00e8tre\nVeiller \u00e0 la qualit\u00e9 et l'efficience des d\u00e9veloppements de l'\u00e9quipe\nContribuer \u00e0 la construction de la plateforme data et des services en remontant les besoins non couverts par le framework\nTravailler en \u00e9troite collaboration avec l'\u00e9quipe actuelle de Data Engineers, Data Scientists et les \u00e9quipes m\u00e9tiers.\nTu \u00c9volueras Dans Un Environnement Technique Compos\u00e9 De\nGoogle cloud platform (BigQuery, VertexAI)\nSQL\nPython\nDescription Du Profil\nVotre profil :\n\u00c9tudiant(e) en \u00e9cole d'Ing\u00e9nieurs ou Master Informatique ou \u00e9quivalent, vous recherchez une alternance et \u00eates passionn\u00e9(e) de la Data pour participer \u00e0 des projets d'envergures au sein d'une \u00e9quipe Data dynamique.\nComp\u00e9tences Techniques\nA l'aise (ou ayant envie de le devenir) dans l'environnement cloud GCP et ses services associ\u00e9s (Bigquery, GCS, Pubsub, Cloud function, Composer etc\u2026)\nVos connaissances sur les langages SQL et Python et des grands principes de mod\u00e8le seront vos alli\u00e9s pour r\u00e9pondre aux besoins de cette offre.\nSavoir \u00catre\nR\u00e9actif, avec le sens du service, vous justifiez de bonnes capacit\u00e9s d'\u00e9coute et d'un bon relationnel.\nCurieux, autonome et proactif.\nParce qu'Auchan Retail est convaincu que la diversit\u00e9 fait la richesse d'une entreprise, nous \u00e9tudions, \u00e0 comp\u00e9tences \u00e9gales, toutes les candidatures et adaptons le processus de recrutement et le poste \u00e0 tous les profils.\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "R",
                "Go"
            ],
            "DataBase": [
                "SQL"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [
                "Google Cloud Platform"
            ],
            "DevTools": [
                "Git"
            ],
            "Os": [],
            "DBMS": [
                "BigQuery"
            ],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [
                "Cloud"
            ],
            "FrSoftSkills": [
                "Collaboration"
            ],
            "EnSoftSkils": [
                "Collaboration"
            ]
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "Senior Data Engineer",
        "company": "Foxintelligence",
        "location": "Paris, \u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/senior-data-engineer-at-foxintelligence-3822491504?position=9&pageNum=10&refId=YRlmHfDXD2q8y%2FLEi2ngtQ%3D%3D&trackingId=qoKsI34biGUtx2FrnXb9Bg%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Chez Foxintelligence, nous sommes des amoureux de la data. \ud83e\udd13\nNotre mission est de rendre les consommateurs et les marques plus intelligents, gr\u00e2ce \u00e0 une donn\u00e9e de march\u00e9 r\u00e9volutionnaire issue de l'intelligence collective. Pour les consommateurs, Foxintelligence rend accessibles et utiles leurs donn\u00e9es transactionnelles issues de leurs bo\u00eetes mail ou comptes bancaires. En les anonymisant, nous cr\u00e9ons des statistiques uniques qui permettent aux marques de rester en phase avec les produits qui se vendent le mieux et les attentes des consommateurs.\nNous publions une application grand public aim\u00e9e par des millions de personnes (Cleanfox, 5m+ de t\u00e9l\u00e9chargements, 4.8/5 \ud83d\udc96 sur l'app store et le play store) et pr\u00e9parons le lancement d'une app de bilan carbone \u00e0 l'exp\u00e9rience radicalement nouvelle. Gr\u00e2ce \u00e0 notre plateforme data, elle va rendre possible une prise de conscience massive des enjeux du changement climatique \ud83c\udf0d et des actions individuelles possibles pour le combattre. Nous pensons que l'information est une force de changement puissante, lorsqu'elle s'appuie sur la data.\nUtilisant ces donn\u00e9es personnelles totalement anonymis\u00e9es, notre plateforme SaaS foxintelligence.io est devenue la r\u00e9f\u00e9rence de la market intelligence digitale en Europe avec des dizaines de grands groupes clients. Le point commun entre Deliveroo, Just Eat, Mano Mano, BackMarket ou The Boston Consulting Group ? Ils vont tr\u00e8s vite (on ne s'ennuie pas avec eux !) et ils nous font tous confiance !\nSoutenus par des investisseurs de premier plan (17m lev\u00e9s aupr\u00e8s de Daphni, Partech, GFC et eFounders) et r\u00e9cemment int\u00e9gr\u00e9 au groupe NielsenIQ nous sommes maintenant \u00e0 la conqu\u00eate de l'Europe et en phase d'hyper-croissance.\nSi notre FoxHQ reste \u00e0 Paris, notre \u00e9quipe de plus de 120 talents pluridisciplinaires (tech, data et business) travaille depuis partout en France et m\u00eame en dehors (ex. Turquie). Nous pensons que notre politique remote-first, notre culture forte (bienveillance, exigence, r\u00e9silience et data-first) et notre innovation permanente en termes de modes de travail (ex. grille de salaire transparente, formation au changement climatique, transparence sur la strat\u00e9gie) sont les cl\u00e9s de notre r\u00e9ussite collective.... et de ta r\u00e9ussite avec nous !\nJob Description\nNous recherchons un\nSenior Data Engineer\npour rejoindre l'\u00e9quipe charg\u00e9e des applications et des services internes. Tu seras responsables du cycle de vie complet de tes projets, du design \u00e0 la mise en production. Les projets r\u00e9cents accomplis par l'\u00e9quipe comprennent une plateforme d'enrichissement des donn\u00e9es de g\u00e9olocalisation capable de g\u00e9rer des centaines de millions de data points par jour ainsi qu'un API de machine learning bas\u00e9e sur ChatGPT capable de cat\u00e9goriser automatiquement nos donn\u00e9es.\nTes responsabilit\u00e9s\nDesign, d\u00e9veloppement et maintenance de nos services internes d'enrichissement des donn\u00e9es\nTravailler en \u00e9troite collaboration avec nos product managers, data analysts, et autre partie prenantes pour d\u00e9finir les besoin techniques et les sp\u00e9cifications\nCoacher et guider nos profils junior\nDiagnostiquer et r\u00e9soudre les diff\u00e9rents probl\u00e8mes techniques qui peuvent survenir (pas d'astreinte)\nRequirements\nComp\u00e9tences n\u00e9cessaires (ce qu'il te faut pour r\u00e9ussir sur ce poste):\nHard Skills\nExcellent niveau en SQL et tr\u00e8s bonne connaissance du service BigQuery de GCP\nUne bonne connaissance de Python est requise\nDes connaissances sur Airflow sont fortement recommand\u00e9es\nDe bonnes connaissances sur K8s plus g\u00e9n\u00e9ralement en gestion d'infrastructure\nSoft Skills\nExcellente communication\nCapacit\u00e9 \u00e0 g\u00e9rer plusieurs priorit\u00e9s et \u00e0 s'adapter \u00e0 un environnement en constante \u00e9volution\nExp\u00e9rience\nAvoir travaill\u00e9 avec BigQuery\nUne solide exp\u00e9rience en gestion de bases de donn\u00e9es relationnelles\nLadies\nLes \u00e9tudes montrent que les femmes ont moins tendance \u00e0 postuler \u00e0 une offre d'emploi quand elles n'ont pas toutes les qualifications. Ladies, ne vous mettez pas de barri\u00e8re et donnez-nous la chance de nous faire notre propre avis, nous serons toujours ravis d'\u00e9changer avec vous ! Si notre raison d'\u00eatre vous parle, postulez !\nSelf-made data lovers\nLes dipl\u00f4mes c'est bien, les skills c'est mieux et l'exp\u00e9rience t'en donne. Aucun dipl\u00f4me n'est requis chez nous, ce sont les comp\u00e9tences et l'\u00e9nergie qui comptent !\nRecruitment process\nRound 0 : entretien (fit) avec notre Head of People\nRound 1 : entretien avec un ou 2 manager(s) de l'\u00e9quipe\nTest technique / Etude de cas\nRound 2: entretien avec notre CTO\nBenefits\nAvantages/ce que nous offrons :\nSalaire et variable comp\u00e9titifs\nRemote friendly (+ budget am\u00e9nagement de l'espace de travail @Home)\nBonus Cooptation\nBonne assurance sant\u00e9 (Alan - prise en charge \u00e0 50%)\nTitres restaurants (swile) : pris en charge \u00e0 60% par Fox\nSyst\u00e8me de cr\u00e8che subventionn\u00e9 par Fox\nCulture forte et pratiques de management \u00e0 la pointe (strat\u00e9gie et r\u00e9sultats financiers transparents, feedback 360, grille de salaire innovante et transparente etc.)\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "R",
                "Go"
            ],
            "DataBase": [
                "SQL"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [
                "Statistiques"
            ],
            "CloudComputing": [],
            "DevTools": [
                "Git"
            ],
            "Os": [],
            "DBMS": [
                "BigQuery"
            ],
            "SoftBigDataProcessing": [],
            "Automation": [
                "Airflow"
            ],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [
                "Machine Learning",
                "Statistiques"
            ],
            "FrSoftSkills": [
                "Communication",
                "Collaboration"
            ],
            "EnSoftSkils": [
                "Communication",
                "Collaboration"
            ]
        },
        "details": {
            "JobDetail": [
                "Remote",
                "Junior",
                "Senior"
            ],
            "TypeContract": [],
            "Salary": [
                "0"
            ],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "Data Engineer (Snowflake)",
        "company": "MindPal",
        "location": "Toulouse, Occitanie, France",
        "link": "https://fr.linkedin.com/jobs/view/data-engineer-snowflake-at-mindpal-3896992742?position=10&pageNum=10&refId=YRlmHfDXD2q8y%2FLEi2ngtQ%3D%3D&trackingId=Cnl6cwGQ8OVBr%2BVZq52Q3w%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "We are looking for experienced\nData Engineers\nwith knowledge of\nSnowflake\nplatform.\nResponsibilities\nCreating and managing data in the Snowflake environment\nDesigning and implementing ETL (Extract, Transform, Load) solutions for transferring data between various sources and platforms\nOptimizing the performance of Snowflake databases, including designing and implementing data structures and using indexes appropriately\nAutomating data processing workflows using tools such as Airflow or other workflow management tools\nDeploying and configuring tools to monitor and report on the performance of the Snowflake system\nRequirements\nMinimum 1 year of experience as a Data Engineer\nAbility to use Snowflake\nVery good knowledge of SQL and programming in Python\nAbility to work with databases, including the Snowflake platform\nKnowledge of ETL tools and data integration\nAbility to work in a team and good communication skills\nFluent English in speaking and writing\nWe Offer\nB2B contract type\nFull-time job\nRemote and flexible working hours\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "R",
                "Go"
            ],
            "DataBase": [
                "SQL"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [],
            "DevTools": [],
            "Os": [],
            "DBMS": [
                "Snowflake",
                "Snowflake"
            ],
            "SoftBigDataProcessing": [],
            "Automation": [
                "Airflow"
            ],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [],
            "FrSoftSkills": [
                "Communication"
            ],
            "EnSoftSkils": [
                "Communication"
            ]
        },
        "details": {
            "JobDetail": [
                "Remote",
                "Full"
            ],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "Data Engineer H/F",
        "company": "Meilleurtaux",
        "location": "Paris, \u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/data-engineer-h-f-at-meilleurtaux-3912494325?position=1&pageNum=12&refId=RDfIAW6D%2Bq5WzkINrCwGag%3D%3D&trackingId=r4C2Hgw4OP5G7JgzOclkoA%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Description De L'entreprise\nScale-up embl\u00e9matique du paysage Tech fran\u00e7ais et marque connue aupr\u00e8s d\u2019un large public, Meilleurtaux est la marketplace incontournable pour le cr\u00e9dit, l\u2019assurance et le placement. Chaque ann\u00e9e, plus de 3 millions de Fran\u00e7ais utilisent nos services.\nNotre mission : offrir \u00e0 nos clients les meilleurs produits, au meilleur prix avec le meilleur conseil. Notre but : redonner le pouvoir \u00e0 nos clients et leur faire gagner du temps et de l\u2019argent.\nNos sites web et applis mobiles recueillent plus de 100M de visites par an. Nous travaillons avec de nombreux partenaires banques, assurance et gestionnaires d\u2019actifs.\nNotre ADN d\u2019innovation et de remise en question permanente pour servir nos clients nous conduit \u00e0 lancer chaque semaine de nouveaux projets, pilot\u00e9s par l\u2019une de nos \u00e9quipes produit.\nQuelques Chiffres\n\ud83d\udc49 pr\u00e8s de 2000 collaborateurs au sein du groupe dont 1000 collaborateurs au sein de notre r\u00e9seau de franchises.\n\ud83d\udc49 + de 350 agences r\u00e9parties sur l\u2019ensemble du territoire.\n\ud83d\udc49 x2 CA en l\u2019espace de 4 ans.\n\ud83d\udc49 une satisfaction client \u00e0 4,8/5 en 2022.\n\ud83d\udc49 100 M de visites sur les sites et applis du groupe.\nDescription Du Poste\nVous souhaitez rejoindre la fintech leader en cr\u00e9dit et en assurance, en forte croissance, innovante, dynamique et d\u00e9bordante de projets ? Ce qui suit va vous int\u00e9resser !\nContexte de ce recrutement\n\ud83d\ude80\nNous sommes engag\u00e9s dans le d\u00e9veloppement d\u2019une\nCustomer Data Platform.\nCette Plateforme De Donn\u00e9es Est Au C\u0153ur De La Strat\u00e9gie De Croissance De L\u2019entreprise Va Nous Permettre De\nAugmenter la Customer Lifetime Value (CLTV) de nos clients,\nD'int\u00e9grer dans tous nos produits des composants IA innovants,\nR\u00e9duire nos co\u00fbts d\u2019acquisition,\nFaciliter le pilotage du business \u00e0 travers une optimisation de nos outils de BI.\nVous vous \u00e9panouirez dans notre environnement en \u00e9volution rapide, o\u00f9 l'adaptabilit\u00e9 est essentielle. Au-del\u00e0 de la r\u00e9solution de d\u00e9fis techniques, nous souhaitons que vous contribuiez activement \u00e0 la construction de la culture d'ing\u00e9nierie de Meilleurtaux, \u00e0 l'am\u00e9lioration des pratiques et \u00e0 la promotion d'un environnement collaboratif et innovant.\nVos missions \ud83d\udcdd\nCr\u00e9er et maintenir une infrastructure de donn\u00e9es de pointe en permettant aux utilisateurs finaux d'acc\u00e9der \u00e0 de la donn\u00e9e pr\u00e9cise et de qualit\u00e9 ;\nD\u00e9velopper de nouveaux mod\u00e8les de donn\u00e9es et des pipelines.\nIls ont auront pour objectif de prendre en charge une grande vari\u00e9t\u00e9 de cas d'utilisation (de l'analyse et du reporting \u00e0 l'apprentissage automatique et \u00e0 l'innovation de produits) ;\nExplorer en permanence de nouvelles technologies de donn\u00e9es ;\nTester les solutions les plus innovantes et prometteuses du march\u00e9 en vue de pouvoir am\u00e9liorer nos capacit\u00e9s en mati\u00e8re de donn\u00e9es ;\nRecruter, encadrer et accompagner votre \u00e9quipe de Data Engineers au quotidien ;\nPartager et d\u00e9fendre vos meilleures pratiques d'ing\u00e9nierie de donn\u00e9es au sein des principaux organes de d\u00e9cision de l'entreprise.\nNotre stack technique\n\ud83d\udee0\nD\u00e9veloppement : Python, React, java, Salesforce\nCI-CD : Git, Docker\nInfrastructure cloud : GCP et Azure\nBases de donn\u00e9es : Google BigQuery et Databricks\nBI : Qliqsense\nCe poste n\u00e9cessite d'interagir avec de nombreuses \u00e9quipes au sein de Meilleurtaux que ce soit sur le plan technique (\u00e9quipes IT, Data Scientist et BI) et/ou fonctionnel (Product Managers).\nCeci n\u2019est qu\u2019un avant-go\u00fbt de la superbe aventure que vous vous appr\u00eatez \u00e0 rejoindre, le poste \u00e9tant \u00e9videmment amen\u00e9 \u00e0 \u00e9voluer en fonction de vous et vos propositions.\nQualifications\nPourquoi \u00eates-vous notre TOP candidat ? \ud83e\uddd0\nAvec une premi\u00e8re exp\u00e9rience r\u00e9ussie de 2 \u00e0 4 ans en tant que Data Engineer.\nVous savez cr\u00e9er des architectures de donn\u00e9es efficaces, \u00e9volutives et robustes.\nVous concevez des syst\u00e8mes adapt\u00e9s au pr\u00e9sent mais \u00e9galement \u00e0 l'avenir et qui r\u00e9sistent \u00e0 l'\u00e9preuve du temps.\nBien entendu, il est important que vous ayez de tr\u00e8s bonnes comp\u00e9tences techniques que ce soit en Python ; SQL et les autres outils pouvant exister en ing\u00e9nierie de donn\u00e9es.\nLa Big Data n'a plus de secret pour vous. Spark & Hadoop sont vos plateformes de r\u00e9f\u00e9rence sur ce domaine.\nVous avez d\u00e9j\u00e0 particip\u00e9 au d\u00e9ploiement d'infrastructure en Big Data.\nId\u00e9alement, vous fa\u00eetes partie d'une communaut\u00e9 de professionnels de la Data vous permettant d'\u00eatre toujours au fait des derni\u00e8res actualit\u00e9s.\nLe must : cette expertise a \u00e9t\u00e9 acquise au sein de l'industrie Fintech / Assurtech ou secteur \u00e9quivalent.\nLes soft-skills attendus pour r\u00e9ussir chez Meilleurtaux ?\nDu leadership : vous savez embarquer vos interlocuteurs dans un projet structurant et \u00e0 forts enjeux pour l'entreprise.\nDe la curiosit\u00e9 et de l'apprentissage continu : dans un domaine en constante \u00e9volution, nous recherchons une personne connect\u00e9e aux nouvelles technologies et aux derni\u00e8res innovations.\nDe l'adaptation : vous savez prendre en consid\u00e9ration les contraintes de l'entreprise et \u00e9valuer les risques techniques.\nComment se d\u00e9roule le processus de recrutement chez nous ?\n1 -\nPremier \u00e9change avec la Team RH pour apprendre \u00e0 mieux vous conna\u00eetre.\n2 -\nRencontre sur place avec votre futur manager, l'\u00e9quipe \u00e9ventuellement et un membre de l'\u00e9quipe RH.\n3 -\nR\u00e9alisation d'une \u00e9tude de cas et restitution avec le manager (selon le poste).\n4 -\nVotre candidature a \u00e9t\u00e9 retenue ? F\u00e9licitations et bienvenue \u00e0 bord \ud83c\udf89\nQu'attendez-vous pour participer \u00e0 la construction de cette \u00e9quipe de Data Engineers et partager votre expertise au sein d'une \u00e9quipe passionn\u00e9e par les sujets de Data ?\nInformations suppl\u00e9mentaires\nEn Nous Rejoignant , Meilleurtaux Vous Offre \ud83d\ude0d\nUn package attractif comprenant primes individuelles et collectives (participation et int\u00e9ressement).\nLa mutuelle ALAN avec des tarifs avantageux, une prise en charge rapide des remboursements et la pr\u00e9voyance prise en charge \u00e0 100% par Meilleurtaux.\nUne carte SWILE avec 10\u20ac de tickets restaurant par jour travaill\u00e9.\nUne prise en charge de votre transport de \"mobilit\u00e9 douce\" (trottinette, scooter, v\u00e9lo...) dans le cadre du Forfait Mobilit\u00e9s Durables.\nL'acc\u00e8s au CSE, sans condition d'anciennet\u00e9.\n2 jours de t\u00e9l\u00e9travail / semaine apr\u00e8s votre p\u00e9riode d'int\u00e9gration et une prise en main de votre poste.\nPour Vous Proposer Un Environnement De Travail Stimulant Et Propice \u00e0 L'\u00e9panouissement Et L'atteinte De Ses Objectifs, Meilleurtaux a Mis En Place \ud83d\udca5\nDes moments de convivialit\u00e9 (afterwork, Lunch & Learn, point d'actualit\u00e9 Groupe, soir\u00e9es d'entreprise, secret coffee...)\nLa possibilit\u00e9 de choisir votre mat\u00e9riel de travail (ordinateur & t\u00e9l\u00e9phone)\nUn dispositif d'acc\u00e8s \u00e0 la formation \u00e0 travers l'attribution d'une licence Openclassrooms (formation au choix selon vos envies et besoins).\nNous n'attendons plus que vous !\nLe manque de confiance peut parfois nous emp\u00eacher de postuler \u00e0 un emploi. Mais nous allons vous r\u00e9v\u00e9ler un secret : il n\u2019existe pas de candidat \u00ab parfait \u00bb. Donc, n\u2019h\u00e9sitez pas \u00e0 postuler si ce poste vous donne envie de vous d\u00e9passer tous les jours.\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "Java",
                "R",
                "Go"
            ],
            "DataBase": [
                "SQL"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [
                "Hadoop",
                "Spark",
                "Databricks"
            ],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [
                "Azure"
            ],
            "DevTools": [
                "Git",
                "Docker"
            ],
            "Os": [],
            "DBMS": [
                "BigQuery"
            ],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [
                "Docker"
            ],
            "Collaboration": [],
            "Other": [
                "Big Data",
                "Cloud"
            ],
            "FrSoftSkills": [
                "Adaptabilit\u00e9",
                "Leadership"
            ],
            "EnSoftSkils": [
                "Leadership"
            ]
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [],
            "Salary": [
                "100"
            ],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s",
                "4",
                "4",
                "4"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "Consultant Data Engineer",
        "company": "WHIZE",
        "location": "Neuilly-sur-Seine, \u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/consultant-data-engineer-at-whize-3907486262?position=2&pageNum=12&refId=RDfIAW6D%2Bq5WzkINrCwGag%3D%3D&trackingId=w6CYjt5HexGT1E7LfIFO3Q%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Offre d\u2019emploi pour un CDI : Consultant Data Engineer\nWHIZE est sp\u00e9cialis\u00e9e dans le d\u00e9veloppement de solutions sur mesure en architecture Serverless (Azure, Amazon WS, Google CP) et de solutions bas\u00e9es sur l'\u00e9cosyst\u00e8me Microsoft 365 (SharePoint, Teams, Power Platform).\nVos missions :\nConcevoir des solutions de traitement de volume tr\u00e8s important de donn\u00e9es.\nD\u00e9veloppement de flux de donn\u00e9es et pr\u00e9paration de leur analyse.\nPr\u00e9paration des donn\u00e9es pour l'analyse des donn\u00e9es collect\u00e9es.\nProfil recherch\u00e9 :\n2 ans minimum d\u2019exp\u00e9rience.\nMa\u00eetrise du langage Python et Scala\nConnaissance d'un ou plusieurs ETL du march\u00e9 (Talent , SSIS, Azure Data Factory, ...)\nForte expertise en SQL\n\u00catre \u00e0 l\u2019aise avec un ou plusieurs outils Devops (Jenkins, git, GitHub, gitlab, docker, kubernetes, etc\u2026)\nConnaissances appr\u00e9ci\u00e9es :\nHadoop, Spark, Kafka\nConnaissance des syst\u00e8mes NoSQL : Elasticsearch, HBase, Cassandra, Redshift\nConnaissance de l'offre data d'un des providers Cloud (GCP, Azure, AWS)\nQu\u2019attendez vous pour nous rejoindre ?\nVous ferez partie d\u2019une soci\u00e9t\u00e9 \u00e0 taille humaine et qui b\u00e9n\u00e9ficie des avantages d'un grand groupe. Nous adressons une centaine de clients en direct dont la moiti\u00e9 sont des grands comptes.\nVous serez accompagn\u00e9(e) et manag\u00e9(e) par le CEO de WHIZE (THE WHIZE MAN).\nVous allez compl\u00e9ter notre \u00e9quipe dynamique et travailler avec nous dans une ambiance Start-up et conviviale.\nVous occuperez des postes int\u00e9ressants et \u00e9volutifs.\nVous b\u00e9n\u00e9ficierez des \u00e9v\u00e8nements internes organis\u00e9s pour parler tech, business et projets.\nVous r\u00e9aliserez des projets \u00e0 forte valeur ajout\u00e9e.\n\ud83d\udccd : Neuilly-Sur-Seine+ T\u00e9l\u00e9travail\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "Scala",
                "R",
                "Go"
            ],
            "DataBase": [
                "SQL",
                "NoSQL",
                "Cassandra",
                "HBase",
                "Elasticsearch"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [
                "Hadoop",
                "Spark"
            ],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [
                "AWS",
                "Azure"
            ],
            "DevTools": [
                "Git",
                "Docker",
                "Jenkins"
            ],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [
                "HBase"
            ],
            "Automation": [
                "Kubernetes"
            ],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [
                "Docker",
                "Kubernetes"
            ],
            "Collaboration": [
                "Teams"
            ],
            "Other": [
                "DevOps",
                "Cloud"
            ],
            "FrSoftSkills": [],
            "EnSoftSkils": []
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [
                "CDI"
            ],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s",
                "2",
                "2",
                "2"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "Big Data Engineer \u2013 Paris, France (H/F)",
        "company": "Astek",
        "location": "Paris, \u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/big-data-engineer-%E2%80%93-paris-france-h-f-at-astek-3470775874?position=3&pageNum=12&refId=RDfIAW6D%2Bq5WzkINrCwGag%3D%3D&trackingId=6%2FLH5FlHsKFTsDTg3Z1MyA%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "CDI\nParis - France\nPubli\u00e9e il y a 2 mois\nLe Groupe Astek\nCe Que Nous Allons Accomplir Ensemble :\nNous rejoindre en tant que\nBig Data Engineer (H/F),\nafin d\u2019accompagner un op\u00e9rateur t\u00e9l\u00e9coms, Leader en Europe dans la cr\u00e9ation d\u2019une infrastructure cloud (IAAS) performante, robuste et s\u00e9curis\u00e9e.\nUn challenge portant sur des millions d\u2019utilisateurs dans un environnement technique innovant, strat\u00e9gique et o\u00f9 l\u2019entraide et la bonne humeur priment !\nVotre Mission, Si Vous L\u2019acceptez :\nQualifier les donn\u00e9es et les r\u00e9sultats\nConception technique des solutions\nD\u00e9cliner les impacts de la strat\u00e9gie et des innovations technologiques au sein des processus et outils de l\u2019exploitant SI\nAssurer l\u2019accompagnement et le d\u00e9ploiement des \u00e9volutions des processus et outils\nContribuer aux programmes de transformation DevOps, Cloud et catalogues des offres SI\nD\u00e9velopper des fonctions transverses et les \u00ab uses cases \u00bb\nAccompagner la phase de mise en production\nVotre Future \u00c9quipe :\nVous int\u00e9grerez une \u00e9quipe \u00e0 la fois technique et fonctionnel, qui \u0153uvre chaque jour pour d\u00e9velopper et maintenir en conditions op\u00e9rationnelles l\u2019ensemble des solutions IT !\nL\u2019\u00e9quipe est en interaction avec des clients \u00e0 la fois internes et externes.\nVotre stack de jeu\nSyst\u00e8me d\u2019exploitation : Linux\nEnvironnement Big data : Hadoop, Spark, Scala\nCloud computing : GCP ou AWS\nBase de donn\u00e9es : No SQL (Cassandra, Mongo DB)\nDataviz : Power BI ou Kibana\nDes notions en d\u00e9veloppement feront la diff\u00e9rence !\nLes Petits Plus Du Projet :\nVous \u00e9voluerez au sein d\u2019une \u00e9quipe impliqu\u00e9e et r\u00e9active et interviendrez sur un projet polyvalent et \u00e0 forte valeur ajout\u00e9e.\nVous ?\nDipl\u00f4m\u00e9(e) d\u2019une \u00e9cole d\u2019ing\u00e9nieur ou \u00e9quivalent de niveau Bac+5.\nVous justifiez id\u00e9alement d\u2019une exp\u00e9rience d\u2019au moins 3 ans d\u2019exp\u00e9riences sur un poste similaire ?\nVous faite preuve de proactivit\u00e9 et d\u2019esprit d\u2019\u00e9quipe, \u00eates dot\u00e9(e) d\u2019un excellent sens de l\u2019organisation et vous aimez les challenges et la r\u00e9solution de probl\u00e8me ?\nAlors ce poste est fait pour vous, n\u2019h\u00e9sitez plus et rejoignez l\u2019aventure ASTEK !\nAstek\nCr\u00e9\u00e9 en France en 1988, Astek est un acteur mondial de l\u2019ing\u00e9nierie et du conseil en technologies. Fort de son expertise dans de nombreux secteurs industriels et tertiaires, Astek accompagne ses clients internationaux dans le d\u00e9ploiement intelligent de leurs produits et de leurs services, et dans la mise en \u0153uvre de leur transformation digitale.\nDepuis sa cr\u00e9ation, le Groupe a fond\u00e9 son d\u00e9veloppement sur une forte culture d\u2019entrepreneuriat et d\u2019innovation, et sur l\u2019accompagnement et la mont\u00e9e en comp\u00e9tence de\nses 7800 collaborateurs\nqui s\u2019engagent chaque jour \u00e0 promouvoir la compl\u00e9mentarit\u00e9 entre les technologies num\u00e9riques et l\u2019ing\u00e9nierie des syst\u00e8mes complexes.\nRejoignez un Groupe en fort d\u00e9veloppement en France et \u00e0 travers le monde ayant r\u00e9alis\u00e9 un chiffre d\u2019affaires de 600 M\u20ac en 2023.\nTous les d\u00e9tails sur le Groupe sur le site https://astekgroup.fr. Et vous pouvez aussi nous suivre sur notre blog : https://blog.groupeastek.com.\nRencontrons-nous\nNotre projet commun vous plait ?\nPostulez \u00e0 cette annonce, et soyez transparent !\nMaud, notre Talent Acquisition Referent, vous contactera pour un premier \u00e9change.\nPuis vous rencontrerez Yoram, votre futur manager, avec lequel vous \u00e9changerez autour d\u2019Astek, de votre parcours, de vos attentes et de votre future mission .\nEnfin, vous rencontrerez Anthime, notre Directeur d\u2019agence avec lequel vous pourrez valider votre int\u00e9r\u00eat et ad\u00e9quation pour le poste et finaliser les \u00e9l\u00e9ments contractuels.\nNos Plus\nAstek est green et fait b\u00e9n\u00e9ficier ses salari\u00e9s d\u2019une indemnit\u00e9 kilom\u00e9trique v\u00e9lo\nUne politique CARE sur-mesure d\u00e9ploy\u00e9e par nos \u00e9quipes RH pour nos collaborateurs (https://astekgroup.fr/engagements)\nNotre charte de la Diversit\u00e9\nMots-cl\u00e9s :\ning\u00e9nieur \u2013 ing\u00e9nieure \u2013 consultant \u2013 consultante \u2013 developpement \u2013 Scala \u2013 Data\nCaract\u00e9ristiques de l'emploi\nCat\u00e9gorie Ing\u00e9nieur\nJob Industry T\u00e9l\u00e9com / M\u00e9dia\nPostuler en ligne\nNom *\nPr\u00e9nom *\nEmail *\nUn email valide est requis.\nT\u00e9l\u00e9phone *\nUn num\u00e9ro de t\u00e9l\u00e9phone valide est requis.\nJoindre un CV *\nMots-cl\u00e9s :\ning\u00e9nieur \u2013 ing\u00e9nieure \u2013 consultant \u2013 consultante \u2013 developpement \u2013 Scala \u2013 Data\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Scala",
                "R",
                "Go"
            ],
            "DataBase": [
                "SQL",
                "Cassandra"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [
                "Hadoop",
                "Spark"
            ],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [
                "Power BI"
            ],
            "Statistics": [],
            "CloudComputing": [
                "AWS"
            ],
            "DevTools": [
                "Git"
            ],
            "Os": [
                "Linux"
            ],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [
                "DevOps",
                "Big Data",
                "Cloud"
            ],
            "FrSoftSkills": [
                "Organisation"
            ],
            "EnSoftSkils": []
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [
                "CDI"
            ],
            "Salary": [],
            "Level": [
                "Bac+5"
            ],
            "Experience": [
                "a",
                "n",
                "s",
                "3",
                "3",
                "3"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "Big Data Engineer \u2013 Lille, France (H/F)",
        "company": "Astek",
        "location": "Lille, Hauts-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/big-data-engineer-%E2%80%93-lille-france-h-f-at-astek-3839097187?position=4&pageNum=12&refId=RDfIAW6D%2Bq5WzkINrCwGag%3D%3D&trackingId=NviWlQb3wBpX4sQPbEeH4w%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "CDI\nLille - France\nPubli\u00e9e il y a 2 mois\nLe Groupe Astek\nCe Que Nous Allons Accomplir Ensemble :\nNous rejoindre en tant que\nBig Data Engineer (H/F),\nafin d\u2019accompagner un op\u00e9rateur t\u00e9l\u00e9coms, Leader en Europe dans la cr\u00e9ation d\u2019une infrastructure cloud (IAAS) performante, robuste et s\u00e9curis\u00e9e.\nUn challenge portant sur des millions d\u2019utilisateurs dans un environnement technique innovant, strat\u00e9gique et o\u00f9 l\u2019entraide et la bonne humeur priment !\nVotre Mission, Si Vous L\u2019acceptez :\nQualifier les donn\u00e9es et les r\u00e9sultats\nConception technique des solutions\nD\u00e9cliner les impacts de la strat\u00e9gie et des innovations technologiques au sein des processus et outils de l\u2019exploitant SI\nAssurer l\u2019accompagnement et le d\u00e9ploiement des \u00e9volutions des processus et outils\nContribuer aux programmes de transformation DevOps, Cloud et catalogues des offres SI\nD\u00e9velopper des fonctions transverses et les \u00ab uses cases \u00bb\nAccompagner la phase de mise en production\nVotre Future \u00c9quipe :\nVous int\u00e9grerez une \u00e9quipe \u00e0 la fois technique et fonctionnel, qui \u0153uvre chaque jour pour d\u00e9velopper et maintenir en conditions op\u00e9rationnelles l\u2019ensemble des solutions IT !\nL\u2019\u00e9quipe est en interaction avec des clients \u00e0 la fois internes et externes.\nVotre stack de jeu\nSyst\u00e8me d\u2019exploitation : Linux\nEnvironnement Big data : Hadoop, Spark, Scala\nCloud computing : GCP ou AWS\nBase de donn\u00e9es : No SQL (Cassandra, Mongo DB)\nDataviz : Power BI ou Kibana\nDes notions en d\u00e9veloppement feront la diff\u00e9rence !\nLes Petits Plus Du Projet :\nVous \u00e9voluerez au sein d\u2019une \u00e9quipe impliqu\u00e9e et r\u00e9active et interviendrez sur un projet polyvalent et \u00e0 forte valeur ajout\u00e9e.\nVous ?\nDipl\u00f4m\u00e9(e) d\u2019une \u00e9cole d\u2019ing\u00e9nieur ou \u00e9quivalent de niveau Bac+5.\nVous justifiez id\u00e9alement d\u2019une exp\u00e9rience d\u2019au moins 3 ans d\u2019exp\u00e9riences sur un poste similaire ?\nVous faite preuve de proactivit\u00e9 et d\u2019esprit d\u2019\u00e9quipe, \u00eates dot\u00e9(e) d\u2019un excellent sens de l\u2019organisation et vous aimez les challenges et la r\u00e9solution de probl\u00e8me ?\nAlors ce poste est fait pour vous, n\u2019h\u00e9sitez plus et rejoignez l\u2019aventure ASTEK !\nAstek\nCr\u00e9\u00e9 en France en 1988, Astek est un acteur mondial de l\u2019ing\u00e9nierie et du conseil en technologies. Fort de son expertise dans de nombreux secteurs industriels et tertiaires, Astek accompagne ses clients internationaux dans le d\u00e9ploiement intelligent de leurs produits et de leurs services, et dans la mise en \u0153uvre de leur transformation digitale.\nDepuis sa cr\u00e9ation, le Groupe a fond\u00e9 son d\u00e9veloppement sur une forte culture d\u2019entrepreneuriat et d\u2019innovation, et sur l\u2019accompagnement et la mont\u00e9e en comp\u00e9tence de\nses 7800 collaborateurs\nqui s\u2019engagent chaque jour \u00e0 promouvoir la compl\u00e9mentarit\u00e9 entre les technologies num\u00e9riques et l\u2019ing\u00e9nierie des syst\u00e8mes complexes.\nRejoignez un Groupe en fort d\u00e9veloppement en France et \u00e0 travers le monde ayant r\u00e9alis\u00e9 un chiffre d\u2019affaires de 600 M\u20ac en 2023.\nTous les d\u00e9tails sur le Groupe sur le site https://astekgroup.fr. Et vous pouvez aussi nous suivre sur notre blog : https://blog.groupeastek.com.\nRencontrons-nous\nNotre projet commun vous plait ?\nPostulez \u00e0 cette annonce, et soyez transparent !\nMaud, notre Talent Acquisition Referent, vous contactera pour un premier \u00e9change.\nPuis vous rencontrerez Yoram, votre futur manager, avec lequel vous \u00e9changerez autour d\u2019Astek, de votre parcours, de vos attentes et de votre future mission .\nEnfin, vous rencontrerez Anthime, notre Directeur d\u2019agence avec lequel vous pourrez valider votre int\u00e9r\u00eat et ad\u00e9quation pour le poste et finaliser les \u00e9l\u00e9ments contractuels.\nNos Plus\nAstek est green et fait b\u00e9n\u00e9ficier ses salari\u00e9s d\u2019une indemnit\u00e9 kilom\u00e9trique v\u00e9lo\nUne politique CARE sur-mesure d\u00e9ploy\u00e9e par nos \u00e9quipes RH pour nos collaborateurs (https://astekgroup.fr/engagements)\nNotre charte de la Diversit\u00e9\nMots-cl\u00e9s :\ning\u00e9nieur \u2013 ing\u00e9nieure \u2013 consultant \u2013 consultante \u2013 developpement \u2013 Scala \u2013 Data\nCaract\u00e9ristiques de l'emploi\nCat\u00e9gorie Ing\u00e9nieur\nJob Industry T\u00e9l\u00e9com / M\u00e9dia\nPostuler en ligne\nNom *\nPr\u00e9nom *\nEmail *\nUn email valide est requis.\nT\u00e9l\u00e9phone *\nUn num\u00e9ro de t\u00e9l\u00e9phone valide est requis.\nJoindre un CV *\nMots-cl\u00e9s :\ning\u00e9nieur \u2013 ing\u00e9nieure \u2013 consultant \u2013 consultante \u2013 developpement \u2013 Scala \u2013 Data\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Scala",
                "R",
                "Go"
            ],
            "DataBase": [
                "SQL",
                "Cassandra"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [
                "Hadoop",
                "Spark"
            ],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [
                "Power BI"
            ],
            "Statistics": [],
            "CloudComputing": [
                "AWS"
            ],
            "DevTools": [
                "Git"
            ],
            "Os": [
                "Linux"
            ],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [
                "DevOps",
                "Big Data",
                "Cloud"
            ],
            "FrSoftSkills": [
                "Organisation"
            ],
            "EnSoftSkils": []
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [
                "CDI"
            ],
            "Salary": [],
            "Level": [
                "Bac+5"
            ],
            "Experience": [
                "a",
                "n",
                "s",
                "3",
                "3",
                "3"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "Data engineer Palantir - H/F - Paris",
        "company": "Lojelis",
        "location": "Greater Paris Metropolitan Region",
        "link": "https://fr.linkedin.com/jobs/view/data-engineer-palantir-h-f-paris-at-lojelis-3901067276?position=5&pageNum=12&refId=RDfIAW6D%2Bq5WzkINrCwGag%3D%3D&trackingId=EUheVK8VM82DLRjEgxHx8g%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Pr\u00e9sentation de la soci\u00e9t\u00e9\nLojelis\nest n\u00e9 en 2005, d\u2019un projet entrepreneurial de Sylvain Jourdy, toujours \u00e0 la t\u00eate du groupe. Historiquement int\u00e9grateur de solutions ERP, lojelis a \u00e9volu\u00e9 au fil des ann\u00e9es dans un objectif d\u2019accompagnement des entreprises dans leurs probl\u00e9matiques technologiques et m\u00e9tiers.\nExperts en\nERP, D\u00e9veloppement, Business Intelligence, AMOA\net\nPMO,\nnous sommes 170 collaborateurs r\u00e9partis sur 6 agences en France. Nous conseillons nos clients sur tous les secteurs d\u2019activit\u00e9s et sans distinction de taille. Nos \u00e9quipes les accompagnent tout au long de leurs projets, de la conception \u00e0 la mise en production et au support.\nNous vous proposons donc de rejoindre une entreprise qui mise sur la proximit\u00e9 avec ses collaborateurs et o\u00f9 la cr\u00e9ativit\u00e9 et la prise d\u2019initiatives y sont fortement encourag\u00e9es.\nDescription des missions\nDans le cadre de divers projets en r\u00e9gion parisienne, nous recherchons un(e) Data Engineer maistrisant Palantir Foundry.\nLe contexte ?\nNous aidons nos clients dans leur transformation digitale.\nVotre r\u00f4le sera d'accompagner les utilisateurs m\u00e9tiers dans l'expression, la formalisation, l'analyse et la mod\u00e9lisation de leurs besoins SI, ainsi que dans le suivi des projets.\nVos missions ;\nConstruire, livrer et maintenir des produits de donn\u00e9es.\nTravailler avec les \u00e9quipes produits afin de d\u00e9velopper de nouvelles fonctionnalit\u00e9s.\nEtre responsable de la construction, de la livraison, de la maintenance et de la documentation d'artefacts de donn\u00e9es.\nConseiller sur l'architecture des flux de donn\u00e9es de bout en bout.\nProfil recherch\u00e9\nVotre profil ?\nApr\u00e8s 1 \u00e0 2 ans en tant que Data Engineer ou Data Scientist, vous d\u00e9sirez \u00e9voluer au sein d'un grand groupe afin de continuer \u00e0 d\u00e9velopper vos comp\u00e9tences.\nYou speak and write English in a professional environment\nVous maitrisez les technologies Python et SQL.\nVous avez d\u00e9j\u00e0 travaill\u00e9 sur l'outil Palantir Foundry.\nNous recherchons surtout une personne dot\u00e9e d'un bon relationnel qui appr\u00e9cie le travail en \u00e9quipe et sait se montrer force de proposition.\nLes petits +\nNous nous engageons \u00e0 \u00e9viter toute discrimination et \u00e0 traiter tous nos candidats de mani\u00e8re \u00e9quitable. C\u2019est pourquoi l\u2019ensemble de nos intervenants au processus de recrutement sont form\u00e9s au recrutement et \u00e0 la non-discrimination peu importe sa nature selon la loi applicable.\nNotre processus de recrutement ?\nEtude du CV\nEchange t\u00e9l\u00e9phonique pour faire connaissance\nUn entretien RH pour parler plus en d\u00e9tail de vos aspirations et de Lojelis\nUn entretien m\u00e9tier avec la manager du p\u00f4le AMOA\nPrise de d\u00e9cision et retour\nNotre processus d\u2019int\u00e9gration ?\nInformations transmises en amont de votre arriv\u00e9e : documentations, planning de votre premier jour, \u2026\nParcours d\u2019int\u00e9gration : pr\u00e9sentation de Lojelis, des locaux, des \u00e9quipes, des projets, des outils et process, formations au besoin, \u2026\nExemples de ce qu'il vous attend chez Lojelis\nQualit\u00e9 de vie au travail et RSE\nDes managers de p\u00f4le qui vous accompagnent au quotidien dans votre carri\u00e8re\nCarte titres restaurant Edenred : 8,80\u20ac par jour pris \u00e0 60% en charge par Lojelis\nMutuelle couvrant gratuitement les enfants\nRemboursement de 75% de l\u2019abonnement transports en commun\n10 jours de compensation/an d\u00e8s 6 mois d\u2019anciennet\u00e9\nPrime vacances (convention Syntec)\nPrimes de cooptation\n3 jours de t\u00e9l\u00e9travail possibles par semaine\nUn CSE offrant diff\u00e9rents avantages\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "R"
            ],
            "DataBase": [
                "SQL"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [],
            "DevTools": [
                "Git"
            ],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [],
            "FrSoftSkills": [
                "Cr\u00e9ativit\u00e9"
            ],
            "EnSoftSkils": [
                "Initiative"
            ]
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s",
                "2",
                "2",
                "2"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "Data Engineer",
        "company": "HarfangLab",
        "location": "Paris, \u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/data-engineer-at-harfanglab-3849760187?position=6&pageNum=12&refId=RDfIAW6D%2Bq5WzkINrCwGag%3D%3D&trackingId=ee2YG0IB53MykNwqdA7klQ%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Who we are?\nHarfangLab\nis a\ncybersecurity scale-up\n, and we have developed an\nEndpoint Detection and Response\n(EDR) software to\ndetect and mitigate modern cyberattacks\non a company's workstations and servers. Our algorithms detect abnormal behaviors and generate security alerts or block program execution.\nFrom 50 to 100 employees in 2023, HarfangLab is experiencing hypergrowth and has already achieved several significant milestones: winners of the Ministry of Defense's cyber challenge in 2019, recipients of the BPI's I-Nov competition in 2020, and software certified by ANSSI in 2021.\nOur initial clients include CAC40 industrial companies and government entities. We completed our\nfirst funding round of \u20ac5 million in 2021 and our second funding round of \u20ac25 millions in 2023\n, which will enable us to strengthen our teams, and to expand internationally in Europe.\nOur mission is to\nprotect businesses and government agencies from modern cybersecurity threats\n(cybercrime, data theft, influence)\nthat endanger the economic health of companies and the security of the nation\n.\nWhat you will do with us?\nYou will work within the\nArtificial Intelligence team\n, consisting of 5 individuals, under the direct and daily supervision of the team lead.\nThis team designs, implements, and deploys supervised algorithms for detecting malicious behavior.\nAs a\nData Engineer\nyou will:\nGather requirements from stakeholders,\nManage data for the AI and CTI departments,\nDesign, develop, and maintain the existing data warehouse,\nImplement a data lake if deemed appropriate,\nCreate data pipelines using ELT processes,\nDesign tools for data visualization.\nAbout You\nHard Skills\nMaster\u2019s degree in Computer Science, Engineering, or a related field,\nProven experience as a Data Engineer, 2 years minimum,\nProficient in Python,\nSQL: Strong in SQL syntax and query optimization, NoSQL will be a big plus,\nCompetence in data warehousing and data lake architecture,\nProficiency in at least one ELT tool and strong understanding of related processes.\nSoft Skills\nStrong communication and teamwork skills,\nExcellent problem-solving and attention to detail,\nYou enjoy learning and sharing your knowledge with others,\nYou demonstrate initiative - when an opportunity arises to improve existing processes, you seize it.\nAbout Us\nOur office and Team Life:\nOffices located in the heart of Paris, near Bourse (75002),\nHigh-quality equipment based on preferences and needs (PC, Mac, additional screens, etc.),\nThanks to our Office Manager, we regularly organize events such as seminars, happy hours, themed evenings, and more,\nAn onboarding process to welcome each new colleague with an explanation of the roles and a mentor to support you during your early days!\"\nA great team that always seeks to improve their skills\nAnd more:\nAn attractive package: Base salary + profit sharing,\nFlexible remote work options,\nA mentor to guide you throughout your probationary period,\nHealth insurance: The best health insurance with Alan and Moka Care, a mental health at work app,\nMeal vouchers: We use the Swile card and also have access to a discount platform through our works council,\n7 to 11 additional days off (RTT) per year, in addition to the 25 days of paid vacation. GymLib subscription, covered 80% by HarfangLab,\nAccess to training and events of your choice and according to your professional needs.\nThe recruitment process\nA 30-minutes call with our Talent Acquisition Manager,\nA 30-minutes visio interview with the Hiring Manager,\nA 1 hour on-site interview + 30 minutes with the team for a team fit assessment,\nA psychometric test to assess your motivations and soft skills,\nA final HR video appointment to review your soft skills and motivations.\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "R",
                "Go"
            ],
            "DataBase": [
                "SQL",
                "NoSQL"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [],
            "DevTools": [],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [
                "Teams"
            ],
            "Other": [
                "ML"
            ],
            "FrSoftSkills": [
                "Communication"
            ],
            "EnSoftSkils": [
                "Communication",
                "Teamwork",
                "Initiative"
            ]
        },
        "details": {
            "JobDetail": [
                "Remote"
            ],
            "TypeContract": [],
            "Salary": [
                "7",
                "7"
            ],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "Senior Data Engineer (H/F)",
        "company": "relevanC",
        "location": "Paris, \u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/senior-data-engineer-h-f-at-relevanc-3845776902?position=7&pageNum=12&refId=RDfIAW6D%2Bq5WzkINrCwGag%3D%3D&trackingId=%2BIBvHbhwTiBQPpKpHBIS8g%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "relevanC est une filiale du Groupe Casino et a \u00e9t\u00e9 fond\u00e9e en 2017.\nNous avons des bureaux en France, au Br\u00e9sil et en Colombie et op\u00e9rons \u00e0 l'\u00e9chelle mondiale.\nNos solutions de Retail Media permettent \u00e0 nos clients de g\u00e9n\u00e9rer de nouvelles sources de revenus publicitaires gr\u00e2ce \u00e0 des annonces pertinentes et personnalis\u00e9es.\nEn tant que Data Engineer tu auras acc\u00e8s aux donn\u00e9es de nos clients internes (enseignes du groupe Casino) et externes \u00e0 traiter au sein de notre data warehouse. Tes missions seront les suivantes :\ntravailler en \u00e9troite collaboration avec tous les autres membres de la squad\n\u00e9crire / relire du code en respectant les bonnes pratiques de d\u00e9veloppement ainsi que les tests unitaires et participer\nassurer la co-responsabilit\u00e9 du d\u00e9roulement des d\u00e9ploiements, des mises en production et du bon fonctionnement des applications avec les autres membres de la squad\nr\u00e9diger la documentation technique quand cela est n\u00e9cessaire\nmettre en \u0153uvre les bonnes pratiques relatives au RGPD telles que d\u00e9finies par le tech lead\nCe CDI bas\u00e9 \u00e0 Paris centre (1er arrondissement) d\u00e9butera d\u00e8s que possible.\nFaire partie de relevanC, qu\u2019est-ce que \u00e7a signifie ?\nTravailler sur une stack technologique de pointe (Python, PySpark, Google BigQuery, Apache, Airflow\u2026)\n\u00catre membre \u00e0 part enti\u00e8re d\u2019une \u00e9quipe dynamique et passionn\u00e9e aux profils tr\u00e8s vari\u00e9s (chefs de projets, d\u00e9veloppeurs, designers, animations commerciales)\nTravailler dans un environnement stimulant et relever des nouveaux d\u00e9fis chaque jour\nRejoindre une entreprise en pleine expansion avec des opportunit\u00e9s fortes de d\u00e9veloppements et d\u2019innovation\nProfil recherch\u00e9\nDipl\u00f4m\u00e9(e) d\u2019une grande \u00e9cole d\u2019ing\u00e9nieur ou profil universitaire sp\u00e9cialis\u00e9 en Data / Informatique / Math / Stats.\n5 ans (et plus) d\u2019exp\u00e9rience en Data Engineering\nApp\u00e9tence forte pour le marketing digital et le retail, force de proposition, business oriented et moteur d\u2019innovation\nUne maitrise parfaites des bonnes pratiques de d\u00e9veloppement\nSolides comp\u00e9tences en Python, Spark et SQL\nUne exp\u00e9rience sur Google Cloud Platform est un plus\nLien vers notre politique de traitement des donn\u00e9es : https://relevanc.com/fr/politique-de-protection-des-donn%C3%A9es-recrutemen\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "R",
                "Go"
            ],
            "DataBase": [
                "SQL"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [
                "Spark"
            ],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [
                "Google Cloud Platform"
            ],
            "DevTools": [
                "Git"
            ],
            "Os": [],
            "DBMS": [
                "BigQuery"
            ],
            "SoftBigDataProcessing": [],
            "Automation": [
                "Chef",
                "Airflow"
            ],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [
                "Cloud"
            ],
            "FrSoftSkills": [
                "Collaboration"
            ],
            "EnSoftSkils": [
                "Collaboration"
            ]
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [
                "CDI"
            ],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s",
                "5",
                "5",
                "5"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "Data engineer senior - PAU",
        "company": "Capgemini",
        "location": "Greater Pau Area",
        "link": "https://fr.linkedin.com/jobs/view/data-engineer-senior-pau-at-capgemini-3905823820?position=8&pageNum=12&refId=RDfIAW6D%2Bq5WzkINrCwGag%3D%3D&trackingId=l8ZlSgutdgTLQMyhKsDHJQ%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Capgemini :\nChoisir Capgemini, c\u2019est choisir une entreprise o\u00f9 vous serez en mesure de fa\u00e7onner votre carri\u00e8re selon vos aspirations. Avec le soutien et l\u2019inspiration d\u2019une communaut\u00e9 d\u2019experts dans le monde entier, vous pourrez r\u00e9\u00e9crire votre future.\nRejoignez nous pour red\u00e9finir les limites de ce qui est possible, contribuer \u00e0 lib\u00e9rer la valeur de la technologie pour les plus grandes organisations et participer \u00e0 la construction d\u2019un monde plus durable et inclusif.\nVos missions :\nAu sein d'une \u00e9quipe pluridisciplinaire, vos missions seront de :\nConcevoir, d\u00e9velopper et mod\u00e9liser des outils de traitement et visualisation de la donn\u00e9es\n: mettre en place des pipelines de collecte, stockage et transformation de la donn\u00e9es dans un contexte DevOps ; mettre en place des outils de nettoyage de la donn\u00e9es afin de la rendre accessible et exploitable aux Data analysts et Data scientists.\nIndustrialiser des solutions dans un contexte Cloud DevOps\n.\nCollaborer \u00e0 la strat\u00e9gie projet et au d\u00e9veloppement de l'offre port\u00e9e par Capgemini\n: se positionner comme expert dans votre domaine, apporter et concevoir des solutions innovantes garantissant \u00e0 nos clients comp\u00e9titivit\u00e9 et respect des normes li\u00e9es \u00e0 leur secteur d'activit\u00e9.\nAccompagner de jeunes d\u00e9veloppeuses et d\u00e9veloppeurs dans leur mont\u00e9e en comp\u00e9tence\n: apporter conseils techniques et retours d'exp\u00e9riences ; les faire b\u00e9n\u00e9ficier de vos savoirs et expertises ; les challenger en leurs proposant au quotidien un accompagnement qui leur permettra de sortir de leur zone de confort.\nParticiper \u00e0 la vie de l'\u00e9quipe data de Pau\n: proposer, organiser et assister aux \u00e9v\u00e9nements et ateliers.\nVotre profil :\nDipl\u00f4me en informatique, Data, Big Data ou \u00e9quivalent\nMinimum 4 ann\u00e9es d'exp\u00e9rience sur un poste similaire en ESN, client final ou cabinet\nAnglais courant\nMaitrise du langage de programmation Python (notamment Pandas)\nMaitrise des technologies Cloud (AWS, Azure ou GCP) et outils DevOps (Ansible, Kubernetes, Terraform\u2026)\nMaitrise des processus de mise en place de pipeline, gestion et traitement de la donn\u00e9e.\nAptitude d\u00e9montr\u00e9e \u00e0 travailler de mani\u00e8re autonome tout en collaborant efficacement au sein d\u2019une \u00e9quipe multidisciplinaire\nForte app\u00e9tence pour le challenge et l'innovation.\n3 raisons de nous rejoindre\n:\nQualit\u00e9 de vie au travail\n: accord de t\u00e9l\u00e9travail en France et \u00e0 l\u2019international, accord sur l\u2019\u00e9galit\u00e9 professionnelle, la parentalit\u00e9, l\u2019\u00e9quilibre des temps et la mobilit\u00e9 durable.\nApprentissage en continu\n: certifications et formations en libre acc\u00e8s, accompagnement sur mesure avec votre career manager, parcours d\u2019int\u00e9gration sur 9 mois.\nAvantages groupe & CSE\n: plan actionnariat, activit\u00e9s \u00e0 tarifs pr\u00e9f\u00e9rentiels, remboursement partiel vacances, remboursement de votre abonnement sportif ou culturel.\nNos engagements et priorit\u00e9s :\nLe groupe Capgemini encourage une culture inclusive dans un cadre multiculturel et handi-accueillant. En nous rejoignant, vous int\u00e9grez un collectif qui valorise la diversit\u00e9, d\u00e9veloppe le potentiel de ses talents, s\u2019engage dans des initiatives solidaires avec ses partenaires, et se mobilise pour r\u00e9duire son impact environnemental sur tous ses sites et aupr\u00e8s de ses clients.\nA propos de Capgemini :\nCapgemini est un leader mondial, responsable et multiculturel, regroupant pr\u00e8s de 350 000 personnes dans plus de 50 pays. Fort de 55 ans d\u2019exp\u00e9rience, nous sommes un partenaire strat\u00e9gique des entreprises pour la transformation de leurs activit\u00e9s en tirant profil de toute la puissance de la technologie et des innovations dans les domaines en perp\u00e9tuelle \u00e9volution tels que le cloud, la data, l\u2019Intelligence Artificielle, la connectivit\u00e9, les logiciels, l\u2019ing\u00e9nierie digitale ou les plateformes.\nGet The Future You Want* | www.capgemini.com/fr-fr\n*Capgemini, le futur que vous voulez\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "R"
            ],
            "DataBase": [],
            "DataAnalytics": [
                "Pandas",
                "R"
            ],
            "BigData": [],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [
                "AWS",
                "Azure"
            ],
            "DevTools": [
                "Git"
            ],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [
                "Ansible",
                "Kubernetes"
            ],
            "InfrastructureAsCode": [
                "Terraform"
            ],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [
                "Kubernetes"
            ],
            "Collaboration": [],
            "Other": [
                "DevOps",
                "Big Data",
                "Cloud"
            ],
            "FrSoftSkills": [
                "Organisation"
            ],
            "EnSoftSkils": [
                "Initiative"
            ]
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s",
                "55",
                "55",
                "55"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "Data Engineer (F/H) - en alternance",
        "company": "Carrefour",
        "location": "Massy, \u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/data-engineer-f-h-en-alternance-at-carrefour-3884390443?position=9&pageNum=12&refId=RDfIAW6D%2Bq5WzkINrCwGag%3D%3D&trackingId=j2jnbwpHUusdjaD5Xbcjaw%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Le saviez-vous ?\nNous rejoindre, c\u2019est rejoindre l\u2019un des leaders mondiaux de la distribution qui met l'accent au quotidien sur la diversit\u00e9, la RSE et le digital, pour satisfaire nos clients et nos collaborateurs. En tant que partenaire premium des Jeux Olympiques et Paralympiques de Paris 2024, nous partageons les valeurs du sport en permettant \u00e0 nos \u00e9quipes de se d\u00e9passer et encourageons une alimentation saine au juste prix pour tous.\nVous cherchez \u00e0 travailler dans une entreprise dynamique o\u00f9 votre travail rime avec impact social et environnemental ? Bienvenue chez nous !\nData Engineer (F/H) - en alternance\nEn tant qu' alternant, vous int\u00e9grerez la plateforme supply chain o\u00f9 vous serez amen\u00e9 \u00e0 appuyer le p\u00f4le pr\u00e9vision et optimisation particuli\u00e8rement sur des sujets data et d\u2019analyse de donn\u00e9es.\nAu sein d'une \u00e9quipe compos\u00e9e de data scientists et de data engineers organis\u00e9e en mode Scrum Agile, vous travaillerez pour am\u00e9liorer au quotidien un outil de calcul de pr\u00e9vision (pr\u00e9vision de la demande des entrep\u00f4ts Carrefour). Vous participez \u00e0 l'\u00e9volution fonctionnelle et technique de l'application.\n\ud83c\udfaf Les missions\nDans ce cadre, vous serez amen\u00e9 \u00e0\nExplorer et analyser les donn\u00e9es du datalake carrefour\nParticiper au cadrage des nouvelles fonctionnalit\u00e9s\nD\u00e9velopper les \u00e9volutions des traitements, des mod\u00e8les statistiques et de machine learning de pr\u00e9vision et des reporting\nTester les fonctionnalit\u00e9s d\u00e9velopp\u00e9es\nR\u00e9pondre aux demandes utilisateurs\n\ud83d\udc65 Profil\nVous \u00eates en \u00e9cole d\u2019ing\u00e9nieur, en master 2 ou \u00e9quivalent avec une sp\u00e9cialisation data science, data engineering, statistique, informatique.\nVous avez une exp\u00e9rience en traitement et analyse de donn\u00e9es.\nVous avez un esprit d\u2019analyse et la capacit\u00e9 de travailler en \u00e9quipe et \u00e0 distance.\nVous \u00eates autonome et rigoureux, fluide dans votre communication orale et \u00e9crite et \u00e0 l'\u00e9coute des besoins de vos interlocuteurs.\nVous \u00eates reconnu pour vos capacit\u00e9s d'anticipation, votre sens de l'initiative et votre r\u00e9activit\u00e9.\nVous avez une bonne connaissance des langages suivants\nSQL\nPython\nUne connaissance de GCP et de Big query serait un plus.\nUne connaissance m\u00eame th\u00e9orique de la m\u00e9thodologie agile serait un plus\nUne connaissance de GIT serait un plus.\nEncore plus de bonnes raisons de nous rejoindre\nInt\u00e9grer une \u00e9quipe conviviale \u00e0 taille humaine au sein d\u2018un grand groupe\n12 % de remise sur achat\n\ud83d\udcdd Informations compl\u00e9mentaires\nDate de d\u00e9but  09 septembre 2024\nDur\u00e9e  1 an\nLieu  Lyon\nD\u00e9placements en magasin et en concurrence dans la r\u00e9gion parisienne\nAvantages 50 % du titre de transport pris en charge par Carrefour\nEnvie de rejoindre l\u2019aventure ?\nChez Carrefour, nous avons \u00e0 c\u0153ur de ne passer \u00e0 c\u00f4t\u00e9 d\u2019aucun talent et sommes fiers de compter des \u00e9quipes repr\u00e9sentatives de la soci\u00e9t\u00e9 dans son ensemble. Nous encourageons ainsi tous types de profils \u00e0 postuler \u00e0 cette offre et garantissons un processus de recrutement d\u00e9nu\u00e9 de toutes formes de discriminations.\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "R",
                "Go"
            ],
            "DataBase": [
                "SQL"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [
                "Statistiques"
            ],
            "CloudComputing": [],
            "DevTools": [
                "Git"
            ],
            "Os": [],
            "DBMS": [
                "Big Query"
            ],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [
                "Machine Learning",
                "Statistiques"
            ],
            "FrSoftSkills": [
                "Communication"
            ],
            "EnSoftSkils": [
                "Communication",
                "Initiative"
            ]
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "Data Engineer +3 years xp",
        "company": "OntraaK",
        "location": "Paris, \u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/data-engineer-%2B3-years-xp-at-ontraak-3909457589?position=10&pageNum=12&refId=RDfIAW6D%2Bq5WzkINrCwGag%3D%3D&trackingId=pm1pYKxQsqU4o%2FAja6BOYg%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Company Description\nOntraaK is a start-up focused on operational excellence powered by advanced technologies such as process mining, intelligent process automation, and execution management systems. Our goal is to enable deep knowledge of real processes, identify inefficiencies, and automate processes at scale. We work with a pragmatic and flexible approach, maximizing value for our customers during proof of value or organization-wide implementation projects. Our team consists of data engineers, business and process experts, and managers who are certified on the most advanced solutions in the market.\nWe are looking for\n2 Experienced Data Engineers\n. You have 3 to 5 years in data engineering positions. You are passionate about playing with big set of datas from multiple sources. You love to improve complex situations with data driven decisions, to work in an innovative environment, and at the end of the day to transform all this in high valuable insights ? You love challenges and are ready to take off by developing your skills with a dynamic team ?\nLet\u2019s have a chat !\nAs a Data Explorer by OntraaK, you will deliver highly valuable data-driven insights through your data expertise. Our passion for solving complex and challenging problems four our customers is what is moving us every day. Your role as a Data Explorer is key to deliver this value !\nRole Description\nThis is a full-time data engineer role at OntraaK. As a data engineer, your day-to-day tasks will include data exploration, connecting source systems, data preparation, data modeling, and implementing data solutions. This is a hybrid role based in Paris, with the flexibility for some remote work.\nQualifications\nData Engineering, Data Modeling, and Extract Transform Load (ETL) skills\nData Warehousing and Data Analytics skills\nExperience in working with large and complex datasets\nProficiency in SQL and programming languages such as Python or Java\nStrong problem-solving and analytical skills\nExcellent communication and collaboration abilities\nBachelor's or Master's degree in Computer Science, Information Systems, or a related field\nExperience with process mining or intelligent process automation is a plus\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "Java",
                "R",
                "Go"
            ],
            "DataBase": [
                "SQL"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [],
            "DevTools": [],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [],
            "FrSoftSkills": [
                "Communication",
                "Collaboration"
            ],
            "EnSoftSkils": [
                "Communication",
                "Collaboration",
                "Organization",
                "Flexibility"
            ]
        },
        "details": {
            "JobDetail": [
                "Remote",
                "Full"
            ],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "Senior Data engineer (H/F)",
        "company": "Believe",
        "location": "Paris, \u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/senior-data-engineer-h-f-at-believe-3904676141?position=1&pageNum=15&refId=4Y4I0MAYAq8eeUJ%2FxaKDAA%3D%3D&trackingId=yWYK7VADP87Qgb%2BjxbIrEg%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Description De L'entreprise\nBelieve est avant tout une passion pour la musique, la technologie et le marketing num\u00e9rique, partag\u00e9e par plus de 1720 talents dans plus de 50 pays. C'est un esprit visionnaire et entrepreneurial qui nous anime et fait de nous un leader mondial de la distribution num\u00e9rique de musique.\nBelieve est une tribu d'experts qui rel\u00e8ve avec succ\u00e8s les d\u00e9fis de la transformation de notre industrie musicale au quotidien. C\u2019est une aventure, une aventure humaine, propice et stimulante pour nous tous.\nEnfin, Believe est une histoire qui a d\u00e9but\u00e9 en 2005 et que nous devons continuer \u00e0 raconter, maintenant et avec vous. Believe a pour mission de d\u00e9velopper les labels et les artistes de mani\u00e8re adapt\u00e9e \u00e0 chaque stade de leur carri\u00e8re ; dans tous les march\u00e9s locaux dans le monde ; avec respect, expertise, \u00e9quit\u00e9 et transparence.\nwww.believe.com\nReady to #setthetone with Believe?\nDescription Du Poste\nContexte\nVous int\u00e9grez la Tribu Data Office de Believe et la squad Dataplateforme en tant que Data engineer.\nLa Dataplateforme s'appuie sur une stack AWS / Snowflake avec des pratiques \u00e0 l'\u00e9tat de l'art en data engineering et data mod\u00e9lisation, et des contraintes de fort volume et haute performance.\nAu Sein De La Squad Organis\u00e9e Selon La Pratique Scrum, En Charge Du Build Et Du Run De Son P\u00e9rim\u00e8tre, Vous Aurez Pour Responsabilit\u00e9 D'impl\u00e9menter Les Flux De Donn\u00e9es Depuis L'ingestion Des Nouvelles Sources Jusqu'\u00e0 Leur Pr\u00e9paration Pour Exposition Au Travers Des Niveaux Bronze, Silver Et Gold (warehouse) Vous Maitrisez Ainsi\nLa conception et le d\u00e9veloppement d'un pipeline d'ingestion sur AWS (Step function / python / S3) La transformation de donn\u00e9es (Python, Spark Scala / Databricks, SQL) Les pratiques de test (TU Python, TU Spark Scala) La mod\u00e9lisation Data en flocons Les pratiques de run (surveillance, monitoring, fix) La r\u00e9daction de la documentation (Data galaxy / Confluence) Les enjeux de performances, de suivi des couts et de s\u00e9curit\u00e9\nQualifications\nPourquoi nous rejoindre ? Chez believe, notre leitmotiv est simple : ouverture d\u2019esprit, passion et implication ! On appr\u00e9ciera aussi votre agilit\u00e9, votre sens de l\u2019innovation, votre excellent relationnel et votre enthousiasme !\nVous \u00eates de niveau BAC+3 \u00e0 BAC+5 (\u00c9coles d'ing\u00e9nieurs, BTS, DUT, DESS, Mast\u00e8re).\nVous justifiez d\u2019une exp\u00e9rience significative (au moins 3 ans) dans les technologies de notre stack: AWS, Snowflake, python, spark scala, SQL.\nL'esprit Craft est une \u00e9vidence.\nVous \u00eates convaincu de l\u2019importance de la donn\u00e9e, et pensez qu\u2019elle est \u00e0 mettre en regard des besoins m\u00e9tiers. Bref, vous aimez la donn\u00e9e et \u00eates pragmatique.\nVous aimez vous tenir au courant des nouvelles \u00e9volutions technologiques, et pratiquez une veille r\u00e9guli\u00e8re.\nVotre niveau d\u2019anglais est courant, \u00e0 l\u2019oral comme \u00e0 l\u2019\u00e9crit.\nInformations suppl\u00e9mentaires\nSet the tone with us\nChez Believe, nous avons deux c\u0153urs : nos collaborateurs et nos artistes.\nNous croyons en la force de nos collaborateurs, qui s'\u00e9panouissent chaque jour en d\u00e9veloppant leur potentiel... Notre objectif est d'offrir \u00e0 nos collaborateurs le meilleur environnement possible pour qu'ils puissent s'\u00e9panouir.\nRock the job\nProgramme de formation et de coaching sur mesure\nUne politique de t\u00e9l\u00e9travail\nUn programme de bien-\u00eatre \"Pauses\" avec de nombreuses activit\u00e9s et animations en interne\nAcc\u00e8s \u00e0 Eutelmed, la plateforme num\u00e9rique de sant\u00e9 mentale et de bien-\u00eatre qui permet de parler \u00e0 un psychologue exp\u00e9riment\u00e9\nUn restaurant d'entreprise sain et \u00e9co-responsable\nUne assurance sant\u00e9 individuelle ou familiale\nAvantages CE\nUn rooftop\nUne salle de sport avec des cours gratuits\nSing in harmony\nDes groupes d'ambassadeurs pour s'engager sur la r\u00e9duction de l'empreinte carbone et environnementale de Believe et l\u2019\u00e9quit\u00e9 professionnelle Femme/Homme.\nMise en place du Forfait mobilit\u00e9 durable: remboursement jusqu\u2019\u00e0 600\u20ac des frais de transport en commun/avec une faible empreinte carbone.\nCong\u00e9 2nd parent de 5 jours calendaires r\u00e9mun\u00e9r\u00e9s \u00e0 100% (en plus du cong\u00e9 l\u00e9gal paternit\u00e9 ou du cong\u00e9 d\u2019adoption, nous ne l\u2019attribuons pas au cong\u00e9 maternit\u00e9)\nBelieve s\u2019engage \u00e0 garantir l\u2019\u00e9galit\u00e9 des chances en mati\u00e8re d\u2019emploi, sans tenir compte de l\u2019origine, du sexe, des m\u0153urs, de l\u2019orientation sexuelle, du genre, de l\u2019\u00e2ge, de la situation de famille, de l\u2019\u00e9tat de grossesse, d\u2019une pr\u00e9tendue race, des opinions politiques, des activit\u00e9s syndicales, des convictions religieuses, de l\u2019apparence physique, du nom de famille, du lieu de r\u00e9sidence, de l\u2019\u00e9tat de sant\u00e9, ou en situation de handicap.\nD\u00e9couvrez nos nouveaux locaux : bit.ly/believeoffice\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "Scala",
                "R",
                "Go"
            ],
            "DataBase": [
                "SQL"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [
                "Spark",
                "Databricks"
            ],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [
                "AWS"
            ],
            "DevTools": [],
            "Os": [],
            "DBMS": [
                "Snowflake",
                "Snowflake"
            ],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [
                "Confluence"
            ],
            "Other": [],
            "FrSoftSkills": [],
            "EnSoftSkils": []
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [],
            "Salary": [],
            "Level": [
                "Bac+5",
                "Bac+3"
            ],
            "Experience": [
                "a",
                "n",
                "s",
                "3",
                "3",
                "3"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "Data Engineer F/H - Syst\u00e8me, r\u00e9seaux, donn\u00e9es (H/F)",
        "company": "UpMan Consulting",
        "location": "Lille, Hauts-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/data-engineer-f-h-syst%C3%A8me-r%C3%A9seaux-donn%C3%A9es-h-f-at-upman-consulting-3901572843?position=2&pageNum=15&refId=4Y4I0MAYAq8eeUJ%2FxaKDAA%3D%3D&trackingId=ZKfIreukuM7MAeHx18f0CA%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Cette offre d\u2019emploi est fournie par P\u00f4le emploi\nDescription\nDescriptif du poste: C est maintenant l occasion pour toi de rejoindre UpMan Consulting Notre ambition est de trouver les meilleurs profils Data Engineer pour intervenir chez nos clients grands comptes de la m\u00e9tropole lilloise. On te propose une exp\u00e9rience professionnelle en ad\u00e9quation avec ce que tu souhaites r\u00e9ellement. Tu d\u00e9couvriras une ambiance de travail saine & bienveillante, tu participeras activement au d\u00e9veloppement d une Happy StartUp, actuellement en forte croissance. O\u00f9 convivialit\u00e9 rime avec efficacit\u00e9 & o\u00f9 ta performance individuelle contribue \u00e0 notre r\u00e9ussite globale. Tes missions / comp\u00e9tences techniques Si tu l acceptes, ton r\u00f4le & tes missions seront les suivantes : * R\u00e9aliser le processus d int\u00e9gration de nouvelles donn\u00e9es (r\u00e9flexion sur la solution, mise en place d ETL, r\u00e8gles de nettoyage, anonymisation ) * \u00catre garant de l'acc\u00e8s aux sources de donn\u00e9es. * Ma\u00eetrise de la donn\u00e9e et \u00eatre le garant de sa qualit\u00e9 (r\u00e9f\u00e9rencement, normalisation et qualification) afin d'en faciliter l'exploitation par les \u00e9quipes (Data Analysts et Data Scientists). * Ma\u00eetrise de technologies Big Data et Cloud : Hadoop, Spark * Assurer la supervision et l'int\u00e9gration de donn\u00e9es structur\u00e9es et non structur\u00e9es venant de sources multiples, tout en veillant \u00e0 garder des donn\u00e9es de qualit\u00e9. * Assurer le suivi, la cartographie et la documentation des donn\u00e9es int\u00e9gr\u00e9es * Afin de garantir une bonne ex\u00e9cution de ta mission, nous recherchons les comp\u00e9tences techniques suivantes : Langages de programmation : * SQL * Python / Pyspark * Java/Scala (plus rare, mais important) Diff\u00e9rents types d ETL & orchestrateurs : * Airflow * Dagster * Prefect * SSIS/informatica * Talend Plateformes cloud : * GCP * Microsoft Azure * AWS Base de donn\u00e9es relationnelles & NoSQL : * postgreSQL, MySQL,... * Redis, graphDB * Data warehouse/data transform : * Snowflake, Bigquery (tr\u00e8s important) * DBT Qualit\u00e9 & comp\u00e9tences n\u00e9cessaires * Communiquant.e dans l \u00e2me * Avoir une bonne capacit\u00e9 de synth\u00e8se & l esprit critique * Travail d \u00e9quipe * Curiosit\u00e9 aigu\u00eb * Comprendre les objectifs & les besoins Nice to have * Anglais courant * Connaissance de la m\u00e9thodologie DevOps * Notions en Data-science The office Pas de full remote (pour l instant) mais de l hybride dans la plupart des missions. En moyenne, 2 jours de t\u00e9l\u00e9travail par semaine. Cependant, les portes de nos bureaux \u00e0 Wambrechies sont toujours ouvertes pour accueillir nos collaborateurs pendant leurs journ\u00e9es de t\u00e9l\u00e9travail & passer une bonne journ\u00e9e tous ensemble ! Le salaire Junior : 30K \u00e0 36K Ma\u00eetrisant : 37K \u00e0 43K Expert : 44K \u00e0 50K & plus + notre package avantage Profil recherch\u00e9: Ton Profil Tu es une personne passionn\u00e9e & passionnante. Tu as envie d'\u00e9voluer, de partager, de participer \u00e0 une mission collective & d\u00e9couvrir LA nouvelle fa\u00e7on de collaborer avec une ESN made in Lille. Tu peux justifier d'une exp\u00e9rience forte & significative en tant que Tech Lead Java, dans le d\u00e9veloppement Java ! Pas besoin d'avoir trop ou pas assez de dipl\u00f4mes, chez nous, ce sont les comp\u00e9tences qui priment \u202f! On se rencontre, on discute, on \u00e9change sur tes envies professionnelles & on laisse la magie op\u00e9rer. L'envie de grandir & de monter en comp\u00e9tences est ton moteur au quotidien. Tu aimes les probl\u00e9matiques complexes et les d\u00e9fis technologiques. On dit de toi que tu es un.e agiliste dans l'\u00e2me, qui effectue une veille constante, \u00e0 l'aff\u00fbt de tout ce qui \u00e9volue autour de toi... Ne r\u00e9fl\u00e9chis plus, saute le pas & d\u00e9couvre UpMan Consulting, tu ne seras pas d\u00e9\u00e7u. Tu balances ta d\u00e9mission ?\nPROFIL SOUHAIT\u00c9\nExp\u00e9rience\nExp\u00e9rience exig\u00e9e de 1 An(s)\nSource: Pole emploi (https://www.pole-emploi.fr)\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "Java",
                "Scala",
                "R"
            ],
            "DataBase": [
                "SQL",
                "NoSQL"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [
                "Hadoop",
                "Spark"
            ],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [
                "AWS",
                "Azure"
            ],
            "DevTools": [],
            "Os": [],
            "DBMS": [
                "MySQL",
                "PostgreSQL",
                "Snowflake",
                "Snowflake",
                "BigQuery"
            ],
            "SoftBigDataProcessing": [],
            "Automation": [
                "Airflow"
            ],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [
                "DevOps",
                "Big Data",
                "Cloud"
            ],
            "FrSoftSkills": [],
            "EnSoftSkils": []
        },
        "details": {
            "JobDetail": [
                "Hybride",
                "Remote",
                "Full",
                "Junior"
            ],
            "TypeContract": [],
            "Salary": [
                "30K",
                "1"
            ],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "Consultant Data Engineer F/H",
        "company": "SOFTEAM",
        "location": "\u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/consultant-data-engineer-f-h-at-softeam-3839971789?position=3&pageNum=15&refId=4Y4I0MAYAq8eeUJ%2FxaKDAA%3D%3D&trackingId=vE0RySd%2Bbfx6mGbdJZuJRg%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Vous \u00e9voluez dans le domaine de la Data et souhaitez int\u00e9grer\nun leader de la transformation num\u00e9rique sp\u00e9cialis\u00e9 dans les secteurs de la Banque-Finance-Assurance ?\nRejoignez notre communaut\u00e9 et d\u00e9veloppez vos comp\u00e9tences chez\nSOFTEAM DATA !\nVOTRE MISSION\nPour le compte d'un client grand compte, vos missions seront :\nA\ncomprendre le besoin\nde nos clients au travers de missions de type : aide aux choix d\u2019outils, cadrage des besoins, POC ;\nRecueillir et analyser les besoins et proposer une architecture technique\nadapt\u00e9e aux cas d\u2019usage des clients ;\nConduire des projets de\nd\u00e9ploiement des Modern Data Platform\n(Applications Cloud Native, Migration d\u2019applications existantes) et participer \u00e0 la mise en \u0153uvre\nFournir une expertise technique approfondie\naux \u00e9quipes projets\nR\u00e9diger la documentation permettant \u00e0 l'IT d'assurer la maintenance ;\nVOTRE PROFIL\nVos\ncomp\u00e9tentes techniques\n:\nVous avez un minimum de\n3\nann\u00e9es d\u2019exp\u00e9rience sur des\nprojets Data sur les outils ETL\n(Talend, SQL Server) et\nReporting\n(Power BI, Tableau Software).\nId\u00e9alement au moins une premi\u00e8re exp\u00e9rience sur des projets\nCloud AWS ou Azure ou GCP\n.\nVous avez une grande aisance dans la\ncommunication orale et \u00e9crite\nalli\u00e9e \u00e0 un esprit de synth\u00e8se, de la rigueur et un tr\u00e8s bon sens de la formalisation\nFournir une expertise technique\napprofondie aux \u00e9quipes projets\nR\u00e9aliser une veille technologique\npermanente sur les tendances du march\u00e9 et les perspectives concurrentielles\nVos\natouts\n:\nVous \u00eates dipl\u00f4m\u00e9 d\u2019une formation Bac+5 en informatique ;\nVous avez des comp\u00e9tences approfondies dans un ou plusieurs de ces domaines : Op\u00e9rations / Gestion des syst\u00e8mes, Conception ou d\u00e9veloppement de logiciels, Processus DevOps et outillage, Strat\u00e9gie d'entreprise, Infrastructure Cloud (virtualisation, mise en r\u00e9seau, stockage, base de donn\u00e9es), S\u00e9curit\u00e9 et conformit\u00e9 ;\nVous souhaitez vous impliquer dans le d\u00e9veloppement d\u2019\u00e9quipes et de communaut\u00e9s techniques autour du Cloud et des solutions Data\nVos exp\u00e9riences pass\u00e9es vous ont amen\u00e9 \u00e0 mettre en avant votre capacit\u00e9 \u00e0 int\u00e9grer des probl\u00e9matiques fonctionnelles complexes, comprendre les enjeux m\u00e9tiers, analyser les risques et \u00eatre force de propositions,\nEnfin, on vous appr\u00e9cie pour vos qualit\u00e9s de communication, de r\u00e9daction et votre bon relationnel\u2026and a good level of english would be a definite asset !\nNOUS VOUS OFFRONS\nDes missions engageantes aupr\u00e8s des grands acteurs du march\u00e9.\nUn management de proximit\u00e9, \u00e0 l\u2019\u00e9coute et bienveillant.\nLa possibilit\u00e9 d\u2019\u00e9voluer dans chacune des facettes des m\u00e9tiers de l\u2019IT !\nQUI SOMMES NOUS ?\nSofteam Data est le d\u00e9partement de Softeam, marque de Docaposte, sp\u00e9cialis\u00e9 dans les diff\u00e9rents domaines de la Data (Hadoop et Cloud) et de l\u2019informatique d\u00e9cisionnelle. Nous apportons notre expertise \u00e0 nos clients, principalement des grands comptes de la place financi\u00e8re fran\u00e7aise, dans des projets de transformation digitale et cognitive.\nPlus de 1650 Softeamien.nes sont d\u00e9di\u00e9.es \u00e0 la transformation m\u00e9tier et digitale de nos clients et ont g\u00e9n\u00e9r\u00e9 191 M\u20ac de chiffre d\u2019affaires en 2019.\nSOFTEAM est labellis\u00e9 Happy At Work !\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "R",
                "Go"
            ],
            "DataBase": [
                "SQL"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [
                "Hadoop"
            ],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [
                "Tableau",
                "Power BI"
            ],
            "Statistics": [],
            "CloudComputing": [
                "AWS",
                "Azure"
            ],
            "DevTools": [
                "Git"
            ],
            "Os": [],
            "DBMS": [
                "SQL Server"
            ],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [
                "DevOps",
                "Cloud"
            ],
            "FrSoftSkills": [
                "Communication"
            ],
            "EnSoftSkils": [
                "Communication"
            ]
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [],
            "Salary": [],
            "Level": [
                "Bac+5"
            ],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "Data Engineer",
        "company": "MindPal",
        "location": "Toulouse, Occitanie, France",
        "link": "https://fr.linkedin.com/jobs/view/data-engineer-at-mindpal-3914438789?position=4&pageNum=15&refId=4Y4I0MAYAq8eeUJ%2FxaKDAA%3D%3D&trackingId=tzbXTPpYKqPNK%2FnKPcV6Lw%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "We are looking for\nData Engineer!\nResponsibilities\nDesigning, creating, and maintaining data processing systems\nAnalyzing and optimizing data processing workflows\nCollaborating with the team to ensure data quality and efficiency\nTesting and implementing new solutions\nRequirements\nAt least 2 years of experience in designing and creating data processing systems\nProficiency in tools and programming languages related to data engineering (e.g. Hadoop, Spark, Scala, Python)\nExcellent knowledge of databases and SQL language\nAbility to work in a team and communicate effectively with other departments\nCommunicative English skills\nExperience with AWS/AWS Glue is a plus\nWe Offer\nB2B contract\nFull-time job\nRemote work and flexible hours\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "Scala",
                "R"
            ],
            "DataBase": [
                "SQL"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [
                "Hadoop",
                "Spark"
            ],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [
                "AWS"
            ],
            "DevTools": [],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [],
            "FrSoftSkills": [],
            "EnSoftSkils": []
        },
        "details": {
            "JobDetail": [
                "Remote",
                "Full"
            ],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "Data Engineer",
        "company": "MindPal",
        "location": "Toulouse, Occitanie, France",
        "link": "https://fr.linkedin.com/jobs/view/data-engineer-at-mindpal-3896997018?position=5&pageNum=15&refId=4Y4I0MAYAq8eeUJ%2FxaKDAA%3D%3D&trackingId=%2Fub5oFSbqtnXh5AwV%2Fm5NQ%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "We are looking for\nData Engineer!\nResponsibilities\nDesigning, creating, and maintaining data processing systems\nAnalyzing and optimizing data processing workflows\nCollaborating with the team to ensure data quality and efficiency\nTesting and implementing new solutions\nRequirements\nAt least 2 years of experience in designing and creating data processing systems\nProficiency in tools and programming languages related to data engineering (e.g. Hadoop, Spark, Scala, Python)\nExcellent knowledge of databases and SQL language\nAbility to work in a team and communicate effectively with other departments\nCommunicative English skills\nExperience with AWS/AWS Glue is a plus\nWe Offer\nB2B contract\nFull-time job\nRemote work and flexible hours\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "Scala",
                "R"
            ],
            "DataBase": [
                "SQL"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [
                "Hadoop",
                "Spark"
            ],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [
                "AWS"
            ],
            "DevTools": [],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [],
            "FrSoftSkills": [],
            "EnSoftSkils": []
        },
        "details": {
            "JobDetail": [
                "Remote",
                "Full"
            ],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "Data Engineer PySpark Senior H/F",
        "company": "DELANE SI",
        "location": "Boulogne-Billancourt, \u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/data-engineer-pyspark-senior-h-f-at-delane-si-3907364439?position=6&pageNum=15&refId=4Y4I0MAYAq8eeUJ%2FxaKDAA%3D%3D&trackingId=uezP%2FZfGmiHzY1ZvRTUyGA%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "DELANE SI\nest une soci\u00e9t\u00e9 de conseil et de services, une ESN, intervenant sur des projets \u00e0 forte valeur ajout\u00e9e aupr\u00e8s de clients grands comptes des secteurs Banque, Assurance et Finance de March\u00e9.\nNos engagements ?\n\u00catre \u00e0 votre\n\u00e9coute\n, afin de rapidement comprendre vos attentes et objectifs.\nEchanger en toute\ntransparence\nafin d\u2019engager un partenariat durable avec vous.\nEt enfin, la\nr\u00e9activit\u00e9\nqui nous permet de r\u00e9pondre \u00e0 vos attentes dans les meilleurs d\u00e9lais.\nVous cherchez \u00e0\nbooster votre carri\u00e8re\n? Vous cherchez un\nnouveau d\u00e9fi\ndans une structure en pleine \u00e9volution ?\nDe notre c\u00f4t\u00e9, nous cherchons\nun tout\n: un parcours, une exp\u00e9rience, mais avant tout ... une personnalit\u00e9 !\nRejoignez-nous !\nDans le cadre d\u2019un projet d\u2019envergure chez l\u2019un de nos clients grands comptes, nous cherchons notre futur\nData Engineer PySpark Senior\nqui sera en charge des missions suivantes :\nPasser de la donn\u00e9e brute \u00e0 de la donn\u00e9e exploitable, expos\u00e9e sous forme de tables requ\u00eatables ;\nConsolider ces donn\u00e9es au fur et \u00e0 mesure de leur alimentation r\u00e9currente ;\nAccompagner les Data Engineer sur son p\u00e9rim\u00e8tre pour garantir la qualit\u00e9 des livrables.\nIssu d'une formation de Bac+5, vous justifiez d'une premi\u00e8re exp\u00e9rience d'au moins 6 ans sur un poste de Data.\nVous justifiez d'une exp\u00e9rience dans le domaine de l\u2019assurance.\nVous avez des connaissances avanc\u00e9es en d\u00e9veloppement en Spark et id\u00e9alement PySpark.\nConnaissances requises sur les outils de BI comme Power BI.\nUne exp\u00e9rience professionnelle avec des outils comme Azure Databricks, Azure Data Lake Storage ou encore Azure Data Factory.\nR\u00e9mun\u00e9ration envisag\u00e9e :\n50-55K\nUn anglais courant est exig\u00e9.\nConform\u00e9ment \u00e0 la r\u00e8glementation en vigueur et \u00e0 notre politique d\u2019\u00e9galit\u00e9 professionnelle et de diversit\u00e9 ; nous encourageons tous les talents \u00e0 postuler, ind\u00e9pendamment de leur origine, identit\u00e9, \u00e2ge, handicap ou de leurs caract\u00e9ristiques personnelles.\nUn processus de recrutement\nsimple et rapide\n:\nUn premier entretien avec un(e) de nos charg\u00e9(e)s de Recrutement, nos experts m\u00e9tiers, qui seront amen\u00e9 \u00e0 en savoir plus sur\nvous et votre parcours\nafin de pouvoir vous pr\u00e9senter \u00e0\nl\u2019ensemble\nde nos ing\u00e9nieurs d\u2019affaires ;\nUn second entretien avec un ou plusieurs ing\u00e9nieur(s) d\u2019affaires afin de pouvoir vous\npr\u00e9senter une ou plusieurs missions\n;\nUn dernier entretien avec notre client dans le cadre d\u2019une derni\u00e8re validation.\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "R"
            ],
            "DataBase": [],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [
                "Spark",
                "Databricks"
            ],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [
                "Power BI"
            ],
            "Statistics": [],
            "CloudComputing": [
                "Azure"
            ],
            "DevTools": [],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [],
            "FrSoftSkills": [],
            "EnSoftSkils": []
        },
        "details": {
            "JobDetail": [
                "Senior"
            ],
            "TypeContract": [],
            "Salary": [],
            "Level": [
                "Bac+5"
            ],
            "Experience": [
                "a",
                "n",
                "s",
                "6",
                "6",
                "6"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "Data engineer - A\u00e9ronautique, Spatial et D\u00e9fense",
        "company": "MP DATA",
        "location": "\u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/data-engineer-a%C3%A9ronautique-spatial-et-d%C3%A9fense-at-mp-data-3731603307?position=7&pageNum=15&refId=4Y4I0MAYAq8eeUJ%2FxaKDAA%3D%3D&trackingId=uXhP2MeXYg5mj9%2BVe8QIRg%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "MP DATA recrute\nun(e) Data Engineer (H/F).\nDans le cadre de la transformation digitale industrielle, l\u2019\u00e9quipe de data engineering en charge de l\u2019exploitation du Cluster Big Data cherche \u00e0 se d\u00e9velopper : afin de r\u00e9pondre aux attentes des d\u00e9partements op\u00e9rationnels en termes de :\nValorisation et d'exploitation des donn\u00e9es de l'entreprise\nD\u00e9ploiement des outils de traitement de donn\u00e9es pour une utilisation industrielle.\nLe Data Engineer doit faire l'interface entre plusieurs services :\nL'infrastructure hardware du Cluster,\nLes Data Architect,\nLes Data Scientists.\nIl doit \u00eatre capable de comprendre les contraintes industrielles li\u00e9es \u00e0 chaque :\nUse-case d'exploitation des donn\u00e9es,\nLes contraintes et les algorithmes propos\u00e9s par les Data Scientists,\nProposer des solutions robustes d\u2019impl\u00e9mentation des traitements d\u2019ingestion ou de transformation de donn\u00e9es dans les \u00e9cosyst\u00e8mes Big Data.\nTa mission (si tu l'acceptes) :\nEn tant que membre du service DATA au sein du d\u00e9partement Data Intelligence, le Data Ing\u00e9nieur est un acteur cl\u00e9 dans le traitement et la mise \u00e0 disposition des donn\u00e9es au sein de l\u2019entreprise. Il sera en particulier impliqu\u00e9 dans les missions suivantes :\nConception et d\u00e9veloppement de solutions permettant la collecte, l\u2019organisation, le stockage et la mod\u00e9lisation des donn\u00e9es. Ceux-ci doivent \u00eatre suffisamment s\u00e9curis\u00e9s et lisibles pour les Data Analysts et Data Scientists,\nAssurer l\u2019acc\u00e8s aux diff\u00e9rentes sources de donn\u00e9es, et veiller \u00e0 la qualit\u00e9 des donn\u00e9es,\nDonner un acc\u00e8s facilit\u00e9 aux Data Analysts et Data Scientists afin exploiter les donn\u00e9es dans des conditions optimales,\nMise \u00e0 jour permanente sur les technologies et les langages utilis\u00e9s dans le but de partager ses connaissances et aider \u00e0 l\u2019avancement des projets,\nContribution, sous la responsabilit\u00e9 op\u00e9rationnelle de notre Architecte, aux meilleures pratiques, normes, politiques, m\u00e9thodes, outils et proc\u00e9dures sur le Cluster Big Data,\nIl est contributeur de la mise en place d\u2019une politique de donn\u00e9es respectueuse des r\u00e9glementations en vigueur.\nProfil recherch\u00e9 :\nIng\u00e9nieur issu d\u2019une grande \u00e9cole, vous avez des connaissances en mod\u00e9lisation et machine learning (deep learning, random forest, svm\u2026). Acquises lors de votre scolarit\u00e9 ou de vos exp\u00e9riences pass\u00e9es (stage ou c\u00e9sure).\nVous avez de bonnes connaissances en Python pour coder ces algorithmes.\nSuite \u00e0 votre cursus ing\u00e9nieur ou vos exp\u00e9riences professionnelles, vous avez des app\u00e9tences m\u00e9tiers dans les domaines de l\u2019a\u00e9ronautique, spatial, d\u00e9fense etc.\nVous \u00eates reconnu(e) pour votre autonomie, votre excellent relationnel et votre capacit\u00e9 \u00e0 \u00eatre force de proposition.\nVous \u00eates int\u00e9ress\u00e9 pour vous d\u00e9passer en data science & data engineering et vous avez une premi\u00e8re exp\u00e9rience dans ce domaine, comme :\nC/C++ / Java / Rust\nSpark / PySpark\nKafka\nCloud : AWS / GCP / Azure\nTechnologies de stockage : Snowflake / S3 / GCS / Azure Blob\nDjango / Flask\nGit Lab\nSQL : Postgres / MongoDB\nCI/CD\nD\u00e9roulement des entretiens :\nC\u2019est tr\u00e8s simple :\n1. Pr\u00e9qualification t\u00e9l\u00e9phonique de 5 min avec un membre de l'\u00e9quipe,\n2. Second \u00e9change de 30 min (Visio / Physique) avec un Manager pour faire connaissance,\n3. R\u00e9alisation d'un Test Technique,\n4. \u00c9change avec la Direction Technique\n5. Bienvenue dans la Team\nAvantages\n\u24c2\ufe0f Remboursement 50 % de ton titre de transport\n\ud83c\udfe5 Mutuelle H\u00e9lium\n\ud83d\udcb3 Carte Edenred\n\u2600\ufe0f Des \u00e9v\u00e8nements et Team Building\n\ud83c\udf6c Candy bar\n\ud83d\ude0e Terrasse plein sud\nPour te faire une id\u00e9e sur MP DATA, je t'invite \u00e0 regarder notre site et nos vid\u00e9os sur Welcome to the jungle.\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "Java",
                "C++",
                "R",
                "Go"
            ],
            "DataBase": [
                "SQL",
                " MongoDB"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [
                "Spark"
            ],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [
                "AWS",
                "Azure"
            ],
            "DevTools": [
                "Git"
            ],
            "Os": [],
            "DBMS": [
                "Snowflake",
                "Snowflake"
            ],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [
                "Big Data",
                "Machine Learning",
                "Cloud",
                "CI/CD"
            ],
            "FrSoftSkills": [
                "Organisation"
            ],
            "EnSoftSkils": []
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "Data Engineer DevOps H/F",
        "company": "Inetum",
        "location": "Courbevoie, \u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/data-engineer-devops-h-f-at-inetum-3843956952?position=8&pageNum=15&refId=4Y4I0MAYAq8eeUJ%2FxaKDAA%3D%3D&trackingId=7MW%2B24OTCIqkGbxkfdoiXw%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "D\u00e9tail de l'offre\nInformations g\u00e9n\u00e9rales\nEntit\u00e9 de rattachement\nNous sommes une ESN agile, un groupe international certifi\u00e9 Top Employer Europe 2024.\nA l'\u00e8re de la post-transformation digitale, nous mettons tout en \u0153uvre pour que chacun de nos 28 000 athl\u00e8tes du digital puisse se renouveler perp\u00e9tuellement, en vivant positivement son propre flow digital.\nChacun de nos talents peut ainsi fa\u00e7onner son parcours de carri\u00e8re selon ses app\u00e9tences, entreprendre de mani\u00e8re pragmatique avec ses clients pour un monde \u00e0 impact positif, innover localement dans 27 pays et harmoniser son investissement professionnel et son bien-\u00eatre personnel.\nRejoignez Inetum. Live your positive digital flow.\nTous nos postes sont ouverts aux personnes en situation de handicap.\nDescription du poste\nM\u00e9tier\nConseil et Int\u00e9gration - Business Consulting\nIntitul\u00e9 du poste\nData Engineer DevOps H/F\nContrat\nCDI\nDescription De La Mission\nQui sommes-nous ?\nNous sommes une ESN agile et un groupe international. A l'\u00e8re de la post-transformation digitale, nous mettons tout en \u0153uvre pour que chacun de nos 27 000 collaborateurs puisse se renouveler perp\u00e9tuellement, en vivant positivement son propre flow digital. Chacun d'entre eux peut ainsi fa\u00e7onner son parcours de carri\u00e8re selon ses app\u00e9tences, entreprendre de mani\u00e8re pragmatique avec ses clients pour un monde plus positif, innover localement dans 26 pays et harmoniser son investissement professionnel et son bien-\u00eatre personnel.\nRejoignez\nCapital Market, entit\u00e9 Inetum en Finance de March\u00e9\n. Nous accompagnons les acteurs majeurs du secteur de la finance en France et \u00e0 l\u2019International.\nCultivant la double comp\u00e9tence technique et fonctionnelle, nous intervenons sur des projets innovants \u00e0 haute valeur ajout\u00e9e.\nQuelles sont nos valeurs ?\n\ud83c\udfc6 Excellence Notre culture de l\u2019excellence na\u00eet de notre audace.\n\ud83e\udd1d Engagement S\u2019associer et grandir ensemble !\n\ud83d\udef0 Innovation Nos FabLab au service de la transformation digitale de nos clients.\nMissions propos\u00e9es\nPour accompagner notre forte croissance, nous recherchons des\nData Engineer DevOps\npour le compte d\u2019un acteur majeur de la finance de march\u00e9 en Europe et dans le monde. Dans ce contexte international et exigeant, vous travaillez sur la conception de solutions Big Data afin de r\u00e9pondre aux besoins des op\u00e9rationnels m\u00e9tiers.\nPour mener \u00e0 bien ce projet, vous aurez pour responsabilit\u00e9s de\nComprendre les enjeux des \u00e9quipes Data et les accompagner. Faire le lien entre les environnements (datalake, datawarehouse et environnement de d\u00e9ploiement du mod\u00e8le) gr\u00e2ce \u00e0 des pipelines sophistiqu\u00e9s\n\u00catre r\u00e9f\u00e9rent et garant des bonnes pratiques pour le d\u00e9veloppement des langages utilis\u00e9s par l'\u00e9quipe. Accompagner les Data Scientists dans l'optimisation de leurs algorithmes\nAssurer la viabilit\u00e9 des solutions de datamining et de machine learning de l'\u00e9quipe Data et les mettre en production.Construire et optimiser des pipelines de donn\u00e9es complexes (ETL et ELT)\nCoordonner le d\u00e9veloppement et les op\u00e9rations gr\u00e2ce \u00e0 l\u2019automatisation des flux de travail, la cr\u00e9ation de services Web pr\u00e9dictifs.\nD\u00e9ployez ces mod\u00e8les en utilisant les derni\u00e8res techniques et pratiques (API REST, Docker, Tensorflow Serving, etc.)\nAnalyser et r\u00e9soudre les anomalies li\u00e9es aux performances et \u00e0 l\u2019\u00e9volutivit\u00e9 des solutions Cloud BI et Big Data\nProfil\nProfil souhait\u00e9\nDe formation Ing\u00e9nieur Grande Ecole ou \u00e9quivalent, vous poss\u00e9dez une premi\u00e8re exp\u00e9rience r\u00e9ussite de trois ans minimum sur un poste \u00e9quivalent id\u00e9alement en banque d\u2019investissement ou asset management.\nVous \u00eates familier avec l\u2019environnement Big Data (data grids, compute grids, REST based architectures, SGBDR, No-SQL Databases, GPUs)\nVous avez d\u00e9j\u00e0 travaill\u00e9 avec la m\u00e9thodologie Agile\nUne certaine aisance technique est \u00e9galement requise (Jenkins, Docker, Ansible, Git, Scala, Kubernetes, Python/Java, Maven)\nUne double comp\u00e9tence Cloud (AWS, Google Cloud, Azure) serait un v\u00e9ritable plus\nEvoluant dans un contexte international, la ma\u00eetrise de l'Anglais est n\u00e9cessaire.\nL\u2019aisance relationnelle, de l\u2019autonomie, la gestion des priorit\u00e9s, des capacit\u00e9s d\u2019analyse et de synth\u00e8se, \u2026 le savoir-\u00eatre est une composante importante dans notre processus de recrutement.\nTous nos postes sont ouverts aux personnes en situation de handicap.\nEt pourquoi Inetum Capital Market ?\n\ud83d\ude04 Des missions int\u00e9ressantes\n\ud83e\udd29 Des perspectives d'\u00e9volutions professionnelles et financi\u00e8res\n\ud83d\ude0e Les avantages d'un grand groupe international\n\ud83d\ude09 Un suivi r\u00e9gulier\n\u2708\ufe0f Une aide \u00e0 la mobilit\u00e9 g\u00e9ographique que vous soyez localis\u00e9 en France ou \u00e0 l'\u00e9tranger\n\ud83d\udc68\u200d\ud83c\udf93 Des formations certifiantes\n\ud83e\udd73 Des moments de FUN !\nLocalisation du poste\nLocalisation du poste\nFrance, Ile-de-France, 75 Paris\nVille\nCourbevoie\nCrit\u00e8res candidat\nNiveau d'\u00e9tudes min. requis\nBac+5\nNiveau d'exp\u00e9rience min. requis\nPlus de 2 ans\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "Java",
                "Scala",
                "R",
                "Go"
            ],
            "DataBase": [
                "SQL"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [],
            "MachingLearning": [
                "TensorFlow"
            ],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [
                "AWS",
                "Azure"
            ],
            "DevTools": [
                "Git",
                "Docker",
                "Jenkins"
            ],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [
                "Ansible",
                "Kubernetes"
            ],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [
                "Docker",
                "Kubernetes"
            ],
            "Collaboration": [],
            "Other": [
                "DevOps",
                "Big Data",
                "Machine Learning",
                "Cloud"
            ],
            "FrSoftSkills": [],
            "EnSoftSkils": []
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [
                "CDI"
            ],
            "Salary": [],
            "Level": [
                "Bac+5"
            ],
            "Experience": [
                "a",
                "n",
                "s",
                "2",
                "2",
                "2"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "Big Data engineer \u2013 Ing\u00e9nieur des donn\u00e9es massives (H/F)",
        "company": "DGSE - Direction G\u00e9n\u00e9rale de la S\u00e9curit\u00e9 Ext\u00e9rieure",
        "location": "Paris, \u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/big-data-engineer-%E2%80%93-ing%C3%A9nieur-des-donn%C3%A9es-massives-h-f-at-dgse-direction-g%C3%A9n%C3%A9rale-de-la-s%C3%A9curit%C3%A9-ext%C3%A9rieure-3778473628?position=9&pageNum=15&refId=4Y4I0MAYAq8eeUJ%2FxaKDAA%3D%3D&trackingId=iBOhk%2F4d%2BBZvLIrtTbFbPQ%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Introduction\nLa Direction G\u00e9n\u00e9rale de la S\u00e9curit\u00e9 Ext\u00e9rieure, DGSE, recrute Big Data engineer \u2013 Ing\u00e9nieur des donn\u00e9es massives (H/F).\nLe poste est situ\u00e9 \u00e0 Paris.\nLa nationalit\u00e9 fran\u00e7aise est obligatoire.\nDomaine m\u00e9tier\nSciences et Technologies\nVotre environnement de travail\nLe flux de donn\u00e9es trait\u00e9es par la DGSE est \u00e9quivalent \u00e0 celui des GAFAM. Ces donn\u00e9es sont au centre du travail des analystes de renseignement, qui doivent pouvoir compter sur des syst\u00e8mes leur permettant de rechercher, croiser, traiter ces donn\u00e9es, en temps r\u00e9el ou en batch. Dans ce contexte, la DGSE cherche \u00e0 renforcer ses \u00e9quipes de traitement de la donn\u00e9e massive.\nAu sein d'un service centr\u00e9 sur le stockage, l'exploitation et la valorisation des donn\u00e9es, nous vous proposons d'int\u00e9grer les \u00e9quipes en charge des plateformes de stockage ou des traitements temps r\u00e9el des donn\u00e9es. Ces \u00e9quipes pluridisciplinaires d\u00e9veloppent et maintiennent de bout en bout diverses plateformes reposant sur les technologies Kafka, Yarn, Hadoop, HBase ou encore Elasticsearch. Plus sp\u00e9cifiquement, l\u2019\u00e9quipe Stockage administre des entrep\u00f4ts Big Data ainsi que des couches d\u2019acc\u00e8s \u00e0 leurs donn\u00e9es. L\u2019\u00e9quipe Temps r\u00e9el con\u00e7oit des algorithmes r\u00e9pondant \u00e0 des besoins de temps de r\u00e9action tr\u00e8s courts (lev\u00e9e d\u2019alertes, enrichissement \u00e0 la vol\u00e9e, r\u00e9ponse \u00e0 des besoins op\u00e9rationnels).\nEn nous rejoignant, vous d\u00e9couvrirez :\nun environnement unique, qu'aucune autre structure ne peut vous proposer,\nun m\u00e9tier proche du renseignement et de l'op\u00e9rationnel,\nune action sur l'int\u00e9gralit\u00e9 de la cha\u00eene, du d\u00e9veloppement au d\u00e9ploiement en production,\nun minimum de 48 jours de cong\u00e9s par an,\nune ambiance propice \u00e0 l\u2019\u00e9panouissement professionnel.\nVos missions\nLes missions des \u00e9quipes auxquelles vous serez amen\u00e9s \u00e0 contribuer seront d\u00e9termin\u00e9es en fonction de votre exp\u00e9rience et de vos app\u00e9tences.\nVous serez en charge de plusieurs activit\u00e9s parmi les suivantes :\nconcevoir, impl\u00e9menter et optimiser des algorithmes de traitement de donn\u00e9es distribu\u00e9s (Scala, Spark, Java),\ngarantir le bon fonctionnement, la disponibilit\u00e9 et la performance des plateformes de traitement,\nparticiper \u00e0 l\u2019\u00e9volution de l\u2019architecture, en int\u00e9grant de nouveaux composants (frameworks, biblioth\u00e8ques, \u2026) permettant de mieux r\u00e9pondre aux besoins,\nassurer une veille technologique constante pour rester au plus haut niveau et garantir une ad\u00e9quation des clusters existants avec l\u2019\u00e9tat de l\u2019art du domaine,\ncontribuer \u00e0 l'am\u00e9lioration continue de l'\u00e9quipe,\ninteragir avec l\u2019\u00e9quipe SRE/Devops pour am\u00e9liorer la fiabilit\u00e9 des architectures, l\u2019automatisation des d\u00e9ploiements et l'observabilit\u00e9 des syst\u00e8mes mis en \u0153uvre.\nVotre profil\nVous \u00eates titulaire d\u2019un dipl\u00f4me en informatique, niveau master ou \u00e9cole d\u2019ing\u00e9nieur, ou pouvez d\u00e9montrer une exp\u00e9rience \u00e9quivalente.\nVous devez poss\u00e9der les comp\u00e9tences et qualit\u00e9s suivantes :\nbonnes connaissances fondamentales logicielles (structures de donn\u00e9es, algorithmique, architecture),\nma\u00eetrise des langages Scala, Java ou python, vous n'avez pas peur de monter en comp\u00e9tences sur ceux que vous ne ma\u00eetrisez pas,\nadepte de l'int\u00e9gration continue, vous \u00eates familier de Gitlab CI, Github Actions ou Jenkins,\nfamilier avec les bonnes pratiques de d\u00e9veloppement collaboratif (usage de git, pratique de relecture de code).\nEn bonus :\npremi\u00e8re exp\u00e9rience avec un framework de traitement en streaming (SparkStreaming, KStream, Storm, Flink, ...),\nconvaincu de l'importance de l'observabilit\u00e9 des syst\u00e8mes qui regroupe m\u00e9trologie, logging et tracing, vous avez d\u00e9j\u00e0 mis en place une stack de ce type (Prometheus, Telegraph, OpenTelemetry, Jaeger, ELK, \u2026),\nfamilier avec un outil de gestion de configuration (Ansible, Puppet, ...),\nexp\u00e9rience sur les clusters Kafka, Hadoop, HBase ou Elasticsearch de plusieurs n\u0153uds.\nLes plus de l\u2019offre\nContexte d\u2019activit\u00e9s unique\nDiversit\u00e9 des projets\nTechnologies \u00e0 la pointe\nContact\nEnvoyez-nous votre candidature \u00e0 l\u2019adresse :\ndgse-macandidature.cer.fct@intradef.gouv.fr\nPlus d\u2019information sur www.dgse.gouv.fr > Nous rejoindre.\nRESTEZ DISCRET SUR VOTRE CANDIDATURE A LA DGSE\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "Java",
                "Scala",
                "R",
                "Go"
            ],
            "DataBase": [
                "HBase",
                "Elasticsearch"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [
                "Hadoop",
                "Spark",
                "Flink"
            ],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [],
            "DevTools": [
                "Git",
                "Jenkins"
            ],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [
                "HBase"
            ],
            "Automation": [
                "Ansible",
                "Puppet"
            ],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [
                "DevOps",
                "Big Data"
            ],
            "FrSoftSkills": [],
            "EnSoftSkils": []
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "Data Engineer",
        "company": "Harnham",
        "location": "Paris, \u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/data-engineer-at-harnham-3909639055?position=10&pageNum=15&refId=4Y4I0MAYAq8eeUJ%2FxaKDAA%3D%3D&trackingId=1CSnqICdRwScGUYo4BHNzQ%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "DATA ENGINEER\nPARIS (75) / LILLE (59)\n50K-65K EUR\nCloud AWS \u2013 Python \u2013 PySpark - Glue\nUne nouvelle opportunit\u00e9 s\u2019ouvre pour un Data Engineer dans le domaine de l\u2019assurance. La personne rejoindra une grande \u00e9quipe ayant pour projet la cr\u00e9ation d\u2019une nouvelle plateforme Data ! Si vous recherchez un d\u00e9fi stimulant dans un environnement qui encourage les nouvelles id\u00e9es, cette opportunit\u00e9 est faite pour vous.\nVOTRE MISSION :\nCollaboration avec les Data Architectes pour garantir un bon alignement sur l\u2019architecture\nDeveloppement des processus d\u2019ingestion pour la diffusion des donn\u00e9es dans le Datalake\nMise en place de m\u00e9canisme pour g\u00e9n\u00e9rer les couches de donn\u00e9es organis\u00e9es\nImplementation d\u2019outils MLOps pour la mise en \u0153uvre d\u2019algorithmes ML\nConception de Data Warehouse pour acc\u00e9l\u00e9rer la g\u00e9n\u00e9ration de mod\u00e8les en Etoile\nTravail dans une \u00e9quipe agile avec le train Agile Release, le Product Owner et le SCRUM Master\nVOTRE PROFIL :\n3 \u00e0 5 ans d\u2019exp\u00e9rience en tant que Data Engineer\nComp\u00e9tences solides en Cloud AWS, Python, PySpark et SQL\nComp\u00e9tences avec les services AWS Cloud Computing : Glue ; Ath\u00e9na ; Redshift\nCapacit\u00e9 \u00e0 travailler en autonomie\nFrancais et Anglais : Fluent obligatoire\nLes outils BI tels que Power BI ou QuickSight est un plus\nN\u2019h\u00e9sitez plus pour postuler !\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "R",
                "Go"
            ],
            "DataBase": [
                "SQL"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [
                "Spark"
            ],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [
                "Power BI"
            ],
            "Statistics": [],
            "CloudComputing": [
                "AWS"
            ],
            "DevTools": [],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [
                "ML",
                "Cloud"
            ],
            "FrSoftSkills": [
                "Collaboration"
            ],
            "EnSoftSkils": [
                "Collaboration"
            ]
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s",
                "5",
                "5",
                "5"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "Data Engineer H/F",
        "company": "AXEAL",
        "location": "Lyon, Auvergne-Rh\u00f4ne-Alpes, France",
        "link": "https://fr.linkedin.com/jobs/view/data-engineer-h-f-at-axeal-3913998011?position=1&pageNum=17&refId=l8SH%2B3yTgmzGUPyUpkaAhw%3D%3D&trackingId=cyRIjxyXCNx9BJ%2Fl7OpG9g%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "AXEAL, filiale d'HEVERETT Group porte une r\u00e9elle ambition digitale et propose des solutions de conseil dans les domaines des technologies industrielles.\nNous sommes sp\u00e9cialistes de l'Ing\u00e9nierie du Num\u00e9rique appliqu\u00e9e \u00e0 l'Industrie 4.0 dans les secteurs de l'Energie, de la D\u00e9fense, de l'A\u00e9ronautique et du Naval.\nParce que nous ciblons des clients qui d\u00e9veloppent des projets innovants, nous sommes en mesure de proposer les meilleures missions \u00e0 nos consultants.\nActuellement en forte croissance, nous sommes \u00e0 la recherche d'un(e) Data Engineer pour rejoindre cette aventure passionnante et participer aux transformations technologiques de demain.\nCe Que Nous Proposons\nEn tant que Data Engineer, vous aurez les responsabilit\u00e9s suivantes :\nD\u00e9finir, architecturer, mettre en place et maintenir les outils et infrastructures permettant la valorisation des donn\u00e9es dans un contexte \u00ab Data centric \u00bb.\nVous aurez \u00e0 garantir le p\u00e9rim\u00e8tre technique applicatif allant la captation des donn\u00e9es (source h\u00e9t\u00e9rog\u00e8ne, temps r\u00e9el, structur\u00e9 ou non, multi protocole) \u00e0 son stockage (SQL, nosql) en passant par son traitement (batch, micro batch ou stream) dans un environnement on-Premise, cloud ou hybride.\nLe dimensionnement, la s\u00e9curit\u00e9, la p\u00e9rennit\u00e9 et l'accessibilit\u00e9 sont des \u00e9l\u00e9ments cl\u00e9s \u00e0 prendre en compte.\nLa capacit\u00e9 \u00e0 travailler en \u00e9quipe avec des m\u00e9thodologies/outils collaboratifs est un pr\u00e9 requis.\nVous \u00eates dipl\u00f4m\u00e9(e) d'un doctorat, d'une grande \u00c9cole d'Ing\u00e9nieur et/ou d'un 3\u00e8me cycle universitaire sp\u00e9cialis\u00e9 en que Data Engineer ou Math\u00e9matiques appliqu\u00e9es.\nRigoureux(se) et curieux(se), vous faites preuve d'autonomie et aimez relever de nouveaux challenges scientifiques et techniques.\nLa connaissance des protocoles industriels serait appr\u00e9ci\u00e9e. Vous \u00e9voluerez dans un environnement m\u00ealant projet industriel et projet de recherche/innovation.\nVous Avez Des Comp\u00e9tences Sur\nCaptation de la donn\u00e9e : Protocole MQTT, OPC-UA, SQL, API RestFul, WS\nTransformation de la donn\u00e9e : Kafka, Spark, storm, Hadoop, Elastic Search, NIFI, ESBMule, Talend, MLFLOW\nStockage de la donn\u00e9e : SQL, NoSQL (timeseries, graph, document)\nMonitoring/Visualisation : Grafana, PROMETHEUS, superset, BI\nInfrastructure : Docker, Kubernetes\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "R",
                "Go"
            ],
            "DataBase": [
                "SQL",
                "NoSQL"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [
                "Hadoop",
                "Spark"
            ],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [],
            "DevTools": [
                "Git",
                "Docker"
            ],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [
                "Kubernetes"
            ],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [
                "Docker",
                "Kubernetes"
            ],
            "Collaboration": [],
            "Other": [
                "ML",
                "Cloud"
            ],
            "FrSoftSkills": [],
            "EnSoftSkils": []
        },
        "details": {
            "JobDetail": [
                "Hybride"
            ],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "Junior Data Engineer",
        "company": "Constellium",
        "location": "Voreppe, Auvergne-Rh\u00f4ne-Alpes, France",
        "link": "https://fr.linkedin.com/jobs/view/junior-data-engineer-at-constellium-3791294675?position=2&pageNum=17&refId=l8SH%2B3yTgmzGUPyUpkaAhw%3D%3D&trackingId=VuMdW2oTIzx9CYlGnswtXw%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "C\n-TEC RECRUTE\nJunior Data Engineer (all genders)\nConstellium est un leader mondial du d\u00e9veloppement et de la fabrication de produits et de solutions en aluminium \u00e0 haute valeur ajout\u00e9e pour un large \u00e9ventail de march\u00e9s et d'applications, se concentrant en particulier sur l'a\u00e9rospatiale, l'automobile et l'emballage.\nL'\u00e9quipe Digital centrale d\u00e9ploie les technologies de l'industrie 4.0 partout dans le groupe pour cr\u00e9er nos futurs processus de fabrication de classe mondiale. Elle est h\u00e9berg\u00e9e dans le centre R&D de Constellium \u00e0 Voreppe, en France. T\u00e9l\u00e9travail possible jusqu\u2019\u00e0 2 jours par semaine.\nResponsibilit\u00e9s:\nDans le cadre de notre strat\u00e9gie digitale l\u2019objectif du poste est de concevoir, d\u00e9velopper et maintenir des applications autour de la collecte, du stockage et de l\u2019utilisation de la donn\u00e9e, avec pour finalit\u00e9 sa valorisation pour notre activit\u00e9.\nLe titulaire du poste devra :\nInteragir avec les sites de production et les experts m\u00e9tiers pour comprendre leurs besoins.\nParticiper \u00e0 la d\u00e9finition de l\u2019architecture des solutions et des applications.\nConcevoir, d\u00e9velopper et maintenir les applications et les solutions ax\u00e9es sur la donn\u00e9e.\nPromouvoir les applications digitales et participer activement \u00e0 leur d\u00e9ploiement.\nTravailler en \u00e9troite collaboration avec une \u00e9quipe de d\u00e9veloppeurs.\nLe poste implique des d\u00e9placements professionnels occasionnels dans les usines du groupe en Europe et aux \u00c9tats-Unis.\nProfile :\nUn dipl\u00f4me de niveau master en d\u00e9veloppement informatique li\u00e9 \u00e0 la gestion des donn\u00e9es\nUne premi\u00e8re exp\u00e9rience en tant qu\u2019ing\u00e9nieur de donn\u00e9es, avec des r\u00e9alisations dans les domaines suivants :\nD\u00e9veloppements d\u2019application en Python ;\nArchitecture applicative ;\nSQL / Mod\u00e9lisation de donn\u00e9es ;\nConnaissance de Git / GitHub ;\nLa connaissance du cloud Azure est un plus.\nLe candidat id\u00e9al aura :\nUn int\u00e9r\u00eat prononc\u00e9 pour les donn\u00e9es et les sujets li\u00e9s \u00e0 l\u2019industrie ;\nUne volont\u00e9 av\u00e9r\u00e9e \u00e0 apprendre et \u00e0 d\u00e9livrer ;\nUne capacit\u00e9 \u00e0 interagir avec des profils vari\u00e9s (notamment non informaticiens) ;\nUne curiosit\u00e9 pour \u00e9valuer les technologies innovantes du monde digital.\nUn niveau de Fran\u00e7ais et d'anglais courant \u00e9crit et parl\u00e9 est essentiel.\nNous offrons:\nUne politique salariale attractive\nUn syst\u00e8me d'int\u00e9ressement\nUn syst\u00e8me de bonus\nUne possibilit\u00e9 de t\u00e9l\u00e9traviller\nUn restaurant d'entreprise\nDes avantages importants par les oeuvres sociales\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "R"
            ],
            "DataBase": [
                "SQL"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [
                "Azure"
            ],
            "DevTools": [
                "Git"
            ],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [
                "Cloud"
            ],
            "FrSoftSkills": [
                "Collaboration"
            ],
            "EnSoftSkils": [
                "Collaboration"
            ]
        },
        "details": {
            "JobDetail": [
                "Junior"
            ],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "Data Engineer",
        "company": "Harnham",
        "location": "Paris, \u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/data-engineer-at-harnham-3909599777?position=3&pageNum=17&refId=l8SH%2B3yTgmzGUPyUpkaAhw%3D%3D&trackingId=G5qtrNaKlOVlK%2BC16Tnbdw%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "DATA ENGINEER\nPARIS (75)\nUP TO 65K\u20ac FIXE\nPython - AWS - Glue - Pyspark\nUne entreprise sp\u00e9cialis\u00e9e dans l'assurance automobile des particuliers, recherche un Data Engineer. Dans le cadre de la cr\u00e9ation d'une nouvelle plateforme data en Europe, l'entreprise recherche un data engineer pour renforcer son \u00e9quipe.\nLE POSTE\nEn tant que Data Engineer, vous allez construire les pipelines pour la pr\u00e9paration et la transformation des donn\u00e9es, y compris les donn\u00e9es brutes, ingestion et donn\u00e9es organis\u00e9es. Vous serez responsable de la mise en \u0153uvre des mod\u00e8les de donn\u00e9es qui contiennent les KPI et qui sont la source des analyses cl\u00e9s d\u00e9finies par le m\u00e9tier. Vous accompagnerez aussi les data engineer juniors dans leur mont\u00e9e en comp\u00e9tences.\nVoici vos responsabilit\u00e9s au quotidien :\nTravailler avec les data architectes pour garantir que le d\u00e9veloppement est align\u00e9 sur l'architecture cible\nD\u00e9velopper les processus d'ingestion de donn\u00e9es pour diffuser les donn\u00e9es dans le Data Lake, \u00e0 la fois en temps r\u00e9el et temps diff\u00e9r\u00e9\nImpl\u00e9menter le m\u00e9canisme pour g\u00e9n\u00e9rer la couche de donn\u00e9es organis\u00e9e avec les diff\u00e9rents ensembles de donn\u00e9es disponibles pour l'entreprise\nImpl\u00e9menter l'outil MLOps pour acc\u00e9l\u00e9rer la mise en \u0153uvre des algorithmes ML au niveau niveau de l'entreprise\nConstruire la data warehouse pour acc\u00e9l\u00e9rer la g\u00e9n\u00e9ration de mod\u00e8les\nTravailler dans une \u00e9quipe agile en \u00e9troite collaboration avec le train Agile Release, le Product Owner et le Scrum Master afin d'ex\u00e9cuter la t\u00e2che assign\u00e9e pour atteindre les objectifs d'AgileTeam, en particulier communiquer avec le Scrum Master pour faire remonter les obstacles ou les am\u00e9liorations pour l'\u00e9quipe Agile\nVOTRE PROFIL\n3 \u00e0 5 ans d'exp\u00e9rience en gestion de donn\u00e9es et technologies Big Data, en particulier : SQL,PySpark et Python\nPlus de 3 ans d'exp\u00e9rience avec les services AWS Cloud Computing : Glue, Athena, Redshift et DynamoDB\nPlus de 3 ans d'exp\u00e9rience dans l'impl\u00e9mentation de data warehouse\nFran\u00e7ais et anglais courant\nUne exp\u00e9rience avec les outils BI (de pr\u00e9f\u00e9rence : QuickSight ou PowerBI) est un vrai plus\nPOUR POSTULER\nMerci de me faire part de votre CV et je vous recontacterai au plus vite.\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "R",
                "Go"
            ],
            "DataBase": [
                "SQL"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [
                "Spark"
            ],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [
                "PowerBI"
            ],
            "Statistics": [],
            "CloudComputing": [
                "AWS"
            ],
            "DevTools": [],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [
                "Big Data",
                "ML",
                "Cloud"
            ],
            "FrSoftSkills": [
                "Collaboration"
            ],
            "EnSoftSkils": [
                "Collaboration"
            ]
        },
        "details": {
            "JobDetail": [
                "Junior"
            ],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s",
                "5",
                "5",
                "5"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "Senior Data Engineer",
        "company": "QUANT AI Lab",
        "location": "Paris, \u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/senior-data-engineer-at-quant-ai-lab-3870444702?position=4&pageNum=17&refId=l8SH%2B3yTgmzGUPyUpkaAhw%3D%3D&trackingId=QQK86xMjdcq%2FXDnOI0H7%2BA%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Chez QUANT AI LAB, nous travaillons avec nos clients pour les aider \u00e0 r\u00e9soudre leurs probl\u00e8mes, de la d\u00e9finition de la strat\u00e9gie \u00e0 la mise en \u0153uvre de solutions robustes et durables. Nous nous appuyons sur notre approche op\u00e9rationnelle qui lie conseil et outils.\nNous avons le projet d'accompagner nos clients sur le long terme avec nos convictions, nos approches et notre plateforme QUANT. Rejoindre QUANT AI LAB, c'est rejoindre une aventure entrepreneuriale o\u00f9 chaque collaborateur est un \u00e9l\u00e9ment important de ce projet.\nC'est pourquoi, notre recherche vise \u00e0 recruter plusieurs profils sp\u00e9cialis\u00e9s, dont un\nSenior\nData Engineer\npour rejoindre notre \u00e9quipe interne de QUANT AI LAB.\nLieu de poste:\nParis.\nLas comp\u00e9tences du candidat sont:\nTitul\u00e9 d'un dipl\u00f4me universitaire\n(\u00c9conomie, Ing\u00e9nierie...)\nNatif(ve) en fran\u00e7ais.\nExp\u00e9rience au moins 5 ans\nautant que Data Engineer.\nExp\u00e9rience avec\nScala.\nProgrammation en\nPython.\nMa\u00eetrise de l'environnement Cloud\nAzure (Databricks).\nMa\u00eetrise de\nprocess ETLs.\nQUANT AI LAB, ce que nous offrons:\nContribuer au d\u00e9veloppement d'une entreprise internationale en croissance continue et d\u00e9veloppant des projets et produits de pointe.\nInt\u00e9grer une \u00e9quipe multidisciplinaire avec une formation professionnelle et acad\u00e9mique de haut niveau, compos\u00e9e de certains des meilleurs experts dans le domaine de l'intelligence artificielle, de l'analytique avanc\u00e9e et du traitement des donn\u00e9es.\nL'opportunit\u00e9 de travailler directement avec des clients d'envergure internationale et certaines des plus grandes entreprises du pays et du monde.\nUn environnement de travail collaboratif, entrepreneurial et solidaire, et une \u00e9quipe jeune et dynamique o\u00f9 chacun s'entraide pour grandir ensemble.\nUne ambiance ludique et conviviale et des \u00e9v\u00e9nements festifs (afterworks, s\u00e9minaires...).\nUn contrat \u00e0 dur\u00e9e ind\u00e9termin\u00e9e et un salaire tr\u00e8s comp\u00e9titif, \u00e0 d\u00e9terminer en fonction du profil et de l'exp\u00e9rience.\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "Scala",
                "R"
            ],
            "DataBase": [],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [
                "Databricks"
            ],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [
                "Azure"
            ],
            "DevTools": [],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [
                "Cloud"
            ],
            "FrSoftSkills": [],
            "EnSoftSkils": []
        },
        "details": {
            "JobDetail": [
                "Senior"
            ],
            "TypeContract": [],
            "Salary": [
                "Salaire"
            ],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s",
                "5",
                "5",
                "5"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "Data Engineer Lille H/F",
        "company": "Jems Group",
        "location": "Lille, Hauts-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/data-engineer-lille-h-f-at-jems-group-3887943159?position=5&pageNum=17&refId=l8SH%2B3yTgmzGUPyUpkaAhw%3D%3D&trackingId=YKBGlO4%2BmKgm4JyE4pKCsg%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "A propos de JEMS\nNous sommes le seul industriel de la donn\u00e9e en Europe. Notre m\u00e9tier est de cr\u00e9er, manager et exploiter le patrimoine data de nos clients.\nNous avons la conviction que chaque entreprise peut adopter une d\u00e9marche innovante de gestion de la donn\u00e9e et cr\u00e9er des cas d\u2019usage disruptifs en r\u00e9duisant l'impact \u00e9cologique et en diminuant la dette technique.\nNous comptons plus de 840 collaborateurs en mission chez nos clients grands comptes dans tout secteur d\u2019activit\u00e9 : banque, assurance, sant\u00e9, \u00e9nergie, e-commerce, automobile, luxe, retail, transport, agritech\u2026\nVos missions\nNous recherchons un(e) data engineer capable de trouver des solutions innovantes et robustes \u00e0 l'ensemble des probl\u00e9matiques Data.\nVous aurez la charge de :\nParticiper \u00e0 la conception et r\u00e9alisation d'une solution Data depuis l'acquisition jusqu'\u00e0 l'exploitation de la donn\u00e9e en accompagnant la r\u00e9flexion des directions m\u00e9tiers\nIdentifier, collecter et int\u00e9grer les donn\u00e9es n\u00e9cessaires \u00e0 la r\u00e9solution de probl\u00e9matiques m\u00e9tier et op\u00e9rationnelles\nGarantir la qualit\u00e9 des donn\u00e9es en mettant en place les outils de mesure et de suivi ad\u00e9quats en appliquant les r\u00e8gles de Data Gouvernance et de Data Management\nTranscrire des besoins m\u00e9tier en r\u00e8gles de gestion data\nIndustrialiser le d\u00e9ploiement de vos r\u00e9alisations \u00e0 travers l'impl\u00e9mentation de tests unitaires, d'int\u00e9gration et de non-r\u00e9gression\nVos comp\u00e9tences\nEn tant que Data Engineer vous ma\u00eetrisez :\nLe langage SQL\nUn langage objet (Python, JAVA, Scala)\nUn framework de calcul distribu\u00e9\nL'int\u00e9gration continue (Git, JUnit, SonarQube, Jenkins)\nUn cloud provider (AWS, GCP, Azure) ou une distribution Big Data (Hortonworks, Cloudera, Datastax)\nLes concepts de la mod\u00e9lisation relationnelle et non-relationnelle\nVotre profil\nDipl\u00f4m\u00e9(e) d'une \u00e9cole d'ing\u00e9nieur ou d'un parcours acad\u00e9mique bac+5 , vous justifiez d'une exp\u00e9rience professionnelle d'au moins 3 ans dans un contexte projet Data. Rigoureux, proactif et autonome vous restez en veille technologique et \u00eates force de proposition. Vous \u00eates capable de prendre de la hauteur et vous adapter aux enjeux du projet.\nAvantages \u00e0 travailler chez JEMS\nUne JEMS Acad\u00e9mie au service de votre mont\u00e9e en comp\u00e9tences (formations et certifications sur les technologies de pointe)\nUn accompagnement personnalis\u00e9 et un management de proximit\u00e9 pour vous proposer des \u00e9volutions de carri\u00e8re\nUne int\u00e9gration dans des communaut\u00e9s techniques et de pratiques JEMS (encadrement par des experts, \u00e9changes sur les bonnes pratiques, favoriser l'innovation...)\nUne entreprise reconnue \"Great Place To Work\"\nDes \u00e9v\u00e8nements et s\u00e9minaires inoubliables, des soir\u00e9es d'agence conviviales\nMobilit\u00e9\nUne mobilit\u00e9 nationale et internationale pour vous accompagner dans vos projets de vie.\nDiversit\u00e9\nLe Groupe JEMS porte fi\u00e8rement sa valeur \"Diversit\u00e9\" en se mobilisant pour l'inclusion et l'\u00e9galit\u00e9 des chances et en luttant contre toutes formes de discrimination.\nTous nos postes sont ouverts aux personnes en situation de handicap.\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "Java",
                "Scala",
                "R",
                "Go"
            ],
            "DataBase": [
                "SQL"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [
                "AWS",
                "Azure"
            ],
            "DevTools": [
                "Git",
                "Jenkins"
            ],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [
                "Big Data",
                "Cloud"
            ],
            "FrSoftSkills": [],
            "EnSoftSkils": []
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [],
            "Salary": [],
            "Level": [
                "Bac+5"
            ],
            "Experience": [
                "a",
                "n",
                "s",
                "3",
                "3",
                "3"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "Data Engineer Cloud Azure F/H",
        "company": "SOFTEAM",
        "location": "Paris, \u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/data-engineer-cloud-azure-f-h-at-softeam-3609925189?position=6&pageNum=17&refId=l8SH%2B3yTgmzGUPyUpkaAhw%3D%3D&trackingId=hEH4xMsVArxvZE38RT24qg%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Vous \u00e9voluez dans le domaine de la Data et souhaitez int\u00e9grer un leader de la transformation num\u00e9rique sp\u00e9cialis\u00e9 dans les secteurs de la Banque, du Luxe, de l'Assurance, de la Finance, de l'Energie et la possibilit\u00e9 d'\u00e9voluer au sein du Groupe Docaposte !\nSofteam est labellis\u00e9 \"HappyIndex\u00ae AtWork \" 2022 pour la 5\u00e8me ann\u00e9e cons\u00e9cutive !\nNos collaborateurs travaillent en \u00ab mode projet \u00bb autour des Modern DATA Platform \u2601 et technologies Big Data Azure Cloud / On premise et autre \"playeur\" du march\u00e9. Nous accompagnons de bout en bout nos clients sur des probl\u00e9matiques de Gouvernance, d\u2019Int\u00e9gration, de Visualisation et d\u2019IA.\nCE QUE NOUS RECHERCHONS\nSOFTEAM Data recherche un(e) Data Engineer Cloud, disposant de solides connaissances techniques.\nCE QUE NOUS ATTENDONS DE VOUS\nEn tant que Data Engineer Cloud, vous concevez, mettez en place et administrez des clusters et des solutions big data.\nVos missions d\u00e9taill\u00e9es :\nAnalyse et compr\u00e9hension des besoins m\u00e9tiers,\nParticipation \u00e0 la d\u00e9finition et \u00e0 la conception de l\u2019architecture,\nGestion des donn\u00e9es : pr\u00e9paration, ingestion, traitement, contr\u00f4le qualit\u00e9,\nD\u00e9veloppements des jobs Spark et automatisation des flux d\u2019alimentation du Data Lake,\nTests de charge, tests unitaires\u2026\nMaintenabilit\u00e9 de la solution Big Data (Optimisation et performance des traitements Spark)\nVOUS ETES\nIng\u00e9nieur(e) de formation, vous disposez d'une exp\u00e9rience de 3 ans minimum en tant que Data Engineer.\nVous ma\u00eetrisez les langages Java, Scala ou Python et \u00eates expert sur les framework Spark et Hadoop.\nVous avez une expertise sur les services Data suivants : Azure Data Lake, Azure synapse, Azure Data Factory, Azure Data Explorer\u2026\nNOUS VOUS OFFRONS\nDes missions engageantes aupr\u00e8s des grands acteurs du march\u00e9.\nUn management de proximit\u00e9 avec Gilles SALVADOR, Directeur du Centre d'Expertise Data, toujours bienveillant et \u00e0 \u00e0 l'\u00e9coute et avec qui vous pourrez \u00e9changer au quotidien sur les enjeux de votre mission et \u00e9voquer vos futurs projets afin que nous puissions vous aider \u00e0 les r\u00e9aliser.\nLa possibilit\u00e9 d\u2019\u00e9voluer et de monter en comp\u00e9tences gr\u00e2ce \u00e0 des formations et \u00e0 des certifications aupr\u00e8s de nos clients et de nos consultants, des 12@13, notre Entit\u00e9 Softeam Institute, Organisme de formation interne de renomm\u00e9 qui d\u00e9livre des formations aupr\u00e8s de nos clients...\nQUI SOMMES-NOUS ?\nSOFTEAM DATA est une marque de DOCAPOSTE sp\u00e9cialis\u00e9e dans l'informatique d\u00e9cisionnelle et les nouvelles technologies. Nous apportons notre expertise \u00e0 nos clients, principalement des Grands Comptes de la place financi\u00e8re fran\u00e7aise, dans des projets de transformation digitale et cognitive.\n2000 Softeamien.nes sont d\u00e9di\u00e9.es \u00e0 la transformation m\u00e9tier et digitale de nos clients et ont g\u00e9n\u00e9r\u00e9 200 M\u20ac de chiffre d\u2019affaires en 2020.\nSOFTEAM SPIRIT\nDes communaut\u00e9s d'expertises sur les sujets de la Data\nDe super nouveaux locaux qui sont en plus accessibles facilement\nUne \u00e9cole de formation int\u00e9gr\u00e9e\nDes \u00e9v\u00e8nements : des soir\u00e9es avec les consultants, des 12@13...\nUne entreprise labellis\u00e9e \"Happy at Work\" pour la 5\u00e8me ann\u00e9e cons\u00e9cutive.\nN\u2019attendez plus, rejoignez SOFTEAM et venez nous rencontrer dans nos nouveaux locaux situ\u00e9s \u00e0 la D\u00e9fense #DevenezSofteamien !\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "Java",
                "Scala",
                "R",
                "Go"
            ],
            "DataBase": [],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [
                "Hadoop",
                "Spark"
            ],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [
                "Azure"
            ],
            "DevTools": [
                "Git"
            ],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [
                "Big Data",
                "Cloud"
            ],
            "FrSoftSkills": [],
            "EnSoftSkils": []
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s",
                "3",
                "3",
                "3"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "AI Engineer Intern",
        "company": "SITA",
        "location": "Paris, \u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/ai-engineer-intern-at-sita-3913856183?position=7&pageNum=17&refId=l8SH%2B3yTgmzGUPyUpkaAhw%3D%3D&trackingId=6d%2FsgnHB%2Futl0dC34z%2FiQw%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "ABOUT THE ROLE & TEAM:\nThe Data Intelligence team develops and deploys data-driven and AI-powered solutions to optimize operations in the aviation industry, with a specific focus on reducing the sector's CO2 emissions. For example, SITA Opticlimb helps to save fuel for each climb by computing optimal climb speeds considering number of factors like air density, weight, etc.\nWe are seeking a highly motivated\nAI Engineer Intern\nto join our Data Intelligence team. As an AI Expert Intern, you will have the opportunity to work closely with our AI Experts on cutting-edge projects, leveraging your skills and knowledge in AI development and optimization. This internship provides a valuable opportunity to gain hands-on experience in the field of AI and contribute to the success of our data intelligence solutions.\nWHAT YOU WILL DO:\nCollaborate with AI Experts to develop and optimize AI models and algorithms for aviation operations\nAssist in implementing and maintaining the AI pipeline and infrastructure for data processing and model training\nSupport AI Experts in conducting experiments and tests to evaluate the performance and accuracy of AI models.\nPre-process\u00a0and analyze data using Python and relevant libraries (e.g., Pandas, NumPy) to prepare it for model training and evaluation\nContribute to the development of data pre-processing\u00a0techniques, feature engineering approaches, and model evaluation methodologies\nDocument development processes, procedures, and findings\nStay up-to-date with the latest AI research and industry trends to contribute innovative ideas to the team\nEXPERIENCE:\nCurrently pursuing a Bachelor's or Master's degree in Computer Science, Data Science, or a related field.\nSolid understanding of AI and machine learning concepts.\nProficiency in Python and experience with libraries such as Pandas, NumPy, and scikit-learn.\nKnowledge of data pre-processing, feature engineering, and model evaluation techniques.\nStrong analytical and problem-solving skills.\nExcellent communication and teamwork abilities.\nPassion for learning and staying up-to-date with AI advancements.\nNICE-TO-HAVE:\nAeronautical background is a plus\nWHAT WE OFFER:\nSITA\u2019s workplace is all about diversity, many different countries and cultures are represented in our workforce. We collaborate in our impressive offices, embracing a hybrid work format. As part of our global benefits, we offer:\n\ud83c\udfe1\nFlex-week:\nWork from home up to 2 days/week (depending on your Team's needs).\n\u231a\nFlex-day:\nYou may wish to flex your arrival time at the office, to beat the rush hours or you may want to leave the office earlier to pick up your kids from school or to go to your favorite game: We support you in being open about your needs and routine with you manager.\n\ud83c\udf0e\nFlex-location:\nBenefit for 30 working days from anywhere around the world each year!\n\ud83d\ude4c\ud83c\udffd\nCompetitive benefits\naccording to the local market\nSITA is an Equal Opportunity Employer and values a diverse workforce. In support of our Employment Equity Program, women, aboriginal people, members of visible minorities, and/or persons with disabilities are encouraged to apply and self-identify in the application process\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "R",
                "Go"
            ],
            "DataBase": [],
            "DataAnalytics": [
                "Pandas",
                "NumPy",
                "R"
            ],
            "BigData": [],
            "MachingLearning": [
                "Scikit-Learn"
            ],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [],
            "DevTools": [],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [
                "Machine Learning"
            ],
            "FrSoftSkills": [
                "Communication"
            ],
            "EnSoftSkils": [
                "Communication",
                "Teamwork"
            ]
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "Data Engineer - H/F - CDI",
        "company": "CubeRH",
        "location": "Tourcoing, Hauts-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/data-engineer-h-f-cdi-at-cuberh-3862951855?position=8&pageNum=17&refId=l8SH%2B3yTgmzGUPyUpkaAhw%3D%3D&trackingId=UcyKVwyyFAHcs5s4Wologg%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "La soci\u00e9t\u00e9 :\nNotre client est une entreprise de services sp\u00e9cialis\u00e9e dans le domaine de la Data, \u00e0 \u00e9chelle humaine, qui se distingue par son expertise d\u00e9velopp\u00e9e autour de trois axes principaux : la Data g\u00e9n\u00e9raliste, l'outil de reporting Power BI et la solution cloud Microsoft Azure.\nAu c\u0153ur de sa mission, l'\u00e9co-responsabilit\u00e9 constitue un pilier essentiel. En adoptant cette approche, elle offre une vision compl\u00e8te et int\u00e9gr\u00e9e de la gestion des donn\u00e9es. Gr\u00e2ce \u00e0 une \u00e9quipe de consultants experts, elle simplifie les op\u00e9rations, optimise les donn\u00e9es et les valorise, offrant ainsi \u00e0 ses clients une opportunit\u00e9 de progression.\nEn pleine croissance, l'entreprise recherche \u00e0 agrandir son \u00e9quipe avec un Data Engineer H/F.\nSi vous recherchez une \u00e9quipe qui met en avant votre d\u00e9veloppement professionnel et votre \u00e9panouissement, vous \u00eates au bon endroit !\nL'objectif de la mission :\nInitier et d\u00e9velopper des outils d\u2019infrastructure dans l\u2019objectif de fa\u00e7onner et transformer les donn\u00e9es.\nAgir tel un alli\u00e9 des Data Scientists, pour industrialiser leurs algorithmes et flux de donn\u00e9es.\n\u00catre un acteur de choix dans l\u2019architecture big data afin de r\u00e9pondre aux diff\u00e9rents cas m\u00e9tiers.\nProt\u00e9ger et garantir l\u2019int\u00e9grit\u00e9 des donn\u00e9es en assurant leur s\u00e9curit\u00e9 et leur accessibilit\u00e9s\nMettre en \u0153uvre des pratiques de s\u00e9curit\u00e9 redoutables pour prot\u00e9ger les donn\u00e9es les plus confidentielles et sensibles\nTravailler en collaboration avec les \u00e9quipes techniques dans l\u2019ingestion des donn\u00e9es.\nLes conditions de travail :\nUne mutuelle avantageuse et des tickets restaurants\nRemboursement int\u00e9gral de vos frais de transports en commun\nDes trottinettes \u00e9lectrique et des v\u00e9los \u00e0 disposition\nPrimes (notamment de cooptation)\nT\u00e9l\u00e9travail\nVotre profil :\nVous maitrisez des technologies big data ainsi que les environnements Google cloud platform, Amazon web service et/ou Microsoft Azure\nVous connaissez le langage SQL et Python\nVous poss\u00e9dez des bases solides en architecture data (notamment big data et informatique d\u00e9cisionnelle\nEtre force de proposition sur la mise en oeuvre et l'utilisation des solutions big data\nConnaitre les principes de s\u00e9curit\u00e9\nProcess entretien :\nDeux premiers \u00e9changes avec le cabinet Cube RH;\nEntretiens avec le client (RH et avec le manager).\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "R",
                "Go"
            ],
            "DataBase": [
                "SQL"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [
                "Power BI"
            ],
            "Statistics": [],
            "CloudComputing": [
                "Azure",
                "Google Cloud Platform"
            ],
            "DevTools": [],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [
                "Big Data",
                "Cloud"
            ],
            "FrSoftSkills": [
                "Collaboration"
            ],
            "EnSoftSkils": [
                "Collaboration"
            ]
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "Data Engineer Cloud (F/H)",
        "company": "Apside",
        "location": "\u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/data-engineer-cloud-f-h-at-apside-3904088503?position=9&pageNum=17&refId=l8SH%2B3yTgmzGUPyUpkaAhw%3D%3D&trackingId=%2B%2BPQMVY2DJykjwzejMYJVg%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "\ud83d\udca5\nD\u00e9couvrez la Vie Apsidienne\n\ud83d\udcf9\net vous aussi, devenez Apsidien\nOn aurait pu demander \u00e0 Chat GPT de vous d\u00e9montrer en quoi\nApside est l\u2019ESN qu\u2019il vous faut,\nmais on pr\u00e9f\u00e8re que vous le d\u00e9couvriez vous-m\u00eames \ud83d\udc47\ud83d\ude0f\n\ud83d\udd25\nD\u00e9couvrez votre future mission\n\ud83d\udc49\nContexte\nRejoignez notre Practise Cloud/Data, afin d\u2019intervenir sur des sujets \u00e0 haute valeur ajout\u00e9e !\nNotre\nclient migre actuellement toutes ses applications vers le cloud AWS.\nDe plus, dans le cadre du d\u00e9veloppement d'un produit de restitution automatis\u00e9e de donn\u00e9es, ils recherchent actuellement d\u00e9veloppeur data ayant d\u00e9j\u00e0 travaill\u00e9 sur un projet similaire. La solution produit est techniquement con\u00e7ue en lien avec le Tech Lead validant l'architecture logicielle \u00e0 mettre en place sur le cloud AWS.\nSecteur\n: culture/m\u00e9dia\nM\u00e9thode de travail\n: Agile Safe\n\ud83d\ude0e Mission\nCapter les donn\u00e9es (structur\u00e9es et non structur\u00e9es) produites dans les diff\u00e9rentes applications\nInt\u00e9grer les \u00e9l\u00e9ments\nStructurer la donn\u00e9e (s\u00e9mantique, etc\u2026)\nCartographier les \u00e9l\u00e9ments \u00e0 disposition\nNettoyer la donn\u00e9e (\u00e9limination des doublons, etc\u2026)\nValider la donn\u00e9e\nCr\u00e9er les r\u00e9f\u00e9rentiels de donn\u00e9es\nEnvironnement technique\n:\nPython\nLambda\nStep Function\nAWS / AWS RDS\nPostegreSQL\nSnowflake\nSpark\n\ud83d\udccd\nLocalisation\nLa D\u00e9fense\n\ud83d\udcb0\nLe package salarial que nous vous proposons\nContrat :\nCDI\nAvantages groupe :\ncarte ticket restaurant Swile, prime de mobilit\u00e9, RTT, accord t\u00e9l\u00e9travail, Mutuelle, prime de cooptation, avantages CE, prise en charge de la mutuelle \u00e0 100% etc\u2026\nAvantages agence :\nCommunaut\u00e9 Cloud/Data, afterworks, communaut\u00e9 techlead\nFormation :\ncertifications techniques, cours particuliers d\u2019anglais en interne, acc\u00e8s \u00e0 un catalogue de formations gr\u00e2ce \u00e0 notre plateforme e-learning (\nAcademy by Apside\n) ou via nos organismes partenaires.\n\ud83d\udd2e\n\u00d4 vous futur Apsidien, qui \u00eates-vous ?\nAu moins 4 ans d'exp\u00e9rience en tant que Data Engineer\nMaitrise de l\u2019environnement cloud AWS\nForce de proposition, bon relationnel et autonome\n\ud83d\ude0f\nApside a suscit\u00e9 votre curiosit\u00e9 ?\nDans un environnement marqu\u00e9 par une acc\u00e9l\u00e9ration des \u00e9volutions technologiques, de transformations des usages et de disruptions majeures, Apside est un partenaire de confiance qui accompagne ses clients \u00e0 cr\u00e9er de la valeur et \u00e0 adresser leurs enjeux strat\u00e9giques en leur mettant \u00e0 disposition des expertises technologiques (\nData / IA, Cloud, Cyber\n) et une exp\u00e9rience sectorielle (\nIndustrie, Banque, Assurance, Service, Secteur Public\n). Pour un accompagnement global, le groupe propose des offres transverses autour du\nHandicap\n(Apsid\u2019EA), du\nDigital Learning\n, et du\nConseil\n.\n\ud83e\udd14\nEt votre place dans tout \u00e7a ?\n\ud83d\udc49 Notre volont\u00e9\nest de vous accompagner dans la construction et l\u2019\u00e9panouissement de votre carri\u00e8re\nen nous appuyant notamment\nsur 3 piliers :\nUne\nr\u00e9mun\u00e9ration\n\u00e0 hauteur de vos investissements et de vos comp\u00e9tences\nUne\ntrajectoire professionnelle\nstimulante sur mesure\nUn\nengagement\nautour des valeurs Apsidiennes : la qualit\u00e9 de vie et des conditions de travail au c\u0153ur de nos enjeux\nEngag\u00e9e pour\nun monde plus inclusif et plus responsable\n, Apside r\u00e9invente l\u2019ESN et propose l\u2019Engagement Soci\u00e9tal et Num\u00e9rique. D\u00e9couvrez notre d\u00e9marche RSE ainsi que notre vision de l\u2019Entreprise Engag\u00e9e.\nConvaincu ? A vous de jouer, envoyez-nous votre CV !\nRejoignez l\u2019aventure Apsidienne et d\u00e9couvrez notre vision d\u2019une ESN singuli\u00e8re et r\u00e9siliente\n\ud83d\ude80\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "R"
            ],
            "DataBase": [
                "SQL"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [
                "Spark"
            ],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [
                "AWS"
            ],
            "DevTools": [
                "Git"
            ],
            "Os": [],
            "DBMS": [
                "Snowflake",
                "Snowflake"
            ],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [
                "Cloud"
            ],
            "FrSoftSkills": [],
            "EnSoftSkils": []
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [
                "CDI"
            ],
            "Salary": [
                "100"
            ],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s",
                "4",
                "4",
                "4"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "Senior Data Engineer H/F \u2013 CDI \u2013 Paris",
        "company": "IODA Group",
        "location": "Greater Paris Metropolitan Region",
        "link": "https://fr.linkedin.com/jobs/view/senior-data-engineer-h-f-%E2%80%93-cdi-%E2%80%93-paris-at-ioda-group-3908890202?position=10&pageNum=17&refId=l8SH%2B3yTgmzGUPyUpkaAhw%3D%3D&trackingId=En91OVaDWAVBsJRBkXEEVg%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "IODA Group, cabinet de conseil en plein essor en France et \u00e0 l'international, \u00e0 taille humaine et orient\u00e9 business, mixant la Data, le Marketing, le Digital & la Technologie, est \u00e0 la recherche de talents passionn\u00e9s pour rejoindre son \u00e9quipe.\nSi tu es un(e)\nSenior Data Engineer\nchevronn\u00e9(e) avec\nau moins 4 ans d'exp\u00e9rience\n, ce poste est fait pour toi !\nCe poste est bas\u00e9 \u00e0 Paris mais nous avons \u00e9galement des bureaux \u00e0 Bordeaux, l\u2019Ile de la R\u00e9union et Barcelone.\nLe Job \ud83d\udcbb\nEn tant\nque Senior Data Engineer\nchez IODA Group, tu seras aux commandes des missions suivantes :\nD\u00e9velopper de nouveaux mod\u00e8les de donn\u00e9es et des pipelines\nTester les solutions les plus innovantes et prometteuses du march\u00e9 en vue de pouvoir am\u00e9liorer nos capacit\u00e9s en mati\u00e8re de donn\u00e9es\nComprendre les enjeux business et savoir les traduire dans un environnement technique\nAssister nos clients dans le cadrage des projets et contribuer au design fonctionnel et technique avec une vision avant-gardiste\nAssumer le r\u00f4le de r\u00e9f\u00e9rent, coacher les consultants juniors et faire \u00e9voluer son \u00e9quipe\nComp\u00e9tences techniques requises \ud83d\udd27\nPour ce poste, nous recherchons une personne aux comp\u00e9tences multiples avec :\nUne exp\u00e9rience approfondie des technologies li\u00e9es aux donn\u00e9es, y compris les mod\u00e8les d'architecture Big Data (Spark, Hive, Impala...)\nUne exp\u00e9rience approfondie des services Cloud (AWS / Azure / GCP)\nUne expertise en langages de programmation : Python, Java, et si possible Scala\nUne mise en production de cas d'usage Data, notamment en Machine Learning\nUne capacit\u00e9 \u00e0 mettre en place des mod\u00e8les de donn\u00e9es flexibles et \u00e9volutifs (optimisation de stockage et traitement, regroupement, agr\u00e9gation, partitionnement\u2026)\nUne maitrise des bases de donn\u00e9es SQL (conception, exploitation \u2026)\nUne connaissance en DevOps et en d\u00e9veloppement de flux de donn\u00e9es (data pipelines) avec une ma\u00eetrise de Docker/Kubernetes et des cha\u00eenes CI/CD seraient un plus\nProfil recherch\u00e9 \ud83c\udf1f\nSi tu es dipl\u00f4m\u00e9(e) d'une \u00e9cole d\u2019ing\u00e9nieur / g\u00e9nie informatique Bac+5, que tu as \u00e0 minima 4 ans d\u2019exp\u00e9rience et que tu as une exp\u00e9rience solide dans le monde de la Data, alors nous voulons te rencontrer !\nSi tu es une personne entreprenante, capable de travailler en \u00e9quipe en s\u2019adaptant \u00e0 divers profils, de superviser, de prioriser et de g\u00e9rer plusieurs actions, d\u2019avoir d'excellentes comp\u00e9tences en communication, pr\u00e9sentation et coordination, nous souhaitons toujours te rencontrer !\nDe plus, si tu as des comp\u00e9tences av\u00e9r\u00e9es en analyse et r\u00e9solution de probl\u00e8mes, associ\u00e9es \u00e0 une aptitude \u00e0 assimiler rapidement de nouvelles technologies, tu es bien la personne qu\u2019il nous faut !\nCe qui t'attend chez IODA Group \ud83c\udf08\nEn nous rejoignant, tu auras droit \u00e0 :\nUne \u00e9quipe dynamique et motiv\u00e9e qui reconna\u00eetra et encouragera tes talents et tes id\u00e9es\nUne diversit\u00e9 de projets stimulants dans diff\u00e9rents secteurs d'activit\u00e9s\nDes plateformes internes de R&D pour toujours \u00eatre \u00e0 la pointe de la technologie\nDes perspectives d'\u00e9volution concr\u00e8tes pour faire d\u00e9coller ta carri\u00e8re\nUn CDI avec une r\u00e9mun\u00e9ration fixe attractive et une part variable selon ton profil (voire des bonus compl\u00e9mentaires si tu surperformes !)\nDeux jours de t\u00e9l\u00e9travail par semaine apr\u00e8s la p\u00e9riode d'essai\nDes avantages tels que des tickets restaurants, une participation au titre de transport, une mutuelle...\nUne participation active \u00e0 la vie de l'entreprise avec des afterworks, des \u00e9v\u00e9nements, des s\u00e9minaires et bien plus encore !\nREJOINS-NOUS\nd\u00e8s maintenant pour une aventure o\u00f9 les donn\u00e9es deviennent une source infinie d'opportunit\u00e9s ! \ud83d\ude80\u2728\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "Java",
                "Scala",
                "R"
            ],
            "DataBase": [
                "SQL"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [
                "Spark"
            ],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [
                "AWS",
                "Azure"
            ],
            "DevTools": [
                "Git",
                "Docker"
            ],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [
                "Kubernetes"
            ],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [
                "Docker",
                "Kubernetes"
            ],
            "Collaboration": [],
            "Other": [
                "DevOps",
                "Big Data",
                "Machine Learning",
                "Cloud",
                "CI/CD"
            ],
            "FrSoftSkills": [
                "Communication",
                "R\u00e9solution de probl\u00e8mes"
            ],
            "EnSoftSkils": [
                "Communication"
            ]
        },
        "details": {
            "JobDetail": [
                "Junior",
                "Senior"
            ],
            "TypeContract": [
                "CDI"
            ],
            "Salary": [],
            "Level": [
                "Bac+5"
            ],
            "Experience": [
                "a",
                "n",
                "s",
                "4",
                "4",
                "4"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "Data Engineer",
        "company": "Harnham",
        "location": "Paris, \u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/data-engineer-at-harnham-3909658681?position=1&pageNum=20&refId=%2FS%2FUEqH%2F4ToPDYrc6skyJQ%3D%3D&trackingId=qUGt7EsqBEzusK1%2FE031NA%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Data Engineer\nParis / Lille\nUp to 65k\u20ac\nCDI - Pas Freelance\nCette entreprise internationale dans le monde de l'assurance developpe son equipe data et recherche un nouveau Data Engineer.\nResponsabilit\u00e9s :\nCollaborer avec les architectes de donn\u00e9es pour garantir que le d\u00e9veloppement est align\u00e9 sur l'architecture cible.\nD\u00e9velopper des processus d'ingestion de donn\u00e9es, facilitant le streaming de donn\u00e9es en temps r\u00e9el et par lots dans le lac de donn\u00e9es.\nMettre en \u0153uvre des m\u00e9canismes de g\u00e9n\u00e9ration de couches de donn\u00e9es s\u00e9lectionn\u00e9es comprenant divers ensembles de donn\u00e9es pour la consommation commerciale.\nDiriger la mise en \u0153uvre de MLOps pour rationaliser le d\u00e9ploiement d'algorithmes ML \u00e0 l'\u00e9chelle de l'entreprise.\n\u00c9tablir des cadres pour l'entreposage de donn\u00e9es afin d'acc\u00e9l\u00e9rer la g\u00e9n\u00e9ration de mod\u00e8les en \u00e9toile.\nTravailler en \u00e9troite collaboration au sein d'une \u00e9quipe agile aux c\u00f4t\u00e9s des trains de publication agile, des propri\u00e9taires de produits et des ma\u00eetres scrum pour atteindre les objectifs de l'\u00e9quipe.\nParticiper activement aux c\u00e9r\u00e9monies de la communaut\u00e9 de pratique de l'ing\u00e9nierie des donn\u00e9es, en particulier aux chapitres, pour partager des connaissances techniques et favoriser la collaboration.\nCandidat id\u00e9al :\nMust have :\n3 \u00e0 5 ans d'exp\u00e9rience en gestion de donn\u00e9es et en technologies Big Data, avec une ma\u00eetrise de SQL, PySpark et Python.\nUne exp\u00e9rience pratique approfondie (3+ ans) avec les services de Cloud Computing AWS : Glue, Athena, Redshift et DynamoDB.\nUne exp\u00e9rience av\u00e9r\u00e9e (3+ ans) dans la mise en \u0153uvre des entrep\u00f4ts de donn\u00e9es.\nMa\u00eetrise de l'anglais.\nUn Plus :\nConnaissance suppl\u00e9mentaire des services de Cloud Computing AWS : CDK, SageMaker, fonctions Lambda, Lake Formation, Kinesis.\nFamiliarit\u00e9 avec les outils BI (de pr\u00e9f\u00e9rence QuickSight ou PowerBI).\nMa\u00eetrise de Git, Jupyter Notebook, pip, Java, Apache Airflow.\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "Java",
                "R",
                "Go"
            ],
            "DataBase": [
                "SQL"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [
                "Spark",
                "Apache Airflow"
            ],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [
                "PowerBI"
            ],
            "Statistics": [],
            "CloudComputing": [
                "AWS"
            ],
            "DevTools": [
                "Git"
            ],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [
                "Airflow"
            ],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [
                "Big Data",
                "ML",
                "Cloud"
            ],
            "FrSoftSkills": [
                "Collaboration"
            ],
            "EnSoftSkils": [
                "Collaboration"
            ]
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [
                "CDI"
            ],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s",
                "5",
                "5",
                "5"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "Data Engineer",
        "company": "Pictarine",
        "location": "Toulouse, Occitanie, France",
        "link": "https://fr.linkedin.com/jobs/view/data-engineer-at-pictarine-3911913926?position=2&pageNum=20&refId=%2FS%2FUEqH%2F4ToPDYrc6skyJQ%3D%3D&trackingId=XgvgsQOypETxNXQ%2Bsrs8Vw%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Mission and challenges \ud83c\udfaf\nSi tu es enthousiaste \u00e0 embarquer dans la nouvelle \u00e9quipe data de Pictarine pour la faire rayonner avec tout ton savoir-faire, alors c\u2019est l\u2019aventure qu\u2019il te faut! \ud83c\udfd4\ufe0f\nAvec plus de 1K tables, 2M de clients et 4M de commandes en 2022, les \u00e9quipes de Pictarine ne sont jamais \u00e0 court d\u2019id\u00e9es pour explorer de nouveaux horizons. \ud83d\ude80\nEn tant que Data Engineer chez Pictarine tu vas pouvoir utiliser toutes tes comp\u00e9tences SQL pour garantir la qualit\u00e9 de la data sur GCP, accompagner et challenger les besoins data.\nTu \u00e9volueras au sein de l\u2019\u00e9quipe Engineering, compos\u00e9e des p\u00f4les dev & data.\nTon r\u00f4le comprendra les aspects suivants \ud83d\udc47\ud83c\udffb\nTu es garant de la qualit\u00e9 de la data !\nEn simplifiant la structure de la data et r\u00e9duisant le nombre de tables\nEn transformant les donn\u00e9es pour les rendre facilement utilisables\nEn orchestrant le flux des donn\u00e9es de mani\u00e8re continue et automatique\nTu accompagnes et challenges les \u00e9quipes de Pictarine !\nEn co-construisant des solutions data appropri\u00e9es\nEn \u00e9levant le niveau de jeu des m\u00e9thodes data existantes\nEn faisant rayonner la data autour de bonnes pratiques et d\u2019outillages ad\u00e9quates\nProfil Recherch\u00e9\nAbout you \ud83d\udc8e\nTu as au moins 5 ans d\u2019exp\u00e9rience sur un poste similaire\nTu ma\u00eetrises le data warehouse BigQuery et son langage SQL\nTu es \u00e0 l'aise avec les services GCP\nTu as de bonnes connaissances dans la conception de mod\u00e8les de donn\u00e9es et les strat\u00e9gies d'optimisation des requ\u00eates SQL\nTu as des comp\u00e9tences en DevOps pour le d\u00e9ploiement et la gestion efficace des pipelines de donn\u00e9es\nTu as une bonne ma\u00eetrise de Python & Github\nTu es organis\u00e9, rigoureux et portes une grande attention aux d\u00e9tails\nTu es dot\u00e9 d\u2019excellentes qualit\u00e9s relationnelles, de communication et de vulgarisation\nTu as une passion pour r\u00e9soudre des probl\u00e8mes business avec la programmation\nTu es curieux de tester des nouvelles technologies\nTu es un team player et toujours \u00e0 l'aff\u00fbt de nouvelles id\u00e9es\nWork @ Pictarine\u2728\nUn environnement de travail agile, collaboratif, international et multiculturel\nDes perspectives d\u2019\u00e9volution rapides\nDes locaux tout beaux \u00e0 Lab\u00e8ge avec du mat\u00e9riel dernier cri (mais aussi des snacks \u00e0 profusion et un frigo \u00e0 boissons toujours bien rempli)\nUn apprentissage permanent : conf\u00e9rence, meet-up, Pictarine Academy, cours d\u2019anglais.\nDes events tous les mois : massage, pilates, TGIF, team building .\nUn environnement de travail flexible : horaires, politique de remote hybride.\nUn package de r\u00e9mun\u00e9ration attractif : salaire comp\u00e9titif, RTT, mutuelle & pr\u00e9voyance 100% prise en charge, int\u00e9ressement.\nDes petits + : D\u00e9veloppement de photos gratuit, subvention sport, 3 jours \u201centraide familiale\u201d, jours de cong\u00e9s en plus avec l'anciennet\u00e9... \ud83e\udd2b on ne te d\u00e9voile pas tout !\nRecruitment process \u2699\ufe0f\nTu souhaites nous rejoindre ? Viens rencontrer les gens avec qui tu vas bosser :\n1er \u00e9change pour apprendre \u00e0 se conna\u00eetre avec Marie - Engineering Manager Data (15\u2019)\nEntretien Manager avec Marie (60-90\u2019)\nTest pratique afin de nous montrer tes talents \ud83d\ude42 (3 heures)\nEntretien final avec 2 membres du Codir (90\u2019)\nWelcome aboard !\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "R",
                "Go"
            ],
            "DataBase": [
                "SQL"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [],
            "DevTools": [
                "Git"
            ],
            "Os": [],
            "DBMS": [
                "BigQuery"
            ],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [
                "DevOps"
            ],
            "FrSoftSkills": [
                "Communication"
            ],
            "EnSoftSkils": [
                "Communication"
            ]
        },
        "details": {
            "JobDetail": [
                "Hybride",
                "Remote"
            ],
            "TypeContract": [],
            "Salary": [
                "100",
                "100"
            ],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s",
                "5",
                "5",
                "5"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "Data Engineer",
        "company": "NW",
        "location": "Paris, \u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/data-engineer-at-nw-3904072453?position=3&pageNum=20&refId=%2FS%2FUEqH%2F4ToPDYrc6skyJQ%3D%3D&trackingId=vDQfEmvWaoDACO%2Fg0SceBQ%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": null,
        "skills": {
            "ProgLanguage": [
                "Python",
                "R",
                "Go"
            ],
            "DataBase": [
                "SQL"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [],
            "DevTools": [
                "Git"
            ],
            "Os": [],
            "DBMS": [
                "BigQuery"
            ],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [
                "DevOps"
            ],
            "FrSoftSkills": [
                "Communication"
            ],
            "EnSoftSkils": [
                "Communication"
            ]
        },
        "details": {
            "JobDetail": [
                "Hybride",
                "Remote"
            ],
            "TypeContract": [],
            "Salary": [
                "100",
                "100"
            ],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s",
                "5",
                "5",
                "5"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "Data Engineer Paris H/F (H/F)",
        "company": "Inventiv IT",
        "location": "Levallois-Perret, \u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/data-engineer-paris-h-f-h-f-at-inventiv-it-3910222334?position=4&pageNum=20&refId=%2FS%2FUEqH%2F4ToPDYrc6skyJQ%3D%3D&trackingId=thOWBDZ31CHfsFXdwy4SpA%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Cette offre d\u2019emploi est fournie par P\u00f4le emploi\nDescription\nInventifs Wanted vous propose un CDI pr\u00e9c\u00e9d\u00e9 d'une formation professionnalisante acc\u00e9l\u00e9r\u00e9e de 400h, dans le cadre d'une POEI (Pr\u00e9paration Op\u00e9rationnelle \u00e0 l'Emploi Individuel), pour que vous soyez pleinement op\u00e9rationnel et 100% \u00e0 l'aise dans la mission qui vous sera confi\u00e9e. Situ\u00e9 au c\u0153ur de Levallois, un \u00e9crin o\u00f9 il fait bon vivre et travailler, Inventiv IT b\u00e9n\u00e9ficie d'un cadre vibrant et dynamique, id\u00e9al pour s'\u00e9panouir. Nous sommes en qu\u00eate d'une \u00e9toile filante avec une exp\u00e9rience d'au moins 5 ans minimum dans le domaine de la data science et de la data engineering. Vous \u00eates un leader galactique dot\u00e9 d'une expertise en data, optimisation de processus, et m\u00e9thodologies Agile. Ce que vous apporterez \u00e0 notre galaxie : - Cartographier les constellations de donn\u00e9es : \u00c9tudier les besoins, cadrer les projets et d\u00e9finir les p\u00e9rim\u00e8tres d'interventions afin de r\u00e9aliser le release plan des diff\u00e9rents livrables. - Ing\u00e9nierie des \u00e9toiles : Vous participerez au d\u00e9veloppement des projets ou des services data en d\u00e9veloppant une cha\u00eene de traitement de donn\u00e9es robuste et automatis\u00e9e. - Architecture c\u00e9leste: Participer activement \u00e0 l'ingestion et la mise en qualit\u00e9 des donn\u00e9es selon les bonnes pratiques de la Factory et g\u00e9rer le traitement, l'agr\u00e9gation et la sauvegarde des donn\u00e9es. En \u00e9troite collaboration avec le chef de projet, les OPS et les architectes, vous participerez aux activit\u00e9s d'architecture, conception et d\u00e9veloppement. - Mise en production de la galaxie : Effectuer l'int\u00e9gration continue (avec le versioning, le packaging, les tests et le d\u00e9ploiement) pour assurer une bonne mise en production de notre appareil cosmique. - Surveillance des n\u00e9buleuses: Contribuer professionnellement et activement \u00e0 la veille scientifique et technique, aux projets R&D, et \u00e0 la construction d'assets et de services techniques orient\u00e9s data. Participer \u00e9galement aux autres activit\u00e9s du p\u00f4le Data Science & Engineering (reporting d'activit\u00e9, communication interne et externe, collaboration avec les universit\u00e9s et laboratoires associ\u00e9s). Votre profil stellaire comprendra : - Ma\u00eetrise de l'univers data : Votre expertise en data et mod\u00e9lisation des donn\u00e9es forme la colonne vert\u00e9brale de notre exploration. Vous savez comment transformer des n\u00e9buleuses de donn\u00e9es brutes en syst\u00e8mes solaires d'informations structur\u00e9es et exploitables. - Architecte des flux de donn\u00e9es: Vous \u00eates expert dans la gestion de la cha\u00eene de transformation des donn\u00e9es, de l'ingestion \u00e0 la visualisation. Votre capacit\u00e9 \u00e0 optimiser les processus de traitement et de calcul assure la fluidit\u00e9 et l'efficacit\u00e9 de notre exploration. - Ing\u00e9nieur de l'industrialisation: Gr\u00e2ce \u00e0 votre habilet\u00e9 \u00e0 industrialiser les flux de donn\u00e9es, vous garantissez la scalabilit\u00e9 et la robustesse de nos syst\u00e8mes, pr\u00e9parant notre architecture \u00e0 l'inconnu. - Cr\u00e9ateur d'Outils Visuels: Votre talent dans la conception d'outils graphiques et la data visualisation illumine le chemin, permettant \u00e0 tous de naviguer avec clart\u00e9 dans le cosmos des donn\u00e9es. - Guide et Mentor: Vous accompagnez chaque projet data, assurant la compr\u00e9hension et l'atteinte des objectifs. Votre capacit\u00e9 \u00e0 analyser et comprendre les besoins m\u00e9tier, et \u00e0 r\u00e9diger avec pr\u00e9cision technique et scientifique enrichit la connaissance collective et solidifie notre qu\u00eate. - Arsenal Technologique: Votre ma\u00eetrise de Microsoft Azure Data Lake Storage, Spark / Scala, Git / Azure DevOps, Airflow / DataDog / Nifi, et plus encore, est l'arsenal qui nous propulse dans cette aventure. Chaque outil, chaque langage, est une \u00e9toile dans la galaxie de vos comp\u00e9tences, illuminant notre chemin vers l'avant-garde technologique. Votre Mission, si vous l'acceptez: Faire partie de la Data Factory d' Inventiv IT, c'est accepter de naviguer vers l'inconnu, d'explorer de nouveaux horizons et pr\u00eats \u00e0 s'embarquer dans cette aventure cosmique.\nPROFIL SOUHAIT\u00c9\nExp\u00e9rience\n2 An(s)\nSource: Pole emploi (https://www.pole-emploi.fr)\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Scala",
                "R"
            ],
            "DataBase": [],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [
                "Spark"
            ],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [
                "Azure"
            ],
            "DevTools": [
                "Git"
            ],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [
                "Chef",
                "Airflow"
            ],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [
                "DevOps"
            ],
            "FrSoftSkills": [
                "Communication",
                "Collaboration"
            ],
            "EnSoftSkils": [
                "Communication",
                "Collaboration"
            ]
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [
                "CDI"
            ],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s",
                "5",
                "5",
                "5"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "DATA Engineer Azure F/H",
        "company": "SOFTEAM",
        "location": "\u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/data-engineer-azure-f-h-at-softeam-3839971802?position=5&pageNum=20&refId=%2FS%2FUEqH%2F4ToPDYrc6skyJQ%3D%3D&trackingId=8Q3yQextnpgvyUs%2Brm5KYg%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Vous \u00e9voluez dans le domaine de la\nData\net souhaitez int\u00e9grer un leader de la transformation num\u00e9rique sp\u00e9cialis\u00e9 dans les secteurs de la\nBanque, du\nLGuxe\n, de l'Assurance, de la Finance, de l'Energie\net la possibilit\u00e9 d'\u00e9voluer au sein du Groupe\nDocaposte\n!\nSofteam\nest labellis\u00e9 \"\nHappyIndex\u00ae AtWork\n\" 2022 pour la\n5\u00e8me\nann\u00e9e cons\u00e9cutive !\nNos collaborateurs travaillent en \u00ab\nmode projet\n\u00bb autour des\nModern DATA Platform\n\u2601 et\ntechnologies Big Data Azure Cloud / On premise\net autre \"playeur\" du march\u00e9. Nous accompagnons de bout en bout nos clients sur des probl\u00e9matiques de\nGouvernance, d\u2019Int\u00e9gration, de Visualisation et d\u2019IA\n.\nCE QUE NOUS RECHERCHONS\nSOFTEAM Data\nrecherche un(e)\nData Engineer Cloud Azure\n, disposant de solides connaissances techniques.\nCE QUE NOUS ATTENDONS DE VOUS\nEn tant que\nData Engineer Cloud Azure\n, vous concevez, mettez en place et administrez\ndes clusters et des solutions big data\n.\nVos missions d\u00e9taill\u00e9es :\nA\ncomprendre le besoin de nos clients\nau travers de missions de type : aide aux choix d\u2019outils, cadrage des besoins, POC ;\nRecueillir et analyser les besoins et proposer une architecture technique\nadapt\u00e9e aux cas d\u2019usage des clients ;\nConduire des projets de\nd\u00e9ploiement des Modern Data Platform\n(Applications Cloud Native, Migration d\u2019applications existantes) et participer \u00e0 la mise en \u0153uvre ;\nD\u00e9velopper et maintenir des cas d\u2019usages clients avec\nles outils et les infrastructures Big Data / Cloud Azure. Mod\u00e9liser et analyser des donn\u00e9es dans le Cloud\n. Garantir la s\u00e9curit\u00e9 / compliance des donn\u00e9es ;\nFournir une expertise technique approfondie\naux \u00e9quipes projets ;\nR\u00e9diger\nla documentation permettant \u00e0 l'IT d'assurer la maintenance.\nVOUS ETES\nIng\u00e9nieur(e) de formation\n, vous disposez d'une exp\u00e9rience de\n3 ans\nminimum en tant que\nData Engineer\n.\nVous avez un minimum de\n4\nann\u00e9es d\u2019exp\u00e9rience sur des\nprojets Data et id\u00e9alement au moins une premi\u00e8re exp\u00e9rience sur des projets Cloud Azure\nou \u00e0 d\u00e9faut une certification\nAzure\navec l\u2019ambition de vous pr\u00e9parer \u00e0 d\u2019autres.\nVous ma\u00eetrisez au minimum\nun langage de programmation\n(Spark, Scala, Python, Java, R) ;\nVous avez une grande aisance dans la\ncommunication orale et \u00e9crite\nalli\u00e9e \u00e0 un esprit de synth\u00e8se, de la rigueur et un tr\u00e8s bon sens de la formalisation ;\nFournir une expertise technique\napprofondie aux \u00e9quipes projets ;\nR\u00e9aliser une veille technologique\npermanente sur les tendances du march\u00e9 et les perspectives concurrentielles.\nNOUS VOUS OFFRONS\nDes\nmissions engageantes\naupr\u00e8s des\ngrands acteurs du march\u00e9\n.\nUn\nmanagement de proximit\u00e9\navec Gilles SALVADOR, Directeur du Centre d'Expertise Data, toujours bienveillant et \u00e0 l'\u00e9coute et avec qui vous pourrez\n\u00e9changer au quotidien\nsur les\nenjeux de votre mission\net \u00e9voquer vos\nfuturs projets\nafin que nous puissions vous aider \u00e0 les r\u00e9aliser.\nLa\npossibilit\u00e9 d\u2019\u00e9voluer\net de\nmonter en comp\u00e9tences\ngr\u00e2ce \u00e0 des\nformations et \u00e0 des certifications\naupr\u00e8s de nos clients et de nos consultants, des 12@13, notre Entit\u00e9 Softeam Institute, Organisme de formation interne de renomm\u00e9 qui d\u00e9livre des formations aupr\u00e8s de nos clients...\nQUI SOMMES-NOUS ?\nSOFTEAM DATA\nest une marque de\nDOCAPOSTE\nsp\u00e9cialis\u00e9e dans\nl'informatique d\u00e9cisionnelle\net les\nnouvelles technologies\n. Nous apportons notre expertise \u00e0 nos clients, principalement\ndes Grands Comptes\nde la place\nfinanci\u00e8re fran\u00e7aise\n, dans des projets de transformation digitale et cognitive.\n2000 Softeamien.nes sont d\u00e9di\u00e9.es \u00e0 la transformation m\u00e9tier et digitale de nos clients et ont g\u00e9n\u00e9r\u00e9\n200 M\u20ac de chiffre d\u2019affaires\nen 2020.\nSOFTEAM SPIRIT\nDes\ncommunaut\u00e9s d'expertises\nsur les sujets de la\nData\n;\nDe super\nnouveaux locaux\nqui sont en plus accessibles facilement ;\nUne\n\u00e9cole de formation\nint\u00e9gr\u00e9e ;\nDes\n\u00e9v\u00e8nements\n: des soir\u00e9es avec les consultants, des 12@13... ;\nUne entreprise labellis\u00e9e\n\"Happy at Work\"\npour la 5\u00e8me ann\u00e9e cons\u00e9cutive.\nN\u2019attendez plus, rejoignez SOFTEAM et venez nous rencontrer dans nos nouveaux locaux situ\u00e9s \u00e0 la D\u00e9fense #DevenezSofteamien !\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "Java",
                "Scala",
                "R",
                "Go"
            ],
            "DataBase": [],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [
                "Spark"
            ],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [
                "Azure"
            ],
            "DevTools": [
                "Git"
            ],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [
                "Big Data",
                "Cloud"
            ],
            "FrSoftSkills": [
                "Communication"
            ],
            "EnSoftSkils": [
                "Communication"
            ]
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s",
                "3",
                "3",
                "3"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "Senior Data Engineer",
        "company": "RSight\u00ae",
        "location": "\u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/senior-data-engineer-at-rsight%C2%AE-3913324068?position=6&pageNum=20&refId=%2FS%2FUEqH%2F4ToPDYrc6skyJQ%3D%3D&trackingId=tY%2FcpQNsIOvXDKVnH0msxA%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Nous recherchons activement un(e)\nData Engineer confirm\u00e9\n, pour le compte de l\u2019un de nos clients,\nune ESN, leader de l\u2019Ing\u00e9nierie et du Conseil en Technologies\n. Vous interviendrez sur des\nprojets \u00e0 forte valeur ajout\u00e9e\nd\u2019une\nLeader mondial du secteur de la r\u00e9assurance\n.\nResponsabilit\u00e9s\nConstruire, livrer et maintenir les produits de donn\u00e9es (pipelines de donn\u00e9es, services, APIs...).\nCollaborer \u00e9troitement avec les \u00e9quipes produits pour d\u00e9velopper de nouvelles fonctionnalit\u00e9s li\u00e9es aux produits, notamment les fonctionnalit\u00e9s li\u00e9es :\nAu pipelinage des donn\u00e9es au sein ou entre plusieurs produits.\nAux capacit\u00e9s d\n\u2019\nanalyse et de data warehousing pour l\n\u2019\nexploration des donn\u00e9es, la science des donn\u00e9es et la BI.\nAu calcul parall\u00e8le sur de grands volumes de donn\u00e9es.\nD\u00e9velopper des artefacts ou fonctionnalit\u00e9s de donn\u00e9es (pipelines de donn\u00e9es, services de donn\u00e9es, APIs...) en suivant des mod\u00e8les de pointe (architecture Medaillon, gitflow).\nConseiller sur l\n\u2019\narchitecture des flux de donn\u00e9es de bout en bout.\nCollaborer avec divers intervenants (propri\u00e9taires de produits, propri\u00e9taires de solutions, analystes de solutions de donn\u00e9es, d\u00e9veloppeurs, chefs techniques, architectes) pour livrer des artefacts de donn\u00e9es dans un esprit d\n\u2019\n\u00e9quipe.\nComp\u00e9tences requises\nPython, SQL, Databricks, Palantir Foundry, DataViz : Expert\nMSDevOps, Jenkins, Artifactory, Container Registry : Confirm\u00e9\nTechnique de parall\u00e9lisation, programmation distribu\u00e9e : Confirm\u00e9\nDelta Lake, architecture Medaillon, blobStorage, fileshare : Confirm\u00e9\nComp\u00e9tences humaines\nOrientation vers la r\u00e9solution de probl\u00e8mes avec une forte pens\u00e9e analytique.\nAutonomie et rigueur dans la mani\u00e8re d\n\u2019\naborder les d\u00e9fis techniques.\nAptitude \u00e0 conseiller sur l\n\u2019\narchitecture des flux de donn\u00e9es.\nCapacit\u00e9 \u00e0 collaborer avec divers intervenants pour atteindre les objectifs dans un esprit d\n\u2019\n\u00e9quipe.\nB\u00e9n\u00e9fices\nOpportunit\u00e9 de travailler sur des projects d\n\u2019\nenvergure.\nUn processus de recrutement court, un accompagnement personnalis\u00e9, une \u00e9volution qui s\n\u2019\nadapte \u00e0 votre trajectoire de carri\u00e8re.\nEn plus de votre quotidien li\u00e9 \u00e0 votre mission, vous pourrez entreprendre, \u00eatre form\u00e9, passer des certifications.\nUn environnement de collaboration positif o\u00f9 chacun est valoris\u00e9 et int\u00e9gr\u00e9.\nUne culture forte et bienveillante, et une grande place laiss\u00e9e \u00e0 la libert\u00e9.\nLa diversit\u00e9 et l\n\u2019\nenvergure des projets.\nUne approche pragmatique, qui r\u00e9pond aux vrais enjeux des entreprises.\nUne \u00e9quipe d\u2019ing\u00e9nieurs anim\u00e9e par l\u2019innovation dans un environnement collaboratif h\u00e9t\u00e9rog\u00e8ne et inclusif.\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "R"
            ],
            "DataBase": [
                "SQL"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [
                "Databricks"
            ],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [],
            "DevTools": [
                "Git",
                "Jenkins"
            ],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [
                "Chef"
            ],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [
                "DevOps"
            ],
            "FrSoftSkills": [
                "R\u00e9solution de probl\u00e8mes",
                "Collaboration"
            ],
            "EnSoftSkils": [
                "Collaboration"
            ]
        },
        "details": {
            "JobDetail": [
                "Confirm\u00e9"
            ],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "Data Engineer",
        "company": "MindPal",
        "location": "Marseille, Provence-Alpes-C\u00f4te d'Azur, France",
        "link": "https://fr.linkedin.com/jobs/view/data-engineer-at-mindpal-3914442063?position=7&pageNum=20&refId=%2FS%2FUEqH%2F4ToPDYrc6skyJQ%3D%3D&trackingId=spIKVJhzAUv59XOxHP8m1w%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "We are looking for\nData Engineer!\nResponsibilities\nDesigning, creating, and maintaining data processing systems\nAnalyzing and optimizing data processing workflows\nCollaborating with the team to ensure data quality and efficiency\nTesting and implementing new solutions\nRequirements\nAt least 2 years of experience in designing and creating data processing systems\nProficiency in tools and programming languages related to data engineering (e.g. Hadoop, Spark, Scala, Python)\nExcellent knowledge of databases and SQL language\nAbility to work in a team and communicate effectively with other departments\nCommunicative English skills\nExperience with AWS/AWS Glue is a plus\nWe Offer\nB2B contract\nFull-time job\nRemote work and flexible hours\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "Scala",
                "R"
            ],
            "DataBase": [
                "SQL"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [
                "Hadoop",
                "Spark"
            ],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [
                "AWS"
            ],
            "DevTools": [],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [],
            "FrSoftSkills": [],
            "EnSoftSkils": []
        },
        "details": {
            "JobDetail": [
                "Remote",
                "Full"
            ],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "DATA Engineer GCP F/H",
        "company": "SOFTEAM",
        "location": "\u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/data-engineer-gcp-f-h-at-softeam-3852605158?position=8&pageNum=20&refId=%2FS%2FUEqH%2F4ToPDYrc6skyJQ%3D%3D&trackingId=WcFAXjIUmdRk9lGYaUhJog%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Vous \u00e9voluez dans le domaine de la\nData\net souhaitez int\u00e9grer un leader de la transformation num\u00e9rique sp\u00e9cialis\u00e9 dans les secteurs de la\nBanque, du Luxe, de l'Assurance, de la Finance, de l'Energie\net la possibilit\u00e9 d'\u00e9voluer au sein du Groupe\nDocaposte\n!\nSofteam\nest labellis\u00e9 \"\nHappyIndex\u00ae AtWork\n\" 2022 pour la\n5\u00e8me\nann\u00e9e cons\u00e9cutive !\nNos collaborateurs travaillent en \u00ab\nmode projet\n\u00bb autour des\nModern DATA Platform\n\u2601 et\ntechnologies Big Data Azure Cloud / On premise\net autre \"playeur\" du march\u00e9. Nous accompagnons de bout en bout nos clients sur des probl\u00e9matiques de\nGouvernance, d\u2019Int\u00e9gration, de Visualisation et d\u2019IA\n.\nCE QUE NOUS RECHERCHONS\nSOFTEAM Data\nrecherche un(e)\nData Engineer Cloud GCP\n, disposant de solides connaissances techniques.\nCE QUE NOUS ATTENDONS DE VOUS\nEn tant que\nData Engineer Cloud GCP\n, vous concevez, mettez en place et administrez\ndes clusters et des solutions big data\n.\nVos missions d\u00e9taill\u00e9es :\nA\ncomprendre le besoin de nos clients\nau travers de missions de type : aide aux choix d\u2019outils, cadrage des besoins, POC ;\nRecueillir et analyser les besoins et proposer une architecture technique\nadapt\u00e9e aux cas d\u2019usage des clients ;\nConduire des projets de\nd\u00e9ploiement des Modern Data Platform\n(Applications Cloud Native, Migration d\u2019applications existantes) et participer \u00e0 la mise en \u0153uvre ;\nD\u00e9velopper et maintenir des cas d\u2019usages clients avec\nles outils et les infrastructures Big Data / Cloud GCP. Mod\u00e9liser et analyser des donn\u00e9es dans le Cloud\n. Garantir la s\u00e9curit\u00e9 / compliance des donn\u00e9es ;\nFournir une expertise technique approfondie\naux \u00e9quipes projets ;\nR\u00e9diger\nla documentation permettant \u00e0 l'IT d'assurer la maintenance.\nVOUS ETES\nIng\u00e9nieur(e) de formation\n, vous disposez d'une exp\u00e9rience de\n3 ans\nminimum en tant que\nData Engineer\n.\nVous avez un minimum de\n4\nann\u00e9es d\u2019exp\u00e9rience sur des\nprojets Data et id\u00e9alement au moins une premi\u00e8re exp\u00e9rience sur des projets Cloud GCP\n(Compute, Stockage), ou \u00e0 d\u00e9faut une certification GCP avec l\u2019ambition de vous pr\u00e9parer \u00e0 d\u2019autres.\nVous ma\u00eetrisez au minimum\nun langage de programmation\n(Spark, Scala, Python, Java, R) ;\nVous avez une grande aisance dans la\ncommunication orale et \u00e9crite\nalli\u00e9e \u00e0 un esprit de synth\u00e8se, de la rigueur et un tr\u00e8s bon sens de la formalisation ;\nFournir une expertise technique\napprofondie aux \u00e9quipes projets ;\nR\u00e9aliser une veille technologique\npermanente sur les tendances du march\u00e9 et les perspectives concurrentielles.\nNOUS VOUS OFFRONS\nDes\nmissions engageantes\naupr\u00e8s des\ngrands acteurs du march\u00e9\n.\nUn\nmanagement de proximit\u00e9\navec Gilles SALVADOR, Directeur du Centre d'Expertise Data, toujours bienveillant et \u00e0 l'\u00e9coute et avec qui vous pourrez\n\u00e9changer au quotidien\nsur les\nenjeux de votre mission\net \u00e9voquer vos\nfuturs projets\nafin que nous puissions vous aider \u00e0 les r\u00e9aliser.\nLa\npossibilit\u00e9 d\u2019\u00e9voluer\net de\nmonter en comp\u00e9tences\ngr\u00e2ce \u00e0 des\nformations et \u00e0 des certifications\naupr\u00e8s de nos clients et de nos consultants, des 12@13, notre Entit\u00e9 Softeam Institute, Organisme de formation interne de renomm\u00e9 qui d\u00e9livre des formations aupr\u00e8s de nos clients...\nQUI SOMMES-NOUS ?\nSOFTEAM DATA\nest une marque de\nDOCAPOSTE\nsp\u00e9cialis\u00e9e dans\nl'informatique d\u00e9cisionnelle\net les\nnouvelles technologies\n. Nous apportons notre expertise \u00e0 nos clients, principalement\ndes Grands Comptes\nde la place\nfinanci\u00e8re fran\u00e7aise\n, dans des projets de transformation digitale et cognitive.\n2000 Softeamien.nes sont d\u00e9di\u00e9.es \u00e0 la transformation m\u00e9tier et digitale de nos clients et ont g\u00e9n\u00e9r\u00e9\n200 M\u20ac de chiffre d\u2019affaires\nen 2020.\nSOFTEAM SPIRIT\nDes\ncommunaut\u00e9s d'expertises\nsur les sujets de la\nData\n;\nDe super\nnouveaux locaux\nqui sont en plus accessibles facilement ;\nUne\n\u00e9cole de formation\nint\u00e9gr\u00e9e ;\nDes\n\u00e9v\u00e8nements\n: des soir\u00e9es avec les consultants, des 12@13... ;\nUne entreprise labellis\u00e9e\n\"Happy at Work\"\npour la 5\u00e8me ann\u00e9e cons\u00e9cutive.\nN\u2019attendez plus, rejoignez SOFTEAM et venez nous rencontrer dans nos nouveaux locaux situ\u00e9s \u00e0 la D\u00e9fense #DevenezSofteamien !\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "Java",
                "Scala",
                "R",
                "Go"
            ],
            "DataBase": [],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [
                "Spark"
            ],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [
                "Azure"
            ],
            "DevTools": [
                "Git"
            ],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [
                "Big Data",
                "Cloud"
            ],
            "FrSoftSkills": [
                "Communication"
            ],
            "EnSoftSkils": [
                "Communication"
            ]
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s",
                "3",
                "3",
                "3"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "Ing\u00e9nieur Data Talend (F/H)",
        "company": "Thales",
        "location": "V\u00e9lizy-Villacoublay, \u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/ing%C3%A9nieur-data-talend-f-h-at-thales-3890948785?position=9&pageNum=20&refId=%2FS%2FUEqH%2F4ToPDYrc6skyJQ%3D%3D&trackingId=pENNDDIYneLegG1YTnqB5g%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "QUI SOMMES-NOUS ?\nThales est un leader mondial des hautes technologies comptant plus de 81 000 collaborateurs pr\u00e9sents sur tous les continents. Le Groupe investit dans les innovations du num\u00e9rique et de la \u00ab deep tech \u00bb \u2013 big data, intelligence artificielle, connectivit\u00e9, cybers\u00e9curit\u00e9 et quantique \u2013 pour construire un avenir de confiance, essentiel au d\u00e9veloppement de nos soci\u00e9t\u00e9s, en pla\u00e7ant l\u2019humain au c\u0153ur des d\u00e9cisions.\nThales propose des solutions, services et produits qui aident ses clients \u2013 entreprises, organisations, Etats \u2013 dans cinq grands march\u00e9s vitaux pour le fonctionnement de nos soci\u00e9t\u00e9s : identit\u00e9 et s\u00e9curit\u00e9 num\u00e9riques, d\u00e9fense, a\u00e9ronautique, espace, et transport.\nQUI ETES-VOUS ?\nDipl\u00f4m\u00e9 d\u2019un Bac+5 en \u00e9cole d\u2019ing\u00e9nieur ou \u00e9quivalent universitaire avec une sp\u00e9cialisation en informatique, vous avez au moins 3 ans d'exp\u00e9rience dans les technologies Big Data.\nCE QUE NOUS POUVONS ACCOMPLIR ENSEMBLE :\nEn tant que Data Engineer, vous jouerez un r\u00f4le cl\u00e9 dans la conception, le d\u00e9veloppement et la maintenance de notre infrastructure de donn\u00e9es, ainsi que dans la transformation et la gestion des flux de donn\u00e9es.\nVOS MISSIONS :\n\u2022 Concevoir, d\u00e9velopper et d\u00e9ployer des solutions Big Data en utilisant les technologies Talend.\n\u2022 Mettre en place des pipelines de donn\u00e9es performants pour l'ingestion, le traitement et le stockage des donn\u00e9es massives.\n\u2022 Collaborer \u00e9troitement avec les \u00e9quipes m\u00e9tier pour comprendre leurs besoins en mati\u00e8re d'analyse de donn\u00e9es et proposer des solutions adapt\u00e9es.\n\u2022 Optimiser les performances des clusters Hadoop pour garantir une exploitation efficace des donn\u00e9es.\n\u2022 Assurer la qualit\u00e9 et la fiabilit\u00e9 des donn\u00e9es trait\u00e9es, en mettant en place des processus de validation et de nettoyage.\n\u2022 Identifier et r\u00e9soudre les probl\u00e8mes li\u00e9s \u00e0 l'infrastructure Big Data et proposer des am\u00e9liorations.\n\u2022 Travailler en \u00e9troite collaboration avec les Data Scientists et les Data Analysts pour fournir des insights pertinents \u00e0 partir des donn\u00e9es.\nInnovation, passion, ambition : rejoignez Thales et cr\u00e9ez le monde de demain, d\u00e8s aujourd\u2019hui.\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "R"
            ],
            "DataBase": [],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [
                "Hadoop"
            ],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [],
            "DevTools": [],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [
                "Big Data"
            ],
            "FrSoftSkills": [
                "Collaboration",
                "Organisation"
            ],
            "EnSoftSkils": [
                "Collaboration"
            ]
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [],
            "Salary": [],
            "Level": [
                "Bac+5"
            ],
            "Experience": [
                "a",
                "n",
                "s",
                "3",
                "3",
                "3"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "Tech Lead Data Engineer",
        "company": "AXA en France",
        "location": "Hauts-de-Seine, \u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/tech-lead-data-engineer-at-axa-en-france-3905641945?position=10&pageNum=20&refId=%2FS%2FUEqH%2F4ToPDYrc6skyJQ%3D%3D&trackingId=8BK0UmBOqb%2Be1Wnkmtu6Tw%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Environnement\nEn tant que\nTech Lead Data Engineer F/H\n, vous allez contribuer directement aux projets des directions m\u00e9tier (ex : fraude sant\u00e9, multi\u00e9quipements, pricing IARD, optimisation du lead management, fragilit\u00e9 auto, \u2026) d\u2019AXA France et \u00e0 la construction du socle technique Big Data.\nVous allez int\u00e9grer une \u00e9quipe d'une dizaine de personne compos\u00e9e de Data Engineer et des Tech Lead travaillant en mode Feature Team au sein des tribus m\u00e9tier de la Direction Transformation Digital Tech et DATA (DT2).\nLa Direction Transfo. & Tech. d'AXA France en quelques mots :\nUne organisation agile en feature teams : tribus, guildes, squads\nDes projets sur des applications innovantes \u00e0 fort trafic (web, mobile\u2026)\nDes m\u00e9thodologies craft (TDD, BDD, clean code, code review\u2026) et DevOps\nUne communaut\u00e9 de partage de bonnes pratiques (BBL, dojo, meetup, conf\u2026)\nVotre r\u00f4le et vos missions\nVous aurez pour missions principales de d\u00e9velopper les projets Big Data demand\u00e9s par le m\u00e9tier, et notamment :\nD\u2019accompagner techniquement les Data Engineer de l\u2019\u00e9quipe (coaching, code review, pair programming\u2026)\nPasser de la donn\u00e9e brute \u00e0 de la donn\u00e9e exploitable, expos\u00e9e sous forme de tables requ\u00eatables dans le datalake\nConsolider ces donn\u00e9es au fur et \u00e0 mesure de leur alimentation r\u00e9currente dans le data lake\nLes exploiter pour atteindre la finalit\u00e9 business (exposition de business view, r\u00e9int\u00e9gration des r\u00e9sultats dans le SI, service de scoring, \u2026)\nDe travailler \u00e0 la cr\u00e9ation du socle technique Big Data et industrialiser le cycle de d\u00e9veloppement de l'\u00e9quipe\nDe mettre en place et de garantir le respect dans la dur\u00e9e d'un processus qualit\u00e9 sur l'ensemble du cycle de DEV (documents, tests unitaires / int\u00e9gration / fonctionnels, commentaires, versionning, etc.)\nVotre profil\nD'une formation sup\u00e9rieure en informatique ou scientifique (Master ou Dipl\u00f4me d'ing\u00e9nieur), vous justifiez de plusieurs exp\u00e9riences significatives (+ de 7 ans)\nsur du d\u00e9veloppement big data, en particulier sur du PySpark.\nComp\u00e9tences techniques :\nConnaissances avanc\u00e9es en d\u00e9veloppement en\nPySpark (Spark avec le langage Python)\nMaitrise de l'environnement\nMicrosoft Azure\nConnaissances avanc\u00e9es d'outils de BI comme\nPowerBI\nComp\u00e9tences transverses :\nCapacit\u00e9 \u00e0 interagir avec des parties prenantes diverses : Business analyst, Architectes, M\u00e9tier\nExp\u00e9rience en mode de delivery Agile (Scrum, Kanban, etc...)\nDriver et accompagner des Data Engineer sur le plan op\u00e9rationnel\nEt Id\u00e9alement :\nAvoir une exp\u00e9rience en tant que lead\nDes Connaissances sur Azure DevOps, Azure Pipeline, GIT, JIRA\nMaitrise des Traitements Big Data en mode Streaming avec Kafka\nMaitrise des Bases de donn\u00e9es relationnelles et NoSQL\nUne exp\u00e9rience professionnelle avec des outils comme Azure Databricks, Azure Data Lake Storage ou encore Azure Data Factory\nMais pourquoi AXA France ?\nNous sommes persuad\u00e9s que pour bien prendre soin de nos clients, nous devons commencer par bien prendre soin de nos collaborateurs ! Les avantages que nous proposons \u00e0 nos salari\u00e9s sont nombreux.\nNous choisir, c\u2019est b\u00e9n\u00e9ficier par exemple :\nD\u2019un package de r\u00e9mun\u00e9ration complet comprenant un salaire fixe, un compl\u00e9ment de r\u00e9mun\u00e9ration variable, des primes, de la participation et de l\u2019int\u00e9ressement, la possibilit\u00e9 d\u2019acqu\u00e9rir des actions AXA, ou encore des solutions d\u2019\u00e9pargne avantageuses ;\nEquilibre vie Pro / Perso. : D\u2019un cadre de travail flexible jusqu\u2019\u00e0 3 jours de t\u00e9l\u00e9travail possible par semaine, des tickets restaurant pour les jours t\u00e9l\u00e9travaill\u00e9s ou encore une participation \u00e0 l\u2019achat d\u2019un \u00e9cran ou fauteuil ergonomique ;\nD\u2019une politique visant \u00e0 concilier vie personnelle et vie professionnelle avec 28 jours de cong\u00e9s pay\u00e9s, entre 14 et 16 RTT selon les ann\u00e9es, des formules de travail \u00e0 temps partiel ou encore des jours d\u2019absence r\u00e9mun\u00e9r\u00e9es pour la rentr\u00e9e scolaire ou un d\u00e9m\u00e9nagement par exemple ;\nDe la possibilit\u00e9 de s\u2019engager pour une cause qui vous tient \u00e0 c\u0153ur gr\u00e2ce \u00e0 nos associations telles que AXA Atout C\u0153ur, AXA Comp\u00e9tences Solidaires ou encore AXA Pr\u00e9vention ;\nEt bien plus encore ! Perspectives de d\u00e9veloppement des comp\u00e9tences et de carri\u00e8res immenses, CE, conciergerie, offres privil\u00e8ges, soutien en cas d\u2019\u00e9preuve personnelle\u2026On s\u2019arr\u00eate l\u00e0, la liste est longue\nQui sommes nous ?\nAXA est un des leaders de l\u2019assurance et de la gestion d\u2019actifs dans le monde.\nNous aidons nos 108 millions de clients \u00e0 traverser les petites et grandes difficult\u00e9s de la vie.\nChaque jour, nous agissons ensemble pour inventer la meilleure mani\u00e8re de les prot\u00e9ger et voulons donner \u00e0 chacun les moyens de vivre une vie meilleure.\nUn challenge qui donne le sourire et envie de se lever le matin !\nChez AXA, nous sommes persuad\u00e9s que pour bien prendre soin de nos clients, nous devons commencer par bien prendre soin de nos collaborateurs. C\u2019est pour cette raison que nous menons une politique RH engag\u00e9e qui favorise la diversit\u00e9, qui pr\u00e9serve l\u2019\u00e9quilibre vie priv\u00e9e-vie professionnelle et acc\u00e9l\u00e8re le d\u00e9veloppement des comp\u00e9tences et des carri\u00e8res.\nAinsi, en rejoignant AXA France vous travaillerez dans une entreprise responsable, offrant une v\u00e9ritable culture d\u2019expertise, acc\u00e9l\u00e9rant le d\u00e9veloppement des comp\u00e9tences de chacun et proposant une r\u00e9mun\u00e9ration attractive.\nPourquoi nous rejoindre ?\nVous \u00eates porteur d\u2019id\u00e9es et d\u2019initiatives innovantes ? Vous proposez des solutions et \u00eates au service du client ? Faites partie de notre grande famille en rejoignant\nUn leader mondial offrant des opportunit\u00e9s de carri\u00e8res int\u00e9ressantes\nUne entreprise qui donne une place de choix \u00e0 l\u2019innovation, \u00e0 l\u2019initiative et aux actions solidaires (notamment via l\u2019association AXA Atout C\u0153ur)\nUn environnement inclusif \u00e0 tous les niveaux (mixit\u00e9, handicap, initiatives pour favoriser l\u2019insertion des jeunes, orientation sexuelle, etc.)\nUn acc\u00e8s \u00e0 de multiples avantages (cong\u00e9s, temps partiel, t\u00e9l\u00e9travail, etc.)\nUn cadre stimulant, qui permet de rencontrer des collaborateurs performants et d\u2019enrichir ses comp\u00e9tences\nVictime ou t\u00e9moin, en cas de discrimination, vous pouvez adresser vos signalements et/ou alertes discrimination \u00e0 alerte.discrimination.harcelement@axa.fr\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "R",
                "Go"
            ],
            "DataBase": [
                "SQL",
                "NoSQL"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [
                "Spark",
                "Databricks"
            ],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [
                "PowerBI"
            ],
            "Statistics": [],
            "CloudComputing": [
                "Azure"
            ],
            "DevTools": [
                "Git"
            ],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [
                "JIRA",
                "Teams"
            ],
            "Other": [
                "DevOps",
                "Big Data"
            ],
            "FrSoftSkills": [
                "Organisation"
            ],
            "EnSoftSkils": [
                "Initiative"
            ]
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [],
            "Salary": [
                "3",
                "3"
            ],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s",
                "7",
                "7",
                "7"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "Data Engineer (Cloud Azure) - Confirm\u00e9 F/H",
        "company": "VISEO",
        "location": "Boulogne-Billancourt, \u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/data-engineer-cloud-azure-confirm%C3%A9-f-h-at-viseo-3904219460?position=1&pageNum=22&refId=xJ%2FHB6j7MCr9%2BdBcMIDMwQ%3D%3D&trackingId=zf%2FExEFZwQw2YJkORJaEPA%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Rejoignez\nVISEO\net explorez un univers de possibilit\u00e9s o\u00f9\nl'Humain\n, le\nCollectif\net le\nChallenge\nsont au c\u0153ur de notre ADN.\nQui \u00eates-vous ?\nSi pour vous \u00eatre\nData Engineer Cloud Azure Confirm\u00e9 F/H\n, c'est :\nFaire partie d'une communaut\u00e9 d'experts en ing\u00e9nierie des donn\u00e9es et en solutions cloud ;\nConcevoir, construire et maintenir des pipelines de donn\u00e9es robustes et \u00e9volutifs sur Microsoft Azure ;\nMa\u00eetriser les services Azure tels que Azure Data Factory, Azure Data Lake, Azure SQL Database, et Azure Synapse Analytics ;\nD\u00e9couvrir les nouveaut\u00e9s tel que Microsoft Fabric\nAppliquer les meilleures pratiques en mati\u00e8re de s\u00e9curit\u00e9, de qualit\u00e9 des donn\u00e9es et de gouvernance de l'information ;\n\u00catre familiaris\u00e9 avec les technologies de transformation de donn\u00e9es \u00e0 grande \u00e9chelle (Spark, Azure Databricks) ;\nCollaborer \u00e9troitement avec les \u00e9quipes BI et analytics pour transformer les donn\u00e9es en insights pr\u00e9cieux...\nAlors, vous \u00eates le talent que nous recherchons !\nSi vous avez une solide exp\u00e9rience en tant que\nData Engineer\n, une passion pour le cloud\nAzure\net que vous \u00eates pr\u00eat \u00e0 \u00e9largir vos comp\u00e9tences et \u00e0 avancer dans votre carri\u00e8re, c'est le moment parfait pour nous rejoindre.\nCe que nous allons faire ensemble ?\nD\u00e9couvrez comment votre quotidien sera transform\u00e9 en rejoignant l\u2019\u00e9quipe projet de Nabil. Rattach\u00e9 \u00e0 notre agence de Boulogne-Billancourt, vous pourrez :\nAccompagner et conseiller le client dans son adoption des Modern Data Platform dans Azure (Etude d\u2019architecture, pr\u00e9paration des DAT, FinOps, DevOps) ;\nConcevoir des architectures Cloud Data exploitant efficacement les services de donn\u00e9es manag\u00e9s d'Azure ;\nConduire des projets de d\u00e9ploiement des Modern Data Platform (Applications Cloud Native, Migration d\u2019applications existantes) et participer \u00e0 la mise en \u0153uvre ;\nEtablir des relations de confiance avec les d\u00e9cisionnaires techniques et m\u00e9tiers afin de favoriser l\u2019adoption du Cloud Microsoft Azure \u00e0 long terme au sein de l\u2019entreprise ;\nR\u00e9aliser une veille technologique permanente sur les tendances du march\u00e9 et les perspectives concurrentielles ;\nPartager votre expertise et apprendre continuellement au sein d'une \u00e9quipe anim\u00e9e par l'innovation.\nCe que nous avons \u00e0 vous offrir ?\nDes formations, des certifications Azure et un syst\u00e8me de mentoring ;\nUn environnement stimulant, souple et agile pour des parcours sans limite ;\nUn engagement fort pour l\u2019environnement, la soci\u00e9t\u00e9, l\u2019\u00e9galit\u00e9 et l\u2019inclusion\u202f: la plateforme Vendredi, atelier fresque du climat, Caf\u00e9 Joyeux, l'institut Imagine, Yumaincap...\nUne organisation flexible pour un bon \u00e9quilibre vie pro / vie perso.\nCe qui nous diff\u00e9rencie ?\nUne communaut\u00e9 engag\u00e9e d'experts en data et cloud Azure : des talks toutes les semaines, la participation \u00e0 des \u00e9v\u00e8nements techniques (ateliers, rencontres d\u2019experts, Tech An Hour, BBL, Rex, Sponsoring\u2026) ;\nDes dispositifs collectifs d\u2019\u00e9pargne salariale\u202f(PEE et PERECO) et la possibilit\u00e9 de devenir actionnaire VISEO ;\nUn partenariat privil\u00e9gi\u00e9 avec Microsoft (Gold Partner) vous donnant acc\u00e8s aux derni\u00e8res innovations et technologies Azure.\nEnvie de nous rejoindre ? Contactez-nous et faites partie du #VISEOspirit\nEn tant qu'employeur, VISEO promeut activement la diversit\u00e9 et l'inclusion.\n\u00c0 propos de VISEO\nAvec plus de 3 000 collaborateurs r\u00e9partis sur 5 continents, VISEO allie agilit\u00e9 et expertise technique pour faire du digital un moteur essentiel de comp\u00e9titivit\u00e9 et de performance.\n#PositiveDigitalMakers\nGDPR MESSAGE:\nOur privacy policy has been updated to comply with the new regulations. We invite you to consult it by clicking here: https://www.viseo.com/fr/politique-de-confidentialite. The VISEO Group uses the data collected as part of your application to assess your suitability for the job in question. We use the Jazz HR tool to help us in our recruitment process. This tool complies with current regulations on the protection of personal data. The tool is hosted in the United States and is PrivacyShield certified for HR data. In all cases, we may keep your file for 5 years so that we can contact you again if another position matches your profile. You may, of course, object to this. To find out more about how your data is used and how you can exercise your rights, please consult our privacy policy https://www.viseo.com/fr/politique-de-confidentialite.\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "R",
                "Go"
            ],
            "DataBase": [
                "SQL"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [
                "Spark",
                "Databricks"
            ],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [
                "Azure"
            ],
            "DevTools": [
                "Git"
            ],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [
                "DevOps",
                "Cloud"
            ],
            "FrSoftSkills": [
                "Organisation"
            ],
            "EnSoftSkils": []
        },
        "details": {
            "JobDetail": [
                "Confirm\u00e9"
            ],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "Lead Data & Cloud Engineer (H/F)",
        "company": "fifty-five",
        "location": "Paris, \u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/lead-data-cloud-engineer-h-f-at-fifty-five-3910829083?position=2&pageNum=22&refId=xJ%2FHB6j7MCr9%2BdBcMIDMwQ%3D%3D&trackingId=8bM2m%2FNdFrusnjgAx55njQ%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "fifty-five est une data-company d'un genre nouveau qui aide les marques \u00e0 exploiter les donn\u00e9es pour am\u00e9liorer le marketing, les m\u00e9dias et l'exp\u00e9rience client gr\u00e2ce \u00e0 une combinaison de services de conseil et de technologie sp\u00e9cialis\u00e9s.\nEn tant que pilier data et marketing du Brandtech Group, nous offrons des services qui combinent le conseil en strat\u00e9gie, les services de cloud, le conseil en m\u00e9dia et l'exp\u00e9rience client.\nfifty-five, c'est plus de 400 experts du num\u00e9rique. Des digital consultants, des sp\u00e9cialistes du tracking et du m\u00e9dia, des ing\u00e9nieurs et des data scientists, travaillent tous en \u00e9troite collaboration pour fournir des conseils marketing de haut niveau et une assistance technique aux marques, dans tout type d'industrie, partout dans le monde.\nPartenaire des annonceurs de la collecte \u00e0 l'activation et l'exploitation des donn\u00e9es, nous aidons les organisations \u00e0 devenir de v\u00e9ritables entit\u00e9s omnicanales ma\u00eetrisant l'efficacit\u00e9 de leur \u00e9cosyst\u00e8me digital et ses synergies avec le monde physique.\nBas\u00e9 \u00e0 Paris, nous op\u00e9rons sur 3 fuseaux horaires depuis nos 10 bureaux, situ\u00e9s \u00e0 Paris, Londres, Gen\u00e8ve, Milan, Shanghai, Hong Kong, Shenzhen, Taipei, Singapour et New York. fifty-five attache une importance particuli\u00e8re au bien-\u00eatre de ses collaborateurs, ce qui lui a permis de figurer dans le classement Best Workplaces France en 2018.\nContexte :\nL'\u00e9quipe d'ing\u00e9nierie d\u00e9veloppe et met en oeuvre les solutions techniques permettant la r\u00e9alisation de pipelines de donn\u00e9es et de datalake pour nos clients : r\u00e9cup\u00e9ration de datas sur de multiples sources de donn\u00e9es (APIs, files, etc.), data cleaning, data processing, automation et monitoring de l'ensemble. L'\u00e9quipe s'appuie sur des technologies r\u00e9centes (docker, kubernetes, terraform, notebooks, etc.) et met en place ses projets dans les diff\u00e9rents clouds du march\u00e9 (GCP, Azure, AWS...).\nMission :\nNous sommes \u00e0 la recherche d'une personne capable de r\u00e9aliser des projets techniques pour r\u00e9pondre aux besoins de nos clients (par exemple: syst\u00e8me de recommandations de produits, d\u00e9tection d'anomalies, ranking). Les activit\u00e9s vont du chiffrage et du sizing technique \u00e0 la mise en \u0153uvre des architectures, en passant par la revue des sp\u00e9cifications fonctionnelles et la production de code.\nLe Data & Cloud Lead g\u00e8re une \u00e9quipe d'environ 4 Data & Cloud Engineer qu'il accompagne au quotidien (suivi des t\u00e2ches, validation des livrables, code review, suivi de la formation, etc.). Le Data & Cloud Lead intervient \u00e9galement directement sur les missions, principalement dans les discussions avec nos clients (recueil des contraintes techniques, validation d'architecture, etc.) mais aussi dans le delivery (d\u00e9ploiement d'infrastructure participation au code). Il sera \u00e9galement amen\u00e9 \u00e0 participer \u00e0 la R&D et \u00e0 accompagner les \u00e9quipes transverses dans la mise en place d'outils de travail internes (librairies pour les data scientists, environnement Notebooks pour les data analysts et data scientists, d\u00e9veloppement de frameworks sur diff\u00e9rents cloud providers, etc.).\nPassionn\u00e9.e par la data et le cloud ? Envie de partager tes connaissances et faire grandir des profils plus juniors ? Envie de collaborer avec des profils experts, aussi bien c\u00f4t\u00e9 technique (Data, Cloud, DevOps, Data Science, etc.) que business (digital marketing, analytics, media, CRM, CDP, etc.) ? N'h\u00e9site plus et postule !\nComp\u00e9tences et exp\u00e9riences :\n5 ans d'exp\u00e9rience avec une premi\u00e8re exp\u00e9rience professionnelle en tant que Lead et/ou Architecte\nMa\u00eetrise des architectures data\nMa\u00eetrise de Python et SQL\nMa\u00eetrise des environnements Cloud. Certifi\u00e9 sur GCP, Azure ou AWS\nMa\u00eetrise d'au moins un data warehouse (BigQuery, Snowflake, etc)\nMa\u00eetrise des concepts li\u00e9s aux APIs (OAuth, REST, etc.)\nBonne connaissance de Docker\nA l'aise avec les notions d'Infrastructure as Code (Terraform)\nA l'aise avec les pratiques GitOps et les concepts autour du CI/CD\nConnaissance autour des Notebooks (Jupyter)\nLa ma\u00eetrise d'un orchestrateur,comme Apache Airflow, est un plus\nEsprit d'\u00e9quipe (collaborer aux tests unitaires, revue de code, partage de code, sprints)\nBon niveau en fran\u00e7ais et en anglais\nA d\u00e9j\u00e0 travaill\u00e9 en mode projet avec des interlocuteurs vari\u00e9s (consultant, data analyst, data scientist), id\u00e9alement client facing\nUne exp\u00e9rience en marketing digital est un plus\nNous proposons :\nun bureau au centre de Paris avec terrasse et jardin\nun environnement multiculturel avec des collaborateurs aux nationalit\u00e9s multiples (France, Royaume-Uni, Etats-Unis, Chine, Tunisie, Italie et plus)\ndes projets avec nos bureaux \u00e0 Londres, Hong Kong, New York, Shanghai, Gen\u00e8ve, Shenzhen et Taipei\ndes TGIF et supers soir\u00e9es\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "R"
            ],
            "DataBase": [
                "SQL"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [
                "Apache Airflow"
            ],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [
                "AWS",
                "Azure"
            ],
            "DevTools": [
                "Git",
                "Docker"
            ],
            "Os": [],
            "DBMS": [
                "Snowflake",
                "Snowflake",
                "BigQuery"
            ],
            "SoftBigDataProcessing": [],
            "Automation": [
                "Kubernetes",
                "Airflow"
            ],
            "InfrastructureAsCode": [
                "Terraform"
            ],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [
                "Docker",
                "Kubernetes"
            ],
            "Collaboration": [],
            "Other": [
                "DevOps",
                "Cloud",
                "CI/CD"
            ],
            "FrSoftSkills": [
                "Collaboration",
                "Organisation"
            ],
            "EnSoftSkils": [
                "Collaboration"
            ]
        },
        "details": {
            "JobDetail": [
                "Junior"
            ],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s",
                "5",
                "5",
                "5"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "Data Ing\u00e9nieur H/F",
        "company": "Alteca",
        "location": "Toulouse, Occitanie, France",
        "link": "https://fr.linkedin.com/jobs/view/data-ing%C3%A9nieur-h-f-at-alteca-3846531570?position=3&pageNum=22&refId=xJ%2FHB6j7MCr9%2BdBcMIDMwQ%3D%3D&trackingId=k2G88SleWl5Pfdf0F8CVuA%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "TRAVAILLER CHEZ ALTECA\nChez Alteca le management de proximit\u00e9, le bien-\u00eatre et l'\u00e9volution de nos collaborateurs sont des priorit\u00e9s qui nous permettent, chaque jour, de proposer la meilleure expertise possible \u00e0 nos clients.\nEt c'est gr\u00e2ce \u00e0 ces convictions, que nous sommes aujourd'hui r\u00e9f\u00e9renc\u00e9s aupr\u00e8s de partenaires grands comptes dans les secteurs de la Banque, de l'Assurance ou encore de la Distribution\n(Si vous souhaitez en savoir plus sur Alteca, RDV sur l'onglet \"Qui sommes-nous ?\").\n________________________________\n>\nEn tant que\nData Ing\u00e9nieur (H/F),\ntu seras rattach\u00e9(e) au\nP\u00f4le Data\nde notre Agence toulousaine\n.\nTon Manager sera Christian COT (Responsable du P\u00f4le) ou l'un de ses R\u00e9f\u00e9rent technique.\nInterlocuteur privil\u00e9gi\u00e9\n, il assurera ton\nint\u00e9gration\ndurant tes trois premiers mois dans l'entreprise, ta mont\u00e9e en comp\u00e9tences, tes\npoints de suivi\ntout au long de tes missions et tes\nEntretiens Annuels\n.\n>\nTu auras \u00e9galement acc\u00e8s \u00e0 une\ncommunaut\u00e9 technique d'experts\ngr\u00e2ce aux nombreux\nWebinar\norganis\u00e9s tout au long de l'ann\u00e9e, tu pourras aussi participer aux\nprojets de notre Centre de R&D\nou encore assister aux\nMID'INNO\n(pr\u00e9sentations de nos collaborateurs sur des th\u00e9matiques donn\u00e9es comme la Green Tech, l'IA...).\n>\nRejoindre ALTECA c'est aussi rejoindre une entreprise engag\u00e9e sur la RSE (labellis\u00e9e\nEcovadis Silver 2022\n), pour le bien-\u00eatre de ses salari\u00e9s (labellis\u00e9e\nHappyAtWork\npour la 5\u00e8me ann\u00e9e cons\u00e9cutive), et dans la formation de ses stagiaires et alternants (labellis\u00e9e\nHappyTrainees\npour la 4\u00e8me ann\u00e9e cons\u00e9cutive).\nTES MISSIONS\nEn coordination avec les \u00e9quipes d'un de nos clients grands comptes, tes missions seront les suivantes\n:\nConcevoir les Data Models et Data Pipelines\n: cartographier et documenter les types de donn\u00e9es et leur usage, concevoir les solutions, les processus, \u00e9laborer la strat\u00e9gie de validation des solutions\nConcevoir et sp\u00e9cifier l\u2019infrastructure\n: sp\u00e9cifier les solutions d\u2019acquisition en fonction des flux, les solutions de traitement adapt\u00e9es aux mod\u00e8les, estimer les besoins et co\u00fbts, sp\u00e9cifier les solutions de gestion des donn\u00e9es\nAccompagner et guider les \u00e9quipes : pr\u00e9sentation des \u00e9tudes et solutions, accompagnement dans les expertises, les parcours de formation\u2026\nMettre en \u0153uvre l\u2019infrastructure, d\u00e9velopper et maintenir\nles services de traitement de donn\u00e9es, supervision / monitoring des infrastructures\nLa majeure partie des projets de nos clients sont sur des\nenvironnements techniques r\u00e9cents\n: Python, FastAPI (ou Django / Flask) et des ORM type SQLAlchemy, Pandas, Numpy, Xarray, ETL, Airflow, BDD (timescaleDB, IngluxDB, MongoDB, Elastic, NoSQL Redis, PostgreSQL), Kafka, Prefect, Nifi, Pandas, Numpy, Xarray, Dask) Docker, Kubernetes, Gitlab et en m\u00e9thodologie Agile Scrum.\nTon profil :\ndipl\u00f4m\u00e9(e) d'un Bac+5 dans le domaine de la Data (Universit\u00e9 ou Ecole d'Ing\u00e9nieur), tu as au moins 7 ans d'exp\u00e9rience sur un poste similaire et tu sais \u00e9voluer en environnement Agile. Tu poss\u00e8des \u00e9galement une exp\u00e9rience dans le d\u00e9veloppement de logiciel (Python) dans une architecture orient\u00e9e microservices et API\nTa personnalit\u00e9 :\ntu es une personne organis\u00e9e et rigoureuse. Tu disposes d'un bon relationnel et tu aimes le travail en \u00e9quipe. Tu as la capacit\u00e9 de vulgarisation et de d\u00e9monstration. Tu appr\u00e9cies et contribues \u00e0 d\u00e9velopper un contexte de travail bienveillant et qui favorise le partage de connaissances, l\u2019accompagnement au changement. Enfin, tu et motiv\u00e9 pour les grands projets d\u2019infrastructure (moyen / long terme)\nType de contrat propos\u00e9 :\ntemps plein |\nNiveau de poste :\nconfirm\u00e9\n________________________________\nProcess de recrutement :\n\u03bd\nMalivanh te contactera pour un premier \u00e9change t\u00e9l\u00e9phonique, puis elle te recevra dans le cadre d'un\nentretien RH\n.\n\u03bd\nSi cet entretien est valid\u00e9, tu rencontreras alors Christophe, le Responsable du P\u00f4le Digital, pour un\nentretien technique.\n________________________________\nNOS AVANTAGES\nTransport pris en charge \u00e0 75% | Tickets resto pris en charge \u00e0 60% | Mutuelle prise en charge \u00e0 60%\n10 jours de RTT en plus des 25 jours de CP | Mode de travail : hybride | Acc\u00e8s au CSE (billetterie, voyages...)\nDes parcours de formations personnalis\u00e9s (75% de nos collaborateurs ont suivis au moins 1 formation en 2022)\nEn tant que signataire de la charte de diversit\u00e9 en entreprise, Alteca favorise un environnement de travail inclusif et respectueux de tous. A comp\u00e9tences \u00e9gales, tous nos postes sont ouverts aux personnes en situation de handicap.\nVotre chance c'est votre talent, la n\u00f4tre c'est de le d\u00e9velopper : rejoignez-nous !\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "R",
                "Go"
            ],
            "DataBase": [
                "SQL",
                "NoSQL",
                " MongoDB"
            ],
            "DataAnalytics": [
                "Pandas",
                "NumPy",
                "R"
            ],
            "BigData": [],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [],
            "DevTools": [
                "Git",
                "Docker"
            ],
            "Os": [],
            "DBMS": [
                "PostgreSQL"
            ],
            "SoftBigDataProcessing": [],
            "Automation": [
                "Kubernetes",
                "Airflow"
            ],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [
                "Docker",
                "Kubernetes"
            ],
            "Collaboration": [],
            "Other": [],
            "FrSoftSkills": [],
            "EnSoftSkils": []
        },
        "details": {
            "JobDetail": [
                "Hybride",
                "Temps plein",
                "Confirm\u00e9"
            ],
            "TypeContract": [],
            "Salary": [],
            "Level": [
                "Bac+5"
            ],
            "Experience": [
                "a",
                "n",
                "s",
                "7",
                "7",
                "7"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "Senior Data Engineer",
        "company": "DCube",
        "location": "Boulogne-Billancourt, \u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/senior-data-engineer-at-dcube-3892422399?position=4&pageNum=22&refId=xJ%2FHB6j7MCr9%2BdBcMIDMwQ%3D%3D&trackingId=UesBbmydvpha%2B8AyqbhxKQ%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "La Data, c\u2019est votre dada, vous \u00eates c\u00e2bl\u00e9(e) comme \u00e7a : vous aimez collecter et traiter des donn\u00e9es pour les mettre \u00e0 disposition des autres.\nVotre mission, si vous l'acceptez :\nComprendre et analyser des besoins m\u00e9tiers.\nConcevoir et r\u00e9aliser des processus optimis\u00e9s d\u2019ingestion et de traitement de donn\u00e9es dans des architectures lakehouse et data mesh.\nOrganiser et urbaniser le stockage des donn\u00e9es.\nIndustrialiser des mod\u00e8les de Machine Learning.\nExposer des donn\u00e9es via le d\u00e9veloppement d\u2019APIs.\nR\u00e9aliser des tests de validation des traitements.\n\u00catre consultant(e) chez dcube :\nNos consultant.e.s sont toutes et tous en CDI, ils interviennent en mission chez nos clients, mais ils ont aussi le choix de travailler depuis les locaux de dcube ou depuis chez eux en t\u00e9l\u00e9travail ponctuel.\nIls travaillent parfois \u00e0 plusieurs sur un projet, parfois en solo, mais ils peuvent toujours compter sur le soutien de leur manager r\u00e9f\u00e9rent et de leur lead practice pour \u00e9changer sur des sujets techniques et/ou humains !\nNos clients sont majoritairement des PME, mais 30% d'entre eux sont des grands groupes. Nous proposons \u00e0 nos consultant.e.s des missions dans toutes sortes de secteurs : finance, assurances, BTP, m\u00e9dias, services...\nNos consultant.e.s sont fier.e.s de leur apporter leur expertise pour r\u00e9pondre \u00e0 leurs probl\u00e9matiques techniques et m\u00e9tiers en leur proposant des solutions sur mesure.\nVous seriez parfait(e) pour rejoindre nos \u00e9quipes si :\nVous \u00eates ceinture noire en Data Engineering avec une exp\u00e9rience d\u2019au moins 5 ans.\nVous \u00eates rod\u00e9(e) \u00e0 la mise en place de pipelines de donn\u00e9es en mode batch et/ou streaming autour des technologies Snowflake, Databricks, Microsoft Fabrics ou Azure Synapse Analytics, DBT, Azure.\nVous avez un peu travaill\u00e9 sur des architectures lakehouse et/ou data mesh.\nVous ma\u00eetrisez les principes de mod\u00e9lisation Data Vault et sch\u00e9ma en \u00e9toile.\nQuand votre grand-m\u00e8re vous demande quel est votre m\u00e9tier, pour faire simple, vous r\u00e9pondez que vous \u00eates facilitateur(trice) de la vie des gens. Vous aimez rendre service en accompagnant les clients dans leur transformation, en leur apportant de la valeur et en les aidant \u00e0 r\u00e9soudre leurs probl\u00e8mes gr\u00e2ce \u00e0 votre savoir-faire technologique.\nBonus :\nCurieux(se) et gourmand(e), vous vous enfilez de grosses tartines d\u2019Azure au petit d\u00e9j.\nVous \u00eates une star du NoSQL, Machine Learning ou d\u00e9veloppement d\u2019APIs.\nLes cubes de Power BI n'ont pas de secrets pour vous.\nPourquoi choisir dcube ?\nNotre vision :\ndcube rassemble des femmes et des hommes de valeur, engag\u00e9s avec leurs partenaires, pour partager une exp\u00e9rience humaine et technique enrichissante.\nQuelques avantages :\nR\u00e9mun\u00e9ration \u00e0 partir de 50k.\nT\u00e9l\u00e9travail hybride et flexible.\nUn accompagnement tout au long de votre carri\u00e8re par un r\u00e9f\u00e9rent technique et un manager d\u00e9di\u00e9 hyper sympas.\nUne mont\u00e9e en comp\u00e9tence continue avec le financement de nombreuses formations et certifications, ainsi que la possibilit\u00e9 d\u2019\u00e9changer entre experts sur vos sujets techniques de pr\u00e9dilection lors de nos dcube learning.\nL\u2019organisation d\u2019\u00e9v\u00e9nements internes qui rassemblent (Afterworks, Meetups, Webinars, etc.)\nUn ordinateur portable et un package t\u00e9l\u00e9travail pour \u00e9quiper votre bureau.\nVotre pass Navigo pris en charge \u00e0 100%.\nUne mutuelle r\u00e9active et g\u00e9n\u00e9reuse (Alan) et une carte ticket restaurant (Swile).\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "R",
                "Go"
            ],
            "DataBase": [
                "SQL",
                "NoSQL"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [
                "Databricks"
            ],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [
                "Power BI"
            ],
            "Statistics": [],
            "CloudComputing": [
                "Azure"
            ],
            "DevTools": [],
            "Os": [],
            "DBMS": [
                "Snowflake",
                "Snowflake"
            ],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [
                "Machine Learning"
            ],
            "FrSoftSkills": [
                "Organisation"
            ],
            "EnSoftSkils": []
        },
        "details": {
            "JobDetail": [
                "Hybride"
            ],
            "TypeContract": [
                "CDI"
            ],
            "Salary": [
                "100"
            ],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s",
                "5",
                "5",
                "5"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "Data Engineer Cloud - Azure Confirm\u00e9 F/H",
        "company": "VISEO",
        "location": "Toulouse, Occitanie, France",
        "link": "https://fr.linkedin.com/jobs/view/data-engineer-cloud-azure-confirm%C3%A9-f-h-at-viseo-3904216858?position=5&pageNum=22&refId=xJ%2FHB6j7MCr9%2BdBcMIDMwQ%3D%3D&trackingId=xRPBF%2Bq%2F%2BS2quxjA%2BssoLQ%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Rejoignez VISEO et explorez un univers de possibilit\u00e9s o\u00f9 l'Humain, le Collectif et le Challenge sont au c\u0153ur de notre ADN.\nQui \u00eates-vous ?\nSi pour vous \u00eatre\nData Engineer Cloud Azure Confirm\u00e9 F/H\n, c'est :\nFaire partie d'une communaut\u00e9 d'experts en ing\u00e9nierie des donn\u00e9es et en solutions cloud ;\nConcevoir, construire et maintenir des pipelines de donn\u00e9es robustes et \u00e9volutifs sur Microsoft Azure;\nMa\u00eetriser les services Azure tels que Azure Data Factory, Azure Data Lake, Azure SQL Database, et Azure Synapse Analytics ;\nD\u00e9couvrir les nouveaut\u00e9s tel que Microsoft Fabric\nAppliquer les meilleures pratiques en mati\u00e8re de s\u00e9curit\u00e9, de qualit\u00e9 des donn\u00e9es et de gouvernance de l'information ;\n\u00catre familiaris\u00e9 avec les technologies de transformation de donn\u00e9es \u00e0 grande \u00e9chelle (Spark, Azure Databricks) ;\nCollaborer \u00e9troitement avec les \u00e9quipes BI et analytics pour transformer les donn\u00e9es en insights pr\u00e9cieux...\nAlors, vous \u00eates le talent que nous recherchons !\nSi vous avez une solide exp\u00e9rience en tant que Data Engineer, une passion pour le cloud Azure et que vous \u00eates pr\u00eat \u00e0 \u00e9largir vos comp\u00e9tences et \u00e0 avancer dans votre carri\u00e8re, c'est le moment parfait pour nous rejoindre.\nCe que nous allons faire ensemble ?\nD\u00e9couvrez comment votre quotidien sera transform\u00e9 en rejoignant l\u2019\u00e9quipe projet de Gr\u00e9gory. Rattach\u00e9 \u00e0 notre agence de Toulouse, vous pourrez :\nAccompagner et conseiller le client dans son adoption des Modern Data Platform dans Azure (Etude d\u2019architecture, pr\u00e9paration des DAT, FinOps, DevOps) ;\nConcevoir des architectures Cloud Data exploitant efficacement les services de donn\u00e9es manag\u00e9s d'Azure ;\nConduire des projets de d\u00e9ploiement des Modern Data Platform (Applications Cloud Native, Migration d\u2019applications existantes) et participer \u00e0 la mise en \u0153uvre ;\nEtablir des relations de confiance avec les d\u00e9cisionnaires techniques et m\u00e9tiers afin de favoriser l\u2019adoption du Cloud Microsoft Azure \u00e0 long terme au sein de l\u2019entreprise ;\nR\u00e9aliser une veille technologique permanente sur les tendances du march\u00e9 et les perspectives concurrentielles ;\nPartager votre expertise et apprendre continuellement au sein d'une \u00e9quipe anim\u00e9e par l'innovation.\nCe que nous avons \u00e0 vous offrir ?\nDes formations, des certifications Azure et un syst\u00e8me de mentoring ;\nUn environnement stimulant, souple et agile pour des parcours sans limite ;\nUn engagement fort pour l\u2019environnement, la soci\u00e9t\u00e9, l\u2019\u00e9galit\u00e9 et l\u2019inclusion\u202f: la plateforme Vendredi, atelier fresque du climat, Caf\u00e9 Joyeux, l'institut Imagine, Yumaincap ... https://www.viseo.com/fr/notre-demarche-rse\nUne organisation flexible pour un bon \u00e9quilibre vie pro / vie perso\nCe qui nous diff\u00e9rencie ?\nUne communaut\u00e9 engag\u00e9e d'experts en data et cloud Azure : des talks toutes les semaines, la participation \u00e0 des \u00e9v\u00e8nements techniques (ateliers, rencontres d\u2019experts, Tech An Hour, BBL, Rex, Sponsoring\u2026) ;\nDes dispositifs collectifs d\u2019\u00e9pargne salariale\u202f(PEE et PERECO) et la possibilit\u00e9 de devenir actionnaire VISEO ;\nUn partenariat privil\u00e9gi\u00e9 avec Microsoft (Gold Partner) vous donnant acc\u00e8s aux derni\u00e8res innovations et technologies Azure.\nEnvie de nous rejoindre ? Contactez-nous et faites partie du #VISEOspirit\nEn tant qu'employeur, VISEO promeut activement la diversit\u00e9 et l'inclusion.\n\u00c0 propos de VISEO\nAvec plus de 3 000 collaborateurs r\u00e9partis sur 5 continents, VISEO allie agilit\u00e9 et expertise technique pour faire du digital un moteur essentiel de comp\u00e9titivit\u00e9 et de performance.\n#PositiveDigitalMakers\nGDPR MESSAGE:\nOur privacy policy has been updated to comply with the new regulations. We invite you to consult it by clicking here: https://www.viseo.com/fr/politique-de-confidentialite. The VISEO Group uses the data collected as part of your application to assess your suitability for the job in question. We use the Jazz HR tool to help us in our recruitment process. This tool complies with current regulations on the protection of personal data. The tool is hosted in the United States and is PrivacyShield certified for HR data. In all cases, we may keep your file for 5 years so that we can contact you again if another position matches your profile. You may, of course, object to this. To find out more about how your data is used and how you can exercise your rights, please consult our privacy policy https://www.viseo.com/fr/politique-de-confidentialite.\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "R",
                "Go"
            ],
            "DataBase": [
                "SQL"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [
                "Spark",
                "Databricks"
            ],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [
                "Azure"
            ],
            "DevTools": [
                "Git"
            ],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [
                "DevOps",
                "Cloud"
            ],
            "FrSoftSkills": [
                "Organisation"
            ],
            "EnSoftSkils": []
        },
        "details": {
            "JobDetail": [
                "Confirm\u00e9"
            ],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "Consultant\u00b7e Data Engineer",
        "company": "Ntico",
        "location": "Villeneuve-d\u2019Ascq, Hauts-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/consultant%C2%B7e-data-engineer-at-ntico-3902424755?position=6&pageNum=22&refId=xJ%2FHB6j7MCr9%2BdBcMIDMwQ%3D%3D&trackingId=sfs99cvTMUAxpvjSb9EVrQ%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Sois acteur de ta r\u00e9ussite et rejoins notre \u00e9quipe de 140 collaborateurs\u00b7trices qui ne font pas que des projets, mais qui vivent une vraie exp\u00e9rience humaine unique !\n\ud83d\udca1 Partage, Progr\u00e8s, Plaisir : nos valeurs, ton avenir !\n\ud83c\udf10 Pr\u00e9sents \u00e0 Lille, Orl\u00e9ans, Montpellier : des expert\u00b7e\u00b7s partout en France !\n\ud83d\udcbc + de 40 clients qui nous font confiance\n\ud83e\uddd1\u200d\ud83d\udcbb Recrutement sur profil\n\ud83c\udfaf\nTA MISSION :\n* Tu int\u00e8gres une communaut\u00e9 Data, en tant que Data Engineer.\n* Tu con\u00e7ois et mod\u00e9lises les donn\u00e9es et identifies les sources et flux \u00e0 r\u00e9aliser.\n* Tu es en lien permanent avec les \u00e9quipes m\u00e9tiers et IT.\n* Tu formes et transmets ton savoir.\n* Tu es garant\u00b7e de la qualit\u00e9 des livraisons.\n\ud83e\uddd1\u200d\ud83d\udcbb\nTES COMP\u00c9TENCES :\nTalend, ODI, Stambia, Kafka, API, Bases SQL, et NoSQL, GCP, AWS\n\ud83e\udd47\nTON PROFIL :\nTu es expert\u00b7e des flux de donn\u00e9es.\nLa manipulation et le traitement des donn\u00e9es est une seconde nature.\nTu as le sens du service et tu apportes des solutions innovantes.\nTu aimes transmettre et partager ton savoir.\nTu justifies imp\u00e9rativement d\u2019au moins 3 ans d\u2019exp\u00e9rience et tu as d\u00e9velopp\u00e9\u00b7e une autonomie sur ton domaine de comp\u00e9tence.\nTu souhaites diversifier tes comp\u00e9tences pour \u00eatre toujours \u00e0 la pointe des cas d\u2019usages m\u00e9tiers et des nouvelles technologies Data.\n\ud83d\ude4c\nNOS AVANTAGES :\n\u2728 Pourquoi nous rejoindre ?\n\ud83d\udcaa\nD\u00e9veloppement Continu\n: Chez Ntico, tu montes en comp\u00e9tences gr\u00e2ce \u00e0 nos communaut\u00e9s d\u2019experts et nos formations !\n\ud83e\udd1d\nManagement de proximit\u00e9\n: On t'\u00e9coute, on te valorise et on t'accompagne dans ton projet pro, en toute transparence !\n\ud83c\udf89\nMoments conviviaux\n: Sport, culture, DIY, insolite\u2026 Tu peux participer \u00e0 nos \u00e9v\u00e9nements tous les mois, et en proposer ! On n\u2019est jamais \u00e0 court d\u2019id\u00e9es pour des animations uniques !\nNtico, c'est un cadre de travail bienveillant, un environnement dynamique o\u00f9 l'\u00e9panouissement personnel est aussi important que le succ\u00e8s collectif !\nPostule d\u00e8s maintenant et pr\u00e9pare-toi \u00e0 vivre une exp\u00e9rience humaine unique ! \u2728\nDe notre c\u00f4t\u00e9, on te contacte dans les 72h suivant ta candidature et on te propose un processus de recrutement rapide. \ud83d\ude80\nNtico s'engage activement en faveur de l'inclusion professionnelle des personnes en situation de handicap, tout en promouvant la mixit\u00e9, la diversit\u00e9 et l'\u00e9galit\u00e9 au sein de son effectif.\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "R"
            ],
            "DataBase": [
                "SQL",
                "NoSQL"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [
                "AWS"
            ],
            "DevTools": [],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [],
            "FrSoftSkills": [],
            "EnSoftSkils": []
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s",
                "3",
                "3",
                "3"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "Data Analyst \u2013 Lille, France (H/F)",
        "company": "Astek",
        "location": "Lille, Hauts-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/data-analyst-%E2%80%93-lille-france-h-f-at-astek-3839093481?position=7&pageNum=22&refId=xJ%2FHB6j7MCr9%2BdBcMIDMwQ%3D%3D&trackingId=2nnLsE%2BysTgP0uI%2B0%2FQPuA%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "CDI\nLille - France\nPubli\u00e9e il y a 2 mois\nLe Groupe Astek\nCe Que Nous Allons Accomplir Ensemble :\nNous rejoindre en tant que\nData Analyst (H/F),\nafin d\u2019accompagner un op\u00e9rateur t\u00e9l\u00e9coms, Leader en Europe dans la gestion de ses solutions robustes, efficientes et s\u00e9curis\u00e9es \u00e0 destination d\u2019environnements vari\u00e9s.\nUn challenge portant sur des millions d\u2019utilisateurs dans un environnement technique innovant, strat\u00e9gique et o\u00f9 l\u2019entraide et la bonne humeur priment !\nVotre Mission, Si Vous L\u2019acceptez :\nEtude sur les donn\u00e9es pour aide au cadrage du besoin M\u00e9tier.\nForce de proposition sur des solutions analytiques adapt\u00e9es aux besoins utilisateurs (avec nos \u00e9quipes UX).\nAnalyse des besoins m\u00e9tiers, accompagnement \u00e0 la formulation et \u00e0 la d\u00e9finition de KPI m\u00e9tiers.\nMod\u00e9lisation des donn\u00e9es.\nConception de Datasets Big Query.\nConception et R\u00e9alisation de Datamarts et de Dashboards (PowerBI / Looker)\nAnalyse de la qualit\u00e9 de la donn\u00e9e source, pour challenger les \u00e9quipes Digitales / Data Engineers.\nVotre Future \u00c9quipe :\nAu sein d\u2019un environnement riche et complexe, vous \u00e9voluerez avec des experts passionn\u00e9s \u00e0 la fois techniques et fonctionnels (Ing\u00e9nieurs sp\u00e9cialis\u00e9s, chef de projet, scrum master, product owner \u2026).\nL\u2019\u00e9quipe est en interaction avec des clients \u00e0 la fois internes et externes.\nVotre stack de jeu\nSQL \u2013 Confirm\u00e9\nMod\u00e9lisation de Donn\u00e9es \u2013 Confirm\u00e9\nOutils de Data Viz \u2013 Confirm\u00e9\nGCP \u2013 Junior\nAnglais \u2013 Professionnel\nLes Petits Plus Du Projet :\nVous interviendrez de A \u00e0 Z sur des projets riches fonctionnellement et ambitieux techniquement. Un challenge portant sur des millions d\u2019utilisateurs dans un environnement technique innovant et strat\u00e9gique.\nVous ?\nDipl\u00f4m\u00e9(e) d\u2019une \u00e9cole d\u2019ing\u00e9nieur ou \u00e9quivalent de niveau Bac+5.\nVous justifiez id\u00e9alement d\u2019une exp\u00e9rience d\u2019au moins 3 ans d\u2019exp\u00e9riences sur un poste similaire ?\nVous faite preuve d\u2019un bon relationnel et d\u2019esprit d\u2019\u00e9quipe, \u00eates dot\u00e9(e) d\u2019un excellent sens de l\u2019organisation et vous aimez les challenges et la r\u00e9solution de probl\u00e8me ?\nAlors ce poste est fait pour vous, n\u2019h\u00e9sitez plus et rejoignez l\u2019aventure ASTEK !\nAstek\nCr\u00e9\u00e9 en France en 1988, Astek est un acteur mondial de l\u2019ing\u00e9nierie et du conseil en technologies. Fort de son expertise dans de nombreux secteurs industriels et tertiaires, Astek accompagne ses clients internationaux dans le d\u00e9ploiement intelligent de leurs produits et de leurs services, et dans la mise en \u0153uvre de leur transformation digitale.\nDepuis sa cr\u00e9ation, le Groupe a fond\u00e9 son d\u00e9veloppement sur une forte culture d\u2019entrepreneuriat et d\u2019innovation, et sur l\u2019accompagnement et la mont\u00e9e en comp\u00e9tence de\nses 7800 collaborateurs\nqui s\u2019engagent chaque jour \u00e0 promouvoir la compl\u00e9mentarit\u00e9 entre les technologies num\u00e9riques et l\u2019ing\u00e9nierie des syst\u00e8mes complexes.\nRejoignez un Groupe en fort d\u00e9veloppement en France et \u00e0 travers le monde ayant r\u00e9alis\u00e9 un chiffre d\u2019affaires de 600 M\u20ac en 2023.\nTous les d\u00e9tails sur le Groupe sur le site https://astekgroup.fr. Et vous pouvez aussi nous suivre sur notre blog : https://blog.groupeastek.com.\nRencontrons-nous\nNotre projet commun vous plait ?\nPostulez \u00e0 cette annonce, et soyez transparent !\nMaud, notre Talent Acquisition Referent, vous contactera pour un premier \u00e9change.\nPuis vous rencontrerez Martin, votre futur manager, avec lequel vous \u00e9changerez autour d\u2019Astek, de votre parcours, de vos attentes et de votre future mission .\nEnfin, vous rencontrerez J\u00e9r\u00e9my, notre Directeur d\u2019agence avec lequel vous pourrez valider votre int\u00e9r\u00eat et ad\u00e9quation pour le poste et finaliser les \u00e9l\u00e9ments contractuels.\nNos Plus\nAstek est green et fait b\u00e9n\u00e9ficier ses salari\u00e9s d\u2019une indemnit\u00e9 kilom\u00e9trique v\u00e9lo\nUne politique CARE sur-mesure d\u00e9ploy\u00e9e par nos \u00e9quipes RH pour nos collaborateurs (https://astekgroup.fr/engagements)\nNotre charte de la Diversit\u00e9\nMots-cl\u00e9s :\ning\u00e9nieur \u2013 ing\u00e9nieure \u2013 consultant \u2013 consultante \u2013 data \u2013 analyst \u2013 mod\u00e9lisation \u2013 donn\u00e9es\nCaract\u00e9ristiques de l'emploi\nCat\u00e9gorie Ing\u00e9nieur\nJob Industry T\u00e9l\u00e9com / M\u00e9dia\nPostuler en ligne\nNom *\nPr\u00e9nom *\nEmail *\nUn email valide est requis.\nT\u00e9l\u00e9phone *\nUn num\u00e9ro de t\u00e9l\u00e9phone valide est requis.\nJoindre un CV *\nMots-cl\u00e9s :\ning\u00e9nieur \u2013 ing\u00e9nieure \u2013 consultant \u2013 consultante \u2013 data \u2013 analyst \u2013 mod\u00e9lisation \u2013 donn\u00e9es\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "R",
                "Go"
            ],
            "DataBase": [
                "SQL"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [
                "PowerBI"
            ],
            "Statistics": [],
            "CloudComputing": [],
            "DevTools": [
                "Git"
            ],
            "Os": [],
            "DBMS": [
                "Big Query"
            ],
            "SoftBigDataProcessing": [],
            "Automation": [
                "Chef"
            ],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [],
            "FrSoftSkills": [
                "Organisation"
            ],
            "EnSoftSkils": []
        },
        "details": {
            "JobDetail": [
                "Confirm\u00e9",
                "Junior"
            ],
            "TypeContract": [
                "CDI"
            ],
            "Salary": [],
            "Level": [
                "Bac+5"
            ],
            "Experience": [
                "a",
                "n",
                "s",
                "3",
                "3",
                "3"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "Consultante/Consultant Data Engineer alternance - GRENOBLE",
        "company": "Capgemini",
        "location": "Grenoble, Auvergne-Rh\u00f4ne-Alpes, France",
        "link": "https://fr.linkedin.com/jobs/view/consultante-consultant-data-engineer-alternance-grenoble-at-capgemini-3862396000?position=8&pageNum=22&refId=xJ%2FHB6j7MCr9%2BdBcMIDMwQ%3D%3D&trackingId=iEnQtBt6OzplzL6ySEaPBA%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Choisir Capgemini, c'est choisir une entreprise o\u00f9 vous serez en mesure de fa\u00e7onner votre carri\u00e8re selon vos aspirations. Avec le soutien et l'inspiration d\u2019une communaut\u00e9 d\u2019experts dans le monde entier, o\u00f9 vous pourrez r\u00e9\u00e9crire votre futur. Rejoignez-nous pour red\u00e9finir les limites de ce qui est possible, contribuer \u00e0 lib\u00e9rer la valeur de la technologie pour les plus grandes organisations et participer \u00e0 la construction d\u2019un monde plus durable et inclusif.\nVos missions\n:\nFaisant partie int\u00e9grante de l\u2019\u00e9quipe DataValue, compos\u00e9e d\u2019une quarantaine de collaborateurs, vous participerez activement \u00e0 :\n\u2022 Intervenir sur les diff\u00e9rentes phases d'un projet dans un environnement Cloud et Agile.\n\u2022 Contribuer \u00e0 la gestion de la qualit\u00e9 des donn\u00e9es et extraction et analyse de celle-ci, ainsi qu\u2019\u00e0 la pr\u00e9sentation des donn\u00e9es dans leur forme raffin\u00e9e.\n\u2022 Proposer des nouvelles lectures de donn\u00e9es via un travail de fouille sur les gisements d\u2019information, notamment client.\n\u2022 Adopter une posture de consultant : proposer de nouvelles solutions et accompagner le client dans ses choix.\nVotre profil\n:\n\u2022 En \u00e9cole d\u2019ing\u00e9nieur ou en universit\u00e9, vous \u00eates \u00e0 la recherche d'une alternance d'une dur\u00e9e de 1 an.\n\u2022 Connaissances approfondies des ETL (Talend, Informatica ou SSIS), du traitement de donn\u00e9es (Spark, Python, Scala) ainsi que des bases de donn\u00e9es (Oracle, SQL Server, Postgres).\n\u2022 Facult\u00e9 pour se montrer curieux, autonome et proactif dans la r\u00e9alisation de ses t\u00e2ches.\n\u2022 Capacit\u00e9 \u00e0 faire preuve de rigueur et \u00e0 travailler en \u00e9quipe.\n\u2022 Bon niveau d\u2019anglais (B2 minimum).\n3 raisons de nous rejoindre\n:\nQualit\u00e9 de vie au travail\n: accord de t\u00e9l\u00e9travail en France et \u00e0 l\u2019international, accord sur l\u2019\u00e9galit\u00e9 professionnelle, la parentalit\u00e9, l\u2019\u00e9quilibre des temps et la mobilit\u00e9 durable.\nApprentissage en continu\n: certifications et formations en libre acc\u00e8s, accompagnement sur mesure avec votre career manager, parcours d\u2019int\u00e9gration sur 9 mois.\nAvantages groupes & CSE\n: plan actionnariat, tarifs pr\u00e9f\u00e9rentiels, remboursement partiel vacances, remboursement de votre abonnement sportif ou culturel.\nNos engagements et priorit\u00e9s\n:\nLe groupe Capgemini encourage une culture inclusive dans un cadre multiculturel et handiaccueillant.\nEn nous rejoignant, vous int\u00e9grez un collectif qui valorise la diversit\u00e9, d\u00e9veloppe le potentiel de ses talents, s\u2019engage dans des initiatives solidaires avec ses partenaires, et se mobilise pour r\u00e9duire son impact environnemental sur tous ses sites et aupr\u00e8s de ses clients.\n\u00c0 propos de Capgemini\n:\nCapgemini est un leader mondial, responsable et multiculturel, regroupant pr\u00e8s de 350 000 personnes dans plus de 50 pays. Fort de 55 ans d\u2019exp\u00e9rience, nous sommes un partenaire strat\u00e9gique des entreprises pour la transformation de leurs activit\u00e9s en tirant profit de toute la puissance de la technologie et des innovations dans les domaines en perp\u00e9tuelle \u00e9volution tels que le cloud, la data, l\u2019Intelligence Artificielle, la connectivit\u00e9, les logiciels, l\u2019ing\u00e9nierie digitale ou les plateformes.\nGet The Future You Want* | www.capgemini.com/fr-fr\n*Capgemini, le futur que vous voulez\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "Scala",
                "R"
            ],
            "DataBase": [
                "SQL"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [
                "Spark"
            ],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [],
            "DevTools": [
                "Git"
            ],
            "Os": [],
            "DBMS": [
                "Oracle",
                "SQL Server"
            ],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [
                "Cloud"
            ],
            "FrSoftSkills": [
                "Organisation"
            ],
            "EnSoftSkils": [
                "Initiative"
            ]
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s",
                "55",
                "55",
                "55"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "Senior Data Engineer (H/F)",
        "company": "Believe",
        "location": "Paris, \u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/senior-data-engineer-h-f-at-believe-3726297642?position=9&pageNum=22&refId=xJ%2FHB6j7MCr9%2BdBcMIDMwQ%3D%3D&trackingId=PWmdK6CxbV%2FSaJRt2OQbCA%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Description De L'entreprise\nBelieve est l'un des leaders mondiaux du march\u00e9 de la musique num\u00e9rique. Believe a pour mission d\u2019accompagner les artistes et les labels locaux dans l\u2019\u00e9cosyst\u00e8me digital en leur offrant des solutions \u00e0 chaque \u00e9tape de leur carri\u00e8re et d\u00e9veloppement\nCe sont plus de 1900 salari\u00e9s dans 50 pays qui accompagnent artistes avec expertise, respect, \u00e9quit\u00e9 et transparence.\nAfin de soutenir notre forte croissance sur tous les continents, nous sommes constamment \u00e0 l\u2019aff\u00fbt de nouveaux Believers. Rejoignez-nous afin qu\u2019ensemble, nous ayons un impact fort et plus positif sur l\u2019industrie musicale\u202f!\nBelieve est cot\u00e9e sur le compartiment A du march\u00e9 r\u00e9glement\u00e9 d\u2019Euronext Paris (Ticker : BLV, ISIN : FR0014003FE9).\nwww.believe.com\nReady to #setthetone with Believe?\nDescription Du Poste\nContexte\nLe Tribe \u00ab\u202fCustomer Finance\u202f\u00bb est compos\u00e9 de plusieurs Squad, parmi elles la squad\u202fFinance Ingestion qui a pour mission de d\u00e9velopper des outils et des applications pour la collecte de royalties aupr\u00e8s des plateformes de streaming de musique ainsi que pr\u00e9parer les donn\u00e9es afin de faire la distribution des royalties aupr\u00e8s des producteurs de musiques.\nEn tant que Senior Data Engineer, tu int\u00e9gras une \u00e9quipe de Data Engineering travaillant avec les principes du framework agile Scrum. Cette \u00e9quipe est compos\u00e9e essentiellement de 5 Data Engineer et 1 Software Engineer.\nNous Avons Un \u00c9cosyst\u00e8me Compos\u00e9 De\nUn socle de gestion des donn\u00e9es (Delta Lake) plus d\u20191.5 milliard de lignes /mois\nData processing avec Scala et Spark utilisant le runtime de Databricks\nOrchestration de nos data pipelines avec Airflow manag\u00e9\nDes APIs d\u00e9ploy\u00e9es avec AWS Lambda et API Gateway pour faire interagir les utilisateurs avec notre interface front (PHP)\nAWS RDS pour hoster la base de donn\u00e9es back-end sous PostgreSQL\nVersionning du code sous GitLab avec un environnement de dev, staging et production\nInfrastructure sous AWS\nLes missions du Senior Data Engineer au sein de l\u2019\u00e9quipe :\nAccompagner les d\u00e9veloppeurs \u00e0 \u00e9crire du code propre, qualitatif et conforme aux standards de l\u2019\u00e9quipe\nInteragir avec l\u2019architecte, les \u00e9quipes infrastructures Cloud pour concevoir les solutions de data engineering\nProposer des am\u00e9liorations continues et \u00eatre garant de r\u00e9duire les dettes techniques\nD\u00e9velopper des flux de donn\u00e9es (data pipelines) avec de l\u2019Apache Spark et du Scala\nFaire de l\u2019orchestration via Airflow avec du Python\nMaintenir le workflow GitLab afin de garantir une bonne productivit\u00e9 de l\u2019\u00e9quipe de d\u00e9veloppement\nEffectuer des revues de codes des autres membres de l\u2019\u00e9quipe\nCollaborer les membres de l\u2019\u00e9quipe dev pour atteindre l\u2019objectif du sprint\nFaire du support applicatif et fonctionnel de l\u2019application aupr\u00e8s des op\u00e9rationnel\nQualifications\nQualifications du Data Engineer\n5-8 ans d\u2019exp\u00e9rience en Scala\nUne maitrise horizontale de tous les composants d\u2019une plateforme de data\nExp\u00e9rience en programmation fonctionnel\nConnaissance d\u2019un effect system en Scala (ZIO ou cats)\nExcellente ma\u00eetrise de l\u2019API Spark en Scala avec pour but de guider l\u2019\u00e9quipe sur les bonnes pratiques\nExp\u00e9rience en d\u00e9veloppement backend\nUne bonne maitrise des services AWS (API Gateway, Lambda, SNS, SQS, S3, Cloudwatch, VPC)\nD\u00e9velopper avec un \u00e9tat d\u2019esprit Keep it Simple, Stupid (KISS)\nExcellente comp\u00e9tence dans la gestion de relation avec une \u00e9quipe en remote\nBonne communication pour g\u00e9rer les diff\u00e9rents points de vue et expliquer les contraintes aux utilisateurs\nOptionnel\nExp\u00e9rience en PHP (framewok Symfony ou Laravel)\nInformations suppl\u00e9mentaires\nSet the tone with us\nChez Believe, nous avons deux c\u0153urs : nos collaborateurs et nos artistes.\nNous croyons en la force de nos collaborateurs, qui s'\u00e9panouissent chaque jour en d\u00e9veloppant leur potentiel... Notre objectif est d'offrir \u00e0 nos collaborateurs le meilleur environnement possible pour qu'ils puissent s'\u00e9panouir.\nRock the job\nProgramme de formation et de coaching sur mesure\nUne politique de t\u00e9l\u00e9travail\nUn programme de bien-\u00eatre \"Pauses\" avec de nombreuses activit\u00e9s et animations en interne\nAcc\u00e8s \u00e0 Eutelmed, la plateforme num\u00e9rique de sant\u00e9 mentale et de bien-\u00eatre qui permet de parler \u00e0 un psychologue exp\u00e9riment\u00e9\nUn restaurant d'entreprise sain et \u00e9co-responsable\nUne assurance sant\u00e9 individuelle ou familiale\nAvantages CE\nUn rooftop\nUne salle de sport avec des cours gratuits\nSing in harmony\nDes groupes d'ambassadeurs pour s'engager sur la r\u00e9duction de l'empreinte carbone et environnementale de Believe et l\u2019\u00e9quit\u00e9 professionnelle Femme/Homme.\nMise en place du Forfait mobilit\u00e9 durable: remboursement jusqu\u2019\u00e0 600\u20ac des frais de transport en commun/avec une faible empreinte carbone.\nCong\u00e9 2nd parent de 5 jours calendaires r\u00e9mun\u00e9r\u00e9s \u00e0 100% (en plus du cong\u00e9 l\u00e9gal paternit\u00e9 ou du cong\u00e9 d\u2019adoption, nous ne l\u2019attribuons pas au cong\u00e9 maternit\u00e9)\nBelieve s\u2019engage \u00e0 garantir l\u2019\u00e9galit\u00e9 des chances en mati\u00e8re d\u2019emploi, sans tenir compte de l\u2019origine, du sexe, des m\u0153urs, de l\u2019orientation sexuelle, du genre, de l\u2019\u00e2ge, de la situation de famille, de l\u2019\u00e9tat de grossesse, d\u2019une pr\u00e9tendue race, des opinions politiques, des activit\u00e9s syndicales, des convictions religieuses, de l\u2019apparence physique, du nom de famille, du lieu de r\u00e9sidence, de l\u2019\u00e9tat de sant\u00e9, ou en situation de handicap.\nD\u00e9couvrez nos nouveaux locaux : bit.ly/believeoffice\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "Scala",
                "R"
            ],
            "DataBase": [
                "SQL"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [
                "Spark",
                "Databricks"
            ],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [
                "AWS"
            ],
            "DevTools": [
                "Git"
            ],
            "Os": [],
            "DBMS": [
                "PostgreSQL"
            ],
            "SoftBigDataProcessing": [],
            "Automation": [
                "Airflow"
            ],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [
                "Cloud"
            ],
            "FrSoftSkills": [
                "Communication"
            ],
            "EnSoftSkils": [
                "Communication"
            ]
        },
        "details": {
            "JobDetail": [
                "Remote",
                "Senior"
            ],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s",
                "8",
                "8",
                "8"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "Alternance - Data Engineer Junior (H/F)",
        "company": "Transdev",
        "location": "Issy-les-Moulineaux, \u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/alternance-data-engineer-junior-h-f-at-transdev-3879679114?position=10&pageNum=22&refId=xJ%2FHB6j7MCr9%2BdBcMIDMwQ%3D%3D&trackingId=UCZZDRclG746BsTGQUMbdw%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Transdev recrute un Data Engineer Junior (H/F) en alternance\nRejoignez un Groupe international fortement ancr\u00e9 dans les territoires\nVotre destination\nLa Direction \"IT, Data, Digital, Cybersecurity\" d\u00e9finit la Strat\u00e9gie de Transformation du Groupe et suit sa mise en oeuvre au travers de 9 programmes strat\u00e9giques.\nParmi ces programmes, au sein du d\u00e9partement Digital, notre \u00e9quipe \"Data & Technology Office\" anime le programme Data Powered qui vise \u00e0 augmenter la maturit\u00e9 Data du Groupe Transdev et de ses filiales \u00e0 l'international, ainsi qu'\u00e0 valoriser ses assets Data encore peu exploit\u00e9s autour d\u2019une m\u00e9thodologie innovante ax\u00e9e sur la valeur des cas d\u2019usage \u00e0 destination de profils bien d\u00e9finis.\nDans ce contexte, nous mettons en place un certain nombre d\u2019environnements techniques qui ont besoin d\u2019\u00eatre gouvern\u00e9s et nous r\u00e9alisons des d\u00e9veloppements de manipulation de donn\u00e9es pour les besoins propres du Groupe. Nous aidons aussi les pays \u00e0 lancer leurs propres programmes et nous les accompagnons sur tous les volets du changement.\nVotre feuille de route\nLe/la Data Engineer Junior a la responsabilit\u00e9 :\nde la structuration des d\u00e9veloppements des traitements d\u2019int\u00e9gration de donn\u00e9es h\u00e9t\u00e9rog\u00e8nes (en lien avec l\u2019Architecte Data et le/la Data Engineer Senior)\nde la mise en place de processus fiables et automatis\u00e9s de test et de d\u00e9ploiement.\nEn parall\u00e8le, il/elle travaille avec l\u2019\u00e9quipe de Data Science afin de comprendre leurs besoins et pr\u00e9parer les donn\u00e9es n\u00e9cessaires aux cas d\u2019usage.\nVotre parcours\nActuellement en \u00e9cole d'ing\u00e9nieur ou universit\u00e9, vous pr\u00e9parez un Master en Sciences de l'information, Sciences de la donn\u00e9e et vous recherchez une entreprise o\u00f9 r\u00e9aliser vos deux ann\u00e9es d\u2019alternance (M1/M2).\nVous avez un vrai int\u00e9r\u00eat pour l\u2019ing\u00e9nierie de la donn\u00e9e.\nEnfin, vous avez id\u00e9alement une premi\u00e8re exp\u00e9rience significative (stage, projet \u00e9tudiant solide) en tant que Data Engineer.\nVos atouts\nVous \u00eates tr\u00e8s \u00e0 l'aise (voire bilingue)\nen fran\u00e7ais et anglais\n\u00e0 l'oral comme \u00e0 l'\u00e9crit. C'est un pr\u00e9requis pour ce poste car vous serez amen\u00e9(e) \u00e0 travailler avec les filiales de Transdev \u00e0 l'\u00e9tranger.\nVous avez une bonne compr\u00e9hension du Data Engineering, vous connaissez les environnements Cloud (notamment Amazon Web Services) ainsi que les technologies Git.\nLa connaissance accrue des langages SQL et Python est indispensable. La c onnaissance de Snowflake est un vrai plus.\nEnfin, rigoureux(se), curieux(se), et proactif(ve), vous avez une r\u00e9elle capacit\u00e9 \u00e0 vous adapter, \u00e0 g\u00e9rer vos projets de mani\u00e8re autonome, tout en travaillant de mani\u00e8re collaborative dans des \u00e9quipes pluridisciplinaires.\nA savoir\nAlternance bas\u00e9e \u00e0 Issy-les-Moulineaux (92)\nD\u00e9marrage en septembre 2024 pour un an ou deux ans\nRythme id\u00e9al : 4 jours/1 jour (ou 3 semaines /1 semaine)\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "R",
                "Go"
            ],
            "DataBase": [
                "SQL"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [],
            "DevTools": [
                "Git"
            ],
            "Os": [],
            "DBMS": [
                "Snowflake",
                "Snowflake"
            ],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [
                "Cloud"
            ],
            "FrSoftSkills": [],
            "EnSoftSkils": []
        },
        "details": {
            "JobDetail": [
                "Junior",
                "Senior"
            ],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "Senior Data Engineer",
        "company": "netcarbon",
        "location": "Bordeaux, Nouvelle-Aquitaine, France",
        "link": "https://fr.linkedin.com/jobs/view/senior-data-engineer-at-netcarbon-3909777157?position=1&pageNum=25&refId=bvabfaeIkTn6w1fyYCK6qA%3D%3D&trackingId=hrlicBfcntsfyCNt8%2F4V%2BA%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "A propos de netcarbon\nLe rapport du GIEC est clair pour lutter contre le changement climatique, nous devons :\n\ud83c\udfed\nR\u00e9duire nos \u00e9missions de CO2\n\ud83c\udf31\nCapter le CO2 de l'atmosph\u00e8re\nQuand il s\u2019agit de capter du CO2,\nla v\u00e9g\u00e9tation a un super pouvoir.\nGr\u00e2ce \u00e0 la photosynth\u00e8se, les plantes absorbent le CO2 contenu dans l\u2019atmosph\u00e8re pour le stocker dans le sol.\nLe probl\u00e8me c\u2019est que ce qui ne peut pas \u00eatre mesur\u00e9, ne peut pas \u00eatre am\u00e9lior\u00e9.\nNetcarbon\nentre alors en sc\u00e8ne ! Netcarbon est une startup\nsp\u00e9cialis\u00e9e dans la mesure du carbone.\nMais pas n\u2019importe quelle mesure, nous utilisons des donn\u00e9es satellites pour avoir une vision globale, homog\u00e8ne et quotidienne du carbone. Heureusement nous ne travaillons pas seuls, Netcarbon est soutenu par le CNES et l\u2019Agence Spatiale Europ\u00e9enne.\nComment cela fonctionne ?\n\ud83d\udef0\ufe0f\nLa donn\u00e9e satellite pour mesurer le carbone\nLe coeur de netcarbon, c\u2019est les donn\u00e9es issues des satellites en orbite au dessus de nos t\u00eates. Gr\u00e2ce \u00e0 cela, nous pouvons mesurer le CO2 absorb\u00e9 par la v\u00e9g\u00e9tation en temps r\u00e9el et partout sur Terre.\n\ud83d\udda5\ufe0f\nUn SaaS pour am\u00e9liorer et valoriser sa captation carbone\nPour rendre accessible la mesure du carbone \u00e0 tous, netcarbon a con\u00e7u une application qui permet \u00e0 nos clients de conna\u00eetre leur captation carbone et d\u2019identifier la v\u00e9g\u00e9tation \u00e0 mettre en place pour capter plus de CO2.\nQui sont nos clients ?\n\ud83d\udc68\u200d\ud83c\udf3e\nL\u2019agriculture\nGr\u00e2ce \u00e0 leurs champs les agriculteurs peuvent stocker \u00e9norm\u00e9ment de CO2. En utilisant l\u2019application netcarbon, les coop\u00e9ratives et agro industriels peuvent encourager les agriculteurs \u00e0 stocker plus de CO2 et donc contribuer \u00e0 lutter contre le changement climatique.\n\ud83c\udf33\nLes villes\nPour lutter contre le changement climatique et rendre nos villes plus agr\u00e9ables \u00e0 vivre, il est indispensable de mettre plus de v\u00e9g\u00e9tation. L\u2019application netcarbon aide les d\u00e9cideurs politiques \u00e0 concevoir des villes plus durables en mettant la v\u00e9g\u00e9tation et ses bienfaits au centre de tous projets.\nLe poste\nTon poste consistera \u00e0 consolider les infrastructures de traitement de donn\u00e9es de Netcarbon incluant le traitement de donn\u00e9es satellites pour que notre produit puisse \u00eatre d\u00e9ploy\u00e9 massivement. Pour cela, tu travailleras sur deux axes cl\u00e9s :\nDatafactory (ETL) :\nPour suivre la captation de carbone, nous avons construit une datafactory qui permet d\u2019analyser des donn\u00e9es satellites partout sur Terre. L\u2019objectif sera de consolider la datafactory.\nCloud / Architecture :\nNetcarbon s\u2019appuie sur plusieurs Cloud Providers pour le traitement de donn\u00e9es, pour le stockage ainsi que le d\u00e9ploiement de son produit. Tu aideras l\u2019\u00e9quipe \u00e0 construire la meilleure strat\u00e9gie cloud pour d\u00e9ployer notre produit.\nEn tant que membre central de la team data, tu porteras une mission indispensable pour le d\u00e9veloppement de netcarbon :\nconsolider nos ETL et insuffler les meilleurs pratiques de data engineering \u00e0 la team.\nTu interagiras avec la Science Team, la Dev Team et surtout, tu auras l\u2019occasion de faire grandir une solution r\u00e9pondant au d\u00e9fi de notre si\u00e8cle : lutter contre le changement climatique.\nTes missions\nR\u00e9aliser un audit de nos ETL et de notre Architecture cloud.\nConsolider nos ETL & notre Architecture afin de soutenir le d\u00e9veloppement et l\u2019am\u00e9lioration de notre solution de mesure du carbone.\nD\u00e9ployer les meilleures pratiques de data engineering au sein de la Team.\nGarder un \u0153il sur les nouvelles technologies et les avanc\u00e9es dans le domaine de la data engineering et des donn\u00e9es satellites (stac, cog, xarray, zarr, dask, ...)\nProfil id\u00e9al\nTu es le candidat id\u00e9al si:\nTu as une exp\u00e9rience solide avec des bases de donn\u00e9es SQL et noSQL dans le cloud.\nTu as d\u00e9j\u00e0 travaill\u00e9 avec des donn\u00e9es g\u00e9ospatiales / imagerie / satellite.\nTu sais ce que signifient GCP, GeoPandas, STAC, GEE, COG, xarray et Dask.\nTu es proactif et tu n\u2019as pas peur de mettre les mains dans le cambouis pour faire un peu de dev ops ou proposer une nouvelle architecture data.\nTu sais qu\u2019une data pipeline bien huil\u00e9e vaut mieux qu\u2019un mod\u00e8le chiad\u00e9. (ie: tu as d\u00e9j\u00e0 collabor\u00e9 avec une \u00e9quipe machine learning).\nTu as un bon esprit de synth\u00e8se et capable de communiquer efficacement avec ton \u00e9quipe.\nTu n\u2019as pas pour projet de devenir data scientist.\nFormation et Exp\u00e9rience\n3 ans d\u2019exp\u00e9rience minimum dans une \u00e9quipe data.\nmaster ou \u00e9quivalent en informatique, ing\u00e9nierie ou science des donn\u00e9es.\nProcess de recrutement\nLe processus de recrutement se divise en 3 \u00e9tapes :\nUn entretien en visio de 30/45 minutes avec le head of data\nR\u00e9alisation d\u2019un cas d\u2019usage \u00e0 effectuer en une semaine\nUn entretien final avec les co-fondateurs de Netcarbon (id\u00e9alement en pr\u00e9sentiel pour que tu puisses rencontrer ta future team \ud83e\udd29)\nProcessus de recrutement\nMerci de postuler sur notre job indeed pour nous permettre de centraliser les demandes.\nhttps://fr.indeed.com/job/senior-data-engineer-97612e2a2f4cf205\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "R"
            ],
            "DataBase": [
                "SQL",
                "NoSQL"
            ],
            "DataAnalytics": [
                "Pandas",
                "R"
            ],
            "BigData": [],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [],
            "DevTools": [
                "Git"
            ],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [
                "Machine Learning",
                "Cloud"
            ],
            "FrSoftSkills": [],
            "EnSoftSkils": []
        },
        "details": {
            "JobDetail": [
                "Senior"
            ],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s",
                "3",
                "3",
                "3"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "Senior Data Engineer Databricks",
        "company": "Visian",
        "location": "Paris, \u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/senior-data-engineer-databricks-at-visian-3893237152?position=2&pageNum=25&refId=bvabfaeIkTn6w1fyYCK6qA%3D%3D&trackingId=V8EstfE8XicXmnSHXYl6dQ%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "La Direction des Syst\u00e8mes d\u2019Information de notre client grand compte dans l\u2019\u00e9nergie recherche un profil\nData Engineer Databricks Senior\npour concevoir, d\u00e9velopper et maintenir les architectures Data n\u00e9cessaires \u00e0 l\u2019exploitation de ses donn\u00e9es par les analystes m\u00e9tiers et data scientists.\nLe D\nata Engineer Senior\nint\u00e8gre une \u00e9quipe en charge du lakehouse (AWS + Databricks) pour la B2C.\nMissions\n:\nContribution \u00e0 la conception de outils de traitement BigData (Ingestion / Traitement / Analyse)\nCadrage technique des besoins \u00e9mis par les consommateurs de la plateforme Data\nGarantir la mise en production des traitements au sein de la plateforme\nOptimisation du code et de la capacit\u00e9 des VMs mise en \u0153uvre pour chaque traitement\nGarantir la disponibilit\u00e9 et l\u2019outillage pour les \u00e9quipes m\u00e9tier, ainsi qu\u2019aux utilisateurs de la plateforme (data scientists / data analystes / data engineer)\nEtre en relation avec les \u00e9quipes infrastructure afin d\u2019assurer le cadrage et le d\u00e9ploiement des solutions valides\nSupport aux \u00e9quipes consommatrices\nAnalyse d\u2019anomalies et proposition solution court / moyen terme\nD\u00e9veloppement sous Databrick (Python / SQL / Spark / Airflow)\nEtre force de propositions techniques\nProfil recherch\u00e9 :\nFormation ing\u00e9nieure ou universitaire de niveau Bac+5 \u00e0 dominante informatique et math\u00e9matiques\nExp\u00e9rience de 3 \u00e0 5 ans minimum sur un poste similaire\nCode source (composants applicatifs et tests unitaires)\nMa\u00eetrise de Databricks + Python + SQL + Spark + Airflow\nAvoir une premi\u00e8re exp\u00e9rience sur de la MCO et Support\nComp\u00e9tences en langage SQL et en programmation (Python et PowerShell)\nAisance dans l\u2019utilisation des API (REST, SOA)\nMa\u00eetrise de l\u2019anglais\nRigueur, capacit\u00e9 d\u2019analyse et d\u2019adaptation\nAutonome, vous savez travailler en \u00e9quipe et avez l\u2019esprit d\u2019initiative\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "R"
            ],
            "DataBase": [
                "SQL"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [
                "Spark",
                "Databricks"
            ],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [
                "AWS"
            ],
            "DevTools": [],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [
                "Airflow"
            ],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [],
            "FrSoftSkills": [],
            "EnSoftSkils": [
                "Initiative"
            ]
        },
        "details": {
            "JobDetail": [
                "Senior"
            ],
            "TypeContract": [],
            "Salary": [],
            "Level": [
                "Bac+5"
            ],
            "Experience": [
                "a",
                "n",
                "s",
                "5",
                "5",
                "5"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "Data Engineer",
        "company": "eXalt",
        "location": "Paris, \u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/data-engineer-at-exalt-3901508929?position=3&pageNum=25&refId=bvabfaeIkTn6w1fyYCK6qA%3D%3D&trackingId=M%2BMvcApOtpH2QjDIjUux3A%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Descriptif du poste\nNous recherchons un\nData Engineer Confirm\u00e9 H/F (minimum 4 ans d\u2019exp\u00e9rience dans la fonction)\npour rejoindre notre communaut\u00e9 sur le\npilier Data Engineering & Big Data.\nVos missions:\nConcevoir et d\u00e9velopper des pipelines et des flux de donn\u00e9es.\nInt\u00e9grer et transformer des donn\u00e9es provenant de diff\u00e9rentes sources.\nD\u00e9velopper et mettre en \u0153uvre des algorithmes de traitement de donn\u00e9es avanc\u00e9s.\nCollaborer \u00e9troitement avec les \u00e9quipes clients pour comprendre leurs besoins et fournir des solutions adapt\u00e9es.\nAssurer la qualit\u00e9 et la fiabilit\u00e9 des solutions d\u00e9velopp\u00e9es.\nConseiller les \u00e9quipes clients sur les solutions \u00e0 mettre en place.\nProfil recherch\u00e9\nTitulaire d\u2019un Bac+5, Ecole d\u2019Ing\u00e9nieur\nMa\u00eetrise d\u2019un ou plusieurs langages de programmation (Python, Scala, Spark, etc.).\nExp\u00e9rience approfondie des technologies Big Data (Hadoop, Spark, Kafka, Talend, etc.)\nExp\u00e9rience av\u00e9r\u00e9e en environnement Cloud (AWS, GCP, ou Azure).\nSolides comp\u00e9tences en conception et en optimisation de pipelines de donn\u00e9es.\nExp\u00e9rience de travail en m\u00e9thode Agile\nCapacit\u00e9 \u00e0 travailler de mani\u00e8re autonome et en \u00e9quipe.\nExcellentes comp\u00e9tences en communication et en r\u00e9solution de probl\u00e8mes.\nMa\u00eetrise de l\u2019anglais (oral & \u00e9crit dans un contexte international professionnel).\nD\u00e9roulement des entretiens\nUn entretien RH avec Estelle, \u00e0 la suite duquel vous saurez tout (ou presque) d\u2019eXalt Value,\nUn entretien technique avec un Manager assorti d\u2019un test technique, lors duquel vous aurez l\u2019occasion de d\u00e9montrer vos talents mais aussi d\u2019apprendre avant m\u00eame de dire oui,\nUn entretien final avec la Directrice Associ\u00e9e ou le Directeur Op\u00e9rationnel, pour finir de vous convaincre de nous rejoindre \ud83d\ude0a\nVotre environnement eXalt\u00e9:\nUn environnement de travail Collaboratif favorisant les initiatives et projets transverses \u00e0 la Practice Data & IA (Lab IA, Data Hub, etc.).\nUn collectif de consultants passionn\u00e9s, s\u2019int\u00e9ressant aux tendances innovantes du secteur.\nUne Practice de proximit\u00e9, privil\u00e9giant la mont\u00e9e en comp\u00e9tence de ses collaborateurs (formations, coachings, mentorats, etc.)\nUn suivi individualis\u00e9 et de proximit\u00e9 par un.e Data Sales Manager r\u00e9f\u00e9rent du compte client, un.e Charg\u00e9.e RH et un.e Practice Manager\nUne \u00e9quipe ouverte et dynamique, qui privil\u00e9gie les moments de partage et de convivialit\u00e9 (s\u00e9minaires, eXaltemps, meet-up, d\u00e9jeuners d\u2019\u00e9quipe, etc.)\nQui sont-ils ?\neXalt\nest un cabinet de conseil IT\nPure player Data\n& IA bas\u00e9 \u00e0 Paris (1er arrondissement).\nNotre offre s\u2019articule autour de 4 piliers r\u00e9unis au sein d\u2019une m\u00eame communaut\u00e9 pour un accompagnement \u00e0 360\u00b0 alliant une expertise technique et m\u00e9thodologique \u00e0 une approche conseil m\u00e9tier:\nData Gouvernance & Project\nData Engineering & Big Data\nData Performance\u202f& Analytics\nData Science & IA\nFiliale du groupe eXalt cr\u00e9\u00e9 en 2018,\nregroupant plus de\n950 collaborateurs en France\n(Paris, Lyon, Bordeaux, Lille, Nantes, Marseille)\net \u00e0 l\u2019international\n(Colombie, Etats-Unis, Espagne, Belgique),\neXalt Value\nd\u00e9montre une\nexpertise approfondie\ndans le domaine de la Data & IA et conseille les entreprises dans le d\u00e9ploiement de leurs strat\u00e9gies data-driven.\nB\u00e9n\u00e9ficiant de la renomm\u00e9e et des relations client du groupe eXalt\n(1er dans la cat\u00e9gorie Conseil & Audit au classement des Champions de la Croissance 2024), eXalt Value\nest en pleine croissance et regroupe aujourd\u2019hui une communaut\u00e9 d\u2019expertise de plus de 60 collaborateurs en r\u00e9gion parisienne.\nNos consultants interviennent sur d\nes projets d\u2019envergure stimulants\ndans divers secteurs d\u2019activit\u00e9, Banque & Assurance, M\u00e9dias, Transports, Retail, Tourisme, etc.\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "Scala",
                "R",
                "Go"
            ],
            "DataBase": [],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [
                "Hadoop",
                "Spark"
            ],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [
                "AWS",
                "Azure"
            ],
            "DevTools": [],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [
                "Big Data",
                "Cloud"
            ],
            "FrSoftSkills": [
                "Communication",
                "R\u00e9solution de probl\u00e8mes"
            ],
            "EnSoftSkils": [
                "Communication",
                "Initiative"
            ]
        },
        "details": {
            "JobDetail": [
                "Confirm\u00e9"
            ],
            "TypeContract": [],
            "Salary": [],
            "Level": [
                "Bac+5"
            ],
            "Experience": [
                "a",
                "n",
                "s",
                "4",
                "4",
                "4"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "Data Engineer H/F",
        "company": "Proxiel",
        "location": "Montpellier, Occitanie, France",
        "link": "https://fr.linkedin.com/jobs/view/data-engineer-h-f-at-proxiel-3913995044?position=4&pageNum=25&refId=bvabfaeIkTn6w1fyYCK6qA%3D%3D&trackingId=w8S9Uma4TwjKIiHoLu%2Bw%2Bw%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Depuis 1999, PROXIEL accompagne des entreprises dans leur d\u00e9veloppement en assurant des prestations de conseil et d'ing\u00e9nierie dans le domaine des technologies.\nProxiel : C'est plusieurs p\u00f4les d'activit\u00e9s.\nNous mettons un point d honneur \u00e0 associer votre bien-\u00eatre - adaptabilit\u00e9 en fonction de vos contraintes (possibilit\u00e9 de t\u00e9l\u00e9travail). Des solutions alternatives, peuvent \u00eatre envisag\u00e9es, dans la mesure o\u00f9 elles sont compatibles avec le business que nous entreprenons. Nous souhaitons que chacun de nos salari\u00e9s s investissent dans nos projets et que notre entreprise soit anim\u00e9e par un projet commun : la r\u00e9ussite de chacun !\nNotre approche est simple alors restons transparents dans nos \u00e9changes.\nNotre si\u00e8ge est implant\u00e9 \u00e0 Montpellier PROXIEL. Nous disposons \u00e9galement d une agence sur Paris\nVous pr\u00e9sentez des comp\u00e9tences dans les nouvelles technologies en qualit\u00e9 de techniciens d\u00e9veloppeurs ing\u00e9nieurs, cot\u00e9 d\u00e9veloppement ou r\u00e9seau, vous \u00eates bas\u00e9s ou mobile sur MONTPELLIER PARIS LYON TOULOUSE MARSEILLE AIX EN PROVENCE, NICE rejoignez-nous !\nBonjour,\nNous recherchons pour notre partenaire un grand compte sur Montpellier un Data engineer :\nComp\u00e9tences\nExp\u00e9rience en architecture de syst\u00e8mes distribu\u00e9s Big Data\nScala/Java (exp\u00e9rience obligatoire dans l'un des deux langages)\nEcosyst\u00e8me Big Data (Hadoop, Spark, Apache Kafka, Avro, Nifi)\nMa\u00eetrise de la CI/CD et des outils de d\u00e9ploiement et orchestration (Jenkins, GitLab, Kubernetes, Docker, Ansible)\nConcepts fondamentaux de Kafka\nBases de donn\u00e9es NoSQL (Cassandra, BigTable)\nMoteur de recherche (Elastic Search)\nBac +5 ou \u00e9quivalent\nMin 3 ans d'exp\u00e9rience\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Java",
                "Scala",
                "R"
            ],
            "DataBase": [
                "SQL",
                "NoSQL",
                "Cassandra"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [
                "Hadoop",
                "Spark"
            ],
            "MachingLearning": [],
            "DataSerialization": [
                "Avro"
            ],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [],
            "DevTools": [
                "Git",
                "Docker",
                "Jenkins"
            ],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [
                "Apache Kafka"
            ],
            "Automation": [
                "Ansible",
                "Kubernetes"
            ],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [
                "Docker",
                "Kubernetes"
            ],
            "Collaboration": [],
            "Other": [
                "Big Data",
                "CI/CD"
            ],
            "FrSoftSkills": [
                "Adaptabilit\u00e9"
            ],
            "EnSoftSkils": []
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s",
                "3",
                "3",
                "3"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "Data Engineer | Python - Spark - Hadoop | Sp\u00e9cialis\u00e9 en Big Data | Paris ou Remote Partiel",
        "company": "Octopus IT - Expert du recrutement tech",
        "location": "Paris, \u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/data-engineer-python-spark-hadoop-sp%C3%A9cialis%C3%A9-en-big-data-paris-ou-remote-partiel-at-octopus-it-expert-du-recrutement-tech-3837194913?position=5&pageNum=25&refId=bvabfaeIkTn6w1fyYCK6qA%3D%3D&trackingId=HYiCQ7lqeOTOgLlDeC8znA%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "La soci\u00e9t\u00e9\nCr\u00e9\u00e9e il y a 7 ans, cette entreprise de conseil en hyper croissance, se compose d'environ 90 personnes. Elle est devenue experte en Data et IA (NLP, Deep Learning, Machine Learning) et accompagne leurs clients sur l\u2019ensemble de leurs projets data \u00e0 travers la valorisation de leurs donn\u00e9es.\nLeur valeur ajout\u00e9e ? Leur sp\u00e9cialisation en Data ce qui leur permet d'offrir 3 expertises m\u00e9tiers distinctes : la Data Science, la Data Engineering et le Machine Learning Engineering. Autour de ces expertises gravitent bien s\u00fbr les m\u00e9tiers de Lead et d'Architecte.\nUne autre de leur force est leur formation interne (avec des profils de seniors ou d'architectes) et externe (avec des partenaires pour passer les certifications).\nChez eux, le collaborateur est plac\u00e9 au centre des pr\u00e9occupations, permettant ainsi de cr\u00e9er une coh\u00e9sion et une v\u00e9ritable culture au sein de l'entreprise. Par exemple la majorit\u00e9 des projets se font en \u00e9quipe et non seul.\nConnu et reconnu pour leur expertise en Big Data, ils sont devenu le partenaire principal d'un grand groupe du CAC 40 et ont pris le lead sur tous les sujets touchant \u00e0 la transformation Big Data de ce groupe.\nPour poursuivre leur croissance, r\u00e9pondre \u00e0 leurs ambitions et d\u00e9velopper de nouveaux march\u00e9s, nous recherchons plusieurs profils pour renforcer leurs effectifs.\nLe poste\nEn les rejoignant vous travaillerez sur les probl\u00e9matiques suivantes :\nMise en place et/ou scale d'architectures\nConstruction de Datalake\nMise en production de model de ML\nPipelining de donn\u00e9es\nStreaming de donn\u00e9es et temps r\u00e9el\nLa stack sur laquelle vous travaillerez :\nPython, Scala, Spark, Architectures distribu\u00e9es : Hadoop, HDFS, Cloud : Aws, GCP, Azure\nVotre profil\nA partir de 3 ans d'exp\u00e9rience en CDI\nVous avez une exp\u00e9rience significative sur des probl\u00e9matiques Big Data\nTr\u00e8s bonne comp\u00e9tences en Python et/ou Scala et en Spark\nVous \u00eates familier avec Hadoop, Hive, Hbase\nUne logique cloud (Aws, GCP ou Azure)\nLe salaire & avantages\n50-60 K\u20ac selon exp\u00e9rience\nRTT\nCarte Swile & Mutuelle\n3/4 jours de t\u00e9l\u00e9travail par semaine\nEt plus encore\u2026\nCe qu\u2019on pr\u00e9f\u00e8re\n\u00catre impliqu\u00e9 \u00e0 fond dans une aventure avec de nombreux challenges techniques\nBelles opportunit\u00e9s d'\u00e9volutions sur des postes d'Architecte, de Lead ou de Ml Ops\nTr\u00e8s bonne ambiance, \u00e9quipe solidaire et orient\u00e9e partage d\u2019informations\nBeaucoup de workshops en interne et catalogue de formations \u00e0 votre guise\nCe poste a \u00e9t\u00e9 soigneusement choisi par votre coach. Powered by Octopus IT, cabinet d\u2019Experts en Recrutement Tech (CDI et clients finaux uniquement) \u2013 Visitez nous pour plus d\u2019opportunit\u00e9s :\nwww.octopusit.fr\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "Scala",
                "R"
            ],
            "DataBase": [
                "HBase"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [
                "Hadoop",
                "Spark"
            ],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [
                "AWS",
                "Azure"
            ],
            "DevTools": [],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [
                "HBase"
            ],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [
                "Big Data",
                "ML",
                "Machine Learning",
                "Cloud"
            ],
            "FrSoftSkills": [],
            "EnSoftSkils": []
        },
        "details": {
            "JobDetail": [
                "Senior"
            ],
            "TypeContract": [
                "CDI"
            ],
            "Salary": [
                "50"
            ],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s",
                "7",
                "7",
                "7"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "DATA ENGINEER - H/F - (STG-4572)",
        "company": "Banque de France",
        "location": "Paris, \u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/data-engineer-h-f-stg-4572-at-banque-de-france-3814497304?position=6&pageNum=25&refId=bvabfaeIkTn6w1fyYCK6qA%3D%3D&trackingId=gQMqXLid0WUm%2BDlp1dyxLg%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Pr\u00e9sentation de la direction g\u00e9n\u00e9rale et du service\nLa Direction G\u00e9n\u00e9rale du Syst\u00e8me d\u2019Information (DGSI) a pour r\u00f4le de concevoir et mettre en \u0153uvre la strat\u00e9gie informatique de la Banque de France. Elle veille \u00e0 la mise \u00e0 niveau de l'architecture informatique, \u00e0 l'int\u00e9gration de l'innovation, \u00e0 la s\u00e9curit\u00e9 num\u00e9rique de la Banque de France mais aussi \u00e0 la bonne gestion de son patrimoine de donn\u00e9es. La DGSI regroupe plus de 2 000 personnes (internes et externes) r\u00e9parties sur diff\u00e9rents sites, \u00e0 Paris, Vincennes, Marne-la-Vall\u00e9e, Paris La Courneuve et Poitiers.\nAu sein de la Direction G\u00e9n\u00e9rale du Syst\u00e8me d\u2019information, le Lab incarne le centre d\u2019innovation de la Banque de France. Outil d\u2019anticipation, de facilitation et de construction des offres innovantes, le Lab Banque de France a pour mission de faire d\u00e9couvrir aux m\u00e9tiers de la banque centrale les nouveaux usages, les nouvelles technologies et les nouvelles m\u00e9thodes pour conduire des projets de transformation de fa\u00e7on agile et rapide.\nDescriptif de mission\nDans le cadre de son plan de travail sur l'Intelligence Artificielle, le Lab propose un stage afin de d\u00e9velopper et de concr\u00e9tiser les sujets suivants :\nMaintenance de scraping de sites avec l\u2019IA (\u00e9valuer si \u00e0 partir de scraping existant, l\u2019IA pourrait corriger les erreurs li\u00e9es aux \u00e9volutions des sites scrap\u00e9s.)\n\u00c9valuation du produit Giskard (framework pour tester les mod\u00e8les LLM)\nGestion des CRA (Comptes Rendus d\u2019Activit\u00e9s) des prestataires (traitement \u00e0 base de OCR les CRA transmis par les prestataires, contr\u00f4le sur les consommations, voir la possibilit\u00e9 de faire des traitements IA)\nProfil recherch\u00e9\nFormation recherch\u00e9e :\nMaster (1 ou 2) Data Engineer, Data Scientist\nMaster (1 ou 2) Ing\u00e9nierie des syst\u00e8mes num\u00e9riques\nComp\u00e9tences :\nTechnologie: IA, IA G\u00e9n\u00e9rative\noutils de gestion/analyse de la data: PowerBI ou autres\nLangages de programmation: Python, ReactJS, Java\nEnvironnements: Cloud, Docker, Git\nQualit\u00e9s :\nCapable de travailler \u00e0 la fois en autonomie et en \u00e9quipe.\nForce de proposition dans son domaine d'expertise\nUne tr\u00e8s bonne communication autant \u00e0 l'\u00e9crit qu'\u00e0 l'oral\nContactez nos ambassadeurs\nLa Banque de France est une institution socialement responsable, attach\u00e9e au respect de la diversit\u00e9 sous toutes ses formes, \u00e0 la lutte contre les discriminations, \u00e0 favoriser la parit\u00e9 Femme/Homme et \u00e0 garantir un environnement de travail de qualit\u00e9.\nDes am\u00e9nagements de poste peuvent \u00eatre organis\u00e9s pour tenir compte des handicaps des personnes recrut\u00e9es.\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "Java",
                "R"
            ],
            "DataBase": [],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [
                "PowerBI"
            ],
            "Statistics": [],
            "CloudComputing": [],
            "DevTools": [
                "Git",
                "Docker"
            ],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [
                "Docker"
            ],
            "Collaboration": [],
            "Other": [
                "Cloud"
            ],
            "FrSoftSkills": [
                "Communication"
            ],
            "EnSoftSkils": [
                "Communication"
            ]
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "Data ing\u00e9nieur (H/F)",
        "company": "Abeille Assurances",
        "location": "Bois-Colombes, \u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/data-ing%C3%A9nieur-h-f-at-abeille-assurances-3819474490?position=7&pageNum=25&refId=bvabfaeIkTn6w1fyYCK6qA%3D%3D&trackingId=wLLtaB7AES6VNQd3lV%2Bm1Q%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Rejoignez les \u00e9quipes de la Data Factory d\u2019Abeille assurances ! Au sein de cette direction compos\u00e9e d\u2019une 40aine de collaborateurs, l\u2019enjeu pour vous sera de g\u00e9rer les plateformes Data pour les rendre disponibles et accessibles au business ! Ainsi, vous contribuez \u00e0 la modernisation du SI Data, accompagnez les directions m\u00e9tiers dans la mise en \u0153uvre de leur besoin en termes de donn\u00e9es, et assurer la disponibilit\u00e9 des services au quotidien.\nA ce titre, vos missions principales sont les suivantes :\nMise en place et maintenance des architectures d\u00e9cisionnelles en int\u00e9grant des nouveaux outils ou services en conformit\u00e9 avec la strat\u00e9gie d\u2019entreprise. A ce titre vous serez amen\u00e9 \u00e0 tester des solutions (benchmark/POC), \u00e0 coordonner ou \u00eatre lead technique Data pour des projets d\u2019int\u00e9gration et de d\u00e9ploiement de solution en fonction de votre exp\u00e9rience, documenter les divers aspects y compris des best practice et normes d\u2019utilisation, ainsi que d\u00e9velopper des outillages facilitant l\u2019int\u00e9gration ou l\u2019industrialisation des nouvelles applications.\nMise en place de nouvelles interfaces techniques pour des sources de donn\u00e9es encore non r\u00e9f\u00e9renc\u00e9es dans le SI Data et participation \u00e0 leur standardisation et d\u00e9ploiement.\nParticiper activement \u00e0 tous les process transverse de gestion IT au quotidien pour le SI Data : Gestion des identit\u00e9s, Conformit\u00e9, Cartographie, Audit, Test d'intrusion, Rem\u00e9diations des vuln\u00e9rabilit\u00e9s, Plan de recours, Plan de tests et Plan de maintenance.\nFacilitation de l\u2019usage des donn\u00e9es dans l\u2019entreprise dans un environnement de plus en plus hybride On-Premise, Cloud, SaaS\nProfil et comp\u00e9tence :\nBAC +5 Master ou Ing\u00e9nieur IT sp\u00e9cialit\u00e9 Data et IT\nComp\u00e9tences techniques : Python, Big Data,\nLa connaissance d\u2019outils de DataVIZ (Qlik serait un plus) ainsi que Dataiku ou des outils d\u2019IA.\nGestion de projet indispensable .\nSens de l\u2019analyse pr\u00e9cise du contexte afin de trouver la solution la plus efficace et pertinente\nVous \u00eates autonome , \u00eates dot\u00e9(e) d\u2019un bon relationnel notamment face \u00e0 des interlocuteurs m\u00e9tiers et experts techniques vari\u00e9s. \u00catre bien organis\u00e9. Faire preuve d\u2019une grande rigueur .Vous avez une aisance naturelle pour le travail en \u00e9quipe et avez l\u2019habitude de vulgariser les demandes, faire comprendre avec p\u00e9dagogie les contraintes m\u00e9tiers et des \u00e9quipes IT.\nVous \u00e9voluez dans un environnement \u00e9voluant tr\u00e8s rapidement. Aussi, vous \u00eates curieux.se, apprendre en permanence, La veille technologie est essentielle\nContraintes li\u00e9es au poste\n: astreintes occasionnelles\nAnglais :\nindispensable (travail avec les \u00e9diteurs)\nCe que nous avons \u00e0 vous proposer ?\nUne r\u00e9mun\u00e9ration globale, compos\u00e9e :\nD\u2019une part fixe,\nD\u2019une part variable : Individuelle, et collective, via l\u2019Epargne salariale (Participation / int\u00e9ressement),\nUne surcompl\u00e9mentaire retraite (PERE - Plan d\u2019Epargne Retraite Entreprise)\nDu t\u00e9l\u00e9travail, encadr\u00e9 par un accord qui pr\u00e9voit jusqu\u2019\u00e0 2,5 jours de t\u00e9l\u00e9travail par semaine, accessible apr\u00e8s la p\u00e9riode d\u2019int\u00e9gration (sauf exception), Le t\u00e9l\u00e9travail donne droit \u00e0 des titres restaurant, une aide \u00e0 l\u2019\u00e9quipement et une indemnit\u00e9 internet mensuelle.\nUne mutuelle interentreprise avantageuse.\nUn remboursement de transport flexible, encadr\u00e9 par un forfait mobilit\u00e9 durable, pour favoriser les mobilit\u00e9s douces.\nEntre 26 et 29 jours de cong\u00e9s pay\u00e9s et 15 jours de RTT pour un temps plein.\nUn CSE avec des offres et services attractifs.\nDes offres de produits d\u2019assurance et un accompagnement personnalis\u00e9,\nUn environnement de travail chaleureux et convivial 100% en flex-office, facilement accessible en transport\nEt apr\u00e8s ?\nChez Abeille Assurances, la mobilit\u00e9 interne est un vrai levier pour d\u00e9velopper la carri\u00e8re et les comp\u00e9tences de nos collaborateurs et collaboratrices, avec un objectif ambitieux de 50% des postes pourvus en interne.\nNous favorisons les mobilit\u00e9s au sein du Groupe A\u00e9ma, de Macif, Aesio Mutuelle, Ofi Invest. Ensemble, nous formons le 5\u00e8me groupe d\u2019assurance en France.\nQuels sont nos engagements ?\nL\u2019assurance d\u2019\u00eatre soi-m\u00eame :\nChez Abeille Assurances nous sommes convaincus que la diversit\u00e9 est une richesse. Nous nous engageons \u00e0 traiter les candidatures sans consid\u00e9ration de sexe, d\u2019\u00e2ge, d\u2019origine, de handicap ou de conviction. La direction et les collaborateurs s\u2019engagent au quotidien sur les sujets de diversit\u00e9 et d\u2019inclusion, en t\u00e9moigne nos diff\u00e9rentes communaut\u00e9s : LGBT+, Egalit\u00e9 professionnelle et Handicap.\nEt nous ?\nCompagnie majeure de l\u2019assurance en France forte de ses 3000 collaborateurs, 1000 agents g\u00e9n\u00e9raux d\u2019assurance et de ses 180 ans d\u2019exp\u00e9rience, Abeille Assurances dispose d\u2019une gamme \u00e9tendue de produits et services d\u2019assurance, de protection, d\u2019\u00e9pargne et de retraite. Abeille Assurances est par ailleurs le partenaire historique de l\u2019AFER, la premi\u00e8re association d\u2019\u00e9pargnants en France (avec pr\u00e8s de 754 000 adh\u00e9rents).\nPlus d\u2019informations sur abeille-assurances.fr\nAbeille Assurances est une entit\u00e9 d\u2019A\u00e9ma Groupe, n\u00e9 en janvier 2021 du rapprochement entre A\u00e9sio Mutuelle, Macif, et Ofi Invest. Ce groupe imagine chaque jour les contours d\u2019un monde plus juste et plus humain en pla\u00e7ant la pr\u00e9venance au c\u0153ur de la relation avec ses adh\u00e9rents, soci\u00e9taires et entreprises clientes. Il couvre les besoins de protection de 11 millions de personnes et r\u00e9pond aux besoins assurantiels et serviciels de 1 fran\u00e7ais sur 6.\nPlus d\u2019infos sur aemagroupe.fr\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "R",
                "Go"
            ],
            "DataBase": [],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [],
            "DevTools": [],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [
                "Big Data",
                "Cloud"
            ],
            "FrSoftSkills": [],
            "EnSoftSkils": []
        },
        "details": {
            "JobDetail": [
                "Hybride",
                "Temps plein"
            ],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s",
                "180",
                "180",
                "180"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "Data Analyst H/F",
        "company": "Valeuriad",
        "location": "Nantes, Pays de la Loire, France",
        "link": "https://fr.linkedin.com/jobs/view/data-analyst-h-f-at-valeuriad-3741219622?position=8&pageNum=25&refId=bvabfaeIkTn6w1fyYCK6qA%3D%3D&trackingId=lOT9PrrG2hiHK9%2BBwW%2FxsQ%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Rejoins la Team Data\ncr\u00e9\u00e9e par Nicolas Greffard,\nDocteur en Intelligence Artificielle\n, d\u00e9j\u00e0 compos\u00e9e de 20 Data Scientists et Data Engineer talentueux \ud83d\ude0d\nNous recherchons de nouvelles p\u00e9pites pour rejoindre notre \u00e9quipe de choc et r\u00e9pondre aux multiples probl\u00e9matiques Data science de nos clients nantais mais \u00e9galement contribuer \u00e0 nos projets de R&D et travailler sur des conf\u00e9rences incroyables (DevFest, Salon de la Data) \ud83e\udd29\nTa future mission si tu l'acceptes \ud83d\ude09\nNous te proposons d'intervenir au sein de nos grandes DSI clientes, sur des sujets de collecte, d'alimentation et de transformation de donn\u00e9es autour de l\u2019intelligence artificielle.\nLe job en d\u00e9tail \ud83e\udd29\nToutes Les Missions Ne Sont Pas Identiques, Mais Voici Des Exemples De Choses Sur Lesquelles Nos Data Analyst Sont Intervenus\nMettre en oeuvre des outils informatiques, des techniques et des m\u00e9thodes statistiques pour permettre d'organiser, synth\u00e9tiser et traduire efficacement des donn\u00e9es ;\nFournir un appui analytique \u00e0 la conduite d'exploration et \u00e0 l'analyse complexe de donn\u00e9es ;\nCr\u00e9er des algorithmes de recherche de donn\u00e9es qui permettent d'explorer les donn\u00e9es utiles ;\nProc\u00e9der \u00e0 l'industrialisation du proc\u00e9d\u00e9 pour les donn\u00e9es les plus int\u00e9ressantes. Et organiser, synth\u00e9tiser et traduire les informations pour faciliter la prise de d\u00e9cision ;\nG\u00e9rer les op\u00e9rations et l'administration, la mod\u00e9lisation et l'architecture des sources de donn\u00e9es. Et s'assurer que les bases de donn\u00e9es existantes soient op\u00e9rationnelles et int\u00e8gres ;\nDonner un sens aux donn\u00e9es \u00e0 l'aide de ses connaissances analytiques (SQL, analytics/BI, statistiques basiques) ;\nD\u2019int\u00e9grer de nouveaux jeux de donn\u00e9es (Open Data, crowd sourcing, API, fichiers, etc.).\nNous intervenons sur\ndes donn\u00e9es Big Data\n(Hadoop, Hive, Spark, etc...), NoSQL (Neo4j, Redis Graph, Redis, mongo) avec toujours quelques bases de donn\u00e9es Oracle ind\u00e9boulonnables. Mais aussi r\u00e9guli\u00e8rement sur des environnements\nCloud\n(principalement AWS et GCP). C\u00f4t\u00e9 outillage et ETL, les missions r\u00e9centes \u00e9taient principalement sur Informatica, Dataiku et Dig Dash. A retenir : nous faisons de tout !\nPourquoi choisir Valeuriad ? \ud83d\ude0a\nEn plus d\u2019\u00eatre aujourd\u2019hui un acteur nantais reconnu de l\u2019expertise IT, nous nous inscrivons depuis notre cr\u00e9ation dans une d\u00e9marche d'entreprise\nOpale\net\nHolacratique\n, o\u00f9 l'ensemble de nos prises de d\u00e9cisions et projets sont r\u00e9alis\u00e9s par et avec l'ensemble de nos 120 co\u00e9quipiers \ud83d\udcaa\nRejoindre Valeuriad, c'est\npouvoir s'investir dans la co-construction\nde l'entreprise :\nPar un r\u00f4le, avec une fiche de poste et un temps d\u00e9di\u00e9 (gestionnaire des Ci\u2019s, porteur des partenariats \u00e9coles, organisateur d\u2019\u00e9v\u00e9nements, PO des projets internes, gestion de l'Acad\u00e9mie Valeuriad\u2026).\nPar les projets strat\u00e9giques (200 jours mis \u00e0 disposition pour les co\u00e9quipiers chaque ann\u00e9e) pour cr\u00e9er et faire grandir des projets structurants (cr\u00e9ation de nouveaux avantages \u00e0 l'anciennet\u00e9, cr\u00e9ation d'indicateurs mensuels pour \u00eatre toujours plus transparents, m\u00e9c\u00e9nat de comp\u00e9tences pour des associations caritatives...).\nPar les projets cagnottes (150\u20ac par co\u00e9quipiers et par an) pour r\u00e9aliser des projets collaboratifs qui te tiennent \u00e0 c\u0153ur avec d'autres Valeurieux (d\u00e9couverte du c\u00e9cifoot, challenge \u00e9cologique, challenges sportifs pour des dons \u00e0 des associations humanitaires, borne photo...).\nPar les ateliers collaboratifs, chaque mois des brainstorming et ateliers de travail sont propos\u00e9s par les diff\u00e9rents porteurs de projets et sont ouverts \u00e0 tous les volontaires.\nMais avant-tout nous sommes une\n\u00e9quipe soud\u00e9e\n, des coll\u00e8gues qui appr\u00e9cient passer du temps ensemble lors de nos soir\u00e9es hebdomadaires et se cr\u00e9er des souvenirs inoubliables \ud83e\udd29 C'est pour \u00e7a que chez Valeuriad, le plus important pour nous reste le savoir-\u00eatre : des passionn\u00e9s, du dynamisme, des sourires, de l'\u00e9coute et le sens de la f\u00eate \ud83d\ude09\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "R",
                "Go"
            ],
            "DataBase": [
                "SQL",
                "NoSQL",
                "Neo4j"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [
                "Hadoop",
                "Spark"
            ],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [
                "Statistiques"
            ],
            "CloudComputing": [
                "AWS"
            ],
            "DevTools": [],
            "Os": [],
            "DBMS": [
                "Oracle"
            ],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [
                "Big Data",
                "Statistiques",
                "Cloud"
            ],
            "FrSoftSkills": [],
            "EnSoftSkils": []
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "Data Engineer (M/F)",
        "company": "SESAMm",
        "location": "Paris, \u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/data-engineer-m-f-at-sesamm-3771461770?position=9&pageNum=25&refId=bvabfaeIkTn6w1fyYCK6qA%3D%3D&trackingId=oH%2FhN4EBRj4DmceeTT87Lw%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "SESAMm\nSESAMm (www.sesamm.com) extracts behavioral insights from millions of unstructured text data sources across the public internet in over 100 languages, helping clients distill valuable intelligence on businesses and their customers to make investment decisions and manage risk.\nWe work with many well-known firms around the world in private equity, investment banking, insurance, and asset management to apply Natural Language Processing and Artificial Intelligence algorithms to track e-reputation, competitive positioning, sentiment analysis, risk and ESG factors.\nSESAMm is growing quickly, with over 90 team members around the globe and offices in Paris, New York, London, Metz, Tunis, and Tokyo.\nKey technologies: Alternative Data, Natural Language Processing, Machine Learning and Quantitative Analysis.\nAre you looking for a new challenge? Do you dream of joining a growing company, proposing new ideas, and taking part in innovative processes?\nAt SESAMm, everyone brings their ideas, skills, and creativity. We value collaboration, support and teamwork. We learn every day from the experience of this great team and we constantly take up new challenges. We are proud of the work accomplished and to participate in the success of this great adventure!\nThe Data Engineer Role\nAs a Data Engineer, you will build and scale data components to key SESAMm products, such as raw data ingestion pipeline, job scheduling and ETL design/optimization,t optimize cloud solutions for Product Data Platform, and set up the best data development practices for other tech members. Communicate the work of your team with weekly updates.\nYou're joining a team that is already highly dynamic and adaptable, ready for expansion. This is a chance for you to play a key role in influencing and shaping the team's culture.\nKey Activities\n\u2756 Design and implement best data pipeline for our Text-based products (ingestion, processing, exposition) :\nTest and design state-of-the-art data ingestion pipelines\nImplement efficient streaming services\n\u2756 Take part in the acquisition of new data sources\nFor each new data source, describe its feasibility and potential\nCreate and maintain data collection and centralization pipelines\nIntegration of data enrichment modules created by Data Scientists\n\u2756 Develop data request tooling for Technical teams\nEase the use of data requesting engines\nOptimize architecture and data pipelines\n\u2756 Implement and maintain critical data systems\nProcess and integrate data in our systems\nEnsure maintainability and efficiency\nUsed technologies : PySpark, AWS EMR, Databricks, SQL, MongoDB,,, An excellent level of English proficiency, very good interpersonal skills and strong motivation are required. The candidate will need to demonstrate autonomy and innovation in the face of a constantly changing environment. The list of tasks described is not necessarily exhaustive and may be modified according to the constraints of the company and the evolution of its needs.\nDesired Background and Skills\nEducation\nEngineering school/university with specialization in IT, software engineering or data science. Other types of profiles are welcome to apply as long as they have significant IT experience\nExperience\nAt least 3 years of experience in data engineering with a successful implementation of a cloud-based data processing pipeline\nSkills\nGood understanding of different databases and data storage technologies\nVery good knowledge of distributed computing systems, such as Spark\nGood knowledge of cloud computing systems, such as AWS, GCP, Azure ML\nDevelopment: Be at ease with Python\nGood communication and popularization skills: understand technical team needs and issues, collaborate with several internal teams. Team player.\nAdditional skills: strong interest in Data Science / Natural Language Processing.\nYou should be able to work in a product team and show high motivation. This job requires autonomy, curiosity toward a changing environment and real dedication to solving problems for clients\nBenefits of Working at SESAMm\nFlexibility:\nTeam members can work remotely and have the opportunity to work with colleagues around the world.\nWork environment:\nSESAMm is multicultural, with technology, sales, and management teams in the US, France, and Tunisia making important contributions to the company's growth.\nCareer development:\nSESAMm is growing quickly, which means the opportunities for your own growth are continually expanding, and that you can shape the company's culture and evolution.\nProfessional evolution:\nSESAMm values training and knowledge-sharing. We organize internally and externally led training sessions and pay for access to educational platforms.\nTransparency:\nYou will be kept apprised of the company's continuing evolution and performance through monthly \"Ask Me Anything\" meetings, frequent business/finance updates, and strategy-sharing discussions.\nWell-being:\nBuilding a good culture is key to building a good business at SESAMm. We focus on being a learning organization that values and supports teamwork, thoughtfulness, and work/life balance.\nJob Specifics\nLocation: Paris or Metz\nDuration: Permanent contract\nType of contract: Full time\nStart Date: As soon as possible\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "R",
                "Go"
            ],
            "DataBase": [
                "SQL",
                " MongoDB"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [
                "Spark",
                "Databricks"
            ],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [
                "AWS",
                "Azure"
            ],
            "DevTools": [],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [
                "Teams"
            ],
            "Other": [
                "ML",
                "Machine Learning",
                "Cloud"
            ],
            "FrSoftSkills": [
                "Communication",
                "Collaboration"
            ],
            "EnSoftSkils": [
                "Communication",
                "Teamwork",
                "Creativity",
                "Collaboration",
                "Organization",
                "Flexibility",
                "Interpersonal Skills"
            ]
        },
        "details": {
            "JobDetail": [
                "Remote",
                "Full"
            ],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "Data Analyst / Analytics Engineer (H/F)",
        "company": "METEOJOB by CleverConnect",
        "location": "Paris, \u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/data-analyst-analytics-engineer-h-f-at-meteojob-by-cleverconnect-3902873375?position=10&pageNum=25&refId=bvabfaeIkTn6w1fyYCK6qA%3D%3D&trackingId=HEC1%2BOT9CwGgp%2Bz4EHoEpQ%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Entreprise\nDescription de l'entreprise\nCleverConnect est une scale-up franco-allemande de la HR Tech en croissance fond\u00e9e il y a 10 ans par des ing\u00e9nieurs. Nous sommes pr\u00e9sents en France et Allemagne. Depuis la fusion avec Talentry en 2022, nous partageons l'ambition de devenir le leader des software solutions du Talent Acquisition en Europe\nNous accompagnons actuellement plus de 10 millions de candidats par an \u00e0 trouver le bon poste Pour cela, nous mettons en relation les recruteurs et les candidats avec des solutions digitales et des plateformes SaaS innovantes pour rendre le processus de recrutement plus efficace. Nos technologies permettent aux candidats de trouver des opportunit\u00e9s plus cibl\u00e9es et de valoriser leur personnalit\u00e9 et motivation\nRejoignez notre \u00e9quipe internationale de 200 coll\u00e8gues qui partagent la m\u00eame culture et les m\u00eames valeurs, et qui sont pleinement engag\u00e9s dans un projet \u00e0 fort impact soci\u00e9tal\nSi vous voulez en savoir plus : www.cleverconnect.com\nDescription Du Poste\nDescription du poste\nEn tant que Data Analyst, quelles seront vos responsabilit\u00e9s ?\nCollaborer avec les d\u00e9partements Product, Sales, Marketing et Communication pour comprendre les besoins m\u00e9tier et les traduire en solutions de donn\u00e9es.\nImpl\u00e9menter et optimiser des mod\u00e8les de donn\u00e9es \u00e0 l'aide de DBT et garantir la qualit\u00e9 et l'int\u00e9grit\u00e9 des donn\u00e9es. Vous serez en charge de transformer et mettre en forme les donn\u00e9es du datawarehouse en approche ELT.\nUtiliser BigQuery et DBT pour analyser de grands ensembles de donn\u00e9es et en tirer des insights exploitables.\nCr\u00e9er et maintenir des rapports et des tableaux de bord dans des outils de dataviz type Looker Studio, Superset, PowerBI ou Metabase. Ces tableaux de bords peuvent concerner les besoins internes (product, communication, marketing, sales, etc.) et externes (embedded dans nos solutions \u00e0 destination des clients).\nParticiper \u00e0 la conception des pipelines d'ingestion de donn\u00e9es avec le Data Engineer.\nEffectuer des analyses ad hoc et fournir des recommandations bas\u00e9es sur les donn\u00e9es pour soutenir les d\u00e9cisions m\u00e9tier.\nQualifications\nDescription du profil :\nQui \u00eates-vous ?\nVous avez au moins 5 ann\u00e9es d'exp\u00e9rience en tant que Data Analyst dans un environnement similaire.\nTechniquement et id\u00e9alement ,\nMa\u00eetrise avanc\u00e9e de SQL et exp\u00e9rience de travail avec des ensembles de donn\u00e9es \u00e0 grande \u00e9chelle.\nExp\u00e9rience pratique avec BigQuery, DBT ou \u00e9quivalents requis. Exp\u00e9riences Snowplow et Elasticsearch appr\u00e9ci\u00e9es.\nFamiliarit\u00e9 avec les outils de visualisation de donn\u00e9es tels que Looker Studio, Superset, PowerBI ou Metabase.\n\u00catre \u00e0 l'aise dans le scripting python pour automatiser certaines transformations de donn\u00e9es.\nAvoir d\u00e9j\u00e0 manipul\u00e9 un outil de Web Analytics tel que Google Analytics.\nExp\u00e9rience dans un environnement Agile et capacit\u00e9 \u00e0 travailler en collaboration dans des \u00e9quipes interfonctionnelles.\nQ\nue trouverez-vous chez CleverConnect ?\nUne \u00e9quipe dirigeante accessible, bienveillante et \u00e0 l'\u00e9coute\nDes bureaux au c\u0153ur des villes et la possibilit\u00e9 de faire du t\u00e9l\u00e9travail\nDes opportunit\u00e9s de formation, d'\u00e9volution et de mobilit\u00e9 en Europe\nRTT, mutuelle, carte d\u00e9jeuner, remboursement 50% transport, forfait mobilit\u00e9 durable\nNotre Processus De Recrutement Comprend\nEntretien initial avec un Responsable de l'Acquisition de Talents\nEntretien avec le Manager (d\u00e9couverte/\u00e9valuations techniques)\nDernier entretien avec le Directeur IT ou CPTO.\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "R",
                "Go"
            ],
            "DataBase": [
                "SQL",
                "Elasticsearch"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [
                "Tableau",
                "PowerBI"
            ],
            "Statistics": [],
            "CloudComputing": [],
            "DevTools": [
                "Git"
            ],
            "Os": [],
            "DBMS": [
                "BigQuery"
            ],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [],
            "FrSoftSkills": [
                "Communication",
                "Collaboration"
            ],
            "EnSoftSkils": [
                "Communication",
                "Collaboration"
            ]
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s",
                "10",
                "10",
                "10"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "Data Engineer - H/F",
        "company": "Free Pro",
        "location": "Marseille, Provence-Alpes-C\u00f4te d'Azur, France",
        "link": "https://fr.linkedin.com/jobs/view/data-engineer-h-f-at-free-pro-3861276685?position=1&pageNum=27&refId=Uq1oQzOiE7s5uwPCeaspnQ%3D%3D&trackingId=8580IxIBEcGpb2%2B5NQW08Q%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Au sein de la Direction Technique & innovation, dans le service recherche et innovation, vous travaillez sur des projets d\u2019envergure, notamment autour de la 5G et du Edge. Ce p\u00f4le d\u2019innovation d\u00e9friche et pr\u00e9pare les technologies de demain, le tout dans un contexte de croissance avec une forte composante technique. Dans une \u00e9quipe d\u2019ing\u00e9nieurs experts FULL STACK passionn\u00e9s dans les d\u00e9veloppements Back / Front / DevOps / Syst\u00e8me / Embarqu\u00e9 ainsi que PO / CP, vous int\u00e9grez une \u00e9quipe dont le moteur est sa capacit\u00e9 \u00e0 apporter des r\u00e9ponses techniques innovantes en rupture de l\u2019existant, via des POC fiables et rapides, qui pr\u00e9figureront les produits Free Pro de demain.\nVos Missions\nD\u00e9velopper les solutions techniques de collecte, stockage et transformation de la donn\u00e9e, dans un contexte MLOps :\nMa\u00eetrise avanc\u00e9e des langages de programmation pour le traitement des donn\u00e9es, tels que Python, et SQL\nCapacit\u00e9 \u00e0 construire et \u00e0 maintenir des architectures de donn\u00e9es robustes et des pipelines de donn\u00e9es \u00e9volutifs\nExp\u00e9rience approfondie avec les syst\u00e8mes de gestion, le maintien et la documentation de base de donn\u00e9es (SQL, NoSQL) et des outils d'extraction de donn\u00e9es.\nExp\u00e9rience dans la manipulation et l'analyse de grands ensembles de donn\u00e9es (Big Data) avec des outils tels que Hadoop, Spark, ou Kafka\nIndustrialiser et automatiser le nettoyage de la donn\u00e9e\nMettre en place et maintenir les batchs, c\u2019est-\u00e0-dire les automatisations d\u2019une s\u00e9rie de traitements en vue de l'int\u00e9gration dans des mod\u00e8les statistiques\nCompr\u00e9hension des algorithmes d'apprentissage automatique et de leur mise en \u0153uvre pratique\nG\u00e9rer le cycle de vie de la donn\u00e9e conform\u00e9ment \u00e0 la politique de gouvernance des donn\u00e9es de l'entreprise (RGPD...)\nR\u00e9aliser les tests unitaires et d\u2019int\u00e9gration\nAssurer le suivi de production et la maintenance\nDe formation Bac+3 \u00e0 Bac+5, vous justifiez d\u2019une exp\u00e9rience r\u00e9ussie sur ce type de poste. Si vous souhaitez monter en comp\u00e9tence sur la technique et \u00e9voluer dans un environnement en perp\u00e9tuel \u00e9volution, ce poste est fait pour vous.\nComp\u00e9tences Requises\nComp\u00e9tences solides en statistique et en mod\u00e9lisation math\u00e9matique en vue de l'int\u00e9gration dans des mod\u00e8les de Machine Learning\nAptitude \u00e0 travailler avec des outils de visualisation de donn\u00e9es comme Matplotlib, Seaborn, Tableau, Power BI.\nDes connaissances sp\u00e9cifiques dans les domaines de la 5G du Edge computing ou de l\u2019IA seraient un atout suppl\u00e9mentaire.\nAutonomie et prise d\u2019initiative\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "R",
                "Go"
            ],
            "DataBase": [
                "SQL",
                "NoSQL"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [
                "Hadoop",
                "Spark"
            ],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [
                "Tableau",
                "Power BI",
                "Matplotlib",
                "Seaborn"
            ],
            "Statistics": [
                "Statistiques"
            ],
            "CloudComputing": [],
            "DevTools": [],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [
                "DevOps",
                "Big Data",
                "ML",
                "Machine Learning",
                "Statistiques"
            ],
            "FrSoftSkills": [],
            "EnSoftSkils": [
                "Initiative"
            ]
        },
        "details": {
            "JobDetail": [
                "Full"
            ],
            "TypeContract": [],
            "Salary": [],
            "Level": [
                "Bac+5",
                "Bac+3"
            ],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "DATA ENGINEER \u2013 F/H \u2013 ALTERNANCE",
        "company": "La Mutuelle G\u00e9n\u00e9rale",
        "location": "Greater Paris Metropolitan Region",
        "link": "https://fr.linkedin.com/jobs/view/data-engineer-%E2%80%93-f-h-%E2%80%93-alternance-at-la-mutuelle-g%C3%A9n%C3%A9rale-3909189678?position=2&pageNum=27&refId=Uq1oQzOiE7s5uwPCeaspnQ%3D%3D&trackingId=t8Ie4MR4QMK2e8YkVMymPA%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "A PROPOS DE NOUS\nD\u00e9butez ou faites \u00e9voluer votre carri\u00e8re\nau sein d\u2019un acteur singulier de l\u2019\u00e9conomie sociale et solidaire,\navec un m\u00e9tier et une culture qui vous ressemblent!\nLa possibilit\u00e9 de t\u00e9l\u00e9travailler de 1 \u00e0 4 jours par semaine, selon la fonction et l\u2019organisation du site, permet \u00e0 nos 1900 collaborateurs de\nb\u00e9n\u00e9ficier d\u2019un cadre de travail source de sens, de confiance mutuelle et de responsabilisation\n.\n89% d\u2019entre eux recommandent La Mutuelle G\u00e9n\u00e9rale !\nPosez vos questions \u00e0 nos ambassadeurs ici:\nhttps://lamutuellegenerale.career-inspiration.com/\nVOTRE ENVIRONNEMENT DE TRAVAIL\nLa Direction des Syst\u00e8mes d\u2019Information est un partenaire aupr\u00e8s des M\u00e9tiers et a pour ambition de leur d\u00e9livrer l\u2019offre, la valeur ajout\u00e9e, les services et les comp\u00e9tences. Dans ce contexte, nous renfor\u00e7ons l\u2019\u00e9quipe Datalake de la Direction des Syst\u00e8mes d\u2019Information en recrutant un(e) apprenti(e) Data Engineer.\nMISSIONS\nVous identifiez et vous r\u00e9pondez aux besoins des directions fonctionnelles ;\nVous participez \u00e0 la conception et au d\u00e9veloppement des solutions performantes pour la construction, la maintenance et l'enrichissement du Datalake de la Mutuelle G\u00e9n\u00e9rale ;\nVous participez au d\u00e9veloppement et \u00e0 l\u2019industrialisation des projets Data Sciences avec les m\u00e9thodologies Agiles et DevOps ;\nVous contribuez ainsi \u00e0 des uses case innovants ;\nVous assurez une veille technologique autour de l'\u00e9cosyst\u00e8me Big Data.\nCE QUE VOUS POUVEZ ATTENDRE DE NOUS\nUne mont\u00e9e en comp\u00e9tences sur des technologies r\u00e9centes et innovantes\nUn r\u00e9el accompagnement pour d\u00e9couvrir le m\u00e9tier de Data Engineer\nUn environnement de travail bienveillant et responsabilisant\nJusqu\u2019\u00e0 quatre jours de t\u00e9l\u00e9travail par semaine\nVOS ATOUTS POUR REUSSIR\nFormation:\nDe formation sup\u00e9rieure BAC + 4/5, vous avez une app\u00e9tence pour travailler dans un environnement Data/BIG Data (AWS, Snowflake, Python, Spark, SQL \u2026)\nDans votre bo\u00eete \u00e0 outils:\nDe nature curieuse, vous appr\u00e9ciez prendre des initiatives\nAutonome, vous \u00eates capable de remonter les difficult\u00e9s / alertes\nStructur\u00e9(e), vous avez une bonne capacit\u00e9 d\u2019\u00e9coute, d\u2019analyse et de synth\u00e8se\nRigoureux(se), vous savez prioriser et trouver sans cesse des axes d\u2019am\u00e9lioration\nSi vous vous reconnaissez, alors n\u2019h\u00e9sitez plus, postulez et rencontrons-nous au plus vite !\nContrat\n{{:}}\nApprentissage 12 ou 24 mois, \u00e0 compter de septembre 2024\nLieu de travail:\n75013 - Paris\nVous trouverez \u00e9galement chez nous:\nOpen travail, Tickets restaurant, RIE, Mutuelle, Remboursement transport, \u2026\nMots cl\u00e9s: #devops, #bigdata, #assurance, #alternance\nPour aller plus loin, visionnez cette vid\u00e9o\nhttps://www.youtube.com/watch?v=GdYDg60Ryus\net/ou rendez-vous sur\nhttps://www.lamutuellegenerale.fr/ et https://www.lamutuellegenerale.fr/les-salaries-de-lamutuelle-generale-plebiscitent-lopen-travail-et-pres-de-9-sur-10-la-recommandent\nConform\u00e9ment aux engagements pris par La Mutuelle G\u00e9n\u00e9rale en faveur de l'int\u00e9gration des personnes en situation de handicap, le poste propos\u00e9 est ouvert \u00e0 tous.\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "R",
                "Go"
            ],
            "DataBase": [
                "SQL"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [
                "Spark"
            ],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [
                "AWS"
            ],
            "DevTools": [],
            "Os": [],
            "DBMS": [
                "Snowflake",
                "Snowflake"
            ],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [
                "DevOps",
                "Big Data"
            ],
            "FrSoftSkills": [
                "Organisation"
            ],
            "EnSoftSkils": [
                "Initiative"
            ]
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "Ing\u00e9nieur data Spark exp\u00e9riment\u00e9 (F/ H)",
        "company": "Thales",
        "location": "V\u00e9lizy-Villacoublay, \u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/ing%C3%A9nieur-data-spark-exp%C3%A9riment%C3%A9-f-h-at-thales-3886251447?position=3&pageNum=27&refId=Uq1oQzOiE7s5uwPCeaspnQ%3D%3D&trackingId=oSyZoLohhtClt8DitaAKHw%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "QUI SOMMES-NOUS ?\nThales est un leader mondial des hautes technologies comptant plus de 81 000 collaborateurs pr\u00e9sents sur tous les continents. Le Groupe investit dans les innovations du num\u00e9rique et de la \u00ab deep tech \u00bb \u2013 big data, intelligence artificielle, connectivit\u00e9, cybers\u00e9curit\u00e9 et quantique \u2013 pour construire un avenir de confiance, essentiel au d\u00e9veloppement de nos soci\u00e9t\u00e9s, en pla\u00e7ant l\u2019humain au c\u0153ur des d\u00e9cisions.\nThales propose des solutions, services et produits qui aident ses clients \u2013 entreprises, organisations, Etats \u2013 dans cinq grands march\u00e9s vitaux pour le fonctionnement de nos soci\u00e9t\u00e9s : identit\u00e9 et s\u00e9curit\u00e9 num\u00e9riques, d\u00e9fense, a\u00e9ronautique, espace, et transport.\nQUI ETES-VOUS ?\nDipl\u00f4m\u00e9 d\u2019un Bac+5 en \u00e9cole d\u2019ing\u00e9nieur ou \u00e9quivalent universitaire avec une sp\u00e9cialisation en informatique, vous avez au moins 5 ans d'exp\u00e9rience dans les technologies Big Data.\nCE QUE NOUS POUVONS ACCOMPLIR ENSEMBLE :\nEn tant que Data Engineer, vous jouerez un r\u00f4le cl\u00e9 dans la conception, le d\u00e9veloppement et la maintenance de notre infrastructure de donn\u00e9es, ainsi que dans la transformation et la gestion des flux de donn\u00e9es.\nVOS MISSIONS :\n\u2022 Concevoir, d\u00e9velopper et d\u00e9ployer des solutions Big Data en utilisant les technologies Spark.\n\u2022 Mettre en place des pipelines de donn\u00e9es performants pour l'ingestion, le traitement et le stockage des donn\u00e9es massives.\n\u2022 Collaborer \u00e9troitement avec les \u00e9quipes m\u00e9tier pour comprendre leurs besoins en mati\u00e8re d'analyse de donn\u00e9es et proposer des solutions adapt\u00e9es.\n\u2022 Optimiser les performances des clusters Hadoop pour garantir une exploitation efficace des donn\u00e9es.\n\u2022 Assurer la qualit\u00e9 et la fiabilit\u00e9 des donn\u00e9es trait\u00e9es, en mettant en place des processus de validation et de nettoyage.\n\u2022 Identifier et r\u00e9soudre les probl\u00e8mes li\u00e9s \u00e0 l'infrastructure Big Data et proposer des am\u00e9liorations.\n\u2022 Travailler en \u00e9troite collaboration avec les Data Scientists et les Data Analysts pour fournir des insights pertinents \u00e0 partir des donn\u00e9es.\nInnovation, passion, ambition : rejoignez Thales et cr\u00e9ez le monde de demain, d\u00e8s aujourd\u2019hui.\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "R"
            ],
            "DataBase": [],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [
                "Hadoop",
                "Spark"
            ],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [],
            "DevTools": [],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [
                "Big Data"
            ],
            "FrSoftSkills": [
                "Collaboration",
                "Organisation"
            ],
            "EnSoftSkils": [
                "Collaboration"
            ]
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [],
            "Salary": [],
            "Level": [
                "Bac+5"
            ],
            "Experience": [
                "a",
                "n",
                "s",
                "5",
                "5",
                "5"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "Data Engineer (F/H)",
        "company": "Akuo",
        "location": "Paris, \u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/data-engineer-f-h-at-akuo-3905522805?position=4&pageNum=27&refId=Uq1oQzOiE7s5uwPCeaspnQ%3D%3D&trackingId=IwoO0Zykt%2F%2BB1AG8NMgw8g%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Fond\u00e9 en 2007, Akuo est un producteur ind\u00e9pendant d\u2019\u00e9nergie renouvelable implant\u00e9 dans plus d'une vingtaine de pays \u00e0 travers le monde. Le Groupe est pr\u00e9sent sur l\u2019ensemble de la cha\u00eene de valeur : d\u00e9veloppement, financement, construction et exploitation de centrale d\u2019\u00e9nergie solaire, \u00e9olienne et de stockage.\nLes \u00e9quipes d'Akuo allient pertinence technologique, valeur ajout\u00e9e environnementale et gain soci\u00e9tal pour d\u00e9velopper des projets exemplaires et porteurs de sens dans les territoires. Le Groupe est notamment le pionnier de l'agrivolta\u00efsme, des solutions de stockage et a \u00e9t\u00e9 le premier \u00e0 d\u00e9velopper des centrales solaires flottantes de grande envergure en France.\nFid\u00e8le \u00e0 ses valeurs et ses convictions, Akuo est une entreprise responsable, attach\u00e9e \u00e0 la diversit\u00e9 de ses \u00e9quipes, engag\u00e9e et d\u00e9termin\u00e9e dans l'inclusion de tous.\nDescription du poste\nLe poste est \u00e0 pourvoir \u00e0 Paris, dans le d\u00e9partement IT/OT d'Akuo, et plus particuli\u00e8rement au sein du p\u00f4le Data, dont l\u2019objectif est de construire et faire \u00e9voluer la strat\u00e9gie \u2018data\u2019 du groupe.\nEn tant que Data Engineer, vous ferez \u00e9voluer la base de donn\u00e9es d\u2019Akuo. Vous aurez pour objectif de faciliter l\u2019exploitation de ces donn\u00e9es en optimisant tout le chemin de la donn\u00e9e, de l\u2019extraction jusqu\u2019au stockage et au nettoyage de la donn\u00e9e.\nVos\nmissions op\u00e9rationnelles\nseront les suivantes:\nBUILD :\nMise en place de l'architecture Data : concevoir et mettre en place les flux d'int\u00e9gration de donn\u00e9es,\nR\u00e9pondre aux demandes du m\u00e9tier (\u00e9quipes techniques et supports)\n:\nparticiper \u00e0 toutes les phases de projets, de l'analyse des besoins \u00e0 la r\u00e9alisation des tests tout en respectant les crit\u00e8res de qualit\u00e9, de d\u00e9lai et de co\u00fbt.\nRUN :\nTraitement, structuration et transformation de donn\u00e9es (Python),\nCollecter en temps r\u00e9el, stocker et mod\u00e9liser les donn\u00e9es issues des centrales \u00e9lectriques (Time Series) en relation avec nos \u00e9quipes op\u00e9rationnelles,\nAssurer un support technique sur les probl\u00e9matiques Data : remont\u00e9e des tickets.\nQualifications\nNous sommes \u00e0 la recherche d\u2019un profil junior qui aurait entre 2 et 3 ans d\u2019exp\u00e9rience, alternance incluse, au sein d\u2019\u00e9quipe \u2018data\u2019.\nPython & SQL: vous savez coder. Vous connaissez et savez lancer des proc\u00e9dures stock\u00e9es,\nMaitrise des concepts de mod\u00e9lisation de donn\u00e9es et de conception d'architectures Data,\nComp\u00e9tences en gestion de bases de donn\u00e9es relationnelles,\nLangue\n: La ma\u00eetrise de l\u2019anglais est requise pour pouvoir \u00e9changer avec une partie de nos \u00e9quipes qui n\u2019est pas francophone.\nInformations suppl\u00e9mentaires\nEl\u00e9ments essentiels:\nLa localisation: si\u00e8ge d\u2019Akuo au 140 avenue des Champs-Elys\u00e9es,\nLa r\u00e9mun\u00e9ration: fourchette entre 45k\u20ac et 49k\u20ac fixe selon profil + 5% de r\u00e9mun\u00e9ration variable,\nLe type de contrat: CDI,\nLe poste est ouvert au t\u00e9l\u00e9travail, jusqu\u2019\u00e0 2 jour par semaine + 10 jours flottants par an (soit 100 jours par an).\nAutres avantages:\nJusqu\u2019\u00e0 12 jours de repos par an,\nPrime vacances, ch\u00e8ques-cadeaux,\nInt\u00e9ressement / participation,\nTicket-restaurant (10\u20ac x 19 par mois) pris en charge \u00e0 60%,\nPrise en charge des transports en commun \u00e0 75% du tarif actuellement en vigueur ou forfait mobilit\u00e9 durable,\nLocaux agr\u00e9ables avec terrasses am\u00e9nag\u00e9es et salle de sport.\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "R"
            ],
            "DataBase": [
                "SQL"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [],
            "DevTools": [],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [],
            "FrSoftSkills": [],
            "EnSoftSkils": []
        },
        "details": {
            "JobDetail": [
                "Junior"
            ],
            "TypeContract": [
                "CDI"
            ],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s",
                "3",
                "3",
                "3"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "Data Analyst \u2013 Paris, France (H/F)",
        "company": "Astek",
        "location": "Paris, \u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/data-analyst-%E2%80%93-paris-france-h-f-at-astek-3839098102?position=5&pageNum=27&refId=Uq1oQzOiE7s5uwPCeaspnQ%3D%3D&trackingId=F63flraIlpTMmewFRIj9ZA%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "CDI\nParis - France\nPubli\u00e9e il y a 2 mois\nLe Groupe Astek\nCe Que Nous Allons Accomplir Ensemble :\nNous rejoindre en tant que\nData Analyst (H/F),\nafin d\u2019accompagner un op\u00e9rateur t\u00e9l\u00e9coms, Leader en Europe dans la gestion de ses solutions robustes, efficientes et s\u00e9curis\u00e9es \u00e0 destination d\u2019environnements vari\u00e9s.\nUn challenge portant sur des millions d\u2019utilisateurs dans un environnement technique innovant, strat\u00e9gique et o\u00f9 l\u2019entraide et la bonne humeur priment !\nVotre Mission, Si Vous L\u2019acceptez :\nEtude sur les donn\u00e9es pour aide au cadrage du besoin M\u00e9tier.\nForce de proposition sur des solutions analytiques adapt\u00e9es aux besoins utilisateurs (avec nos \u00e9quipes UX).\nAnalyse des besoins m\u00e9tiers, accompagnement \u00e0 la formulation et \u00e0 la d\u00e9finition de KPI m\u00e9tiers.\nMod\u00e9lisation des donn\u00e9es.\nConception de Datasets Big Query.\nConception et R\u00e9alisation de Datamarts et de Dashboards (PowerBI / Looker)\nAnalyse de la qualit\u00e9 de la donn\u00e9e source, pour challenger les \u00e9quipes Digitales / Data Engineers.\nVotre Future \u00c9quipe :\nAu sein d\u2019un environnement riche et complexe, vous \u00e9voluerez avec des experts passionn\u00e9s \u00e0 la fois techniques et fonctionnels (Ing\u00e9nieurs sp\u00e9cialis\u00e9s, chef de projet, scrum master, product owner \u2026).\nL\u2019\u00e9quipe est en interaction avec des clients \u00e0 la fois internes et externes.\nVotre stack de jeu\nSQL \u2013 Confirm\u00e9\nMod\u00e9lisation de Donn\u00e9es \u2013 Confirm\u00e9\nOutils de Data Viz \u2013 Confirm\u00e9\nGCP \u2013 Junior\nAnglais \u2013 Professionnel\nLes Petits Plus Du Projet :\nVous interviendrez de A \u00e0 Z sur des projets riches fonctionnellement et ambitieux techniquement. Un challenge portant sur des millions d\u2019utilisateurs dans un environnement technique innovant et strat\u00e9gique.\nVous ?\nDipl\u00f4m\u00e9(e) d\u2019une \u00e9cole d\u2019ing\u00e9nieur ou \u00e9quivalent de niveau Bac+5.\nVous justifiez id\u00e9alement d\u2019une exp\u00e9rience d\u2019au moins 3 ans d\u2019exp\u00e9riences sur un poste similaire ?\nVous faite preuve d\u2019un bon relationnel et d\u2019esprit d\u2019\u00e9quipe, \u00eates dot\u00e9(e) d\u2019un excellent sens de l\u2019organisation et vous aimez les challenges et la r\u00e9solution de probl\u00e8me ?\nAlors ce poste est fait pour vous, n\u2019h\u00e9sitez plus et rejoignez l\u2019aventure ASTEK !\nAstek\nCr\u00e9\u00e9 en France en 1988, Astek est un acteur mondial de l\u2019ing\u00e9nierie et du conseil en technologies. Fort de son expertise dans de nombreux secteurs industriels et tertiaires, Astek accompagne ses clients internationaux dans le d\u00e9ploiement intelligent de leurs produits et de leurs services, et dans la mise en \u0153uvre de leur transformation digitale.\nDepuis sa cr\u00e9ation, le Groupe a fond\u00e9 son d\u00e9veloppement sur une forte culture d\u2019entrepreneuriat et d\u2019innovation, et sur l\u2019accompagnement et la mont\u00e9e en comp\u00e9tence de\nses 7800 collaborateurs\nqui s\u2019engagent chaque jour \u00e0 promouvoir la compl\u00e9mentarit\u00e9 entre les technologies num\u00e9riques et l\u2019ing\u00e9nierie des syst\u00e8mes complexes.\nRejoignez un Groupe en fort d\u00e9veloppement en France et \u00e0 travers le monde ayant r\u00e9alis\u00e9 un chiffre d\u2019affaires de 600 M\u20ac en 2023.\nTous les d\u00e9tails sur le Groupe sur le site https://astekgroup.fr. Et vous pouvez aussi nous suivre sur notre blog : https://blog.groupeastek.com.\nRencontrons-nous\nNotre projet commun vous plait ?\nPostulez \u00e0 cette annonce, et soyez transparent !\nMaud, notre Talent Acquisition Referent, vous contactera pour un premier \u00e9change.\nPuis vous rencontrerez Martin, votre futur manager, avec lequel vous \u00e9changerez autour d\u2019Astek, de votre parcours, de vos attentes et de votre future mission .\nEnfin, vous rencontrerez J\u00e9r\u00e9my, notre Directeur d\u2019agence avec lequel vous pourrez valider votre int\u00e9r\u00eat et ad\u00e9quation pour le poste et finaliser les \u00e9l\u00e9ments contractuels.\nNos Plus\nAstek est green et fait b\u00e9n\u00e9ficier ses salari\u00e9s d\u2019une indemnit\u00e9 kilom\u00e9trique v\u00e9lo\nUne politique CARE sur-mesure d\u00e9ploy\u00e9e par nos \u00e9quipes RH pour nos collaborateurs (https://astekgroup.fr/engagements)\nNotre charte de la Diversit\u00e9\nMots-cl\u00e9s :\ning\u00e9nieur \u2013 ing\u00e9nieure \u2013 consultant \u2013 consultante \u2013 data \u2013 analyst \u2013 mod\u00e9lisation \u2013 donn\u00e9es\nCaract\u00e9ristiques de l'emploi\nCat\u00e9gorie Ing\u00e9nieur\nJob Industry T\u00e9l\u00e9com / M\u00e9dia\nPostuler en ligne\nNom *\nPr\u00e9nom *\nEmail *\nUn email valide est requis.\nT\u00e9l\u00e9phone *\nUn num\u00e9ro de t\u00e9l\u00e9phone valide est requis.\nJoindre un CV *\nMots-cl\u00e9s :\ning\u00e9nieur \u2013 ing\u00e9nieure \u2013 consultant \u2013 consultante \u2013 data \u2013 analyst \u2013 mod\u00e9lisation \u2013 donn\u00e9es\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "R",
                "Go"
            ],
            "DataBase": [
                "SQL"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [
                "PowerBI"
            ],
            "Statistics": [],
            "CloudComputing": [],
            "DevTools": [
                "Git"
            ],
            "Os": [],
            "DBMS": [
                "Big Query"
            ],
            "SoftBigDataProcessing": [],
            "Automation": [
                "Chef"
            ],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [],
            "FrSoftSkills": [
                "Organisation"
            ],
            "EnSoftSkils": []
        },
        "details": {
            "JobDetail": [
                "Confirm\u00e9",
                "Junior"
            ],
            "TypeContract": [
                "CDI"
            ],
            "Salary": [],
            "Level": [
                "Bac+5"
            ],
            "Experience": [
                "a",
                "n",
                "s",
                "3",
                "3",
                "3"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "Lead data engineer",
        "company": "Ippon Technologies",
        "location": "Greater Tours Area",
        "link": "https://fr.linkedin.com/jobs/view/lead-data-engineer-at-ippon-technologies-3893228101?position=6&pageNum=27&refId=Uq1oQzOiE7s5uwPCeaspnQ%3D%3D&trackingId=7a8Vs0HE7rPte%2FjFc20ZEw%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Qui sommes-nous ?\nIppon, c'est l\u2019\u00e9nergie du collectif au service de la technologie !\nNous sommes un cabinet de conseil et d\u2019expertise technique.\nNos \u00e9quipes ont pour leitmotive de transformer des id\u00e9es innovantes en solutions de haute qualit\u00e9 avec un focus particulier sur la valeur apport\u00e9e aux utilisateurs.\nAujourd\u2019hui, nous souhaitons recruter un Lead Data Engineer pour lancer et d\u00e9velopper l'\u00e9quipe data tourangelle et int\u00e9grer la Practice Data compos\u00e9e de 70 consultants au national.\nNotre sp\u00e9cialit\u00e9 est de r\u00e9pondre aux enjeux de nos clients et avoir un impact fort dans leur volont\u00e9 de devenir Data-driven.\nMembre de la Practice Data, le futur Lead Data Engineer apportera son exp\u00e9rience et son mindset pour lead des \u00e9quipes sur des missions \u00e0 forte valeur ajout\u00e9e. Encadr\u00e9 par un mentor et le support de notre communaut\u00e9 Data dynamique, il pourra s'\u00e9panouir sur des sujets tendance et assurera sa mont\u00e9e en comp\u00e9tence et celle des autres.\nLa communaut\u00e9 Data propose un cadre et des \u00e9v\u00e8nements pour faire de la veille collective, partager leurs retours d'exp\u00e9riences, d\u00e9battre de sujets Data, etc. Notre lead sera un acteur majeur au sein de ce cadre.\nLes missions\nIntervenir sur les data platforms de nos clients pour d\u00e9velopper de nouveaux pipelines de donn\u00e9es en appliquant les bonnes pratiques de d\u00e9veloppements\nTravailler en collaboration avec les m\u00e9tiers, les data analystes et les data scientists pour leur fournir un support \u00e0 l\u2019industrialisation de leurs travaux (tests, int\u00e9gration continue, scalabilit\u00e9 des mod\u00e8les, craftsmanship, etc.)\nS'appuyer sur des sachants Cloud Builders pour construire des assets Data sur une infrastructure r\u00e9siliente aux petits oignons\nApporter son expertise sur un domaine en constante \u00e9volution\nParticiper aux \u00e9v\u00e8nements internes \u00e0 la communaut\u00e9 data (BBL, webinar, datap\u00e9ro interne, meetup, blog, dojos) et externes (Salon du Big Data, GCP Summit, Spark Summit, AWS Summit, Devoxx, workshop partenaire, meetups)\nCapitaliser sur les missions et les diff\u00e9rents \u00e9v\u00e8nements de la communaut\u00e9 au travers d\u2019articles de blogs, REX, BBL interne\nLe profil recherch\u00e9\nTu es de temp\u00e9rament curieux, force de proposition, tu as le sens du partage, l\u2019envie de t'am\u00e9liorer en continue et de participer activement \u00e0 une communaut\u00e9 data pleine de projets.\nUne exp\u00e9rience sur le cloud est un gros (gros, gros) plus, une veille active sur des sujets cloud est indispensable.\nId\u00e9alement, notre curieux saura identifier le pok\u00e9mon parmi cette liste et nous expliquer les autres mots qui n'en sont pas un :\nModern Data Platform\nData Warehouse\nData Lakehouse\nPikachu\nCloud Native\nServerless\nSi pour toi aussi \"tout part du besoin m\u00e9tier\", que tu t'identifies dans cette liste au p\u00e8re no\u00ebl et sauras nous en parler par exp\u00e9rience :\nPublic Cloud Provider (AWS, GCP, Azure)\nQuery engine (Spark, EMR, Databricks, Starburst, Athena...)\nLangage de programmation data (Python, SQL, Scala...)\nStockage (Redshift, Snowflake, BigQuery, Stockage objet S3/CloudStorage...)\nFramework d'ingestion/streaming de donn\u00e9es (Kafka, Amazon Kinesis, Google DataFlow, ...)\nOutil de visualisation (Tableau, Metabase, Superset...)\nLe delivery et les projets en production faisant partie de notre ADN, tu es capable de livrer du code de qualit\u00e9 dans des environnements agiles.\nLes + du job\nTravailler avec une \u00e9quipe o\u00f9 tu pourras apporter tes propres id\u00e9es !\nDevenir ceinture noire en Data gr\u00e2ce \u00e0 notre programme d\u2019accompagnement de carri\u00e8re Blackbelt ! (formations, certifications AWS/Azure, mentoring, coaching)\nUne \u00e9volution de carri\u00e8re adapt\u00e9e \u00e0 tes exp\u00e9riences et tes souhaits\nLe partage de connaissances (articles, meetup, blog), participation des \u00e0 conf\u00e9rences nationales ou internationales (AWS Summit, Salon du big data)\nUne charte de t\u00e9l\u00e9travail\nEt Tours alors ?\nCr\u00e9\u00e9e en 2023, l\u2019agence est en plein d\u00e9veloppement et nous comptons sur toi pour y jouer un r\u00f4le majeur afin de construire l\u2019agence qui te, et nous, ressemble. Tu int\u00e9greras une petite \u00e9quipe de consultants experts et passionn\u00e9s par la technique, et o\u00f9 le partage et la bonne humeur sont de mise.\nTu l\u2019auras compris, en tant que lead data engineer, tu seras le r\u00e9f\u00e9rent Data au niveau de l\u2019agence et tu accompagneras nos prochains data engineers tourangeaux dans l\u2019acc\u00e9l\u00e9ration de leur carri\u00e8re et expertises.\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "Scala",
                "R",
                "Go"
            ],
            "DataBase": [
                "SQL"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [
                "Spark",
                "Databricks"
            ],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [
                "Tableau"
            ],
            "Statistics": [],
            "CloudComputing": [
                "AWS",
                "Azure"
            ],
            "DevTools": [],
            "Os": [],
            "DBMS": [
                "Snowflake",
                "Snowflake",
                "BigQuery"
            ],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [
                "Big Data",
                "Cloud"
            ],
            "FrSoftSkills": [
                "Collaboration"
            ],
            "EnSoftSkils": [
                "Collaboration"
            ]
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "Data Engineer, Wheat",
        "company": "Louis Dreyfus Company",
        "location": "Villeurbanne, Auvergne-Rh\u00f4ne-Alpes, France",
        "link": "https://fr.linkedin.com/jobs/view/data-engineer-wheat-at-louis-dreyfus-company-3892567948?position=7&pageNum=27&refId=Uq1oQzOiE7s5uwPCeaspnQ%3D%3D&trackingId=1XqpxPIHqCkfK%2B%2B3ZoLmkA%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Company Description\nLouis Dreyfus Company is a leading merchant and processor of agricultural goods. Our activities span the entire value chain from farm to fork, across a broad range of business lines, we leverage our global reach and extensive asset network to serve our customers and consumers around the world. Structured as a matrix organization of six geographical regions and ten platforms, Louis Dreyfus Company is active in over 100 countries and employs approximately 17,000 people globally.\nJob Description\nLDC is looking for a Data Engineer to join the Global Digital Transformation and Analytics (DT & A) team of data engineering experts, supporting innovative solutions whose impact is transforming our business.\nAs a data engineer, you will provide the data to enable faster, better, data-informed decision-making within our business. You will be working with the\nYou will focus on creating high performant, easy to maintain, state of the art data pipelines, bringing data from source to insight. You will use the latest technology and you will see the impact of your work in transforming our business.\nDuties & Responsibilities:\nEnsure data availability, quality, and timeliness by designing and implementing performant pipelines and proactive monitoring. Ideate meaningful tests and monitoring to be proactively informed in case of data problems and to minimize regressions.\nCreate and maintain high quality, well documented code and data transformations to feed models and insights reliably.\nAct as data steward with researchers, traders and operations to help them leverage the best data sets for their use case and the most relevant best practices to ensure data is always available\nRetrieve, clean, model, transform and maintain data from many sources to better understand the factors influencing wheat global and local flows and prices\nTroubleshoot and solve data issues from data ingestion to display in dashboards and reports\nProvide technical support and guidance to data scientists and researchers\nExperience\n3-5 years of experience in technical, hands on roles\n2+ years' experience in data manipulation in SQL: DB design, data modelling, data transformation pipelines, ETL, data management\n2+ years\u2019 experience with Python, including data manipulation and visualization packages (e.g., Pandas, Numpy, Plotly\u2026)\nExperience with data visualisation tools and technologies like PowerBI, Tableau, Looker.\nData mining principles: data collection, wrangling and quality checks using multiple data systems\nExperience working with cloud technologies like Azure, AWS or GCP\nExperience with any of the following will be considered a plus:\nHands on experience with data storage solutions and their application: SQL, NoSQL, data lakes\nPrinciples of modern full stack development and exposure to Python frameworks like Dash or Flask, familiarity with APIs\nAgile development and DevOps tools: CI / CD pipelines, testing and monitoring best practices.\nSupport for business-critical data transformation and applications via monitoring and alerting, and contributing to the solution of critical incidents under time pressure\nWhat Soft Skills will make you successful\n:\nQuick learner with the ability to work independently and with little prompting\nExcellent communication, collaboration and engagement skills\nCritical thinking, inclination to make improvements, find new ideas and challenge the status quo\nFlexibility and sense of adaptability in a quick paced, constantly evolving context\nPassionate about improving data literacy and spreading best practices\nAbility to perform under pressure, prioritize and escalate\nStrong problem solving, quantitative and analytical abilities\nFluent in English\nExperience in the commodities sector is considered as a plus\nEducation:\nA Bachelor or Master in Computer Science, Business/Management Information Systems, Computer/Systems/Industrial Engineering, Business Analytics, Data Science, Operations Research or Statistics. Other backgrounds will be considered with relevant work experience.\nAdditional Information\nWhy you should apply for this role\n:\nYou will be working in a very concrete line of business whose impact literally feeds the world. You will get a unique point of view on major data flows of commodities around the world, including the impact of climate change and major geo political events, the importance of sustainability and regenerative agriculture.\nYou will become an expert of the latest cutting-edge technologies in Data Engineering, leveraging Microsoft Azure Platform, working in collaboration with a team of technology and data science experts and accessing high quality training and development opportunities\nYou will see the impact of your role in transforming our business\nWhat We Offer\nWe provide a dynamic and stimulating international environment, which will stretch and develop your abilities and channel your skills and expertise with outstanding career development opportunities in one of the largest and most solid private companies in the world.\nWe offer\nCompetitive salary and benefits\nFlexible working\nAccess to Training and Development\nDiversity & Inclusion\nLDC is driven by a set of shared values and high ethical standards, with diversity and inclusion being part of our DNA. LDC is an equal opportunity employer committed to providing a working environment that embraces and values diversity, equity and inclusion.\nLDC encourages diversity, supports local communities and environmental initiatives. We encourage people of all backgrounds to apply.\nSustainability\nSustainable value is at the heart of our purpose as a company.\nWe are passionate about creating fair and sustainable value, both for our business and for other value chain stakeholders: our people, our business partners, the communities we touch and the environment around us\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "Scala",
                "R",
                "Go"
            ],
            "DataBase": [
                "SQL",
                "NoSQL"
            ],
            "DataAnalytics": [
                "Pandas",
                "NumPy",
                "R"
            ],
            "BigData": [],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [
                "Tableau",
                "PowerBI",
                "Plotly"
            ],
            "Statistics": [
                "Statistics"
            ],
            "CloudComputing": [
                "AWS",
                "Azure"
            ],
            "DevTools": [
                "Git"
            ],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [
                "DevOps",
                "Cloud",
                "CI / CD"
            ],
            "FrSoftSkills": [
                "Communication",
                "Collaboration"
            ],
            "EnSoftSkils": [
                "Communication",
                "Adaptability",
                "Problem Solving",
                "Collaboration",
                "Organization",
                "Flexibility",
                "Initiative",
                "Critical Thinking"
            ]
        },
        "details": {
            "JobDetail": [
                "Full"
            ],
            "TypeContract": [],
            "Salary": [
                "Salary",
                "Package"
            ],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "Data Engineer H/F",
        "company": "ELOSI",
        "location": "Villeneuve-d\u2019Ascq, Hauts-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/data-engineer-h-f-at-elosi-3842107940?position=8&pageNum=27&refId=Uq1oQzOiE7s5uwPCeaspnQ%3D%3D&trackingId=LEzdD9K6u9P8NJ4vMYEhtg%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "A propos d'Elosi\nCr\u00e9\u00e9e en 2005, Elosi r\u00e9unit maintenant 120 collaborateurs pour mener \u00e0 bien les projets digitaux de ses clients depuis leurs locaux ou depuis notre centre de service et R&D \u00e0 Villeneuve d\u2019Ascq.\nLe poste et vos missions\nPour l'un de nos clients grand compte de la m\u00e9tropole lilloise, nous recherchons un data engineer. Vous travaillerez en collaboration avec les \u00e9quipes de d\u00e9veloppement.\nVos missions\n:\nCorrection et cr\u00e9ation des nouvelles features d'int\u00e9gration de donn\u00e9es sur plusieurs produits digitaux ;\nCr\u00e9ation des pipeline d'int\u00e9gration des donn\u00e9es stambia ou outils internes vers google BigQuery ;\nMise en place des dashboard powerBI ;\nTransformation des donn\u00e9es en \u00e9laborant des mod\u00e8les conceptuels.\nL'environnement technique\nStambia, Google BiQuery, PowerBI\nVotre profil\nDe formation sup\u00e9rieure en informatique, vous avec une exp\u00e9rience en d\u00e9veloppement de flux Stambia d'au moins 2 ans, vous connaissez Google BigQuery.\nVous aimez \"pr\u00e9parer\" les donn\u00e9es brutes, faciliter leur exploitation et les rendre \"propres\" pour l'analyse qui suivra.\nVotre anglais est op\u00e9rationnel.\nNous rejoindre, c'est :\nRejoindre une communaut\u00e9 de passionn\u00e9s et la participation \u00e0 des conf\u00e9rences techniques (DevoXX, DevFest Lille, atelier LiveCoding, Pair programming, Ap\u00e9r\u2019Ops\u2026) ;\nDe la convivialit\u00e9, du partage, de la proximit\u00e9 ;\nDes perspectives d\u2019\u00e9volutions tant technique que m\u00e9tier !\nDes avantages : carte restaurant, formations, primes\u2026\nSi ce poste vous anime, n'h\u00e9sitez plus et postulez !\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "R",
                "Go"
            ],
            "DataBase": [],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [
                "PowerBI"
            ],
            "Statistics": [],
            "CloudComputing": [],
            "DevTools": [
                "Git"
            ],
            "Os": [],
            "DBMS": [
                "BigQuery"
            ],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [],
            "FrSoftSkills": [
                "Collaboration"
            ],
            "EnSoftSkils": [
                "Collaboration"
            ]
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s",
                "2",
                "2",
                "2"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "Data Engineer Snowflake/ Azure Senior F/H",
        "company": "NODYA Group - Digital Services",
        "location": "Paris, \u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/data-engineer-snowflake-azure-senior-f-h-at-nodya-group-digital-services-3911222296?position=9&pageNum=27&refId=Uq1oQzOiE7s5uwPCeaspnQ%3D%3D&trackingId=5UYfKxaHdBePWNbdCSMLqg%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Les missions du poste\nNous cherchons un Data Engineer Snowflake/ Azure Senior pour rejoindre l'\u00e9quipe Data Factory d'un grand leader fran\u00e7ais, situ\u00e9 en \u00cele-de-France. Ce r\u00f4le implique la responsabilit\u00e9 de nouveaux d\u00e9veloppements de pipelines de donn\u00e9es, en adh\u00e9rant aux normes, meilleures pratiques, et principes CI/CD complets.\nResponsabilit\u00e9s :\nCr\u00e9ation et modification d'objets de base de donn\u00e9es Snowflake (bases de donn\u00e9es, tables, vues, etc.).\nD\u00e9veloppement de proc\u00e9dures stock\u00e9es Snowflake avec SQL & Javascript.\nMise en \u0153uvre de l'environnement de d\u00e9veloppement vers l'environnement de production, en suivant le processus CI/CD.\nGarantir un haut niveau de service, incluant la d\u00e9finition, la construction, l'ex\u00e9cution, et la gestion des incidents.\nGarantir une qualit\u00e9 irr\u00e9prochable des codes fournis par l'\u00e9quipe de d\u00e9veloppement.\nLe profil recherch\u00e9\nDipl\u00f4me d'ing\u00e9nieur Bac+5 en informatique.\nPlus de 5 ans d'exp\u00e9rience hors alternance et stage dans un poste similaire.\nUne exp\u00e9rience dans le d\u00e9veloppement SQL et une ma\u00eetrise en technologies de plateformes de donn\u00e9es (Snowflake, Azure SQL, MS SQL, etc.).\nExp\u00e9rience avec Azure DevOps et familiarit\u00e9 avec d'autres produits et technologies Azure (ADLS Gen2, Azure Data Factory, Azure Function, Azure Logicapp, Azure batch, ...).\nComp\u00e9tences en programmation Javascript appr\u00e9ci\u00e9es mais non obligatoires.\nAnglais courant indispensable pour collaboration avec des \u00e9quipes internationales.\nConnaissance des m\u00e9thodologies Agile et outils tels que JIRA.\nQualit\u00e9s attendues :\nAutonomie et confort dans le soutien aux besoins en donn\u00e9es de plusieurs \u00e9quipes.\nCapacit\u00e9 \u00e0 op\u00e9rer techniquement d\u00e8s le premier jour et \u00e0 soutenir le d\u00e9veloppement de profils juniors.\nExcellentes comp\u00e9tences en communication et en formalisation.\nBienvenue chez NODYA Group\nChez NODYA Group, votre parcours vers l'excellence et l'innovation commence d\u00e8s le premier jour. Fond\u00e9 sur la conviction que la Data et l'IA sont les catalyseurs de la transformation num\u00e9rique, NODYA Group s'est positionn\u00e9 comme un pionnier, anticipant l'essor de l'IA d\u00e8s 2016 et int\u00e9grant cette vision \u00e0 l'ensemble de nos strat\u00e9gies. En tant que membre de notre \u00e9quipe, vous contribuerez \u00e0 guider nos clients-partenaires \u00e0 chaque \u00e9tape de leur \u00e9volution dans l'univers de la Data et de l'IA pour cr\u00e9er un impact business positif et durable.\nVotre avenir chez nous est non seulement une promesse de croissance mais aussi une opportunit\u00e9 de faire partie d'une vision qui valorise la cr\u00e9ativit\u00e9, le professionnalisme, l'\u00e9quilibre et l'encouragement, des valeurs qui fa\u00e7onnent l'exp\u00e9rience que nous offrons \u00e0 nos clients et collaborateurs.\nChez NODYA Group, vous serez au centre d'une culture d'entreprise dynamique et visionnaire, o\u00f9 chaque projet est une aventure, chaque d\u00e9fi une chance d'innover. Vous serez entour\u00e9 par une \u00e9quipe dirigeante qui valorise l'excellence, la proximit\u00e9 et le d\u00e9veloppement durable des comp\u00e9tences, dans un environnement o\u00f9 le mentoring et le d\u00e9veloppement personnel sont cl\u00e9s.\nSi vous \u00eates pr\u00eat \u00e0 exploiter le plein potentiel de la Data et de l'IA, \u00e0 transformer les entreprises et \u00e0 d\u00e9velopper une carri\u00e8re sans pr\u00e9c\u00e9dent, NODYA Group est l'endroit o\u00f9 vous devez \u00eatre. Rejoignez-nous et ensemble, fa\u00e7onnons l'avenir de la technologie et du business. Parlons de votre projet, parlons de votre carri\u00e8re \u2013 votre aventure commence maintenant chez NODYA Group.\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Java",
                "R",
                "JavaScript"
            ],
            "DataBase": [
                "SQL"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [
                "Azure"
            ],
            "DevTools": [],
            "Os": [],
            "DBMS": [
                "Snowflake",
                "Snowflake"
            ],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [
                "JIRA"
            ],
            "Other": [
                "DevOps",
                "CI/CD"
            ],
            "FrSoftSkills": [
                "Communication",
                "Cr\u00e9ativit\u00e9",
                "Collaboration"
            ],
            "EnSoftSkils": [
                "Communication",
                "Collaboration"
            ]
        },
        "details": {
            "JobDetail": [
                "Junior",
                "Senior"
            ],
            "TypeContract": [],
            "Salary": [],
            "Level": [
                "Bac+5"
            ],
            "Experience": [
                "a",
                "n",
                "s",
                "5",
                "5",
                "5"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "Data Analyst (H/F)",
        "company": "Technology & Strategy",
        "location": "Lyon, Auvergne-Rh\u00f4ne-Alpes, France",
        "link": "https://fr.linkedin.com/jobs/view/data-analyst-h-f-at-technology-strategy-3909691608?position=10&pageNum=27&refId=Uq1oQzOiE7s5uwPCeaspnQ%3D%3D&trackingId=fGc7VNvq1a5kgMCd9yukZQ%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "D\u00e9couvrez Novencia\n:\nExpert en Data et Intelligence Artificielle, nous aidons nos clients \u00e0 exploiter et \u00e0 valoriser leurs donn\u00e9es sous toutes ses formes en les accompagnant sur des projets de Data Analyse, Data Gourvernance, Data Architecture, Data Science, et Data Engineering\u2026\nVous avez une solide exp\u00e9rience de minimum 3 ans dans l'analyse des donn\u00e9es et vous \u00eates \u00e0 la recherche de nouveaux d\u00e9fis ? N'h\u00e9sitez plus, la suite est pour vous !\nType de contrat : CDI\nD\u00e9marrage : D\u00e8s que possible\nLieu : Lyon\nDescription du poste\n:\nNous recherchons un Data Analyst exp\u00e9riment\u00e9 pour rejoindre notre \u00e9quipe dynamique en r\u00e9gion lyonnaise. Le candidat id\u00e9al devrait avoir une solide exp\u00e9rience dans l\u2019analyse de donn\u00e9es, ainsi que des comp\u00e9tences techniques en SQL, Python et Power BI (ou tout autre outil de visualisation de donn\u00e9es).\nEn qualit\u00e9 de Data Anlayst (H/F)*, vous serez en charge de :\nCollecter, nettoyer et analyser des donn\u00e9es commerciales provenant de diff\u00e9rentes sources.\nCr\u00e9er des rapports et des tableaux de bord pertinents pour les \u00e9quipes op\u00e9rationnelles et de gestion.\nIdentifier les tendances, les opportunit\u00e9s et les domaines d\u2019am\u00e9lioration \u00e0 partir des donn\u00e9es.\nCollaborer avec les \u00e9quipes m\u00e9tier pour comprendre leurs besoins et fournir des analyses approfondies.\nPr\u00e9-requis :\nExp\u00e9rience professionnelle de minimum 3 ans en tant que Data Analyst.\nMa\u00eetrise des langages SQL et Python pour l\u2019extraction, la transformation et l\u2019analyse des donn\u00e9es.\nConnaissance approfondie de Power BI ou d\u2019autres outils de visualisation de donn\u00e9es.\nCapacit\u00e9 \u00e0 travailler de mani\u00e8re autonome et \u00e0 communiquer efficacement avec les parties prenantes.\nVous disposez des savoir-\u00eatre suivants :\nAmbidextre : Agile \u00e0 droite, Data \u00e0 gauche\nCoordinateur.trice : man\u0153uvre un projet et une \u00e9quipe\nFin.e connaisseur.euse : alimente, reporte et con\u00e7oit des entrep\u00f4ts de donn\u00e9es\nDiplomate : r\u00e9sout les in\u00e9vitables complexit\u00e9s de la r\u00e9alisation d\u2019un projet d\u2019entreprise\nN\u00e9gociateur.trice : met du tact dans chaque discussion\nTenace : un seul objectif, la satisfaction client\nNotre objectif commun est de co-construire votre carri\u00e8re en fonction de vos aspirations et de vos comp\u00e9tences.\nContactez-moi en message priv\u00e9 ou par mail \u00e0 s.ziki@technologyandstrategy.com !\nLet's make it possible #together\n*Nos postes sont ouverts aux personnes b\u00e9n\u00e9ficiant d\u2019une Reconnaissance de la Qualit\u00e9 de Travailleur Handicap\u00e9 (RQTH). T&S Groupe encourage la diversit\u00e9 et l\u2019\u00e9galit\u00e9 sur le lieu de travail. Tous les candidats qualifi\u00e9s H/F/* sont pris en consid\u00e9ration pour un emploi sur un m\u00eame pied d'\u00e9galit\u00e9.\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "R",
                "Go"
            ],
            "DataBase": [
                "SQL"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [
                "Tableau",
                "Power BI"
            ],
            "Statistics": [],
            "CloudComputing": [],
            "DevTools": [],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [],
            "FrSoftSkills": [],
            "EnSoftSkils": []
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [
                "CDI"
            ],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s",
                "3",
                "3",
                "3"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "Data Engineer / Tech Lead",
        "company": "Eulidia",
        "location": "Paris, \u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/data-engineer-tech-lead-at-eulidia-3915040845?position=1&pageNum=30&refId=xJJSxqDLDzWu7D%2BmiW7m%2BA%3D%3D&trackingId=3o0LKiJc0VGmZOodpXCl0A%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "A propos d\u2019Eulidia :\nEulidia est un cabinet de conseil pure-player Data nich\u00e9 au sein du 1er arrondissement de Paris, France. Depuis 2008, nous utilisons les leviers de la Data (architecture, Data ing\u00e9ni\u00e9rie, Data management & gouvernance, Business Intelligence) et de la Data Science (GenAI & Machine learning) pour aider nos clients \u00e0 se r\u00e9inventer, innover et rendre leur business model plus performant.\nEulidia recherche un(e) Data Engineer/Tech Lead.\nSi vous \u00eates int\u00e9ress\u00e9 \u00e0 l'id\u00e9e de rejoindre une soci\u00e9t\u00e9 de sp\u00e9cialiste, partenaire des \u00e9diteurs Data & Cloud les plus innovants (Snowflake, Google, Dataiku, Azure, Talend-Qlik ...) et par le management de projets Data complexes, cette opportunit\u00e9 est tr\u00e8s probablement votre prochain challenge professionnel et l'occasion d'int\u00e9grer un ecosyst\u00e8me Data en pleine croissance.\nVos Activit\u00e9s :\nAccompagner sur le choix des technologies pour concevoir une plateforme de donn\u00e9es r\u00e9pondant aux diff\u00e9rents besoins\nConcevoir et maintenir des pipelines de donn\u00e9es r\u00e9silients et scalable (Batch et/ou streaming)\nCollecter, nettoyer et transformer la donn\u00e9e en provenance de diverses sources\nD\u00e9velopper et impl\u00e9menter des processus de data quality et gouvernance\nTravailler avec des data scientists et analysts afin d\u2019impl\u00e9menter des solutions data-driven\nCollaborer avec les ing\u00e9nieurs et autres collaborateurs pour assurer la livraison des projets\nAccompagner la mont\u00e9e en comp\u00e9tence technique de vos collaborateurs\nD\u00e9couvrez un exemple de projet auquel vous pourriez contribuer sur notre site internet :\nhttps://www.eulidia.com/data-stories-12.html\nVous correspondez \u00e0 notre poste si :\nVous maitrisez les bases de donn\u00e9es relationnelles et analytiques\nLe data warehousing et les concepts de mod\u00e9lisation n\u2019ont aucun secret pour vous\nVous \u00eates familier voire certifi\u00e9 sur des plateformes cloud telles que AWS, Azure ou GCP\nVous avez Une bonne compr\u00e9hension des besoins de s\u00e9curit\u00e9 des donn\u00e9es\nVous avez Une connaissance des technologies de big data tels que Spark et Hive.\nVos Soft skills :\nUne excellente capacit\u00e9 \u00e0 r\u00e9soudre des probl\u00e8mes\nUne bonne communication et travail d\u2019\u00e9quipe\nUne attention au d\u00e9tail particuli\u00e8re et de la rigueur\nDe la curiosit\u00e9 et du partage de connaissances\nCe que nous offrons :\nDe la formation en continue via notre organisme de formation interne (certifications, 5 \u00e0 7, conf\u00e9rence avec les \u00e9diteurs partenaires, squads interne)\nUn accompagnement en mission et un suivi manag\u00e9rial de proximit\u00e9 bas\u00e9 sur la performance\nLes avantages de nos partenariats avec Google Cloud et Snowflake\nUn espace de travail hybride, convivial et confortable au c\u0153ur de Paris (baby foot, ping pong, caf\u00e9, fruits, jeux de soci\u00e9t\u00e9 \u2026)\nUn package comp\u00e9titif et une prime annuelle qui r\u00e9compense la performance globale de l\u2019entreprise\nUne excellente assurance et couverture sant\u00e9 pour prendre soin de nos employ\u00e9s\nUn s\u00e9minaire d\u2019entreprise annuel et de nombreux \u00e9venements afterworks\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Scala",
                "R",
                "Go",
                "HTML"
            ],
            "DataBase": [],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [
                "Spark"
            ],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [
                "AWS",
                "Azure"
            ],
            "DevTools": [],
            "Os": [],
            "DBMS": [
                "Snowflake",
                "Snowflake"
            ],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [
                "Big Data",
                "ML",
                "Machine Learning",
                "Cloud"
            ],
            "FrSoftSkills": [
                "Communication"
            ],
            "EnSoftSkils": [
                "Communication"
            ]
        },
        "details": {
            "JobDetail": [
                "Hybride"
            ],
            "TypeContract": [],
            "Salary": [
                "Package"
            ],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "Data Engineer - F/H",
        "company": "Niji",
        "location": "Lyon, Auvergne-Rh\u00f4ne-Alpes, France",
        "link": "https://fr.linkedin.com/jobs/view/data-engineer-f-h-at-niji-3848294394?position=2&pageNum=30&refId=xJJSxqDLDzWu7D%2BmiW7m%2BA%3D%3D&trackingId=kQVKXOCWIKbTTV931R6N9g%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Nous sommes plus qu\u2019un simple cabinet de conseil, qu'une agence de design et qu'une soci\u00e9t\u00e9 de mise en \u0153uvre technologique. Nous sommes le partenaire de la transformation digitale de nos clients grands-comptes et ETI, que nous accompagnons de l\u2019id\u00e9e \u00e0 la r\u00e9alit\u00e9.\nNous associons, dans une m\u00eame cha\u00eene de valeur, conseil en strat\u00e9gie, design de service et design \u00e9motionnel, management et valorisation de la donn\u00e9e, ing\u00e9nierie et conseil technologique, r\u00e9alisation logicielle et expertise en cybers\u00e9curit\u00e9.\nNotre singularit\u00e9 repose sur les talents pluriels de nos \u00e9quipes, au service de la satisfaction et de la performance de nos clients.\nLe P\u00f4le Data De Niji C'est Avant Tout Une \u00c9quipe \u00e0 Taille Humaine Et Pluridisciplinaire, Compos\u00e9e De Consultants Et Experts Qui Conseillent Et Appuient Nos Clients Sur Toutes Les \u00c9tapes Du Cycle Des Donn\u00e9es\nde la collecte \u00e0 la valorisation dans des services innovants,\nen passant par les architectures de stockage et de services.\nNos consultants sont bas\u00e9s en Ile-de-France et en r\u00e9gions (Nantes, Rennes, Lille, Lyon et Bordeaux).\nNos 3 directeurs : experts confirm\u00e9s de la gouvernance des donn\u00e9es, de la data science de l'IA et des m\u00e9thodologies d'industrialisation de l'IA (MLOps, DataOps), recherchent de nouveaux talents tous compl\u00e9mentaires avec plusieurs niveaux de qualification et s\u00e9niorit\u00e9, qui travailleront en synergie avec la large palette de comp\u00e9tences de Niji en d\u00e9veloppement, communication, cybers\u00e9curit\u00e9 et en conseil.\nInt\u00e9grer le P\u00f4le Data de Niji c'est avoir l'assurance d'\u00eatre accompagn\u00e9 dans sa progression et le d\u00e9veloppement rapide de ses comp\u00e9tences ,vous suivez un\nparcours de formation\nriche et diversifi\u00e9, visant \u00e0 vous faire rapidement monter en expertise et \u00e0 vous certifier.\nEn tant que\nData Engineer\n, vos principales missions seront les suivantes :\nConcevoir, d\u00e9velopper et maintenir une architecture de donn\u00e9es robuste, \u00e9volutive et s\u00e9curis\u00e9e, en tenant compte des besoins sp\u00e9cifiques des clients.\nParticiper activement \u00e0 la r\u00e9daction de propositions commerciales, en contribuant aux aspects techniques (outils, make or buy \u2026) et en fournissant des estimations de projet.\nG\u00e9rer et optimiser les pipelines de donn\u00e9es, en assurant la collecte, le stockage, le traitement et la mise \u00e0 disposition des donn\u00e9es de mani\u00e8re fiable et performante.\nAssurer la qualit\u00e9 des donn\u00e9es en mettant en place des contr\u00f4les de qualit\u00e9, des tests et des processus de validation, conform\u00e9ment aux exigences des clients.\nEncadrer les projets de bout en bout, en veillant \u00e0 ce qu'ils soient livr\u00e9s \u00e0 temps, dans les limites du budget afin d\u2019assurer la satisfaction des clients.\nAssurer la documentation technique, les bonnes pratiques et les standards de d\u00e9veloppement au sein de l'\u00e9quipe.\nProfil recherch\u00e9\nSi Vous\nAvez obtenu un dipl\u00f4me en universit\u00e9, \u00e9cole de commerce ou \u00e9quivalent type bac +5\nMa\u00eetrisez l'anglais \u00e0 l'\u00e9crit comme \u00e0 l'oral\nAvez de solides connaissances en architecture et en mod\u00e9lisation des donn\u00e9es\nMa\u00eetrisez des technologies et des outils li\u00e9s au Big Data (Hadoop, Spark, Hive, etc.)\nMa\u00eetrisez les outils d\u2019industrialisation des pipelines data tel que docker, kubernetes, Dataiku, Jenkins\u2026\nAvez une exp\u00e9rience avec les langages de programmation utilis\u00e9s dans le domaine des donn\u00e9es, tels que : Python,R, Scala, SQL, etc.\nAvez une exp\u00e9rience dans la conception et la mise en \u0153uvre de pipelines de donn\u00e9es\nAvez des comp\u00e9tences en gestion d'\u00e9quipe et en leadership technique\nAvez des capacit\u00e9s \u00e0 r\u00e9diger des propositions commerciales convaincantes\nAlors\u2026 Venez participer au dynamisme de notre site en rejoignant notre Team Data Lyonnaise !\nL'aventure Niji\nProcess de recrutement : premier contact RH puis rencontre avec nos op\u00e9rationnels.\nRejoindre l'exp\u00e9rience Niji c'est avoir l'assurance de participer \u00e0 une aventure humaine dans un environnement de travail motivant, challengeant et innovant.\nNijiU: notre plateforme de formation digital learning contenant pr\u00e8s de 3 000 modules en acc\u00e8s libre.\nNos valeurs : Audace - Bienveillance - Performance \u2013 Talent.\nSi ces mots vous parlent, venez faire la diff\u00e9rence chez Niji !\nEn rejoignant Niji, vous int\u00e9grez une entreprise dont la politique RSE contribue \u00e0 la promotion de la diversit\u00e9 et de l\u2019\u00e9galit\u00e9 des chances, notamment pour les personnes en situation de handicap.\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "Scala",
                "R",
                "Go"
            ],
            "DataBase": [
                "SQL"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [
                "Hadoop",
                "Spark"
            ],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [],
            "DevTools": [
                "Git",
                "Docker",
                "Jenkins"
            ],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [
                "Kubernetes"
            ],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [
                "Docker",
                "Kubernetes"
            ],
            "Collaboration": [],
            "Other": [
                "Big Data",
                "ML"
            ],
            "FrSoftSkills": [
                "Communication",
                "Leadership"
            ],
            "EnSoftSkils": [
                "Communication",
                "Leadership"
            ]
        },
        "details": {
            "JobDetail": [
                "Confirm\u00e9"
            ],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "Python Software Engineer",
        "company": "Redslim",
        "location": "\u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/python-software-engineer-at-redslim-3749529490?position=3&pageNum=30&refId=xJJSxqDLDzWu7D%2BmiW7m%2BA%3D%3D&trackingId=zZI5Gfd%2BYp%2B0ns3BE0%2Fkxw%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Salary Range:\nEUR 50k-80k\nAbout Role:\nThe engineer we are looking for will work in the platform developer team on all aspects of the software development cycle; design, develop, test and deploy. The work will be composed of developing a low & no-code solution that enables users to configure and run batch data operations for the purpose of data reporting & visualisation. The solution is deployed and hosted in Azure and services used include Azure Web App, Storage Accounts, Azure Data Factory and Databricks. The main programming languages used by the team are either Python or C#.\nAbout Team:\nThe central mission of the Redslim Product Team revolves around developing tools and services that support Redslim's data management services. The team's collaboration extends to various business domains, both internally and externally, helping develop products that support operational activities, activation, and client reporting solutions.\nKey Responsibilities:\nCollaborate with cross-functional teams to understand and define data harmonisation & transformation requirements.\nDesign, develop, and maintain data processing libraries, pipelines using Databricks and Python.\nOptimize data processes for performance and scalability.\nEnsure data quality and reliability by implementing data validation and testing procedures.\nRequirements:\n4+ years of software development experience.\nFluent English as a working language.\nExtensible experience with Databricks and Python for data engineering.\nProfessional experience of deploying and testing software solutions in a cloud environment (ideally Azure).\nProfessional experience containerising software solutions to work at scale in the cloud.\nDatabase experience including analytical SQL queries and OLAP databases.\nNice to Have:\nDomain experience involving market research and/or retail data management.\nExperience with modern software development methodologies, for example Test Driven Development, Agile Scrum and Lean Software Development.\nExperience using Large Language Models to enhance user experience.\nFront end development experience, preferably using React.\nWhat We Offer:\nCompetitive salary and benefits package.\nOpportunities for professional development and growth.\nA supportive and collaborative work environment.\nThe chance to work on meaningful projects with real-world impact.\nA remote or office based working environment with irregular face to face team meetings throughout the year.\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "C#",
                "Scala",
                "R"
            ],
            "DataBase": [
                "SQL"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [
                "Databricks"
            ],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [
                "Azure"
            ],
            "DevTools": [],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [
                "Teams"
            ],
            "Other": [
                "Cloud"
            ],
            "FrSoftSkills": [
                "Collaboration"
            ],
            "EnSoftSkils": [
                "Collaboration"
            ]
        },
        "details": {
            "JobDetail": [
                "Remote"
            ],
            "TypeContract": [],
            "Salary": [
                "50k"
            ],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "Senior Data Engineer - Snowflake",
        "company": "FRG Technology Consulting",
        "location": "Paris, \u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/senior-data-engineer-snowflake-at-frg-technology-consulting-3904054143?position=4&pageNum=30&refId=xJJSxqDLDzWu7D%2BmiW7m%2BA%3D%3D&trackingId=kkgSmI6CEzxxiNjUPdZBcA%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Mon client, un End User sur Paris, est \u00e0 la recherche d'un(e) Data Ops, pour intervenir sur l'ensemble de la cha\u00eene d\u00e9cisionnelle au sein du p\u00f4le data.\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "R"
            ],
            "DataBase": [],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [],
            "DevTools": [],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [],
            "FrSoftSkills": [],
            "EnSoftSkils": []
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "Data Engineer H/F",
        "company": "Groupe Havana",
        "location": "Paris, \u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/data-engineer-h-f-at-groupe-havana-3913990947?position=5&pageNum=30&refId=xJJSxqDLDzWu7D%2BmiW7m%2BA%3D%3D&trackingId=4NVBmhdECDN4o9JVXvp%2F7A%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Groupe Havana : Cr\u00e9\u00e9 en 2011, nous incarnons la transformation digitale en misant sur l'innovation, la performance et le bien-\u00eatre au travail.\nNotre Identit\u00e9\n200 experts d\u00e9ploy\u00e9s \u00e0 travers la France.\nActeurs cl\u00e9s dans les domaines de la DATA, du Cloud et de l'intelligence artificielle.\nNous accompagnons nos clients dans la transformation digitale de leur SI\nNous recherchons un(e) data ing\u00e9nieur(e) qualifi\u00e9(e) pour nous aider \u00e0 concevoir, construire et g\u00e9rer nos syst\u00e8mes de donn\u00e9es.\nMissions\nMigration des donn\u00e9es du SI entreprise vers la plateforme de donn\u00e9es GCP\nParticiper \u00e0 l'industrialisation des cas d'usage m\u00e9tiers du groupe\nAssurer la qualit\u00e9, la fiabilit\u00e9 et l'accessibilit\u00e9 des donn\u00e9es.\nCollaborer avec les \u00e9quipes de data science pour comprendre les besoins en donn\u00e9es et mettre en place les solutions appropri\u00e9es.\nAssurer la maintenance et l'optimisation des syst\u00e8mes de donn\u00e9es existants.\nComp\u00e9tences Attendues\nExp\u00e9rience en ing\u00e9nierie de donn\u00e9es, en particulier avec les technologies de big data\nConnaissances GCP Big Query\nConnaissances des langages de programmation tels que Python\nExp\u00e9rience avec les bases de donn\u00e9es SQL et NoSQL\nConnaissances des technologies de conteneurisation (Docker, Kube)\nComp\u00e9tences des technologies de CI/CD et IaC (Gitlab, Terraform)\nCapacit\u00e9 \u00e0 travailler en \u00e9quipe et \u00e0 communiquer efficacement\nComp\u00e9tences interpersonnelles\nAvoir une capacit\u00e9 \u00e0 travailler de mani\u00e8re autonome et \u00e0 g\u00e9rer efficacement plusieurs t\u00e2ches simultan\u00e9ment\nInt\u00e9ress\u00e9(e) ?\nVoici notre processus de recrutement apr\u00e8s envoi de votre CV :\nUn 1er \u00e9change t\u00e9l\u00e9phonique avec notre responsable recrutement Vincent, d'environ 10 minutes\nUn 2\u00e8me \u00e9change t\u00e9l\u00e9phonique avec l'\u00e9quipe commerciale, Christelle, Yves ou Lucas\nUn entretien physique ou en visio avec le client final et le business manager en charge de vous accompagner\nCe poste n'est pas ouvert \u00e0 l'alternance ou aux stages !\nPoste ouvert aux personnes en situation d'handicap !\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "R"
            ],
            "DataBase": [
                "SQL",
                "NoSQL"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [],
            "DevTools": [
                "Git",
                "Docker"
            ],
            "Os": [],
            "DBMS": [
                "Big Query"
            ],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [
                "Terraform"
            ],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [
                "Docker"
            ],
            "Collaboration": [],
            "Other": [
                "Big Data",
                "Cloud",
                "CI/CD"
            ],
            "FrSoftSkills": [],
            "EnSoftSkils": []
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "Data Engineer senior Spark / Scala",
        "company": "Sibylone",
        "location": "Paris, \u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/data-engineer-senior-spark-scala-at-sibylone-3909127442?position=6&pageNum=30&refId=xJJSxqDLDzWu7D%2BmiW7m%2BA%3D%3D&trackingId=zWRvA8cUYHO5VrPJ4rS%2BAA%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "SIBYLONE\n, soci\u00e9t\u00e9 de conseil sp\u00e9cialis\u00e9e dans les syst\u00e8mes d\u2019information de synth\u00e8se et de pilotage, aide ses clients \u00e0 tirer toute la valeur de leur patrimoine de donn\u00e9es, levier strat\u00e9gique majeur de d\u00e9veloppement et de rentabilit\u00e9.\nNotre ambition\n: rendre les diff\u00e9rents acteurs de l\u2019entreprise autonomes dans l\u2019exploitation des donn\u00e9es, lib\u00e9rer les usages M\u00e9tier, pour qu\u2019ils soient en mesure de relever les d\u00e9fis de performance, de couverture de risque, de financement, de conqu\u00eate client, de RSE\u2026 qui s\u2019imposent \u00e0 eux.\nSp\u00e9cialistes reconnus,\nnos consultants s\u2019appuient pour cela sur une connaissance approfondie de l\u2019activit\u00e9 business de nos clients, en lien avec nos trois piliers que sont le M\u00e9tier, la Data et le Projet.\nSIBYLONE\nemploie environ 250 salari\u00e9s et r\u00e9alise un CA de 30m\u20ac dans la prestation de services aupr\u00e8s de grandes entreprises (8 grands comptes repr\u00e9sentant 80% du CA). SIBYLONE est une filiale du Groupe Smart 4 Engineering cr\u00e9\u00e9 en 2020. Le groupe s\u2019est constitu\u00e9 en proc\u00e9dant \u00e0 l\u2019acquisition de 12 soci\u00e9t\u00e9s en France (dont SIBYLONE), Italie, et en Espagne dans le domaine de l\u2019ing\u00e9nierie. Le groupe est d\u00e9tenu par Dzeta Conseil, acteur familial de l\u2019investissement. Avec nos 3,000 ing\u00e9nieurs / consultants hautement qualifi\u00e9s, le Groupe offre ses services dans les domaines tr\u00e8s porteurs du Digital, de la Data, de l\u2019Intelligence Artificielle, de la Cybers\u00e9curit\u00e9, du Cloud et des Logiciels.\nDans le cadre du d\u00e9veloppement de notre activit\u00e9 Data, nous recherchons\nplusieurs Data Engineer\n\u00e0 l'aise avec spark et scala!\nLe Data Engineer participe \u00e0 la conception, la construction, le d\u00e9ploiement et le maintien en production d\u2019architectures Big Data, ces derni\u00e8res ayant pour objectif de permettre tant l\u2019\u00e9volution que l\u2019optimisation du syst\u00e8me d\u2019information d\u00e9cisionnel existant en permettant de nouveaux usages Analytics et IA.\nVous int\u00e9grerez une \u00e9quipe projet Big Data dont l\u2019objectif premier est de conduire des projets ayant traits \u00e0 des probl\u00e9matiques d\u2019architecture et de conception dans un contexte Big Data & Cloud.\nVos missions\nAnalyser, comprendre et cadrer une architecture permettant de r\u00e9pondre aux besoins m\u00e9tiers des clients\nConcevoir et mettre en place des plateformes Data en tenant compte des contraintes tant techniques que fonctionnelles\nIntervenir sur la conception et le d\u00e9ploiement d\u2019environnements \u00ab clusteris\u00e9s \u00bb (Hadoop sur des distributions telles que Cloudera ou Hortonworks) ou Cloud public\nD\u00e9veloppement de pipelines d\u2019ingestion et de pr\u00e9paration\nGestion du stockage de donn\u00e9es (syst\u00e8mes de fichiers comme HDFS, bases SQL ou NoSQL)\nAlimentation d\u2019entrep\u00f4ts de donn\u00e9es (Hive, Impala, \u2026)\nD\u00e9velopper des applications d\u2019exploration et de manipulation de donn\u00e9es (SPARK / pySpark, Scala) afin d\u2019alimenter les flux sortants, les reporting et d\u2019exposer les donn\u00e9es\nEvoluer sur l\u2019ordonnancement des traitements de donn\u00e9es (Oozie, Bash / Shell)\nAssurer le maintien en conditions op\u00e9rationnelles des plateformes produites\nEtablir, formaliser, et promouvoir les best practices\nPourquoi pas vous ?\nProfil recherch\u00e9 :\nDe formation sup\u00e9rieure ing\u00e9nieur en Informatique, vous justifiez d\u2019une premi\u00e8re exp\u00e9rience r\u00e9ussie en data engineering acquise dans un contexte projet au sein d\u2019une start-up, d\u2019un pure player, ou d\u2019une ESN.\nVous disposez d\u2019une bonne maitrise des langages propres aux environnements Big Data tels que :\nHadoop et ses distributions\nLes solutions Cloud (Azure, AWS, GPC)\nSpark, Scala, Python, Unix, SQL.\nUne connaissance de : Docker, ELK, Kubernetes, Cassandra, Kafka, \u2026 serait un plus, de m\u00eame que des fondamentaux DevOps (CI / CD).\nVous avez d\u00e9j\u00e0 \u00e9volu\u00e9 dans un contexte projet agile ou scrum et faites preuve de flexibilit\u00e9, d\u2019adaptabilit\u00e9 et savez \u00eatre force de proposition.\nAu-del\u00e0 de vos comp\u00e9tences techniques, vous \u00eates curieux, autonome, organis\u00e9, dot\u00e9 d\u2019un bon sens relationnel et d\u2019un esprit de synth\u00e8se.\nLes PLUS Sibylone !\nEvoluer au sein d\u2019une soci\u00e9t\u00e9 qui exige le meilleur de ses collaborateurs tout en cultivant la coh\u00e9sion et l\u2019esprit d\u2019\u00e9quipe !\nS\u2019engager dans une politique RSE exigeante : labellisation Ecovadis\nAvoir un Partenariat EcoTree France : 1 recrutement = 1 arbre plant\u00e9 !\nContribuer activement au bien-\u00eatre de ses collaborateurs : participation aux frais d\u2019abonnements activit\u00e9s ou achat 2 roues\nAvoir de nombreux moments de convivialit\u00e9s : s\u00e9minaires, afterworks, conf\u00e9rences et petits d\u00e9jeuners, sports en groupe via l\u2019application United Heroes\nDonner une offre de formation innovante et \u00e0 la pointe des nouvelles technologies\nAccord de t\u00e9l\u00e9travail en vigueur\nVous vous reconnaissez dans la description du poste ?\nVous souhaitez travailler dans un environnement stimulant et dynamique ?\nVous souhaitez rejoindre une soci\u00e9t\u00e9 ambitieuse ?\nVous souhaitez comprendre l\u2019origine de Sibylone ?\nVenez-nous rencontrer : L'\u00e9quipe TA sera ravie d\u2019\u00e9changer avec vous !\nCe poste est ouvert aux personnes en situation de handicap.\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "Scala",
                "R",
                "Bash"
            ],
            "DataBase": [
                "SQL",
                "NoSQL",
                "Cassandra"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [
                "Hadoop",
                "Spark"
            ],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [
                "AWS",
                "Azure"
            ],
            "DevTools": [
                "Git",
                "Docker"
            ],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [
                "Kubernetes"
            ],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [
                "Docker",
                "Kubernetes"
            ],
            "Collaboration": [],
            "Other": [
                "DevOps",
                "Big Data",
                "Cloud",
                "CI / CD"
            ],
            "FrSoftSkills": [
                "Adaptabilit\u00e9",
                "Flexibilit\u00e9"
            ],
            "EnSoftSkils": []
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "Ing\u00e9nieur Data confirm\u00e9 F/H",
        "company": "Mobile Tech People",
        "location": "Lille, Hauts-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/ing%C3%A9nieur-data-confirm%C3%A9-f-h-at-mobile-tech-people-3887689223?position=7&pageNum=30&refId=xJJSxqDLDzWu7D%2BmiW7m%2BA%3D%3D&trackingId=hPIySwJlTshaog2MYOJd3Q%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Missions :\nParticiper \u00e0 la prise en charge du d\u00e9veloppement et de la maintenance de l infrastructure adapt\u00e9e \u00e0 l analyse de donn\u00e9es (D\u00e9veloppement de nouvelles fonctionnalit\u00e9s via des d\u00e9veloppements sp\u00e9cifiques ou ETL),\nIntervenir en mode support (Suivre le d\u00e9veloppement et apporter du support aux autres d\u00e9veloppeurs sur les solutions logicielles),\nGestion de base de donn\u00e9es SQL sur Azure\nDocumenter les r\u00e9alisations effectu\u00e9es via des manuels d exploitation,\nCr\u00e9ations de script python pour r\u00e9cup\u00e9rer les donn\u00e9es depuis le Web Scraping\nFaire les revus de codes,\nIntervenir sur la mise \u00e0 jour des langages et technologie,\nCultiver des relations op\u00e9rationnelles avec les \u00e9quipes m\u00e9tiers.\nFormation d'ing\u00e9nieur data juniors.\nEnvironnement technique :\nJava SE, Python, Spark, Hadoop, Hive, Scala, NoSQL, SQL, PSQL, Oracle Database, Dataiku, Informatica, Teradata, Azure, Datbricks, Git\nRequirements\nDescription du profil\nNous cherchons une personne :\nQui a id\u00e9alement 4 ans min d exp\u00e9riences en tant que Data Engineer,\nAyant de solides comp\u00e9tences en programmation et bases de donn\u00e9es sur les technologies ci dessus ainsi qu en Math\u00e9matiques appliqu\u00e9es pour la construction des algorithmes,\nAimant le travail d \u00e9quipe,\nQui cultive sa curiosit\u00e9 et se tient inform\u00e9 des \u00e9volutions technologiques,\nAutonome, autodidacte, proactive.\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "Java",
                "Scala",
                "R",
                "Go"
            ],
            "DataBase": [
                "SQL",
                "NoSQL"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [
                "Hadoop",
                "Spark"
            ],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [
                "Azure"
            ],
            "DevTools": [
                "Git"
            ],
            "Os": [],
            "DBMS": [
                "Oracle"
            ],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [],
            "FrSoftSkills": [],
            "EnSoftSkils": []
        },
        "details": {
            "JobDetail": [
                "Junior"
            ],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s",
                "4",
                "4",
                "4"
            ]
        }
    },
    {
		"source": "LinkedIn",
		"source": "LinkedIn",
        "title": "DATA ENGINEER - Azure H/F",
        "company": "Squaar",
        "location": "\u00c9couflant, Pays de la Loire, France",
        "link": "https://fr.linkedin.com/jobs/view/data-engineer-azure-h-f-at-squaar-3896400467?position=8&pageNum=30&refId=xJJSxqDLDzWu7D%2BmiW7m%2BA%3D%3D&trackingId=XwQWwVcKXaNeQhtCZ50OMg%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Nous recherchons pour notre client, \u00e9diteur de logiciels sp\u00e9cialis\u00e9s, un DATA ENGINEER - Azure H/F dans le cadre d'une mission Freelance de 6 mois renouvelable plusieurs fois.\nLe Poste\nLieu : ANGERS (49) ,\nTJM : 500-550\u20ac (frais inclus) / Jour,\nRythme : 2j sur site / semaine pendant le 1er mois?\nNous recherchons pour notre client, \u00e9diteur de logiciels sp\u00e9cialis\u00e9s, un DATA ENGINEER - Azure H/F dans le cadre d'une mission Freelance de 6 mois renouvelable plusieurs fois.\nVos Missions\nAu sein d'une \u00e9quipe informatique d'une dizaine de personnes et rattach\u00e9 au CTO, vous intervenez dans une cadre d'un projet de refonte compl\u00e8te de la plateforme du client.\nVos Missions Sont Les Suivantes\nD\u00e9veloppement et maintenance de pipelines de donn\u00e9es sur Azure.\nMise en place d'architectures de donn\u00e9es efficaces.\nTransformation de donn\u00e9es en temps r\u00e9el\nValidation des donn\u00e9es selon les r\u00e8gles m\u00e9tier et mod\u00e9lisation des structures.\nGestion de gros volumes de donn\u00e9es clients.\nEnvironnement technique : \u00c9cosyst\u00e8me Azure (Azure Data Factory, SQL, Azure Data Lake Store, Spark, Hive, Airflow, Python, Scala)\nVous\nDe formation au minimum Bac+4/5 en Informatique, vous justifiez d'au moins 3 ann\u00e9es d'exp\u00e9rience en Data Engineering autour de l'\u00e9cosyst\u00e8me Azure. (imp\u00e9ratif).\nAttention, vous serez LE r\u00e9f\u00e9rent sur ces sujets, votre capacit\u00e9 \u00e0 travailler de fa\u00e7on autonome et \u00e0 trouver l'\u00e9quilibre entre qualit\u00e9 et efficacit\u00e9 tout en proposant des solutions fiables et durables est donc \u00e9galement imp\u00e9rative.\nVous \u00eates int\u00e9ress\u00e9 par le fait de r\u00e9pondre \u00e0 des probl\u00e9matiques techniques notamment, de qualit\u00e9, de performance et de s\u00e9curit\u00e9.\nProcess\nApr\u00e8s une visio avec un membre de notre \u00e9quipe, vous rencontrez :\nLe CTO et le Responsable Infrastructure en visio\nD\u00e9cision sous quelques jours\nEnvoyez-nous votre CV et si votre profil correspond vous serez contact\u00e9 par un membre de l'\u00e9quipe dans les 24h.\nAu plaisir d'\u00e9voquer votre projet,\nSquaar\nProfil\nDe formation au minimum Bac+4/5 en Informatique, vous justifiez d'au moins 3 ann\u00e9es d'exp\u00e9rience en Data Engineering autour de l'\u00e9cosyst\u00e8me Azure. (imp\u00e9ratif).\nAttention, vous serez LE r\u00e9f\u00e9rent sur ces sujets, votre capacit\u00e9 \u00e0 travailler de fa\u00e7on autonome et \u00e0 trouver l'\u00e9quilibre entre qualit\u00e9 et efficacit\u00e9 tout en proposant des solutions fiables et durables est donc \u00e9galement imp\u00e9rative.\nVous \u00eates int\u00e9ress\u00e9 par le fait de r\u00e9pondre \u00e0 des probl\u00e9matiques techniques notamment, de qualit\u00e9, de performance et de s\u00e9curit\u00e9.\nEnvironnement technique : \u00c9cosyst\u00e8me Azure (Azure Data Factory, SQL, Azure Data Lake Store, Spark, Hive, Airflow, Python, Scala)\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "Scala",
                "R"
            ],
            "DataBase": [
                "SQL"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [
                "Spark"
            ],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [
                "Azure"
            ],
            "DevTools": [],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [
                "Airflow"
            ],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [],
            "FrSoftSkills": [],
            "EnSoftSkils": []
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "Data Engineer H/F",
        "company": "Externatic",
        "location": "Nantes, Pays de la Loire, France",
        "link": "https://fr.linkedin.com/jobs/view/data-engineer-h-f-at-externatic-3911263499?position=9&pageNum=30&refId=xJJSxqDLDzWu7D%2BmiW7m%2BA%3D%3D&trackingId=x2FW23%2F4UjVmsyr5eUj%2F3g%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Pr\u00e9sentation de la soci\u00e9t\u00e9\nCabinet de recrutement Tech, la mission d\u2019Externatic est de faciliter la rencontre entre candidats et entreprises finales (hors donc 0% d'ESN). Nous mettons \u00e0 votre disposition notre r\u00e9seau et notre connaissance du march\u00e9 de la Tech (\u00e9tude des salaires, tendances).\nNotre moteur : vous accompagner sur du long terme pour trouver l\u2019opportunit\u00e9 en CDI, qui correspond \u00e0 votre projet professionnel, et surtout vous proposer un acc\u00e8s privil\u00e9gi\u00e9 \u00e0 des opportunit\u00e9s cach\u00e9es au sein de p\u00e9pites (startup / \u00e9diteur / DSI / PME).\nExternatic en bref :\nPlus de 13 ans de professionnalisme\n+700 postes ouverts HORS ESN\n33 consultants\nPlus de 400 clients tous hors ESN : DSI, \u00e9diteurs, ETI/PME, Centre R&D, Startup/scaleup, organismes publiques et para-publiques, ...\nPlus de 370 candidats accompagn\u00e9s par an\nMission\nMoi c'est Hadrien, Consultant chez Externatic et j\u2019ai une offre tr\u00e8s sympa \u00e0 te partager, surtout si tu as envie de rejoindre une aventure ambitieuse \u00e0 ses d\u00e9buts !\nVoici quelques infos ci-dessous, et je serais ravi d\u2019\u00e9changer ensemble plus de d\u00e9tails !\nL'entreprise\nLe march\u00e9 du recrutement est au d\u00e9but d'une grande r\u00e9volution avec le d\u00e9veloppement de l'IA. Cependant, beaucoup de recruteurs sont encore mal outill\u00e9s, ou ne sont pas familiers avec ces nouvelles technologies.\nC'est dans ce contexte que cette jeune startup cr\u00e9\u00e9e il y a un an est en train de cr\u00e9er une solution SaaS int\u00e9grant de l'IA d\u00e9di\u00e9e aux acteurs du recrutement en France puis en Europe !\nEn quelques mois, ils ont d\u00e9j\u00e0 sorti un premier MVP qui est d\u00e9j\u00e0 utilis\u00e9 chez une 30aine de clients !\nLa startup r\u00e9unit une \u00e9quipe solide de 6 personnes et un investisseur de renom qui soutient le projet.\nLe poste\nTu int\u00e8gres l'\u00e9quipe Tech qui est compos\u00e9e de 3 d\u00e9veloppeurs actuellement et qui recherche son premier Data Engineer !\nC'est un r\u00f4le crucial et cl\u00e9 qui va permettre d'aller encore plus loin au niveau de la roadmap et proposer une solution r\u00e9volutionnaire sur le march\u00e9.\nTon r\u00f4le sera de mettre en place et maintenir une infrastructure Data performante et scalable, qui sera capable de g\u00e9rer une mont\u00e9e en puissance au niveau des volumes de donn\u00e9es \u00e0 capter, structurer et traiter.\nTes enjeux seront par exemple de :\nConcevoir, d\u00e9velopper et optimiser le Data Model et l'architecture Data\nMettre en place et maintenir les pipelines de donn\u00e9es\nOptimiser les performances du syst\u00e8me (vitesse de traitement des donn\u00e9es, capacit\u00e9 de stockage, scalabilit\u00e9...)\nAssurer la s\u00e9curit\u00e9 et la confidentialit\u00e9 des donn\u00e9es\nCollaborer \u00e9troitement avec les d\u00e9veloppeurs, le fondateur et le CSM pour d\u00e9velopper, tester et d\u00e9ployer de nouvelles features\nEnvironnement technique : Python, PostgreSQL, Cloud et autres technos de la stack data \u00e0 d\u00e9finir\nProfil\nTes atouts\nTu as une formation Data et une exp\u00e9rience d'au moins 3 ans autour de sujets Data Engineering, o\u00f9 tu as travaill\u00e9 sur des projets BUILD autour des infrastructures data (cloud, pipelines, data platforms, ...)\nTu as une solide expertise en Python, SQL, et une bonnes connaissances des technos que l'on retrouve sur les stacks data modernes (par exemple AWS, GCP, Snowflake, Databricks, DBT, Airflow, ...)\nEt surtout, tu as envie de rejoindre une aventure startup \u00e0 ses d\u00e9buts et t'impliquer dans un projet passionnant !\nAvantages\nConditions de travail\nLocalisation : Bureaux \u00e0 Nantes et Bordeaux ou full remote\nR\u00e9mun\u00e9ration fixe : entre 45 et 50K\nBSPCE\nRemote friendly\nLe process (rapide et efficace !)\nRDV avec Hadrien d\u2019Externatic\nEntretien avec CTO et Founder\nRencontre \u00e9quipe\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "Scala",
                "R"
            ],
            "DataBase": [
                "SQL"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [
                "Databricks"
            ],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [
                "AWS"
            ],
            "DevTools": [],
            "Os": [],
            "DBMS": [
                "PostgreSQL",
                "Snowflake",
                "Snowflake"
            ],
            "SoftBigDataProcessing": [],
            "Automation": [
                "Airflow"
            ],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [
                "Cloud"
            ],
            "FrSoftSkills": [],
            "EnSoftSkils": []
        },
        "details": {
            "JobDetail": [
                "Remote",
                "Full"
            ],
            "TypeContract": [
                "CDI"
            ],
            "Salary": [
                "13"
            ],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s",
                "13",
                "13",
                "13"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "Data Engineer | LLM/Python",
        "company": "Jus Mundi",
        "location": "Paris, \u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/data-engineer-llm-python-at-jus-mundi-3901457116?position=10&pageNum=30&refId=xJJSxqDLDzWu7D%2BmiW7m%2BA%3D%3D&trackingId=ZaL7tqq8Pl09fbrpRxRK5g%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "*Only applicants who send their CV on Welcome to the Jungle will be considered for this position.*\n\u2b50Who We are\u2b50\nContributing to building the rule of law internationally is everyone\u2019s responsibility. Jus Mundi facilitates and democratizes access to global legal information with unprecedented efficiency, thanks to a search engine that combines international legal expertise with artificial intelligence.\nBased in Paris and NYC, 90% of Jus Mundi\u2019s turnover is 40% from the US and 30% from the UK.\nClients include big law firms, such as DLA Piper, Freshfields, Dentons, and legal departments of multinationals such as governments including Japan and the UK, and universities such as the Sorbonne, and Cambridge.\nOur team: Vision is nothing without a team to carry it!\nOur team has friendly people from diverse backgrounds who are committed and strive to be the best!\n70+ Team Members, with 30+ nationalities from different backgrounds, ambitious & innovative talents in a journey to disrupt and reinvent the entire legal industry.\nBe Part of This Exciting Journey. Join Our International Team.\nYou will live your best life while working at Jus Mundi. We work hard, and we play hard! The impact of our work is meaningful. If you would like to have a career in which you are making a real impact, join us.\n\u2139\ufe0f Job Description:\nToday, we are looking for an engineer to join our new Team to work specifically around LLMs and ship more organic experiences to our users.\nWe\u2019re leveraging LLM models to revolutionize legal research and build valuable products for our users. What we\u2019re building in the short term? We\u2019re developing interactive assistants and agents that leverage our database and perform tasks for our users and partners. But we want to do much more!\nThe legal industry is being revolutionized by LLMs. Lawyers are eagerly adopting cutting-edge technologies, and we are riding this wave! The moment is now.\nWe mainly follow a Kanban/Lean paradigm cherry-picking Events or Artifacts from other methods to create our own practice, matching our own organization.\nWe have an Engineering Culture. And have some practical principles\nDo what you say, Say what you do.\nCommunication builds Trust. Trust improves Performance.\nTry, fail and, learn. Iterate until success.\nLeave your ego at the door.\nBig Ideas, Pragmatical Implementation.\nOur technical stack:\nMain: Python, Go, Nuxt.js, Vue.js, and Node.js\nDatabases: PostgreSQL, Elasticsearch, Neo4j and Redis\nLegacy (being replaced): Symfony with JQuery\nDevelopment and CI/CD: Docker, Git and Gitlab\n\u26a1 Your Missions:\nWhat you\u2019ll do:\nCreate, test, maintain, and consume internal & external APIs (mainly Python, a little bit of Go)\nWrite conception Proposals, RFC and analysis\nHelp to create Proof Of Concept, Minimum Viable Product\nImplement new features and fix bugs\nWork on LLM application (llama-3, GPT-4, Mixtral, etc\u2026)\nDo prompt engineering, few short learning and fine-tuning\n\ud83d\udcbc Preferred Experience & Skills:\nWho you are:\nYou are passionate about your craft and can communicate it\nYou are trustworthy\nYou have 3+ years in your field and have worked on part of our Tech Stack\nYou thrive in a fast-paced environment\nYou are climbing the slope of enlightenment (Dunning\u2013Kruger effect)\nHaving worked on at least one LLM project\nKnowing how to leverage LLM\n\ud83d\ude80 Company Perks and Benefits:\n\ud83d\ude0d Working for a fast-growing global legal tech offering a disruptive product that is revolutionizing the way lawyers around the world interconnect and conduct legal research,\n\ud83d\udcbb Hybrid working organization, mix between remote and on-site,\n\ud83d\udcb0Competitive salary & equity\n\ud83c\udfd6 5 weeks of vacation\n\ud83c\udf7c Paid parental leave (under specific conditions)\n\ud83e\ude7a A great complementary private health insurance (paid 100% for the employee and his children by the company)\n\ud83d\ude8a50% of public transportation reimbursed.\n\ud83c\udf74Personal credit card to buy lunches during the week (\nSwile\n)\n\ud83d\ude0d Every quarter we organize a company-wide summit to\n\ud83c\udf0d Travel (work abroad) policy: 8 weeks per year, you can live and work from where you want across the globe,\n\u2708\ufe0f Relocation Package (to France)\nWhy us, why now?\nWe are structuring our organization to scale. There is a lot to do with high levels of ownership and freedom. Building and creating the practices and processes the Engineering will follow.\nConfidence can sometimes hold us back from applying for a job. But we\u2019ll let you in on a secret: there\u2019s no such thing as a \u2018perfect\u2019 candidate. So however you identify and whatever background you bring with you, please apply if this is a role that would make you excited to come to work every day.\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "R",
                "Go"
            ],
            "DataBase": [
                "SQL",
                "Neo4j",
                "Elasticsearch"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [],
            "DevTools": [
                "Git",
                "Docker"
            ],
            "Os": [],
            "DBMS": [
                "PostgreSQL"
            ],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [
                "Docker"
            ],
            "Collaboration": [],
            "Other": [
                "CI/CD"
            ],
            "FrSoftSkills": [
                "Communication"
            ],
            "EnSoftSkils": [
                "Communication",
                "Organization"
            ]
        },
        "details": {
            "JobDetail": [
                "Remote"
            ],
            "TypeContract": [],
            "Salary": [
                "5"
            ],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "Data Ing\u00e9nieur/e",
        "company": "AXA en France",
        "location": "Nanterre, \u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/data-ing%C3%A9nieur-e-at-axa-en-france-3919473325?position=1&pageNum=32&refId=FUgWcwWTfkSy1LADz3eV7w%3D%3D&trackingId=9eIjBWMHrblYtuA%2Fvy7XHQ%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Votre r\u00f4le et vos missions\nCr\u00e9er des outils\nEtablir des cahiers des charges avec les utilisateurs, en comprenant leurs besoins pour d\u00e9finir les solutions les plus adapt\u00e9es\nLotir les d\u00e9veloppements en ayant le souci de la valeur ajout\u00e9e du 1er lot et de la coh\u00e9rence des livraisons\nD\u00e9velopper les interfaces des applications\nMettre en place des pipelines de traitement de donn\u00e9es (nettoyage, transformation) et des pipelines de d\u00e9ploiement des applications sur le cloud\nAssurer et garantir la production d'un code de qualit\u00e9 et de sa documentation technique\nEtablir des plans de tests\nFaire la maintenance des outils\nAssurer la mise \u00e0 jour r\u00e9guli\u00e8re des outils et documents techniques\nD\u00e9velopper les usages des mod\u00e8les de donn\u00e9es\n\u00catre r\u00e9f\u00e9rent pour les actuaires produits vis-\u00e0-vis de la DSI\nPorter et suivre techniquement les demandes de d\u00e9veloppements de l\u2019Actuariat IARD Entreprises aupr\u00e8s de la DSI\nPrendre de la hauteur sur les probl\u00e9matiques techniques afin d'orienter l'\u00e9quipe et anticiper les blocages et risques dans les phases de d\u00e9veloppement\nG\u00e9n\u00e9raliser les bonnes pratiques d'industrialisation sur les diff\u00e9rents traitements, en \u00e9tant support p\u00e9dagogue aupr\u00e8s des actuaires\nVotre profil\nTechniques\nSavoir coder en Python, R, SAS\nSavoir planifier un projet informatique\nConna\u00eetre Git\nComprendre le fonctionnement de l\u2019architecture d\u2019un cloud\nConna\u00eetre le domaine de l\u2019Actuariat IARD, serait un +\nRelationnelles\nSavoir \u00eatre \u00e0 l\u2019\u00e9coute des interlocuteurs nombreux et pluridisciplinaires (Actuariat, Directions Techniques, Informatique, Souscriptions, \u2026)\nFaire preuve de pragmatisme et de souplesse d\u2019esprit pour imaginer des solutions permettant de concilier contraintes techniques et commerciales\nEsprit de rigueur et de synth\u00e8se, sachant d\u00e9montrer son assertivit\u00e9 et sa curiosit\u00e9\nPourquoi nous rejoindre ?\nNous sommes persuad\u00e9s que pour bien prendre soin de nos clients, nous devons commencer par bien prendre soin de nos collaborateurs ! Les avantages que nous proposons \u00e0 nos salari\u00e9s sont nombreux.\nNous choisir, c\u2019est b\u00e9n\u00e9ficier par exemple\nD\u2019un package de r\u00e9mun\u00e9ration complet comprenant un salaire fixe, un compl\u00e9ment de r\u00e9mun\u00e9ration variable, des primes, de la participation et de l\u2019int\u00e9ressement, la possibilit\u00e9 d\u2019acqu\u00e9rir des actions AXA, ou encore des solutions d\u2019\u00e9pargne avantageuses ;\nD\u2019un cadre de travail flexible jusqu\u2019\u00e0 3 jours de t\u00e9l\u00e9travail possible par semaine, des tickets restaurant pour les jours t\u00e9l\u00e9travaill\u00e9s ou encore une participation \u00e0 l\u2019achat d\u2019un \u00e9cran ou fauteuil ergonomique ;\nD\u2019une politique visant \u00e0 concilier vie personnelle et vie professionnelle avec 28 jours de cong\u00e9s pay\u00e9s, entre 14 et 16 RTT selon les ann\u00e9es, des formules de travail \u00e0 temps partiel ou encore des jours d\u2019absence r\u00e9mun\u00e9r\u00e9es pour la rentr\u00e9e scolaire ou un d\u00e9m\u00e9nagement par exemple ;\nDe la possibilit\u00e9 de s\u2019engager pour une cause qui vous tient \u00e0 c\u0153ur gr\u00e2ce \u00e0 nos associations telles que AXA Atout C\u0153ur, AXA Comp\u00e9tences Solidaires ou encore AXA Pr\u00e9vention ;\nEt bien plus encore ! Perspectives de d\u00e9veloppement des comp\u00e9tences et de carri\u00e8res immenses, CE, conciergerie, offres privil\u00e8ges, soutien en cas d\u2019\u00e9preuve personnelle\u2026On s\u2019arr\u00eate l\u00e0, la liste est longue\nVotre environnement de travail\nNotre raison d\u2019\u00eatre chez AXA ? Chaque jour, nous agissons ensemble pour le progr\u00e8s humain en prot\u00e9geant ce qui compte. Une mission qui donne le sourire et envie de se lever le matin !\nUn des leaders mondiaux de l\u2019assurance dans la protection des biens, des personnes et des actifs, AXA c\u2019est 145 000 collaborateurs et contributeurs qui s\u2019engagent au quotidien pour nos clients, c\u2019est 51 pays dans lesquels nous distribuons nos produits et services et plus de 90 millions de client qui nous font confiance dans le monde. Employeur citoyen et responsable, AXA s\u2019engage au quotidien pour des causes soci\u00e9tales & environnementales. Nous menons une politique inclusive engag\u00e9e pour reconna\u00eetre et valoriser les diff\u00e9rences individuelles. Ces ambitions vous parlent ? Alors venez changer le monde avec nous !\nVictime ou t\u00e9moin, en cas de discrimination, vous pouvez adresser vos signalements et/ou alertes discrimination \u00e0 alerte.discrimination.harcelement@axa.fr\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "R",
                "Go"
            ],
            "DataBase": [],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [],
            "DevTools": [
                "Git"
            ],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [
                "Cloud"
            ],
            "FrSoftSkills": [],
            "EnSoftSkils": []
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [],
            "Salary": [
                "3",
                "3"
            ],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "Data Analyst - Lyon (F/H)",
        "company": "Novencia Group",
        "location": "Lyon, Auvergne-Rh\u00f4ne-Alpes, France",
        "link": "https://fr.linkedin.com/jobs/view/data-analyst-lyon-f-h-at-novencia-group-3842056375?position=2&pageNum=32&refId=FUgWcwWTfkSy1LADz3eV7w%3D%3D&trackingId=pcb3zG3EL0bwAd9WUF3fkw%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Carnet de route\nNovencia accompagne ses clients dans leurs projets de transformation digitale, technologique et data.\nExpert en Data et Intelligence Artificielle nous aidons nos clients \u00e0 exploiter et valoriser leurs donn\u00e9es sous toutes ses formes en les accompagnant sur des projets de Data Gouvernance, Data Architecture, Data Science, et Data Engineering.\nData Analyst\ndepuis au moins\n3 ans,\ntu es \u00e0 la recherche de nouveaux d\u00e9fis. Boucle ta ceinture, la suite est pour toi !\nTon R\u00f4le\nRattach\u00e9.e aux consultants de l\u2019agence Lyonnaise, tu seras amen\u00e9.e \u00e0 travailler chez les clients finaux et/ou au sein de notre Datalab\u2019.\nEn tant que Data Analyst, tu auras les missions suivantes :\nT\u2019immerger dans le contexte client ;\nMener des ateliers avec les \u00e9quipes m\u00e9tier pour recueillir/ d\u00e9finir leurs besoins ;\nChallenger leurs demandes ;\nParticiper au recueil et \u00e0 la mod\u00e9lisation des donn\u00e9es ;\nContr\u00f4ler la fiabilit\u00e9 et la qualit\u00e9 des donn\u00e9es ;\nStructurer et exploiter les donn\u00e9es gr\u00e2ce \u00e0 des outils de Data visualisation ;\nAnalyser ces donn\u00e9es et partager les r\u00e9sultats ;\nFaire des recommandations au client.\nTon profil\nDe formation Bac+5 dans le domaine de la Data, tu as au moins 3 ans d\u2019exp\u00e9rience sur un poste similaire.\nComp\u00e9tences techniques recherch\u00e9es :\nExp\u00e9rience significative sur un outil de Data visualisation pour l\u2019\u00e9laboration de rapports/tableaux de bord (Power BI/Tableau/QlikSense etc.)\nLangage SQL (Python est un plus)\nMod\u00e9lisation de donn\u00e9es\nConnaissance des bases de donn\u00e9es (e.g. Snowflake, Google BigQuery, SQL Server ou Oracle)\nUtilisation d\u2019un ETL (e.g. Azure Data Factory, SSIS, Informatica, Talend, Matillion)\nUne exp\u00e9rience dans le fonctionnement d\u2019une \u00e9quipe agile.\nTu es passionn\u00e9.e par la Data et souhaites \u00e9voluer au sein d\u2019une communaut\u00e9 d\u2019Experts de la Data, tu veux t\u2019investir dans des projets data innovants au sein de notre Datalab\u2019, tu aimes le travail en \u00e9quipe mais sais \u00eatre autonome sur tes sujets, tu es curieux.euse et force de proposition, tu es capable de chercher et trouver des solutions, tu as un bon niveau d\u2019anglais.\nEnfin, tu souhaites int\u00e9grer une agence \u00e0 taille humaine o\u00f9 la bienveillance n\u2019est pas qu\u2019un mot marketing.\nS\u2019engager en faveur du handicap c\u2019est garantir l\u2019\u00e9galit\u00e9 des chances d\u00e8s le recrutement. \u00c0 comp\u00e9tences \u00e9gales, nos postes sont ouverts aux personnes en situation de handicap.\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "R",
                "Go"
            ],
            "DataBase": [
                "SQL"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [
                "Tableau",
                "Power BI"
            ],
            "Statistics": [],
            "CloudComputing": [
                "Azure"
            ],
            "DevTools": [
                "Git"
            ],
            "Os": [],
            "DBMS": [
                "Oracle",
                "SQL Server",
                "Snowflake",
                "Snowflake",
                "BigQuery"
            ],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [],
            "FrSoftSkills": [],
            "EnSoftSkils": []
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [],
            "Salary": [],
            "Level": [
                "Bac+5"
            ],
            "Experience": [
                "a",
                "n",
                "s",
                "3",
                "3",
                "3"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "Data Engineer F/H",
        "company": "ARMOR GROUP",
        "location": "La Chevroli\u00e8re, Pays de la Loire, France",
        "link": "https://fr.linkedin.com/jobs/view/data-engineer-f-h-at-armor-group-3828365820?position=3&pageNum=32&refId=FUgWcwWTfkSy1LADz3eV7w%3D%3D&trackingId=l1gCM7cu9ZgGc%2FpuLpFSwA%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Qui sommes nous ?\nCentenaire (en 2022), ARMOR GROUP poursuit sa croissance gr\u00e2ce \u00e0 une solide implantation, \u00e0 la fois localement avec son site industriel situ\u00e9 \u00e0 la Chevroli\u00e8re en Loire Atlantique et mondialement avec ses diff\u00e9rentes implantations industrielles, logistiques et commerciales.\nNotre c\u0153ur de m\u00e9tier consiste \u00e0 produire des films encr\u00e9s, de la conception des encres \u00e0 la fabrication de rubans, jusqu\u2019\u00e0 leur commercialisation.\nNous d\u00e9veloppons \u00e9galement de nouvelles activit\u00e9s industrielles innovantes : films collecteurs de courant, films photovolta\u00efques organiques et mat\u00e9riaux pour la fabrication additive (impression 3D).\nNous Sommes Une Entreprise Engag\u00e9e Dans\nLa satisfaction de nos clients et la production de produits de qualit\u00e9\nL\u2019investissement de notre outil de production pour am\u00e9liorer la s\u00e9curit\u00e9 et les conditions de travail de nos salari\u00e9s.\nLes Plus D\u2019ARMOR GROUP\nLes conditions de travail, une politique sociale engag\u00e9e (cr\u00e8che d\u2019entreprise, universit\u00e9 interne pour les m\u00e9tiers de la production\u2026)\nSalaire fixe avec des primes li\u00e9es au poste de travail, au transport, int\u00e9ressement et participation, primes mensuelles etc.\nUn comit\u00e9 d\u2019entreprise et un restaurant d\u2019entreprise sur site \u00e0 tarif pr\u00e9f\u00e9rentiel.\nVotre quotidien en nous rejoignant\nAu sein de l'\u00e9quipe Informatique Industrielle du Groupe, votre mission consiste \u00e0 g\u00e9rer et am\u00e9liorer les syst\u00e8mes de donn\u00e9es industrielles du P\u00f4le Industriel France et de ses filiales de production \u00e0 l\u2019international.\nA Cet Effet, Vous \u00cates En Charge De\nMaintenir et faire \u00e9voluer l\u2019architecture n\u00e9cessaire \u00e0 la valorisation de donn\u00e9es,\nG\u00e9rer et organiser les donn\u00e9es industrielles et les flux de donn\u00e9es entrants et sortants (SQL Server, SSIS, Historian),\nConsolider les diff\u00e9rentes sources de donn\u00e9es On Premise dans notre Datalake Azure et Cubes de donn\u00e9es,\nParticiper \u00e0 la conception des reportings en lien avec les services m\u00e9tiers (Am\u00e9lioration continu, process, qualit\u00e9, production, \u2026),\nOptimiser et p\u00e9renniser les syst\u00e8mes existants en temps r\u00e9el,\nAssurer l'accompagnement des utilisateurs cl\u00e9s.\nProfil recherch\u00e9\nDot\u00e9 d'un BAC+5 en Informatique dans le domaine de l'informatique d\u00e9cisionnelle (BI), vous avez une premi\u00e8re exp\u00e9rience r\u00e9ussie en tant que Data Engineer.\nMa\u00eetrise des outils d\u2019ETL tels que SSIS, Azure data factory.\nConnaissance de la plateforme Azure Databricks est appr\u00e9ci\u00e9.\nConnaissances g\u00e9n\u00e9rales en informatique (architecture, bases de donn\u00e9es, m\u00e9thodologies de d\u00e9veloppement\u2026).\nConnaissance du milieu industriel appr\u00e9ci\u00e9e.\nQualit\u00e9s personnelles recherch\u00e9es : capacit\u00e9 d\u2019\u00e9coute et sens relationnel, force de proposition, pragmatisme, capacit\u00e9 de synth\u00e8se, go\u00fbt du terrain, capacit\u00e9 de travail en \u00e9quipe et \u00e0 communiquer.\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "R",
                "Go"
            ],
            "DataBase": [
                "SQL"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [
                "Databricks"
            ],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [
                "Azure"
            ],
            "DevTools": [],
            "Os": [],
            "DBMS": [
                "SQL Server"
            ],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [],
            "FrSoftSkills": [],
            "EnSoftSkils": []
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [],
            "Salary": [
                "5"
            ],
            "Level": [
                "Bac+5"
            ],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "Data Analyst / Analytics Engineer (H/F)",
        "company": "CleverConnect",
        "location": "Paris, \u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/data-analyst-analytics-engineer-h-f-at-cleverconnect-3904533153?position=4&pageNum=32&refId=FUgWcwWTfkSy1LADz3eV7w%3D%3D&trackingId=JXSKMWdUYxr6hXO64nKJ6g%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Description de l'entreprise\nCleverConnect est une scale-up franco-allemande de la HR Tech en croissance fond\u00e9e il y a 10 ans par des ing\u00e9nieurs. Nous sommes pr\u00e9sents en France et Allemagne. Depuis la fusion avec Talentry en 2022, nous partageons l\u2019ambition de devenir le leader des software solutions du Talent Acquisition en Europe\nNous accompagnons actuellement plus de 10 millions de candidats par an \u00e0 trouver le bon poste Pour cela, nous mettons en relation les recruteurs et les candidats avec des solutions digitales et des plateformes SaaS innovantes pour rendre le processus de recrutement plus efficace. Nos technologies permettent aux candidats de trouver des opportunit\u00e9s plus cibl\u00e9es et de valoriser leur personnalit\u00e9 et motivation\nRejoignez notre \u00e9quipe internationale de 200 coll\u00e8gues qui partagent la m\u00eame culture et les m\u00eames valeurs, et qui sont pleinement engag\u00e9s dans un projet \u00e0 fort impact soci\u00e9tal\nSi vous voulez en savoir plus : www.cleverconnect.com\nDescription du poste\nEn tant que Data Analyst, quelles seront vos responsabilit\u00e9s \u200d\u200d?\nCollaborer avec les d\u00e9partements Product, Sales, Marketing et Communication pour comprendre les besoins m\u00e9tier et les traduire en solutions de donn\u00e9es.\nImpl\u00e9menter et optimiser des mod\u00e8les de donn\u00e9es \u00e0 l'aide de DBT et garantir la qualit\u00e9 et l'int\u00e9grit\u00e9 des donn\u00e9es. Vous serez en charge de transformer et mettre en forme les donn\u00e9es du datawarehouse en approche ELT.\nUtiliser BigQuery et DBT pour analyser de grands ensembles de donn\u00e9es et en tirer des insights exploitables.\nCr\u00e9er et maintenir des rapports et des tableaux de bord dans des outils de dataviz type Looker Studio, Superset, PowerBI ou Metabase. Ces tableaux de bords peuvent concerner les besoins internes (product, communication, marketing, sales, etc.) et externes (embedded dans nos solutions \u00e0 destination des clients).\nParticiper \u00e0 la conception des pipelines d\u2019ingestion de donn\u00e9es avec le Data Engineer.\nEffectuer des analyses ad hoc et fournir des recommandations bas\u00e9es sur les donn\u00e9es pour soutenir les d\u00e9cisions m\u00e9tier.\nQualifications\nQui \u00eates-vous ?\nVous avez au moins 5 ann\u00e9es d'exp\u00e9rience en tant que Data Analyst dans un environnement similaire.\nTechniquement et id\u00e9alement ,\nMa\u00eetrise avanc\u00e9e de SQL et exp\u00e9rience de travail avec des ensembles de donn\u00e9es \u00e0 grande \u00e9chelle.\nExp\u00e9rience pratique avec BigQuery, DBT ou \u00e9quivalents requis. Exp\u00e9riences Snowplow et Elasticsearch appr\u00e9ci\u00e9es.\nFamiliarit\u00e9 avec les outils de visualisation de donn\u00e9es tels que Looker Studio, Superset, PowerBI ou Metabase.\n\u00catre \u00e0 l\u2019aise dans le scripting python pour automatiser certaines transformations de donn\u00e9es.\nAvoir d\u00e9j\u00e0 manipul\u00e9 un outil de Web Analytics tel que Google Analytics.\nExp\u00e9rience dans un environnement Agile et capacit\u00e9 \u00e0 travailler en collaboration dans des \u00e9quipes interfonctionnelles.\nQ\nue trouverez-vous chez CleverConnect ?\nUne \u00e9quipe dirigeante accessible, bienveillante et \u00e0 l\u2019\u00e9coute\nDes bureaux au c\u0153ur des villes et la possibilit\u00e9 de faire du t\u00e9l\u00e9travail\nDes opportunit\u00e9s de formation, d\u2019\u00e9volution et de mobilit\u00e9 en Europe\nRTT, mutuelle, carte d\u00e9jeuner, remboursement 50% transport, forfait mobilit\u00e9 durable\nNotre processus de recrutement comprend:\nEntretien initial avec un Responsable de l'Acquisition de Talents\nEntretien avec le Manager (d\u00e9couverte/\u00e9valuations techniques)\nDernier entretien avec le Directeur IT ou CPTO.\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "R",
                "Go"
            ],
            "DataBase": [
                "SQL",
                "Elasticsearch"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [
                "Tableau",
                "PowerBI"
            ],
            "Statistics": [],
            "CloudComputing": [],
            "DevTools": [
                "Git"
            ],
            "Os": [],
            "DBMS": [
                "BigQuery"
            ],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [],
            "FrSoftSkills": [
                "Communication",
                "Collaboration"
            ],
            "EnSoftSkils": [
                "Communication",
                "Collaboration"
            ]
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s",
                "10",
                "10",
                "10"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "Data Engineer F/H",
        "company": "CGI",
        "location": "Greater Clermont-Ferrand Area",
        "link": "https://fr.linkedin.com/jobs/view/data-engineer-f-h-at-cgi-3883952151?position=5&pageNum=32&refId=FUgWcwWTfkSy1LADz3eV7w%3D%3D&trackingId=hb9obuz0c%2BwRgicTmsXWsQ%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Description de poste\nBig Data, Data Science, Data analyse, Data architecture, ... \u00c7a n\u2019a pas de secret pour vous?\nQue vous commenciez votre carri\u00e8re professionnelle ou que vous soyez sp\u00e9cialiste de l\u2019une de ces disciplines, int\u00e9grer notre communaut\u00e9 Data, c\u2019est l\u2019assurance de progresser, innover, partager, vous certifier et rendre service \u00e0 nos clients.\nFonctions et responsabilit\u00e9s\nAlors venez rejoindre nos \u00e9quipes de Data Engineer. Vous pouvez \u00eatre amen\u00e9 \u00e0 intervenir sur tout ou partie de ces missions :\nMod\u00e9lisation des Data Concepts d'un DataLake\nD\u00e9veloppement et maintenance des traitements d'int\u00e9gration et de transformation de donn\u00e9es\nInt\u00e9gration des d\u00e9veloppements dans la chaine CI/CD\nDocumentation technique et fonctionnelle\nR\u00e9daction de plan de tests\nR\u00e9alisation de tests unitaires/qualifications\nAu sein de la communaut\u00e9 Data, vous serez accompagn\u00e9 et vous pourrez \u00e9changer avec des coll\u00e8gues exp\u00e9riment\u00e9s et experts vous permettant de vous d\u00e9velopper, de grandir et d\u2019accomplir pleinement vos missions de conseil.\nL\u2019accompagnement manag\u00e9rial, la communaut\u00e9 Data et de nombreux \u00e9v\u00e8nements tout au long de l\u2019ann\u00e9e nous permettront de vous aider \u00e0 atteindre vos objectifs dans un esprit de convivialit\u00e9.\nEn rejoignant CGI, vous b\u00e9n\u00e9ficiez notamment d\u2019une offre compl\u00e8te de formations (techniques, m\u00e9tiers, d\u00e9veloppement personnel,\u2026), de flexibilit\u00e9 gr\u00e2ce \u00e0 notre accord t\u00e9l\u00e9travail (jusqu\u2019\u00e0 3 jours de t\u00e9l\u00e9travail par semaine), d\u2019une politique de cong\u00e9s avantageuse (27 jours de cong\u00e9s pay\u00e9s, RTT, cong\u00e9s anciennet\u00e9 et enfant malade,\u2026) et d\u2019un package d\u2019avantages int\u00e9ressant (r\u00e9gime d\u2019achats d\u2019actions, participation, CSE,...).\nQualit\u00e9s requises pour r\u00e9ussir dans ce r\u00f4le\nVous avez une formation Bac+3/5 en informatique, au minimum 1 an d\u2019exp\u00e9rience et des aptitudes sur l\u2019un ou plusieurs des domaines suivants :\nVous maitrisez :\nData Visualisation : Power BI, MicroStrategy, Tableau, Cognos\u2026\nLangages : SQL, Python, DAX, R\u2026\nApplications Cloud : Azure, Snowflake, Databricks, AWS...\nBases de donn\u00e9es : Oracle, PostgreSQL, MySQL, Mongo db, Sybase\u2026\nETL : Datastage, Talend, Informatica (PowerCenter) \u2026\nVous avez/ Vous \u00eates :\nPassionn\u00e9 du monde de la data\nCurieux et appr\u00e9ciez le travail en \u00e9quipe\nCGI est un employeur inclusif et attentif aux candidatures des personnes en situation de handicap, \u00e0 l\u2019\u00e9volution de carri\u00e8res des hommes et des femmes et au bien-\u00eatre de nos salari\u00e9s LGBT+. Dans un souci d\u2019accessibilit\u00e9 et de clart\u00e9, le point m\u00e9dian n\u2019est pas utilis\u00e9 dans cette annonce. Tous les termes employ\u00e9s se r\u00e9f\u00e8rent aussi bien au genre f\u00e9minin que masculin.\nEnsemble, en tant que propri\u00e9taires, mettons notre savoir-faire \u00e0 l\u2019\u0153uvre.\nLa vie chez CGI est ancr\u00e9e dans l\u2019actionnariat, le travail d\u2019\u00e9quipe, le respect et un sentiment d\u2019appartenance. Chez nous, vous pourrez exploiter votre plein potentiel parce que\u2026\nNous vous invitons \u00e0 devenir propri\u00e9taire d\u00e8s le jour 1 alors que nous travaillons ensemble \u00e0 faire de notre r\u00eave une r\u00e9alit\u00e9. C\u2019est pourquoi nous nous d\u00e9signons comme associ\u00e9s de CGI, plut\u00f4t que comme employ\u00e9s. Nous tirons profit des retomb\u00e9es de notre succ\u00e8s collectif et contribuons activement \u00e0 l\u2019orientation et \u00e0 la strat\u00e9gie de notre entreprise.\nVotre travail cr\u00e9e de la valeur. Vous \u00e9laborerez des solutions novatrices et d\u00e9velopperez des relations durables avec vos coll\u00e8gues et clients, tout en ayant acc\u00e8s \u00e0 des capacit\u00e9s mondiales pour concr\u00e9tiser vos id\u00e9es, saisir de nouvelles opportunit\u00e9s, et b\u00e9n\u00e9ficier d\u2019une expertise sectorielle et technologique de pointe.\nVous ferez \u00e9voluer votre carri\u00e8re en vous joignant \u00e0 une entreprise b\u00e2tie pour cro\u00eetre et durer. Vous serez soutenus par des leaders qui ont votre sant\u00e9 et bien-\u00eatre \u00e0 c\u0153ur et qui vous permettront de saisir des occasions afin de parfaire vos comp\u00e9tences et \u00e9largir les horizons.\nJoignez-vous \u00e0 nous, l\u2019une des plus importantes entreprises de conseil en technologie de l\u2019information (TI) et en management au monde.\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "R",
                "Go"
            ],
            "DataBase": [
                "SQL"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [
                "Databricks"
            ],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [
                "Tableau",
                "Power BI"
            ],
            "Statistics": [],
            "CloudComputing": [
                "AWS",
                "Azure"
            ],
            "DevTools": [],
            "Os": [],
            "DBMS": [
                "MySQL",
                "PostgreSQL",
                "Oracle",
                "Snowflake",
                "Snowflake"
            ],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [
                "Big Data",
                "Cloud",
                "CI/CD"
            ],
            "FrSoftSkills": [
                "Flexibilit\u00e9"
            ],
            "EnSoftSkils": []
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [],
            "Salary": [
                "3"
            ],
            "Level": [
                "Bac+3"
            ],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "Lead Data Engineer H/F",
        "company": "Neosoft",
        "location": "Lille, Hauts-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/lead-data-engineer-h-f-at-neosoft-3879749134?position=6&pageNum=32&refId=FUgWcwWTfkSy1LADz3eV7w%3D%3D&trackingId=KSuIL63EhPi3OfQhBM92XA%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Tous nos postes sont ouverts au t\u00e9l\u00e9travail\nGroupe ind\u00e9pendant de conseil en transformation digitale de pr\u00e8s de 1800 collaborateurs, N\u00e9osoft s\u2019est construit, depuis 2005, sur un mod\u00e8le qui place l\u2019excellence, le d\u00e9passement de soi et la RSE au c\u0153ur de sa strat\u00e9gie.\nEn nous rejoignant, vous int\u00e9grez des communaut\u00e9s d\u2019experts et de talents qui vous permettent de d\u00e9velopper vos comp\u00e9tences et d\u2019offrir \u00e0 nos clients le meilleur accompagnement possible.\nNotre savoir-faire s\u2019articule autour de nos 6 domaines d\u2019expertise :\nConseil & Agilit\u00e9\nCybers\u00e9curit\u00e9\nData\nDevOps\nInfrastructures & Cloud\nSoftware Engineering\nNous recherchons pour int\u00e9grer notre\nagence lilloise\nun(e)\nLead Data Engineer H/F.\nNous aimerions vous voir rayonner au sein de notre communaut\u00e9 DATA (+100 collaborateurs) anim\u00e9e par Nicolas Huche, son practice leader et Thibaud Blanchard son Technical Officer. Vous aiderez les clients \u00e0 consolider un patrimoine Data responsable.\nVos missions :\nApr\u00e8s une p\u00e9riode d\u2019int\u00e9gration, en tant que\nLead Data Engineer\n, voici \u00e0 quoi ressembleront vos activit\u00e9s dans des contextes clients Retail ou Banque / Assurance / Finance :\nD\u00e9finir la strat\u00e9gie d'ing\u00e9nierie technique des donn\u00e9es\nParticiper \u00e0 la conception d'architectures de donn\u00e9es robustes et \u00e9volutives\nOptimiser les performances et la scalabilit\u00e9\nExercer un v\u00e9ritable r\u00f4le de Leader technique\nVotre profil :\nNous vous imaginons avec au moins 6 ans d\u2019exp\u00e9riences sur des projets autour de la Data, une ma\u00eetrise des bases de donn\u00e9es (SQL), des outils de transformation de la donn\u00e9e (Talend, BigQuery, Airflow), un socle de comp\u00e9tences solides autours des langages Python, Spark, Scala, Hadoop, Java et dans un environnement Cloud.\n\ud83d\udc49\nVotre carri\u00e8re chez N\u00e9osoft\nDepuis sa cr\u00e9ation, N\u00e9osoft place ses collaborateurs au c\u0153ur de sa strat\u00e9gie. Notre culture pourrait se r\u00e9sumer en un mot : le collectif.\nNos communaut\u00e9s d\u2019experts vous donnent la possibilit\u00e9 d\u2019apprendre, mais aussi de transmettre et de partager vos savoirs pour faire progresser les autres.\nNous veillons \u00e0 ce que chacun b\u00e9n\u00e9ficie d\u2019un accompagnement de proximit\u00e9 et d\u2019un suivi de carri\u00e8re personnalis\u00e9 aupr\u00e8s de votre manager d\u00e9di\u00e9 :\n1 bilan d\u2019activit\u00e9 trimestriel pour suivre le d\u00e9veloppement de vos comp\u00e9tences\n1 entretien d\u2019\u00e9valuation qui a lieu chaque ann\u00e9e pour \u00e9valuer votre performance et d\u00e9terminer vos nouveaux objectifs\n1 entretien annuel aupr\u00e8s de votre RH dans le but de cartographier vos nouvelles comp\u00e9tences pour \u00e9changer sur vos projets professionnels et souhaits de formation\n\ud83d\udc49\nVos avantages\nFormations et d\u00e9veloppement de l\u2019expertise :\nVous disposez de temps allou\u00e9 et r\u00e9mun\u00e9r\u00e9 en contribuant au d\u00e9veloppement de votre expertise technique et de celle du groupe (Participations \u00e0 des Tech days, animation d\u2019une conf\u00e9rence \u00e0 l\u2019interne ou \u00e0 l\u2019externe, r\u00e9daction d\u2019articles, rencontres avec nos candidats en processus de recrutement\u2026)\nUn abonnement illimit\u00e9 LinkedIn Learning offert\nBien-\u00eatre au travail :\nUn accord de t\u00e9l\u00e9travail flexible jusqu\u2019\u00e0 100% de t\u00e9l\u00e9travail et personnalisable\nUn partenariat avec Gymlib qui favorise le sport en entreprise\nDes initiatives locales (afterworks, d\u00e9fis sportifs, team buildings, \u2026)\nEt bien plus encore :\nParce que les meilleurs cooptent les meilleurs, une politique de cooptation attractive r\u00e9mun\u00e9r\u00e9e d\u00e8s l\u2019arriv\u00e9e du collaborateur\nEn plus de votre salaire : participation, compte \u00e9pargne temps, actionnariat...\n\ud83d\udc49\nVotre parcours candidat\nNotre processus de recrutement se compose de deux \u00e9tapes cl\u00e9s :\nUn entretien de recrutement RH avec un Talent Acquisition Sp\u00e9cialiste pour dresser un bilan de votre parcours professionnel et identifier les trajectoires de carri\u00e8re possibles au sein de notre groupe\nUn entretien d\u2019\u00e9valuation technique pour r\u00e9aliser un diagnostic de vos comp\u00e9tences techniques et identifier les comp\u00e9tences sur lesquels poursuivre votre \u00e9volution\nVous aurez \u00e9galement la possibilit\u00e9 de rencontrer pour compl\u00e9ter votre processus un acteur de notre p\u00f4le Business ou un pair de votre m\u00e9tier pour \u00e9changer sur son exp\u00e9rience collaborateur.\nNous avons h\u00e2te de vous rencontrer !\nA bient\u00f4t,\nL\u2019\u00e9quipe N\u00e9osoft \ud83d\udd90\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "Java",
                "Scala",
                "R"
            ],
            "DataBase": [
                "SQL"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [
                "Hadoop",
                "Spark"
            ],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [],
            "DevTools": [
                "Git"
            ],
            "Os": [],
            "DBMS": [
                "BigQuery"
            ],
            "SoftBigDataProcessing": [],
            "Automation": [
                "Airflow"
            ],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [
                "DevOps",
                "ML",
                "Cloud"
            ],
            "FrSoftSkills": [],
            "EnSoftSkils": [
                "Initiative"
            ]
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [],
            "Salary": [
                "Salaire"
            ],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s",
                "6",
                "6",
                "6"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "Data Engineer & Architect - 100% T\u00e9l\u00e9travail H/F",
        "company": "Proxiel",
        "location": "Lyon, Auvergne-Rh\u00f4ne-Alpes, France",
        "link": "https://fr.linkedin.com/jobs/view/data-engineer-architect-100%25-t%C3%A9l%C3%A9travail-h-f-at-proxiel-3913994350?position=7&pageNum=32&refId=FUgWcwWTfkSy1LADz3eV7w%3D%3D&trackingId=WogUOlUm8i9QjgIdZLo3FQ%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Cr\u00e9\u00e9e en 1998, Proxiel est une soci\u00e9t\u00e9 de services num\u00e9riques. Proxiel est une soci\u00e9t\u00e9 fran\u00e7aise bas\u00e9e \u00e0 Montpellier et Paris. Proxiel a d\u00e9velopp\u00e9 son expertise pour fournir une gamme de service compl\u00e8te qui va de l'\u00e9tude \u00e0 la r\u00e9alisation, dans le domaine de la maintenance informatique, du d\u00e9veloppement de logiciel et de solutions informatiques.\nProxiel, fort de son exp\u00e9rience, d\u00e9l\u00e8gue \u00e9galement, son savoir au coeur des organisations, au niveau national.\nDepuis plusieurs ann\u00e9es le Groupe Proxiel s'est dot\u00e9 d'un P\u00f4le Formation, pour conseiller, mettre en oeuvre et accompagner ses collaborateurs et partenaires, dans le d\u00e9veloppement de leurs comp\u00e9tences.\nNous sommes experts dans le recrutement de profils tech. Nos consultants se donnent \u00e0 fond pour entrer en contact avec vous !\nNotre politique se poursuit lors de la contractualisation, le service ressources humaines est \u00e0 la disposition de l'ensemble des collaborateurs.\nChez Proxiel, nous valorisons la collaboration et la proximit\u00e9, tout en laissant place \u00e0 l'autonomie.\nNous recherchons un Data Engineer & Architect (F/H) pour int\u00e9grer notre partenaire Grand Compte en 100% t\u00e9l\u00e9travail (d\u00e9placements ponctuels \u00e0 effectuer sur Lyon).\nVous jouerez un r\u00f4le central dans la construction de pipelines de donn\u00e9es robustes pour alimenter des syst\u00e8mes d'IA g\u00e9n\u00e9rative de pointe. Ce r\u00f4le offre une opportunit\u00e9 passionnante de contribuer \u00e0 des projets r\u00e9volutionnaires \u00e0 l'intersection de l'ing\u00e9nierie des donn\u00e9es et de l'intelligence artificielle, tout en assumant des responsabilit\u00e9s dans l'architecture des donn\u00e9es.\nLes Principales Responsabilit\u00e9s Sont Les Suivantes\nVous \u00eates en charge de la conception et de la construction de pipelines de donn\u00e9es \u00e9volutifs permettant de r\u00e9cup\u00e9rer, d'agr\u00e9ger et de pr\u00e9traiter efficacement les donn\u00e9es provenant de diff\u00e9rentes sources, tout en garantissant une fiabilit\u00e9 et des performances \u00e9lev\u00e9es.\nVous \u00eates en charge de la conception des mod\u00e8les de donn\u00e9es, des solutions de stockage et des sch\u00e9mas d'acc\u00e8s.\nVous avez la possibilit\u00e9 de collaborer avec les parties prenantes pour comprendre les besoins et pour d\u00e9finir et faire \u00e9voluer la strat\u00e9gie d'architecture des donn\u00e9es, y compris la mod\u00e9lisation des donn\u00e9es, le stockage et les sch\u00e9mas d'acc\u00e8s.\nVous travaillez avec une \u00e9quipe agile interfonctionnelle pour int\u00e9grer des donn\u00e9es provenant de divers syst\u00e8mes et sources, effectuer des processus d'extraction, de transformation et de chargement (ETL) et maintenir l'int\u00e9grit\u00e9 des donn\u00e9es tout au long du pipeline, en it\u00e9rant sur les solutions et en communiquant sur les progr\u00e8s r\u00e9alis\u00e9s.\nMa\u00eetrise des langages de programmation\nUne solide compr\u00e9hension des technologies de base de donn\u00e9es (par exemple, SQL, NoSQL), des entrep\u00f4ts de donn\u00e9es et d'Azure\nExp\u00e9rience en architecture de donn\u00e9es la conception de mod\u00e8les de donn\u00e9es, la d\u00e9finition de solutions de stockage et les sch\u00e9mas d'acc\u00e8s aux donn\u00e9es.\nFamiliarit\u00e9 avec le Machine learning, les concepts de traitement du langage naturel (NLP) et la G\u00e9n\u00e9ration Augment\u00e9e de R\u00e9cup\u00e9ration (RAG) est un plus.\nVous avez d'excellentes comp\u00e9tences en mati\u00e8re de communication et de collaboration, et \u00eates capable de travailler efficacement dans un environnement d'\u00e9quipe et dans le cadre de projets agiles.\nIssu d'une Formation Bac +2 \u00e0 Bac +5 en informatique, vous \u00eates polyvalent.\nVous d\u00e9tenez 3 ans d'exp\u00e9rience \u00e0 minima sur un poste similaire.\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "R"
            ],
            "DataBase": [
                "SQL",
                "NoSQL"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [
                "Azure"
            ],
            "DevTools": [],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [
                "Machine Learning"
            ],
            "FrSoftSkills": [
                "Communication",
                "Collaboration",
                "Organisation"
            ],
            "EnSoftSkils": [
                "Communication",
                "Collaboration"
            ]
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s",
                "3",
                "3",
                "3"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "Data Analyst F/H",
        "company": "Allianz France",
        "location": "Paris, \u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/data-analyst-f-h-at-allianz-france-3909179361?position=8&pageNum=32&refId=FUgWcwWTfkSy1LADz3eV7w%3D%3D&trackingId=%2F%2BCWe%2FLugj4ZcvfLAHVgjw%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "AIM Paris (Allianz Investment Management Paris), l\u2019unit\u00e9 Investissement d\u2019Allianz France, a la charge de la gestion des investissements des diff\u00e9rentes entit\u00e9s d\u2019Allianz France tant sur les portefeuilles d\u2019actifs g\u00e9n\u00e9raux qu\u2019en unit\u00e9s de compte (UC), sur toute la cha\u00eene de valeur des investissements, qui couvre la gestion actif-passif, la strat\u00e9gie d'investissement, ainsi que la planification des revenus des investissements, le suivi des risques, le reporting et les op\u00e9rations.\nLe r\u00f4le de l\u2019\u00e9quipe :\nPour soutenir ces activit\u00e9s, l\u2019\u00e9quipe AIM Finance & Op\u00e9rations, en charge des donn\u00e9es d\u2019investissements, des reportings et du suivi des risques des investissements, est \u00e0 la recherche d\u2019un\nData Analyst\n. Ce dernier, rattach\u00e9 hi\u00e9rarchiquement \u00e0 AIM Finance & Op\u00e9rations, couvrira l\u2019ensemble des besoins des diff\u00e9rentes \u00e9quipes d\u2019AIM (AIM Investment Strategy, AIM Asset-Liability Management, AIM Finance) et interviendra de fa\u00e7on op\u00e9rationnelle sur des projets de transformation locaux et Groupe.\nVoici vos principales missions :\n\u00b7\nL\u2019automatisation\nde sourcing des donn\u00e9es, des contr\u00f4les et des r\u00e9conciliations entre diff\u00e9rents syst\u00e8mes d\u2019informations\n\u00b7\nLe d\u00e9veloppement\nde macros/codes afin d\u2019automatiser/optimiser les t\u00e2ches\n\u00b7\nL\u2019am\u00e9lioration continue\ndes bases de donn\u00e9es Investissements\n\u00b7\nLa fiabilisation et l\u2019am\u00e9lioration\ncontinue des bases de donn\u00e9es\n\u00b7\nLa mise en place\nde nouveaux reportings (Power BI)\n\u00b7\nLe pilotage de projets\nen lien avec les initiatives groupes et locales\nVous travaillerez en lien \u00e9troit avec les autres \u00e9quipes d'AIM France ainsi que les \u00e9quipes AIM centrales \u00e0 Munich. La maitrise de\nl\u2019anglais\nest alors indispensable.\nVotre parcours :\nDipl\u00f4m\u00e9(e) en informatique/gestion des donn\u00e9es ou d\u2019une \u00e9cole d\u2019ing\u00e9nieur (\nBAC +5),\nvous disposez d\u2019une exp\u00e9rience significative dans la manipulation de donn\u00e9es\n(5-10 ans).\nMa\u00eetrise de plusieurs langages de d\u00e9veloppement du type\nPython, VBA, Access, SAS\nBonne ma\u00eetrise des outils bureautiques Powerpoint, Excel et VBA, et id\u00e9alement une premi\u00e8re exp\u00e9rience significative dans l\u2019utilisation d\u2019outils de datavisualisation\n(Power BI)\nCapacit\u00e9 d\u2019analyse et de synth\u00e8se, ouverture d\u2019esprit, rigueur, organisation et autonomie,\nFran\u00e7ais et\nanglais\nprofessionnel courants indispensables, \u00e0 l\u2019\u00e9crit comme \u00e0 l\u2019oral.\nVous aimez travailler en \u00e9quipe dans une entreprise qui met ses collaborateurs au c\u0153ur de sa strat\u00e9gie de d\u00e9veloppement ! Alors rejoignez-nous chez Allianz ! Toute l\u2019\u00e9quipe de Marwen NAJAR vous y attend !\nEn tant qu\u2019entreprise reconnue et internationale, nous vous offrons des avantages attractifs tels qu\u2019une flexibilit\u00e9 du temps de travail, le t\u00e9l\u00e9travail (3 jours par semaine), 9 semaines de cong\u00e9s, une restauration sur site, des taux pr\u00e9f\u00e9rentiels collaborateurs, des cong\u00e9s maternit\u00e9 et paternit\u00e9 \u00e9largis, des places en cr\u00e8che et bien plus encore.\nEn tant qu\u2019employeur, nous mettons tout en \u0153uvre pour vous assurer un bien \u00eatre propice \u00e0 votre \u00e9panouissement.\nAllianz est la 1\u00e8re marque mondiale d'assurance pr\u00e9sente dans 70 pays. Les #Allianzers, c'est 9.000 salari\u00e9s en France qui accompagnent leurs clients tout au long de leur vie, des collaborateurs qui associent innovation, performance et agilit\u00e9 pour relever des d\u00e9fis permanents au quotidien. Parce qu'en nous pr\u00e9occupant de l\u2019avenir de nos collaborateurs, nous pouvons encore mieux nous pr\u00e9occuper de l\u2019avenir de tous nos clients. Pour cela, Allianz innove et met la technologie aux services des hommes pour pr\u00e9parer leur avenir, un avenir plus s\u00fbr.\nEn qualit\u00e9 d\u2019employeur engag\u00e9, Allianz reconna\u00eet que sa force se trouve dans la diversit\u00e9 de ses collaborateurs. Nous sommes fiers de promouvoir l\u2019int\u00e9gration et l\u2019\u00e9galit\u00e9 des chances quel que soit le sexe, l\u2019\u00e2ge, l\u2019origine, la nationalit\u00e9, la religion, le handicap, ou l\u2019orientation sexuelle de nos collaborateurs.\nAllianz, We secure your future !\nInformations compl\u00e9mentaires :\nPoste base \u00e0 PARIS, La D\u00e9fense, M\u00e9tro Esplanade\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "R"
            ],
            "DataBase": [],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [
                "Power BI"
            ],
            "Statistics": [],
            "CloudComputing": [],
            "DevTools": [],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [],
            "FrSoftSkills": [
                "Organisation",
                "Flexibilit\u00e9"
            ],
            "EnSoftSkils": [
                "Initiative"
            ]
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s",
                "10",
                "10",
                "10"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "Big Data Engineer Confirm\u00e9 \u2013 Paris, France (H/F)",
        "company": "Astek",
        "location": "Paris, \u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/big-data-engineer-confirm%C3%A9-%E2%80%93-paris-france-h-f-at-astek-3839098103?position=9&pageNum=32&refId=FUgWcwWTfkSy1LADz3eV7w%3D%3D&trackingId=NcjHVVoQEj9b2qUQVZUuKA%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "CDI\nParis - France\nPubli\u00e9e il y a 2 mois\nLe Groupe Astek\nCe Que Nous Allons Accomplir Ensemble :\nNous rejoindre en tant que\nBig Data Engineer Confirm\u00e9 (H/F),\nafin d\u2019accompagner un op\u00e9rateur t\u00e9l\u00e9coms, Leader en Europe dans l\u2019assistance et le support applicatif de niveau 3 (r\u00e9solution des probl\u00e8mes utilisateurs, exploitation des environnements hors production).\nUn challenge portant sur des millions d\u2019utilisateurs dans un environnement technique innovant, strat\u00e9gique et o\u00f9 l\u2019entraide et la bonne humeur priment !\nVotre Mission, Si Vous L\u2019acceptez :\nSupervision et d\u00e9tection et r\u00e9solution des probl\u00e8mes utilisateurs (d\u00e9veloppeurs, exploitants et data exploreurs)\nD\u00e9veloppement de solutions de self-service ou d\u2019une solution de r\u00e9solutions automatiques des probl\u00e8mes\nQualifier les donn\u00e9es et les r\u00e9sultats\nConception technique des solutions\nAssurer l\u2019accompagnement et le d\u00e9ploiement des \u00e9volutions des processus et outils\nAccompagner la phase de mise en production\nVotre Future \u00c9quipe :\nVous int\u00e9grerez une \u00e9quipe \u00e0 la fois technique et fonctionnel, qui \u0153uvre chaque jour pour d\u00e9velopper et maintenir en conditions op\u00e9rationnelles l\u2019ensemble des solutions IT !\nL\u2019\u00e9quipe est en interaction avec des clients \u00e0 la fois internes et externes.\nVotre stack de jeu\nSyst\u00e8me d\u2019exploitation : Linux\nOutils des distributions : HDP, HDF, ELK\nEnvironnement Big data : Hadoop, Spark,\nLangage : Scala, Shell, Python\nCloud computing : GCP ou AWS\nBase de donn\u00e9es : No SQL (Cassandra, Mongo DB), Shell, Ansible\nDataviz : Power BI ou Kibana\nDes notions en R\u00e9seau et Syst\u00e8mes feront la diff\u00e9rence !\nLes Petits Plus Du Projet :\nVous \u00e9voluerez au sein d\u2019une \u00e9quipe impliqu\u00e9e et r\u00e9active et interviendrez sur un projet polyvalent et \u00e0 forte valeur ajout\u00e9e.\nVous ?\nDipl\u00f4m\u00e9(e) d\u2019une \u00e9cole d\u2019ing\u00e9nieur ou \u00e9quivalent de niveau Bac+5.\nVous justifiez id\u00e9alement d\u2019une exp\u00e9rience d\u2019au moins 3 ans d\u2019exp\u00e9riences sur un poste similaire ?\nVous faite preuve de proactivit\u00e9 et d\u2019esprit d\u2019\u00e9quipe, \u00eates dot\u00e9(e) d\u2019un excellent sens de l\u2019organisation et vous aimez les challenges et la r\u00e9solution de probl\u00e8me ?\nAlors ce poste est fait pour vous, n\u2019h\u00e9sitez plus et rejoignez l\u2019aventure ASTEK !\nAstek\nCr\u00e9\u00e9 en France en 1988, Astek est un acteur mondial de l\u2019ing\u00e9nierie et du conseil en technologies. Fort de son expertise dans de nombreux secteurs industriels et tertiaires, Astek accompagne ses clients internationaux dans le d\u00e9ploiement intelligent de leurs produits et de leurs services, et dans la mise en \u0153uvre de leur transformation digitale.\nDepuis sa cr\u00e9ation, le Groupe a fond\u00e9 son d\u00e9veloppement sur une forte culture d\u2019entrepreneuriat et d\u2019innovation, et sur l\u2019accompagnement et la mont\u00e9e en comp\u00e9tence de\nses 7800 collaborateurs\nqui s\u2019engagent chaque jour \u00e0 promouvoir la compl\u00e9mentarit\u00e9 entre les technologies num\u00e9riques et l\u2019ing\u00e9nierie des syst\u00e8mes complexes.\nRejoignez un Groupe en fort d\u00e9veloppement en France et \u00e0 travers le monde ayant r\u00e9alis\u00e9 un chiffre d\u2019affaires de 600 M\u20ac en 2023.\nTous les d\u00e9tails sur le Groupe sur le site https://astekgroup.fr. Et vous pouvez aussi nous suivre sur notre blog : https://blog.groupeastek.com.\nRencontrons-nous\nNotre projet commun vous plait ?\nPostulez \u00e0 cette annonce, et soyez transparent !\nMaud, notre Talent Acquisition Referent, vous contactera pour un premier \u00e9change.\nPuis vous rencontrerez Martin, votre futur manager, avec lequel vous \u00e9changerez autour d\u2019Astek, de votre parcours, de vos attentes et de votre future mission .\nEnfin, vous rencontrerez J\u00e9r\u00e9my, notre Directeur d\u2019agence avec lequel vous pourrez valider votre int\u00e9r\u00eat et ad\u00e9quation pour le poste et finaliser les \u00e9l\u00e9ments contractuels.\nNos Plus\nAstek est green et fait b\u00e9n\u00e9ficier ses salari\u00e9s d\u2019une indemnit\u00e9 kilom\u00e9trique v\u00e9lo\nUne politique CARE sur-mesure d\u00e9ploy\u00e9e par nos \u00e9quipes RH pour nos collaborateurs (https://astekgroup.fr/engagements)\nNotre charte de la Diversit\u00e9\nMots-cl\u00e9s :\ning\u00e9nieur \u2013 ing\u00e9nieure \u2013 consultant \u2013 consultante \u2013 Hadoop \u2013 Scala \u2013 Data\nCaract\u00e9ristiques de l'emploi\nCat\u00e9gorie Ing\u00e9nieur\nJob Industry T\u00e9l\u00e9com / M\u00e9dia\nPostuler en ligne\nNom *\nPr\u00e9nom *\nEmail *\nUn email valide est requis.\nT\u00e9l\u00e9phone *\nUn num\u00e9ro de t\u00e9l\u00e9phone valide est requis.\nJoindre un CV *\nMots-cl\u00e9s :\ning\u00e9nieur \u2013 ing\u00e9nieure \u2013 consultant \u2013 consultante \u2013 Hadoop \u2013 Scala \u2013 Data\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "Scala",
                "R",
                "Go"
            ],
            "DataBase": [
                "SQL",
                "Cassandra"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [
                "Hadoop",
                "Spark"
            ],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [
                "Power BI"
            ],
            "Statistics": [],
            "CloudComputing": [
                "AWS"
            ],
            "DevTools": [
                "Git"
            ],
            "Os": [
                "Linux"
            ],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [
                "Ansible"
            ],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [
                "Big Data",
                "Cloud"
            ],
            "FrSoftSkills": [
                "Organisation"
            ],
            "EnSoftSkils": []
        },
        "details": {
            "JobDetail": [
                "Confirm\u00e9"
            ],
            "TypeContract": [
                "CDI"
            ],
            "Salary": [],
            "Level": [
                "Bac+5"
            ],
            "Experience": [
                "a",
                "n",
                "s",
                "3",
                "3",
                "3"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "Lead Data Engineer",
        "company": "Ippon Technologies",
        "location": "Greater Paris Metropolitan Region",
        "link": "https://fr.linkedin.com/jobs/view/lead-data-engineer-at-ippon-technologies-3851535052?position=10&pageNum=32&refId=FUgWcwWTfkSy1LADz3eV7w%3D%3D&trackingId=yY%2FhyCA7DHFhXuAJwymR4g%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Cabinet de conseil et d'expertise en technologie, international et ind\u00e9pendant.\nEn quelques mots : 700 passionn\u00e9s de tech, 12 agences dans le monde, 6 communaut\u00e9s d\u2019expertise d\u2019excellence, contributeur actif et sponsor de l'\u00e9cosyst\u00e8me num\u00e9rique, des publications soutenues et reconnues sur nos r\u00e9seaux.\nRejoignez notre communaut\u00e9 de 70 experts en data, dont 30 \u00e0 Paris, o\u00f9 la collaboration dynamique entre data engineers, data analysts et data architects est le moteur de notre succ\u00e8s. Avec une communication proactive sur des canaux internes, restez constamment inform\u00e9 des derni\u00e8res tendances, participez \u00e0 des discussions stimulantes et contribuez \u00e0 l'organisation d'\u00e9v\u00e9nements passionnants (dataday, datap\u00e9ro, datalunch\u2026).\nFaites partie d'une \u00e9quipe o\u00f9 l'innovation et l'engagement sont les cl\u00e9s de notre excellence collective !\nNotre sp\u00e9cialit\u00e9 ? construire des data platforms dans le cloud public avec les meilleures technos du moment.\nEn tant que tech lead, tu interviendras sur la cr\u00e9ation d'un entrep\u00f4t de donn\u00e9es pour les KPIs d\u2019un grand groupe dans le secteur de l\u2019\u00e9nergie. Le but \u00e9tant de leur permettre de superviser leurs activit\u00e9s afin de supporter leurs d\u00e9cisions strat\u00e9giques.\nTon r\u00f4le :\nIntervenir sur l\u2019architecture et le d\u00e9veloppement d\u2019une pipeline d'alimentation de donn\u00e9es\nTravailler sur la mod\u00e9lisation et l\u2019impl\u00e9mentation de l'entrep\u00f4t de donn\u00e9es\nConseiller et accompagner les \u00e9quipes dans la r\u00e9alisation des dashboards de suivi des KPIs\nDevOps: projet enti\u00e8rement Terraform\u00e9 (ressources + droits), CI/CD Gitlab, administration GCP\nFaire une veille technologique active et partager tes connaissances en interne\nTravailler en collaboration avec les m\u00e9tiers et les data analysts pour leur fournir un support \u00e0 l\u2019industrialisation de leurs travaux (tests, int\u00e9gration continue, scalabilit\u00e9 des mod\u00e8les, craftsmanship etc\u2026)\nSi tu le souhaites, tu pourras \u00e9galement :\nParticiper aux \u00e9v\u00e8nements internes \u00e0 la communaut\u00e9 data (BBL, webinar, datap\u00e9ro interne, meetup, blog, dojos) et externes (Salon du Big Data, GCP Summit, Spark Summit, AWS Summit, Devoxx, workshop partenaire, meetups)\nCapitaliser sur les missions et les diff\u00e9rents \u00e9v\u00e8nements de la communaut\u00e9 au travers d\u2019articles de blogs, REX, BBL interne.\nTes connaissances :\nTu ma\u00eetrises le d\u00e9veloppement en Python\nTu as de l\u2019exp\u00e9rience dans la mise en place de pipeline de donn\u00e9es jusqu\u2019en production (CI/CD Gitlab, Terraform)\nTu as une exp\u00e9rience dans un environnement Cloud (GCP de pr\u00e9f\u00e9rence, AWS, Azure)\nTu as une bonne connaissance d\u2019un outil de visualisation (Looker Studio, Power BI)\nTu accompagnes des data engineers dans la mise en place des bonnes pratiques\nTu es capable de proposer/challenger la stack technique\nIppon c\u2019est aussi :\nTravailler en \u00e9quipe au sein d'une communaut\u00e9 data \u00e0 la pointe des \u00e9volutions\nUn suivi de proximit\u00e9 r\u00e9alis\u00e9 par ton manager (expert data)\nDevenir ceinture noire en data gr\u00e2ce \u00e0 notre programme d\u2019accompagnement de carri\u00e8re Blackbelt\nParticiper \u00e0 nos ap\u00e9ros et divers \u00e9v\u00e8nements internes pour consolider la coh\u00e9sion d\u2019\u00e9quipe\nNotre process de recrutement :\nPr\u00e9qualification t\u00e9l\u00e9phonique - 20 min\nUn entretien RH / Sales - 1H00\nUn entretien technique avec 2 consultants data\nSi le match est bon des deux c\u00f4t\u00e9s : Hadjim\u00e9 ! Tu te lanceras sur le tatami Ippon !\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "Scala",
                "R"
            ],
            "DataBase": [],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [
                "Spark"
            ],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [
                "Power BI"
            ],
            "Statistics": [],
            "CloudComputing": [
                "AWS",
                "Azure"
            ],
            "DevTools": [
                "Git"
            ],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [
                "Terraform"
            ],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [
                "DevOps",
                "Big Data",
                "Cloud",
                "CI/CD"
            ],
            "FrSoftSkills": [
                "Communication",
                "Collaboration",
                "Organisation"
            ],
            "EnSoftSkils": [
                "Communication",
                "Collaboration"
            ]
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "Data & Software Engineer Intern",
        "company": "Ledger",
        "location": "Paris, \u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/data-software-engineer-intern-at-ledger-3884430248?position=1&pageNum=35&refId=dZ1gMrOpD8AXyzg1FiBMxg%3D%3D&trackingId=vWJk2DfCNQCU7uPn3dV2bA%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "We're making the world of digital assets accessible and secure for everyone.\nJoin the mission.\nFounded in 2014, Ledger is the global platform for digital assets and Web3. Over 20% of the world\u2019s crypto assets are secured through our Ledger Nanos. Headquartered in Paris and Vierzon, with offices in UK, US, Switzerland and Singapore, Ledger has a team of more than 600 professionals developing a variety of products and services to enable individuals and companies to securely buy, store, swap, grow and manage crypto assets \u2013 including the Ledger hardware wallets line with more than 6 millions units already sold in 200 countries.\nAt Ledger, we embody the values that make us unique: Pragmatism, Audacity, Commitment, Trust and Transparency. Hear from our employees how they shape the work we do here.\nData at Ledger\nAs a data driven company, we ensure all major decisions are backed by data. To continue meeting that goal, we are looking for an intern to reinforce our data engineering team.\nYou will be responsible for optimizing our new data platform, building and maintaining reliable data pipelines. The ideal candidate is a software builder who will enjoy optimizing data systems and building them from the ground up in a fast paced environment and innovative space (blockchain is one of our key data sources!). You will also support data analysts and data scientists on data initiatives.\nThis internship will be a valuable opportunity to gain hands-on experience in all the aspects of a modern data stack: software engineering best practices, DevOps, SecOps concerns, Cloud infrastructure, legal compliance, etc.\nStart date: As soon as possible\nLength of internship: 6 months\nYour mission\nWork on data extractions from various sources (relational databases, API, flat files, etc.) and their transformations\nPerform code reviews to guarantee code quality\nMonitor data pipelines and investigate discrepancies\nContribute to migration of existing pipelines on AWS\nContribute to the improvement of the data engineering stack. We are an open-minded team and your opinion will be valued\nTeam tech stack\nELT: custom development (Python, SQL), Fivetran, Stitch, Adverity + dbt\nCloud: AWS\nDWH: Redshift, migration to Snowflake underway\nOrchestration: Airflow\nBI: Tableau, Mixpanel\nVersionning: Github\nIaC: Terraform\nWhat we're looking for\nFluent English\nSQL & Python are among your best friends\nYou know how to fix conflicts in Git\nPlus Points\nAirflow, dbt, Snowflake, Github Actions\nKnowledge about crypto\nExperience working with Cloud infrastructure (ideally AWS)\nWhat\u2019s in it for you?\nFlexibility: A hybrid work policy\nSocial: Frequent social events, snacks and drinks\nHigh tech: Access to high performance office equipment and gadgets, including Apple products\nTransport: Ledger reimburses 75% of your preferred means of transportation\nFood: We offer lunch vouchers with Swile\nVacation: 1 day off for every full month worked\nWe are an equal opportunity employer for all without any distinction of gender, ethnicity, religion, sexual orientation, social status, disability or age\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "R",
                "Go"
            ],
            "DataBase": [
                "SQL"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [
                "Tableau"
            ],
            "Statistics": [],
            "CloudComputing": [
                "AWS"
            ],
            "DevTools": [
                "Git"
            ],
            "Os": [],
            "DBMS": [
                "Snowflake",
                "Snowflake"
            ],
            "SoftBigDataProcessing": [],
            "Automation": [
                "Airflow"
            ],
            "InfrastructureAsCode": [
                "Terraform"
            ],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [
                "DevOps",
                "Cloud"
            ],
            "FrSoftSkills": [],
            "EnSoftSkils": [
                "Flexibility",
                "Initiative"
            ]
        },
        "details": {
            "JobDetail": [
                "Full"
            ],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "Data Engineer Talend (confirm\u00e9/s\u00e9nior) - H/F - CDI",
        "company": "Talan",
        "location": "Paris, \u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/data-engineer-talend-confirm%C3%A9-s%C3%A9nior-h-f-cdi-at-talan-3902901378?position=2&pageNum=35&refId=dZ1gMrOpD8AXyzg1FiBMxg%3D%3D&trackingId=py96T5xv7qfymnc5Nn1EyA%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Talan est un groupe international de conseil en transformation et en innovation par la technologie, cr\u00e9\u00e9 en 2002.\nNos 5000 consultantes et consultants partagent \u00e0 travers le monde l\u2019audace d\u2019innover, le go\u00fbt de l\u2019excellence, et l\u2019envie de relever les d\u00e9fis les plus complexes.\nNous accompagnons les entreprises dans des secteurs vari\u00e9s\u202f: \u00e9nergie, industrie, transport, finance, luxe\u2026 \u00e0 travers 3 grandes expertises\u202f:\nLe Conseil en Management et Innovation (320 Consultants en France)\nLa valorisation des donn\u00e9es, leurs structurations, et leurs usages (Data et Technologies)\nL\u2019int\u00e9gration de solutions logicielles (Cloud et Applications Services)\nNos valeurs\u202f: engagement, respect, partage, esprit d\u2019\u00e9quipe et optimisme.\nTalan est une entreprise responsable, reconnue par ses collaborateurs et attach\u00e9e \u00e0 la diversit\u00e9. Des am\u00e9nagements peuvent \u00eatre propos\u00e9s si vous \u00eates en situation de handicap.\nRetrouvez nos engagements RSEiciet nos actions en faveur de la diversit\u00e9ici\nJob Description\nVOTRE ROLE SUR NOS PROJETS :\nVous interviendrez sur des projets de:\nMise en place de Modern Data Platform\nInterconnexion d\u2019applications op\u00e9rationnelles en temps r\u00e9el\nAu sein d\u2019\u00e9quipes projet, votre r\u00f4le sera de:\nConcevoir et mettre en place des flux d\u2019int\u00e9gration de donn\u00e9es\nGarantir la qualit\u00e9 des d\u00e9veloppements\nR\u00e9diger des sp\u00e9cifications fonctionnelles et techniques\nMod\u00e9liser l\u2019entrep\u00f4t de donn\u00e9es\nMettre en place des solutions de suivi et pilotage des flux de donn\u00e9es\nProposer des solutions d\u2019optimisation\nMettre en place ou faire \u00e9voluer des cha\u00eenes CI/CD\nVOTRE ROLE CHEZ TALAN :\nAu sein du p\u00f4le Tech for Data, vous contribuerez \u00e0 la croissance et la prosp\u00e9rit\u00e9 de la communaut\u00e9 au travers des activit\u00e9s suivantes:\nBenchmark de solutions et conseil aupr\u00e8s de nos clients sur les solutions technologiques \u00e0 adopter, en lien avec leurs besoins\nR\u00e9alisation de POC (Proof Of Concept)\nPartage de connaissances et formations internes\nPassage de certifications\nVeille technologique\nParticipation \u00e0 la r\u00e9daction de r\u00e9ponse \u00e0 appel d\u2019offre\nQualifications\nVOTRE PROFIL:\nDipl\u00f4m\u00e9 d\u2019un Bac+5 en informatique/data, vous justifiez d\u2019une exp\u00e9rience d\u2019au moins 3 ans sur des probl\u00e9matiques d\u2019int\u00e9gration, traitement et mise en qualit\u00e9 de donn\u00e9es en ayant mis en \u0153uvre des flux de donn\u00e9es sur un Talend (la ma\u00eetrise d\u2019autres solutions de traitement de donn\u00e9es est un plus).\nVous ma\u00eetrisez les concepts de mod\u00e9lisation de donn\u00e9es et les architectures de type DataLake, DWH, Datamarts (la connaissance de la mod\u00e9lisation Datavault est un plus).\nVous savez \u00e9voluer dans un environnement avec un mod\u00e8le de donn\u00e9es complexe et \u00e9volutif.\nVous disposez d\u2019un tr\u00e8s bon relationnel et vous \u00eates reconnu pour votre capacit\u00e9 \u00e0 \u00e9voluer efficacement avec des interlocuteurs aussi bien techniques que non-techniques.\nForce de proposition, vous savez mobiliser autour de vos id\u00e9es et de vos projets.\nVous savez \u00e9voluer dans un contexte data ops et avez une connaissance des cha\u00eenes CI / CD (gitlab, Azure Devops, ...)\nLa ma\u00eetrise de la m\u00e9thodologie Agile est un plus.\nEnsemble r\u00e9alisons de nouveaux projets Talantueux!!\nVOTRE SOUHAIT D\u2019EVOLUTION:\nSi vous \u00eates passionn\u00e9 par l\u2019innovation, et souhaitez \u00e9largir vos comp\u00e9tences techniques dans la data, acc\u00e9der \u00e0 des fonctions de management de projet et d\u2019\u00e9quipe, participer au d\u00e9veloppement commercial et organisationnel, ou tout simplement pouvoir valoriser vos prises d\u2019initiatives et d\u00e9velopper de nouveaux terrains de jeux, alors rejoignez-nous!\nAdditional Information\nAVANTAGES\n:\nPlan de formation pour accompagner votre carri\u00e8re (formations \u00e9diteurs, certifications) gr\u00e2ce \u00e0 nos partenariats nous accordant une position de partenaire privil\u00e9gi\u00e9, et management de proximit\u00e9 par des experts\nLocaux modernes en centre-ville\nTop 5 du Palmar\u00e8s Great Place to Work\nT\u00e9l\u00e9travail jusqu\u2019\u00e0 5 jours selon les missions, prime d\u2019\u00e9quipement de 100\u20ac\nMobilit\u00e9 en France et \u00e0 l\u2019\u00e9tranger\nTop 1% des entreprises \u00e9valu\u00e9es par Ecovadis dans le domaine social, environnemental et \u00e9thique\nTickets restaurant, prime vacances, 50% transport (abonnement transport public), mutuelle\nPermanence handicap (consultant d\u00e9di\u00e9 aux collaborateurs en situation de handicap et aux proches aidants)\nActionnariat salari\u00e9\nPrime de cooptations\nRTT\nPROCESS RECRUTEMENT\n:\nL\u2019\u00e9quipe recrutement s\u2019engage \u00e0 vous proposer un processus de recrutement rapide et fluide\n1 entretien RHpar Teams (45min)\n1 entretien op\u00e9rationnel avec le responsable de domaine, au si\u00e8ge (1heure)\n1 entretien avec le directeur de p\u00f4le, au si\u00e8ge(1heure)\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "R",
                "Go"
            ],
            "DataBase": [],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [
                "Azure"
            ],
            "DevTools": [
                "Git"
            ],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [
                "Teams"
            ],
            "Other": [
                "DevOps",
                "Cloud",
                "CI/CD",
                "CI / CD"
            ],
            "FrSoftSkills": [
                "Organisation"
            ],
            "EnSoftSkils": [
                "Initiative"
            ]
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [],
            "Salary": [],
            "Level": [
                "Bac+5"
            ],
            "Experience": [
                "a",
                "n",
                "s",
                "3",
                "3",
                "3"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "Data engineer F/H",
        "company": "DOCAPOSTE",
        "location": "Lyon, Auvergne-Rh\u00f4ne-Alpes, France",
        "link": "https://fr.linkedin.com/jobs/view/data-engineer-f-h-at-docaposte-3879674310?position=3&pageNum=35&refId=dZ1gMrOpD8AXyzg1FiBMxg%3D%3D&trackingId=4DW5b8oYCvw49FhS2q2jkg%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Intitul\u00e9 du poste\nData engineer F/H\nContrat\nCDI\nT\u00e9l\u00e9travail\nOui\nDescription de la mission\nAu sein du p\u00f4le, vous avez la charge de manipuler les donn\u00e9es de la plus grosse base de donn\u00e9es m\u00e9dicale du monde, transmises par l'Assurance Maladie. Votre mission est de pr\u00e9parer et de mettre \u00e0 disposition les donn\u00e9es pour les diff\u00e9rents acteurs de l'entreprise. Vous industrialisez les flux de donn\u00e9es de centaines de milliers de patients, pour les suivre sur une dizaine d'ann\u00e9es et rep\u00e9rer certains \u00e9v\u00e9nements de leur prise en charge. Ainsi, les analyses pourront mettre en \u00e9vidence les diff\u00e9rents cycles des parcours de soin. Ce travail collaboratif se d\u00e9roule en mode projet pluridisciplinaire.\nAinsi vous devez :\n\u00c0 partir de bases de donn\u00e9es complexes et volumineuses, r\u00e9aliser les op\u00e9rations de contr\u00f4le d'int\u00e9grit\u00e9, d'extraction, de nettoyage, et programmer leurs automatisations pour constitution des bases de donn\u00e9es d'\u00e9tudes\nCoder des algorithmes sp\u00e9cifiques de s\u00e9lection de soins (hospitalisations, d\u00e9livrance de m\u00e9dicaments, consultations \u2026) et de s\u00e9quences de traitement en utilisant toutes les particularit\u00e9s des donn\u00e9es,\nR\u00e9aliser des jointures complexes entre les diff\u00e9rentes tables de donn\u00e9es,\nOptimiser les temps de traitement et de l'espace de stockage : millions de patients sur des T\u00e9ra de donn\u00e9es, en automatisant au maximum les op\u00e9rations de traitement,\nTravailler en mode collaboratif pour la r\u00e9daction de macros/fonctions g\u00e9n\u00e9riques pour que votre travail puisse servir \u00e0 toute l'\u00e9quipe,\nVotre nouvel environnement\nFiliale du groupe DOCAPOSTE SANTE, nous sommes leader en France dans le traitement et l\u2019analyse des donn\u00e9es de sant\u00e9 en vie r\u00e9elle, et plus particuli\u00e8rement celles issues des bases du Syst\u00e8me National des Donn\u00e9es de Sant\u00e9 (SNDS) et des bases en OPEN DATA. Nous \u00e9laborons et produisons pour nos clients (industries pharmaceutiques, fabricants de dispositifs m\u00e9dicaux, institutionnels) des \u00e9tudes pharmaco-\u00e9pid\u00e9miologiques, m\u00e9dico-\u00e9conomiques et de parcours de soins \u00e0 partir de solides m\u00e9thodes statistiques et de solutions innovantes s'appuyant sur l'Intelligence Artificielle (Machine Learning, Deep Learning, \u2026).\n2jours de T\u00e9l\u00e9travail\nNous vous accompagnons\nUn programme de formation et d'accompagnement est pr\u00e9vu en fonction de vos comp\u00e9tences pr\u00e9c\u00e9demment acquises et de votre exp\u00e9riences\nLocalisation du poste\nEurope, France, Auvergne-Rh\u00f4ne-Alpes, Rh\u00f4ne (69)\nLieu\nNiveau d'\u00e9tudes min. requis\nDipl\u00f4me\nNiveau d'exp\u00e9rience min. requis\nLangues\nProfil : Pour l\u2019\u00e9galit\u00e9 des chances, Docaposte fait vivre la diversit\u00e9. Nos postes sont ouverts \u00e0 tous.\nLYON\nCrit\u00e8res candidat\nProfil : Pour l\u2019\u00e9galit\u00e9 des chances, Docaposte fait vivre la diversit\u00e9. Nos postes sont ouverts \u00e0 tous.\nRigueur\nmanipulation de donn\u00e9es de sant\u00e9\nAnalytique\nDonn\u00e9es riches et complexes\nR\u00e9f\u00e9rence\n2023-4471D\nEntit\u00e9 qui recrute\nHEVA\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "R",
                "Go"
            ],
            "DataBase": [],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [
                "Statistiques"
            ],
            "CloudComputing": [],
            "DevTools": [],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [
                "Machine Learning",
                "Statistiques"
            ],
            "FrSoftSkills": [],
            "EnSoftSkils": []
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [
                "CDI"
            ],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "Data engineer - Dev - Alternance H/F",
        "company": "Assystem",
        "location": "Courbevoie, \u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/data-engineer-dev-alternance-h-f-at-assystem-3888473931?position=4&pageNum=35&refId=dZ1gMrOpD8AXyzg1FiBMxg%3D%3D&trackingId=aJ6OHI9E7yPzGHW%2BOkjCjQ%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Trouver des solutions au d\u00e9r\u00e8glement climatique est la priorit\u00e9 du 21\u00e8me si\u00e8cle, et implique de switcher \u00e0 l\u2019\u00e9nergie bas-carbone. Chez Assystem, on s\u2019est donc donn\u00e9 pour mission d\u2019acc\u00e9l\u00e9rer la transition \u00e9nerg\u00e9tique partout dans le monde. Et pour y parvenir, nos 7500 Switchers couplent leur expertise historique en ing\u00e9nierie et en management de projet aux technologies digitales.\nPr\u00e9sent dans 12 pays (Europe, Moyen-Orient, Asie), nous travaillons sur la production et la distribution d'\u00e9lectricit\u00e9 bas-carbone, \u00e0 travers le d\u00e9veloppement des \u00e9nergies nucl\u00e9aires et renouvelables. Nous participons \u00e9galement \u00e0 modernisation des r\u00e9seaux \u00e9lectriques et l'\u00e9lectrification des usages, \u00e0 travers l'hydrog\u00e8ne pour d\u00e9carboner les secteurs des transports et de l'industrie.\nDescription du poste\nVous serez int\u00e9gr\u00e9 sur notre plateau de data science \u00e0 la D\u00e9fense.\nEn tant qu'alternant(e) en gestion des donn\u00e9es, vous serez charg\u00e9(e) de :\nParticiper \u00e0 la conception, au d\u00e9veloppement et \u00e0 la maintenance des processus de gestion des donn\u00e9es.\nCollaborer avec l'\u00e9quipe pour r\u00e9soudre les probl\u00e8mes techniques et proposer des solutions.\nContribuer aux revues des projets, en comprenant les d\u00e9fis li\u00e9s aux donn\u00e9es et en proposant des solutions appropri\u00e9es.\nEffectuer des tests et des analyses pour assurer la qualit\u00e9 des applications.\nSuivre les bonnes pratiques de d\u00e9veloppement logiciel et contribuer \u00e0 l'am\u00e9lioration continue des processus.\nParticiper \u00e0 la mise en place des pratiques MLOPS \u00e0 travers l'int\u00e9gration et le d\u00e9ploiement continu.\nVotre r\u00f4le inclura \u00e9galement de proposer des solutions technologiques pour r\u00e9pondre aux contraintes de productivit\u00e9 et de s\u00e9curit\u00e9.\n\u00abPourquoi r\u00e9aliser votre alternance chez Assystem? On a 3 bonnes raisons pour vous convaincre!\n\ud83e\udd50 Travailler au sein d\u2019une \u00e9quipe engag\u00e9e qui ram\u00e8ne expertise et croissants le matin!\n\ud83d\ude0e D\u00e9couvrir pourquoi 92% de nos stagiaires/alternants appr\u00e9cient l\u2019ambiance et leur environnement de travail\n\ud83c\udfc6 Gagner en comp\u00e9tences et d\u00e9velopper votre expertise m\u00e9tier en \u00e9changeant au quotidien avec les collaborateurs Assystem, ainsi que le client en direct pour plus de proximit\u00e9 !\u00bb\nQualifications\nNous recherchons un candidat titulaire d'un dipl\u00f4me de\nniveau BAC+2\navec des comp\u00e9tences dans les domaines de SQL, NoSQL, UML, Python, React.js, Node.js et l'architecture des syst\u00e8mes d'information.\nLa ma\u00eetrise du fran\u00e7ais et de l'anglais est n\u00e9cessaire.\nNous valorisons \u00e9galement des qualit\u00e9s telles qu'un bon relationnel, un esprit de synth\u00e8se, une autonomie et un esprit innovant chez nos candidats.\nInformations suppl\u00e9mentaires\nNous nous engageons au respect de l\u2019\u00e9galit\u00e9 de traitement entre les candidats, et c\u00e9l\u00e9brons toutes les formes de diversit\u00e9. Chez Assystem, seules les comp\u00e9tences comptent!Si vous souhaitez porter \u00e0 la connaissance d\u2019Assystem une quelconque situation ou des besoins sp\u00e9cifiques, n\u2019h\u00e9sitez pas vous serez accompagn\u00e9(e)!\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "R"
            ],
            "DataBase": [
                "SQL",
                "NoSQL"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [],
            "DevTools": [
                "Git"
            ],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [
                "ML"
            ],
            "FrSoftSkills": [],
            "EnSoftSkils": []
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "Senior Data Engineer (Spark, Hive, Impala) - Paris - CDI",
        "company": "METEOJOB by CleverConnect",
        "location": "Paris, \u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/senior-data-engineer-spark-hive-impala-paris-cdi-at-meteojob-by-cleverconnect-3862148207?position=5&pageNum=35&refId=dZ1gMrOpD8AXyzg1FiBMxg%3D%3D&trackingId=%2FRXOfDy2If%2BTy%2BVQXX5s8w%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Entreprise\nChez LJE Solutions, nous pla\u00e7ons l\u2019humain au c\u0153ur de chaque projet. Au-del\u00e0 des comp\u00e9tences, nous valorisons les\naspirations\net les\nvaleurs\nde chaque individu.\nNous intervenons dans tous les secteurs d'activit\u00e9 en France et en Suisse.\nDescription Du Poste\nLJE Solutions recherche, pour un de ses clients, cabinet de conseil sp\u00e9cialis\u00e9 dans la technologie, un/une S\u00e9nior Data Engineer pour compl\u00e9ter son \u00e9quipe.\nNotre client est un cabinet de conseil mixte qui allie la technologie, la data & l'IA, le CRM & le digital.\nLe Poste\nEn tant que Senior Data Engineer, vous serez responsable du d\u00e9veloppement de nouveaux mod\u00e8les de donn\u00e9es et de pipelines. Vous aurez l'opportunit\u00e9 de tester les solutions les plus innovantes du march\u00e9 pour am\u00e9liorer nos capacit\u00e9s en mati\u00e8re de donn\u00e9es. Vous jouerez \u00e9galement un r\u00f4le crucial dans l'assistance aux clients, le cadrage des projets et le coaching des consultants juniors.\nVos Responsabilit\u00e9s\nD\u00e9veloppement de mod\u00e8les de donn\u00e9es et de pipelines,\nTest des solutions innovantes pour am\u00e9liorer les capacit\u00e9s en donn\u00e9es,\nAssistance aux clients dans le cadrage des projets,\nCoaching des consultants juniors,\nParticipation au d\u00e9veloppement de l'entreprise.\nR\u00e9mun\u00e9ration Et Avantages\nTickets restaurant,\nMutuelle d'entreprise,\nEnvironnement de travail dynamique et motivant,\nDiversit\u00e9 de projets stimulants,\nPerspectives d'\u00e9volution de carri\u00e8re,\nCDI avec r\u00e9mun\u00e9ration fixe attractive et part variable, \u00e0 partir de 50k\u20ac/an et d\u00e9finie en fonction du profil et de l'exp\u00e9rience,\nDeux jours de t\u00e9l\u00e9travail par semaine,\nParticipation active \u00e0 la vie de l'entreprise.\nDescription Du Profil\nProfil recherch\u00e9 :\nDipl\u00f4me d'une \u00e9cole d\u2019ing\u00e9nieur / g\u00e9nie informatique Bac+5,\nMinimum 4 ans d'exp\u00e9rience dans le domaine de la data,\nCapacit\u00e9 \u00e0 travailler en \u00e9quipe et \u00e0 superviser plusieurs actions,\nExcellentes comp\u00e9tences en communication, pr\u00e9sentation et coordination,\nCapacit\u00e9 d'analyse et de r\u00e9solution de probl\u00e8mes,\nAptitude \u00e0 assimiler rapidement de nouvelles technologies,\nMindset positif et volont\u00e9 de contribuer au d\u00e9veloppement de l'entreprise.\nComp\u00e9tences Techniques\nTechnologies Big Data (Spark, Hive, Impala...),\nServices Cloud (AWS / Azure / GCP),\nLangages de programmation : Python, Java, Scala,\nMise en production de cas d'usage Data, notamment en Machine Learning,\nBases de donn\u00e9es SQL,\nDevOps et d\u00e9veloppement de flux de donn\u00e9es (data pipelines) avec Docker/Kubernetes et cha\u00eenes CI/CD.\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "Java",
                "Scala",
                "R"
            ],
            "DataBase": [
                "SQL"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [
                "Spark"
            ],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [
                "AWS",
                "Azure"
            ],
            "DevTools": [
                "Git",
                "Docker"
            ],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [
                "Kubernetes"
            ],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [
                "Docker",
                "Kubernetes"
            ],
            "Collaboration": [],
            "Other": [
                "DevOps",
                "Big Data",
                "Machine Learning",
                "Cloud",
                "CI/CD"
            ],
            "FrSoftSkills": [
                "Communication",
                "R\u00e9solution de probl\u00e8mes"
            ],
            "EnSoftSkils": [
                "Communication"
            ]
        },
        "details": {
            "JobDetail": [
                "Junior",
                "Senior"
            ],
            "TypeContract": [
                "CDI"
            ],
            "Salary": [],
            "Level": [
                "Bac+5"
            ],
            "Experience": [
                "a",
                "n",
                "s",
                "4",
                "4",
                "4"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "Data Engineer (F/H) \u2013 en stage",
        "company": "Carrefour",
        "location": "Massy, \u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/data-engineer-f-h-%E2%80%93-en-stage-at-carrefour-3884393188?position=6&pageNum=35&refId=dZ1gMrOpD8AXyzg1FiBMxg%3D%3D&trackingId=oRZJtJ4lw6LlmZ%2BTwf0kow%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Nous rejoindre, c\u2019est rejoindre l\u2019un des leaders mondiaux de la distribution qui met l'accent au quotidien sur la diversit\u00e9, la RSE et le digital, pour satisfaire nos clients et nos collaborateurs. En tant que partenaire premium des Jeux Olympiques et Paralympiques de Paris 2024, nous partageons les valeurs du sport en permettant \u00e0 nos \u00e9quipes de se d\u00e9passer et encourageons une alimentation saine au juste prix pour tous.\nVous cherchez \u00e0 travailler dans une entreprise dynamique o\u00f9 votre travail rime avec impact social et environnemental ? Bienvenue chez nous !\nPorteuse de cette ambition, la Direction D&A Technology recrute un(e)\nData Engineer (F/H) \u2013 en stage\nAu sein de Carrefour, la Direction D&A Technology a pour mission la construction d\u2019un socle de donn\u00e9es mutualis\u00e9es d\u2019Entreprise.Les \u00e9quipes de la Direction travaillent conjointement \u00e0 une plateforme unique pour collecter, structurer, stocker et diffuser les donn\u00e9es du Syst\u00e8me d\u2019Informations Carrefour. Un socle Data Centric est mis en \u0153uvre pour permettre des usages op\u00e9rationnels, d\u00e9cisionnels et analytiques. Vous aurez un r\u00f4le de Data Engineer sur un scope fonctionnel, ce qui se traduira par le d\u00e9veloppement de traitements d\u2019ingestion, stockage et exposition de donn\u00e9es, que ce soit avec un framework Temps R\u00e9el ou avec un framework de type ETL\n\ud83c\udfaf Les missions\nDans ce cadre, vous serez amen\u00e9 \u00e0\nComprendre les volets technique et fonctionnel du Produit Data en charge\nAppliquer les bonnes pratiques et les normes de d\u00e9veloppement\nContribuer \u00e0 l\u2019automatisation du delivery\nD\u00e9livrer les cas d\u2019usages attendus sur le Produit Data\nProposer des axes d\u2019am\u00e9lioration sur la Plateforme\n\ud83d\udc65 Profil\nVous \u00eates \u00e9tudiant dans une \u00e9cole d\u2019ing\u00e9nieurs informatique cherchant un stage de fin d\u2019\u00e9tudes et souhaitant \u00e9voluer dans un environnement BigData avec de forts enjeux pour l\u2019entreprise.\nVous avez un int\u00e9r\u00eat pour l\u2019architecture de syst\u00e8mes distribu\u00e9s Big Data et des capacit\u00e9s d\u2019analyse\nVous avez une bonne connaissance des m\u00e9thodes de gestion de projets en mode agile (SCRUM)\nVous avez une bonne capacit\u00e9 \u00e0 travailler en \u00e9quipe, tout en \u00e9tant tr\u00e8s autonome\nVous avez des comp\u00e9tences techniques sur ces domaines\n\u25cb Scala/Java (Connaissance d\u2019un des deux langages)\n\u25cb Ecosyst\u00e8me Big Data (Spark, Apache Kafka, Avro ...)\n\u25cb Outils de d\u00e9ploiement et orchestration (Kubernetes, Docker, Ansible \u2026)\n\u25cb Google Cloud Plateform (GCS, BigQuery, GKE, Cloud Pub/Sub, Dataproc, \u2026)\n\u25cb Bases de donn\u00e9es NoSQL (Cassandra, BigTable\u2026) & Moteur de recherche (Elastic Search...)\n\u25cb CI/CD (Git, Jenkins, Nexus, Docker Registry, \u2026)\nVous \u00eates une personne passionn\u00e9e, curieuse, autonome, et int\u00e9ress\u00e9e par le Software Craftsmanship.\nEncore plus de bonnes raisons de nous rejoindre\nInt\u00e9grer une \u00e9quipe conviviale \u00e0 taille humaine au sein d\u2018un grand groupe\nPour le site de Massy  Un campus attractif avec plusieurs restaurants d\u2019entreprises, salle de sport avec cours, offres Comit\u00e9 d\u2019entreprise.\n12 % de remise sur achat\n\ud83d\udcdd Informations compl\u00e9mentaires\nDate de d\u00e9but  02 janvier 2024\nDur\u00e9e  6 mois\nLieu  Massy (91) \u2013 RER B/RER C Massy-Palaiseau\nChez Carrefour, nous avons \u00e0 c\u0153ur de ne passer \u00e0 c\u00f4t\u00e9 d\u2019aucun talent et sommes fiers de compter des \u00e9quipes repr\u00e9sentatives de la soci\u00e9t\u00e9 dans son ensemble. Nous encourageons ainsi tous types de profils \u00e0 postuler \u00e0 cette offre et garantissons un processus de recrutement d\u00e9nu\u00e9 de toutes formes de discriminations.\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Java",
                "Scala",
                "R",
                "Go"
            ],
            "DataBase": [
                "SQL",
                "NoSQL",
                "Cassandra"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [
                "Spark"
            ],
            "MachingLearning": [],
            "DataSerialization": [
                "Avro"
            ],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [],
            "DevTools": [
                "Git",
                "Docker",
                "Jenkins"
            ],
            "Os": [],
            "DBMS": [
                "BigQuery"
            ],
            "SoftBigDataProcessing": [
                "Apache Kafka"
            ],
            "Automation": [
                "Ansible",
                "Kubernetes"
            ],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [
                "Docker",
                "Kubernetes"
            ],
            "Collaboration": [],
            "Other": [
                "Big Data",
                "Cloud",
                "CI/CD"
            ],
            "FrSoftSkills": [],
            "EnSoftSkils": []
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "Intermediate/Senior Data Engineer - Scientific Engine - CDI",
        "company": "Descartes Underwriting",
        "location": "Paris, \u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/intermediate-senior-data-engineer-scientific-engine-cdi-at-descartes-underwriting-3863474083?position=7&pageNum=35&refId=dZ1gMrOpD8AXyzg1FiBMxg%3D%3D&trackingId=KFHl0gad8reCli%2FEGp2aVQ%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "ABOUT DESCARTES UNDERWRITING\nDescartes was born out of the conviction that the ever-increasing complexity of risks faced by corporations, governments and vulnerable communities calls for a renewed approach in insurance. Our team brings together industry veterans from the most renowned institutions (AXA, SCOR, Swiss Re, Marsh, Aon, ...) and scientists on top of their field to bring underwriting excellence. After 5 years of existence, Descartes has secured a leading position in parametric insurance for weather and climate-related risks utilizing machine learning, real-time monitoring from satellite imagery & IoT. After a successful Series B raise of $120M USD, we launched Descartes Insurance, a 'full stack' insurer licensed to underwrite risk by the French regulator ACPR. With a growing corporate client base (350+ and counting), our diverse team is headquartered in Paris and operates out of our 13 global offices in North America, Europe, Australia, Singapore, Hong Kong and Japan. Descartes is trusted by a panel of A-rated (re)insurers to carry out its activities.\nABOUT YOUR ROLE\nDue to our consistent growth, we are expanding our Data, Software and DevOps team. We are seeking profiles dedicated to data engineering. At the core of the development of our scientific engine modeling climate phenomena, your main missions will be to create, improve and maintain the data pipelines used to train our model and infer the different scenarios to make a climate risk assessment. You will have to take initiative and assess the viability of proof-of-concept projects.\nYou will have to work with data scientists and software engineers to run and develop our models. You will be working alongside DevOps engineers to reliably put models in production and selected the compute/store instance needed to perform these tasks. Your secondary mission will be to automate the flow of information between the tech and business to monitor climate events.\n\ud83d\udd14\nKEY MISSIONS \ud83d\udd14\nDesign, setup, and maintain:\nData pipelines and associated datalakes;\nConnections to external and internal APIs;\nAssociated CI/CD and release pipelines;\nNotification tools to inform the team of the status of the operations.\nPropose and setup data storage, data processing and data visualizing tools including:\nAssessing the pains and needs of the teams;\nBenchmarking different solutions;\nAssessing the security, price and reliability of data architecture;\nFollowing the development the evolution of technologies on the topic;\nForecasting and tracking cloud spend.\nParticipate in:\nTech stack evolution;\nDiscussions with tech partners;\nTraining of other tech teams;\nSupport and debug of internal users.\nTECH STACK \ud83d\udda5\ufe0f\nCloud provider: GCP\nCode versioning tool: Git + Gitlab\nOS: Linux\nContainer: Docker\nContainer orchestrator: Kubernetes\nCode base: Python\nNotification tool: Slack\nDATA STACK\nTypes: images, time series, data frames, etc.\nPipeline orchestrator: Apache Airflow\nData stores: Cloud SQL, FireStore, BigQuery\nIn our project, data is collected by sensors (satellite, weather station, IoT). We don\u2019t work with personal or sensitive data, in most cases the data is publicly available (earthquake magnitude, cyclone track, precipitation \u2026).\nABOUT YOU\nEXPERIENCE & QUALIFICATIONS \ud83d\udcbb\ud83d\udda5\ufe0f\n[Hard skills]\nKnowledge of the tech stack and demonstrated proficiency in production environments;\nMinimum 3 years\u2019 experience in Python object-oriented programming;\nExperience converting Python code to efficient data engineering tools;\nProduction experience with Docker;\nProduction experience with a cloud provider (GCP, AWS or Azure);\nCI/CD and release pipelines;\nGood knowledge in English and fluency in French.\n[Soft skills]\nExcellent communication skills, in both formal and informal settings, and in English and French;\nContribute to a rigorous data engineering culture;\nPropagate Data Engineer best practices to other tech teams;\nWell versed in Agile;\nMentoring junior engineers.\n[Nice-to-have]\nPrior experience working in data science or scientific computing projects;\nWorking knowledge of DevOps;\nContribution to an open source project.\nMINDSET \ud83d\udca5\nStrong interest with climate issue (it\u2019s not a hoax, many people suffer from it);\nBeing comfortable to work alongside corporate insurers (some still wear suits \ud83d\udc54);\nYou enjoy CI/CD automation (or at least appreciate the elegance of a well-crafted pipeline);\nStrong team spirit and ability to work (you\u2019ll have to review code and have your code reviewed);\nRigorous, creative and meticulous mind (we handle large insurance, we take our time);\nStrong desire to learn (there\u2019s no limitation to the tech used, we\u2019re happy to test and learn new tools);\nEagerness to work in a multi-cultural environment (policies and teams are from all around the world \ud83d\uddfa\ufe0f).\nWHY JOIN DESCARTES UNDERWRITING?\nOpportunity to work and learn with teams from the most prestigious schools and research labs in the world, allowing you to progress towards technical excellence;\nCommitment from Descartes to its staff of continued learning and development (think annual seminars, training etc.) ;\nWork in a collaborative & professional environment ;\nBe part of an international team, passionate about diversity ;\nJoin a company with a true purpose \u2013 help us help our clients be more resilient towards climate risks;\nA competitive salary, bonus and benefits;\nYou can benefit from a punctual home office days.\nIf you want to develop your skills and work in a friendly startup atmosphere, don\u2019t hesitate and send us your application!\nAt Descartes Underwriting, we cherish value of diversity whatever it may be. We are committed to fighting against all forms of discrimination and for equal opportunities. We foster an inclusive work environment that respects all differences.\nWith equal skills, all our positions are open to people with disabilities.\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "R",
                "Go"
            ],
            "DataBase": [
                "SQL"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [
                "Apache Airflow"
            ],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [
                "AWS",
                "Azure"
            ],
            "DevTools": [
                "Git",
                "Docker"
            ],
            "Os": [
                "Linux"
            ],
            "DBMS": [
                "BigQuery"
            ],
            "SoftBigDataProcessing": [],
            "Automation": [
                "Kubernetes",
                "Airflow"
            ],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [
                "Docker",
                "Kubernetes"
            ],
            "Collaboration": [
                "Slack",
                "Teams"
            ],
            "Other": [
                "DevOps",
                "Machine Learning",
                "Cloud",
                "CI/CD"
            ],
            "FrSoftSkills": [
                "Communication"
            ],
            "EnSoftSkils": [
                "Communication",
                "Initiative"
            ]
        },
        "details": {
            "JobDetail": [
                "Full",
                "Junior"
            ],
            "TypeContract": [],
            "Salary": [
                "Salary"
            ],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "Data Engineer H/F",
        "company": "Davidson consulting",
        "location": "Lyon, Auvergne-Rh\u00f4ne-Alpes, France",
        "link": "https://fr.linkedin.com/jobs/view/data-engineer-h-f-at-davidson-consulting-3913991399?position=8&pageNum=35&refId=dZ1gMrOpD8AXyzg1FiBMxg%3D%3D&trackingId=r1M1AAERTfnl0evdu2IjpQ%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Rejoindre Davidson, ce n'est pas seulement int\u00e9grer un groupe de 3000 consultants dans 8 pays et 3 continents, c'est int\u00e9grer LA soci\u00e9t\u00e9 qui a \u00e9t\u00e9 \u00e9lue par ses salari\u00e9s Great Place To Work France et Europe pendant 4 ans ainsi que la plus grande B Corp (Benefit Corporation) de France !\nLes \u00ab B Corp \u00bb formant une communaut\u00e9 de soci\u00e9t\u00e9s qui ont d\u00e9cid\u00e9 d'\u00eatre non pas les meilleures du monde mais les meilleures POUR le monde.\nParce que notre d\u00e9veloppement repose sur des principes forts :\nUn profond respect de l'ensemble de nos parties prenantes : consultants, clients et fournisseurs. Car si le travail ne fait pas le bonheur, il peut cependant faire le malheur. Nous nous engageons donc \u00e0 \u00e9couter, agir avec honn\u00eatet\u00e9 et promouvoir l'\u00e9quit\u00e9.\nUne empreinte environnementale minimale, et soci\u00e9tale maximale. C'est pourquoi, au-del\u00e0 des missions que vous r\u00e9aliserez, vous pourrez \u00e9galement contribuer \u00e0 des projets que Davidson soutient : missions de solidarit\u00e9 internationale (avec Plan\u00e8te Urgence), accompagnement d'\u00e9tudiant(e)s issus de milieux peu favoris\u00e9s (avec Article 1), investissement dans des startups d\u00e9veloppant des solutions innovantes !.\nUn Management adhocratique bas\u00e9 sur la mise en oeuvre des principes de l'entreprise horizontale et du management tribal.\nSur ce dernier point une pr\u00e9cision d'importance : le bien-\u00eatre au travail est un luxe qu'il faut pouvoir s'offrir en \u00e9tant une entreprise solide. Ceci induit pour les davidsonien(ne)s d'allier prises d'initiative, engagement et professionnalisme. Car sans travail, le talent n'est qu'une sale manie. Et nous incite \u00e0 chercher \u00e0 recruter des \u00e9l\u00e9ments meilleurs que nous. Dans une organisation classico-hi\u00e9rarchique, il peut \u00eatre b\u00e9n\u00e9fique d'avoir une arm\u00e9e de gens qui travaillent pour vous. Dans une adhocratie, ils causent des d\u00e9g\u00e2ts.\nPour Le Compte D'un De Nos Clients Grand Compte, Et Sous La Responsabilit\u00e9 Du Manager Davidson, Vous Apporterez Votre Expertise En Tant Que Data Engineer. Vos Missions Seront Entre Autres\nAssurer la collecte, le stockage et l'exploitation des donn\u00e9es.\nD\u00e9velopper des applications distribu\u00e9es \u00e0 grande \u00e9chelle.\nConstruire des mod\u00e8les de stockage performants.\nDe formation Bac +5, vous \u00eates dipl\u00f4m\u00e9 d'une Ecole d'Ing\u00e9nieurs ou de l'Universit\u00e9, avec une sp\u00e9cialisation en informatique et d\u00e9veloppement.\nVous avez une bonne ma\u00eetrise des diff\u00e9rentes technologies/outils suivants :\nSpark / Hadoop.\nScala, Java.\nSQL (MariaDB), HBase, Hive, Impala.\nVertica, Elastic Search, HDFS (Parquet, ORC).\nKafka.\nAirflow.\nVous avez un tr\u00e8s bon niveau d'anglais et id\u00e9alement une exp\u00e9rience de travail en m\u00e9thodes agiles.\nVos capacit\u00e9s d'analyse et votre rigueur vous permettent de mener \u00e0 bien les attendus techniques de vos projets dans le respect des d\u00e9lais impartis.\nVotre ouverture d'esprit et votre disponibilit\u00e9 vous permettront de r\u00e9ussir et d'appr\u00e9cier le m\u00e9tier de consultant au sein d'une entreprise en forte croissance.\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Java",
                "Scala",
                "R"
            ],
            "DataBase": [
                "SQL",
                "HBase"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [
                "Hadoop",
                "Spark"
            ],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [],
            "DevTools": [],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [
                "HBase"
            ],
            "Automation": [
                "Airflow"
            ],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [],
            "FrSoftSkills": [
                "Organisation"
            ],
            "EnSoftSkils": [
                "Initiative"
            ]
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s",
                "4",
                "4",
                "4"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "Consultant Microsoft Data & BI (H/F)",
        "company": "EXAKIS NELITE",
        "location": "Clermont-Ferrand, Auvergne-Rh\u00f4ne-Alpes, France",
        "link": "https://fr.linkedin.com/jobs/view/consultant-microsoft-data-bi-h-f-at-exakis-nelite-3905645675?position=9&pageNum=35&refId=dZ1gMrOpD8AXyzg1FiBMxg%3D%3D&trackingId=IJwuqp4QuWYYzre07ojdbQ%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Exakis Nelite, entit\u00e9 du groupe\nMagellan Partners\n, est le\n1er partenaire pure-player Microsoft\nind\u00e9pendant en France avec l\u2019ambition de devenir le premier partenaire Europ\u00e9en et en Afrique Francophone avec sa forte pr\u00e9sence au Maroc.\nN\u00e9s du rapprochement de 2 leaders sp\u00e9cialistes de l\u2019int\u00e9gration des solutions Microsoft, nous allions expertise technique et fonctionnelle pour r\u00e9pondre concr\u00e8tement aux enjeux de demain : acc\u00e9l\u00e9ration de la transformation digitale,\nCyberS\u00e9curit\u00e9, Intelligence Artificielle, IoT, Data, transformation vers le cloud Azure, Services Cognitifs \u2026\nEn rejoignant la communaut\u00e9 Exakis Nelite dans l\u2019une de nos 12 agences (680 collaborateurs), vous int\u00e9grerez une \u00e9quipe passionn\u00e9e et impliqu\u00e9e dans les projets les plus innovants. Vous rejoindrez une structure construite autour de valeurs tourn\u00e9es vers ses collaborateurs : intelligence collective, convivialit\u00e9 et bienveillance.\nExakis Nelite a re\u00e7u la certification\nGreat Place to Work\net se place\n3\u00e8me de sa cat\u00e9gorie\nen 2024 parmi les entreprises o\u00f9 il fait bon travailler en France !\nPoste et missions:\nEn tant que Consultant(e) Microsoft Data / BI, vous intervenez dans le cadre de projet d\u2019informatiques d\u00e9cisionnelles, en forfait ou en r\u00e9gie aupr\u00e8s de nos clients. Les missions sont les suivantes :\n\u2022 Accompagner le client dans une d\u00e9marche de mise en \u0153uvre d'un syst\u00e8me d\u00e9cisionnel classique ou d'un outil de Modern BI\n\u2022 Analyser et qualifier le besoin\n\u2022 R\u00e9diger des sp\u00e9cifications fonctionnelles, techniques\n\u2022 Concevoir et d\u00e9velopper les solutions BI\n\u2022 Mod\u00e9liser et enrichir des bases de donn\u00e9es\n\u2022 Mettre en place des outils de restitution BI pour la production de tableaux de bord et de reporting\n\u2022 Mod\u00e9liser et impl\u00e9menter des Datamarts et Datawarehouses\n\u2022 Pr\u00e9parer et animer des formations et des s\u00e9ances de coaching BI en entreprise\n\u2022 Mod\u00e9liser des algorithmes de calculs statistiques permettant de faire diverses analyses (pr\u00e9diction,clustering,\u2026)\nProfil:\nDe formation BAC+5 id\u00e9alement en ing\u00e9nierie, vous justifiez d\u2019un minimum de 2 ans d\u2019exp\u00e9rience sur des technologies de Business Intelligence et/ou d\u2019outils statistiques.\nVous avez une r\u00e9elle expertise sur un ou plusieurs environnements et langages suivants :\nSQL server (2012 et suivants) et d\u00e9veloppement de requ\u00eates SQL complexes\nMa\u00eetrise de la suite Microsoft BI (SSIS, SSAS, SSRS)\nMa\u00eetrise de l'outil de Modern BI (Power BI)\nPr\u00e9paration de la donn\u00e9e\nMod\u00e9lisation de la donn\u00e9e (conception d'un mod\u00e8le de donn\u00e9e optimal)\nCr\u00e9ation de rapports interactifs et tableaux de bords\nConnaissance des probl\u00e9matiques de connexion aux donn\u00e9es (une exp\u00e9rience en d\u00e9veloppement de Custom Connectors est un plus)\nMise en \u0153uvre de serveur Power BI Report Server\nVous \u00eates \u00e0 l\u2019aise avec les syntaxes DAX ou MDX\nBonne connaissance des services Data de Microsoft Azure (SQL Database, SQL Datawarehouse, Cosmos DB, Azure Data Lake Store, Azure Data Lake Analytics, Azure Data Factory, Azure Databricks, Azure HDInsight)\nBonne connaissance des services IA de Microsoft Azure (Azure Machine Learning, Azure Cognitive Services)\nBonne connaissance d\u2019un langage de programmation (R,Python)\nMaitrise de l'anglais.\nDes exp\u00e9riences dans les domaines du Big data et du machine learning sera un r\u00e9el avantage (profils Data Scientists ou Data Citizens appr\u00e9ci\u00e9s). Maitrise de l\u2019anglais indispensable.\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "R",
                "Go"
            ],
            "DataBase": [
                "SQL"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [
                "Databricks"
            ],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [
                "Tableau",
                "Power BI"
            ],
            "Statistics": [
                "Statistiques"
            ],
            "CloudComputing": [
                "Azure"
            ],
            "DevTools": [
                "Git"
            ],
            "Os": [],
            "DBMS": [
                "SQL Server"
            ],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [
                "Big Data",
                "Machine Learning",
                "Statistiques",
                "Cloud"
            ],
            "FrSoftSkills": [],
            "EnSoftSkils": []
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [],
            "Salary": [],
            "Level": [
                "Bac+5"
            ],
            "Experience": [
                "a",
                "n",
                "s",
                "2",
                "2",
                "2"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "Data Engineer en Alternance",
        "company": "Archery Data & Analytics",
        "location": "Tours, Centre-Val de Loire, France",
        "link": "https://fr.linkedin.com/jobs/view/data-engineer-en-alternance-at-archery-data-analytics-3907527785?position=10&pageNum=35&refId=dZ1gMrOpD8AXyzg1FiBMxg%3D%3D&trackingId=fuMbh5r3Mmp72P1Au75CNg%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Description de l'entreprise\nArchery Data & Analytics est un cabinet d\u2019expertise Data, filiale d\u2019Archery Strategy Consulting, cabinet de conseil en direction g\u00e9n\u00e9rale sp\u00e9cialis\u00e9 dans 3 secteurs\u202f: a\u00e9ronautique/spatial/d\u00e9fense, transports/logistique et \u00e9nergie.\nNous intervenons chez nos clients sur des probl\u00e9matiques :\nDe strat\u00e9gie et de transformation data/digitale (gouvernance des donn\u00e9es, roadmap data, digitalisation\u2026)\nDe ma\u00eetrise d\u2019\u0153uvre et gestion de projets Data \u00e0 forts enjeux (utilisation des m\u00e9thodes Agiles, Scrum, DevOps\u2026)\nDe r\u00e9alisation de projets Data & Analytics (Business Intelligence, MDM, BIG DATA, Data Sciences, Low Coding\u2026)\nEnfin, nous d\u00e9veloppons et commercialisons des solutions m\u00e9tiers \u00e0 haute valeur ajout\u00e9e (ing\u00e9nierie, gestion de projets, outils grands programmes, suivi de production, maintenance\u2026).\nLe cabinet a \u00e9t\u00e9 constitu\u00e9 en 2021 et est aujourd\u2019hui repr\u00e9sent\u00e9 par 13 consultants Data & Analytics r\u00e9partis sur nos sites de Tours, Paris et Toulouse.\nDescription de la mission\nArchery Data & Analytics \u00e0 la recherche d\u2019un.e alternant.e en Data Engineering en Master 1 (4\u00e8me ann\u00e9e) afin de compl\u00e9ter notre \u00e9quipe.\nAu sein du cabinet, vous \u00e9voluerez dans l\u2019environnement de travail suivant :\nFonctionnel : Industrie, supply-chain, logistique, fonctions transverses (qualit\u00e9, finance, informatique\u2026)\nPlateformes Cloud : Microsoft AZURE\nPlateformes Data Onpremise : Hadoop/Spark\nOutils de Reporting : Microsoft Power BI ou QlikView ou Tableau.\nPlateformes d\u2019int\u00e9gration : SQL Integration Services, Informatica, Azure Data Factory\nLangages de programmation : SQL, DAX, Python, .NET\nOutils de Data Science : Data Bricks\nDes connaissances dans cet environnement sont un v\u00e9ritable plus, aucune maitrise n\u2019est demand\u00e9e.\nVos Missions au quotidien :\nApporter conseils et expertises \u00e0 nos clients lors des missions Data.\nConcevoir, d\u00e9velopper et mettre en place des solutions Data & Analytics de bout en bout :\nParticiper \u00e0 la captation et l\u2019analyse des besoins de nos clients avec l\u2019aide de nos consultants Data.\nConcevoir les solutions \u00e0 mettre en \u0153uvre de fa\u00e7on \u00e0 r\u00e9pondre aux exigences et attentes des utilisateurs.\nContribuer \u00e0 la conception, puis \u00e0 la mise en place des infrastructures que ce soit en IaaS, SaaS ou PaaS\u2026\nConcevoir et mettre en place des flux de donn\u00e9es automatis\u00e9s, des mod\u00e8les de donn\u00e9es\u2026\nConcevoir et d\u00e9velopper des reporting d\u2019aide \u00e0 la d\u00e9cision (calculs complexes et algorithmes inclus).\nDocumenter les solutions d\u00e9velopp\u00e9es et en assurer le maintien en conditions op\u00e9rationnelles (MCO).\nAssurer le suivi du projet et la relation avec le client final.\n3. Participer aux projets de d\u00e9veloppements de produits internes du cabinet Archery.\n4. Assurer la veille technologique et contribuer \u00e0 \u00e9tendre nos expertises.\nProfil recherch\u00e9\nNiveau du dipl\u00f4me vis\u00e9 : Bac+5 avec des bases en syst\u00e8mes d\u2019informations\nAutonomie, rigueur, esprit d\u2019\u00e9quipe et force de proposition\nTr\u00e8s bon relationnel, bonnes capacit\u00e9s d\u2019analyse, de synth\u00e8se et de r\u00e9daction.\nLocalisation du poste : Tours (37)\nPrise de fonctions : Septembre 2024\nTypes de contrats : Contrat d\u2019apprentissage ou contrat de professionnalisation selon profil sur 24 mois\nProcessus de recrutement\nUn premier entretien avec Meghann, notre charg\u00e9e RH et Paul, notre manager du p\u00f4le Date engineering\nUn deuxi\u00e8me entretien avec Julien, notre Pr\u00e9sident\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "R",
                "Go"
            ],
            "DataBase": [
                "SQL"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [
                "Hadoop",
                "Spark"
            ],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [
                "Tableau",
                "Power BI"
            ],
            "Statistics": [],
            "CloudComputing": [
                "Azure"
            ],
            "DevTools": [
                "Git"
            ],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [
                "DevOps",
                "Big Data",
                "Cloud"
            ],
            "FrSoftSkills": [],
            "EnSoftSkils": []
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [],
            "Salary": [],
            "Level": [
                "Bac+5"
            ],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "D\u00e9veloppeur Big Data - Spark",
        "company": "NEXTON",
        "location": "Lyon, Auvergne-Rh\u00f4ne-Alpes, France",
        "link": "https://fr.linkedin.com/jobs/view/d%C3%A9veloppeur-big-data-spark-at-nexton-3911787310?position=1&pageNum=37&refId=3scIT4h7LcxHkowem3t5kA%3D%3D&trackingId=lNIo4gI17gKIgLn8o6MPpw%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Mission (fiche m\u00e9tier)\nNEXTON recrute un\nD\u00e9veloppeur Big Data - Spark\n, en CDI, \u00e0\nLyon\n!\nQui sommes-nous ?\nNEXTON c\u2019est avant tout une entreprise qui accompagne ses clients dans leur transformation digitale. Tous les jours, nous travaillons avec des grands comptes et des pures players (SNCF, Orange, BNP PARIBAS\u2026).\nNous sommes experts du digital aussi bien sur de l\u2019accompagnement strat\u00e9gique qu\u2019op\u00e9rationnel.\nFort du succ\u00e8s, Nexton conna\u00eet aujourd\u2019hui un d\u00e9veloppement significatif, autour de ses valeurs piliers : coh\u00e9sion, confiance et performance.\nEt pour toi ? Notre politique de d\u00e9veloppement des comp\u00e9tences dynamique saura te s\u00e9duire avec un programme de suivi de carri\u00e8re sur-mesure.\nLe contexte :\nPour l'un de nos clients, dans le secteur de l'\u00e9nergie, nous sommes \u00e0 la recherche d'un d\u00e9veloppeur Big Data.\nLes missions :\nApporter une expertise\nBig Data\npour faciliter la manipulation des donn\u00e9es.\nD\u00e9finir les solutions techniques permettant le traitement massif des donn\u00e9es.\nMettre en place des\nsolutions de stockage de donn\u00e9es\n(SQL, NoSQL etc.)\nVeiller la s\u00e9curisation et la clart\u00e9 des pipelines de donn\u00e9es pour faciliter\nl'analyse\net la\ntransformation\n.\nAssurer la cr\u00e9ation, la maintenance, l'optimisation et la s\u00e9curit\u00e9 des bases de donn\u00e9es.\nAssurer le support aux \u00e9quipes de\nd\u00e9veloppement\nafin d'identifier et proposer des solutions performantes.\nProfil (fiche m\u00e9tier)\nDe formation sup\u00e9rieure, tu justifies d'une exp\u00e9rience d'au moins\n4 ans\ndans le domaine.\nTu maitrises\nSpark\n,\nPython\net\nSQL\n.\nTu es\nautonome\n,\nrigoureux\net\nforce de proposition\n.\nDe plus, tu as acquis une\ncapacit\u00e9 d'analyse\net de\nsynth\u00e8se\ngr\u00e2ce \u00e0 tes diff\u00e9rentes exp\u00e9rience.\nTu maitrises \u00e9galement les fondamentaux de\nl'agilit\u00e9\n.\nEnfin, ton\nesprit d'\u00e9quipe\nte permet de communiquer et de travailler dans les meilleures conditions.\nNEXTON c\u2019est aussi et surtout de nombreux moments de rencontres tout au long de l\u2019ann\u00e9e :\n- Des communaut\u00e9s : 2 Meet Up par mois pour partager et \u00e9changer avec des experts\n- De nombreux moments de rencontres professionnels et extra professionnels tout au long de l\u2019ann\u00e9e\n- Des moments privil\u00e9gi\u00e9s avec ton manager\nPr\u00eats \u00e0 nous rejoindre ? Rencontrons-nous !\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "R",
                "Go"
            ],
            "DataBase": [
                "SQL",
                "NoSQL"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [
                "Spark"
            ],
            "MachingLearning": [
                "Orange"
            ],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [],
            "DevTools": [
                "Git"
            ],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [
                "Big Data"
            ],
            "FrSoftSkills": [],
            "EnSoftSkils": []
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [
                "CDI"
            ],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s",
                "4",
                "4",
                "4"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "Data Engineer Snowflake (confirm\u00e9/s\u00e9nior) - H/F - CDI",
        "company": "Talan",
        "location": "Paris, \u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/data-engineer-snowflake-confirm%C3%A9-s%C3%A9nior-h-f-cdi-at-talan-3890985747?position=2&pageNum=37&refId=3scIT4h7LcxHkowem3t5kA%3D%3D&trackingId=7fDmrg36TdmiPiOJV45ifA%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Talan est un cabinet de conseil en innovation et transformation par la technologie.\nDepuis 20 ans, Talan conseille les entreprises et les administrations, les accompagne et met en \u0153uvre leurs projets de transformation et d\u2019innovation en France et \u00e0 l'international. Pr\u00e9sent sur cinq continents, le groupe pr\u00e9voit de r\u00e9aliser un chiffre d'affaires de 600 millions d'euros en 2022 pour plus de 6000 consultant\u00b7e\u00b7s et vise \u00e0 d\u00e9passer la barre du milliard d\u2019\u20ac de CA \u00e0 horizon 2024.\nLe Groupe met l'innovation au c\u0153ur de son d\u00e9veloppement et intervient dans les domaines li\u00e9s aux mutations technologiques des grands groupes, comme le Big Data, l'IoT, la Blockchain et l'Intelligence Artificielle.\nPr\u00e9sent dans les \u00e9v\u00e9nements incontournables du secteur, comme Viva Technology, Talan prend r\u00e9guli\u00e8rement la parole sur les enjeux de ces technologies r\u00e9volutionnaires aux c\u00f4t\u00e9s d'acteurs majeurs du secteur et de parlementaires (Syntec Num\u00e9rique, Forum de l'intelligence artificielle, French Fab Tour, Forum de Giverny\u2026).\nTalan est une entreprise responsable, attach\u00e9e \u00e0 la diversit\u00e9. Des am\u00e9nagements de poste peuvent \u00eatre organis\u00e9s pour tenir compte des personnes en situation de handicap.\nRetrouvez nos engagementsRSEiciet nos actions en faveur de la diversit\u00e9ici\nJob Description\nNous sommes \u00e0 la recherche d\u2019un Big Data Engineer Snowflake qui sera en charge des mod\u00e9lisations data et de l\u2019int\u00e9gration des donn\u00e9es: acquisition, pr\u00e9paration, mod\u00e9lisation et stockage, exposition, . Vous devrez faire preuve d\u2019un \u00e9tat d\u2019esprit \u00e0 la fois innovant, m\u00e9thodique, orient\u00e9 solution (et non probl\u00e8me!), et communiquant.\nResponsabilit\u00e9s\nAnalyse des besoins techniques m\u00e9tiers, participation \u00e0 la d\u00e9finition des architectures solution SQL, d\u00e9veloppement et optimisation, code review, maintenir les pratiques Devops \u201cYou build IT, You run IT\u201d, support \u00e0 recette et mise en production, documentation,\u2026\nMod\u00e9lisation de la Cloud Database Snowflake\nBenchmark de solutions et conseil aupr\u00e8s de notre client sur les solutions technologiques \u00e0 adopter, en lien avec leurs besoins\nPartage de connaissances et formations interne\nQualifications\nIssu d\u2019une formation sup\u00e9rieure (\u00e9cole d\u2019ing\u00e9nieur, master\u2026) avec une exp\u00e9rience dans le domaine du conseil (orient\u00e9 satisfaction client et vision partenariale)\nVous disposez d\u2019au moins 6 ann\u00e9es d\u2019exp\u00e9rience dans le domaine du SQL/ETL et ayant une exp\u00e9rience d\u2019au moins 1 an sur Snowflake\nMa\u00eetrise du d\u00e9veloppement data (SQL, Python, \u2026) et vous disposez de solides exp\u00e9riences dans la mise en place de pipeline de donn\u00e9es\nMa\u00eetrise d\u2019au moins une technique de mod\u00e9lisation: Star Sch\u00e9ma, DataVault, DataMesh,\u2026\nExp\u00e9rience sur une plateforme Cloud (id\u00e9alement AWS)\nExp\u00e9rience sur des flux temps r\u00e9el\nLa connaissance de concepts comme les suivants serait un +: DataOps, FinOps,..\nExp\u00e9rience de l\u2019Agilit\u00e9\nAutonomie, organisation, sens du partage\nBonne communication\nOrientation produit et solution\nAdditional Information\nAVANTAGES\n:\nPlan de formation pour accompagner votre carri\u00e8re (formations \u00e9diteurs, certifications) gr\u00e2ce \u00e0 nos partenariats nous accordant une position de partenaire privil\u00e9gi\u00e9, et management de proximit\u00e9 par des experts\nLocaux modernes en centre-ville\nTop 5 du Palmar\u00e8s Great Place to Work\nT\u00e9l\u00e9travail jusqu\u2019\u00e0 5 jours selon les missions, prime d\u2019\u00e9quipement de 100\u20ac\nMobilit\u00e9 en France et \u00e0 l\u2019\u00e9tranger\nTop 1% des entreprises \u00e9valu\u00e9es par Ecovadis dans le domaine social, environnemental et \u00e9thique\nTickets restaurant, prime vacances, 50% transport (abonnement transport public), mutuelle\nPermanence handicap (consultant d\u00e9di\u00e9 aux collaborateurs en situation de handicap et aux proches aidants)\nActionnariat salari\u00e9\nPrime de cooptations\nRTT\nL\u2019\u00e9quipe recrutement s\u2019engage \u00e0 vous proposer un processus de recrutement rapide et fluide :\nUn premier \u00e9change de 30 min en visio avec le recruteur pour vous pr\u00e9senter le poste et comprendre votre projet professionnel\n2 entretiens m\u00e9tier, dont au moins 1 dans nos locaux, pour entrer dans les d\u00e9tails du poste et rencontrer votre futur manager\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "R"
            ],
            "DataBase": [
                "SQL"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [
                "AWS"
            ],
            "DevTools": [],
            "Os": [],
            "DBMS": [
                "Snowflake",
                "Snowflake"
            ],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [
                "DevOps",
                "Big Data",
                "Cloud"
            ],
            "FrSoftSkills": [
                "Communication",
                "Organisation"
            ],
            "EnSoftSkils": [
                "Communication"
            ]
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s",
                "20",
                "20",
                "20"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "Data engineer - d\u00e9veloppeur C# H/F",
        "company": "Reboot Conseil",
        "location": "Strasbourg, Grand Est, France",
        "link": "https://fr.linkedin.com/jobs/view/data-engineer-d%C3%A9veloppeur-c%23-h-f-at-reboot-conseil-3909657286?position=3&pageNum=37&refId=3scIT4h7LcxHkowem3t5kA%3D%3D&trackingId=Bu0VwR8Z3%2FIHjniwIutgYA%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "En 2020, dans un climat d\u00e9favorable et d\u00e9moralisant, nous avons d\u00e9cid\u00e9 d\u2019\u00eatre cette jeune pousse porteuse d\u2019espoir que l\u2019on voit apr\u00e8s un incendie ayant d\u00e9cim\u00e9 toute une for\u00eat, d\u2019\u00eatre ce vent nouveau qui veut faire \u00e9voluer les choses, d\u2019\u00eatre ce bouton Reboot qu\u2019on presse pour corriger ce qui n\u2019allait pas et repartir sur une bonne base. Voil\u00e0 comment notre soci\u00e9t\u00e9 est n\u00e9e.\nJour apr\u00e8s jour, nous portons nos ambitions et nos r\u00eaves pour nous r\u00e9aliser individuellement et collectivement avec un socle culturel atypique issu du livre \u00ab Reinventing organizations \u00bb dont d\u00e9coule des valeurs fortes de bien-\u00eatre au travail, de partage, de libert\u00e9 et de transparence.\nChez Reboot Conseil, nous ne nous contentons pas de fournir des prestations de conseil, nous cr\u00e9ons de la valeur pour nos clients, que ce soit par des conseils en pr\u00e9sentiel ou \u00e0 distance, l\u2019accompagnement de candidats en immersion dans les \u00e9quipes de nos clients, la conception de projets innovants depuis notre centre d'expertise, le recrutement de talents exceptionnels ou m\u00eame la commercialisation de nos propres produits.\nNotre mission est de ne jamais s'ennuyer et de toujours repousser les limites de ce que nous pouvons r\u00e9aliser. Rejoignez-nous pour une aventure passionnante o\u00f9 chaque membre est une source in\u00e9puisable de nouveaut\u00e9s.\nNous recherchons actuellement un/e Data Engineer - analyste d\u00e9veloppeur\nContexte_:\nL'avancement des solutions informatiques permettant le traitement automatique du langage naturel et l'apprentissage par l'exemple ouvre de nouvelles perspectives pour am\u00e9liorer le soutien aux collaborateurs et mieux servir les clients.\nLe client a ainsi choisi d'investir consid\u00e9rablement dans le domaine de l'informatique cognitive, en \u00e9tant parmi les premi\u00e8res en France \u00e0 d\u00e9ployer la technologie. Plusieurs solutions dites ont \u00e9t\u00e9 mises en place, comprenant des Assistants Virtuels (chatbots), des Analyseurs d'emails et des Assistants Vocaux t\u00e9l\u00e9phoniques.\nAu sein du d\u00e9partement d\u00e9di\u00e9, dans un environnement innovant, vous aurez l'opportunit\u00e9 de rejoindre une \u00e9quipe sp\u00e9cialis\u00e9e dans l'exploitation des donn\u00e9es et les architectures.\nCette \u00e9quipe a pour mission de d\u00e9finir l'architecture applicative des solutions, de d\u00e9velopper des outils d'analyse des donn\u00e9es collect\u00e9es et d'enrichir les processus m\u00e9tiers de l'entreprise.\nSelon les projets en cours, les technologies utilis\u00e9es incluent notamment C#, SQL Server, NOSQL, Kibana, Kafka et d'autres technologies \u00e9mergentes. En tant que membre de cette \u00e9quipe dynamique, vous serez impliqu\u00e9 dans diverses t\u00e2ches li\u00e9es \u00e0 la gestion des donn\u00e9es.\nVous serez amen\u00e9 \u00e0 concevoir et r\u00e9diger des sp\u00e9cifications fonctionnelles, applicatives et techniques, \u00e0 d\u00e9velopper des applications intranet pour l'exploration et la restitution des donn\u00e9es, \u00e0 mod\u00e9liser les donn\u00e9es des solutions dans le syst\u00e8me d'information d\u00e9cisionnel, \u00e0 cr\u00e9er des tableaux de bord et \u00e0 fournir un support aux autres \u00e9quipes. Vous serez \u00e9galement charg\u00e9 d'organiser la recette des solutions applicatives, de g\u00e9rer les demandes d'\u00e9volution et de suivre la production, tout en travaillant en mode projet conform\u00e9ment aux normes de qualit\u00e9 en vigueur.\nProfil\nTitulaire d'une formation sup\u00e9rieure en informatique de niveau bac +4/5, vous avez acquis une expertise dans les ETL, les bases de donn\u00e9es orient\u00e9es Analytique, les solutions BI ainsi que dans les langages de programmation objet comme le C#.\nCe qui retiendra notre attention chez vous, c'est avant tout votre personnalit\u00e9 ! Nous recherchons des candidats curieux, ouverts aux innovations technologiques, pr\u00eats \u00e0 relever des d\u00e9fis techniques tout en \u00e9tant \u00e0 l'\u00e9coute et rigoureux, car ces qualit\u00e9s vous permettront de mener \u00e0 bien votre mission.\nVous disposez \u00e9galement de capacit\u00e9s d'analyse et de synth\u00e8se, vous attachez de l'importance au respect des normes et standards qualit\u00e9, et vous \u00eates enthousiaste \u00e0 l'id\u00e9e d'apprendre de nouveaux outils et langages.\nVous appr\u00e9ciez la communication et le travail en \u00e9quipe, mais vous savez \u00e9galement collaborer efficacement avec d'autres \u00e9quipes.\nInformations contractuelles\nPoste en CDI bas\u00e9 \u00e0 Strasbourg\nSalaire: 32-42K\u20ac\nD\u00e9placements: non\nLes avantages chez Reboot\nUne prime de mobilit\u00e9 durable de 200\u20ac/an, 2 jours de t\u00e9l\u00e9travail/semaine, 2 charity days par an, un abonnement \u00e0 Gymlib pris en charge par Reboot \u00e0 50%, une \u00e9volution salariale annuelle, automatique, une bonne mutuelle, abonnement transports en commun pris en charge \u00e0 50%, des BSPCE...\nSoit au total, un Package Salarial de 3.5k\u20ac en compl\u00e9ment de votre salaire annuel brut.\n\u2795des tech party days 1x/trimestre\n\u2795un Hackathon 1x/an\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "C#",
                "R",
                "Go"
            ],
            "DataBase": [
                "SQL",
                "NoSQL"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [
                "Tableau"
            ],
            "Statistics": [],
            "CloudComputing": [],
            "DevTools": [],
            "Os": [],
            "DBMS": [
                "SQL Server"
            ],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [
                "ML"
            ],
            "FrSoftSkills": [
                "Communication"
            ],
            "EnSoftSkils": [
                "Communication",
                "Organization"
            ]
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [
                "CDI"
            ],
            "Salary": [
                "32",
                "3.5k"
            ],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "Data Engineer",
        "company": "Societe Generale",
        "location": "La D\u00e9fense, \u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/data-engineer-at-societe-generale-3889843774?position=4&pageNum=37&refId=3scIT4h7LcxHkowem3t5kA%3D%3D&trackingId=K%2BeDgWn%2FwNWyqx33YjAVSA%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "240006K4\nVos missions au quotidien\nVous souhaitez exercer votre talent et exprimer votre cr\u00e9ativit\u00e9 au sein de notre \u00e9quipe (Feature Team) en charge des services Big Data en tant que Data Engineer ? Rejoignez-nous !\nEn tant qu'alternant(e) Data Engineer, vous rejoindrez l'\u00e9quipe M\u00e9trologie, en charge le service Big Data h\u00e9bergeant les donn\u00e9es techniques logs, m\u00e9triques\u2026du cloud priv\u00e9 de la Soci\u00e9t\u00e9 G\u00e9n\u00e9rale. Ces donn\u00e9es sont expos\u00e9es pour des utilisations diverses : monitoring, maintenance pr\u00e9dictive, capacity planning, am\u00e9liorations des services...\nConcr\u00e8tement, vous serez amen\u00e9(e), sous la supervision de votre tuteur et/ou votre manager, \u00e0 :\nParticiper \u00e0 l'\u00e9volution des services offerts par cette \u00e9quipe en enrichissant son offre\nParticiper \u00e0 la production du Cloud Priv\u00e9 Soci\u00e9t\u00e9 G\u00e9n\u00e9rale qui est au service des DSI m\u00e9tiers\nTravailler sur des technologies Big Data tr\u00e8s r\u00e9centes, h\u00e9berg\u00e9es sur le Cloud Priv\u00e9 de la banque\nEt si c\u2019\u00e9tait vous ?\nVous pr\u00e9parez un Bac +4/5 en \u00e9cole de Commerce, d'Ing\u00e9nieur ou Universit\u00e9 avec une sp\u00e9cialisation en D\u00e9veloppement, Informatique.\nVrai(e) team player, vous vous \u00e9panouissez dans un environnement collaboratif et favorisez la r\u00e9ussite de votre \u00e9quipe\nVous avez des connaissances sur certaines des technologies suivantes : Python, Kafka, Hadoop, Bigdata, Elastic Search, Druid\nVous avez de bonnes bases autour de la CI/CD (Jenkins)\nRigoureux(se), autonome et organis\u00e9(e), vous avez un bon relationnel\nYou're fluent in english ! Vous \u00eates notre candidat(e) id\u00e9al(e) !\nPensez \u00e0 accompagner votre CV de votre planning de formation\nPlus qu\u2019un poste, un tremplin\nD\u00e8s votre arriv\u00e9e, vous serez int\u00e9gr\u00e9 dans nos \u00e9quipes et apprendrez chaque jour aux c\u00f4t\u00e9s de nos experts qui vous accompagneront dans vos missions. Progressivement, vous gagnerez en autonomie sur vos projets pour faire de cette exp\u00e9rience un vrai acc\u00e9l\u00e9rateur de carri\u00e8re. Vous d\u00e9couvrirez \u00e9galement toute la diversit\u00e9 de nos m\u00e9tiers, dans un secteur qui \u00e9volue et innove en permanence.\nA la fin de vos \u00e9tudes, diverses opportunit\u00e9s pourront s\u2019offrir \u00e0 vous, en France et \u00e0 l\u2019international.\nPourquoi nous choisir ?\nAttentif \u00e0 votre qualit\u00e9 de vie et conditions de travail, vous b\u00e9n\u00e9ficiez d\u2019avantages :\nPrime* de participation et d\u2019int\u00e9ressement\nJours de t\u00e9l\u00e9travail (selon le rythme de votre service et celui de votre alternance)\nPrise en charge de 50% de votre titre de transport\nBilletterie \u00e0 prix r\u00e9duits de notre Comit\u00e9 d\u2019Entreprise (concerts, cin\u00e9ma, sport\u2026).\nOffre vari\u00e9e de restaurants d\u2019entreprise et de caf\u00e9t\u00e9rias \u00e0 tarifs comp\u00e9titifs ainsi que des titres restaurants d\u00e9mat\u00e9rialis\u00e9s quand vous \u00eates en t\u00e9l\u00e9travail\nSi vous avez 3 mois d\u2019anciennet\u00e9 sur l\u2019exercice de r\u00e9f\u00e9rence\nCr\u00e9er, oser, innover, entreprendre font partie de notre ADN. Si vous aussi vous souhaitez \u00eatre dans l\u2019action, \u00e9voluer dans un environnement stimulant et bienveillant, vous sentir utile au quotidien et d\u00e9velopper ou renforcer votre expertise, nous sommes faits pour nous rencontrer !\nVous h\u00e9sitez encore ?\nSachez que nos collaborateurs peuvent s\u2019engager quelques jours par an pour des actions de solidarit\u00e9 sur leur temps de travail : parrainer des personnes en difficult\u00e9 dans leur orientation ou leur insertion professionnelle, participer \u00e0 l\u2019\u00e9ducation financi\u00e8re de jeunes en apprentissage ou encore partager leurs comp\u00e9tences avec une association. Les formats d\u2019engagement sont multiples.\nNous sommes un\nemployeur garantissant l'\u00e9galit\u00e9 des chances\net nous sommes fiers de faire de la diversit\u00e9 une force pour notre entreprise. Le groupe s\u2019engage \u00e0 reconna\u00eetre et \u00e0\npromouvoir tous les talents\n, quels que soient leurs croyances, \u00e2ge, handicap, parentalit\u00e9, origine ethnique, nationalit\u00e9, identit\u00e9 de genre, orientation sexuelle, appartenance \u00e0 une organisation politique, religieuse, syndicale ou \u00e0 une minorit\u00e9, ou toute autre caract\u00e9ristique qui pourrait faire l\u2019objet d\u2019une discrimination.\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "R",
                "Go"
            ],
            "DataBase": [],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [
                "Hadoop"
            ],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [],
            "DevTools": [
                "Jenkins"
            ],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [
                "Big Data",
                "Cloud",
                "CI/CD"
            ],
            "FrSoftSkills": [
                "Cr\u00e9ativit\u00e9",
                "Organisation"
            ],
            "EnSoftSkils": []
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "Data Engineer",
        "company": "MS Amlin",
        "location": "Paris, \u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/data-engineer-at-ms-amlin-3910914411?position=5&pageNum=37&refId=3scIT4h7LcxHkowem3t5kA%3D%3D&trackingId=k4225ovXcJ%2FeYbTYQOOjbQ%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "We are looking for a highly skilled and motivated Data Engineer to join our dynamic team. As a Data Engineer you will play an important role in designing, building and maintaining the systems and architecture that enable MS AISE to collect, store and analyze large volumes of data. The ideal candidate is passionate about data, possesses strong analytical skills and has a proven track record of implementing robust and scalable data solutions in the cloud.\nAs an MS AISE Data Engineer you will reportin into MS AISE\u2019s Data Engineering Team Manager and will work closely with the MS AISE\u2019s Reporting & Analytics team as well as other key stakeholders with a strong interest in data, such as technical pricing, actuarial and finance.\nKey Responsibilities\nData architecture design: design and implement scalable and robust data architectures to support MS AISE\u2019s data needs. Collaborate with stakeholders to understand data requirements and translate them into technical specifications.\nData Integration: Develop and implement ETL (Extract, Transform, Load) processes to integrate data from various sources into a unified data lake. Ensure data integrity, accuracy and reconciliation throughout the integration process\nData Management: Manage and optimize database / datamart design including schema design, indexing and performance tuning as well as data security and access controls to ensure protection of sensitive data.\nData Modeling: Create and maintain data models to represent the structure and relationships within the data of MS AISE.\nData Pipeline Development: Build and maintain data pipelines to ensure automated collection, processing and storage of data. Monitor and troubleshoot data pipeline issues to ensure smooth and reliable data flow and availability.\nCollaboration with cross-functional teams: Collaborate with the MS AISE Reporting & Analytics team and other key stakeholders to understand data requirements and contribute to the delivery of solutions that meet business objectives.\nDocumentation: contribute to creating and maintaining comprehensive documenatation for data engineering processes, workflows and data dictionaries.\nTechnological Evaluation: Ensure you stay informed about emerging technologies and evaluate their applicability to the organization\u2019s data architecture and processes.\nKey Skills / Experience\nMinimum 3+ years of Experience as a Data Engineer\nStrong Experience with relational data structures, theories, principles and practices\nStrong hands-on experience with SQL Language, data transformation and modelling tools.\nProven experience with building Data Lake, Delta lake and large scale Data Warehouses\nStrong experience in implementing large scale cloud data architecture using Azure, Synapse, Azure Databricks, Data Fabric etc\nProficient in Azure Data Factory, Azure Data Lake, Azure DevOps, Azure Databricks, Azure SQL Database, Stream Analytics. Knowledge of Microsoft Fabric is a strong plus\nGood knowledge of tools associated with data ingestions & data transformations (e.g. SQL, Spark, Python)\nGood knowledge or experience with Python Programming Language\nGood knowledge or experience with other Cloud platforms is a strong plus (Google Cloud, Databricks, AWS, Snowflake, etc)\nKnowledge of insurance market business applications & procedures and/or from an equivalent industry\nCompetencies\nStrong analytical & conceptual mindset\nStrong teamplayer\nAbility to deliver from start to finish with minimal oversight\nAbility to work in a structured and efficient manner\nAbility to work in line with standard development framework & practices\nPragmatic, self-starter and solution oriented\nAbility to identify and anticipate on problems early and communicate timely\nGood communication skills\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "Scala",
                "R",
                "Go"
            ],
            "DataBase": [
                "SQL"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [
                "Spark",
                "Databricks"
            ],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [
                "AWS",
                "Azure"
            ],
            "DevTools": [],
            "Os": [],
            "DBMS": [
                "Snowflake",
                "Snowflake"
            ],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [
                "Teams"
            ],
            "Other": [
                "DevOps",
                "Cloud"
            ],
            "FrSoftSkills": [
                "Communication",
                "Collaboration"
            ],
            "EnSoftSkils": [
                "Communication",
                "Collaboration",
                "Organization"
            ]
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "Data Engineer F/H - Syst\u00e8me, r\u00e9seaux, donn\u00e9es (H/F)",
        "company": "HelloWork",
        "location": "Rennes, Brittany, France",
        "link": "https://fr.linkedin.com/jobs/view/data-engineer-f-h-syst%C3%A8me-r%C3%A9seaux-donn%C3%A9es-h-f-at-hellowork-3900073980?position=6&pageNum=37&refId=3scIT4h7LcxHkowem3t5kA%3D%3D&trackingId=M433s5A%2B6fw3NFQES954wQ%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Cette offre d\u2019emploi est fournie par P\u00f4le emploi\nDescription\nDescriptif du poste: Participez au d\u00e9veloppement d'hellowork.com au sein de l'\u00e9quipe Data Ing\u00e9 d'Antoine ! hellowork.com, c'est : * Plus de 4 millions de visites par mois * Plus de 500 000 candidats uniques par mois Vous \u00e9voluerez dans un environnement o\u00f9 la qualit\u00e9, la performance et l'accessibilit\u00e9 sont au c\u0153ur de tous nos d\u00e9veloppements ! Et bien s\u00fbr, tout \u00e7a se d\u00e9roule dans un cadre accueillant, motivant et bienveillant pour vous permettre de mener \u00e0 bien la multitude de sujets actuels ou \u00e0 imaginer pour faire avancer le produit ;) Plus concr\u00e8tement, votre quotidien sera compos\u00e9 de : * Faire \u00e9voluer et maintenir l'infrastructure recommandation principalement en Python en collaboration avec l'\u00e9quipe Data Science ; * Assurer la haute disponibilit\u00e9 de la donn\u00e9e ; * Collaborer avec les \u00e9quipes expertes et produit pour r\u00e9soudre les probl\u00e8mes, remettre en question et am\u00e9liorer les pratiques de travail sur la donn\u00e9e, les process, les architectures et les technologies ; La stack technique : * Python sur les services li\u00e9s \u00e0 la Data Science, NodeJs sur les services orient\u00e9s API ; * Des services scalables d\u00e9ploy\u00e9s sur Kubernetes via une CI Gitlab aux petits oignons cr\u00e9\u00e9e en collaboration avec l'\u00e9quipe DevOps ; * GPU ou CPU ? Il y a qu'\u00e0 tester ! * Du monitoring cl\u00e9 en main Prometheus / Grafana / Log Elastics ; * Des challenges sur des DB vari\u00e9es plut\u00f4t NoSQL : Elastics, MongoDB, Redis. * Broker de message via Azure Event Hubs Profil recherch\u00e9: Pour \u00eatre tr\u00e8s simple, voici les points importants pour nous dans le profil recherch\u00e9 : * Vous avez une expertise sur le langage Python et \u00eates pr\u00eat \u00e0 utiliser d'autres langages (principalement NodeJs). * Vous \u00eates curieux et passionn\u00e9 par les nouvelles technologies ; * Vous justifiez de minimum 2 ans d'exp\u00e9rience sur un poste similaire. Une expertise Python est un vrai plus mais nous cherchons avant tout quelqu'un sachant s'adapter ! * Vous avez un esprit d'\u00e9quipe, aimez collaborer avec des profils diff\u00e9rents du v\u00f4tre, et \u00eates familier des m\u00e9thodes agiles ; Si vous \u00eates int\u00e9ress\u00e9, alors rencontrons nous ! Promis, on est tr\u00e8s sympa. Et si vous h\u00e9sitez \u00e0 postuler parce que vous ne cochez pas toutes les cases, surtout venez nous en parler ! Nous favorisons la diversit\u00e9 et nous formons et accompagnons les personnes qui nous rejoignent tout au long de leur \u00e9volution.\nPROFIL SOUHAIT\u00c9\nExp\u00e9rience\nExp\u00e9rience exig\u00e9e de 1 An(s)\nSource: Pole emploi (https://www.pole-emploi.fr)\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "Scala",
                "R",
                "Go"
            ],
            "DataBase": [
                "SQL",
                "NoSQL",
                " MongoDB"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [
                "Azure"
            ],
            "DevTools": [
                "Git"
            ],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [
                "Kubernetes"
            ],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [
                "Kubernetes"
            ],
            "Collaboration": [],
            "Other": [
                "DevOps"
            ],
            "FrSoftSkills": [
                "Collaboration"
            ],
            "EnSoftSkils": [
                "Collaboration"
            ]
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s",
                "2",
                "2",
                "2"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "Data engineer SQL server / Dev SSIS / C# (H/F) \ud83d\udc68\ud83c\udffb\ud83d\udcbb",
        "company": "XRAYS TRADING",
        "location": "Paris, \u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/data-engineer-sql-server-dev-ssis-c%23-h-f-%F0%9F%91%A8%F0%9F%8F%BB%E2%80%8D%F0%9F%92%BB-at-xrays-trading-3813760880?position=7&pageNum=37&refId=3scIT4h7LcxHkowem3t5kA%3D%3D&trackingId=PpuTStCeaf%2BEecpbgYcOag%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "XRAYS TRADING\nest depuis 19 ans la structure la plus\natypique\ndu monde de la bourse !\nNous faisons en sorte pour que ton quotidien soit bourr\u00e9 d'\nadr\u00e9naline\net de\nmoments inoubliables\n, le tout en t\u2019aidant \u00e0 construire ta\ncarri\u00e8re\nau sein d'un groupe de travail sans \u00e9quivalent \ud83d\udc69\ud83c\udffc\u200d\ud83d\udcbb\nPour r\u00e9sumer : Tu vas int\u00e9grer une boite d\u2019\ning\u00e9nieurs\ntotalement barr\u00e9s qui savent s\u2019\u00e9clater pendant et apr\u00e8s le boulot ! \ud83d\ude09\nNOTRE BESOIN :\nParticiper aux projets li\u00e9s aux Stress Tests Risques de March\u00e9s en tant que data engineer et d\u00e9veloppeur (MS SQL, packages SSIS, cubes SSAS et composants C#)\nFournir des solutions pour des nouveaux besoins\nAssurer le support et la maintenance de l'outil\nTraitements ETL complexes (SSIS) pour fournir des donn\u00e9es via des cubes OLAP (Multidimensionnel). Ecosyst\u00e8me d'outils en C#. Gestion du code dans Git/ BitBucket. Pipe de livraison Jenkins & XL Release.\nUne connaissance des produits financiers et de mesures de risque de march\u00e9 serait un plus sur ce poste ainsi qu'un Anglais op\u00e9rationnel obligatoire.\nTOI\n:\nTu es dipl\u00f4m\u00e9(e) d'une belle \u00e9cole d'ing\u00e9nieur.\nTu es \u00e9veill\u00e9(e) et tu communiques sans difficult\u00e9 tant en Fran\u00e7ais qu'en Anglais.\nTu es passionn\u00e9(e) par la finance de march\u00e9, tu es donc quelqu'un de curieux qui cherche \u00e0 comprendre comment fonctionne notre \u00e9cosyst\u00e8me.\nTu recherches une port\u00e9e internationale dans tes attributions\ud83c\udf0d\nTon temp\u00e9rament te m\u00e8ne \u00e0 sortir de ta zone de confort afin de gagner en autonomie tout en d\u00e9couvrant un immense p\u00e9rim\u00e8tre dont on ne fait jamais le tour : la finance de march\u00e9 !\nNOTRE OFFRE :\nAvec une exp\u00e9rience minimale de 5 ans, tu peux partir du principe o\u00f9 nous te proposons un salaire minimal de 3800 euros nets.\nCe salaire est \u00e9videment tr\u00e8s bien revaloris\u00e9 en fonction de ton dipl\u00f4me mais surtout de ton exp\u00e9rience !\nNous te formerons \u00e0 nos outils, m\u00e9tier et m\u00e9thodes, nous sommes souples, ouverts et humains. Nous souhaitons t'accompagner dans ta mont\u00e9e en comp\u00e9tences.\nPasse nous faire un check sur www.xrays.fr ! \ud83d\ude80\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "C#",
                "R"
            ],
            "DataBase": [
                "SQL"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [],
            "DevTools": [
                "Git",
                "Jenkins"
            ],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [],
            "FrSoftSkills": [],
            "EnSoftSkils": []
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [],
            "Salary": [
                "3800",
                "5"
            ],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s",
                "19",
                "19",
                "19"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "Data Analyst H/F",
        "company": "Inetum",
        "location": "Lille, Hauts-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/data-analyst-h-f-at-inetum-3843955768?position=8&pageNum=37&refId=3scIT4h7LcxHkowem3t5kA%3D%3D&trackingId=iHtnLky7lKLcRpf5Mbva9Q%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "D\u00e9tail de l'offre\nInformations g\u00e9n\u00e9rales\nEntit\u00e9 de rattachement\nInetum est un leader europ\u00e9en des services num\u00e9riques. Pour les entreprises, les acteurs publics et la soci\u00e9t\u00e9 dans son ensemble, les 28 000 consultants et sp\u00e9cialistes du groupe visent chaque jour l'impact digital des solutions qui contribuent \u00e0 la performance, \u00e0 l'innovation et au bien commun.\nPr\u00e9sent dans 19 pays au plus pr\u00e8s des territoires, et avec ses grands partenaires \u00e9diteurs de logiciels, Inetum r\u00e9pond aux enjeux de la transformation digitale avec proximit\u00e9 et flexibilit\u00e9.\nPort\u00e9 par son ambition de croissance et d'industrialisation, Inetum a g\u00e9n\u00e9r\u00e9 en 2023 un chiffre d'affaires de 2,5 milliards d'\u20ac.\nPour r\u00e9pondre \u00e0 un march\u00e9 en croissance continue depuis plus de 30ans, Inetum a fait le choix d\u00e9lib\u00e9r\u00e9 de se recentrer sur 4 m\u00e9tiers afin de gagner en puissance et proposer des solutions sur mesure, adapt\u00e9es aux besoins sp\u00e9cifiques de ses clients le conseil (Inetum Consulting), la gestion des infrastructures et applications \u00e0 fa\u00e7on (Inetum Technologies), l'impl\u00e9mentation de progiciels (Inetum Solutions) et sa propre activit\u00e9 d'\u00e9diteur de logiciels (Inetum Software). Inetum a conclu des partenariats strat\u00e9giques avec 4 grands \u00e9diteurs mondiaux - Salesforce, ServiceNow, Microsoft et SAP et poursuit une strat\u00e9gie d'acquisitions d\u00e9di\u00e9e afin d'entrer dans le top 5 europ\u00e9en sur ces technologies et proposer la meilleure expertise \u00e0 ses clients.\nTous nos postes sont ouverts aux personnes en situation de handicap.\nDescription du poste\nM\u00e9tier\nApplications Delivery - Software Development\nIntitul\u00e9 du poste\nData Analyst H/F\nContrat\nCDI\nDescription De La Mission\nDans le cadre de la croissance de notre agence lilloise, nous d\u00e9veloppons notre Practice Data et recrutons des profils Data de divers horizons Data Analyst, Data Engineer, Data Scientist et Data Gouv. Les besoins m\u00e9tiers de nos clients et la multitude des technologies font qu'il nous faut nous appuyer sur une diversit\u00e9 de comp\u00e9tences. Vous pourriez \u00eatre l\u2019un d\u2019eux et rejoindre Inetum.\nEn tant que Data Analyst, vos principales missions consistent \u00e0\nAnalyser et retranscrire le besoin client\nIdentifier, extraire et exploiter les sources d'acquisition de donn\u00e9es les plus pertinentes\nValoriser de la donn\u00e9e\nD\u00e9velopper l'outil de data visualisation pour accompagner les \u00e9quipes m\u00e9tiers dans leurs aides \u00e0 la d\u00e9cision\n\u00catre le lien entre les \u00e9quipes m\u00e9tier pour les accompagner dans la mise en \u0153uvre des nouveaux outils\nProfil\nPour mener \u00e0 bien votre r\u00f4le, il vous faut\nparler SQL couramment\nun niveau avanc\u00e9 sur Excel et/ou Google Spreadsheet\nune ma\u00eetrise d'un outil d\u00e9cisionnel comme PowerBI, Qlik, Tableau ou encore Google Data Studio\nVous vous reconnaissez dans ces quelques lignes, alors rencontrons-nous !\nNotre plus\nRejoindre la r\u00e9gion Nord-Est, c\u2019est b\u00e9n\u00e9ficier des avantages d\u2019un Grand Groupe tout en gardant la proximit\u00e9 r\u00e9gionale.\nNous mettrons tout en \u0153uvre pour vous apporter un \u00e9quilibre vie perso / vie pro. C\u2019est pourquoi nous vous proposons un rythme hybride (selon les contraintes clients)\nUne trajectoire de carri\u00e8re personnalis\u00e9e et adapt\u00e9e \u00e0 vos souhaits d'\u00e9volution gr\u00e2ce \u00e0 une implantation \u00e0 l\u2019international (26 pays, 7 Fablab), des formations cibl\u00e9es et des projets couvrant l\u2019ensemble de la cha\u00eene de valeur IT (+25 fili\u00e8res m\u00e9tiers)\nInt\u00e9grer un collectif d\u2019experts partageant des valeurs de solidarit\u00e9 et d\u2019excellence\nInt\u00e9grer une entreprise ayant une strat\u00e9gie affirm\u00e9e de certifications de ses collaborateurs\nLocalisation du poste\nLocalisation du poste\nFrance, Nord, 59 Nord\nVille\nLille\nCrit\u00e8res candidat\nNiveau d'\u00e9tudes min. requis\nBac+5\nNiveau d'exp\u00e9rience min. requis\nPlus de 2 ans\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "R",
                "Go"
            ],
            "DataBase": [
                "SQL"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [
                "Tableau",
                "PowerBI"
            ],
            "Statistics": [],
            "CloudComputing": [],
            "DevTools": [
                "Git"
            ],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [],
            "FrSoftSkills": [
                "Flexibilit\u00e9"
            ],
            "EnSoftSkils": []
        },
        "details": {
            "JobDetail": [
                "Hybride"
            ],
            "TypeContract": [
                "CDI"
            ],
            "Salary": [],
            "Level": [
                "Bac+5"
            ],
            "Experience": [
                "a",
                "n",
                "s",
                "30",
                "30",
                "30"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "Data engineer",
        "company": "Societe Generale",
        "location": "La D\u00e9fense, \u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/data-engineer-at-societe-generale-3918754036?position=10&pageNum=37&refId=3scIT4h7LcxHkowem3t5kA%3D%3D&trackingId=C%2Fki0HYve2YtGbtwssrtHQ%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "24000COX\nVos missions au quotidien\nNous recherchons un(e) alternant(e) en Data Engineering dans le cadre d'un de nos projets au sein de notre direction informatique Corporate Functions Technologies.\nVous contribuerez \u00e0 l\u2019ex\u00e9cution d'un chantier majeur de la cha\u00eene Credit Risk.\nConcr\u00e8tement, vous serez amen\u00e9(e) \u00e0 :\nConcevoir des solutions pour collecter, nettoyer, organiser et synth\u00e9tiser de gros volumes de donn\u00e9es (pour alimenter bases de donn\u00e9es, datalakes et projets Big Data) ;\nCo-\u00e9laborer le design technique du produit d\u00e9livr\u00e9 ;\nApporter votre soutien sur les d\u00e9veloppements de votre \u00e9quipe ;\nD\u00e9velopper, entretenir et utiliser votre expertise sur la stack Scala, Spark, Hadoop ;\nParticiper \u00e0 l\u2019industrialisation du proc\u00e9d\u00e9 pour les donn\u00e9es les plus pertinentes dans le cadre du projet pour produire les analyses les plus op\u00e9rationnelles, assurer une veille technologique et d\u00e9montrer un int\u00e9r\u00eat pour le domaine bancaire.\nEt si c\u2019\u00e9tait vous ?\nVous \u00eates un(e) \u00e9tudiant(e) de niveau Bac+4/5 en Universit\u00e9, \u00e9cole de Commerce, d\u2019Ing\u00e9nieur, avec une sp\u00e9cialisation en Big Data.\nVous maitrisez les technologies Big Data, en particulier l'\u00e9cosyst\u00e8me Hadoop.\nVous poss\u00e9dez de solides connaissances en Spark et Scala.\nVous \u00eates attach\u00e9(e) au respect des bonnes pratiques de d\u00e9veloppement.\nYou're fluent in english ! Vous \u00eates notre candidat(e) id\u00e9al(e) !\nPensez \u00e0 accompagner votre CV de votre planning de formation!\nPlus qu\u2019un poste, un tremplin\nD\u00e8s votre arriv\u00e9e, vous serez int\u00e9gr\u00e9 dans nos \u00e9quipes et apprendrez chaque jour aux c\u00f4t\u00e9s de nos experts qui vous accompagneront dans vos missions.\nProgressivement, vous gagnerez en autonomie sur vos projets pour faire de cette exp\u00e9rience un vrai acc\u00e9l\u00e9rateur de carri\u00e8re. Vous d\u00e9couvrirez \u00e9galement toute la diversit\u00e9 de nos m\u00e9tiers, dans un secteur qui \u00e9volue et innove en permanence.\nA la fin de vos \u00e9tudes ou de votre VIE, diverses opportunit\u00e9s pourront s\u2019offrir \u00e0 vous, en France et \u00e0 l\u2019international.\nPourquoi nous choisir ?\nAttentif \u00e0 votre qualit\u00e9 de vie et conditions de travail, vous b\u00e9n\u00e9ficiez d\u2019avantages :\nPrime de participation et d\u2019int\u00e9ressement\nJours de t\u00e9l\u00e9travail (selon le rythme de votre service et celui de votre alternance)\nPrise en charge de 50% de votre titre de transport\nBilletterie \u00e0 prix r\u00e9duits de notre Comit\u00e9 d\u2019Entreprise (concerts, cin\u00e9ma, sport\u2026).\nOffre vari\u00e9e de restaurants d\u2019entreprise et de caf\u00e9t\u00e9rias \u00e0 tarifs comp\u00e9titifs ainsi que des titres restaurants d\u00e9mat\u00e9rialis\u00e9s quand vous \u00eates en t\u00e9l\u00e9travail\nCr\u00e9er, oser, innover, entreprendre font partie de notre ADN. Si vous aussi vous souhaitez \u00eatre dans l\u2019action, \u00e9voluer dans un environnement stimulant et bienveillant, vous sentir utile au quotidien et d\u00e9velopper ou renforcer votre expertise, nous sommes faits pour nous rencontrer !\nVous h\u00e9sitez encore ?\nSachez que nos collaborateurs peuvent s\u2019engager quelques jours par an pour des actions de solidarit\u00e9 sur leur temps de travail : parrainer des personnes en difficult\u00e9 dans leur orientation ou leur insertion professionnelle, participer \u00e0 l\u2019\u00e9ducation financi\u00e8re de jeunes en apprentissage ou encore partager leurs comp\u00e9tences avec une association. Les formats d\u2019engagement sont multiples.\nNous sommes un\nemployeur garantissant l'\u00e9galit\u00e9 des chances\net nous sommes fiers de faire de la diversit\u00e9 une force pour notre entreprise. Le groupe s\u2019engage \u00e0 reconna\u00eetre et \u00e0\npromouvoir tous les talents\n, quels que soient leurs croyances, \u00e2ge, handicap, parentalit\u00e9, origine ethnique, nationalit\u00e9, identit\u00e9 de genre, orientation sexuelle, appartenance \u00e0 une organisation politique, religieuse, syndicale ou \u00e0 une minorit\u00e9, ou toute autre caract\u00e9ristique qui pourrait faire l\u2019objet d\u2019une discrimination.\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Scala",
                "R"
            ],
            "DataBase": [],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [
                "Hadoop",
                "Spark"
            ],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [],
            "DevTools": [],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [
                "Big Data"
            ],
            "FrSoftSkills": [
                "Organisation"
            ],
            "EnSoftSkils": []
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "Data engineer GCP S\u00e9nior",
        "company": "Apside",
        "location": "\u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/data-engineer-gcp-s%C3%A9nior-at-apside-3825028887?position=1&pageNum=40&refId=PlhdJ%2BvRBuQPyL9EJS3cmw%3D%3D&trackingId=OFv5GAwoVnXsBllV5IoOZA%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "\ud83d\udca5\nD\u00e9couvrez la Vie Apsidienne\n\ud83d\udcf9\net vous aussi, devenez Apsidien\nOn aurait pu demander \u00e0 Chat GPT de vous d\u00e9montrer en quoi\nApside est l\u2019ESN qu\u2019il vous faut,\nmais on pr\u00e9f\u00e8re que vous le d\u00e9couvriez vous-m\u00eames \ud83d\udc47\ud83d\ude0f\n\ud83d\udd25\nD\u00e9couvrez votre future mission\n\ud83d\udc49\nContexte\nRejoignez notre Practise Cloud/Data, afin d\u2019intervenir sur des sujets \u00e0 haute valeur ajout\u00e9e !\nSecteur\n: T\u00e9l\u00e9com\nM\u00e9thode de travail\n: Agile Safe\nNotre client a besoin d\u2019un accompagnement sur leurs projets m\u00e9tiers\nData/IA\naccostant sur un cloud public et \u00e0 la construction d'outils pour acc\u00e9l\u00e9rer et faciliter cet accostage.\nCela sera r\u00e9alis\u00e9 dans un environnement\nGCP\net en grande majorit\u00e9 sur des\ntechnologies innovantes\npour des services Data & IA. La mission sera partag\u00e9 entre le \"build\" des cas d'usage et outils, et le \"run\" de ces derniers.\n\ud83d\ude0e Mission\nEtude et d\u00e9finition des architectures GCP, ainsi que leur impl\u00e9mentation\nMise en application des exigences op\u00e9rationnelles (s\u00e9curit\u00e9, exploitabilit\u00e9 et industrialisation)\nAiguillage sur nos outils transverse et pr\u00e9conisations \u00e0 l'usage du cloud public\nConstruction d'outillages facilitant l'accostage de ces des projets m\u00e9tiers DATA-IA\n\u2026\nEnvironnement technique\n:\nGCP\nGit\nGitlab\nBash\nDocker\nKubernetes\nGitlabCI\n\ud83d\udcb0\nLe package salarial que nous vous proposons\nContrat :\nCDI\nAvantages groupe :\ncarte ticket restaurant Swile, prime de mobilit\u00e9, RTT, accord t\u00e9l\u00e9travail, Mutuelle, prime de cooptation, avantages CE, prise en charge de la mutuelle \u00e0 100% etc\u2026\nAvantages agence :\nint\u00e9gration de la Practise Cloud/Data, afterworks, communaut\u00e9 techlead\nFormation :\ncertifications techniques, cours particuliers d\u2019anglais en interne, acc\u00e8s \u00e0 un catalogue de formations gr\u00e2ce \u00e0 notre plateforme e-learning (\nAcademy by Apside\n) ou via nos organismes partenaires.\n\ud83d\udd2e\n\u00d4 vous futur Apsidien, qui \u00eates-vous ?\nAu moins 5 ans d'exp\u00e9rience en tant que Data Engineer\nMaitrise de l\u2019environnement cloud GCP\nForce de proposition, bon relationnel et autonome\n\ud83d\ude0f\nApside a suscit\u00e9 votre curiosit\u00e9 ?\nDans un environnement marqu\u00e9 par une acc\u00e9l\u00e9ration des \u00e9volutions technologiques, de transformations des usages et de disruptions majeures, Apside est un partenaire de confiance qui accompagne ses clients \u00e0 cr\u00e9er de la valeur et \u00e0 adresser leurs enjeux strat\u00e9giques en leur mettant \u00e0 disposition des expertises technologiques (\nData / IA, Cloud, Cyber\n) et une exp\u00e9rience sectorielle (\nIndustrie, Banque, Assurance, Service, Secteur Public\n). Pour un accompagnement global, le groupe propose des offres transverses autour du\nHandicap\n(Apsid\u2019EA), du\nDigital Learning\n, et du\nConseil\n.\n\ud83e\udd14\nEt votre place dans tout \u00e7a ?\n\ud83d\udc49 Notre volont\u00e9\nest de vous accompagner dans la construction et l\u2019\u00e9panouissement de votre carri\u00e8re\nen nous appuyant notamment\nsur 3 piliers :\nUne\nr\u00e9mun\u00e9ration\n\u00e0 hauteur de vos investissements et de vos comp\u00e9tences\nUne\ntrajectoire professionnelle\nstimulante sur mesure\nUn\nengagement\nautour des valeurs Apsidiennes : la qualit\u00e9 de vie et des conditions de travail au c\u0153ur de nos enjeux\nEngag\u00e9e pour\nun monde plus inclusif et plus responsable\n, Apside r\u00e9invente l\u2019ESN et propose l\u2019Engagement Soci\u00e9tal et Num\u00e9rique. D\u00e9couvrez notre d\u00e9marche RSE ainsi que notre vision de l\u2019Entreprise Engag\u00e9e.\nConvaincu ? A vous de jouer, envoyez-nous votre CV !\nRejoignez l\u2019aventure Apsidienne et d\u00e9couvrez notre vision d\u2019une ESN singuli\u00e8re et r\u00e9siliente\n\ud83d\ude80\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "R",
                "Bash"
            ],
            "DataBase": [],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [],
            "DevTools": [
                "Git",
                "Docker"
            ],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [
                "Kubernetes"
            ],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [
                "Docker",
                "Kubernetes"
            ],
            "Collaboration": [],
            "Other": [
                "Cloud"
            ],
            "FrSoftSkills": [],
            "EnSoftSkils": []
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [
                "CDI"
            ],
            "Salary": [
                "100"
            ],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s",
                "5",
                "5",
                "5"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "Big Data Engineer Confirm\u00e9 \u2013 Lille, France (H/F)",
        "company": "Astek",
        "location": "Lille, Hauts-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/big-data-engineer-confirm%C3%A9-%E2%80%93-lille-france-h-f-at-astek-3839095323?position=2&pageNum=40&refId=PlhdJ%2BvRBuQPyL9EJS3cmw%3D%3D&trackingId=nK8OX75hvZYpbs8abogtpA%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "CDI\nLille - France\nPubli\u00e9e il y a 2 mois\nLe Groupe Astek\nCe Que Nous Allons Accomplir Ensemble :\nNous rejoindre en tant que\nBig Data Engineer Confirm\u00e9 (H/F),\nafin d\u2019accompagner un op\u00e9rateur t\u00e9l\u00e9coms, Leader en Europe dans l\u2019assistance et le support applicatif de niveau 3 (r\u00e9solution des probl\u00e8mes utilisateurs, exploitation des environnements hors production).\nUn challenge portant sur des millions d\u2019utilisateurs dans un environnement technique innovant, strat\u00e9gique et o\u00f9 l\u2019entraide et la bonne humeur priment !\nVotre Mission, Si Vous L\u2019acceptez :\nSupervision et d\u00e9tection et r\u00e9solution des probl\u00e8mes utilisateurs (d\u00e9veloppeurs, exploitants et data exploreurs)\nD\u00e9veloppement de solutions de self-service ou d\u2019une solution de r\u00e9solutions automatiques des probl\u00e8mes\nQualifier les donn\u00e9es et les r\u00e9sultats\nConception technique des solutions\nAssurer l\u2019accompagnement et le d\u00e9ploiement des \u00e9volutions des processus et outils\nAccompagner la phase de mise en production\nVotre Future \u00c9quipe :\nVous int\u00e9grerez une \u00e9quipe \u00e0 la fois technique et fonctionnel, qui \u0153uvre chaque jour pour d\u00e9velopper et maintenir en conditions op\u00e9rationnelles l\u2019ensemble des solutions IT !\nL\u2019\u00e9quipe est en interaction avec des clients \u00e0 la fois internes et externes.\nVotre stack de jeu\nSyst\u00e8me d\u2019exploitation : Linux\nOutils des distributions : HDP, HDF, ELK\nEnvironnement Big data : Hadoop, Spark,\nLangage : Scala, Shell, Python\nCloud computing : GCP ou AWS\nBase de donn\u00e9es : No SQL (Cassandra, Mongo DB), Shell, Ansible\nDataviz : Power BI ou Kibana\nDes notions en R\u00e9seau et Syst\u00e8mes feront la diff\u00e9rence !\nLes Petits Plus Du Projet :\nVous \u00e9voluerez au sein d\u2019une \u00e9quipe impliqu\u00e9e et r\u00e9active et interviendrez sur un projet polyvalent et \u00e0 forte valeur ajout\u00e9e.\nVous ?\nDipl\u00f4m\u00e9(e) d\u2019une \u00e9cole d\u2019ing\u00e9nieur ou \u00e9quivalent de niveau Bac+5.\nVous justifiez id\u00e9alement d\u2019une exp\u00e9rience d\u2019au moins 3 ans d\u2019exp\u00e9riences sur un poste similaire ?\nVous faite preuve de proactivit\u00e9 et d\u2019esprit d\u2019\u00e9quipe, \u00eates dot\u00e9(e) d\u2019un excellent sens de l\u2019organisation et vous aimez les challenges et la r\u00e9solution de probl\u00e8me ?\nAlors ce poste est fait pour vous, n\u2019h\u00e9sitez plus et rejoignez l\u2019aventure ASTEK !\nAstek\nCr\u00e9\u00e9 en France en 1988, Astek est un acteur mondial de l\u2019ing\u00e9nierie et du conseil en technologies. Fort de son expertise dans de nombreux secteurs industriels et tertiaires, Astek accompagne ses clients internationaux dans le d\u00e9ploiement intelligent de leurs produits et de leurs services, et dans la mise en \u0153uvre de leur transformation digitale.\nDepuis sa cr\u00e9ation, le Groupe a fond\u00e9 son d\u00e9veloppement sur une forte culture d\u2019entrepreneuriat et d\u2019innovation, et sur l\u2019accompagnement et la mont\u00e9e en comp\u00e9tence de\nses 7800 collaborateurs\nqui s\u2019engagent chaque jour \u00e0 promouvoir la compl\u00e9mentarit\u00e9 entre les technologies num\u00e9riques et l\u2019ing\u00e9nierie des syst\u00e8mes complexes.\nRejoignez un Groupe en fort d\u00e9veloppement en France et \u00e0 travers le monde ayant r\u00e9alis\u00e9 un chiffre d\u2019affaires de 600 M\u20ac en 2023.\nTous les d\u00e9tails sur le Groupe sur le site https://astekgroup.fr. Et vous pouvez aussi nous suivre sur notre blog : https://blog.groupeastek.com.\nRencontrons-nous\nNotre projet commun vous plait ?\nPostulez \u00e0 cette annonce, et soyez transparent !\nMaud, notre Talent Acquisition Referent, vous contactera pour un premier \u00e9change.\nPuis vous rencontrerez Martin, votre futur manager, avec lequel vous \u00e9changerez autour d\u2019Astek, de votre parcours, de vos attentes et de votre future mission .\nEnfin, vous rencontrerez J\u00e9r\u00e9my, notre Directeur d\u2019agence avec lequel vous pourrez valider votre int\u00e9r\u00eat et ad\u00e9quation pour le poste et finaliser les \u00e9l\u00e9ments contractuels.\nNos Plus\nAstek est green et fait b\u00e9n\u00e9ficier ses salari\u00e9s d\u2019une indemnit\u00e9 kilom\u00e9trique v\u00e9lo\nUne politique CARE sur-mesure d\u00e9ploy\u00e9e par nos \u00e9quipes RH pour nos collaborateurs (https://astekgroup.fr/engagements)\nNotre charte de la Diversit\u00e9\nMots-cl\u00e9s :\ning\u00e9nieur \u2013 ing\u00e9nieure \u2013 consultant \u2013 consultante \u2013 Hadoop \u2013 Scala \u2013 Data\nCaract\u00e9ristiques de l'emploi\nCat\u00e9gorie Ing\u00e9nieur\nJob Industry T\u00e9l\u00e9com / M\u00e9dia\nPostuler en ligne\nNom *\nPr\u00e9nom *\nEmail *\nUn email valide est requis.\nT\u00e9l\u00e9phone *\nUn num\u00e9ro de t\u00e9l\u00e9phone valide est requis.\nJoindre un CV *\nMots-cl\u00e9s :\ning\u00e9nieur \u2013 ing\u00e9nieure \u2013 consultant \u2013 consultante \u2013 Hadoop \u2013 Scala \u2013 Data\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "Scala",
                "R",
                "Go"
            ],
            "DataBase": [
                "SQL",
                "Cassandra"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [
                "Hadoop",
                "Spark"
            ],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [
                "Power BI"
            ],
            "Statistics": [],
            "CloudComputing": [
                "AWS"
            ],
            "DevTools": [
                "Git"
            ],
            "Os": [
                "Linux"
            ],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [
                "Ansible"
            ],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [
                "Big Data",
                "Cloud"
            ],
            "FrSoftSkills": [
                "Organisation"
            ],
            "EnSoftSkils": []
        },
        "details": {
            "JobDetail": [
                "Confirm\u00e9"
            ],
            "TypeContract": [
                "CDI"
            ],
            "Salary": [],
            "Level": [
                "Bac+5"
            ],
            "Experience": [
                "a",
                "n",
                "s",
                "3",
                "3",
                "3"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "Data Engineer \u2013 Bordeaux, France (H/F)",
        "company": "Astek",
        "location": "Bordeaux, Nouvelle-Aquitaine, France",
        "link": "https://fr.linkedin.com/jobs/view/data-engineer-%E2%80%93-bordeaux-france-h-f-at-astek-3839091989?position=3&pageNum=40&refId=PlhdJ%2BvRBuQPyL9EJS3cmw%3D%3D&trackingId=y4Kk%2Bf4%2BPQLFNzvLUNrwvw%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "CDI\nBordeaux - France\nPubli\u00e9e il y a 2 mois\nLe Groupe Astek\nCe Que Nous Allons Accomplir Ensemble :\nVous \u00eates passionn\u00e9 par la Data ?\nVous avez \u00e0 c\u0153ur d\u2019aider les entreprises \u00e0 mieux g\u00e9rer leurs donn\u00e9es ?\nVous souhaitez contribuer \u00e0 la croissance et \u00e0 la r\u00e9ussite de nos projets clients ?\nNous aussi !\nRejoignez-nous et intervenez sur toute la cha\u00eene de traitement de la donn\u00e9e dans un environnement grand compte : de la r\u00e9cup\u00e9ration, en passant par le traitement, pour en faire l\u2019affichage et l\u2019analyse.\nVotre Mission, Si Vous L\u2019acceptez :\nR\u00e9alisation d\u2019op\u00e9rations de collecte de donn\u00e9es\nConcevoir et d\u00e9velopper des pipelines de donn\u00e9es r\u00e9utilisables pour collecter, nettoyer, extraire et transformer les donn\u00e9es.\nIndustrialisation et optimisation des jobs data\nR\u00e9alisation de contr\u00f4les qualit\u00e9 tout au long des op\u00e9rations,\nR\u00e9alisation d\u2019op\u00e9rations d\u2019int\u00e9gration de donn\u00e9es et de traitements de masse\nCollaborer avec les \u00e9quipes multidisciplinaires pour int\u00e9grer les solutions de donn\u00e9es dans les applications existantes.\nParticiper \u00e0 la veille technologique et recommander des solutions innovantes pour am\u00e9liorer nos pratiques de data engineerin g.\nVotre Future \u00c9quipe :\nAu sein d\u2019une \u00e9quipe compos\u00e9e de 4 Data Engineers Astek, vous rejoindrez les \u00e9quipes m\u00e9tiers et techniques de notre client afin de l\u2019accompagner dans le traitement de ses donn\u00e9es.\nVotre stack de jeu\nLangages : Python, Java\nAnalyse de donn\u00e9es : Talend, Power BI, Qlik\nBDD : SQL, PostgreSQL, MongoDB, Oracle\nLes Petits Plus Du Projet :\nVous \u00e9voluerez dans un contexte data innovant dans lequel vous progresserez tout en \u00e9tant accompagn\u00e9 sur les nouveaux outils.\nVous ?\nDe formation Ing\u00e9nieur ou \u00e9quivalent (Bac+5), vous avez une premi\u00e8re exp\u00e9rience dans un contexte autour de la Data et vous avez pour objectif de continuer votre mont\u00e9e en comp\u00e9tences.\nVous aimez d\u00e9velopper en Python et \u00eates int\u00e9ress\u00e9 par les sujets d\u2019IA g\u00e9n\u00e9rative.\nCe projet n\u2019est pas le seul que nous pourrions vous proposer. Prenons le temps d\u2019\u00e9changer afin de vous pr\u00e9senter les sujets les plus adapt\u00e9s \u00e0 vos ambitions.\nAstek\nCr\u00e9\u00e9 en France en 1988, Astek est un acteur mondial de l\u2019ing\u00e9nierie et du conseil en technologies. Fort de son expertise dans de nombreux secteurs industriels et tertiaires, Astek accompagne ses clients internationaux dans le d\u00e9ploiement intelligent de leurs produits et de leurs services, et dans la mise en \u0153uvre de leur transformation digitale.\nDepuis sa cr\u00e9ation, le Groupe a fond\u00e9 son d\u00e9veloppement sur une forte culture d\u2019entrepreneuriat et d\u2019innovation, et sur l\u2019accompagnement et la mont\u00e9e en comp\u00e9tence de\nses 7800 collaborateurs\nqui s\u2019engagent chaque jour \u00e0 promouvoir la compl\u00e9mentarit\u00e9 entre les technologies num\u00e9riques et l\u2019ing\u00e9nierie des syst\u00e8mes complexes.\nRejoignez un Groupe en fort d\u00e9veloppement en France et \u00e0 travers le monde ayant r\u00e9alis\u00e9 un chiffre d\u2019affaires de 600 M\u20ac en 2023.\nTous les d\u00e9tails sur le Groupe sur le site https://astekgroup.fr. Et vous pouvez aussi nous suivre sur notre blog : https://blog.groupeastek.com.\nRencontrons-nous\nNotre projet commun vous plait ?\nPostulez \u00e0 cette annonce, et soyez transparent !\nMathilde, notre Talent Acquisition Officer, vous contactera pour un premier \u00e9change t\u00e9l\u00e9phonique.\nPuis vous rencontrerez Thomas, votre futur manager, avec lequel vous \u00e9changerez autour d\u2019Astek, de votre parcours, de vos attentes et de votre future mission.\nEnfin, vous rencontrerez Guillaume, notre Directeur de d\u00e9partement, avec lequel vous pourrez valider votre int\u00e9r\u00eat et ad\u00e9quation pour le poste et finaliser les \u00e9l\u00e9ments contractuels.\nNos Plus\nAstek est green et fait b\u00e9n\u00e9ficier ses salari\u00e9s d\u2019une indemnit\u00e9 kilom\u00e9trique v\u00e9lo\nUne politique CARE sur-mesure d\u00e9ploy\u00e9e par nos \u00e9quipes RH pour nos collaborateurs (https://astekgroup.fr/engagements)\nNotre charte de la Diversit\u00e9\nCaract\u00e9ristiques de l'emploi\nCat\u00e9gorie Ing\u00e9nieur\nJob Industry A\u00e9rospatial / D\u00e9fense / S\u00e9curit\u00e9, Distribution / Services Internet, Energie / Sciences de la Vie / Autres industries, Finance / Gouvernement, T\u00e9l\u00e9com / M\u00e9dia, Transports Terrestres\nPostuler en ligne\nNom *\nPr\u00e9nom *\nEmail *\nUn email valide est requis.\nT\u00e9l\u00e9phone *\nUn num\u00e9ro de t\u00e9l\u00e9phone valide est requis.\nJoindre un CV *\nLes Petits Plus Du Projet :\nVous \u00e9voluerez dans un contexte data innovant dans lequel vous progresserez tout en \u00e9tant accompagn\u00e9 sur les nouveaux outils.\nVous ?\nDe formation Ing\u00e9nieur ou \u00e9quivalent (Bac+5), vous avez une premi\u00e8re exp\u00e9rience dans un contexte autour de la Data et vous avez pour objectif de continuer votre mont\u00e9e en comp\u00e9tences.\nVous aimez d\u00e9velopper en Python et \u00eates int\u00e9ress\u00e9 par les sujets d\u2019IA g\u00e9n\u00e9rative.\nCe projet n\u2019est pas le seul que nous pourrions vous proposer. Prenons le temps d\u2019\u00e9changer afin de vous pr\u00e9senter les sujets les plus adapt\u00e9s \u00e0 vos ambitions.\nAstek\nCr\u00e9\u00e9 en France en 1988, Astek est un acteur mondial de l\u2019ing\u00e9nierie et du conseil en technologies. Fort de son expertise dans de nombreux secteurs industriels et tertiaires, Astek accompagne ses clients internationaux dans le d\u00e9ploiement intelligent de leurs produits et de leurs services, et dans la mise en \u0153uvre de leur transformation digitale.\nDepuis sa cr\u00e9ation, le Groupe a fond\u00e9 son d\u00e9veloppement sur une forte culture d\u2019entrepreneuriat et d\u2019innovation, et sur l\u2019accompagnement et la mont\u00e9e en comp\u00e9tence de\nses 7800 collaborateurs\nqui s\u2019engagent chaque jour \u00e0 promouvoir la compl\u00e9mentarit\u00e9 entre les technologies num\u00e9riques et l\u2019ing\u00e9nierie des syst\u00e8mes complexes.\nRejoignez un Groupe en fort d\u00e9veloppement en France et \u00e0 travers le monde ayant r\u00e9alis\u00e9 un chiffre d\u2019affaires de 600 M\u20ac en 2023.\nTous les d\u00e9tails sur le Groupe sur le site https://astekgroup.fr. Et vous pouvez aussi nous suivre sur notre blog : https://blog.groupeastek.com.\nRencontrons-nous\nNotre projet commun vous plait ?\nPostulez \u00e0 cette annonce, et soyez transparent !\nMathilde, notre Talent Acquisition Officer, vous contactera pour un premier \u00e9change t\u00e9l\u00e9phonique.\nPuis vous rencontrerez Thomas, votre futur manager, avec lequel vous \u00e9changerez autour d\u2019Astek, de votre parcours, de vos attentes et de votre future mission.\nEnfin, vous rencontrerez Guillaume, notre Directeur de d\u00e9partement, avec lequel vous pourrez valider votre int\u00e9r\u00eat et ad\u00e9quation pour le poste et finaliser les \u00e9l\u00e9ments contractuels.\nNos Plus\nAstek est green et fait b\u00e9n\u00e9ficier ses salari\u00e9s d\u2019une indemnit\u00e9 kilom\u00e9trique v\u00e9lo\nUne politique CARE sur-mesure d\u00e9ploy\u00e9e par nos \u00e9quipes RH pour nos collaborateurs (https://astekgroup.fr/engagements)\nNotre charte de la Diversit\u00e9\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "Java",
                "R",
                "Go"
            ],
            "DataBase": [
                "SQL",
                " MongoDB"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [
                "Power BI"
            ],
            "Statistics": [],
            "CloudComputing": [],
            "DevTools": [
                "Git"
            ],
            "Os": [],
            "DBMS": [
                "PostgreSQL",
                "Oracle"
            ],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [],
            "FrSoftSkills": [],
            "EnSoftSkils": []
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [
                "CDI"
            ],
            "Salary": [],
            "Level": [
                "Bac+5"
            ],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "Alternant - Data Engineer H/F",
        "company": "ALLIANCE EMPLOI",
        "location": "La Couture, Hauts-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/alternant-data-engineer-h-f-at-alliance-emploi-3913991795?position=4&pageNum=40&refId=PlhdJ%2BvRBuQPyL9EJS3cmw%3D%3D&trackingId=D4Pqp4d97XFIilzjFbjMyQ%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "La campagne \" alternance2024 \" est lanc\u00e9e ! \u00cates-vous pr\u00eat(e) \u00e0 monter en comp\u00e9tences et acqu\u00e9rir de l'exp\u00e9rience ? Avec 25 ans d'expertise, 2000 salari\u00e9s et notre r\u00e9seau de 400 entreprises issues des secteurs industriel, agroalimentaire, automobile, m\u00e9tallurgie, pharmaceutique, sid\u00e9rurgie ou encore logistique, nous sommes la destination id\u00e9ale pour celles et ceux qui cherchent une alternance.\nLaur\u00e9at 2021 des P\u00e9pites de l'alternance, notre mission est simple : apporter la bonne comp\u00e9tence au bon moment. Et c'est l\u00e0 que vous entrez en jeu !\nNous sommes \u00e0 la recherche d'un Alternant - Data Engineer (H/F) en alternance pour une entreprise partenaire sp\u00e9cialis\u00e9e dans la chimie pour une dur\u00e9e de 12 \u00e0 24 mois au sein du Utilit\u00e9s qui a en charge la fourniture d'utilit\u00e9s pour l'ensemble du site.\nLe poste et les missions ?\nInformatique\nModernisation des pratiques de collecte de donn\u00e9es industrielles,\nCr\u00e9ation d'interface saisie d'encours de production\nRefonte des rapports d'exploitation\nAlgorithme de num\u00e9risation des rapports PDF\nAutomatisation des archivages\nGestion des datas consolid\u00e9es\nStatisitques\nInt\u00e9gration des statistiques au coeur des syst\u00e8mes de production\nCartes de contr\u00f4les\nPr\u00e9visions statistiques\nEtude d'implantation de machine learning\nAlgorithme de traitement et nettoyage des donn\u00e9es (analyse de la d\u00e9rive)\nOrganisationnel\nD\u00e9ploiement des solutions de power BI au sein du service\nOutils d'affiche, de partage et d'analyse de donn\u00e9es\nAnalyse fonctionnelle des flux de donn\u00e9es\nR\u00e9daction des logigrammes de gestion de donn\u00e9es\nR\u00e9daction des bonnes pratiques d'archivage et de traitement de don\u00e9nes\nFormation des utilisateurs et propri\u00e9taires\nCe que nous allons aimer chez vous ?.\nVous avez le sens de l'organisation et du service, une capacit\u00e9 \u00e0 s'int\u00e9grer dans un milieu technique de terrain, vous avez le sens de l'organisation et des priorit\u00e9s, vous \u00eates rigoureux\nMais aussi :\nVous pr\u00e9parez un dipl\u00f4me d'ing\u00e9nieur Bac +4 / 5 en informatique et analyse de donn\u00e9es\nVous ma\u00eetrisez le d\u00e9veloppement informatique (base de donn\u00e9es, Python, Java)\nLes avantages de rejoindre Alliance Emploi\nContrat : ALTERNANCE de 12 \u00e0 24 mois\nD\u00e9but : Septembre 2024\nLieu : LESTREM [ site non accessible en transport en commun]\nR\u00e9mun\u00e9ration : Selon le bar\u00e8me de l'alternance\nEt aussi : int\u00e9ressement, mutuelle, pr\u00e9voyance, CSE, formations qualifiantes\nEt ce n'est pas tout ! En choisissant Alliance Emploi, vous vivrez une exp\u00e9rience bas\u00e9e sur la confiance, la solidarit\u00e9 et l'engagement. Vous d\u00e9velopperez vos comp\u00e9tences \u00e0 travers une diversit\u00e9 de missions et notre r\u00e9seau d'entreprises, et nous nous engageons \u00e0 vous proposer un accompagnement personnalis\u00e9 pour booster votre carri\u00e8re.\nAlors convaincu(e) ?\nN'attendez plus pour postuler et venez d\u00e9couvrir la diff\u00e9rence Alliance Emploi !\nLa diversit\u00e9 est une force. Nous sommes engag\u00e9s pour l'inclusion en offrant des opportunit\u00e9s de carri\u00e8re \u00e0 toutes les personnes, ind\u00e9pendamment de leur genre ou de leur situation de handicap.\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "Java",
                "R",
                "Go"
            ],
            "DataBase": [],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [
                "Power BI"
            ],
            "Statistics": [
                "Statistiques"
            ],
            "CloudComputing": [],
            "DevTools": [],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [
                "Machine Learning",
                "Statistiques"
            ],
            "FrSoftSkills": [
                "Organisation"
            ],
            "EnSoftSkils": []
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s",
                "25",
                "25",
                "25"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "Data engineer & BI (IT) / Freelance",
        "company": "Free-Work",
        "location": "Gennevilliers, \u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/data-engineer-bi-it-freelance-at-free-work-3891617843?position=5&pageNum=40&refId=PlhdJ%2BvRBuQPyL9EJS3cmw%3D%3D&trackingId=ofPaeu5UIMHyncbiJE4gfQ%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Data engineering : mise \u00e0 disposition des donn\u00e9es dans le datalake au format\ndelta lake (Azure Databricks)\n\u25aa Conception des flux data\n\u25aa D\u00e9veloppement des pipelines de donn\u00e9es avec ADF et\nDatabricks (ingestion Bronze/ Impl\u00e9mentation Silver)\n\u25aa Mise en \u0153uvre avec le superviseur des flux du monitoring de ceux-ci\n\u25aa Int\u00e9gration des tests unitaires\nAnalyse & BI :\n\u25aa Analyse des besoins\n\u25aa Conception, \u00e9laboration et d\u00e9ploiement des rapports et tableaux de bord\nsous Power BI \u00e0 partir du Gold\n\u25aa Mod\u00e9lisation des datamarts\n\u25aa Analyses de donn\u00e9es et Requ\u00eatages\n\u25aa Maintenance \u00e9volutive et corrective\nCoordination des intervenants SI\nR\u00e9daction de sp\u00e9cifications & Documentation\nMise en place des exigences RGPD/SSI\nProfil candidat:\nProfil confirm\u00e9 Technico-Fonctionnel :\nIncontournable :\nExp\u00e9rience de mise en \u0153uvre de data platform Databricks & de projets BI\nConnaissances et exp\u00e9riences sur Azure Data Factory et Azure Databricks\nSQL (niveau confirm\u00e9)\nPower BI, DAX\nForce de proposition\nRigoureux et autonome\nAppr\u00e9ciables :\nSQL Server SSIS, SSRS\nDev Python\nGit Azure Devops\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "R",
                "Go"
            ],
            "DataBase": [
                "SQL"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [
                "Databricks"
            ],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [
                "Tableau",
                "Power BI"
            ],
            "Statistics": [],
            "CloudComputing": [
                "Azure"
            ],
            "DevTools": [
                "Git"
            ],
            "Os": [],
            "DBMS": [
                "SQL Server"
            ],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [
                "DevOps"
            ],
            "FrSoftSkills": [],
            "EnSoftSkils": []
        },
        "details": {
            "JobDetail": [
                "Confirm\u00e9"
            ],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "Alternance Data Engineer (H / F)",
        "company": "Servier",
        "location": "Suresnes, \u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/alternance-data-engineer-h-f-at-servier-3906489264?position=8&pageNum=40&refId=PlhdJ%2BvRBuQPyL9EJS3cmw%3D%3D&trackingId=gFDTjOYYRhDTsVSpW5mpfw%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Description du poste :\nLe Groupe Servier m\u00e8ne une transformation digitale ambitieuse avec un objectif clair de devenir \u00ab\u00a0best in class Digital Performer\u00a0\u00bb. La Data Factory joue un r\u00f4le central dans cette ambition et a un impact fort \u00e0 chaque \u00e9tape de la chaine de valeur. Depuis la recherche de nouvelles mol\u00e9cules, la pr\u00e9diction de leur comportement, l\u2019analyse d\u2019efficacit\u00e9 des traitements en passant par l\u2019optimisation des processus de production des m\u00e9dicaments, la gestion des stocks et la pr\u00e9vision des ruptures jusqu\u2019\u00e0 l\u2019approche omnicanale et personnalis\u00e9e aupr\u00e8s des professionnels de sant\u00e9, le suivi des patients\u2026 : tous ces enjeux s\u2019appuient sur la Data et sa puissance transformante.\nRattach\u00e9e \u00e0 la Direction Digital, Data & IS, la Data Factory \u0153uvre pour rendre les donn\u00e9es accessibles, les valoriser \u00e0 travers des produits data m\u00e9tiers \u00e0 base d\u2019IA et d\u2019Advanced Analytics, et transformer Servier en un groupe orient\u00e9e data (\u00ab\u00a0Data-driven\u00a0\u00bb) o\u00f9 tous les collaborateurs connaissent les enjeux de la data.\nLa cr\u00e9ation des produits Data s\u2019appuie sur une \u00ab\u202fplateforme Data \u00bb centrale, cloud-native, s\u00e9curis\u00e9e et performante avec les technologies les plus avanc\u00e9es. Servier a \u00e9tabli un partenariat strat\u00e9gique de cinq ann\u00e9es avec Google Cloud, lui donnant acc\u00e8s \u00e0 des technologies innovantes et des liens privil\u00e9gi\u00e9s avec ses experts, et permettant de disposer d\u2019une puissance de calcul augment\u00e9e, d\u2019acc\u00e9l\u00e9rer l\u2019analyse et de d\u00e9velopper l\u2019innovation sur de nombreux d\u00e9fis business et technologiques.\nAu sein de la Data Factory, et en lien avec les autres p\u00f4les de la Data Factory, le Chapter TechLead a pour mission de pourvoir en ing\u00e9nieur les diff\u00e9rentes \u00e9quipes produits et les \u00e9quipes enablers afin de d\u00e9velopper les data pipeline (ingestion, Exposition), outils, software n\u00e9cessaire au produit. Les ing\u00e9nieurs sont aussi responsables de tester, de documenter le code ainsi que le maintien en condition op\u00e9rationnel de ce code.\nAfin d\u2019accompagner le Global Data Office, vous serez charg\u00e9(e) de\u00a0:\nEcrire le code n\u00e9cessaire au produit\nTester et documenter le code\nD\u00e9ployer le code dans les diff\u00e9rents environnements\nFaire de la veille autour des enjeux et opportunit\u00e9s de la Data dans un groupe pharmaceutique,\nContribuer \u00e0 votre fa\u00e7on \u00e0 la transformation digitale du groupe, et participer \u00e0 la construction dynamique de la Data Factory\nDescription du profil :\nVotre formation :\nEcole d\u2019ing\u00e9nieur en informatique ou/et data science\nVos comp\u00e9tences :\nMaitrise des langages de programmation python et SQL\nCuriosit\u00e9 pour les nouvelles technologies et l\u2019innovation au sens large\nMa\u00eetrise des outils collaboratifs et de la suite office (Word, Excel, PowerPoint, et SharePoint)\nRigueur, votre sens du d\u00e9tail, capacit\u00e9s d'analyse et de synth\u00e8se, autonomie et bon relationnel\nExcellentes aptitudes interpersonnelles, \u00e9coute, empathie, assertivit\u00e9, esprit d\u2019\u00e9quipe\nInd\u00e9pendance, organisation et capacit\u00e9 \u00e0 g\u00e9rer plusieurs sujets en m\u00eame temps\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "R",
                "Go"
            ],
            "DataBase": [
                "SQL"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [],
            "DevTools": [
                "Git"
            ],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [
                "Cloud"
            ],
            "FrSoftSkills": [
                "Empathie",
                "Organisation"
            ],
            "EnSoftSkils": []
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "Staff Data Ops Engineer (x/f/m)",
        "company": "Doctolib",
        "location": "Paris, \u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/staff-data-ops-engineer-x-f-m-at-doctolib-3824234041?position=9&pageNum=40&refId=PlhdJ%2BvRBuQPyL9EJS3cmw%3D%3D&trackingId=RX46B7dYVz9kKnrZFyVlog%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "About Doctolib\nDoctolib is a purpose-led company that strives for a healthier world with more than 2,800 employees across France, Italy, and Germany. Since 2013, Doctolib has been improving the daily lives of more than 340,000 healthcare professionals by providing them with new-generation technology and services. Doctolib also serves more than 80 million Europeans, offering a fast, frictionless and secure journey for all their care needs.\nWe are currently looking for a Data Ops to help us build and develop the data architecture that will enable Doctolib to offer its users an ever more efficient service.\nAn important point at Doctolib: personal data is fully encrypted and anonymized, and security requirements are extreme.\nYour tasks\nBuild and maintain Doctolib's data architecture;\nGuarantee the maintainability and scalability of the various components, relying on the services of Doctolib's cloud provider and all Devops best practices;\nAdapt the technical stack to anticipate user needs and the limits of existing systems;\nEvaluate new market technologies and their potential within the stack;\nCollaborate with Data Engineers, Data Scientists, Security teams and developers to develop future Data-driven functionalities within Doctolib products;\nParticipate in team improvement and agile rituals.\nWho you are :\nIf you don\u2019t meet all the requirements below but believe this opportunity matches your expectations and experience, we still encourage you to apply!\nYou have significant experience in the Data world, including at least 3 years in Data Ops / DevOps.\nYou have an interest in Big Data technologies\nYou're familiar with Terraform and Docker\nYou have an interest in code and Python\nYou have a good knowledge of data transformation tools and AWS services\nYou like to innovate and make Data architectures evolve towards greater scalability\nWhat we offer\nA stock-option program for each Doctoliber\nA competitive health insurance paid 100% by the company\nA dedicated onboarding program - the Doctolib Academy\nMental health and wellbeing offer in partnership with moka.care\nThe Doctolib Parent Care Program, including extended parental leave, meet-ups and inspiring conferences\nA subsidy from the work council to refund part of the membership to a sport club or a creative class\nSubsidy for lunch and various food offers in our offices\nA flexible workplace policy offering both hybrid and office-based mode\nFlexibility days allowing to work in EU countries and the UK 10 days per year\nThe interview process\nRecruiter Interview\nCase study to do at home + technical interview with the team\nTeam Meeting\nReference check\nOffer !\nIf you would like to find out more about tech life at Doctolib, feel free to read our latest Medium blog articles!\nAt Doctolib, we believe in improving access to healthcare for everyone - regardless of where you come from, what you look like. This translates into our recruitment process: Doctolib is an equal opportunity employer. We don't just accept diversity at Doctolib, we respect and celebrate it!\nThe more diverse ideas are heard, the more our product will truly improve healthcare for all. You are welcome to apply to Doctolib, regardless of your gender, religion, age, sexual orientation, ethnicity, disability, or place of origin. If you have a disability, let us know if there's any way we can make the interview process smoother for you!\nAll the information transmitted via this form is processed by Doctolib for the purpose of managing applications. For more information on how Doctolib processes your application data, click\nhere\n.\nIf you wish to exercise your rights or if you have any questions about the processing of your data, you can write to us at\nhr.dataprivacy@doctolib.com\n.\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "Scala",
                "R",
                "Go"
            ],
            "DataBase": [],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [
                "AWS"
            ],
            "DevTools": [
                "Docker"
            ],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [
                "Terraform"
            ],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [
                "Docker"
            ],
            "Collaboration": [
                "Teams"
            ],
            "Other": [
                "DevOps",
                "Big Data",
                "Cloud"
            ],
            "FrSoftSkills": [],
            "EnSoftSkils": [
                "Flexibility"
            ]
        },
        "details": {
            "JobDetail": [
                "Full"
            ],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "Data Engineer - H/F",
        "company": "MARGO",
        "location": "Paris, \u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/data-engineer-h-f-at-margo-3816671828?position=10&pageNum=40&refId=PlhdJ%2BvRBuQPyL9EJS3cmw%3D%3D&trackingId=dizlXreGGcB%2BlipDGTUbAg%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Entit\u00e9 experte\nde Margo Group des probl\u00e9matiques\nData, Cloud et DevOps\ncr\u00e9\u00e9e en 2020 par leurs fondateurs Rapha\u00ebl et Mounir. Aujourd\u2019hui\n60 consultants\nont int\u00e9gr\u00e9 l'entit\u00e9 et nous avons commenc\u00e9 \u00e0 travailler avec\n18 nouveaux clients\n(Banque, Industrie, Assurance, \u00c9nergie, E commerce, Sant\u00e9). A leurs c\u00f4t\u00e9s, vous pourrez \u00e9voluer rapidement et d\u00e9velopper de nouvelles comp\u00e9tences.\nDeux ADN fondateurs forts\net sp\u00e9cifiques \u00e0 Margo Analytics \u00e0 l\u2019origine de l\u2019entit\u00e9 :\n- Toujours se positionner sur\nles plus beaux sujets\net sur les\nmissions \u00e0 fortes valeurs ajout\u00e9es\n- Recruter\ndes\nconsultants passionn\u00e9s\net\ncurieux\nqui cherchent \u00e0 \u00eatre\nchalleng\u00e9s\nAujourd\u2019hui, Margo Analytics poss\u00e8de 4 communaut\u00e9s\nde comp\u00e9tences :\n- Data engineer\n- Data Science/ IA\n- Galaxy OPS (devOps, dataOps, cloudOps)\n- Architecte Big Data\nAinsi en rejoignant Margo Analytics vous aurez le choix des missions (#consultantfirst) sur lesquelles vous souhaitez travailler. Vous serez accompagn\u00e9 par les deux fondateurs ainsi que par le leader de votre communaut\u00e9, dont les r\u00f4les sont de rechercher le projet qui correspondra le plus \u00e0 vos attentes et de vous accompagner dans votre carri\u00e8re.\n\ud83c\udfafLes missions Margo Analytics :\nAu sein de la communaut\u00e9 Data Engineer vos missions\nseront\n:\n-\nD\u00e9velopper en mode agile\nles cas d\u2019usages m\u00e9tier\n- Mettre en place des\nprocessus de collecte, d\u2019organisation, de stockage et de mod\u00e9lisation des donn\u00e9es\n- D\u00e9velopper des traitements de transformation et de production de donn\u00e9es\n- Assurer la\nmise en production des mod\u00e8les de pr\u00e9diction\ncr\u00e9\u00e9s par les Data Scientists\n- Participer \u00e0 l\u2019\nam\u00e9lioration continue\net au refactoring de code\nBesoin de projection ? Voici un exemple de mission :\nCamille accompagne un grand compte dans le domaine de l\u2019industrie sur son projet de mise en place d\u2019un nouveau datalake en Azure databricks. L\u2019objectif de cette mission est d\u2019assurer la distribution de la donn\u00e9e de mani\u00e8re optimis\u00e9e pour cr\u00e9er une couche de distribution et permettre aux Data Scientists d\u2019impl\u00e9menter les use cases. Camille apporte son expertise sur les technologies suivantes : Spark, Scala, Azure, Databricks.\nNos stack Technique :\n- Langage : Python/Scala/Java\n- Framework : Spark/Hadoop\n- Cloud: Azure/ AWS/ GCP\n\ud83d\ude4c Les avantages :\n- Tickets restaurants Swile\n- Mutuelle Alan prise en charge \u00e0 100%\n- Pass Navigo pris en charge \u00e0 100%\n- T\u00e9l\u00e9travail\n- Formations illimit\u00e9es\n- Locaux en plein coeur de Paris\n- Places en cr\u00e8ches\n\ud83e\udd1dNotre processus de recrutement :\nNotre processus de recrutement se fait en 3 \u00e9tapes, r\u00e9parties sur 7 \u00e0 15 jours maximum :\n- Premi\u00e8re rencontre !\nVous \u00e9changez avec un RH et un dirigeant sur votre parcours, vos aspirations professionnelles ainsi que sur Margo Analytics et les opportunit\u00e9s que nous proposons\n-\nChallengez-vous\ndans le cadre d\u2019un entretien technique avec l\u2019un de nos experts. C\u2019est \u00e9galement l\u2019occasion pour vous d\u2019avoir son retour d\u2019exp\u00e9rience\n- Dernier entretien de motivation\n: pour finir, vous rencontrez un membre du board de Margo Analytics pour un entretien final\n\ud83d\udd0d Vous \u00eates un(e) futur(e) Margo Analytics si :\nMust-Have\nVous \u00eates issu(e) d\u2019une \u00e9cole d\u2019ing\u00e9nieur ou d\u2019un cursus universitaire \u00e9quivalent niveau Bac + 5\n/ Master\nVous aimez coder et vous \u00eates passionn\u00e9(e) d\u2019informatique et de Data\nVous \u00eates curieux(se) et vous vous int\u00e9ressez aux derni\u00e8res technologies du march\u00e9\nVous justifiez d\u2019une premi\u00e8re exp\u00e9rience en tant que Data Engineer\nNice to Have\nVous \u00eates ambitieux(se) et n\u2019avez pas peur de travailler sur des projets challengeants dans des environnements \u00e0 fortes contraintes techniques . Vous parlez et comprenez l\u2019anglais.\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "Java",
                "Scala",
                "R",
                "Go"
            ],
            "DataBase": [],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [
                "Hadoop",
                "Spark",
                "Databricks"
            ],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [
                "AWS",
                "Azure"
            ],
            "DevTools": [],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [
                "DevOps",
                "Big Data",
                "Cloud"
            ],
            "FrSoftSkills": [
                "Organisation"
            ],
            "EnSoftSkils": []
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "Backend Data Engineer | Python - AWS | Plateforme SaaS BtoB - Culture et sport | Paris (1 jour sur site/semaine))",
        "company": "Octopus IT - Expert du recrutement tech",
        "location": "Paris, \u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/backend-data-engineer-python-aws-plateforme-saas-btob-culture-et-sport-paris-1-jour-sur-site-semaine-at-octopus-it-expert-du-recrutement-tech-3837199239?position=1&pageNum=42&refId=hZyb1K8CoeqwCyZyTWnF7w%3D%3D&trackingId=rw9KnhS4AN95GIKeUl9F8g%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "La soci\u00e9t\u00e9\nCette Start-up fond\u00e9e par une \u00e9quipe de Data Scientists, a d\u00e9velopp\u00e9 un logiciel SaaS BtoB au service des diff\u00e9rentes structures culturelles et sportives.\nLes clients (th\u00e9\u00e2tres, mus\u00e9es, clubs de sport professionnels, salles de spectacles,...)\nutilisent la solution afin de mieux comprendre et valoriser leurs donn\u00e9s et de d\u00e9velopper leurs publics de demain.\nNovateur, cette solution compl\u00e8te, centralise et automatise les donn\u00e9es venant de la billetterie, cashless, boutique en ligne ...\nElle permet d\u2019analyser finement les publics (BI) et de mettre en place des strat\u00e9gies de marketing innovantes. Notre solution, \u00e0 la pointe de la technologie, ainsi que l\u2019accompagnement de nos clients au quotidien par notre \u00e9quipe d'experts d\u00e9di\u00e9s, nous positionnent comme leader sur le march\u00e9 fran\u00e7ais.\nMieux connaitre son client, ses envies et go\u00fbts est primordial pour s'adresser de mani\u00e8re personnalis\u00e9 et percutante \u00e0 lui !\nLa soci\u00e9t\u00e9, est rentable et en forte croissance en 2020 et 2021.\nLe poste\nUne \u00e9quipe de 20 personnes dont 6 \u00e0 la tech passionn\u00e9s qui ne demande qu'\u00e0 en accueillir d'autres autour de valeurs fortes et assum\u00e9es : bienveillance, transparence et combativit\u00e9.\nLe Backend Engnineer travaillera au sein de l\u2019\u00e9quipe technique, en synergie avec le CTO.\nLes missions du poste\n:\nAm\u00e9liorer la maintenabilit\u00e9 et le monitoring des ETL\nMettre en place et d\u00e9velopper des API\nD\u00e9velopper de nouvelles features\nD\u00e9veloppement de nouveaux pipelines de donn\u00e9es pour aller r\u00e9cup\u00e9rer la Data n'importe o\u00f9\nOptimiser et challenger l'environnement technique existant\nStack : Python (Django, Flask) Vue.js, PostgreSql, AWS\nLes \u00e9volutions \u00e0 venir d\u00e9pendront majoritairement de vous et de vos pr\u00e9conisations.\nVotre profil\nVous avez un esprit vif et \u00eates capable d\u2019apprendre vite de nouvelles technologies ou de nouveaux langages\nVous \u00eates \u00e0 l'aise avec du Python et du Sql et vous avez \u00e0 partir de 2 ans d'exp\u00e9rience\nVous travaillez avec beaucoup de rigueur, vous recherchez l'efficacit\u00e9 tout en faisant les choses dans les r\u00e8gles de l'art et avec les bonnes pratiques du d\u00e9veloppement logiciel\nVous avez l'habitude de travailler avec des API\nVous avez une parfaite connaissance de l\u2019architecture d\u2019une plateforme web\nLe plus : connaissance des ETL et technologie de scraping de donn\u00e9es.\nLe salaire & avantages\n50-55K\u20ac selon exp\u00e9rience\n4 jours de remote/ 1 jours de pr\u00e9sentiel\nCarte de transport\nCarte Swile & mutuelle\nEt plus encore\u2026\nCe qu\u2019on pr\u00e9f\u00e8re\nAmbiance start-up, humaine et vivante avec de nombreux \u00e9v\u00e9nements organis\u00e9s\nDe nombreuses responsabilit\u00e9s sont confi\u00e9es \u00e0 tous les postes\nM\u00e9thodes Agiles (Scrum) dans une \u00e9quipe qui a une vraie vision agile\nCe poste a \u00e9t\u00e9 soigneusement choisi par votre coach. Powered by Octopus IT, cabinet d\u2019Experts en Recrutement Tech (CDI et clients finaux uniquement) \u2013 Visitez nous pour plus d\u2019opportunit\u00e9s :\nwww.octopusit.fr\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "R",
                "Go"
            ],
            "DataBase": [
                "SQL"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [
                "AWS"
            ],
            "DevTools": [],
            "Os": [],
            "DBMS": [
                "PostgreSQL"
            ],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [],
            "FrSoftSkills": [],
            "EnSoftSkils": []
        },
        "details": {
            "JobDetail": [
                "Remote"
            ],
            "TypeContract": [
                "CDI"
            ],
            "Salary": [
                "50"
            ],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s",
                "2",
                "2",
                "2"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "Data Analyst (F/H)",
        "company": "FBD Group",
        "location": "Tremblay-en-France, \u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/data-analyst-f-h-at-fbd-group-3886652484?position=2&pageNum=42&refId=hZyb1K8CoeqwCyZyTWnF7w%3D%3D&trackingId=7TfIusgG6zvJO9lRTIEq%2Bw%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Vous aimez :\nConduire le changement dans le secteur de la distribution\nPartager les challenges d\u2019une entreprise agile en forte croissance\nL\u2019esprit d\u2019\u00e9quipe et l\u2019ambiance qui r\u00e8gnent dans un groupe \u00e0 taille humaine (250 collaborateurs)\nL\u2019innovation, le num\u00e9rique et les nouvelles technologies au service de l\u2019exp\u00e9rience client\nLa gestion de projet\nVous aimerez accompagner l\u2019entreprise dans son \u00e9volution en \u00e9tant un agitateur d'id\u00e9es.\nRattach\u00e9(e) au Responsable Performance, vous aurez pour objectif principal le recueil, l\u2019analyse et l\u2019interpr\u00e9tation de la donn\u00e9e de l\u2019entreprise. Ces donn\u00e9es peuvent \u00eatre li\u00e9es aux clients (CRM), aux produits et \u00e0 leurs performances, ou m\u00eame aux concurrents.\nEn collaboration \u00e9troite avec les autres p\u00f4les de la Direction Digitale, les \u00e9quipes Commerce, les \u00e9quipes Marketing, et les \u00e9quipes IT, ainsi que les autres Directions support du Groupe, vous construirez, exploiterez et interpr\u00e9terez les donn\u00e9es pour en d\u00e9gager des observations business utiles.\nMissions Principales :\nEchanger avec les diff\u00e9rentes \u00e9quipes internes concern\u00e9es pour comprendre leurs besoins et leurs enjeux\nD\u00e9finir les indicateurs cl\u00e9s de performance (KPI) avec les parties prenantes pour mesurer la tenue des objectifs\nMettre en place ou optimiser les outils de suivi et de pr\u00e9vision avec la DSI\nAnalyser les bases de donn\u00e9es\nSynth\u00e9tiser les r\u00e9sultats de ces analyses pour les communiquer aux bons interlocuteurs\nProposer des plans d\u2019action (mise en place d\u2019outils, d\u00e9finition des processus\u2026)\nIdentifier les probl\u00e8mes et proposer des solutions appropri\u00e9es\nAssurer la qualit\u00e9 et la fiabilit\u00e9 des donn\u00e9es\nEtablir une cartographie des donn\u00e9es utilis\u00e9es au sein des analyses pour une meilleure compr\u00e9hension des interlocuteurs\nMissions D\u00e9taill\u00e9es :\nRecueil des besoins\nEchanger avec les diff\u00e9rentes \u00e9quipes internes concern\u00e9es pour comprendre leurs besoins et leurs enjeux\nD\u00e9finir les indicateurs cl\u00e9s de performance (KPI) avec les parties prenantes pour mesurer la tenue des objectifs\nMod\u00e9liser les donn\u00e9es n\u00e9cessaires \u00e0 l\u2019analyse\nCollecte des donn\u00e9es\nRecueillir et extraire les sources de donn\u00e9es pertinentes (savoir o\u00f9 les trouver) et de qualit\u00e9, \u00e0 traduire ensuite en donn\u00e9es statistiques\nAssurer la qualit\u00e9 et la fiabilit\u00e9 des donn\u00e9es\nIdentifier les probl\u00e8mes (donn\u00e9es manquantes, qualit\u00e9 insuffisante, stockage, centralisation, etc.) et proposer des solutions appropri\u00e9es en exprimant le besoin associ\u00e9 aux \u00e9quipes IT\nTraitement\nProposer des plans d\u2019action :\nMettre en place des process/requ\u00eates et des automatisations\nMettre en place ou optimiser les outils de suivi et de pr\u00e9vision avec la DSI\nTrouver de nouvelles fa\u00e7ons de traiter la donn\u00e9e avec l\u2019appui de nouveaux outils, au vu de l\u2019accroissement consid\u00e9rable du nombre de donn\u00e9es\nAnalyse\nD\u00e9finir et g\u00e9rer des outils d\u2019analyse et d\u2019aide \u00e0 la d\u00e9cision : pr\u00e9visions et objectifs de vente, tableaux de bord, indicateurs de performance, analyse de la conjoncture et des march\u00e9s, suivi de la performance et appui aux \u00e9quipes commerciales\nAnalyser les bases de donn\u00e9es, produire des analyses m\u00e9tiers et proposer des recommandations aux managers\nS\u2019assurer de la coh\u00e9rence des r\u00e9sultats par rapport au commerce et \u00e0 l\u2019activit\u00e9 r\u00e9elle en point de vente\nCommunication\nCr\u00e9er des Dashboard, mettre en place des KPIs et des reportings de performance\nConstruire et faire \u00e9voluer les rapports issus de la Business Intelligence (BI) & Web Analytics\nSynth\u00e9tiser les r\u00e9sultats de ces analyses pour les communiquer aux bons interlocuteurs\nEtablir une cartographie des donn\u00e9es utilis\u00e9es au sein des analyses pour une meilleure compr\u00e9hension des interlocuteurs\nDiffuser et assurer la bonne interpr\u00e9tation et la bonne compr\u00e9hension des rapports d\u2019analyse\nTransverse\nFaire preuve de proactivit\u00e9 pour explorer les donn\u00e9es disponibles et proposer des analyses non sollicit\u00e9es\nR\u00e9aliser une veille marketing et commerciale sur la concurrence et proposer des analyses associ\u00e9es\nContribuer \u00e0 l\u2019analyse des parcours omnicanaux et \u00e0 la recherche de leviers de croissance\nExplorer les opportunit\u00e9s d\u2019application de l\u2019IA dans la Data Analyse\nR\u00e9aliser des \u00e9tudes qualitatives sur diff\u00e9rentes probl\u00e9matiques business\nParticiper \u00e0 la mesure \u00e9conom\u00e9trique des campagnes d\u2019acquisition ainsi qu\u2019\u00e0 la mesure de l\u2019attribution/contribution des diff\u00e9rents leviers marketing actionn\u00e9s\nExp\u00e9rience : 5 ans minimum en Data analyse, avec des connaissances en data engineering id\u00e9alement dans le secteur du retail\nFormation : Bac+5, cursus en math\u00e9matiques, statistiques, \u00e9conomie, marketing ou en informatique (id\u00e9alement Master en statistiques / \u00e9conom\u00e9trie ou Master sp\u00e9cialis\u00e9 en Big Data)\nLa maitrise de l\u2019anglais courant est n\u00e9cessaire\nSavoir-faire & comp\u00e9tences :\nMa\u00eetrise des bases de donn\u00e9es business (BigQuery, Snowflake, Redshift\u2026) et du langage SQL\nMaitrise de la construction d\u2019un Datawarehouse\nMa\u00eetrise d\u2019un outil d\u2019orchestration (DBT, Airflow\u2026) et du langage Python\nMa\u00eetrise d\u2019au moins un outil de dashboarding (Looker, Power BI, Tableau\u2026)\nMa\u00eetrise des librairies de manipulation de donn\u00e9es en Python (NumPy, Pandas, Matplotlib, SciPy, Scikit-learn)\nUne connaissance des outils tels que Hadoop ou Spark serait un plus\nCompr\u00e9hension des enjeux li\u00e9s \u00e0 la tra\u00e7abilit\u00e9 des donn\u00e9es (data lineage)\nUne connaissance m\u00e9tier, notamment en marketing et relation client est n\u00e9cessaire\nSavoir \u00eatre :\nGrande aisance \u00e9crite et orale pour optimiser la compr\u00e9hension et la communication avec les \u00e9quipes\nPassion pour les chiffres et les statistiques\nOrientation business pour faire des recommandations pertinentes et actionnables\nAisance relationnelle pour emporter l\u2019adh\u00e9sion des interlocuteurs\nEsprit de synth\u00e8se et analytique\nEsprit ouvert et comp\u00e9tences transverses pour appr\u00e9hender les probl\u00e9matiques techniques et les restituer de fa\u00e7on compr\u00e9hensible aux diff\u00e9rents publics\nRigoureux, organis\u00e9 et r\u00e9actif\nForce de proposition\nPrise de recul\nPourquoi nous rejoindre ?\nLa brigade\nUne Direction qui accorde une attention particuli\u00e8re au bien \u00eatre des collaborateurs : Nous sommes Great Place to Work !\nLes ingr\u00e9dients\nVous aurez tous les ustensiles n\u00e9cessaires pour votre recette (ordinateur, t\u00e9l\u00e9phone portable professionnel etc.)\nUne r\u00e9mun\u00e9ration fixe + Prime annuelle li\u00e9e \u00e0 vos objectifs + Prime de participation\nLes assaisonnements\nUne mutuelle familiale prise en charge \u00e0 100% par le Groupe FBD\nL\u2019acc\u00e8s \u00e0 un Restaurant Interentreprises\n2 jours de t\u00e9l\u00e9travail par semaine sans condition d\u2019anciennet\u00e9\nDes locaux \u00e0 Roissy \u00e0 200m du RER B et une annexe \u00e0 Paris 9\u00e8me\nUn r\u00e9seau social Entreprise pour vous mettre au courant et participer \u00e0 la vie d\u2019entreprise\nLa carte\nNotre menu est compos\u00e9e d\u2019ingr\u00e9dients divers et vari\u00e9s, ce qui en fait la richesse de ses plats.\nNous accordons une attention particuli\u00e8re \u00e0 lutter contre toute formes de discriminations, raison pour laquelle nous avons adh\u00e9r\u00e9 \u00e0 l'association A Comp\u00e9tences Egales qui \u0153uvre dans ce domaine.\nLa cerise sur le g\u00e2teau\nBoissons chaudes et fruits Bio \u00e0 disposition pour bien commencer la journ\u00e9e !\nDes activit\u00e9s tous les mois pour les collaborateurs, pr\u00e9par\u00e9s par notre service Com Interne + 2 \u00e9v\u00e8nements groupe par an.\nEn cuisine, le meilleur reste \u00e0 inventer ! Nous vous attendons !\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "R",
                "Go"
            ],
            "DataBase": [
                "SQL"
            ],
            "DataAnalytics": [
                "Pandas",
                "NumPy",
                "R"
            ],
            "BigData": [
                "Hadoop",
                "Spark"
            ],
            "MachingLearning": [
                "Scikit-Learn"
            ],
            "DataSerialization": [],
            "DataVisualization": [
                "Tableau",
                "Power BI",
                "Matplotlib"
            ],
            "Statistics": [
                "Statistiques"
            ],
            "CloudComputing": [],
            "DevTools": [
                "Git"
            ],
            "Os": [],
            "DBMS": [
                "Snowflake",
                "Snowflake",
                "BigQuery"
            ],
            "SoftBigDataProcessing": [],
            "Automation": [
                "Airflow"
            ],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [
                "Big Data",
                "Statistiques"
            ],
            "FrSoftSkills": [
                "Communication",
                "Collaboration"
            ],
            "EnSoftSkils": [
                "Communication",
                "Collaboration"
            ]
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [],
            "Salary": [],
            "Level": [
                "Bac+5"
            ],
            "Experience": [
                "a",
                "n",
                "s",
                "5",
                "5",
                "5"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "Data Engineer",
        "company": "Lyreco France",
        "location": "Valenciennes, Hauts-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/data-engineer-at-lyreco-france-3918198650?position=3&pageNum=42&refId=hZyb1K8CoeqwCyZyTWnF7w%3D%3D&trackingId=HJ%2Fkp3pwyyjqSMpJSYgSXQ%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Responsible for building systems that collect, manage, and convert raw data into usable information for\ndata scientists and business analysts to interpret.\nThe data engineer aims to make data accessible so that the organization can use it to evaluate and\noptimize its performance\nAre you excited for your new career adventure?\nAt Lyreco, we offer more than just a job, but a career! Our Data Storage Team is looking for a talented and ambitious new Data Engineer to join in HQ (Marly).\nLyreco is the European leader and the third largest distributor of workplace products and services in the world. A privately owned company since 1926, Lyreco has constantly adapted to the evolutions of workplace thanks to its focus on excellence in customer experience, strong partnerships with renowned suppliers, and efficient logistics.\nWith more than 12,000 employees, Lyreco directly operates in 25 countries in Europe and Asia and covers 17 additional markets on 4 continents through a network of distribution partners.\nYOUR MISSIONS:\nIndustrialize data integration, data cleansing, data analytics programs or data management processes.\nContribute to the design, development, testing, deployment, performance in production and maintenance of the data-centric software including APIs, cloud-based architectures, libraries, toolbox.\nLiaise with the Business Analysts, Data Scientists, Analytics specialist or Architects to understand how data needs to be: extracted, converted/transformed, loaded and exposed; consumed, calculated and updated.\nHelp the Data Architect to create an overview of the Data Lineage (from data flows, data transformations inside applications).\nProvide clear documentation of the business rules embedded in the systems and potentially manage or help solving Data Quality issues.\nAdapt to the central/ spokes\u2019 ecosystem and local context and standards\nYOUR PROFILE:\nDegree in Computer Science or relevant data field\nExperience in the area of trade working in projects\u2026 working in projects in Data Engineering, Big Data and/or Cloud environment using Apache Spark\nWorking experience with Cloudera Data Platform is a plus\nStructured yet agile approach \u2013 with good knowledge of the scrum agile methodology\nLanguages: SQL; Python\nBig Data & Streaming technologies (Hadoop/HDFS, Spark\u2026)\nNoSQL Databases (e.g. Hbase, MongoDB\u2026)\nFluency in written and spoken English\nREASONS TO JOIN LYRECO :\nA full- time job in a dynamic, passionate, international team\nPossibility to join internal mobility program\nCompetitive salary (bonus, benefits)\nYou will work in hybrid model in Valenciennes/Marly/France\nIf the above job description interests you and you think you are a good fit, apply now! We look forward to receiving your application in English.\n\u00cates-vous enthousiaste \u00e0 l'id\u00e9e de vivre une nouvelle aventure professionnelle ?\nChez Lyreco, nous offrons plus qu'un emploi, une carri\u00e8re ! Notre \u00e9quipe Data Storage est \u00e0 la recherche d'un Data Engineer H/F talentueux et ambitieux pour rejoindre notre \u00e9quipe au si\u00e8ge social.\nLyreco est le leader europ\u00e9en et le troisi\u00e8me distributeur mondial de produits et services pour l\u2019environnement de travail. Soci\u00e9t\u00e9 priv\u00e9e depuis 1926, Lyreco s'est constamment adapt\u00e9e aux \u00e9volutions du monde du travail gr\u00e2ce \u00e0 son souci d'excellence en mati\u00e8re d'exp\u00e9rience client, \u00e0 ses partenariats solides avec des fournisseurs renomm\u00e9s et \u00e0 sa logistique efficace.\nAvec plus de 12 000 employ\u00e9s, Lyreco op\u00e8re directement dans 25 pays d'Europe et d'Asie et couvre 17 autres march\u00e9s sur 4 continents par le biais d'un r\u00e9seau de partenaires de distribution.\nLyreco se pr\u00e9occupe des personnes.\nNous nous engageons \u00e0 offrir Une Excellente Journ\u00e9e de Travail \u00e0 nos clients et \u00e0 nos employ\u00e9s.\nCela signifie que chez Lyreco, nous cultivons activement les talents et veillons \u00e0 ce que tous nos employ\u00e9s aient une Une Excellente Journ\u00e9e de Travail. Afin de garantir le d\u00e9veloppement de nos employ\u00e9s, nous leur offrons une formation continue et une mobilit\u00e9 interne lorsque nous recrutons pour un poste vacant - Chez Lyreco, tout est possible !\nChez Lyreco, nous valorisons l'excellence, la passion, le respect et l'agilit\u00e9. Nous savons que les personnes sont au c\u0153ur de tout ce que nous r\u00e9alisons, c'est pourquoi chez Lyreco nous faisons de notre mieux pour soutenir nos employ\u00e9s o\u00f9 qu'ils travaillent, quelle que soit leur mission, en leur offrant la meilleure exp\u00e9rience professionnelle possible pour atteindre l'excellence.\nCE QUE NOUS PROPOSONS:\nIndustrialiser les programmes d'int\u00e9gration de donn\u00e9es, de nettoyage de donn\u00e9es, d'analyse de donn\u00e9es ou de gestion des donn\u00e9es.\nContribuer \u00e0 la conception, au d\u00e9veloppement, aux tests, au d\u00e9ploiement, \u00e0 la performance en production et \u00e0 la maintenance des logiciels ax\u00e9s sur les donn\u00e9es, y compris les API, les architectures bas\u00e9es sur le cloud, les biblioth\u00e8ques et les bo\u00eetes \u00e0 outils.\nCollaborer avec les analystes m\u00e9tier, les data scientists, les sp\u00e9cialistes de l'analyse ou les architectes pour comprendre comment les donn\u00e9es doivent \u00eatre : extraites, converties/transform\u00e9es, charg\u00e9es et expos\u00e9es ; consomm\u00e9es, calcul\u00e9es et mises \u00e0 jour.\nAider l'architecte de donn\u00e9es \u00e0 cr\u00e9er une vue d'ensemble de la lign\u00e9e des donn\u00e9es (\u00e0 partir des flux de donn\u00e9es, des transformations de donn\u00e9es \u00e0 l'int\u00e9rieur des applications).\nFournir une documentation claire des r\u00e8gles m\u00e9tier int\u00e9gr\u00e9es dans les syst\u00e8mes et potentiellement g\u00e9rer ou aider \u00e0 r\u00e9soudre les probl\u00e8mes de qualit\u00e9 des donn\u00e9es.\nS'adapter \u00e0 l'\u00e9cosyst\u00e8me central ou d\u00e9centralis\u00e9 et aux normes locales.\nCE QUE NOUS RECHERCHONS:\nFormation sup\u00e9rieure en informatique (Bac+4/5) ou en Big Data\nExp\u00e9rience dans le domaine du e-commerce travaillant sur des projets de Data Engineering, Big Data et/ou en environnement Cloud en utilisant Apache Spark Bonnes connaissances de la plateforme de donn\u00e9es Cloudera *\nApproche structur\u00e9e mais agile, avec une bonne connaissance de la m\u00e9thodologie agile Scrum\nBonnes connaissances des langages : SQL ; Python Technologies Big Data & Streaming (Hadoop/HDFS, Spark\u2026) , bases de donn\u00e9es NoSQL (par exemple, Hbase, MongoDB\u2026)\nMa\u00eetrise de l'anglais \u00e9crit et parl\u00e9\nLes \u00ab + \u00bb chez Lyreco Management\nUne exp\u00e9rience dans un environnement international.\nPrime sur objectifs.\nPrime de participation et prime d\u2019int\u00e9ressement.\nDes actions en faveur de l\u2019\u00e9quilibre vie professionnelle/ vie personnelle (conciergerie d\u2019entreprise, associations sportives, plateforme de covoiturage, cr\u00e8che d\u2019entreprise).\n\u00ab\u202fLyreco est signataire de la Charte de la diversit\u00e9. Nous garantissons le respect des r\u00e8gles de non-discrimination \u00e0 l'embauche et nous nous engageons \u00e0 aider les personnes \u00e9loign\u00e9es de l'emploi.\u202f\u00bb\nT\u00e9l\u00e9travail.\nEnvie de rejoindre l\u2019aventure Lyreco Management ? N\u2019attendez plus, transmettez-nous votre candidature !\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "R",
                "Go"
            ],
            "DataBase": [
                "SQL",
                "NoSQL",
                " MongoDB",
                "HBase"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [
                "Hadoop",
                "Spark"
            ],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [],
            "DevTools": [],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [
                "HBase"
            ],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [
                "Big Data",
                "Cloud"
            ],
            "FrSoftSkills": [],
            "EnSoftSkils": [
                "Organization"
            ]
        },
        "details": {
            "JobDetail": [
                "Full"
            ],
            "TypeContract": [],
            "Salary": [
                "1926"
            ],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "Data Engineer (F/H) - Nantes",
        "company": "SFEIR",
        "location": "Nantes, Pays de la Loire, France",
        "link": "https://fr.linkedin.com/jobs/view/data-engineer-f-h-nantes-at-sfeir-3477971987?position=4&pageNum=42&refId=hZyb1K8CoeqwCyZyTWnF7w%3D%3D&trackingId=vCFQNCficndPACYOQbG7LA%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "C'est quoi SFEIR ? \ud83e\udd14\nSFEIR, c'est avant tout une communaut\u00e9 de 900 techs en France, en Belgique et au Luxembourg.\nNous aidons nos clients \u00e0 :\n\ud83d\udd39 \u00catre compatible avec le futur en d\u00e9veloppant leurs architectures SI, Cloud et Data ;\n\ud83d\udd39 Donner de la valeur \u00e0 leurs donn\u00e9es, innover avec l'IA ;\n\ud83d\udd39Cr\u00e9ateur de valeur gr\u00e2ce aux API & microservices;\n\ud83d\udd39 D\u00e9velopper des applications web et mobiles pour am\u00e9liorer leur exp\u00e9rience client et se connecter partout.\nNotre culture d'entreprise est r\u00e9solument tourn\u00e9e vers l'expertise technologique, la transmission de connaissances et le respect de nos valeurs phares :\nbienveillance, inclusivit\u00e9, excellence, libert\u00e9, responsabilit\u00e9.\nEt Nantes dans tout \u00e7a ?\nSFEIR Nantes c'est :\n\ud83d\udd39 Une agence cr\u00e9e en 2018 par @Jean-Fran\u00e7ois Garreau , co-fondateur du DevFest Nantes\n\ud83d\udd39 Une trentaine de consultant(e)s qui se connaissent toutes et tous\n\ud83d\udd39 4 Managers qui sont aussi des consultants @Hoani , @Adrien , @Fr\u00e9d\u00e9ric , @Valentin\n\ud83d\udd39 Une dizaine de clients actifs en local et une centaine au niveau du groupe\n\ud83d\udd39 Des \u00e9v\u00e9nements en interne et en organis\u00e9s chaque mois (afterworks, meetup, formations)\n\ud83d\udd39 Une communaut\u00e9 active : une cinquantaine de conf\u00e9rences externes donn\u00e9es en 2022 (Devfest, Devoxx, communaut\u00e9 JS\u2026)\n\ud83d\udd39 Des locaux sur l'\u00eele de Nantes dans le b\u00e2timent totem du num\u00e9rique nantais.\nConcr\u00e8tement, quel sera mon job ?\nEn tant que Data Engineer en mission chez un client, ton r\u00f4le est d\u2019appr\u00e9hender son contexte et d'impl\u00e9menter une plateforme pour valoriser sa donn\u00e9e.\nTu es \u00e0 l\u2019aise sur l\u2019un des langages suivants :\nPython, Java, Scala et SQL\n; et tu as d\u00e9j\u00e0 utilis\u00e9 des\nframeworks de calculs distribu\u00e9s\n(Spark, Beam,\u2026).\nTu connais et utilises les diff\u00e9rentes\nsolutions de stockage\n(SQL, DWH, NoSQL, Search engine,Streaming...).\nTu connais les principes du d\u00e9veloppement Cloud, IaaC et des\ncha\u00eenes CI/CD\net tu as des connaissances en\nmachine learning.\nTu es curieux(se) et fais de la veille technologique.\n@Arthur et @Paul-Antoine , nos super commerciaux, seront \u00e0 ton \u00e9coute pour d\u00e9finir avec toi ta mission id\u00e9ale et tu pourras en changer lorsque tu en auras fait le tour.\nVoici des exemples de projets r\u00e9alis\u00e9s par des sfeiriens pour te donner une id\u00e9e :\n\ud83d\udd39\nOussama\na une mission au sein d'un acteur digital native, il s'agit de la mise en place d'une plateforme data (batch et stream) sur Google Cloud pour de l'analytics et du reporting interne (mises en relations, performances des assureurs, comportements utilisateurs...). La stack technique est compos\u00e9e de : Cloud Storage, Dataflow, Bigquery, Cloud Composer (Airflow), Datastudio, Terraform, GitLab.\n\ud83d\udd39\nPascal\na une mission dans le domaine de la sant\u00e9, il s'agit de la mise en place d'une plateforme s'adaptant automatiquement \u00e0 la charge de travail sur un Cloud provider pour analyser les donn\u00e9es issues du s\u00e9quen\u00e7age du g\u00e9nome de patients atteints d'un cancer afin d'aider au diagnostic. La stack technique est compos\u00e9e de : Kubernetes, DataFlow, BigQuery, MongoDB, elastisearch.\nEt si je souhaite \u00e9voluer ?\nNous proposons des possibilit\u00e9s d'\u00e9volution verticales et horizontales. Nous pourrons t'accompagner pour te certifier ou \u00e9valuer sur une autre sp\u00e9cialit\u00e9, ou encore devenir\nLead Data ou Data Architecte.\nTu auras \u00e9galement la possibilit\u00e9 de prendre des r\u00f4les en interne si tu le souhaites :\n\ud83d\udd39\n\u00c9valuateur(trice)\ndans le processus de recrutement\n\ud83d\udd39\nFormateur(trice)\naux Sfeir Schools ou au Sfeir Institute\n\ud83d\udd39\nSpeaker(euse)\nlors de conf\u00e9rences, meetups, talks internes, aupr\u00e8s des \u00e9coles\n\ud83d\udd39\nEngineering manager\nsi tu veux manager une \u00e9quipe tout en restant dans la technique\nEt si tu as d'autres envies, on en discute, chacun est diff\u00e9rent et on fait au cas par cas.\nJe suis int\u00e9ress\u00e9(e)\ud83d\ude42 , comment vous rejoindre ?\nSi cette annonce a fourni ton attention, il ne te reste plus qu'\u00e0 postuler.\n@Justine se font un plaisir de t'en dire plus \ud83d\ude42. Tu pourras ensuite te frotter \u00e0 nos c\u00e9l\u00e8bres\nPlayOffs\n: 3 tests d'\u00e9valuation technique en pair-programming (algorithmie, langage, framework). Ne t'en fais pas, nos \u00e9valuateur(trice)s sont bienveillant(e)s !\nEnfin, tu \u00e9changeras avec Arthur et Paul-Antoine au commerce et Jean-Fran\u00e7ois et @Arnaud , nos directeurs.\nChez Sfeir, la confiance, la bonne humeur et l'inclusion font partie de notre ADN.\nEn rejoignant notre communaut\u00e9, tu deviendras un(e) Sfeirien(ne) bienveillant(e), libre et responsable.\n#L\u2019inclusionEstUneForce: Notre process de recrutement inclusif assure une \u00e9galit\u00e9 de traitement et de chance aux candidats de tous horizons.\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "Java",
                "Scala",
                "R",
                "Go"
            ],
            "DataBase": [
                "SQL",
                "NoSQL",
                " MongoDB"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [
                "Spark"
            ],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [],
            "DevTools": [
                "Git"
            ],
            "Os": [],
            "DBMS": [
                "BigQuery"
            ],
            "SoftBigDataProcessing": [],
            "Automation": [
                "Kubernetes",
                "Airflow"
            ],
            "InfrastructureAsCode": [
                "Terraform"
            ],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [
                "Kubernetes"
            ],
            "Collaboration": [],
            "Other": [
                "Machine Learning",
                "Cloud",
                "CI/CD"
            ],
            "FrSoftSkills": [],
            "EnSoftSkils": []
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "Software Engineer",
        "company": "Orange Logic",
        "location": "France",
        "link": "https://fr.linkedin.com/jobs/view/software-engineer-at-orange-logic-3862540191?position=5&pageNum=42&refId=hZyb1K8CoeqwCyZyTWnF7w%3D%3D&trackingId=T5fgB%2B5g8k%2Bi3gxd161Chg%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "For more than two decades, Orange Logic has empowered a wide range of clients with its digital asset management system, Cortex. We\u2019ve worked with almost every industry, from Finance to NGOs, Media giants to educational institutions, securing and organizing their assets. The Software Engineer will enhance Orange Logic\u2019s software by participating in the design, development, maintenance and testing process.\nWhat you can expect in your role:\nTaking ownership of projects and having the opportunity to further your knowledge by exploring machine learning, security, DevOps, and more.\nDeveloping scalable new features for our software product that exceeds our customer\u2019s needs.\nBuilding architecture for our platform to ensure optimal performance.\nObtaining requirement feedback from internal teams/clients to maintain/support the product development.\nWrite the Unit Tests for robust development.\nPerforming code reviews on other team member\u2019s work.\nYou are:\nProficient with English (both verbal and written).\nHave 3+ years\u2019 practical experience on a web-based application.\nProficient with any backend programming languages (e.g. .NET, Java, Python, etc.).\nA strong fundamental understanding of software development.\nAn understanding of complex algorithms and data structures, as well as a passion for intellectual challenges.\nStrong self-discipline for delivering well-tested, complete features/modules under a tight schedule and the capability for rational thinking.\nExperience with the database management tool SQL is a plus, but not mandatory.\nObtained bachelor\u2019s degree in any relevant major (e.g. Information Technology, Computer Science, etc.).\nPerks of joining the team:\nCompetitive compensation & benefits package\nRemote Work Environment\nHow to get started:\nIf you\u2019re up for the challenge to be part of a growing engineering team we\u2019d like to hear from you. Apply today!\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "Java",
                "Scala",
                "R",
                "Go"
            ],
            "DataBase": [
                "SQL"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [],
            "MachingLearning": [
                "Orange"
            ],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [],
            "DevTools": [
                "Git"
            ],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [
                "Teams"
            ],
            "Other": [
                "DevOps",
                "Machine Learning"
            ],
            "FrSoftSkills": [],
            "EnSoftSkils": []
        },
        "details": {
            "JobDetail": [
                "Remote"
            ],
            "TypeContract": [],
            "Salary": [
                "Package"
            ],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "Data Engineer (H/F/NB) - Paris",
        "company": "Keyrus",
        "location": "Levallois-Perret, \u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/data-engineer-h-f-nb-paris-at-keyrus-3799373891?position=6&pageNum=42&refId=hZyb1K8CoeqwCyZyTWnF7w%3D%3D&trackingId=FLAgTMnItXbsCuBfCiaawA%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Qui sommes-nous ? Une\nsuccess story\ndans la\nData\net le\nDigital\n!\nNotre mission ?\nDes projets \u00e0 forte valeur ajout\u00e9e pour accro\u00eetre la performance et la comp\u00e9titivit\u00e9 des entreprises, faciliter et acc\u00e9l\u00e9rer leur transformation.\nNotre Expertise Depuis Plus De 20 Ans ? Le Conseil Et L'int\u00e9gration De Solutions Innovantes Autour De Trois Domaines\nData Intelligence\nBusiness Intelligence, Big Data & Analytics, Intelligence Artificielle\nDigital Experience\nConseil, Strat\u00e9gie & Performance Digitales\nConseil en Management & Transformation\nStrat\u00e9gie & Innovation, Pilotage de la Performance & Accompagnement des Projets\nNous sommes plus de 3000 talents sur plus de 20 pays et 4 continents. Notre ADN ? Innover et entreprendre.\nLe Job\nLes principales missions qui vous seront confi\u00e9es seront les suivantes:\nMettre en \u0153uvre divers outils de d\u00e9veloppement, de test, d'automatisation et d'infrastructure informatique.\nD\u00e9finir et param\u00e9trer les processus de d\u00e9veloppement, de test, de publication, de mise \u00e0 jour et de support pour les op\u00e9rations DevOps.\nAvoir les comp\u00e9tences techniques pour examiner, v\u00e9rifier et valider le code logiciel d\u00e9velopp\u00e9 dans le cadre du projet.\nSurveiller les processus tout au long du cycle de vie pour leur adh\u00e9sion et mettre \u00e0 jour ou cr\u00e9er de nouveaux processus pour l'am\u00e9lioration et la minimisation du gaspillage.\nEncourager et cr\u00e9er des processus automatis\u00e9s dans la mesure du possible.\nIdentifier et d\u00e9ployer des mesures de cybers\u00e9curit\u00e9 en effectuant en permanence une \u00e9valuation des vuln\u00e9rabilit\u00e9s et une gestion des risques.\nS'efforcer d'am\u00e9liorer continuellement et de construire une int\u00e9gration continue, un d\u00e9veloppement continu et un pipeline de d\u00e9ploiement constant (CI/CD Pipeline)\nGestion des rapports p\u00e9riodiques sur les progr\u00e8s \u00e0 la direction et au client.\nLe Profil\nVous avez 5 ans d'exp\u00e9rience.\nVous parlez anglais couramment.\nPourquoi nous rejoindre ?\nPour int\u00e9grer une communaut\u00e9 d\u2019experts curieux et passionn\u00e9s et \u00e9voluer dans un environnement multiculturel, formateur et favorisant la mobilit\u00e9 internationale.\nParce que vous \u00eates #DataGeek, #DigitalAddict, #InnovationLover !\n#KeyrusRocks #YouRock\nKeyrus est une entreprise o\u00f9 il fait bon vivre et travailler !\nD\u00e9couvrez\nLa vie chez Keyrus en 60 sec\nKeyrus en 3 mots\nNos animations pour nos collaborateurs sur Facebook et sur Instagram.\nNotre vid\u00e9o par Welcome To The Jungle\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "R"
            ],
            "DataBase": [],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [],
            "DevTools": [
                "Git"
            ],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [
                "DevOps",
                "Big Data",
                "CI/CD"
            ],
            "FrSoftSkills": [],
            "EnSoftSkils": []
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s",
                "20",
                "20",
                "20"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "Ing\u00e9nieur DATA (H/F)",
        "company": "Haute Autorit\u00e9 de Sant\u00e9",
        "location": "St.-Denis, \u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/ing%C3%A9nieur-data-h-f-at-haute-autorit%C3%A9-de-sant%C3%A9-3887884957?position=7&pageNum=42&refId=hZyb1K8CoeqwCyZyTWnF7w%3D%3D&trackingId=Et2SHnCydBT9YAzruviS9A%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Date : 13/02/2024\nPoste \u00e0 pourvoir Ing\u00e9nieur Data (H/F)\nEmploi-rep\u00e8re Chef de projet\nCat\u00e9gorie d\u2019emploi Cat\u00e9gorie 1\nType de contrat Contrat \u00e0 dur\u00e9e ind\u00e9termin\u00e9e / Temps complet\nLocalisation Saint-Denis (93)\nR\u00e9mun\u00e9ration Selon exp\u00e9rience et niveau de formation, par r\u00e9f\u00e9rence aux grilles indiciaires des agences sanitaires en application du d\u00e9cret n\u00b02003-224 du 07 mars 2003 ou selon statut particulier si fonctionnaire (d\u00e9tachement)\nDescription Du Poste a Pourvoir\nMissions g\u00e9n\u00e9rales du poste \u00e0 pourvoir Depuis 3 ans, la mission data a mis en place de nombreux projets mobilisant des traitements de donn\u00e9es. Parmi ceux-ci, on peut citer des projets open sources tels que ADEX qui est utilis\u00e9 au quotidien par les agents de la HAS et d\u2019autres agences sanitaires pour analyser les conflits d\u2019int\u00e9r\u00eat des experts, open SNDS qui permet de visualiser rapidement des informations sur les consommations de soins, ou la base de donn\u00e9es sur la qualit\u00e9 et la s\u00e9curit\u00e9 des soins qui alimente l\u2019espace QualiScope du site internet de la HAS. D\u2019autres projets ambitieux sont en cours, mobilisant notamment du traitement automatique du langage naturel pour mieux exploiter de gros volumes de retours d\u2019exp\u00e9riences de patients ou la litt\u00e9rature scientifique.\nCes projets se basent sur une plateforme data, d\u00e9velopp\u00e9e en interne, h\u00e9berg\u00e9e chez un clouder fran\u00e7ais, et homologu\u00e9e pour traiter les donn\u00e9es sensibles de la HAS. Elle comprend notamment une forge logicielle GitLab, un stockage objet MinIO, et des ressources de calcul importantes selon les besoins, notamment des GPU.\nAu sein de la mission data, votre mission sera de d\u00e9velopper et maintenir des traitements de donn\u00e9es automatis\u00e9s, pour r\u00e9pondre efficacement aux besoins data de la HAS. Vous travaillerez pour ce faire en synergie avec le responsable technique de la mission data, en bin\u00f4me par projet avec les autres membres de l\u2019\u00e9quipe, et de fa\u00e7on r\u00e9guli\u00e8re avec les data managers et statisticiens des diff\u00e9rents services m\u00e9tiers de l\u2019institution.\nAu Fil Des Projets Vous Serez Amen\u00e9 \u00e0\nD\u00e9velopper des traitements de donn\u00e9es et maintenir en condition op\u00e9rationnelle l\u2019existant\nParticiper \u00e0 la rationalisation et l\u2019am\u00e9lioration constante de la qualit\u00e9 technique de nos productions (choix technologiques, promotion des bonnes pratiques, relecture de code)\nContribuer \u00e0 des projets open source permettant d\u2019am\u00e9liorer l\u2019autonomie des utilisateurs et des citoyens dans l\u2019exploitation des donn\u00e9es issues de, ou utilis\u00e9es par la HAS\nParticiper \u00e0 la publication en open-data des donn\u00e9es produites par la HAS\nTravailler au sein d\u2019une \u00e9quipe transverse d\u2019une dizaine de personnes, compos\u00e9e de profils pointus dans leurs domaines (Data, Visualisation, NLP, \u00e9pid\u00e9miologie, etc.)\nEn tant qu\u2019ing\u00e9nieur data, vous occuperez une position cl\u00e9 au sein la mission data, et plus largement des projets data de la HAS. Vous saurez cr\u00e9er une dynamique autour de vos missions, et participer \u00e0 la r\u00e9ussite des projets data de la HAS.\nDirection et service d\u2019affectation\nDirection g\u00e9n\u00e9rale\nMission Data\nLa collecte massive de donn\u00e9es entra\u00eene actuellement des transformations majeures dans tous les secteurs d\u2019activit\u00e9s. Les syst\u00e8mes de sant\u00e9 commencent \u00e0 \u00eatre travers\u00e9s par cette (r)\u00e9volution, qui touche en particulier la production de connaissances et leur usage quotidien. Pour prendre pleinement ce virage, la HAS s\u2019est dot\u00e9e en 2021 d\u2019une strat\u00e9gie pluriannuelle d\u00e9di\u00e9e.\nVous travaillerez dans la mission data, rattach\u00e9e au directeur g\u00e9n\u00e9ral, dont le r\u00f4le est de mettre en euvre cette strat\u00e9gie, par la r\u00e9alisation de projets et d\u2019\u00e9tudes au service des m\u00e9tiers et missions de l\u2019institution.\nLa mission data est \u00e0 la fois un laboratoire d\u2019innovation, un centre d\u2019expertise, et un catalyseur de transformations dans l\u2019usage des donn\u00e9es par la HAS. Elle promeut les dynamiques de connaissance ouverte (open source, open data, open knowledge), conform\u00e9ment aux valeurs de transparence, d\u2019expertise et d\u2019ind\u00e9pendance de l\u2019institution.\nProfil Recherch\u00e9\nFormation Titulaire Bac+5 (Master, dipl\u00f4me d\u2019ing\u00e9nieur ou dipl\u00f4me \u00e9quivalent).\nSp\u00e9cialit\u00e9 en informatique, data ou DataOps.\nExp\u00e9rience Vous justifiez d\u2019une exp\u00e9rience professionnelle significative dans le domaine (5 ans minimum) avec la r\u00e9alisation de projets de traitement de donn\u00e9es d\u2019envergure, et une app\u00e9tence pour les infrastructures de donn\u00e9es sous-jacentes.\nComp\u00e9tences De nature autonome, vous savez faire preuve d\u2019initiative et avez un r\u00e9el sens de l\u2019organisation.\nVous \u00eates expert des langages, librairies et outils de traitement et de flux de donn\u00e9es (ETL). La pile technologique de la HAS, en \u00e9volution, utilise centralement Python et ses librairies (pandas, dask), mais aussi R, SQL, Spark, GitLab-CI. Une connaissance de plusieurs langages et frameworks de programmation est donc appr\u00e9ci\u00e9e.\nBonne maitrise g\u00e9n\u00e9raliste des syst\u00e8mes de stockage de donn\u00e9es : formats de stockage fichier, bases de donn\u00e9es relationnelles et documents, syst\u00e8mes de fichiers local et distribu\u00e9, stockage objet adapt\u00e9 au cloud.\nBonne ma\u00eetrise de git, des syst\u00e8mes de tests automatis\u00e9s, d\u2019int\u00e9gration et de d\u00e9ploiement continu.\nConnaissance des syst\u00e8mes LINUX, de virtualisation et de conteneurisation (Podman, Docker).\nParticipation \u00e0 des projets open source et open data appr\u00e9ci\u00e9e.\nEnfin, vous \u00eates tourn\u00e9 vers l\u2019action, pragmatique, rigoureux, aimez travailler en \u00e9quipe et faire progresser le collectif en partageant vos comp\u00e9tences.\nLA HAUTE AUTORIT\u00c9 DE SANT\u00c9\nAutorit\u00e9 publique ind\u00e9pendante \u00e0 caract\u00e8re scientifique, la Haute Autorit\u00e9 de sant\u00e9 (HAS) vise \u00e0 d\u00e9velopper la qualit\u00e9 dans les champs sanitaire, social et m\u00e9dico-social, au b\u00e9n\u00e9fice des personnes.\nElle travaille au c\u00f4t\u00e9 des pouvoirs publics dont elle \u00e9claire la d\u00e9cision, avec les professionnels de sant\u00e9 pour optimiser leurs pratiques et organisations, et au b\u00e9n\u00e9fice des usagers dont elle renforce la capacit\u00e9 \u00e0 faire des choix.\nElle Exerce Trois Missions Principales\n\u00e9valuer les m\u00e9dicaments, dispositifs et actes en vue de leur remboursement ;\nrecommander les bonnes pratiques professionnelles, \u00e9laborer des recommandations vaccinales et de sant\u00e9 publique ;\nmesurer et am\u00e9liorer la qualit\u00e9 dans les h\u00f4pitaux, cliniques, en m\u00e9decine de ville et dans les structures sociales et m\u00e9dico-sociales.\nLa HAS exerce son activit\u00e9 dans le respect de trois valeurs : la rigueur scientifique, l'ind\u00e9pendance et la transparence.\nElle Est Organis\u00e9e Autour\nd\u2019un Coll\u00e8ge de huit membres dont un pr\u00e9sident ;\nde commissions sp\u00e9cialis\u00e9es pr\u00e9sid\u00e9es par des membres du Coll\u00e8ge :\nde services r\u00e9parties en cinq directions.\nRef : C157O73948\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "R",
                "Go"
            ],
            "DataBase": [
                "SQL"
            ],
            "DataAnalytics": [
                "Pandas",
                "R"
            ],
            "BigData": [
                "Spark"
            ],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [],
            "DevTools": [
                "Git",
                "Docker"
            ],
            "Os": [
                "Linux"
            ],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [
                "Chef"
            ],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [
                "Docker"
            ],
            "Collaboration": [],
            "Other": [
                "Cloud"
            ],
            "FrSoftSkills": [
                "Organisation"
            ],
            "EnSoftSkils": [
                "Initiative"
            ]
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [],
            "Salary": [],
            "Level": [
                "Bac+5"
            ],
            "Experience": [
                "a",
                "n",
                "s",
                "3",
                "3",
                "3"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "Data Analyst H/F",
        "company": "Wewyse",
        "location": "Paris, \u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/data-analyst-h-f-at-wewyse-3811756415?position=8&pageNum=42&refId=hZyb1K8CoeqwCyZyTWnF7w%3D%3D&trackingId=f7%2B8eg2EVVvTYWtksqC2LQ%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Wewyse\nest un cabinet de conseil sp\u00e9cialis\u00e9 en\nData et en Intelligence Artificielle\n. C'est aussi et surtout une communaut\u00e9 de passionn\u00e9s partageant l'ambition de grandir ensemble et d'ouvrir le champ des possibles dans leurs domaines.\nSi vous pensez que la Data et l'Intelligence Artificielle ont beaucoup \u00e0 offrir au monde de demain, et si vous souhaitez apporter votre contribution \u00e0 ce monde, avec humilit\u00e9 et enthousiasme, alors vous \u00eates un Wyser en puissance.\n\u00catre\nData Analyst\nchez Wewyse c'est :\nInt\u00e9grer une communaut\u00e9 d\u2019experts Data passionn\u00e9s,\nRecevoir et partager des connaissances, des savoirs-faire lors de nombreux \u00e9v\u00e8nements internes et acqu\u00e9rir constamment de nouvelles comp\u00e9tences,\nIntervenir sur des projets \u00e0 la fois techniques et business, souvent dans un contexte international, avec des forts enjeux strat\u00e9giques aupr\u00e8s de nos clients dans tous les secteurs (retail, \u00e9nergie, m\u00e9dias, transports, banque et assurance \u2026)\nViser l\u2019excellence dans la qualit\u00e9 et l\u2019actionnabilit\u00e9 des analyses, gr\u00e2ce \u00e0 la ma\u00eetrise technique des outils en Data Analytics (d\u00e9veloppement, notebooks, visualisation, techniques de statistiques avanc\u00e9es\u2026) et la bonne compr\u00e9hension des enjeux business de nos clients,\nParticiper \u00e0 des projets innovants, impactants et positifs au sein de notre Datalab, en \u00e9quipe, avec des partenaires acad\u00e9miques (CentraleSupelec, \u2026) et parfois avec des starts up, afin de laisser exprimer vos valeurs et vos id\u00e9es,\nAvoir la possibilit\u00e9 de s\u2019impliquer dans le d\u00e9veloppement de Wewyse (participer au recrutement, concevoir des formations, donner des masterclass en \u00e9cole d\u2019ing\u00e9nieur, participer \u00e0 l\u2019avant-vente business, piloter des projets au sein du Datalab, d\u00e9velopper de nouveaux partenariats \u2026)\n\u00catre encourag\u00e9, conseill\u00e9 et accompagn\u00e9 dans un parcours de formation adapt\u00e9 \u00e0 vos ambitions professionnelles et avec un budget d\u00e9di\u00e9,\nFaire partie de la famille Wemanity, cr\u00e9er rapidement un r\u00e9seau d\u2019experts et de personnes reconnues dans leur domaine, participer aux \u00e9v\u00e8nements communs (voyage annuel, talks, afterworks ...) et b\u00e9n\u00e9ficier des multiples opportunit\u00e9s de carri\u00e8re au sein du Groupe,\nAvoir l\u2019opportunit\u00e9 de travailler avec une \u00e9quipe dynamique, dans une ambiance start-up et \u00e0 taille humaine dans le centre de Paris (Op\u00e9ra 9\u00e8me arrondissement)\nCe que nous aimons :\nLes personnalit\u00e9s ouvertes, curieuses, ambitieuses\nUn excellent niveau en\nSQL\nUne premi\u00e8re exp\u00e9rience en\nPython\nLa ma\u00eetrise d\u2019un outil de Data Visualisation\n(PBI, Tableau, Qlik, Looker, Data Studio \u2026)\nUne exp\u00e9rience dans l\u2019utilisation de\nJupyter Notebook / Databricks Notebook\nest fortement appr\u00e9ci\u00e9e\nL\u2019aisance en communication\nL\u2019esprit de synth\u00e8se\nL'anglais\nVous vous reconnaissez ? Alors n'h\u00e9sitez pas \u00e0 postuler !\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "R"
            ],
            "DataBase": [
                "SQL"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [
                "Databricks"
            ],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [
                "Tableau"
            ],
            "Statistics": [
                "Statistiques"
            ],
            "CloudComputing": [],
            "DevTools": [],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [
                "Statistiques"
            ],
            "FrSoftSkills": [
                "Communication"
            ],
            "EnSoftSkils": [
                "Communication"
            ]
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "Data Engineer (H/F)",
        "company": "Euro Information Developpements / EID",
        "location": "Villeneuve-d\u2019Ascq, Hauts-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/data-engineer-h-f-at-euro-information-developpements-eid-3821163420?position=9&pageNum=42&refId=hZyb1K8CoeqwCyZyTWnF7w%3D%3D&trackingId=UMhN2ZF6jgNU3v6cad79RQ%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Qui sommes nous\nEuro-Information, filiale technologique de Cr\u00e9dit Mutuel Alliance F\u00e9d\u00e9rale, con\u00e7oit, r\u00e9alise, maintient et exploite un syst\u00e8me d\u2019information commun utilis\u00e9 par le Groupe.\nLes activit\u00e9s de d\u00e9veloppement et de production informatique au niveau national et international sont assur\u00e9es par environ 4000 salari\u00e9s r\u00e9partis sur plusieurs sites g\u00e9ographiques au niveau national : Strasbourg, Nancy, Dijon, Orl\u00e9ans, Lyon, Lille, Cergy, Val de Fontenay, Paris et Nantes.\nPremi\u00e8re Banque \u00e0 adopter le statut d\u2019entreprise \u00e0 mission, le Cr\u00e9dit Mutuel Alliance F\u00e9d\u00e9rale s\u2019investit et s\u2019engage dans diff\u00e9rentes missions sociales et environnementales :\nL\u2019accompagnement de tous par notre organisation coop\u00e9rative et mutualiste reste au c\u0153ur de notre ADN.\nLa technologie au service de l\u2019humain est une r\u00e9f\u00e9rence dans notre monde connect\u00e9.\nLa solidarit\u00e9 et l\u2019\u00e9co-responsabilit\u00e9 deviennent des axes cl\u00e9s dans notre d\u00e9veloppement.\nNotre raison d\u2019\u00eatre : Ensemble, Ecouter et Agir.\nVos missions\nVous souhaitez int\u00e9grer une \u00e9quipe dynamique et \u00e0 taille humaine au sein d\u2019une entreprise solide et d\u2019un grand groupe en d\u00e9veloppement constant ? Vous souhaitez travailler sur un enjeu d\u2019aujourd\u2019hui et plus encore de demain : la donn\u00e9e ? Euro-Information, la Fintech de Cr\u00e9dit Mutuel Alliance F\u00e9d\u00e9rale structure une Data Factory pour :\nAcc\u00e9l\u00e9rer la valorisation des donn\u00e9es au travers d\u2019analyse de masse et de mod\u00e8les allant jusqu\u2019au pr\u00e9dictif.\nR\u00e9pondre \u00e0 la confiance de nos clients en garantissant la s\u00e9curit\u00e9 de leurs donn\u00e9es et une utilisation responsable et encadr\u00e9e, respectueuse de leur vie priv\u00e9e.\nLa Data Factory EI se positionne comme un fournisseur de solutions pour les \u00e9quipes informatiques et pour l\u2019ensemble des entit\u00e9s du groupe et comme un facilitateur d\u2019\u00e9changes et de mutualisation. Pour mener \u00e0 bien ces missions, la relation m\u00e9tier s\u2019av\u00e8re essentielle. Elle r\u00e9unit :\nDes Data Architects. Ils fournissent l\u2019environnement, les outils et s\u2019assurent de leur performance et de leur constante \u00e9volution.\nDes Data Engineers. Ils ont la maitrise des donn\u00e9es, de leur r\u00e9colte \u00e0 leur mise \u00e0 disposition adapt\u00e9e aux besoins des m\u00e9tiers. Ils con\u00e7oivent les mod\u00e8les d\u2019enregistrement des donn\u00e9es.\nDes Concepteurs Business Intelligence. Ils simplifient, mutualisent et industrialisent les reportings.\nDes Data Scientists. Ils accompagnent les m\u00e9tiers et les entit\u00e9s sur la Data Science, ils r\u00e9alisent \u00e0 fa\u00e7on sur les sujets \u00e0 fort enjeu.\nDes Data Officers. Ils coordonnent et mutualisent les \u00e9nergies sur les projets Data comme dans le cadre de la Gouvernance et de l\u2019administration des donn\u00e9es.\nNous recherchons un(e) Data Engineer.\nVous participerez \u00e0 la mise en \u0153uvre et au maintien du Syst\u00e8me d\u2019information D\u00e9cisionnel du groupe\nPour les banques, les cr\u00e9dits \u00e0 consommation et les filiales, en France et \u00e0 l\u2019international :\nCompr\u00e9hension de l\u2019activit\u00e9 et des besoins de vos clients, en dialogue avec la MOA\nCompr\u00e9hension du SI de production, en dialogue avec les \u00e9quipes MOE\nMod\u00e9lisation du Syst\u00e8me d\u2019Information D\u00e9cisionnel\nConception et r\u00e9alisation\nDiagnostic des dysfonctionnements rencontr\u00e9s\nMaintenances correctives et \u00e9volutives\nSupport aupr\u00e8s des diff\u00e9rents m\u00e9tiers\nDocumentation technique\nSuivi des traitements\nPilotage de projets de petite taille en autonomie\nVous travaillerez sur une grande vari\u00e9t\u00e9 de projets sur des m\u00e9tiers divers et sur des dizaines d\u2019entit\u00e9s g\u00e9r\u00e9es sur le SI d\u2019Euro-Information : cr\u00e9dit, assurance, commercial, leasing, pr\u00e9vention de la fraude, sujets li\u00e9s \u00e0 l\u2019Intelligence Artificielle en lien avec la Cognitive Factory, sujets li\u00e9s \u00e0 la lecture automatique des documents en lien avec l\u2019OCR Factory\u2026\nVous intervenez sur des projets \u00e0 dimension internationale sur des environnements Vertica, Hadoop, Stambia, SAS, Business Objects, QlikSense\u2026\nVous participez, coordonnez et menez \u00e0 bien des projets de valorisation de donn\u00e9es sur des cas d\u2019usages concrets :\nParticipez aux projets de bout en bout : de l\u2019expression du besoin jusqu\u2019\u00e0 la r\u00e9alisation et au suivi de sa performance en lien avec la MOA et nos Data Officers\nMobilisez l\u2019ensemble des acteurs : Business, Data scientists, Data engineer, sources de donn\u00e9es \u2026\nEclairez et participez aux prises de d\u00e9cision.\nMutualisez les travaux et les bonnes pratiques entre les acteurs et les diff\u00e9rents m\u00e9tiers du groupe.\nAccompagnez le changement. Au sein de vos projets et au-del\u00e0, vous portez l\u2019acculturation Data au sein du groupe\nCe que vous allez vivre chez nous\nT\u00e9l\u00e9travail (2 jours par semaine)\nR\u00e9mun\u00e9ration fixe vers\u00e9e sur 13 mois\nRTT\nInt\u00e9ressement, participation et abondement\nPlan \u00e9pargne entreprise et PERCO\nContrat de sant\u00e9 collectif\nPr\u00e9voyance\nRetraite suppl\u00e9mentaire prise en charge \u00e0 100% par l\u2019employeur\nConditions bancaires et assurances pr\u00e9f\u00e9rentielles\nPolitique parentale avantageuse\nCe que nous allons aimer chez vous\nDe formation bac +4/5, vous disposez id\u00e9alement, d\u2019une exp\u00e9rience significative sur un poste \u00e9quivalent.\nConnaissance du monde OPEN\nVous avez la maitrise d\u2019un ETL, d\u2019une base de donn\u00e9es orient\u00e9e Analytique, d\u2019une solution BI. La connaissance de l\u2019outil de mod\u00e9lisation PowerDesigner serait un plus\nLa maitrise de l\u2019anglais serait \u00e9galement appr\u00e9ci\u00e9e.\nCe qui nous plaira le plus chez vous :\nC\u2019est vous-m\u00eame ! Alors on vous attend ouvert(e), force de proposition, dot\u00e9(e) d\u2019un certain sens critique, autonome et respectueux(se) de la confidentialit\u00e9 des informations d\u00e9tenues car c\u2019est ce qui vous permettra de mener au mieux votre mission.\nOn dit de vous que vous avez une certaine aptitude \u00e0 communiquer et le sens du travail en \u00e9quipe.\nVous \u00eates motiv\u00e9(e) et vous souhaitez vous investir fonctionnellement et techniquement, n\u2019h\u00e9sitez plus l\u2019offre est faite pour vous.\nAutres informations\nLe poste bas\u00e9 \u00e0 Villeneuve-d\u2019Ascq est \u00e0 pourvoir en CDI d\u00e8s que possible.\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "R",
                "Go"
            ],
            "DataBase": [],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [
                "Hadoop"
            ],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [],
            "DevTools": [],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [],
            "FrSoftSkills": [
                "Organisation"
            ],
            "EnSoftSkils": []
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [
                "CDI"
            ],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "Data Engineer (H/F)",
        "company": "Extia",
        "location": "Sophia Antipolis, Provence-Alpes-C\u00f4te d'Azur, France",
        "link": "https://fr.linkedin.com/jobs/view/data-engineer-h-f-at-extia-3675382393?position=10&pageNum=42&refId=hZyb1K8CoeqwCyZyTWnF7w%3D%3D&trackingId=7G%2FuGfBxDl2QaW7f%2FCkTIg%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Vous souhaitez rejoindre une entreprise qui place l\u2019humain au c\u0153ur de ses pr\u00e9occupations ? On vous attend chez\nExtia\n!\nSoci\u00e9t\u00e9 de conseil sp\u00e9cialis\u00e9e dans les m\u00e9tiers de l\u2019IT, de l\u2019ing\u00e9nierie et du digital, Extia privil\u00e9gie depuis sa cr\u00e9ation en 2007 une approche qui allie performance et bien-\u00eatre au travail. Une vision de l\u2019entreprise partag\u00e9e aujourd\u2019hui par plus de 2 500 Extiens en France et \u00e0 l'international et r\u00e9compens\u00e9e par le label Great Place to Work\u00ae depuis 13 ans, notamment en\n2024 o\u00f9 les Extiens se hissent \u00e0 la premi\u00e8re place du palmar\u00e8s Best Workplaces France\n!\nChez Extia, c\u2019est \u00ab D\u2019abord qui, ensuite quoi \u00bb alors, allons-y !\nD'abord qui\nD'abord qui ?\nIng\u00e9nieux, votre imagination d\u00e9bordante vient \u00e0 bout de chaque probl\u00e9matique,\nAttentif aux d\u00e9tails, vous avez un \u0153il de Lynx pour rep\u00e9rer les incoh\u00e9rences,\nEfficace, vous ne remettez pas \u00e0 demain ce qui peut \u00eatre fait d\u00e8s aujourd\u2019hui.\nEnsuite quoi\nEnsuite quoi ?\nVous aurez le r\u00f4le de support technique aux \u00e9quipes d\u2019analyse : structurer les donn\u00e9es, r\u00e9aliser des analyses \u00ab statistiques \u00bb ou \u00ab techniques \u00bb sur les donn\u00e9es, d\u00e9velopper des outils d\u2019analyse\u2026 Vous m\u00e8nerez des \u00e9tudes afin d\u2019identifier les solutions les plus pertinentes. Vous serez en charge de :\nParticiper \u00e0 la d\u00e9finition des besoins,\nMettre en place des Pipelines de traitement de donn\u00e9es,\nD\u00e9velopper de nouvelles features,\nMaintenir en condition op\u00e9rationnelle du system legacy de test,\nCollaborer avec les Data Scientists au d\u00e9veloppement des modules d\u2019analyse de donn\u00e9e,\nInt\u00e9grer des sources de donn\u00e9es.\n**Profil recherch\u00e9 **\nDisposant de minimum 2 \u00e0 3 ans d'exp\u00e9rience, vous \u00eates habitu\u00e9 \u00e0 travailler aussi bien avec des m\u00e9ta-donn\u00e9es qu\u2019avec des donn\u00e9es non-structur\u00e9es. A cet effet vous maitrisez Spark et vous connaissez le langage de programmation Scala. Vous poss\u00e9dez \u00e9galement une affinit\u00e9 avec le cloud.\nEnfin, vous avez une bonne maitrise de l'anglais, \u00e0 l'\u00e9crit comme \u00e0 l'oral !\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Scala",
                "R"
            ],
            "DataBase": [],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [
                "Spark"
            ],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [
                "Statistiques"
            ],
            "CloudComputing": [],
            "DevTools": [
                "Git"
            ],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [
                "Statistiques",
                "Cloud"
            ],
            "FrSoftSkills": [],
            "EnSoftSkils": []
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s",
                "13",
                "13",
                "13"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "Data Engineer",
        "company": "Energy Jobline",
        "location": "\u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/data-engineer-at-energy-jobline-3892672213?position=1&pageNum=45&refId=helkV5fb1RK2O%2B2D3vOHXQ%3D%3D&trackingId=upuV45Ei8yGufim4hykR%2Fg%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Do you have Data Engineering experience, and are you seeking a new contract role in Paris? NES Fircroft is helping a collaborative company recruit an agile and passionate Data Engineer for a 12-month contract. Hybrid based, must have 5+ years experience. Please note this position requires you to be fluent in French and English.\nAs a Data Engineer, you will be responsible for the data architecture's design, development and production. You will also collect business and user requirements, design data pipelines, and push the architecture into production.\nIn your first few weeks in this Data Engineer role, you can expect to:\nCollect business and user requirements\nDesign the data architecture\nDesign data pipelines\nPut the architecture into production\nEnsure the maintenance and evolution of the architecture\nCollaborate and participate in activities within the chapter\nAttend Communities of Practice (CoPs) meetings.\nTo apply for this Data Engineer role, your soft skills, expertise, and experience should include:\nExperience working with Python/PySpark/Databricks under an Azure Cloud environment\nExperience creating data pipelines and putting the architecture into production\nExperience in working with data pipelines, maintaining and evolving the architecture.\nIf you want to positively impact and create change, you'll be rewarded with an excellent contract per day rate for your inclusive and committed approach.\nTo apply for this contract Data Engineer job in Paris, please contact NES Fircroft today. Please refer any friends or colleagues for this role or direct them to our Careers page on our website.\nWith over 90 years of combined experience in delivering workforce solutions to the global energy industry, NES Fircroft is proud to be the world\u2019s leading engineering staffing provider spanning the Oil & Gas, Power & renewable, Infrastructure, and Life Sciences, Mining, Automotive and Chemicals sectors worldwide. We provide tailored staffing solutions, sourced from a global talent pool by a dedicated, discipline-specific team of consultants.\nWith over 90 years' combined experience, NES Fircroft (NES) is proud to be the world's leading engineering staffing provider spanning the Oil & Gas, Power & Renewables, Chemicals, Construction & Infrastructure, Life Sciences, Mining and Manufacturing sectors worldwide. With more than 80 offices in 45 countries, we are able to provide our clients with the engineering and technical expertise they need, wherever and whenever it is needed. We offer contractors far more than a traditional recruitment service, supporting with everything from securing visas and work permits, to providing market-leading benefits packages and accommodation, ensuring they are safely and compliantly able to support our clients.\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "R"
            ],
            "DataBase": [],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [
                "Spark",
                "Databricks"
            ],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [
                "Azure"
            ],
            "DevTools": [],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [
                "Cloud"
            ],
            "FrSoftSkills": [],
            "EnSoftSkils": []
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [],
            "Salary": [
                "Package"
            ],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "Data Engineer (H/F)",
        "company": "Extia",
        "location": "Lyon, Auvergne-Rh\u00f4ne-Alpes, France",
        "link": "https://fr.linkedin.com/jobs/view/data-engineer-h-f-at-extia-3841318856?position=2&pageNum=45&refId=helkV5fb1RK2O%2B2D3vOHXQ%3D%3D&trackingId=XzXy52KW1ipP%2BVsyy2ii8A%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Vous souhaitez rejoindre une entreprise qui place l\u2019humain au c\u0153ur de ses pr\u00e9occupations ? On vous attend chez\nExtia\n!\nSoci\u00e9t\u00e9 de conseil sp\u00e9cialis\u00e9e dans les m\u00e9tiers de l\u2019IT, de l\u2019ing\u00e9nierie et du digital, Extia privil\u00e9gie depuis sa cr\u00e9ation en 2007 une approche qui allie performance et bien-\u00eatre au travail. Une vision de l\u2019entreprise partag\u00e9e aujourd\u2019hui par plus de 2 500 Extiens en France et \u00e0 l'international et r\u00e9compens\u00e9e par le label Great Place to Work\u00ae depuis 13 ans, notamment en\n2024 o\u00f9 les Extiens se hissent \u00e0 la premi\u00e8re place du palmar\u00e8s Best Workplaces France\n!\nChez Extia, c\u2019est \u00ab D\u2019abord qui, ensuite quoi \u00bb alors, allons-y !\nD'abord qui\nRigoureux, vous ne laissez rien au hasard,\nEfficace, vous ne remettez pas \u00e0 demain ce qui peut \u00eatre fait d\u00e8s aujourd\u2019hui,\nAutonome, vous savez mener vos missions \u00e0 bien sans aide.\nEnsuite quoi\nVous aurez le r\u00f4le de support technique aux \u00e9quipes d\u2019analyse : structurer les donn\u00e9es, r\u00e9aliser des analyses \u00ab statistiques \u00bb ou \u00ab techniques \u00bb sur les donn\u00e9es, d\u00e9velopper des outils d\u2019analyse\u2026\nVous m\u00e8nerez des \u00e9tudes afin d\u2019\u00e9valuer les nouvelles technologies dans le domaine du Big Data, Data Mining ou Machine Learning afin d\u2019identifier les solutions les plus pertinentes.\nVous serez en charge de :\nParticiper \u00e0 la d\u00e9finition des besoins et \u00e0 la r\u00e9daction des User Stories,\nCollaborer avec les Data Scientists au d\u00e9veloppement des modules d\u2019analyse de donn\u00e9e,\nConcevoir et construire des architectures de donn\u00e9es,\nInt\u00e9grer des sources de donn\u00e9es,\nS'assurer que les donn\u00e9es sont facilement accessibles et que leur exploitation fonctionne comme demand\u00e9, m\u00eame dans des circonstances hautement \u00e9volutives,\nEx\u00e9cuter des processus ETL (extraire / transformer / charger) \u00e0 partir d'ensembles de donn\u00e9es complexes et / ou volumineux.\nProfil recherch\u00e9 :\nMaitrise de l\u2019\u00e9cosyst\u00e8me Microsoft Azure Data Factory, Azure Data Lake est un plus\nMaitrise Technologie autour de la data : Power BI, Spark, Airflow, Python, Scala\u2026\nMaitrise des bonnes pratiques de d\u00e9veloppement et m\u00e9thodes agiles\nBase de donn\u00e9es : SQL, Postgr\u00e9 SQL (Paas) et mod\u00e9lisation de la donn\u00e9e\nConnaissance des syst\u00e8mes de gestionnaire de conteneur (Kubernetes,...)\nConnaissance des outils de d\u00e9ploiements : Jenkins, Git, maven, Ansible\nQualit\u00e9s relationnelles et capacit\u00e9 \u00e0 g\u00e9rer nombreuses interactions\nDynamisme, autonomie et envie de d\u00e9couvrir des mani\u00e8res diff\u00e9rentes/innovantes de faire\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "Scala",
                "R",
                "Go"
            ],
            "DataBase": [
                "SQL"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [
                "Spark"
            ],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [
                "Power BI"
            ],
            "Statistics": [
                "Statistiques"
            ],
            "CloudComputing": [
                "Azure"
            ],
            "DevTools": [
                "Git",
                "Jenkins"
            ],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [
                "Ansible",
                "Kubernetes",
                "Airflow"
            ],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [
                "Kubernetes"
            ],
            "Collaboration": [],
            "Other": [
                "Big Data",
                "Machine Learning",
                "Statistiques"
            ],
            "FrSoftSkills": [],
            "EnSoftSkils": []
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s",
                "13",
                "13",
                "13"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "Data Engineer Talend (F/H)",
        "company": "Pact&Go",
        "location": "Montpellier, Occitanie, France",
        "link": "https://fr.linkedin.com/jobs/view/data-engineer-talend-f-h-at-pact-go-3914234996?position=3&pageNum=45&refId=helkV5fb1RK2O%2B2D3vOHXQ%3D%3D&trackingId=7lqBbN6xVdGsLiePECBTYA%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "PACT&GO est un Cabinet de Conseil en Recrutement, ind\u00e9pendant et de proximit\u00e9.\nNotre objectif est de d\u00e9mocratiser les services des cabinets de recrutement aupr\u00e8s des Start-Up, TPE & PME, en proposant un service de qualit\u00e9, pour une facturation plus \u00e9quitable : 2x moins ch\u00e8re en moyenne que les prix en vigueur sur le march\u00e9 !\nDe plus, il n'existe aucun risque pour nos clients de solliciter Pact&Go : nous ne demandons pas d'acompte et n'appliquons pas de clause contraignante (ex : clause d'exclusivit\u00e9) : Nous fonctionnons uniquement au succ\u00e8s !\nEn parall\u00e8le, nous souhaitons nous mettre pleinement aux services de nos candidats, afin de comprendre r\u00e9ellement leurs projets professionnels et pr\u00e9senter LA bonne opportunit\u00e9 qui correspondra \u00e0 leurs attentes.\nNous sommes sp\u00e9cialis\u00e9s sur les secteurs d'activit\u00e9s suivants dans les R\u00e9gions Occitanie & PACA :\nInformatique\nTertiaire\nBureau d'\u00e9tudes & Ing\u00e9nierie\nNos Valeurs\nEngagement\nConfiance\nPers\u00e9v\u00e9rance\nTransparence\nBienveillance\nPour tout compl\u00e9ment d'information, vous pouvez consulter notre site internet : www.pact-go.com\nS\u00e9curisez vos recrutements : Confiez vos recherches \u00e0 Pact&Go !\nLe Poste\nNous recherchons un(e) Data Engineer (F/H) comp\u00e9tent(e) sur Talend pour l'un de nos clients, acteur incontournable dans le secteur IT \u00e0 Montpellier.\nIl s'agit d'un poste \u00e0 pourvoir au sein d'un centre de services d'une ESN r\u00e9put\u00e9e sur Montpellier (depuis + 20 ans), \u00e0 taille humaine, et qui prend soin de ses salari\u00e9s (suivi personnalis\u00e9 et plan de formation tout au long du parcours).\nMissions\nConception et d\u00e9veloppement de processus ETL en utilisant Talend pour int\u00e9grer et transformer les donn\u00e9es en vue de leur utilisation dans un environnement de middleware.\n\u00c9criture et optimisation de requ\u00eates SQL pour la manipulation et l'analyse des donn\u00e9es.\nTravail en \u00e9troite collaboration avec l'\u00e9quipe de d\u00e9veloppement pour int\u00e9grer les solutions.\nCollaboration avec les \u00e9quipes de projet pour comprendre les besoins m\u00e9tiers et traduire ces besoins en solutions techniques efficaces.\nR\u00e9alisation de tests pour garantir la qualit\u00e9 et la fiabilit\u00e9 des donn\u00e9es.\nDocumentation technique pour assurer une bonne compr\u00e9hension et une maintenance efficace des d\u00e9veloppements.\nProfil\nDe formation Bac+3 \u00e0 Bac+5, vous d\u00e9tenez une 1\u00e8re exp\u00e9rience significative sur une fonction similaire.\nVous avez d\u00e9j\u00e0 particip\u00e9 \u00e0 un ou plusieurs projets BI, sur des probl\u00e9matiques de Data Integration (mise en place des bonnes pratiques pour des flux otpimis\u00e9s) ou plus g\u00e9n\u00e9ralement dans la mise en place de Datawarehouses/Datamarts.\nVous attachez une importance particuli\u00e8re \u00e0 la qualit\u00e9 de vos d\u00e9veloppements (respect de l'architecture, normes de codage, tests unitaires,\u2026).\nVous avez une tr\u00e8s bonne ma\u00eetrise de Talend.\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "R",
                "Go"
            ],
            "DataBase": [
                "SQL"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [],
            "DevTools": [
                "Git"
            ],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [],
            "FrSoftSkills": [
                "Collaboration"
            ],
            "EnSoftSkils": [
                "Collaboration"
            ]
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [],
            "Salary": [],
            "Level": [
                "Bac+5",
                "Bac+3"
            ],
            "Experience": [
                "a",
                "n",
                "s",
                "20",
                "20",
                "20"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "Data Analyst (H/F)",
        "company": "Wemanity Lille",
        "location": "Greater Lille Metropolitan Area",
        "link": "https://fr.linkedin.com/jobs/view/data-analyst-h-f-at-wemanity-lille-3890979963?position=4&pageNum=45&refId=helkV5fb1RK2O%2B2D3vOHXQ%3D%3D&trackingId=Ng5MnIpePveHtR6h3PYHtg%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Fond\u00e9e en 2018, l\u2019agence\nWemanity Lille\nse d\u00e9veloppe d\u2019ann\u00e9e en ann\u00e9e gr\u00e2ce aux talents qui font de cette aventure une r\u00e9ussite ! \ud83c\udf08\u200b\n3 mots pour la d\u00e9crire ? P\u00e9tillante, \u00e0 taille humaine et audacieuse !\nPour suivre cette dynamique nous recherchons des talents ayant l'envie de progresser et de se lancer dans une belle aventure professionnelle et humaine \u00e0 nos c\u00f4t\u00e9s. \ud83c\udf33\nNous recherchons un(e)\nData Analyst (H/F)\navec un minimum d'exp\u00e9rience de 3/4 ans, qui a envie d'apprendre et de d\u00e9voiler tout son potentiel \u00e0 nos c\u00f4t\u00e9s !\nQui sommes-nous\n?\n\ud83d\udca1\n\ud83c\udfa2 Cabinet de conseil sp\u00e9cialis\u00e9 en\ntransformations digitales et agiles.\n\ud83c\udf0d Pr\u00e9sent \u00e0 l\u2019international :\nParis, Lille, Belgique, Pays-bas, Maroc et Luxembourg.\n\ud83d\udc65\n600\ncoop\u00e9rateurs passionn\u00e9s.\n\ud83c\udf43Un p\u00f4le RSE d\u00e9bordant d\u2019id\u00e9es qui propose des projets \u00e0\nimpact\nsociaux\net\nenvironnementaux.\n\ud83d\udcbc\u200b Pr\u00e9sence du Wemanity Learning Center permettant\nformations & certifications.\n\ud83e\uddb8 Ton profil :\nTu es Data Analyst (H/F)\n, tu as une exp\u00e9rience de plus de 3/4 ans et tu souhaites rejoindre une \u00e9quipe de passionn\u00e9s ambitieux?\nTu aimes mettre en valeur les bonnes pratiques, apprendre et partager ? Cette offre est faite pour toi !\n\ud83d\ude80 Tes missions* :\nMa\u00eetrise des outils d'analyse de donn\u00e9es.\nExp\u00e9rience avec les outils de visualisation de donn\u00e9es (Tableau, Power BI).\nConnaissance des techniques d'analyse statistique et des mod\u00e8les de machine learning.\nUtilisation de m\u00e9thodologies Agile/Scrum.\nCollaboration avec des \u00e9quipes interfonctionnelles.\n*Liste non exhaustive\n\ud83c\udf08Pourquoi Wemanity ?\nUn salaire attractif et de nombreux avantages (RTT, formations & certifications, primes vacances, CE, carte Swile \u2026) \u2600\ufe0f\nDes projets vari\u00e9s \u00e0 forte valeur ajout\u00e9e \ud83c\udf88\nUne vraie mont\u00e9e en comp\u00e9tences avec notre p\u00f4le formation (formations, certifications) \ud83e\ude84\nL\u2019opportunit\u00e9 d\u2019int\u00e9grer une communaut\u00e9 d\u2019agilistes soud\u00e9e \ud83d\ude80\nLa possibilit\u00e9 d\u2019int\u00e9grer des squads agiles qui fonctionnent en mode startup pour intervenir sur des projets from scratch en interne ou chez nos clients \ud83e\udd39\u200d\nLa possibilit\u00e9 de travailler en r\u00e9elle autonomie (t\u00e9l\u00e9travail) \u2600\ufe0f\nUne carri\u00e8re \u00e9volutive au sein d\u2019une entreprise pleine de projets \ud83d\udcaa\nUne entreprise avec un r\u00e9el engagement RSE \ud83c\udf33\n\ud83d\udccc\nNotre processus de recrutement en 3 \u00e9tapes :\n1\u00e8re \u00e9tape, ton profil nous int\u00e9resse ! Premier \u00e9change avec l\u2019un de nos recruteurs passionn\u00e9s pour faire connaissance et en savoir plus sur tes souhaits d\u2019\u00e9volution.\n2\u00e8me \u00e9tape, l\u2019entretien technique : c\u2019est le moment d\u2019\u00e9changes sur la partie technique avec un membre de Wemanity (coop\u00e9rateurs).\nEntretien final : Tu rencontreras un commercial afin de d\u00e9terminer le projet et le client chez qui tu pourras \u00e9voluer et t\u2019\u00e9panouir ! Suite \u00e0 ces 3 \u00e9changes, je te souhaite d\u2019obtenir ton billet d\u2019entr\u00e9e pour rejoindre l\u2019aventure Wemanity !\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "R"
            ],
            "DataBase": [],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [
                "Tableau",
                "Power BI"
            ],
            "Statistics": [],
            "CloudComputing": [],
            "DevTools": [
                "Git"
            ],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [
                "Machine Learning"
            ],
            "FrSoftSkills": [
                "Collaboration"
            ],
            "EnSoftSkils": [
                "Collaboration"
            ]
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [],
            "Salary": [
                "3"
            ],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s",
                "4",
                "4",
                "4"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "Data Analyst (H/F)",
        "company": "moOngy Digital Lab",
        "location": "Greater Lille Metropolitan Area",
        "link": "https://fr.linkedin.com/jobs/view/data-analyst-h-f-at-moongy-digital-lab-3890974953?position=5&pageNum=45&refId=helkV5fb1RK2O%2B2D3vOHXQ%3D%3D&trackingId=C6F4wu8iMd3zYQGH%2FQrEKg%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Web Transition, c\u2019est qui ?\nFond\u00e9e en 2011,\nWeb transition\nest une entreprise de services num\u00e9riques op\u00e9rant sur le march\u00e9 de l\u2019IT/Digital !\nConstituant une part essentielle de\nMoOngy Digital Lab\n, Web Transition accompagne ses clients grands comptes sur leurs projets de Webmarketing, de Design, Gestion de projet et \u00e9galement en Data !\nNotre objectif : nous implanter comme un acteur principal sur le march\u00e9 de la Transformation Digitale en accompagnant et valorisant les comp\u00e9tences de nos collaborateurs !\nNous sommes convaincus que le succ\u00e8s de MoOngy Digital Lab r\u00e9side dans la somme des potentiels de nos \u00e9quipes \ud83e\udd1d\nTon \u00e9quipe : La tribu Data\nParce qu\u2019il est indispensable que tu puisses partager tes connaissances mais aussi en acqu\u00e9rir de nouvelles, tu feras partie de l\u2019une de nos tribus : celle de la Data. De plus, cela te permettra d\u2019\u00eatre acteur dans le d\u00e9veloppement et la strat\u00e9gie de Web Transition. Ce syst\u00e8me de co-r\u00e9flexion et co-construction est un fondement essentiel chez nous !\nDans cette aventure, tu :\nOptimises\nles requ\u00eates SQL ;\nConstruis\nles mod\u00e8les de r\u00e9gression ;\nAnalyses\nla rentabilit\u00e9 des actions marketing ;\nR\u00e9alises\ndes \u00e9tudes ad hoc sur les comportements clients ;\nProduits\net\nautomatises\nle reporting.\nRejoins-nous si tu as :\nUne exp\u00e9rience de 3 ans minimum,\nUne maitrise technique de GCP / DBT / PowerBI,\nUne exp\u00e9rience similaire dans une startup ou dans l\u2019industrie serait un plus !\nTon savoir-\u00eatre :\nOuvert d\u2019esprit\nRespectueux des diff\u00e9rences de chacun\nCurieux\nProactif\nPar o\u00f9 on commence ?\nUn premier entretien RH d\u20191h pour comprendre ton parcours et tes aspirations\nUn second entretien de 45 minutes avec l\u2019un de nos Business Manager afin de valider tes comp\u00e9tences et qu\u2019il se projette sur l\u2019une des missions qu\u2019il pourrait te proposer\nUn troisi\u00e8me entretien de quelques minutes avec notre responsable d\u2019agence pour te proposer d\u2019int\u00e9grer notre superbe Team Web !\n3 entretiens en peu de temps, si ton profil correspond tu int\u00e8greras tr\u00e8s vite nos \u00e9quipes \ud83d\ude09\nPr\u00eat pour embarquer dans notre grande aventure humaine ? Deviens notre futur Weber en postulant \u00e0 cette offre ! Voici les avantages qui t\u2019attendent en tant que Weber :\n\ud83e\udd29 Des coll\u00e8gues incroyables\n\ud83c\udfc6 Certifi\u00e9e Great Place to Work\n\ud83c\udfae Des bureaux sympas (o\u00f9 vous serez toujours les bienvenus)\n\ud83c\udf89 Des teambuilding et \u00e9vents tous les mois\n\ud83d\udcbb Des tributs m\u00e9tiers pour \u00e9changer entre Weber du m\u00eame m\u00e9tier\nDes missions chez le client qui sont accompagn\u00e9es et coach\u00e9es par ton manager\nUn accompagnement dans ton plan de carri\u00e8re et tes envies de re skilling\n\ud83e\udd13 Un catalogue de formations certifiantes ouvert \u00e0 tous les salari\u00e9s\n\ud83c\udf7d\ufe0f Une carte tickets restaurant MyEdenred\n\u2764\ufe0f Une mutuelle GrasSavoye\n\ud83d\ude8e Une prise en charge des frais de transport \u00e0 100%\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "R"
            ],
            "DataBase": [
                "SQL"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [
                "PowerBI"
            ],
            "Statistics": [],
            "CloudComputing": [],
            "DevTools": [
                "Git"
            ],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [],
            "FrSoftSkills": [],
            "EnSoftSkils": []
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s",
                "3",
                "3",
                "3"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "Data Analyst",
        "company": "Volvo Group",
        "location": "V\u00e9nissieux, Auvergne-Rh\u00f4ne-Alpes, France",
        "link": "https://fr.linkedin.com/jobs/view/data-analyst-at-volvo-group-3860811035?position=6&pageNum=45&refId=helkV5fb1RK2O%2B2D3vOHXQ%3D%3D&trackingId=1Xhk0m4PORbq0Y47g5nYQQ%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Transport is at the core of modern society. Imagine using your expertise to shape sustainable transport solutions for the future? If you seek to make a difference on a global scale, working with next-gen technologies and the sharpest collaborative teams, then we could be a perfect match.\nWhat You Will Do\nAt DIGITAL&IT DATA you will contribute to the transformation of our company, the transport industry and society at large. You will:\nDrive workshops with the business stakeholders to understand their business context and to collect their needs.\nBecome a Data expert on one or more business domains, to draw conclusions and to provide answers to business stakeholders questions.\nAccess, manipulate, query, and analyze data using different software, tools and techniques.\nBe part of the data modeling process (design and implementation) as well as in the definition of business rules that will ensure data consistency and quality.\nPre-process, clean and structure data to facilitate data exploration and advanced analytics activities.\nDesign and implement dashboards using advanced visualization tools.\nWork in cross functional agile teams to continuously experiment, iterate and deliver on new product objectives.\nBe an active member of the Data Analyst Chapter, sharing knowledge and best practices with your peers.\nBenefit from dedicated trainings to maintain and develop your Data Analyst skills.\nYour Future Team\nAs Data Analyst, you will be part of A&BI (Analytics & Business Intelligence) Trucks Dealer agile team. You will have opportunity to work on heterogenous topics such as (non exhaustive list):\nPaperless NLP: Support Paperless project thanks to NLP (Natural Language Processing) & AI (Artificial Intelligence) processes,\nDealer Quality program: Set of Key Performance Indicators on all Dealer processes to support Sales Area organization,\nSet up Data Product on Azure to support smart business services,\nBe part of the maintenance team to ensure business process continuity, ...\nWho are you?\nDo you dream big? We do too, and we are excited to grow together. Are you the one?\nHaving a master degree or equivalent in IT.\nData & Data Analysis\u202fhas been\u202fyour\u202fworld\u202ffor 3-5\u202fyears\u202fnow.\nYou are an experienced Data Analyst looking for new challenges in the transport industry. You\u202fare\u202fproactive\u202fproblem\u202fsolver\u202fwith\u202finnovative\u202fthinking\u202fwith\u202fa strong\u202fsense of teamwork.\nWriting SQL and doing data modelling are natural activities for you.\nYou are experienced working on data manipulation and data modeling.\nYou are experienced designing and developing dashboard using at least one visualization tool (such as PowerBI for example).\nYou are familiar with Azure Data Analytics Stack (Storage accounts, Databricks, Azure Data Factory, SQL Server, SQL Data base, etc...).\nYou are familiar writing scripts on Python to do data preparation/cleaning.\nYou have excellent communication skills in French and English (C1 level)\nReady for the next move?\nAre you excited to bring your skills and disruptive ideas to the table? We can\u2019t wait to hear from you. Apply today!\nWe value your data privacy and therefore do not accept applications via mail.\nWho We Are And What We Believe In\nOur focus on Inclusion, Diversity, and Equity allows each of us the opportunity to bring our full authentic self to work and thrive by providing a safe and supportive environment, free of harassment and discrimination. We are committed to removing the barriers to entry, which is why we ask that even if you feel you may not meet every qualification on the job description, please apply and let us decide.\nApplying to this job offers you the opportunity to join\nVolvo Group.\nEvery day, across the globe, our trucks, buses, engines, construction equipment, financial services, and solutions make modern life possible. We are almost 100,000 people empowered to shape the future landscape of efficient, safe and sustainable transport solutions. Fulfilling our mission creates countless career opportunities for talents with sharp minds and passion across the group\u2019s leading brands and entities.\nGroup Digital & IT\nis the hub for digital development within Volvo Group. Imagine yourself working with cutting-edge technologies in a global team, represented in more than 30 countries. We are dedicated to leading the way of tomorrow\u2019s transport solutions, guided by a strong customer mindset and high level of curiosity, both as individuals and as a team. Here, you will thrive in your career in an environment where your voice is heard and your ideas matter.\n\u2018\nData\n\u2019 is a new function within Volvo Digital & IT with the goal to unlock the power of data for the whole Volvo Group to become a fully data-driven company! With data, the core component of our transformation journey, we will, together with our data talents, make the Volvo Group 2030 vision happen. We will take care of all the aspects of Data, how it is quality assured, documented, made available, prepared and consumed through BI, Analytics and Machine Learning. We have an ambitious transformation in front of us, with an implementation of the Data Layer in Azure as well as the reinforcement of Data Governance and Data Management in the full Group.\nThe \u2018Data\u2019 function is a large multi-cultural organization with 600+ employees and contractors located mainly in 7 countries - Sweden, Poland, India, Belgium, Brazil, USA, and France. In this role you will be joining the Data Analyst Chapter team in France.\nWe collaborate with other parts of the organization, both in Volvo Digital & IT, with Truck Divisions, Business Areas and Group Functions. We foster an environment where ideas, thoughts and opinions can be shared. We are team players with clear common ambitions, and we win together.\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "R",
                "Go"
            ],
            "DataBase": [
                "SQL"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [
                "Databricks"
            ],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [
                "PowerBI"
            ],
            "Statistics": [],
            "CloudComputing": [
                "Azure"
            ],
            "DevTools": [
                "Git"
            ],
            "Os": [],
            "DBMS": [
                "SQL Server"
            ],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [
                "Teams"
            ],
            "Other": [
                "Machine Learning"
            ],
            "FrSoftSkills": [
                "Communication"
            ],
            "EnSoftSkils": [
                "Communication",
                "Teamwork",
                "Organization"
            ]
        },
        "details": {
            "JobDetail": [
                "Full"
            ],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "Data Engineer",
        "company": "DXC Technology",
        "location": "La D\u00e9fense, \u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/data-engineer-at-dxc-technology-3754144852?position=7&pageNum=45&refId=helkV5fb1RK2O%2B2D3vOHXQ%3D%3D&trackingId=%2BvXftRJJ6zT01L49fbFMwQ%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Job Description\nChez DXC Technology, nous agissons en tant que conseiller ind\u00e9pendant et de confiance dans la num\u00e9risation de l'entreprise du client. Nos employ\u00e9s sont responsables de l'optimisation des processus industriels de nos clients dans de nombreux domaines de march\u00e9 diff\u00e9rents ainsi que du d\u00e9veloppement, de la mise en \u0153uvre et de la gestion de leurs m\u00e9canismes li\u00e9s aux donn\u00e9es informatiques.\nDXC Technology conseille, d\u00e9veloppe et met en \u0153uvre des solutions d'analyse et d'IA modernes en appliquant l'expertise de l'industrie, des solutions et services technologiques et commerciaux, des m\u00e9thodologies \u00e9prouv\u00e9es et des personnes exp\u00e9riment\u00e9es. Gr\u00e2ce \u00e0 nos offres, nos capacit\u00e9s et notre port\u00e9e mondiale, les organisations acc\u00e9l\u00e8rent la transformation num\u00e9rique et produisent en toute confiance des r\u00e9sultats commerciaux reproductibles et aliment\u00e9s par l'IA. Nous travaillons avec nos clients pour convertir les donn\u00e9es en informations, les informations en id\u00e9es et les id\u00e9es en meilleurs r\u00e9sultats commerciaux.\nDans notre \u00e9quipe DXC Technology, nous recherchons actuellement un Data Engineer. Les domaines typiques dans lesquels vous travaillerez sont : les solutions et services d'analyse, les plates-formes Big Data, l'intelligence artificielle et l'IoT.\nFonctions Professionnelles Essentielles\nConcevoir et mettre en \u0153uvre des pipelines d'ingestion de donn\u00e9es par lots et en temps r\u00e9el pour Azure Data Lake ou similaires sur autres Cloud Solution Providers (AWS, GCP)\nMettre en \u0153uvre des contr\u00f4les de qualit\u00e9 des donn\u00e9es\nMettre en \u0153uvre des m\u00e9canismes de lignage, d'agr\u00e9gation et de r\u00e9conciliation des donn\u00e9es (y compris des tableaux de bord et des alertes)\nMise en \u0153uvre du catalogage des donn\u00e9es, de l'archivage et de la reprise apr\u00e8s sinistre\nTravailler avec les \u00e9quipes de source de donn\u00e9es et de consommation de donn\u00e9es pour s'aligner sur les structures et les sch\u00e9mas de donn\u00e9es\nComp\u00e9tences\nFamiliarit\u00e9 avec les technologies modernes bas\u00e9es sur le cloud (data lakes, data warehouses, ETL/ELT, Spark)\nExp\u00e9rience de la mise en \u0153uvre de pipelines d'ingestion de donn\u00e9es / ETLs / ELTs\nConnaissance g\u00e9n\u00e9rale d'Azure ou d'une plate-forme et d'un \u00e9cosyst\u00e8me comparables \u2013 Storage Account, CosmosDB (SQL & Gremlin API), Event Hub, App Services\nExp\u00e9rience avec au moins 3 des technologies de donn\u00e9es Azure suivantes ou des technologies Cloud similaires:\nAzure SQL\nAzure Data Lake\nAzure Databricks (SQL ou Python, Delta Lake)\nAzure Data Factory\nAzure Analysis Services\nExp\u00e9rience avec SQL, Python\net\nBaccalaur\u00e9at ou dipl\u00f4me sup\u00e9rieur en informatique, en ing\u00e9nierie commerciale, en informatique ou dans une discipline technique connexe\n1-3 ans d'exp\u00e9rience sur le terrain dans un r\u00f4le similaire\nMa\u00eetrise du fran\u00e7ais et de l'anglais\nPersonnalit\u00e9\nConcentr\u00e9 sur l'avancement du client avec des livrables de qualit\u00e9 dont vous pouvez \u00e9galement \u00eatre fier\nAttention aux d\u00e9tails et aux objectifs\nAimer faire partie d'une \u00e9quipe DXC et client\nD\u00e9montrer l'appropriation\nUn \u00e9tat d'esprit positif\nCe Que Vous Obtiendrez\nUn paquet salarial motivant, comprenant des avantages sociaux, des horaires de travail flexibles et la possibilit\u00e9 de travailler \u00e0 domicile\nFaire partie d'une \u00e9quipe ambitieuse et en pleine croissance\nFormation en cours d'emploi et acc\u00e8s \u00e0 notre plateforme en ligne \u201cDXC-University\u201d\nL'opportunit\u00e9 de travailler avec les derni\u00e8res technologies pour un large \u00e9ventail de clients\nRecruitment fraud is a scheme in which fictitious job opportunities are offered to job seekers typically through online services, such as false websites, or through unsolicited emails claiming to be from the company. These emails may request recipients to provide personal information or to make payments as part of their illegitimate recruiting process. DXC does not make offers of employment via social media networks and DXC never asks for any money or payments from applicants at any point in the recruitment process, nor ask a job seeker to purchase IT or other equipment on our behalf. More information on employment scams is available here\n.\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "R"
            ],
            "DataBase": [
                "SQL"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [
                "Spark",
                "Databricks"
            ],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [
                "Tableau"
            ],
            "Statistics": [],
            "CloudComputing": [
                "AWS",
                "Azure"
            ],
            "DevTools": [
                "Git"
            ],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [
                "Big Data",
                "ML",
                "Cloud"
            ],
            "FrSoftSkills": [
                "Organisation"
            ],
            "EnSoftSkils": []
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s",
                "3",
                "3",
                "3"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "Data Engineer (F/H)",
        "company": "Groupe SII",
        "location": "Montpellier, Occitanie, France",
        "link": "https://fr.linkedin.com/jobs/view/data-engineer-f-h-at-groupe-sii-3906253305?position=8&pageNum=45&refId=helkV5fb1RK2O%2B2D3vOHXQ%3D%3D&trackingId=WCihcTF8zDatDHW40GOocw%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "SII Montpellier\naccompagne ses clients dans l\u2019int\u00e9gration des nouvelles technologies, proc\u00e9d\u00e9s et m\u00e9thodes de management de l\u2019innovation pour contribuer au d\u00e9veloppement de leurs futurs produits ou services et faire \u00e9voluer leurs syst\u00e8mes d\u2019information. Nous conjuguons de mani\u00e8re durable et vertueuse la satisfaction de nos clients avec le bien-\u00eatre et l\u2019\u00e9panouissement de nos collaborateurs tout en d\u00e9livrant un haut niveau de performance.\nAu travers de notre entit\u00e9 compos\u00e9e d\u2019une quarantaine de consultants et de leurs expertises li\u00e9es au d\u00e9veloppement applicatif, \u00e0 la gestion de projets et d\u2019infrastructures, au test et aux enjeux autour de la data et cyber s\u00e9curit\u00e9. Nous intervenons aujourd\u2019hui sur des projets \u00e0 forte valeur ajout\u00e9e, ambitieux et \u00e0 l\u2019international autour des secteurs du num\u00e9rique, du t\u00e9l\u00e9com, de la banque/assurance, de l\u2019industrie et des services en assistance technique et/ou en engagement (centre de services, centre de comp\u00e9tences, ...). Nous accompagnons de nombreux acteurs locaux (Montpellier et agglom\u00e9ration) vous permettant de trouver plusieurs opportunit\u00e9s proches de chez vous ou depuis chez vous (flexibilit\u00e9 / mode de fonctionnement hybride).\nVous rejoindrez une \u00e9quipe soud\u00e9e, talentueuse et engag\u00e9e qui priorise le bien-\u00eatre au travail, l\u2019humilit\u00e9 et le partage. Vos comp\u00e9tences techniques et votre savoir-\u00eatre seront mis en valeur au sein de missions sur des sujets vari\u00e9s allant de la conception et d\u00e9veloppement d\u2019applications web, mobile, IHM \u00e0 la gestion d\u2019infrastructure traditionnelle et Cloud en passant par la gestion de projets agiles.\nRencontrons-nous et valorisons ensemble nos savoir-faire.\nDans le but de r\u00e9pondre aux demandes de nos partenaires, nous ouvrons un poste en qualit\u00e9 de\nData Engineer\n(F/H), sur\nMontpellier\n(34).\nVos Missions\nCollecter et stocker les donn\u00e9es\nComprendre les besoins des utilisateurs\nD\u00e9terminer la coh\u00e9rence des donn\u00e9es\nImpl\u00e9menter des outils de pointe pour faciliter l\u2019usage des donn\u00e9es dans l\u2019entreprise et am\u00e9liorer l\u2019efficacit\u00e9 op\u00e9rationnelle.\nDipl\u00f4m\u00e9(e) d'un Master en Informatique, d'une \u00e9cole d'Ing\u00e9nieur ou \u00e9quivalent, vous disposez d'une exp\u00e9rience de\nminimum 5 ans\nsur des comp\u00e9tences similaires en DATA. Vos comp\u00e9tences techniques sur SSAS, SSIS, SSRS seront un vrai plus !\nLa rigueur, la patience et la curiosit\u00e9 sont vos points forts. Vous disposez d'un important esprit d\u2019\u00e9quipe et faites preuve de bienveillance au quotidien.\nLe Groupe SII est une soci\u00e9t\u00e9 d\u2019ing\u00e9nierie et de conseils en technologies (ICT) et une entreprise de services num\u00e9riques (ESN).\nNous sommes au c\u0153ur de l'innovation au service de grands comptes dans des secteurs d'ing\u00e9nierie vari\u00e9s.\nEn 2023, pour la\n6e ann\u00e9e cons\u00e9cutive\n, SII France a obtenu le label\nGreat Place To Work\n\u00ae.\nNous avons \u00e9t\u00e9 reconnus\n3e entreprise de \u00ab + de 2500 salari\u00e9s \u00bb\no\u00f9 il fait bon vivre.\nNous sommes tr\u00e8s fiers d\u2019obtenir cette reconnaissance de nos salari\u00e9s !\nCe succ\u00e8s est le reflet de notre culture bas\u00e9e sur notre volont\u00e9 de proposer \u00e0 tous nos salari\u00e9s un cadre de travail \u00e9panouissant pour le d\u00e9veloppement de leurs comp\u00e9tences et carri\u00e8res.\nEn fonction de la mission, il est possible de r\u00e9aliser jusqu'\u00e0\n50 % de t\u00e9l\u00e9travail\ngr\u00e2ce \u00e0 notre accord d\u00e9di\u00e9. Rejoignez le\nmouvement #fungenieur\ndans lequel la passion pour la technologie, la cr\u00e9ativit\u00e9, la proximit\u00e9 et l\u2019esprit d\u2019\u00e9quipe sont mis \u00e0 l\u2019honneur.\nLe Groupe SII est une soci\u00e9t\u00e9 handi-accueillante, signataire de la Charte de la diversit\u00e9 en entreprise.\nAlors si ces valeurs vous parlent, rejoignez-nous !\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "R"
            ],
            "DataBase": [],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [],
            "DevTools": [],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [
                "Cloud"
            ],
            "FrSoftSkills": [
                "Cr\u00e9ativit\u00e9",
                "Flexibilit\u00e9"
            ],
            "EnSoftSkils": []
        },
        "details": {
            "JobDetail": [
                "Hybride"
            ],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s",
                "5",
                "5",
                "5"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "Senior Data Engineer",
        "company": "Harnham",
        "location": "Paris, \u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/senior-data-engineer-at-harnham-3903984738?position=9&pageNum=45&refId=helkV5fb1RK2O%2B2D3vOHXQ%3D%3D&trackingId=7ERt5GvD3YB7YI%2FhPxHcXQ%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "SENIOR DATA ENGINEER\nPARIS (75)\n75-80K EUR\nCette entreprise sp\u00e9cialis\u00e9e dans le marketing et la publicit\u00e9 mobile recherche activement un(e) Senior Data Engineer. Le Machine Learning constitue le c\u0153ur de son expertise, avec des solutions technologiques novatrices visant \u00e0 am\u00e9liorer la performance publicitaire sur smartphones et tablettes.\nVOTRE MISSION :\nAssurer le bon fonctionnement de l\u2019infrastructure de donn\u00e9es.\nSuperviser le traitement, le stockage, et l\u2019agr\u00e9gation des donn\u00e9es.\nProposer de nouvelles id\u00e9es pour am\u00e9liorer les outils et les flux de travail.\nG\u00e9rer les algorithmes de data science.\nCollaborer \u00e9troitement avec l\u2019\u00e9quipe SCRUM.\nRationaliser les processus de donn\u00e9es pour une efficacit\u00e9 maximale.\nVOTRE PROFIL :\nDiplome d\u2019une \u00e9cole d\u2019ing\u00e9nieur / Master\nAu moins 4 ans d\u2019exp\u00e9rience (minimum hors stage et alternance)\nComp\u00e9tences solides en Spark, Scala, Kafka et Python (obligatoire)\nMiatrise de la gestion des syst\u00e8mes Big Data.\nConnaissance d\u2019AWS ou GCP\nAnglais: Fluent obligatoire\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "Scala",
                "R",
                "Go"
            ],
            "DataBase": [],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [
                "Spark"
            ],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [
                "AWS"
            ],
            "DevTools": [],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [
                "Big Data",
                "Machine Learning"
            ],
            "FrSoftSkills": [],
            "EnSoftSkils": []
        },
        "details": {
            "JobDetail": [
                "Senior"
            ],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s",
                "4",
                "4",
                "4"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "Data Analyst H/F",
        "company": "GECO RECRUTEMENT",
        "location": "Pontivy, Brittany, France",
        "link": "https://fr.linkedin.com/jobs/view/data-analyst-h-f-at-geco-recrutement-3915127710?position=10&pageNum=45&refId=helkV5fb1RK2O%2B2D3vOHXQ%3D%3D&trackingId=oZ0%2FOs6rk3MLsRzAQbCLcQ%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Geco est un cabinet de recrutement ind\u00e9pendant.\nNous intervenons aupr\u00e8s des cabinets et des entreprises dans la recherche de profils cibl\u00e9s.\nNous accompagnons les candidats dans leurs recherches d'emploi et s'assurons que leurs souhaits professionnels se r\u00e9alisent.\nEn lien permanent avec l'entreprise et le candidat tout au long du processus de recrutement, l'\u00e9coute et la disponibilit\u00e9 vont guider nos interventions afin de r\u00e9pondre au mieux \u00e0 l'int\u00e9r\u00eat des deux parties.\nNous recherchons actuellement un Data Analyst H/F pour rejoindre une \u00e9quipe dynamique au sein d'une industrie en pleine croissance situ\u00e9e \u00e0 proximit\u00e9 de Pontivy.\nEn Tant Que Data Analyst, Vous Serez Responsable De L'analyse Des Donn\u00e9es Afin D'optimiser Les Processus Et De Fournir Des Informations Cl\u00e9s \u00e0 L'entreprise. Vos Principales Missions Seront Les Suivantes\nCollecter, nettoyer et organiser les donn\u00e9es provenant de sources diverses\nAnalyser les donn\u00e9es pour identifier des tendances, des corr\u00e9lations et des insights\nCr\u00e9er des tableaux de bord et des rapports pour pr\u00e9senter les r\u00e9sultats de mani\u00e8re claire et compr\u00e9hensible\nCollaborer avec les diff\u00e9rents d\u00e9partements de l'entreprise pour r\u00e9pondre \u00e0 leurs besoins en termes d'analyse de donn\u00e9es\nParticiper \u00e0 l'am\u00e9lioration des outils et des processus li\u00e9s \u00e0 l'analyse de donn\u00e9es\nVeiller \u00e0 la s\u00e9curit\u00e9 et \u00e0 la confidentialit\u00e9 des donn\u00e9es\nIssu(e) d'une formation Bac +3, vous justifiez d'une exp\u00e9rience sur des fonctions similaires d'au moins 1 an.\nVous avez une expertise dans l'utilisation, l'administration et le d\u00e9veloppement de QlikView / QlikSense ainsi que de Power BI.\nPossibilit\u00e9 de t\u00e9l\u00e9travail 2 jours par semaine.\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "R"
            ],
            "DataBase": [],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [
                "Tableau",
                "Power BI"
            ],
            "Statistics": [],
            "CloudComputing": [],
            "DevTools": [],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [],
            "FrSoftSkills": [],
            "EnSoftSkils": []
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "Ing\u00e9nieur Data SPARK/SCALA (H/F)",
        "company": "DHM IT",
        "location": "Neuilly-sur-Seine, \u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/ing%C3%A9nieur-data-spark-scala-h-f-at-dhm-it-3664561715?position=1&pageNum=47&refId=ulU0mGztWnF4llUcE%2BYHkw%3D%3D&trackingId=MDVOaMAeHhMiqmI8Ki21tA%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Dans le cadre de notre croissance et Afin de renforcer notre Squad Data, nous recherchons plusieurs Ing\u00e9nieurs Data Spark/Scala\nInt\u00e9gr\u00e9.e au sein de nos \u00e9quipes bas\u00e9es \u00e0 Neuilly Sur Seine et/ou la r\u00e9gion parisienne, vous pourrez mettre en pratique vos acquis et d\u00e9velopper de nouvelles comp\u00e9tences techniques.\nMISSIONS:\nAu sein de l'\u00e9quipe projet Business Intelligence & Big Data, l'ing\u00e9nieur SPARK/SCALA aura les activit\u00e9s suivantes :\nConception d\u00e9taill\u00e9e, fonctionnelle et technique.\nD\u00e9veloppements SPARK / SCALA\nContribution \u00e0 la formalisation des plans de tests, ex\u00e9cution des tests unitaires et d'un premier niveau de tests d'int\u00e9gration.\nR\u00e9solution des anomalies pendant les phases d\u2019int\u00e9gration fonctionnelle et de recette utilisateur.\nPackaging et d\u00e9ploiement en pre-production et production.\nOptimisation des traitements afin de garantir la qualit\u00e9 de service standards du DWG.\nMise en \u0153uvre des solutions industrielles et de r\u00e9entrance permettant une reprise optimum des traitements en cas d\u2019incident en production.\nMise en service et accompagnement au d\u00e9ploiement.\nSuivi des environnements.\nPROFIL:\nUne connaissance d'Oracle est n\u00e9cessaire\nUne exp\u00e9rience >5 ans sur des technologies SPARK & SCALA est n\u00e9cessaire\nUne connaissance de contexte technologique similaire est un plus\nSOFT SKILLS:\nPassionn\u00e9.e par les technologies innovantes;\nD\u00e9sireux.se de t\u2019investir dans des projets challengeants et gagner rapidement en responsabilit\u00e9s;\nP\u00e9dagogue, emphatique et \"Problem Solver\";\nDot\u00e9.e d\u2019un excellent relationnel, d\u2019un sens prononc\u00e9 du service et de la qualit\u00e9;\nExcellent niveau de Fran\u00e7ais \u00e0 l'oral et \u00e0 l'\u00e9crit, l'Anglais serait un v\u00e9ritable plus.\nAVANTAGE / CONTEXTE :\nEntreprise de nouvelle g\u00e9n\u00e9ration \u00e0 taille humaine, DHM IT s\u2019engage fortement dans la mouvance RSE en proposant \u00e0 ses consultants et salari\u00e9s un cadre de travail sain o\u00f9 chacun pourra s\u2019\u00e9panouir, se former et progresser \u00e0 son rythme et selon ses aspirations.\nR\u00e9mun\u00e9ration attractive;\nUn fort esprit Startup nouvelle g\u00e9n\u00e9ration;\nParticipation dans notre strat\u00e9gie RSE;\nFormation, certification, Workshop, DHM University;\nCarte resto, Titre de transport, Mutuelle et pr\u00e9voyance;\nTeam buildings, Events, Sport Collectif;\nTravail remote friendly;\nUn environnement de travail 100% Agile / Cloud;\nDes challenges, des nouvelles exp\u00e9riences et des projets innovants;\nUne\u202fhi\u00e9rarchie\u202fSmart.\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Scala",
                "R",
                "Go"
            ],
            "DataBase": [],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [
                "Spark"
            ],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [],
            "DevTools": [],
            "Os": [],
            "DBMS": [
                "Oracle"
            ],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [
                "Big Data",
                "Cloud"
            ],
            "FrSoftSkills": [],
            "EnSoftSkils": []
        },
        "details": {
            "JobDetail": [
                "Remote"
            ],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s",
                "5",
                "5",
                "5"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "Pricing Data Engineer",
        "company": "Luko",
        "location": "Paris, \u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/pricing-data-engineer-at-luko-3914821636?position=2&pageNum=47&refId=ulU0mGztWnF4llUcE%2BYHkw%3D%3D&trackingId=00Usttp0bRUbWMGJLkCsxw%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Your mission in the team:\nLuko x Allianz Direct has a mission to create insurance products which meet each user needs, transparent and quickly available, with a fair price.\nAs a Pricing Data Engineer, your job is build & transform the data and develop the tooling required for pricing analysis, strategies, and operations.\nYou will work closely with the Pricing team as well as with the Product team.\nYour main missions will be:\nCreate and refine our pricing data infrastructure, laying the groundwork for continually improving analytics capabilities and helping create the best data models for modern insurance pricing\nDevelop and maintain our pricing monitoring and testing tools, including automating processes and integrating interfaces with product teams to enhance testing efficiency and streamline rollout productivity\nImplement live reporting mechanisms to effectively communicate pricing monitoring results, while actively contributing to steering the company towards its profitability objectives through data-driven insights and strategic pricing adjustments\nDesign and implement scalable data models and control structures to encompass all products and channels, ensuring seamless integration and adaptability across the entire spectrum of our operations\nParticipate on developments related to the pricing engine\nYour profile:\n\ud83d\udccd Role based in Paris\nTo excel in this role, we recommend the following qualifications and attributes:\nProfessional Experience: 2 to 5 years of experience as a Data Engineer or Analyst.\nEducation: A Master's degree in Data Science, Statistics, or Computer Science is preferred but not mandatory.\nSpecialization: Prior experience in Data & Analytics is highly desirable.\nAnalytical Skills: Exceptional analytical and synthesis abilities.\nTechnical Proficiencies:\nProficient in data processing platforms, specifically DBT.\nStrong programming skills in Jinja and SQL.\nFamiliarity with version control systems, particularly GitLab.\nLanguages: Proficiency in English is required; French proficiency would be an asset.\nPersonal Attributes: Must be a collaborative team player, detail-oriented, and well-organized. Should also demonstrate proactivity and the ability to work independently.\nWhat is in it for you?\nThis is an opportunity to join a company in the process of scaling up, a team on a human scale and to work with Allianz Direct's European subsidiaries to exchange best practices and deal with cross-functional issues, and why not benefit from group mobility in Europe?\nInternational and friendly team & Office in Paris\nGroup mobility in Europe\nMeal vouchers\nHealth Insurance\nRemote-friendly policy\nFree book policy\nOur recruitment process:\nFirst interview/ Introduction call with your future manager Alexis (Lead Pricing Manager)\nCase study + debrief with Alexis and Julien (Chief Actuary)\nTechnical interview with Gautier (Backend Developer)\nLukofit interview with a member of the People team\nAllianz Direct France x Luko, Who are we?\nWe created Luko with a simple vision.\n50% of consumers don\u2019t trust their insurer, yet it is mandatory in many cases and it is the\nonly stakeholder you can turn to when damage occurs in your home. So we decided to\nreinvent insurance to make it finally customer-centric like we believe it was meant to be.\nWe started by creating the most transparent and useful insurance company out there:\none that you can finally trust, because its business model was designed for positive impact and because its product experience is meant to empower users rather than mislead them.\nWe created the most intuitive and user-obsessed insurance experience you can wish\nfor:\nsubscription in 2 minutes, a simple offer, customisable coverages, no hidden fees, policies without any engagement, termination in 3 clicks.\nIn 6 years, we have convinced over 400,000 users to trust us. We rapidly became the online home insurance market, putting technology at the service of customer satisfaction and operational efficiency: by 2022, 25% of home insurance policies sold online in France were Luko policies; and nearly one in two new Luko customers took out a policy on the\nrecommendation of friends and family.\nIn February 2024, Luko joins Allianz Direct, the digital pan-European subsidiary of the\nAllianz Group, with the aim of becoming the market leader in direct home insurance in\nFrance. This makes Luko emerging the strongest neo-insurer.\nTogether, and because Luko and Allianz Direct share a common vision and DNA, we will continue our mission to shake up the market by offering the best value for money and even more simplicity and transparency.\nAllianz Direct DNA\nBecoming part of the Allianz Direct organisation means that you have a match with our DNA. We have the following 6 core values:\nCustomer obsessed\nCommunicative\nData-driven\nAgility\nTeam player\nOpen-minded\nYou\u2019ve read all the way, you may as well apply!\nOur company-wide communication language is English (written & spoken).\nWe would therefore appreciate it if you could send us your application\u2019s content (CV, cover letter, portfolio\u2026) in English.\nBelonging: Diversity, Inclusion & Equity\nWe believe inclusion is the result of ongoing commitment. We want to build an authentic environment, open to everyone regardless of nationality, physical ability, family structure, age, socio-economics, civil status, sexual orientation, gender identity, ethnic origin, religion, belief or anything else that makes your life experience unique. We are continuously working to create a diverse, equitable and inclusive environment, where everyone has a space to thrive.\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Scala",
                "R",
                "Go"
            ],
            "DataBase": [
                "SQL"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [
                "Statistics"
            ],
            "CloudComputing": [],
            "DevTools": [
                "Git"
            ],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [
                "Teams"
            ],
            "Other": [
                "ML"
            ],
            "FrSoftSkills": [
                "Communication",
                "Organisation"
            ],
            "EnSoftSkils": [
                "Communication",
                "Adaptability"
            ]
        },
        "details": {
            "JobDetail": [
                "Remote"
            ],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "CDI - Ing\u00e9nieur Data (H/F)",
        "company": "Herm\u00e8s",
        "location": "Pantin, \u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/cdi-ing%C3%A9nieur-data-h-f-at-herm%C3%A8s-3850308968?position=3&pageNum=47&refId=ulU0mGztWnF4llUcE%2BYHkw%3D%3D&trackingId=aDeaStLnXo4DASVbz%2FiWIA%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Contexte\nAu sein de la DSI Groupe de la Maison Herm\u00e8s, la Direction des Infrastructures et des Op\u00e9rations fournit et supporte l\u2019ensemble des services d\u2019infrastructure avec les niveaux d\u2019expertise requis. Elle construit et s\u00e9curise le fonctionnement des plates-formes applicatives afin de fournir une infrastructure technologique stable et efficace pour les clients internes au niveau du groupe et en local.\nActivit\u00e9s principales\nEn tant qu'Ing\u00e9nieur Data (H/F), vous \u00eates responsable d\u2019un ou plusieurs services technologiques sur les plateformes DATA (BDD, Data Lake, Data Streaming).\nCe domaine d\u00e9signe l\u2019ensemble des services visant \u00e0 assurer la collecte, le stockage, la valorisation et la mise \u00e0 disposition des donn\u00e9es. Le p\u00e9rim\u00e8tre Data int\u00e8gre notamment la gestion des bases de donn\u00e9es (relationnelles et non relationnelles), solutions de donn\u00e9es non structur\u00e9es (Data cloud), flux temps r\u00e9el (Data Streaming) ainsi que les outils de r\u00e9plication et de synchronisation.\nVos principales responsabilit\u00e9s sont de :\nAssurer le Build et le Run des services de votre p\u00e9rim\u00e8tre\nD\u00e9finir le planning de d\u00e9veloppement, les exigences et les pr\u00e9requis au d\u00e9ploiement des services de votre p\u00e9rim\u00e8tre\n\u00catre responsable du d\u00e9veloppement global et du packaging d'un service\nConstruire et g\u00e9rer les socles et les services technologiques de votre p\u00e9rim\u00e8tre et en d\u00e9finir la strat\u00e9gie d\u2019\u00e9volution en collaboration avec l\u2019\u00e9quipe Architecture & Innovation\nPiloter et monitorer la performance et la disponibilit\u00e9 des socles et services\nAssurer la gestion sur l\u2019ensemble du cycle de vie de vos socles et services (\u00e9volution, licences, maintenance, d\u00e9commissionnement, etc.), g\u00e9rer leur obsolescence et r\u00e9duire la dette technique.\nFournir un support technique N2/N3 sur votre p\u00e9rim\u00e8tre\nProfil souhait\u00e9\nDipl\u00f4m\u00e9(e) d'un Bac + 5, vous disposez d'au moins 5 ans d'exp\u00e9rience dans la construction, l'int\u00e9gration, le d\u00e9ploiement d'infrastructure syst\u00e8me/r\u00e9seau dans des environnements Cloud et hybrides.\nVous maitrisez les technologies de bases de donn\u00e9es relationnelles (MSSQL, Oracle, PostGreSQL) et non relationnelles (MongoDB). Vous poss\u00e9dez de solides comp\u00e9tences dans le d\u00e9veloppement et la mise en place de pipeline de donn\u00e9es, notamment le Data Streaming. Les technologies de plateformes Data Modernes, Cloud et On Premise, n'ont plus de secrets pour vous.\nOrient\u00e9(e) client et esprit d'\u00e9quipe, vous \u00eates capables de traduire et analyser les exigences business en exigences techniques en gardant un discours impactant. Vous savez appr\u00e9hender et g\u00e9rer les risques et recherchez \u00e0 monter rapidement en comp\u00e9tences sur de nouvelles technologies et proc\u00e9dures.\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "R",
                "Go"
            ],
            "DataBase": [
                "SQL"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [],
            "DevTools": [],
            "Os": [],
            "DBMS": [
                "PostgreSQL",
                "Oracle"
            ],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [
                "Cloud"
            ],
            "FrSoftSkills": [
                "Collaboration"
            ],
            "EnSoftSkils": [
                "Collaboration"
            ]
        },
        "details": {
            "JobDetail": [
                "Hybride"
            ],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s",
                "5",
                "5",
                "5"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "Data Analyst Junior",
        "company": "Unlimitail",
        "location": "Paris, \u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/data-analyst-junior-at-unlimitail-3912999630?position=4&pageNum=47&refId=ulU0mGztWnF4llUcE%2BYHkw%3D%3D&trackingId=DFtU9h6mBh4XTShonIKYVQ%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Unlimitail\nis a joint venture between\nCarrefour\nGroup and\nPublicis\nGroup, intending to become the leader of the\nretail media market in Europe and Latin America\n. It combines the power of Carrefour Links' in-store and e-commerce assets and traffic with Publicis\nCitrus Ad and Epsilon's\non-site and off-site retail media technologies. The goal of Unlimitail is to become the premier retail media player in Continental Europe and South America for both in-store and digital channels.\nMissions\nWithin the Product team, your mission will be to participate in the development of Unlimitail\u2019s analytics capabilities. Your environment will be millions of transactional data coming from major retailers on the market to analyze and improve the performance of online and offline marketing campaigns.\nAs we work with both retailers (providing media inventory) and brands (buying media inventory), you will have the opportunity to gain a deep understanding of the retail media ecosystem.\nYou will work with different teams (Ad Operations, Marketing, Sales) in different countries and on a wide variety of topics:\n- Perform e-commerce campaigns analysis to provide detailed insights\n- Conduct end-to-end ad hoc analysis to help retailers best monetize their inventory\n- Participate in the design and maintenance of databases, using SQL to store and manage data efficiently\n- Work on automating data analysis and data visualization capabilities\n- Work on Unlimitail\u2019s customer lifetime value calculation capability\n- Participate in the development of new, cutting-edge abilities to create the best\nRequirements\n:\n\u00b7 Master's degree in Data Analysis, business analytics, Computer Science, Statistics, Mathematics, Engineering, or a related field.\n\u00b7 Data Analysis: Proven ability to analyze large datasets, identify trends, and extract actionable insights through using strong SQL skills for querying and data extraction.\n\u00b7 Programming Languages: Python and SQL are mandatory. Any other is a plus\n\u00b7 Data Visualization: previous experience in creating interactive and insightful visualizations, using tools like Power BI or Looker is a big plus\n\u00b7 Knowledge of GCP or Azure environment is a plus\n\u00b7 Problem-solving: Adept at approaching analytical problems and proposing effective solutions.\n\u00b7 Good communication skills in English. Another language (Spanish, Portuguese) is a plus.\n\u00b7 Strong team player with the ability to collaborate effectively\nBenefits\n:\n\u00b7 2 days of WFH\n\u00b7 90% reimbursement of public transportation fees\n\u00b7 Office located in central Paris (Chatelet)\n\u00b7 Swile card of 10\u20ac/working days\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "R",
                "Go"
            ],
            "DataBase": [
                "SQL"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [
                "Power BI"
            ],
            "Statistics": [
                "Statistics"
            ],
            "CloudComputing": [
                "Azure"
            ],
            "DevTools": [
                "Git"
            ],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [
                "Teams"
            ],
            "Other": [],
            "FrSoftSkills": [
                "Communication"
            ],
            "EnSoftSkils": [
                "Communication"
            ]
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "Consultant Data Engineer / Data Management F/H",
        "company": "VISEO",
        "location": "Toulouse, Occitanie, France",
        "link": "https://fr.linkedin.com/jobs/view/consultant-data-engineer-data-management-f-h-at-viseo-3111089632?position=5&pageNum=47&refId=ulU0mGztWnF4llUcE%2BYHkw%3D%3D&trackingId=t3x0qD06L2z9%2FHONHHn2cA%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Vous avez une forte app\u00e9tence pour\nl'int\u00e9gration de donn\u00e9e et le d\u00e9veloppement\n?\nVous souhaitez travailler sur des technologies du\nCloud et des solutions innovantes\n?\nVous\u00a0\u00eates adepte\u00a0de la\nveille\u00a0technologique\n?\nAu sein de\u00a0VISEO\u00a0nous recherchons un\nConsultant Data Engineer / Data Management\u00a0F/H\npour intervenir\u00a0sur\u00a0nos projets et contribuer au d\u00e9veloppement de notre Practice \u00ab Data Management \u00bb\nVISEO\u00a0organise\u00a0et sponsorise\u00a0de\u00a0nombreux\u00a0\u00e9v\u00e9nements techniques\u00a0en interne et en externe\u00a0:\u00a0MixIT, Webinar,\u00a0TechAnHour,\u00a0Snowcamp...\u00a0Participer \u00e0 ces \u00e9v\u00e8nements sont pour nous un moyen\u00a0d\u2019animer la communaut\u00e9 et\u00a0de\u00a0conserver\u00a0un haut niveau d\u2019expertise.\nVos missions :\nAnalyser\net\ncomprendre\nles besoins des utilisateurs en termes de\ncollecte\n,\nstockage\n,\nvalorisation de la donn\u00e9e\nProposer une architecture adapt\u00e9e\n(On Premise, Cloud, hybrides, etc.)\nConcevoir les mod\u00e8les de donn\u00e9es\net\nles processus\n(data flows, Workflows, etc.)\nMettre en \u0153uvre\nla plateforme de\nData Management\net les\nd\u00e9veloppements n\u00e9cessaire pour l\u2019int\u00e9gration\n(ETL),\nla valorisation\n(Data Quality),\nl\u2019administration\n(Data Governance),\nla distribution\n(Data Hub) et\nle stockage de la donn\u00e9e\nTester\u00a0l\u2019architecture et\nles d\u00e9veloppements\n.\nV\u00e9rifier\nla coh\u00e9rence\nfonctionnelle\ndes donn\u00e9es en collaboration avec les\nr\u00e9f\u00e9rents m\u00e9tiers\nD\u00e9ployer\u00a0la solution\nen environnement de recette utilisateurs et \u00e9ventuellement, en environnement de\nproduction\nDans le cadre de projets\nData\n, vous accompagnerez nos\u00a0clients autour de la\nmise en place de\u00a0solutions\nqui auront pour\nobjectif la valorisation des donn\u00e9es\ncomme\ncapital strat\u00e9gique\nde l\u2019entreprise.\nPour cela vous serez amen\u00e9(e) \u00e0 utiliser les\nplateformes de Data Management modernes\nde nos\npartenaires\ntel que\nMicrosoft, Alteryx, Informatica, Talend, SAP, Microsoft Azure, Boomi, etc.\nCes activit\u00e9s pourront \u00eatre men\u00e9es dans des modes de\ncollaboration diff\u00e9rents\n(forfait, r\u00e9gie, mode Agile, m\u00e9thodologie sp\u00e9cifique\u2026).\nVotre profil :\nVous poss\u00e9dez une\u00a0exp\u00e9rience sur tout ou partie des activit\u00e9s d\u00e9crites pr\u00e9c\u00e9demment, en particulier sur les\nphases de\u00a0conception et de d\u00e9veloppement\u00a0de projets Data\n.\nUne exp\u00e9rience acquise autour\nd\u2019actions concr\u00e8tes d\u2019optimisation\n(technique ou fonctionnelle) serait un plus.\nVous ma\u00eetrisez tout ou partie d\u2019une ou plusieurs\ndes solutions ETL classiques\n(Informatica Power Center, Talend Studio, Microsoft SSIS, Alteryx, etc.)\net\\ou IPaaS\n(Azure Data Factory, Informatica IICS, Talend Cloud, Boomi, etc\u2026)\nVous ma\u00eetrisez tout ou partie d\u2019une ou plusieurs solutions de\nstockages de donn\u00e9es\n(Snowflake, Redshift, PostgreSQL, Oracle, etc.)\nL\u2019utilisation\nd\u2019outils de reporting / data visualisation\n(Tableau, Power BI, QlikSence...)\u00a0est \u00e9galement appr\u00e9ciable.\nVous\nappr\u00e9ciez la relation client\n(interlocuteur technique, contact utilisateur\u2026) et poss\u00e9dez un v\u00e9ritable\nsens du service\navec cette double comp\u00e9tence technico-fonctionnelle.\nVous \u00eates\nrigoureux(se), dynamique et dot\u00e9(e) d\u2019une curiosit\u00e9, d\u2019une agilit\u00e9 et d\u2019un esprit d\u2019\u00e9quipe\nvous permettant de vous adapter \u00e0 diff\u00e9rents contextes.\nInt\u00e9grer nos \u00e9quipes au quotidien, \u00e7a veut dire quoi ?\nVous ferez partie de\u00a0la\ncommunaut\u00e9\u00a0Data\n: la proximit\u00e9 et la taille humaine de notre organisation vous permettront de rendre visible vos initiatives et d\u2019\u00e9voquer facilement vos projets. En parall\u00e8le, le dynamisme de l\u2019entreprise et sa croissance perp\u00e9tuelle multiplieront vos opportunit\u00e9s d\u2019\u00e9volution.\nVous b\u00e9n\u00e9ficierez d\u2019un\u00a0management de proximit\u00e9\u00a0par votre mentor tout au long de votre parcours chez VISEO : Votre mentor, consultant exp\u00e9riment\u00e9 de votre practice, viendra r\u00e9guli\u00e8rement \u00e9changer avec vous sur les challenges de votre mission, faire chaque semestre le bilan de vos r\u00e9alisations et \u00e9voquer vos ambitions futures et les moyens de les r\u00e9aliser.\nVous disposerez\nde multiples moyens pour\u00a0monter en comp\u00e9tences\u00a0et d\u00e9couvrir de nouveaux domaines\u00a0: formations, certifications, Brown Bag Lunchs, ateliers,\u00a0meet-ups, rencontre d\u2019experts, s\u00e9minaires techniques\u2026\n#VISEO SPIRIT :\nUn programme d\u2019apprentissage en e-learning : acc\u00e8s digital\u00a0academy\u00a0et 7-speaking\nUn accompagnement pour le bien-\u00eatre\u202f: Sophrologie, Yoga,\u00a0Gymlib,\u00a0IKV\u00e9lo\u00a0\u2026\nDeux jours de t\u00e9l\u00e9travail par semaine\nDu mat\u00e9riel informatique puissant et un double \u00e9cran\nDes locaux agr\u00e9ables\u00a0proches du parc de la Cit\u00e9 de l'Espace\nN\u2019attendez plus, rejoignez VISEO. Devenez un #PositiveDigitalMaker !\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "R",
                "Go"
            ],
            "DataBase": [
                "SQL"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [
                "Tableau",
                "Power BI"
            ],
            "Statistics": [],
            "CloudComputing": [
                "Azure"
            ],
            "DevTools": [
                "Git"
            ],
            "Os": [],
            "DBMS": [
                "PostgreSQL",
                "Oracle",
                "Snowflake",
                "Snowflake"
            ],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [
                "ML",
                "Cloud"
            ],
            "FrSoftSkills": [
                "Collaboration",
                "Organisation"
            ],
            "EnSoftSkils": [
                "Collaboration",
                "Initiative"
            ]
        },
        "details": {
            "JobDetail": [
                "Hybride"
            ],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "Data Engineer & Architect 100% T\u00e9l\u00e9travail avec Quelques D\u00e9placements \u00e0 Lyon H/F",
        "company": "Proxiel",
        "location": "Montpellier, Occitanie, France",
        "link": "https://fr.linkedin.com/jobs/view/data-engineer-architect-100%25-t%C3%A9l%C3%A9travail-avec-quelques-d%C3%A9placements-%C3%A0-lyon-h-f-at-proxiel-3913995274?position=6&pageNum=47&refId=ulU0mGztWnF4llUcE%2BYHkw%3D%3D&trackingId=LrBkKjeQvUt5UD52y8KOhQ%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Depuis 1999, PROXIEL accompagne des entreprises dans leur d\u00e9veloppement en assurant des prestations de conseil et d'ing\u00e9nierie dans le domaine des technologies.\nProxiel : C'est plusieurs p\u00f4les d'activit\u00e9s.\nNous mettons un point d honneur \u00e0 associer votre bien-\u00eatre - adaptabilit\u00e9 en fonction de vos contraintes (possibilit\u00e9 de t\u00e9l\u00e9travail). Des solutions alternatives, peuvent \u00eatre envisag\u00e9es, dans la mesure o\u00f9 elles sont compatibles avec le business que nous entreprenons. Nous souhaitons que chacun de nos salari\u00e9s s investissent dans nos projets et que notre entreprise soit anim\u00e9e par un projet commun : la r\u00e9ussite de chacun !\nNotre approche est simple alors restons transparents dans nos \u00e9changes.\nNotre si\u00e8ge est implant\u00e9 \u00e0 Montpellier PROXIEL. Nous disposons \u00e9galement d une agence sur Paris\nVous pr\u00e9sentez des comp\u00e9tences dans les nouvelles technologies en qualit\u00e9 de techniciens d\u00e9veloppeurs ing\u00e9nieurs, cot\u00e9 d\u00e9veloppement ou r\u00e9seau, vous \u00eates bas\u00e9s ou mobile sur MONTPELLIER PARIS LYON TOULOUSE MARSEILLE AIX EN PROVENCE, NICE rejoignez-nous !\nBonjour,\nNous recherchons pour notre partenaire un Data Engineer & Architect (100% t\u00e9l\u00e9travail) avec quelque d\u00e9placement \u00e0 Lyon :\nVous \u00eates en charge de la conception et de la construction de pipelines de donn\u00e9es \u00e9volutifs permettant de r\u00e9cup\u00e9rer, d'agr\u00e9ger et de pr\u00e9traiter efficacement les donn\u00e9es provenant de diff\u00e9rentes sources, tout en garantissant une fiabilit\u00e9 et des performances \u00e9lev\u00e9es.\nVous \u00eates en charge de la conception des mod\u00e8les de donn\u00e9es, des solutions de stockage et des sch\u00e9mas d'acc\u00e8s.\nVous avez la possibilit\u00e9 de collaborer avec les parties prenantes pour comprendre les besoins et pour d\u00e9finir et faire \u00e9voluer la strat\u00e9gie d'architecture des donn\u00e9es, y compris la mod\u00e9lisation des donn\u00e9es, le stockage et les sch\u00e9mas d'acc\u00e8s.\nVous travaillez avec une \u00e9quipe agile interfonctionnelle pour int\u00e9grer des donn\u00e9es provenant de divers syst\u00e8mes et sources, effectuer des processus d'extraction, de transformation et de chargement (ETL) et maintenir l'int\u00e9grit\u00e9 des donn\u00e9es tout au long du pipeline, en it\u00e9rant sur les solutions et en communiquant sur les progr\u00e8s r\u00e9alis\u00e9s.\nMa\u00eetrise des langages de programmation\nUne solide compr\u00e9hension des technologies de base de donn\u00e9es (par exemple, SQL, NoSQL), des entrep\u00f4t de donn\u00e9es et d'Azure\nExp\u00e9rience en architecture de donn\u00e9es la conception de mod\u00e8les de donn\u00e9es, la d\u00e9finition de solutions de stockage et les sch\u00e9mas d'acc\u00e8s aux donn\u00e9es.\nFamiliarit\u00e9 avec le Machine learning, les concepts de traitement du langage naturel (NLP) et la G\u00e9n\u00e9ration Augment\u00e9e de R\u00e9cup\u00e9ration (RAG) est un plus.\nVous avez d'excellentes comp\u00e9tences en mati\u00e8re de communication et de collaboration, et \u00eates capable de travailler efficacement dans un environnement d'\u00e9quipe et dans le cadre de projets agiles.\nBac +5 ou \u00e9quivalent\nminimum : 3 ans d'exp\u00e9rience\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "R"
            ],
            "DataBase": [
                "SQL",
                "NoSQL"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [
                "Azure"
            ],
            "DevTools": [],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [
                "Machine Learning"
            ],
            "FrSoftSkills": [
                "Communication",
                "Adaptabilit\u00e9",
                "Collaboration"
            ],
            "EnSoftSkils": [
                "Communication",
                "Collaboration"
            ]
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s",
                "3",
                "3",
                "3"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "ALTERNANCE - DATA Engineer (F/H) - LILLE",
        "company": "BPCE Solutions informatiques",
        "location": "Lille, Hauts-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/alternance-data-engineer-f-h-lille-at-bpce-solutions-informatiques-3913916322?position=7&pageNum=47&refId=ulU0mGztWnF4llUcE%2BYHkw%3D%3D&trackingId=FY8M2DqNOomcT8cTtN9c0g%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Description de l'entreprise\nBPCE Solutions informatiques, c\u2019est un acteur IT de r\u00e9f\u00e9rence implant\u00e9 au c\u0153ur des territoires. Ce sont pr\u00e8s de 2 600 femmes et hommes au service des Banques Populaires, des Caisses d\u2019Epargne et de plusieurs m\u00e9tiers sp\u00e9cialis\u00e9s du Groupe BPCE, 2e acteur bancaire en France.\nNous imaginons et d\u00e9veloppons des solutions IT innovantes pour faciliter le quotidien de nos utilisateurs. Chaque jour, ce sont pr\u00e8s de 1 Fran\u00e7ais sur 2 qui utilisent nos solutions !\nEntreprise inclusive et engag\u00e9e, ce sont vos comp\u00e9tences qui font la diff\u00e9rence.\nLe t\u00e9l\u00e9travail et les horaires flexibles vous permettent de pr\u00e9server votre \u00e9quilibre de vie. Et en pr\u00e9sentiel, vous b\u00e9n\u00e9ficiez d\u2019un environnement innovant et responsable.\nNotre vision de l\u2019alternance ? \ud83d\ude80\nVous \u00eates accompagn\u00e9(e) et encourag\u00e9(e) par une \u00e9quipe bienveillante\nVous travaillez sur des projets d\u2019envergure au service de nos clients\nVous apprenez du savoir-faire de personnes passionn\u00e9es par leur m\u00e9tier\nVous d\u00e9ployez votre potentiel et consolidez votre projet professionnel\nAlors, rejoignez-nous pour profiter de la diversit\u00e9 du terrain de jeu que propose BPCE Solutions informatiques !\n\u26a1\nPoste et missions\nInt\u00e9grez la Plateforme Distribution et Data au sein de BPCE Solutions informatiques !\nAu sein de\nl'\u00e9quipe Produit DATA \"Socle D\u00e9cisionnel MYSYS\"\nde BPCE-SI, sous la direction du Scrum Master d'une des squads du produit, nous recherchons notre alternant(e).\nLe patrimoine technologique du produit est Oracle, AIX/Linux/Windows, VTOM, PowerBI/Business Object, semarchy, Angular, JSP, Java, python, shells, VBA, Power Designer.\nGestion en mode Agile (Scrum/Kanban)\nEn tant que\nDATA Engineer\n(F/H) en alternance, vous aurez pour missions :\nPrendre en charge des induits projet pour alimenter des entrep\u00f4ts de pilotage DATA du SI MYSYS des Caisses d'Epargne avec l'ETL Semarchy. Vous assurez l'int\u00e9gration de donn\u00e9es, qui seront exploit\u00e9es par les \u00e9tablissements bancaires. Vous mettrez en place les flux pour r\u00e9pondre au besoin des etablissements.\nIl sera demand\u00e9 \u00e9galement de compl\u00e9ter des informations fonctionnelles concernant le patrimoine des tables du produit.\nLors De Votre Alternance, Vous Vous Formerez Aux Techniques D'alimentation De La Squad Bas\u00e9es Sur L'\u00e9cosyst\u00e8me Suivant\nELT SEMARCHY\nSGBD Oracle/Exadata\nOrdonnanceur VTOM\nSyst\u00e8me AIX/Linux\nProfil et comp\u00e9tences requises\nVous recherchez une alternance dans le cadre de vos \u00e9tudes sup\u00e9rieures en informatique de niveau\nBac+3 \u00e0 Bac+5\n.\nVous avez envie d\u2019apprendre et d\u2019int\u00e9grer une entreprise dynamique et agile qui vous permettra d\u2019acqu\u00e9rir un r\u00e9seau et une premi\u00e8re exp\u00e9rience solide.\nVous avez \u00e0 c\u0153ur d'accompagner vos clients dans des projets d'envergure.\nVous \u00eates rigoureux(se) avec une bonne capacit\u00e9 d'analyse et de synth\u00e8se.\nVous avez un bon relationnel et un esprit positif, vous \u00eates curieux(se) et vous appr\u00e9ciez travailler en \u00e9quipe.\nComp\u00e9tences Et Connaissances Techniques\nExig\u00e9 :\nConnaissance du SQL\ncompr\u00e9hension du fonctionnel\nSouhait\u00e9\nprincipes architecturaux DATA.\nConnaissance d'un Syst\u00e8me d'exploitation \"Unix-like\"\nInformations Compl\u00e9mentaires\nDate de d\u00e9marrage souhait\u00e9e :\nRentr\u00e9e 2024\nRythme d'alternance souhait\u00e9 :\nSemaines compl\u00e8tes\nDur\u00e9e de l'alternance souhait\u00e9e :\n1 an ou 2 ans\nNotre processus de recrutement se compose de deux entretiens : un entretien RH avec Dana, puis un entretien op\u00e9rationnel avec Martial et Paul-Aziz.\nInformations compl\u00e9mentaires sur le poste\n\ud83e\udd1dBPCE SI, c'est un cadre de travail agr\u00e9able avec un accompagnement de proximit\u00e9, des formations, de multiples \u00e9volutions possibles au sein du groupe.\n\ud83d\ude89 80% de prise en charge des frais de transports en commun !\n\u2600\ufe0f Environ 9 semaines de cong\u00e9s annuels (cong\u00e9s et RTT).\n\ud83d\udcbb T\u00e9l\u00e9travail hybride ! 30 jours de t\u00e9l\u00e9travail par trimestre et flexibilit\u00e9 des horaires.\n\ud83c\udfb3 Un CSE actif ! Des locaux attractifs et des comit\u00e9s d'animations par site.\n\ud83c\udf96 Entreprise Partenaire premium des JO2024 et engag\u00e9e sportivement !\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "Java",
                "R",
                "Go"
            ],
            "DataBase": [
                "SQL"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [
                "PowerBI"
            ],
            "Statistics": [],
            "CloudComputing": [],
            "DevTools": [],
            "Os": [
                "Linux",
                "Windows"
            ],
            "DBMS": [
                "Oracle"
            ],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [],
            "FrSoftSkills": [
                "Flexibilit\u00e9"
            ],
            "EnSoftSkils": []
        },
        "details": {
            "JobDetail": [
                "Hybride"
            ],
            "TypeContract": [],
            "Salary": [],
            "Level": [
                "Bac+5",
                "Bac+3"
            ],
            "Experience": [
                "a",
                "n",
                "s",
                "2",
                "2",
                "2"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "Data Analyst F/H",
        "company": "SOFTEAM",
        "location": "Paris, \u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/data-analyst-f-h-at-softeam-3587086987?position=8&pageNum=47&refId=ulU0mGztWnF4llUcE%2BYHkw%3D%3D&trackingId=EqEhNZbVAIsxTMGqS%2BjVhA%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Vous \u00e9voluez dans le domaine de la Data et souhaitez int\u00e9grer\nun leader de la transformation num\u00e9rique sp\u00e9cialis\u00e9 dans les secteurs de la Banque, du Luxe, de l'Assurance, de la Finance, de l'Energie et la possibilit\u00e9 d'\u00e9voluer au sein du Groupe Docaposte !\nSofteam est labellis\u00e9 \"HappyIndex\u00ae AtWork \" 2022 pour la 5\u00e8me ann\u00e9e cons\u00e9cutive !\nNos collaborateurs\ntravaillent en \u00ab mode projet \u00bb et accompagnent de bout en bout nos clients sur des probl\u00e9matiques de Gouvernance.\nCE QUE NOUS RECHERCHONS\nData Analyst\npour intervenir sur nos projets et contribuer au d\u00e9veloppement de notre Practice \u00ab Augmented analytics \u00bb\nCE QUE NOUS ATTENDONS DE VOUS\nVos missions :\nMa\u00eetriser les outils statistiques et les informations n\u00e9cessaires \u00e0 la mise en place d'une base de donn\u00e9es,\nG\u00e9rer parfaitement les diff\u00e9rentes technologies sp\u00e9cifiques au big data,\nExtraire les donn\u00e9es du syst\u00e8me source,\nExtraire et traduire des donn\u00e9es business en donn\u00e9es statistiques,\nMod\u00e9liser et assurer les mises \u00e0 jour r\u00e9guli\u00e8res de la base de donn\u00e9es,\nContr\u00f4ler la qualit\u00e9 des donn\u00e9es,\nMettre en \u0153uvre une data warehouse\nSynth\u00e9tiser et vulgariser les informations pour les rendre accessibles aux utilisateurs.\nVOUS ETES\nIng\u00e9nieur(e) de formation avec une sp\u00e9cialit\u00e9 Business Analytics, Big Data, Applications des Masses de Donn\u00e9es (IAMD), Syst\u00e8mes D\u00e9cisionnels..\nvous disposez d'une exp\u00e9rience de\n3 ans minimum\nen tant que\nData Analyst/Data Miner\n..\nVous avez une expertise sur un ou plusieurs des outils d'alimentation et de traitement suivants :\nSQL, Alteryx, Dataiku, Python\n..\nVous avez une expertise sur un ou plusieurs des outils de data visualisation suivants :\nPower BI, Looker/GCP, Qlik, Tableau Software,\nBon(ne) communicant(e), curieux(se) et adaptable, v\nous \u00eates dot\u00e9(e) d'une grande capacit\u00e9 d\u2019analyse et de synth\u00e8se et d'un bon esprit d'\u00e9quipe,\nVotre ma\u00eetrise de l'\nanglais\nvous permet d'\u00e9voluer dans un contexte international.\nNOUS VOUS OFFRONS\nDes\nmissions engageantes\naupr\u00e8s des grands acteurs du march\u00e9.\nUn management de proximit\u00e9 avec\nGilles SALVADOR, Directeur du Centre d'Expertise Data\n, toujours bienveillant et \u00e0 \u00e0 l'\u00e9coute et avec qui vous pourrez \u00e9changer au quotidien sur les enjeux de votre mission et \u00e9voquer vos futurs projets afin que nous puissions vous aider \u00e0 les r\u00e9aliser.\nLa possibilit\u00e9 d\u2019\u00e9voluer et de monter en comp\u00e9tences gr\u00e2ce \u00e0 des\nformations et \u00e0 des certifications aupr\u00e8s de nos clients et de nos consultants\n, des\n12@13\n, notre Entit\u00e9\nSofteam Institute, Organisme de formation interne\nde renomm\u00e9 qui d\u00e9livre des formations aupr\u00e8s de nos clients...\nQUI SOMMES-NOUS ?\nSOFTEAM DATA\nest une marque de\nDOCAPOSTE\nsp\u00e9cialis\u00e9e dans l'informatique d\u00e9cisionnelle et les nouvelles technologies. Nous apportons notre expertise \u00e0 nos clients, principalement des Grands Comptes de la place financi\u00e8re fran\u00e7aise, dans des projets de transformation digitale et cognitive.\n2000 Softeamien.nes\nsont d\u00e9di\u00e9.es \u00e0 la transformation m\u00e9tier et digitale de nos clients et ont g\u00e9n\u00e9r\u00e9 200 M\u20ac de chiffre d\u2019affaires en 2020.\nSOFTEAM SPIRIT\nDes\ncommunaut\u00e9s d'expertises sur les sujets de la Data\nDe\nsuper nouveaux locaux qui sont en plus accessibles facilement\nUne\n\u00e9cole de formation int\u00e9gr\u00e9e\nDes\n\u00e9v\u00e8nements : des soir\u00e9es avec les consultants, des 12@13...\nUne entreprise\nlabellis\u00e9e \"Happy at Work\" pour la 5\u00e8me ann\u00e9e cons\u00e9cutive\n.\nN\u2019attendez plus, rejoignez SOFTEAM et venez nous rencontrer dans nos nouveaux locaux situ\u00e9s \u00e0 la D\u00e9fense #DevenezSofteamien !\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "R",
                "Go"
            ],
            "DataBase": [
                "SQL"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [
                "Tableau",
                "Power BI"
            ],
            "Statistics": [
                "Statistiques"
            ],
            "CloudComputing": [],
            "DevTools": [
                "Git"
            ],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [
                "Big Data",
                "Statistiques"
            ],
            "FrSoftSkills": [],
            "EnSoftSkils": []
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s",
                "3",
                "3",
                "3"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "Consultant Data Engineer, PYTHON, JAVA & SCALA \u2013 H/F",
        "company": "Cat-Amania",
        "location": "Paris, \u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/consultant-data-engineer-python-java-scala-%E2%80%93-h-f-at-cat-amania-3888905331?position=9&pageNum=47&refId=ulU0mGztWnF4llUcE%2BYHkw%3D%3D&trackingId=8jIqzUqg0HTQbf6m4t9bGw%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Cat-Amania\nCr\u00e9\u00e9e en 1999, Cat-Amania fait partie des ESN les plus comp\u00e9titives dans les r\u00e9gions o\u00f9 elle est implant\u00e9e et se sp\u00e9cialise sur des projets d\u2019envergure orient\u00e9s m\u00e9tiers : Banque, Assurance, Grande Distribution et Protection sociale mais aussi Energie, Industrie, Secteur Public.\nEn 2023, Cat-Amania c\u2019est 90,8 millions d\u2019\u20ac de chiffre d\u2019affaires, 1100 collaborateurs r\u00e9partis sur 15 agences en France et 6 agences \u00e0 l\u2019international : Maroc, Luxembourg, Canada et Suisse.\nAujourd'hui, l\u2019objectif est de conforter le d\u00e9veloppement de nos agences et d\u2019ouvrir de nouveaux pays en Europe, conserver notre croissance pour atteindre 100 millions d'\u20ac de CA en 2024.\nL\u2019Agence de Paris\nFort de nos r\u00e9f\u00e9rencements et pr\u00e9sente depuis 1999 l\u2019agence Cat-Amania Paris b\u00e9n\u00e9ficie d\u2019une croissance solide et dynamique permettant d'offrir de nombreuses opportunit\u00e9s \u00e0 nos collaborateurs. Avec plus de 200 consultants, nous avons su gagner la confiance de nos clients et la conserver gr\u00e2ce \u00e0 l\u2019investissement de chacun, car Cat-Amania c\u2019est avant tout une approche humaine avec la volont\u00e9 d\u2019entretenir des liens \u00e9troits au sein de ses \u00e9quipes.\nLe poste\nParticiper \u00e0 la r\u00e9alisation de projets d\u00e9cisionnels et au d\u00e9veloppement des processus d\u2019int\u00e9gration de Data Hub, de DataWarehouses ou Data Lakes en architecture On Premise ou Cloud & Hadoop.\nAccompagner les M\u00e9tiers dans l\u2019expression de leurs besoins en termes de conception de flux de donn\u00e9es et mod\u00e9lisation des traitements.\nD\u00e9finir et produire les dossiers de conception fonctionnelle et technique des flux de donn\u00e9es et des traitements.\nD\u00e9finir et produire les scripts de traitements de donn\u00e9es structur\u00e9es ou NO-SQL: Data Prep, Data Quality Management, Calculs et traitements de donn\u00e9es en mode batch et/ou real-time, interfaces exports/imports, interfaces API \u2026\nD\u00e9finir et produire les processus d\u2019exploitation IT des traitements de donn\u00e9es : supervision, scheduling, s\u00e9curit\u00e9, gestion des log \u2026\nConcevoir les protocoles de tests. Organiser et r\u00e9aliser les plans de tests. R\u00e9aliser des tests unitaires et de recettes\nR\u00e9diger des manuels utilisateurs et former les utilisateurs\nD\u00e9velopper des requ\u00eates PYTHON et/ou JAVA et/ou SCALA\n\u00catre en support aux Data Analystes pour r\u00e9aliser des \u00e9tudes statistiques et des \u00e9chantillons : profil et segmentation client, analyse de questionnaires \u2026\nVotre profil\nDipl\u00f4m\u00e9\u00b7e d\u2019un cursus ing\u00e9nieur en Informatique, vous justifiez d\u2019une premi\u00e8re exp\u00e9rience de plus de 3 ans dans les activit\u00e9s de Data Int\u00e9gration, Data Ing\u00e9nierie et de d\u00e9veloppement PYTHON, JAVA, SCALA\nVous ma\u00eetriser le framework HADOOP, SPARK\nVous ma\u00eetriser les outils Big Data suivants : YARN, PIG, HIVE, KAFKA ; FLINK, SPLUNK\nVous avez con\u00e7u, d\u00e9velopp\u00e9 et d\u00e9ploy\u00e9 en production des traitements de diff\u00e9rentes natures : Processus d\u2019export, Processus d\u2019import, Migration/reprise d\u2019historique\nVous ma\u00eetriser les probl\u00e9matiques de Data Int\u00e9gration dans un contexte multi-technologie : DB2, ORACLE, SQL SERVER, HDFS \u2026\nVous ma\u00eetriser les probl\u00e9matiques de Data Int\u00e9gration dans un contexte multi-technologie NOSQL : MONGODB, NEO4J, COUCHBASE, HBASE, CASSANDRA\nUne premi\u00e8re exp\u00e9rience des m\u00e9thodes agiles & Devops serait un plus\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "Java",
                "Scala",
                "R",
                "Go"
            ],
            "DataBase": [
                "SQL",
                "NoSQL",
                " MongoDB",
                "Cassandra",
                "Neo4j",
                "HBase"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [
                "Hadoop",
                "Spark",
                "Flink"
            ],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [
                "Statistiques"
            ],
            "CloudComputing": [],
            "DevTools": [],
            "Os": [],
            "DBMS": [
                "Oracle",
                "SQL Server"
            ],
            "SoftBigDataProcessing": [
                "HBase"
            ],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [
                "DevOps",
                "Big Data",
                "Statistiques",
                "Cloud"
            ],
            "FrSoftSkills": [],
            "EnSoftSkils": []
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s",
                "3",
                "3",
                "3"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "Stagiaire Data Engineer (H/F)",
        "company": "V and B",
        "location": "Ch\u00e2teau-Gontier-sur-Mayenne, Pays de la Loire, France",
        "link": "https://fr.linkedin.com/jobs/view/stagiaire-data-engineer-h-f-at-v-and-b-3863792436?position=10&pageNum=47&refId=ulU0mGztWnF4llUcE%2BYHkw%3D%3D&trackingId=hhvsUc9971uvM8ZELL4SlQ%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Rejoignez la team V and B !\nMission\nV and B a cr\u00e9\u00e9 un nouveau concept bas\u00e9 sur des lieux, des produits et une communaut\u00e9 int\u00e9grant tous ses acteurs (si\u00e8ge, franchis\u00e9s et clients). Notre mission : Proposer et d\u00e9velopper le go\u00fbt des bons moments \u00e0 partager de mani\u00e8re simple et responsable, avec des \u00e9v\u00e9nements de plus en plus grands comme le V and B Fest\u2019 ou notre participation au Vend\u00e9e Globe. Notre r\u00e9seau compte aujourd\u2019hui 278 magasins qui \u0153uvrent chaque jour \u00e0 se d\u00e9marquer pour offrir la meilleure satisfaction client, le tout avec une touche d\u2019impr\u00e9vu.\nLe/la Stagiaire Data Engineer Sera Int\u00e9gr\u00e9/\u00e9e \u00e0 L'\u00e9quipe En Charge Du Projet De Gestion Des Erreurs Des Flux D'int\u00e9gration De Donn\u00e9es, De L'analyse Des Logs, Et Du Monitoring De L'\u00e9tat Des Flux. Sous La Supervision Du Responsable DATA, Vos Principales Missions Sont Les Suivantes\nAider \u00e0 identifier, analyser et r\u00e9soudre les anomalies et erreurs dans les flux d'int\u00e9gration\nProposer des solutions techniques pour optimiser la qualit\u00e9 et la fiabilit\u00e9 des flux\nParticiper \u00e0 la mise en place des proc\u00e9dures d'analyse des logs pour d\u00e9tecter les tendances, les anomalies et les opportunit\u00e9s d'optimisation\nCollaborer avec l'\u00e9quipe pour interpr\u00e9ter les informations tir\u00e9es des logs et recommander des actions correctives\nParticiper \u00e0 la conception et la mise en \u0153uvre un syst\u00e8me de monitoring en temps r\u00e9el pour suivre l'\u00e9tat des flux d'int\u00e9gration\nAider au d\u00e9veloppement des alertes automatis\u00e9es pour signaler les dysfonctionnements potentiels\nProfil\nVous \u00eates \u00e9tudiant/te d\u2019une \u00e9cole d\u2019ing\u00e9nieur ou d\u2019un \u00e9quivalent universitaire ?\nVous montrez un int\u00e9r\u00eat pour le domaine des projets Data, \u00e0 travers vos exp\u00e9riences professionnelles, stages, cours ou projets personnels impliquant les flux d\u2019int\u00e9gration de donn\u00e9es par API, l\u2019utilisation d\u2019un ETL, l'automatisation et l\u2019orchestration des pipelines de donn\u00e9es ?\nVous avez une bonne connaissance des technologies de l\u2019API REST\nVous avez d\u00e9j\u00e0 pratiqu\u00e9 un ETL (Informatica est un plus)\nVous avez une forte app\u00e9tence pour l'optimisation et l\u2019ing\u00e9nierie des flux de donn\u00e9es\nVous avez une tr\u00e8s bonne compr\u00e9hension des bases de donn\u00e9es et de SQL\nVous ma\u00eetrisez l'anglais technique\nVous souhaitez vous impliquer et vous \u00e9panouir dans une ambiance motiv\u00e9e et conviviale ? Si rigueur, esprit d'\u00e9quipe, organisation et dynamisme sont des qualit\u00e9s qui vous caract\u00e9risent, alors venez r\u00e9v\u00e9ler et d\u00e9velopper votre talent au sein de notre \u00e9quipe !\nStage d\u2019une dur\u00e9e de 6 mois et bas\u00e9 au Si\u00e8ge social situ\u00e9 \u00e0 Ch\u00e2teau-Gontier (53).\nA comp\u00e9tences \u00e9gales, une attention particuli\u00e8re sera apport\u00e9e aux personnes en situation de handicap.\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "R",
                "Go"
            ],
            "DataBase": [
                "SQL"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [],
            "DevTools": [],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [],
            "FrSoftSkills": [
                "Organisation"
            ],
            "EnSoftSkils": []
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "Data Analyst H/F",
        "company": "Lincoln France",
        "location": "Hauts-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/data-analyst-h-f-at-lincoln-france-3827765148?position=1&pageNum=50&refId=feC9wifmdVTgZ6xVoBIeng%3D%3D&trackingId=A0JQT3D0MGPHTe%2BVb2xN7Q%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "DATA ANALYST H/F\nCDI\n3 ans minimum\nChez Lincoln\n, nous formons une communaut\u00e9 d'innovateurs passionn\u00e9s qui red\u00e9finissent l'analyse de donn\u00e9es depuis\nplus de 30 ans\n. En tant que\nPure Player Data\n, notre expertise est reconnue dans les domaines\nde la Modern BI, du Big Data et de la Science des donn\u00e9es\n.\nNotre mission ?\nTransformer les donn\u00e9es en solutions concr\u00e8tes pour nos clients grands comptes dans divers secteurs tels que la banque, le retail, les t\u00e9l\u00e9coms, l'industrie, la sant\u00e9, etc.\nDescription de poste\nNous recherchons un\nData Analyst H/F\npour accompagner nos clients dans leurs projets strat\u00e9giques.\nVos missions\nCollecter, nettoyer et traiter les donn\u00e9es provenant de diff\u00e9rentes sources.\nAnalyser les donn\u00e9es pour identifier des tendances, des corr\u00e9lations et des anomalies.\nConcevoir et d\u00e9velopper des tableaux de bord et des rapports pour pr\u00e9senter les r\u00e9sultats de mani\u00e8re claire et concise.\nCollaborer avec les \u00e9quipes clients pour comprendre leurs besoins et recommander des solutions adapt\u00e9es.\nPr\u00e9requis :\nMa\u00eetrise avanc\u00e9e des langages de programmation\n(SQL, Python, R, etc.).\nConnaissance approfondie des bases de donn\u00e9es relationnelles et non relationnelles.\nExp\u00e9rience pratique avec des outils d'analyse de donn\u00e9es\n(Tableau, Power BI, Looker, Qlik etc.).\nFortes comp\u00e9tences analytiques et capacit\u00e9 \u00e0 transformer les donn\u00e9es brutes en insights exploitables.\nExp\u00e9rience de travail en\nm\u00e9thode Agile\npour la gestion de projet et le d\u00e9veloppement de solutions.\nCapacit\u00e9 \u00e0 travailler de mani\u00e8re autonome et en \u00e9quipe.\nExcellentes comp\u00e9tences en communication et en pr\u00e9sentation.\nLes plus du poste\nEnvironnement Collaboratif\n: projets innovants favorisant le partage des connaissances.\nAccompagnement individualis\u00e9 et de proximit\u00e9\n: formations certifiantes, attribution d\u2019un Career Manager pour vous orienter dans votre trajectoire professionnelle, opportunit\u00e9s d\u2019\u00e9volution de carri\u00e8re.\nFlexibilit\u00e9 du Travail\n: T\u00e9l\u00e9travail et horaires flexibles pour votre \u00e9quilibre vie professionnelle-personnelle.\nR\u00e9mun\u00e9ration Comp\u00e9titive\n: Salaire comp\u00e9titif avec des avantages sociaux attrayants.\nMobilit\u00e9\n: Possibilit\u00e9 de mobilit\u00e9 \u00e0 Paris, Lyon ou Aix-en-Provence offrant des exp\u00e9riences diversifi\u00e9es au sein de Lincoln.\nNotre processus de recrutement :\nUn entretien RH (1h) et entretien technique (1h)\nCette annonce n\u2019est pas faite pour vous si :\nVous \u00eates freelance et vous comptez le rester !\nToujours l\u00e0 ? Postulez et rejoignez nos\n400 experts en Data\n\ud83d\ude09.\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "R"
            ],
            "DataBase": [
                "SQL"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [
                "Tableau",
                "Power BI"
            ],
            "Statistics": [],
            "CloudComputing": [],
            "DevTools": [],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [
                "Big Data"
            ],
            "FrSoftSkills": [
                "Communication",
                "Flexibilit\u00e9"
            ],
            "EnSoftSkils": [
                "Communication"
            ]
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [
                "CDI"
            ],
            "Salary": [
                "400"
            ],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s",
                "3",
                "3",
                "3"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "Cloud Engineer",
        "company": "SELLIA",
        "location": "Paris, \u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/cloud-engineer-at-sellia-3902686769?position=2&pageNum=50&refId=feC9wifmdVTgZ6xVoBIeng%3D%3D&trackingId=oCyxHxImDX7MWux2XkmZZw%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Nous recherchons un Ops Senior en environnement Kubernetes sur du cloud Azure pour prendre en charge l\u2019automatisation du d\u00e9ploiement de nos applications, le suivi de notre infrastructure et l\u2019optimisation des co\u00fbts des environnements.\nLes missions :\net d\u00e9ployer des infrastructures pour applications cloud (y compris sur les services de CI/CD)\nen place des outils de s\u00e9curisation, monitoring, backup, r\u00e9partition des charges, etc\nles processus et architectures\nau processus de certification ISO (documentation, tests, etc)\n\u00e0 la conception et au d\u00e9veloppement des architectures cloud en utilisant les meilleures pratiques et les services adapt\u00e9s (Azure).\nen place et g\u00e9rer des clusters Kubernetes pour le d\u00e9ploiement d'applications et de micro-services.\navec les \u00e9quipes de data science pour int\u00e9grer les donn\u00e9es et mod\u00e8les selon une approche MLOps.\nles bases de donn\u00e9es relationnelles (postgreSQL) et MongoDB dans les solutions architecturales, en tenant compte des exigences de performances et de disponibilit\u00e9.\nVotre profil :\nann\u00e9es d\u2019exp\u00e9riences minimum sur des projets similaires\ncertifications Azure MS devops engineer expert serait un plus\nmoins une exp\u00e9rience significative sur Kubernetes.\ndes bases de donn\u00e9es relationnelles et exp\u00e9rience avec MongoDB.\napprofondie des principes d'architecture logicielle, de la conception de syst\u00e8mes \u00e9volutifs et de la s\u00e9curit\u00e9 des applications.\n\u00e0 communiquer efficacement et \u00e0 travailler en \u00e9quipe, tout en faisant preuve d'autonomie.\ncompr\u00e9hension des m\u00e9thodologies Agile et des pratiques DevOps.\nLes technologies suivantes n\u2019ont pas de secret pour vous :\n: Windows, Linux (ubuntu, WSL2), r\u00e9seaux\n: JavaScript/TypeScript, Python, Shell\nde donn\u00e9es : postgreSQL , mongoDB\n: Docker/Podman, Kubernetes (AKS/EKS) : Helm, ISTIO,\n: Cloud functions\nGitOps, Serverless, Terraform, Helm, Ansible, Packer\nDeployment: Cloud CI/CD\n: Github, Consul, NGINX, WebPack, AWS Kinesis, Keycloak, Azure Devops\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "Java",
                "R",
                "Go",
                "JavaScript"
            ],
            "DataBase": [
                "SQL",
                " MongoDB"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [
                "AWS",
                "Azure"
            ],
            "DevTools": [
                "Git",
                "Docker"
            ],
            "Os": [
                "Linux",
                "Windows"
            ],
            "DBMS": [
                "PostgreSQL"
            ],
            "SoftBigDataProcessing": [],
            "Automation": [
                "Ansible",
                "Kubernetes"
            ],
            "InfrastructureAsCode": [
                "Terraform"
            ],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [
                "Docker",
                "Kubernetes"
            ],
            "Collaboration": [],
            "Other": [
                "DevOps",
                "ML",
                "Cloud",
                "CI/CD"
            ],
            "FrSoftSkills": [],
            "EnSoftSkils": []
        },
        "details": {
            "JobDetail": [
                "Senior"
            ],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "Data Engineer",
        "company": "L-Acoustics",
        "location": "Paris, \u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/data-engineer-at-l-acoustics-3826015735?position=3&pageNum=50&refId=feC9wifmdVTgZ6xVoBIeng%3D%3D&trackingId=h701WLuvM55ngg0K4lj6rQ%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Join our passionate and dedicated teams who are shaping the future of sound!\nMembre de l\u2019\u00e9quipe IT & Digital, vous intervenez au c\u0153ur des diff\u00e9rents projets de d\u00e9veloppement du Groupe sur un p\u00e9rim\u00e8tre international (3 BU Business EMEA, AMERICAS & APAC \u2013 3 centres R&D France, Royaume-Uni & Allemagne \u2013 4 sites industriels France & Allemagne).\nPour accompagner notre niveau 2 du mod\u00e8le data-drive, avec l\u2019accompagnement d\u2019un manager et un architecte donn\u00e9e. Un plan de formation et d\u2019accompagnement est pr\u00e9vu pour int\u00e9grer la ressource et l\u2019accompagner dans son d\u00e9veloppement.\nDans le respect de la strat\u00e9gie IT \u00e9tablie par le DSI, votre mission consiste \u00e0 :\nResponsabilit\u00e9s\nAnalyser les besoins fonctionnels.\nLocaliser les donn\u00e9es de production.\nD\u00e9terminer les sp\u00e9cifications techniques.\nMod\u00e9liser les datawarehouse (entrep\u00f4ts de donn\u00e9es) et les datamarts (magasins de donn\u00e9es) d\u00e9di\u00e9s \u00e0 une fonction particuli\u00e8re dans l\u2019entreprise.\nAccompagner le client dans la r\u00e9alisation du projet.\nMaintenir les sources de donn\u00e9es \u00e0 jour\nMettre \u00e0 disposition les donn\u00e9es aux m\u00e9tiers\nD\u00e9velopper le dictionnaire de donn\u00e9es\nStack Technique\nPower BI / DAX\nAzure Pureview\nAzure Data Factory\nAzure Synapse Datawarehouse\nData Lake, Logical Datawarehouse\nMicrosoft Fabric\nInt\u00e9gration et la livraison continue (CI/CD)\nSavoir-faire\nRigueur et respect de planning\nEsprit de synth\u00e8se\nCapacit\u00e9s d\u2019analyse\nAutonomie\nMa\u00eetrise de l\u2019anglais\nEnvie d\u2019apprendre et d\u2019\u00e9voluer\nVeille technologique\nR\u00e9diger la documentation technique\nBonne communication \u00e9crite et orale\nVotre Profil\nDipl\u00f4m\u00e9 d\u2019un Bac + 5 (\u00e9cole d'ing\u00e9nieur ou universitaire), vous justifiez d\u2019une exp\u00e9rience de 5 ans minimum dans des fonctions similaires.\nVous avez une exp\u00e9rience significative sur les domaines :\nPlateforme donn\u00e9es de Microsoft Azure (Microsoft Fabric/Lakehouse/Synapse)\nExp\u00e9rience sur des projets d'int\u00e9gration et d\u00e9ploiement\nD\u00e9veloppement et int\u00e9gration des API\nD\u00e9veloppement et gouvernance des rapports dans Power BI\nConnaissance de base des technologies d\u2019intelligence artificielle\nJoin our passionate and dedicated teams who are shaping the future of sound!\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "R",
                "Go"
            ],
            "DataBase": [],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [
                "Power BI"
            ],
            "Statistics": [],
            "CloudComputing": [
                "Azure"
            ],
            "DevTools": [
                "Git"
            ],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [
                "Teams"
            ],
            "Other": [
                "CI/CD"
            ],
            "FrSoftSkills": [
                "Communication"
            ],
            "EnSoftSkils": [
                "Communication"
            ]
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s",
                "5",
                "5",
                "5"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "Senior data engineer",
        "company": "Harnham",
        "location": "Paris, \u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/senior-data-engineer-at-harnham-3917047907?position=4&pageNum=50&refId=feC9wifmdVTgZ6xVoBIeng%3D%3D&trackingId=w%2BSECXFbLwwSLeezM5MFkw%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Senior Data Engineer\nParis - 3 Jours de t\u00e9l\u00e9travail\nUp to 80K\u20ac fixe\nCDI - Pas ouvert au freelance\nScala - Spark - Kafka\n\ud83d\udca1 L'entreprise\nUne entreprise sp\u00e9cialis\u00e9e dans le marketing et la performance des publicit\u00e9s mobiles recherche un Senior Data Engineer. G\u00e9rant un volume important de donn\u00e9es, le Machine Learning est au coeur de son offre. L'entreprise propose des solutions technologiques innovantes pour am\u00e9liorer la performance des campagnes publicitaires sur smartphone et tablettes tout en proposant une strat\u00e9gie et des algorithmes sur mesure \u00e0 ses clients.\n\ud83c\udfaf Le poste\nEn tant Senior Data Engineer, vous rejoindrez l'\u00e9quipe reporting en charge de tous les sujets li\u00e9s \u00e0 la data. Vos missions seront les suivantes :\nAssurer le bon fonctionnement de l'infrastructure de donn\u00e9es : g\u00e9rer les magasins de donn\u00e9es, les processus et la planification\nS'assurer que les donn\u00e9es sont toujours disponibles : superviser le traitement, le stockage, l'agr\u00e9gation et le d\u00e9veloppement d'API\nApporter des nouvelles id\u00e9es pour am\u00e9liorer les outils\nSugg\u00e9rer des solutions nouvelles et int\u00e9ressantes pour mettre \u00e0 niveau l'infrastructure de donn\u00e9es\nG\u00e9rer les algorithmes de data science (garantir leur \u00e9volutivit\u00e9 et leur bon fonctionnement)\nTravailler en \u00e9troite collaboration avec l'\u00e9quipe SCRUM\nGarder un \u0153il sur l'\u00e9chelle des syst\u00e8mes de donn\u00e9es, en s'assurant qu'ils peuvent r\u00e9pondre aux besoins croissants\nRationaliser les processus de donn\u00e9es en int\u00e9grant des tests, une surveillance, des alertes et une r\u00e9cup\u00e9ration d\u2019erreur efficaces\n\ud83d\udd0d Profil Recherch\u00e9 :\nDipl\u00f4me d'ing\u00e9nieur en data engineering\nMinimum 4 ans d'exp\u00e9rience sur un poste similaire\nSolide connaissance du code en Scala/Spark\nSp\u00e9cialiste de la data streaming (ma\u00eetrise de Kafka pour g\u00e9rer des donn\u00e9es en temps r\u00e9el)\nConnaissance d'au moins un cloud provider (AWS, GCP ou Azure)\nConnaissance des pipelines et les outils CI/CD (un vrai plus)\nPro de Python, avec une connaissance de Redis et Cassandra\nAnglais courant\nPour postuler\nMerci de me faire part de votre CV et je vous recontacterai au plus vite.\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "Scala",
                "R",
                "Go"
            ],
            "DataBase": [
                "Cassandra"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [
                "Spark"
            ],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [
                "AWS",
                "Azure"
            ],
            "DevTools": [],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [
                "Machine Learning",
                "Cloud",
                "CI/CD"
            ],
            "FrSoftSkills": [
                "Collaboration"
            ],
            "EnSoftSkils": [
                "Collaboration"
            ]
        },
        "details": {
            "JobDetail": [
                "Senior"
            ],
            "TypeContract": [
                "CDI"
            ],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s",
                "4",
                "4",
                "4"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "Senior Data Engineer",
        "company": "Pentalog",
        "location": "Paris, \u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/senior-data-engineer-at-pentalog-3747758363?position=5&pageNum=50&refId=feC9wifmdVTgZ6xVoBIeng%3D%3D&trackingId=K2snjFw5ATMJtJNoo%2B38cQ%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "France\n(Paris)\nFull time\nJob perks: Professional team; AI software\nAbout The Project\nHow we hire:\nAt Pentalog, excellence is what you'll do. We're guided by a mission to positively impact the software development world.\nAre you ready to be part of a revolutionary team that is reimagining content creation and using cutting-edge technology to drive the future of the creator economy? Our client is using technology, data and expertise to turn today's talented video creators into tomorrow's digital icons.\nAs a\nSenior Data Engineer\n, you'll be working on one or more key projects that drive innovation in content creation. Your role will empower creators to reach their full potential across social platforms such as Facebook, Instagram, Pinterest, Snapchat, TikTok, YouTube and beyond.\nThe majority tech stack is: Python/FastAPI and React with some projects in Node.js, Rust, React Native. Mandatory knowledge: Git, Docker. Nice to haves: AWS, Terraform.\nJob Requirements\nAt least 6 years of experience in similar environments;\nProficiency in Python and familiarity with the data engineering tool landscape, particularly tools such as Airflow and DBT;\nKnowledge of SQL and NoSQL databases;\nStreaming pipeline experience with Kafka, Kinesis, Beam or Flink;\nBig data infrastructure deployment experience, with proven ability to use tools such as Terraform on platforms such as AWS;\nFamiliarity with managed services such as S3, Redshift, EMR or others;\nArchitecture and systems design experience;\nExperience with platforms such as Spark and Hadoop is a plus;\nRigorous, resourceful and curious, with a flair for problem solving;\nGood communicator, with the ability to teach others;\nGood team working skills;\nFluent in English.\nAmazon Web Services (AWS) AWS Kafka AWS Kinesis AWS Redshifht Hadoop Node.Js NoSQL Python React js React native Rust SPARK SQL\nResponsibilities\nDevelop, deploy, and maintain ETL processes in Python and Spark;\nImplement and manage data pipelines utilizing tools such as Airflow, AWS Glue, and Kinesis;\nOversee and manage the data stores, including Redshift and RDS;\nImplement and maintain data lake archiving strategies using S3, Parquet, and Iceberg;\nDrive data modeling initiatives and implement schema governance tooling to ensure data integrity and consistency.\nBenefits\nForeign language classes;\nCompetitive salary and bonuses;\nFree pass to learning platforms;\nA multicultural, friendly work environment;\nWorking in a company with an Agile mindset: continuous knowledge sharing and validated learning;\nThe possibility to bring your own creative and innovative ideas to life;\nMentorship programs that encourage and enable your professional development;\nGreat career development opportunities;\nImprovement of your hard and soft skills through workshops, knowledge sharing sessions and presentations on multiple IT-related topics.\nAbout Pentalog\nAs a leading European Software Services company operating internationally in France, Romania, Germany, Moldova, UK, Vietnam, Mexico, Morocco and USA, we employ over 1,300 engineers and IT experts who work in a very dynamic, multicultural working environment.\nAt Pentalog, your talents & ambitions are recognized and rewarded; we offer plenty of opportunities to develop, both individually, as well as a professional, and we reward our collaborators who understand the importance of self-improvement.\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "R",
                "Go"
            ],
            "DataBase": [
                "SQL",
                "NoSQL"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [
                "Hadoop",
                "Spark",
                "Flink"
            ],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [
                "AWS"
            ],
            "DevTools": [
                "Git",
                "Docker"
            ],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [
                "Airflow"
            ],
            "InfrastructureAsCode": [
                "Terraform"
            ],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [
                "Docker"
            ],
            "Collaboration": [],
            "Other": [
                "Big Data"
            ],
            "FrSoftSkills": [],
            "EnSoftSkils": [
                "Problem Solving",
                "Initiative"
            ]
        },
        "details": {
            "JobDetail": [
                "Full",
                "Senior"
            ],
            "TypeContract": [],
            "Salary": [
                "1,300"
            ],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "Data Analyst H/F",
        "company": "Lincoln France",
        "location": "\u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/data-analyst-h-f-at-lincoln-france-3892483893?position=7&pageNum=50&refId=feC9wifmdVTgZ6xVoBIeng%3D%3D&trackingId=Vqm8X77go1MCC4UqQc%2FGVg%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "CDI\n\ud83d\udcca\n3 ans minimum\nChez Lincoln\n, nous formons une communaut\u00e9 d'innovateurs passionn\u00e9s qui red\u00e9finissent l'analyse de donn\u00e9es depuis\nplus de 30 ans\n. En tant que\nPure Player Data\n, notre expertise est reconnue dans les domaines\nde la Modern BI, du Big Data et de la Science des donn\u00e9es\n.\nNotre mission ?\nTransformer les donn\u00e9es en solutions concr\u00e8tes pour nos clients grands comptes dans divers secteurs tels que la banque, le retail, les t\u00e9l\u00e9coms, l'industrie, la sant\u00e9, etc.\nDescription du poste\nNous recherchons un\nData Analyst H/F\npour accompagner nos clients dans leurs projets strat\u00e9giques.\nVos missions\nCollecter, nettoyer et traiter les donn\u00e9es provenant de diff\u00e9rentes sources.\nAnalyser les donn\u00e9es pour identifier des tendances, des corr\u00e9lations et des anomalies.\nConcevoir et d\u00e9velopper des tableaux de bord et des rapports pour pr\u00e9senter les r\u00e9sultats de mani\u00e8re claire et concise.\nCollaborer avec les \u00e9quipes clients pour comprendre leurs besoins et recommander des solutions adapt\u00e9es.\nPr\u00e9requis :\nMa\u00eetrise avanc\u00e9e des langages de programmation (\nSQL, Python, R\n, etc.).\nConnaissance approfondie des bases de donn\u00e9es relationnelles et non relationnelles.\nExp\u00e9rience pratique avec des outils d'analyse de donn\u00e9es (\nTableau, Power BI\n, etc.).\nFortes comp\u00e9tences analytiques et capacit\u00e9 \u00e0 transformer les donn\u00e9es brutes en insights exploitables.\nExp\u00e9rience de travail en\nm\u00e9thode Agile\npour la gestion de projet et le d\u00e9veloppement de solutions.\nCapacit\u00e9s \u00e0 travailler de mani\u00e8re autonome et en \u00e9quipe.\nExcellentes comp\u00e9tences en communication et en pr\u00e9sentation.\nLes plus du poste\nEnvironnement Collaboratif\n: projets innovants favorisant le partage des connaissances.\nAccompagnement individualis\u00e9 et de proximit\u00e9\n: formations certifiantes, attribution d\u2019un Career Manager pour vous orienter dans votre trajectoire professionnelle, opportunit\u00e9s d\u2019\u00e9volution de carri\u00e8re.\nFlexibilit\u00e9 du Travail\n: T\u00e9l\u00e9travail et horaires flexibles pour votre \u00e9quilibre vie professionnelle-personnelle.\nR\u00e9mun\u00e9ration Comp\u00e9titive\n: Salaire comp\u00e9titif avec des avantages sociaux attrayants.\nMobilit\u00e9\n: Possibilit\u00e9 de mobilit\u00e9 \u00e0 Lille, Lyon ou Aix-en-Provence offrant des exp\u00e9riences diversifi\u00e9es au sein de Lincoln.\nNotre processus de recrutement :\nUn entretien RH (1h) et entretien technique (1h)\nCette annonce n\u2019est pas faite pour vous si :\nVous \u00eates freelance et vous comptez le rester !\nToujours l\u00e0 ? Postulez et rejoignez nos\n400 experts en Data\n\ud83d\ude09.\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "R"
            ],
            "DataBase": [
                "SQL"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [
                "Tableau",
                "Power BI"
            ],
            "Statistics": [],
            "CloudComputing": [],
            "DevTools": [],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [
                "Big Data"
            ],
            "FrSoftSkills": [
                "Communication",
                "Flexibilit\u00e9"
            ],
            "EnSoftSkils": [
                "Communication"
            ]
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [
                "CDI"
            ],
            "Salary": [
                "400"
            ],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s",
                "3",
                "3",
                "3"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "Data Engineer - data factory (H/F)",
        "company": "Euro Information Developpements / EID",
        "location": "Nantes, Pays de la Loire, France",
        "link": "https://fr.linkedin.com/jobs/view/data-engineer-data-factory-h-f-at-euro-information-developpements-eid-3878343308?position=8&pageNum=50&refId=feC9wifmdVTgZ6xVoBIeng%3D%3D&trackingId=PMsSi4Y%2BeHJQ9msDAp5EBw%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Qui sommes nous\nEuro-Information, filiale technologique de Cr\u00e9dit Mutuel Alliance F\u00e9d\u00e9rale, con\u00e7oit, r\u00e9alise, maintient et exploite un syst\u00e8me d\u2019information commun utilis\u00e9 par le Groupe.\nLes activit\u00e9s de d\u00e9veloppement et de production informatique au niveau national et international sont assur\u00e9es par environ 4000 salari\u00e9s r\u00e9partis sur plusieurs sites g\u00e9ographiques au niveau national : Strasbourg, Nancy, Dijon, Orl\u00e9ans, Lyon, Lille, Cergy, Val de Fontenay, Paris et Nantes.\nPremi\u00e8re Banque \u00e0 adopter le statut d\u2019entreprise \u00e0 mission, le Cr\u00e9dit Mutuel Alliance F\u00e9d\u00e9rale s\u2019investit et s\u2019engage dans diff\u00e9rentes missions sociales et environnementales :\nL\u2019accompagnement de tous par notre organisation coop\u00e9rative et mutualiste reste au c\u0153ur de notre ADN.\nLa technologie au service de l\u2019humain est une r\u00e9f\u00e9rence dans notre monde connect\u00e9.\nLa solidarit\u00e9 et l\u2019\u00e9co-responsabilit\u00e9 deviennent des axes cl\u00e9s dans notre d\u00e9veloppement.\nNotre raison d\u2019\u00eatre : Ensemble, Ecouter et Agir.\nVos missions\nVous souhaitez int\u00e9grer une \u00e9quipe dynamique et \u00e0 taille humaine au sein d\u2019une entreprise solide et d\u2019un grand groupe en d\u00e9veloppement constant ? Vous souhaitez travailler sur un enjeu d\u2019aujourd\u2019hui et plus encore de demain : la donn\u00e9e ?\nEuro-Information, la Fintech de Cr\u00e9dit Mutuel Alliance F\u00e9d\u00e9rale structure une Data Factory pour :\nAcc\u00e9l\u00e9rer la valorisation des donn\u00e9es au travers d\u2019analyse de masse et de mod\u00e8les allant jusqu\u2019au pr\u00e9dictif.\nR\u00e9pondre \u00e0 la confiance de nos clients en garantissant la s\u00e9curit\u00e9 de leurs donn\u00e9es et une utilisation responsable et encadr\u00e9e, respectueuse de leur vie priv\u00e9e.\nLa Data Factory EI se positionne comme un fournisseur de solutions pour les \u00e9quipes informatiques et pour l\u2019ensemble des entit\u00e9s du groupe et comme un facilitateur d\u2019\u00e9changes et de mutualisation. Pour mener \u00e0 bien ces missions, la relation m\u00e9tier s\u2019av\u00e8re essentielle. Elle r\u00e9unit :\nDes Data Architects. Ils fournissent l\u2019environnement et les outils et s\u2019assurent de leur performance et de leur constante \u00e9volution.\nDes Data Engineers. Ils ont la maitrise des donn\u00e9es, de leur r\u00e9colte \u00e0 leur mise \u00e0 disposition adapt\u00e9e aux besoins des m\u00e9tiers. Ils con\u00e7oivent les mod\u00e8les d\u2019enregistrement des donn\u00e9es.\nDes Concepteurs Business Intelligence. Ils simplifient, mutualisent et industrialisent les reportings.\nDes Data Scientists. Ils accompagnent les m\u00e9tiers et les entit\u00e9s sur la Data Science, ils r\u00e9alisent \u00e0 fa\u00e7on sur les sujets \u00e0 fort enjeu.\nDes Data Officers. Ils coordonnent et mutualisent les \u00e9nergies sur les projets Data comme dans le cadre de la Gouvernance et de l\u2019administration des donn\u00e9es.\nNous recherchons un(e) Data Engineer.\nVous participerez \u00e0 la mise en \u0153uvre et au maintien du Syst\u00e8me d\u2019information D\u00e9cisionnel du groupe\n.\nPour les banques, les organismes de cr\u00e9dits \u00e0 la consommation et les filiales, en France et \u00e0 l\u2019international :\nCompr\u00e9hension de l\u2019activit\u00e9 et des besoins de vos clients, en dialogue avec la MOA\nCompr\u00e9hension du SI de production, en dialogue avec les \u00e9quipes MOE\nMod\u00e9lisation du Syst\u00e8me d\u2019Information D\u00e9cisionnel\nConception et r\u00e9alisation\nDiagnostic des dysfonctionnements rencontr\u00e9s\nMaintenances correctives et \u00e9volutives\nSupport aupr\u00e8s des diff\u00e9rents m\u00e9tiers\nDocumentation technique\nSuivi des traitements\nPilotage de projets\nVous travaillerez sur une grande vari\u00e9t\u00e9 de projets et \u00e0 l\u2019\u00e9chelle de l\u2019ensemble des entit\u00e9s g\u00e9r\u00e9es sur le SI d\u2019Euro-Information .\nVous intervenez sur des projets \u00e0 dimension internationale sur des environnements Vertica, Semarchy, WebFOCUS, SAP Business Objects, QlikSense\u2026\nVous participerez, coordonnerez et m\u00e8nerez \u00e0 bien des projets de valorisation de donn\u00e9es sur des cas d\u2019usages concrets :\nDes projets de bout en bout : de l\u2019expression du besoin jusqu\u2019\u00e0 la r\u00e9alisation et au suivi de sa performance en lien avec la MOA et nos Data Officers\nEn mobilisant l\u2019ensemble des acteurs : Business, Data Scientists, Data Engineer, sources de donn\u00e9es \u2026\nAvec participation aux prises de d\u00e9cision\nEn mutualisant les travaux et les bonnes pratiques entre les acteurs et les diff\u00e9rents m\u00e9tiers du groupe\nDans vos projets et au-del\u00e0, vous porterez l\u2019acculturation Data au sein du groupe.\nCe que vous allez vivre chez nous\nT\u00e9l\u00e9travail (2 jours par semaine)\nR\u00e9mun\u00e9ration fixe vers\u00e9e sur 13 mois\nRTT\nInt\u00e9ressement, participation et abondement\nPlan \u00e9pargne entreprise et PERCO\nContrat de sant\u00e9 collectif\nPr\u00e9voyance\nRetraite suppl\u00e9mentaire prise en charge \u00e0 100% par l\u2019employeur\nConditions bancaires et assurances pr\u00e9f\u00e9rentielles\nPolitique parentale avantageuse\nCe que nous allons aimer chez vous\nDe formation bac +4/5, vous disposez id\u00e9alement d\u2019une exp\u00e9rience significative sur un poste \u00e9quivalent.\nLa maitrise de l\u2019anglais serait un plus.\nConnaissance du monde OPEN\nVous avez la maitrise d\u2019un ETL, d\u2019une base de donn\u00e9es orient\u00e9e Analytique, d\u2019une solution BI.\nLa connaissance de l\u2019outil de mod\u00e9lisation PowerDesigner serait un plus.\nConnaissance du monde Host\nUne exp\u00e9rience mettant en \u0153uvre des technologies mainframe (MVS, JCL, Cobol, SGBD DB2, OPC) serait un plus.\nCe qui nous plaira le plus chez vous :\nC\u2019est vous-m\u00eame ! Alors on vous attend ouvert(e), force de proposition, dot\u00e9(e) d\u2019un certain sens critique, autonome et respectueux(se) de la confidentialit\u00e9 des informations d\u00e9tenues car c\u2019est ce qui vous permettra de mener au mieux votre mission.\nOn dit de vous que vous avez une certaine aptitude \u00e0 communiquer et le sens du travail en \u00e9quipe.\nVous \u00eates motiv\u00e9(e) et vous souhaitez vous investir fonctionnellement et techniquement, n\u2019h\u00e9sitez plus l\u2019offre est faite pour vous.\nAutres informations\nLe poste est \u00e0 pourvoir d\u00e8s que possible sur Nantes.\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "R",
                "Go"
            ],
            "DataBase": [],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [],
            "DevTools": [],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [],
            "FrSoftSkills": [
                "Organisation"
            ],
            "EnSoftSkils": []
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "ALTERNANCE - Data Engineer H/F",
        "company": "Cr\u00e9dit Agricole Group Infrastructure Platform",
        "location": "Montpellier, Occitanie, France",
        "link": "https://fr.linkedin.com/jobs/view/alternance-data-engineer-h-f-at-cr%C3%A9dit-agricole-group-infrastructure-platform-3903710929?position=9&pageNum=50&refId=feC9wifmdVTgZ6xVoBIeng%3D%3D&trackingId=n3SsDOZU2EIJMkzwnoo%2Fww%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Cr\u00e9dit Agricole \u2013 Group Infrastructure Platform (CA-GIP),\nacteur majeur de la production informatique du groupe Cr\u00e9dit Agricole, recherche ses Jeunes Talents de demain en alternance et en stage !\nL\u2019\u00e9quipe Data souhaite int\u00e9grer son futur\nalternant Data Engineer H/F\n\u00e0\nMontpellier (34)\n.\n\ud83d\ude80 Vos missions :\nLe socle Natif Data Cloud con\u00e7oit et op\u00e8re des plateformes \u00ab as a service \u00bb facilitant la mise en place d\u2019architectures modernes, distribu\u00e9es et hautement r\u00e9silientes pour l\u2019ensemble des entit\u00e9s du groupe Cr\u00e9dit Agricole.\nAu sein de cette \u00e9quipe, vous aurez les missions suivantes :\nMettre en \u0153uvre op\u00e9rationnellement et techniquement la plateforme Streaming ;\nParticiper au daily meeting anim\u00e9 par le Squad Lead, \u00e0 l\u2019ensemble des rituels agiles de la Squad (R\u00e9tro, D\u00e9mos, PI Planning) ainsi qu\u2019aux r\u00e9unions de co-construction de la roadmap et de mise en \u0153uvre de celle-ci ;\nMettre en \u0153uvre les \u00e9l\u00e9ments de la Backlog.\nLes + de cette mission :\nmonterez en comp\u00e9tences au sein d\u2019une\n\u00e9quipe de 40 personnes\nsoit de 20 clusters Kafka et serez accompagn\u00e9 par\nPaul BERNARD\n, responsable squad Streaming.\nSi vous souhaitez acqu\u00e9rir de\nv\u00e9ritables comp\u00e9tences en DevOps et en Kafka\n, alors cette mission est faite pour vous.\n\u2705 Votre profil :\nVous int\u00e9grerez \u00e0 partir de septembre 2024 un cursus de niveau\nBac+4 / M1\nen informatique,\nde pr\u00e9f\u00e9rence en \u00e9cole d\u2019ing\u00e9nieurs.\nVous justifiez d'un\nniveau d'anglais\nprofessionnel\n.\nComp\u00e9tences attendues :\nForce de proposition ;\nRigueur ;\nAnimation et facilitation ;\nCapacit\u00e9 de synth\u00e8se ;\nAutonomie.\nEnvironnements techniques:\nKafka ;\nAnsible ;\nFlink.\n\ud83c\udfc6 Pourquoi devenir un Jeune Talent CA-GIP ?\nPour devenir partenaire des grandes \u00e9volutions technologiques et mettre vos comp\u00e9tences au service des 53 millions de clients du groupe Cr\u00e9dit Agricole ;\nPour \u00e9voluer dans un environnement \u00e0 la pointe de la technologie (DevOps, Cloud Hybride, Digital Workplace, Cybers\u00e9curit\u00e9, T\u00e9l\u00e9communications, R\u00e9seau...) ;\nPour rejoindre une entreprise certifi\u00e9e Top Employer, et donc reconnue comme employeur de r\u00e9f\u00e9rence ;\nPour b\u00e9n\u00e9ficier de missions responsabilisantes et d\u00e9velopper vos comp\u00e9tences au sein d\u2019un environnement de travail aussi bienveillant que challengeant, une exp\u00e9rience id\u00e9ale pour lancer votre carri\u00e8re (46% de nos Jeunes Talents en alternance et stage embauch\u00e9s en CDI en 2023).\n\u2b50 Nos petits plus !\nVous b\u00e9n\u00e9ficierez d\u2019un remboursement de vos frais de transport en commun de 90% !\nVous souhaitez vous rapprocher de votre lieu de travail ? CA-GIP a conclu un partenariat avec l\u2019organisme ViaHumanis ! Pour en savoir plus, cliquez ici.\nVous aurez acc\u00e8s \u00e0 toutes les prestations de notre CSE !\nCA-GIP est une entreprise handi-accueillante\n: vous avez des besoins sp\u00e9cifiques, nous sommes l\u00e0 pour vous accompagner.\nCA-GIP est signataire de la Charte de la Diversit\u00e9 depuis 2023\n: en agissant chaque jour dans l\u2019int\u00e9r\u00eat de la soci\u00e9t\u00e9, nous sommes un Groupe engag\u00e9 en faveur des diversit\u00e9s et de l\u2019inclusion. Pour en savoir plus sur la Politique des Diversit\u00e9s.\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "R"
            ],
            "DataBase": [],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [
                "Flink"
            ],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [],
            "DevTools": [
                "Git"
            ],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [
                "Ansible"
            ],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [
                "DevOps",
                "Cloud"
            ],
            "FrSoftSkills": [
                "Communication"
            ],
            "EnSoftSkils": [
                "Communication"
            ]
        },
        "details": {
            "JobDetail": [
                "Hybride"
            ],
            "TypeContract": [
                "CDI"
            ],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {
		"source": "LinkedIn",
        "title": "Ing\u00e9nieur data Spark (F/ H)",
        "company": "Thales",
        "location": "V\u00e9lizy-Villacoublay, \u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/ing%C3%A9nieur-data-spark-f-h-at-thales-3831274678?position=10&pageNum=50&refId=feC9wifmdVTgZ6xVoBIeng%3D%3D&trackingId=U%2BQniftly41O7LDODp8s1g%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "QUI SOMMES-NOUS ?\nAu sein du site de V\u00e9lizy, nos \u00e9quipes hautement qualifi\u00e9es con\u00e7oivent et produisent des amplificateurs de puissance (tubes \u00e0 ondes progressives, klystrons, gyrotrons, sous-syst\u00e8mes pour les Grandes Infrastructures de Recherche, etc.) \u00e0 destination des march\u00e9s D\u00e9fense, S\u00e9curit\u00e9, Spatial et Scientifique. Chaque jour nos cadres, ing\u00e9nieurs, techniciens et op\u00e9rateurs mettent en commun leurs savoir-faire unique au service de l\u2019innovation.\nQUI SOMMES-NOUS ?\nThales est un leader mondial des hautes technologies comptant plus de 81 000 collaborateurs pr\u00e9sents sur tous les continents. Le Groupe investit dans les innovations du num\u00e9rique et de la \u00ab deep tech \u00bb \u2013 big data, intelligence artificielle, connectivit\u00e9, cybers\u00e9curit\u00e9 et quantique \u2013 pour construire un avenir de confiance, essentiel au d\u00e9veloppement de nos soci\u00e9t\u00e9s, en pla\u00e7ant l\u2019humain au c\u0153ur des d\u00e9cisions.\nThales propose des solutions, services et produits qui aident ses clients \u2013 entreprises, organisations, Etats \u2013 dans cinq grands march\u00e9s vitaux pour le fonctionnement de nos soci\u00e9t\u00e9s : identit\u00e9 et s\u00e9curit\u00e9 num\u00e9riques, d\u00e9fense, a\u00e9ronautique, espace, et transport.\nQUI ETES-VOUS ?\nDipl\u00f4m\u00e9 d\u2019un Bac+5 en \u00e9cole d\u2019ing\u00e9nieur ou \u00e9quivalent universitaire avec une sp\u00e9cialisation en informatique, vous avez au moins 3 ans d'exp\u00e9rience dans les technologies Big Data.\nCE QUE NOUS POUVONS ACCOMPLIR ENSEMBLE :\nEn tant que Data Engineer, vous jouerez un r\u00f4le cl\u00e9 dans la conception, le d\u00e9veloppement et la maintenance de notre infrastructure de donn\u00e9es, ainsi que dans la transformation et la gestion des flux de donn\u00e9es.\nVOS MISSIONS :\nConcevoir, d\u00e9velopper et d\u00e9ployer des solutions Big Data en utilisant les technologies Spark.\nMettre en place des pipelines de donn\u00e9es performants pour l'ingestion, le traitement et le stockage des donn\u00e9es massives.\nCollaborer \u00e9troitement avec les \u00e9quipes m\u00e9tier pour comprendre leurs besoins en mati\u00e8re d'analyse de donn\u00e9es et proposer des solutions adapt\u00e9es.\nOptimiser les performances des clusters Hadoop pour garantir une exploitation efficace des donn\u00e9es.\nAssurer la qualit\u00e9 et la fiabilit\u00e9 des donn\u00e9es trait\u00e9es, en mettant en place des processus de validation et de nettoyage.\nIdentifier et r\u00e9soudre les probl\u00e8mes li\u00e9s \u00e0 l'infrastructure Big Data et proposer des am\u00e9liorations.\nTravailler en \u00e9troite collaboration avec les Data Scientists et les Data Analysts pour fournir des insights pertinents \u00e0 partir des donn\u00e9es.\nInnovation, passion, ambition : rejoignez Thales et cr\u00e9ez le monde de demain, d\u00e8s aujourd\u2019hui.\nInnovation, passion, ambition : rejoignez Thales et cr\u00e9ez le monde de demain, d\u00e8s aujourd\u2019hui.\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "R"
            ],
            "DataBase": [],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [
                "Hadoop",
                "Spark"
            ],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [],
            "DevTools": [],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [
                "Big Data"
            ],
            "FrSoftSkills": [
                "Collaboration",
                "Organisation"
            ],
            "EnSoftSkils": [
                "Collaboration"
            ]
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [],
            "Salary": [],
            "Level": [
                "Bac+5"
            ],
            "Experience": [
                "a",
                "n",
                "s",
                "3",
                "3",
                "3"
            ]
        }
    }
]