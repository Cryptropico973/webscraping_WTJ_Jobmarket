title,company,location,link,description,skills,details
Data Scientist,"Unreal Staffing, Inc","Paris, Île-de-France, France",https://fr.linkedin.com/jobs/view/data-scientist-at-unreal-staffing-inc-3913911173?position=2&pageNum=0&refId=lBTWbVudNP%2F9XLZiNl1XvQ%3D%3D&trackingId=4LG9HFuJZyDS0MMHaEUZBw%3D%3D&trk=public_jobs_jserp-result_search-card,"About Us
The fashion industry contributes significantly to global greenhouse gas emissions. To address this, we developed a Carbon Management Platform tailored for the textile and fashion industry. We automate life-cycle assessment to help brands understand and reduce their environmental footprint.
Data At Our Company
Our Data team manages customer data parsing and analytics. We clean and normalize customer data for accurate analysis and provide analytics on product-level environmental impacts.
Requirements
What You'll Be Working With
Interesting data: Our data describes physical objects, such as shoes, t-shirts, and packaging boxes, enabling real insights into the environmental impact of products
Unique opportunity: Apply your data science skills to reduce the environmental footprint of fashion companies
What We're Looking For
Strong communication skills
Experience with heterogeneous data and basic NLP techniques
Proficiency in Python and SQL
Basic software engineering skills
Benefits
Remote work in Europe
Coworking space allowance up to €300/month
Modern amenities including MacBook, headset, ChatGPT subscription, GitHub Copilot, etc
100% health insurance coverage with Alan at the best coverage level
Option to work from our office in Paris
Work retreats organized 3 times a year
Transparent compensation package with salary range €60k - €80k and significant equity
Opportunities for promotion based on performance and impact on the company
Strong belief in open-source software and contribution to the community
Show more
Show less","{'ProgLanguage': ['Python', 'R'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git'], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': [], 'FrSoftSkills': ['Communication'], 'EnSoftSkils': ['Communication']}","{'JobDetail': ['Remote'], 'TypeContract': [], 'Salary': ['60k', '60k'], 'Level': [], 'Experience': ['a', 'n', 's']}"
Data Scientist (F/M),VINCI Airports,"Nanterre, Île-de-France, France",https://fr.linkedin.com/jobs/view/data-scientist-f-m-at-vinci-airports-3888479165?position=3&pageNum=0&refId=lBTWbVudNP%2F9XLZiNl1XvQ%3D%3D&trackingId=hsRvtKtpUfC4QLNUGIiXag%3D%3D&trk=public_jobs_jserp-result_search-card,"Premier opérateur aéroportuaire privé au monde,
VINCI Airports
gère plus de 70 aéroports dans 13 pays en Europe, en Asie et sur le continent américain. Grâce à son expertise d’intégrateur global, VINCI Airports développe, finance, construit et exploite les aéroports en apportant sa capacité d’investissement et son savoir-faire dans l’optimisation de la performance opérationnelle, la modernisation des infrastructures et la conduite de leur transition environnementale.
Nous recherchons actuellement
un(e) Data Scientist (F/M)
en CDI.
Rattaché(e) au Département Data de la Direction financière de VINCI Airports, vous participerez, en coordination avec les équipes métiers et appuyé(e) par l’équipe d’ingénieurs Data (siège VINCI Airports et Pays), à la mise en œuvre du projet « SMART DATA HUB », un projet stratégique et passionnant, qui a pour vocation de fournir à l’ensemble des aéroports du groupe la capacité à mieux piloter la performance de l’activité autour de la Data.
Pour ce faire vous serez amené(e) à développer des solutions avancées en Data Science, Modèles de Machine Learning, avec un accent particulier sur le traitement du langage naturel (NLP) dans le département Data de VINCI Airports pour les besoins de digitalisation et d’amélioration des processus de VINCI Airports.
Missions :
Modélisation et prévision : Concevoir, développer et mettre en œuvre des modèles statistiques et algorithmiques. Utiliser des méthodes d'apprentissage automatique et d'intelligence artificielle (IA) pour créer des modèles prédictifs.
Analyse des données : Collecter, nettoyer et préparer les données brutes en vue de leur analyse. Utiliser des techniques de visualisation et des outils statistiques pour explorer et comprendre les ensembles de données.
Exploitation des données : Identifier les opportunités d'amélioration des processus et des performances en utilisant les données disponibles. Travailler en étroite collaboration avec les équipes opérationnelles pour comprendre leurs besoins et proposer des solutions basées sur les données.
Communication des résultats : Présenter les résultats de l'analyse de manière claire et compréhensible à des publics non techniques. Collaborer avec des équipes multidisciplinaires pour fournir des recommandations basées sur les données pour la prise de décision stratégique.
Travailler sur des projets impliquant des modèles de langage comme GPT développés par Open AI ou Google (ou autres nouvelles solutions sur le marché).
Participer à des formations et des ateliers avec les analystes de VINCI Airports pour développer leurs compétences techniques et méthodologiques grâce aux solutions Data science/NLP.
L’ensemble de ces actions seront à entreprendre sur l’ensemble des domaines métiers de VINCI Airports : Trafic, commercial, opérations...
Effectuer une veille constante sur les dernières avancées en Data Science, LLM et NLP pour proposer des solutions innovantes et les intégrer aux modèles développés par l’équipe Data.
Le profil que nous recherchons à ce poste :
Diplôme universitaire (Bac+5) en statistiques, mathématiques, informatique, science des données, Intelligence Artificielle ou un domaine connexe.
Expérience pratique dans l'analyse de données et l'utilisation d'outils d'analyse tels que Python, R, SAS, SQL,…
Bonne connaissance des techniques d'apprentissage automatique (machine learning), des algorithmes statistiques et de l'analyse prédictive.
Connaissance approfondie des concepts de Machine Learning et des bibliothèques telles que TensorFlow, PyTorch, Scikit-Learn.
Motivation pour la recherche et la résolution de problèmes complexes.
Intérêt et expérience en traitement du langage naturel (NLP), y compris la familiarité avec les modèles de langage comme GPT.
Capacité à travailler de manière autonome et à gérer efficacement les projets, tout en respectant les délais impartis.
Compétences en communication orale et écrite pour présenter des résultats complexes de manière claire et concise.
Curiosité intellectuelle et passion pour l'exploration des données afin de découvrir des informations cachées et de générer des idées novatrices.
Travail en équipe.
Vous êtes capable de converser en Anglais.
Show more
Show less","{'ProgLanguage': ['Python', 'R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': ['Scikit-Learn', 'TensorFlow', 'PyTorch'], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': ['Statistiques'], 'CloudComputing': [], 'DevTools': ['Git'], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Machine Learning', 'Statistiques'], 'FrSoftSkills': ['Communication', 'Résolution de problèmes', 'Collaboration'], 'EnSoftSkils': ['Communication', 'Collaboration']}","{'JobDetail': [], 'TypeContract': ['CDI'], 'Salary': [], 'Level': ['Bac+5'], 'Experience': ['a', 'n', 's']}"
Data Scientist AI,Cephalgo,France,https://fr.linkedin.com/jobs/view/data-scientist-ai-at-cephalgo-3817203204?position=4&pageNum=0&refId=lBTWbVudNP%2F9XLZiNl1XvQ%3D%3D&trackingId=MDC8INYqcjyOGCX4K1C%2BLw%3D%3D&trk=public_jobs_jserp-result_search-card,"The ideal candidate's favorite words are learning, data, scale, and agility. You will leverage your strong collaboration skills and ability to extract valuable insights from highly complex data sets to ask the right questions and find the right answers.
Responsibilities
Collect, process, and clean data from diverse sources to prepare it for analysis, ensuring consistency and reliability
Analyze raw data: assessing quality, cleansing, structuring for downstream processing and applying machine learning (ML) and deep learning (DL) techniques
A focus on quantitative analytics and data modeling.
Design accurate and scalable prediction algorithms
Ensuring scalable ML/DL pipeline construction
Implementing data storage solutions that optimize for volume, velocity, and variety of EEG data
Collaborate with the team to bring analytical prototypes to production
Stay up-to-date with the latest technologies and trends in data science and machine learning
Qualifications
Master's degree or equivalent experience in Computer Science
At least 2 years' of experience in DL, quantitative analytics and data modeling
A strong statistical and programming background
Experienced in MLOP pipeline construction and big data technologies like Spark, MLFlow, Snowflake, Hadoop for hosting the data
Deep understanding of predictive modeling, machine-learning, clustering and classification techniques, and algorithms
Fluency in a programming language (Python, C,C++, Java, SQL)
Excellent problem-solving skills and ability to work independently or as part of a team
Experienced in working interdisciplinary tasks
We Offer
Competitive salary and benefits package
A collaborative work environment with a supportive team
Opportunities for professional growth and development
Access to the latest tools and technologies.
Flexible working hours and remote work options
CEPHALGO focuses on introducing technological innovations to assist medical professionals to provide better mental health care. Located in Strasbourg, extended beyond Europe, CEPHALGO’s patient monitoring technique using EEG and AI has been applied in psychiatry across Europe. Further information can be found at https://cephalgo.com.
Show more
Show less","{'ProgLanguage': ['Python', 'Java', 'C++', 'Scala', 'R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': ['Hadoop', 'Spark'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'DBMS': ['Snowflake', 'Snowflake'], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Big Data', 'ML', 'Machine Learning'], 'FrSoftSkills': ['Collaboration'], 'EnSoftSkils': ['Collaboration']}","{'JobDetail': ['Remote'], 'TypeContract': [], 'Salary': ['Salary', 'Package'], 'Level': [], 'Experience': ['a', 'n', 's']}"
Data Scientist F/H (IA),Renault Digital,"Boulogne-Billancourt, Île-de-France, France",https://fr.linkedin.com/jobs/view/data-scientist-f-h-ia-at-renault-digital-3885142754?position=5&pageNum=0&refId=lBTWbVudNP%2F9XLZiNl1XvQ%3D%3D&trackingId=24zStH79mhu6id5Vwdd6%2BQ%3D%3D&trk=public_jobs_jserp-result_search-card,"Le groupe RENAULT entre dans une nouvelle ère grâce à la stratégie RENAULuTion qui place
L’IA
au cœur de notre business. Renault Digital, créé en 2017, est un acteur incontournable de ce nouveau cycle et participe activement à relever les challenges des nouvelles mobilités et de l’industrie 4.0
Contexte :
Vous travaillez au sein du Centre d’excellence IA, dans une équipe de 30 data Scientists et data Analysts dont les missions principales sont d’une part la réalisation d’enablers IA permettant de déployer l’IA à l’échelle dans le groupe, et d’autre part de participer à la réalisation de projets métiers en collaboration avec les équipes data sciences locales. Vous serez garant(e) de la valeur ajoutée de la donnée et de l’intelligence artificielle appliquée dans les processus métiers.
Le/la Data Scientist
IA est chargé(e) d'animer une équipe multidisciplinaire composée de Data Scientists, d'Ingénieurs Data, de DevOps et de Développeurs.
Sa mission principale, dans un premier temps, sera d'explorer et de benchmarker les solutions dans le domaine de GEN AI et LLM, et de faciliter leur intégration rapide dans l'architecture existante du groupe RENAULT. Le/la Data Scientist IA travaillera également en étroite collaboration avec l'écosystème externe, y compris les laboratoires de recherche, les IRT et les sociétés du CAC 40.
Responsabilités principales :
Vous animez une équipe multidisciplinaire composée de Data Scientists, d'Ingénieurs Data, de DevOps et de Développeurs.
Vous explorez et benchmarkez les solutions existantes dans le domaine de GEN AI et LLM.
Vous facilitez l'intégration rapide de ces solutions dans l'architecture existante de RENAULT.
Vous développez une stratégie pour l'adoption et l'intégration des nouvelles technologies IA.
Vous gérez toutes les activités du Lab IA, y compris la planification et le suivi du budget.
Vous collaborez avec d'autres départements et équipes pour garantir l'alignement des activités du Lab IA, avec les objectifs stratégiques de RENAULT.
Vous travaillez en étroite collaboration avec l'écosystème externe, y compris les laboratoires de recherche, les IRT et les sociétés du CAC 40.
Profil recherché :
Vous êtes diplômé(e) d’une école d’ingénieur avec une spécialisation Machine Learning ou PHD en ML.
Vous disposez de minimum 7 ans d’expérience en tant que Data Scientist.
Vous avez une expérience réussie dans l’animation d'équipes techniques.
Vous possédez une expérience dans l'exploration et le benchmarking de solutions IA.
Vous êtes capable de collaborer efficacement avec une équipe multidisciplinaire.
Vous possédez une expérience / ou capacité démontrée à travailler en collaboration avec des laboratoires de recherche, des IRT et des sociétés du CAC 40.
Vous avez une capacité d’écoute et de compréhension de problématiques business variées (industrie 4.0, marketing, engineering, qualité, après-vente, …).
Vous êtes capable de vulgariser et présenter de nouvelles approches et simplifier les résultats.
Vous disposez d’une connaissance approfondie des technologies GEN AI et LLM et en particulier des architectures RAG.
Vous avez des connaissances approfondies des algorithmes de machine learning (clustering, classification, régression, détection d’anomalie, optimisation de modèles, traitement d’images et de langage naturel avec du deep learning).
Vous avez une expérience avec au moins l'un des langages de programmation suivants : Python (obligatoire), SQL (obligatoire), R, Scala ou Java.
Vous possédez une expérience sur des frameworks de Machine Learning bien connus : Scikit-learn, TensorFlow/Keras, TFx, PyTorch (un plus) …
Vous avez une expérience en industrialisation de systèmes de machine learning.
Vous disposez d’une expérience avec Docker, et un orchestrateur (kubeflow, airflow …), kubernetes, Git, Gitlab CI/CD (un plus).
Vous utilisez Google Cloud Platform (Storage, BigQuery, Dataproc, Dataflow, AI Platform, …).
Vous avez des connaissances sur les outils DevOps pour AI et ML (MLOps).
Vous êtes capable d’échanger en anglais technique écrit et oral.
Informations complémentaires :
Votre poste sera basé à Boulogne-Billancourt (France) en CDI (temps plein)
Vous bénéficiez de 2 à 3 jours de télétravail par semaine
Vous êtes prêt(e)s à relever avec nous tous ces défis, n’hésitez pas à postuler !!
Show more
Show less","{'ProgLanguage': ['Python', 'Java', 'Scala', 'R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': ['Scikit-Learn', 'TensorFlow', 'Keras', 'PyTorch'], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': ['Google Cloud Platform'], 'DevTools': ['Git', 'Docker'], 'Os': [], 'DBMS': ['BigQuery'], 'SoftBigDataProcessing': [], 'Automation': ['Kubernetes', 'Airflow'], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': ['Docker', 'Kubernetes'], 'Collaboration': [], 'Other': ['DevOps', 'ML', 'Machine Learning', 'Cloud', 'CI/CD'], 'FrSoftSkills': ['Collaboration'], 'EnSoftSkils': ['Collaboration']}","{'JobDetail': ['Temps plein'], 'TypeContract': ['CDI'], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's', '7', '7', '7']}"
Data Scientist IA Gen,eXalt Value,"Île-de-France, France",https://fr.linkedin.com/jobs/view/data-scientist-ia-gen-at-exalt-value-3897781437?position=6&pageNum=0&refId=lBTWbVudNP%2F9XLZiNl1XvQ%3D%3D&trackingId=qs1INkS90XQRc9pwO0fxOA%3D%3D&trk=public_jobs_jserp-result_search-card,"eXalt
est un cabinet de conseil IT
Pure player Data
& IA basé à Paris (1er arrondissement).
Notre offre s’articule autour de 4 piliers réunis au sein d’une même communauté pour un accompagnement à 360° alliant une expertise technique et méthodologique à une approche conseil métier:
Data Gouvernance & Project
Data Engineering & Big Data
Data Performance & Analytics
Data Science & IA
Filiale du groupe eXalt créé en 2018,
regroupant plus de
950 collaborateurs en France
(Paris, Lyon, Bordeaux, Lille, Nantes, Marseille)
et à l’international
(Colombie, Etats-Unis, Espagne, Belgique),
eXalt Value
démontre une
expertise approfondie
dans le domaine de la Data & IA et conseille les entreprises dans le déploiement de leurs stratégies data-driven.
Bénéficiant de la renommée et des relations client du groupe eXalt
(1er dans la catégorie Conseil & Audit au classement des Champions de la Croissance 2024), eXalt Value
est en pleine croissance et regroupe aujourd’hui une communauté d’expertise de plus de 60 collaborateurs en région parisienne.
Nos consultants interviennent sur d
es projets d’envergure stimulants
dans divers secteurs d’activité, Banque & Assurance, Médias, Transports, Retail, Tourisme, etc.
Nous recherchons un
Data Scientist IA Gen H/F
pour rejoindre notre communauté sur le
pilier Data Science & IA.
Vos missions:
Identifier les besoins spécifiques des différentes équipes, à travers des ateliers d'idéation, et proposer des solutions algorithmiques innovantes et adaptées à chaque situation.
Analyser les données disponibles pour sélectionner les modèles d'IA les plus pertinents face aux besoins identifiés, en tenant compte des particularités de chaque cas d'usage.
Développer, tester et déployer les algorithmes des modèles d'apprentissage automatique et des algorithmes avancés pour résoudre des problèmes complexes grâce à des méthodes statistiques, mathématiques et de machine learning.
Collaborer avec les Data Engineer afin d’intégrer les solutions IA dans les produits et les applications existants.
Exploiter les dernières avancées en matière d'IA, notamment le Deep Learning, le Reinforcement Learning, le Traitement du Langage Naturel (NLP), la vision par ordinateur, etc., pour créer des solutions innovantes.
Conseiller les clients tout au long du cycle de vie des projets sur les solutions techniques les plus adaptées à leurs environnements.
Les Prérequis :
Titulaire d'un Bac+5, idéalement Ecole d'Ingénieur
Compréhension des enjeux business autours de
l’exploitation des données et le déploiement des solutions IA
Maîtrise du
Machine Learning et du Deep Learning,
y compris des principaux frameworks (TensorFlow, PyTorch, Scikit-learn, Pandas, NumPy,) et des méthodes statistiques.
Solides connaissances de
Python
(Java, Spark, Scala sont un plus).
Aisance avec l'ensemble du cycle de vie de développement et de déploiement de modèles d'IA (MLOps).
Expérience de travail en
méthode Agile
Capacité à travailler de manière autonome et en équipe.
Excellentes compétences en communication et présentation.
Maîtrise de l’anglais (oral & écrit dans un contexte international professionnel).
Votre environnement eXalté:
Rejoindre
eXalt Value
, c’est également :
Un Lab IA
au sein duquel vous pourrez expérimenter les divers outils et techniques, autour de use cases internes et externes.
Un environnement de travail Collaboratif
favorisant les initiatives et projets transverses à la Practice Data & IA (Data Hub, etc ;)
Un collectif de consultants passionnés,
s’intéressant aux tendances innovantes du secteur
Une Practice de proximité,
privilégiant la montée en compétence de ses collaborateurs (formations, coachings, mentorats, etc.)
Un suivi individualisé et de proximité
par un.e Data Sales Manager référent du compte client, un.e Chargé.e RH et un.e Practice Manager
Une équipe sympa et dynamique,
qui privilégie des moments de partage (séminaires, eXaltemps, meet-ups, déjeuners d’équipe, etc.)
Notre processus de recrutement :
Un entretien RH avec Estelle,
à la suite duquel vous saurez tout (ou presque) d’eXalt Value,
Un entretien technique avec un Manager IA assorti d’un échange technique,
lors duquel vous aurez l’occasion de démontrer vos talents et de challenger vos acquis.
Un entretien final avec la Directrice Associée ou le Directeur Opérationnel,
pour finir de vous convaincre de nous rejoindre 😊
Show more
Show less","{'ProgLanguage': ['Python', 'Java', 'Scala', 'R', 'Go'], 'DataBase': [], 'DataAnalytics': ['Pandas', 'NumPy', 'R'], 'BigData': ['Spark'], 'MachingLearning': ['Scikit-Learn', 'TensorFlow', 'PyTorch'], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': ['Statistiques'], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Big Data', 'ML', 'Machine Learning', 'Statistiques'], 'FrSoftSkills': ['Communication'], 'EnSoftSkils': ['Communication', 'Initiative']}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': ['Bac+5'], 'Experience': ['a', 'n', 's']}"
Data Scientist - Payment Success,Checkout.com,"Paris, Île-de-France, France",https://fr.linkedin.com/jobs/view/data-scientist-payment-success-at-checkout-com-3903448233?position=7&pageNum=0&refId=lBTWbVudNP%2F9XLZiNl1XvQ%3D%3D&trackingId=h1GDNwZ4VJ%2FVXyHdTNM6Zw%3D%3D&trk=public_jobs_jserp-result_search-card,"Company Description
Checkout.com is one of the most exciting fintechs in the world. Our mission is to enable businesses and their communities to thrive in the digital economy. We’re the strategic payments partner for some of the best known fast-moving brands globally such as Wise, Hut Group, Sony Electronics, Homebase, Henkel, Klarna and many others. Purpose-built with performance and scalability in mind, our flexible cloud-based payments platform helps global enterprises launch new products and create experiences customers love. And it's not just what we build that makes us different. It's how.
We empower passionate problem-solvers to collaborate, innovate and do their best work. That’s why we’re on the Forbes Cloud 100 list and a Great Place to Work accredited company. And we’re just getting started. We’re building diverse and inclusive teams around the world — because that’s how we create even better experiences for our merchants and our partners. And we need your help. Join us to build the digital economy of tomorrow.
Job Description
About the opportunity:
We empower businesses in the digital economy, and we know that every payment counts. Our Payment Performance team’s mission is to manage and optimise merchants’ payment flow, to achieve optimal conversion, compliance and cost.
Checkout.com is looking for a data scientist to automate research and investigations tailored for our Tier-1 merchants. This role encompasses the development of automation tools for monitoring, including dashboards and auto-generated presentations, as well as in-depth diagnostic solutions powered by machine learning and recommendation engines.
You will also work closely with Payment Performance Managers to ensure the delivery of a high level of service to our key merchants, underpinned by data-driven expertise. The ideal candidate must be a driven technologist with an affinity for problem solving and creating new tools.
What you'll be doing:
Conduct deep-dive exploratory data analysis to uncover insights and anomalies
Develop cutting-edge automation tools aimed at monitoring and optimising merchants’ performance
Create intuitive, real-time dashboards and reports to provide merchant performance visibility, enabling data-driven decision-making
Propose enhancements of existing processes/tools by utilising statistical and machine learning techniques
Effectively communicate research findings to both technical and non-technical stakeholders through reports and presentations
Qualifications
2+ years experience as data scientist, working with large and diversified data sets
Bachelor’s degree, preferably in Mathematics / Statistics / Computer Science / Engineering, Finance or equivalent
SQL/ Python knowledge to extract & analyse data from our Data Warehouse
Experience with Git & Spark, Databricks, Retool, API
Ability to find creative and effective solutions for business problems
Flexible, adaptable and has a willingness to learn
Payments or Fintech experience is a plus
If you don't meet all the requirements but think you might still be right for the role, please apply anyway. We're always keen to speak to people who connect with our mission and values
If possible, please submit CVs in English.
Additional Information
Apply without meeting all requirements statement
If you don't meet all the requirements but think you might still be right for the role, please apply anyway. We're always keen to speak to people who connect with our mission and values.
We believe in equal opportunities
We work as one team. Wherever you come from. However you identify. And whichever payment method you use.
Our clients come from all over the world — and so do we. Hiring hard-working people and giving them a community to thrive in is critical to our success.
When you join our team, we’ll empower you to unlock your potential so you can do your best work. We’d love to hear how you think you could make a difference here with us.
We want to set you up for success and make our process as accessible as possible. So let us know in your application, or tell your recruiter directly, if you need anything to make your experience or working environment more comfortable. We’ll be happy to support you.
Take a peek inside life at Checkout.com via
Our Culture video https://youtu.be/BEwnpHuadSw
Our careers page https://www.checkout.com/careers
Our LinkedIn Life pages bit.ly/3OaoN1U
Our Instagram https://www.instagram.com/checkout_com/
Apply Without Meeting All Requirements Statement
If you don't meet all the requirements but think you might still be right for the role, please apply anyway. We're always keen to speak to people who connect with our mission and values.
We believe in equal opportunities
We work as one team. Wherever you come from. However you identify. And whichever payment method you use.
Our clients come from all over the world — and so do we. Hiring hard-working people and giving them a community to thrive in is critical to our success.
When you join our team, we’ll empower you to unlock your potential so you can do your best work. We’d love to hear how you think you could make a difference here with us.
We want to set you up for success and make our process as accessible as possible. So let us know in your application, or tell your recruiter directly, if you need anything to make your experience or working environment more comfortable. We’ll be happy to support you.
Take a peek inside life at Checkout.com via
Our Culture video https://youtu.be/BEwnpHuadSw
Our careers page https://www.checkout.com/careers
Our LinkedIn Life pages bit.ly/3OaoN1U
Our Instagram https://www.instagram.com/checkout_com/
Show more
Show less","{'ProgLanguage': ['Python', 'Scala', 'R'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': ['Spark', 'Databricks'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': ['Statistics'], 'CloudComputing': [], 'DevTools': ['Git'], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': ['Teams'], 'Other': ['Machine Learning', 'Cloud'], 'FrSoftSkills': [], 'EnSoftSkils': ['Problem Solving']}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's']}"
APPRENTI.E DATA SCIENTIST,Akademija Oxford,"Val-De-Marne, Île-de-France, France",https://fr.linkedin.com/jobs/view/apprenti-e-data-scientist-at-akademija-oxford-3917870308?position=8&pageNum=0&refId=lBTWbVudNP%2F9XLZiNl1XvQ%3D%3D&trackingId=MZoi9nxbiMM1sLOPfS8j3Q%3D%3D&trk=public_jobs_jserp-result_search-card,"Une des entreprises leader sur le marché de la santé, située dans le Val-De-Marne, recherche un.e Apprenti.e Data Scientist dans le cadre d’un contrat d’apprentissage et pour un démarrage en Octobre 2021.
Show more
Show less","{'ProgLanguage': ['R'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': [], 'FrSoftSkills': [], 'EnSoftSkils': []}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's']}"
Data Scientist (M/W),Mines Paris,"Valbonne, Provence-Alpes-Côte d'Azur, France",https://fr.linkedin.com/jobs/view/data-scientist-m-w-at-mines-paris-3908686193?position=9&pageNum=0&refId=lBTWbVudNP%2F9XLZiNl1XvQ%3D%3D&trackingId=nideR9dbt2vNDnJIGXIMFQ%3D%3D&trk=public_jobs_jserp-result_search-card,"À propos de nous
Mines Paris est une des plus prestigieuses écoles d'ingénieurs en France. Mines Paris est un établissement public qui forme des ingénieurs généralistes via une expérience pédagogique innovante et pluridisciplinaire (sciences de l'ingénieur et sciences humaines et sociales). Son appartenance à l'Université PSL, qui se positionne dans le top 50 des classements internationaux, constitue une véritable opportunité d'enrichissement des parcours.
Mission
Your Environment
As part of the scientific program of The Transition Institute 1.5 (TTI.5), which focuses on the conditions for the emergence of a transition to a low-carbon planet, taking into account technical, social, economic, political and geopolitical issues, Mines Paris - PSL has an opening for a Data Scientist.
Insofar as these issues may represent obstacles to the transition, it is essential to understand their fundamentals and decipher the mechanisms that drive them. The TTI.5 scientific program has been designed to harmonize, enhance and extend the various research projects already on offer at Mines Paris - PSL. It is also intended to provide new impetus in areas that have been little addressed until now, but which are nonetheless essential to steering the transition, or to filling gaps such as that of a complete vision of the distribution of resources worldwide.
Your Challenges And Responsabilities
In order to tackle the various transition strategies, it is essential to have a picture of the production of the various raw materials needed for today's and tomorrow's world. At the same time, the exploitation and circulation of different resources can be strongly impacted by geopolitical conditions and times of tension and conflict.
The aim of this project, with its high methodological stakes, is to develop and couple:
global resource mapping for two critical ""identifiable"" resources (lithium and cobalt)
a mapping of armed tensions (conflicts, installation of military bases, etc.).
To achieve this, we will need to develop a tool for extracting data from a very large mass of information, to be identified, in a changing context that will need to be taken into account for the tool's sustainability.
The Development Prospects For This Work Could Include
a double cartography animated over time ;
the enrichment of military base and tension indicators, with an equal focus on cases of local armed non-tension around the resource
a scalable database that can be continuously updated
a tool that can be replicated for other resources in a rapidly changing world
Profil
Let's talk about you !...
The position is aimed at an engineer / master data scientist with a degree from a university or Grande Ecole. Additional skills in GIS would be a plus. He/she may receive in-house training on mining resource issues.
The candidate will be strongly encouraged to participate in TTI.5 activities, and may also take part in those of the referral centers. He/she must have demonstrated good teamwork skills.
Fluency in spoken and written English is imperative.
Knowledge And Skills
The main skills required for this post are :
Mastery of algorithms and programming languages (ability to write efficient, scalable code)
Mastery of data management language and databases (ability to find, collect and analyze large volumes of data)
Mastery of data visualization tools
Soft Skills
Self-motivated
Spirit of initiative
Sense of teamwork
creativity
Flexibility
Communication and teaching skills
Analytical skills
Thoroughness
…And about us ! Working at Mines Paris also means :
Joining a prestigious institution with a rich history
Playing a part in the digital transition and the transition to carbon neutrality to tackle the climate emergency
Belonging to PSL University, ranked 41st in the Academic Ranking of World Universities
Join a dynamic, multidisciplinary team!
A pleasant living environment in a pine forest, at the heart of the 1st technology cluster on the Côte d'Azur and 1st technology park in Europe!
Référence de l'offre : 6jpx490r88
Show more
Show less","{'ProgLanguage': ['Scala', 'R', 'Go'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git'], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': [], 'FrSoftSkills': ['Communication'], 'EnSoftSkils': ['Communication', 'Teamwork', 'Creativity', 'Flexibility', 'Initiative']}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's']}"
Data Scientist H/F,Valeuriad,"Nantes, Pays de la Loire, France",https://fr.linkedin.com/jobs/view/data-scientist-h-f-at-valeuriad-3741220588?position=10&pageNum=0&refId=lBTWbVudNP%2F9XLZiNl1XvQ%3D%3D&trackingId=ERBNT9HuvBE9DfbNn%2F1gXg%3D%3D&trk=public_jobs_jserp-result_search-card,"Rejoins la
Team Data
créée par
Nicolas Greffard,
Docteur en Intelligence Artificielle
, déjà composée de
20
Data Scientists
et
Data Engineer
talentueux 😍
Nous recherchons de
nouvelles pépites
pour rejoindre notre équipe de choc et répondre aux
multiples problématiques Data science
de nos
clients nantais
mais également
contribuer à nos projets de R&D
et travailler sur des
conférences incroyables
(DevFest, Salon de la Data)
🤩
Ta future mission si tu l'acceptes
😉
Nous te proposons d'intervenir au sein de nos
grandes DSI clientes
, sur des sujets de
collecte
, d
'alimentation
et de
transformation de données
autour de l’intelligence artificielle.
Le job en détail
🤩
Toutes Les Missions Ne Sont Pas Identiques, Mais Voici Des Exemples De Choses Sur Lesquelles Nos Data Scientists Sont Intervenus
Échange avec les architectes, les PO et PPO, les développeurs et la gouvernance de données ;
Deep learning (RNN, LSTM, CNN, DQN) et Machine learning ;
Analyse de données : statistiques descriptives et exploratoires, Data Mining ;
Traitement d’images (pattern matching, extraction de descripteurs, tf-idf et classification, etc..) et traitement de texte.
Traitement du langage / Text-Mining (Word2Vec, BoW, BERT, etc..) ;
Restitutiondes résultats : dataviz, indicateurs, dashboards (tableaux de bord), optimisation d’application streamlit ;
MLOps : pour pour amener l'IA jusqu'à la prod ;
Amélioration de modèles : validation croisée, sélection de descripteurs, métriques d’erreurs ;
Assurer la veille technologique sur les algorithmes et outils de Data Science.
Langages : Principalement du Python, souvent du SQL et parfois du R ou même du SAS ;
Framework : ceux qui reviennent sans arrêt : Tensorflow, PyTorch, Huggingface, SkLearn, Lime, Streamlit, écosystème Hadoop ;
Intégration continue : en fonction des contextes applicatifs : docker, docker-compose, Docker Swarm, GitHub actions, Jenkins, kubernetes, concourse.
Pourquoi choisir Valeuriad ?
😊
En plus d’être aujourd’hui un acteur nantais reconnu de l’expertise IT, nous nous inscrivons depuis notre création dans une démarche d'entreprise
Opale
et
Holacratique
, où l'ensemble de nos prises de décisions et projets sont réalisés par et avec l'ensemble de nos
120 coéquipiers
💪
Rejoindre Valeuriad, c'est pouvoir s'investir dans la co-construction de l'entreprise :
Par un rôle, avec une fiche de poste et un temps dédié (gestionnaire des Ci’s, porteur des partenariats écoles, organisateur d’événements, PO des projets internes, gestion de l'Académie Valeuriad…).
Par les projets stratégiques (200 jours mis à disposition pour les coéquipiers chaque année) pour créer et faire grandir des projets structurants (création de nouveaux avantages à l'ancienneté, création d'indicateurs mensuels pour être toujours plus transparents, mécénat de compétences pour des associations caritatives...).
Par les projets cagnottes (150€ par coéquipiers et par an) pour réaliser des projets collaboratifs qui te tiennent à cœur avec d'autres Valeurieux (découverte du cécifoot, challenge écologique, challenges sportifs pour des dons à des associations humanitaires, borne photo...).
Par les ateliers collaboratifs, chaque mois des brainstorming et ateliers de travail sont proposés par les différents porteurs de projets et sont ouverts à tous les volontaires.
Mais avant-tout nous sommes une
équipe soudée
, des collègues qui apprécient passer du temps ensemble lors de nos soirées hebdomadaires et se créer des
souvenirs inoubliables
🤩 C'est pour ça que chez Valeuriad, le plus important pour nous reste le savoir-être : des passionnés, du dynamisme, des sourires, de l'écoute et le sens de la fête 😉
Show more
Show less","{'ProgLanguage': ['Python', 'R', ' R ', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R', ' R '], 'BigData': ['Hadoop'], 'MachingLearning': ['TensorFlow', 'PyTorch'], 'DataSerialization': [], 'DataVisualization': ['Tableau'], 'Statistics': ['Statistiques', 'Statistiques Descriptives'], 'CloudComputing': [], 'DevTools': ['Git', 'Docker', 'Jenkins'], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': ['Kubernetes'], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': ['Docker', 'Kubernetes'], 'Collaboration': [], 'Other': ['ML', 'Machine Learning', 'Statistiques'], 'FrSoftSkills': [], 'EnSoftSkils': []}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's']}"
Machine Learning Engineer,AXA Group Operations,"Paris, Île-de-France, France",https://fr.linkedin.com/jobs/view/machine-learning-engineer-at-axa-group-operations-3856840119?position=11&pageNum=0&refId=lBTWbVudNP%2F9XLZiNl1XvQ%3D%3D&trackingId=jsgbXuSe6eEEMciI9FMP0g%3D%3D&trk=public_jobs_jserp-result_search-card,"Ready to shape the future? Join our team as a Machine Learning Engineer Extraordinaire!
About the job
Based in Paris or Barcelona, you will be part of the Artificial Intelligence Engineering team, in the Group Emerging Technologies and Data (GETD) division of AXA. This transversal team’s mission is both to build AI-powered initiatives (proofs of concept, proofs of value, pilots) with AXA entities & strategic partners and to define & implement MLOps best practices, tools, and collaboration models to be followed across the whole AXA Group. Our team is composed of 10 people, spread in 3 countries (France, Spain & Switzerland) and we work in hybrid mode (60% remote + 40% on-site).
AXA is a global leader in insurance and asset management present in nearly 60 countries. We leverage Artificial Intelligence to protect our 100+ million customers, in every domain of core insurance (Property & Casualty, Life & Savings, Health, …). As a responsible company, AXA defined and follows strong Responsible AI principles around robustness, interpretability, fairness, and sustainability.
Key responsibilities
In this role, you will:
Build and improve reusable tools & modelling pipelines and support knowledge sharing across several teams.
Work with Data Scientists to improve both technical and statistical performance of models.
Convert the machine learning models into application program interfaces (APIs) so that other applications can use them in alignment with architecture & infrastructure standards.
Secure and monitor ML processing, including safeguards, A/B testing, fault-tolerance, and failover.
Contribute to the definition and deployment of best practices in Machine Learning & MLOps,
Contribute to the sharing of knowledge and expertise through communities and working groups (internal and external).
Help the different actors of the organization (such as product managers and stakeholders) understand what results they gain from MLOps and best engineering practices in Data and AI.
What is needed to succeed
As we want you to succeed in this role, here is a list of examples of key factors:
4+ years of experience with DevOps: versioning (Git), containers (Docker/Kubernetes), CI/CD, Static analysis tools, …
Proficiency in ML Ops and ML Engineering frameworks: experiment trackers (like mlFlow) & orchestrators (Airflow, Kubeflow, Sagemaker Pipeline)
A practical knowledge in one of the popular ML Python libraries (TensorFlow, PyTorch, Keras, Scikit-Learn) and Open-Source libraries.
A good understanding of Agile methodologies and a mindset of continuous improvement.
Ability to articulate the results of your work for various audiences.
Good communication in English and interpersonal skills for working in a multicultural work environment.
Passion about solving challenging problems leveraging new technologies.
Nice to have
Here are other elements we will consider:
2+ years of experience in delivering and running ML models in production, using at least one of some of the main Big Data frameworks and platforms: Spark, Databricks, Snowflake, …
Practical knowledge in Infrastructure as code (Terraform, CloudFormation, …).
Practical knowledge of cloud services (Azure or Amazon Web Services).
Theoretical knowledge in Event Driven Architecture (using Kafka, Event Hub, or Rabbit MQ).
Insurance & Finance functional knowledge
What we offer
On top of usual benefits, we also offer:
Hybrid working (60% remote + 40% on-site).
Global communities of practice and 2 yearly global events gathering Engineers and Data Scientists.
Learning and mentoring opportunities through partnerships with LinkedIn Learning and O’Reilly.
Among a strong Employee benefit program, mental health, and well-being platform to access personalised care.
We bring together the expertise, cultural diversity and creativity of over 8,000 employees worldwide. We’re committed to equal opportunities in all aspects of employment (gender, LGBT+, disabled persons, or people of different origins) and to promoting Diversity & Inclusion by creating a work environment where all employees are treated with dignity and respect, and where individual differences are valued.
Show more
Show less","{'ProgLanguage': ['Python', 'R', 'Go'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': ['Spark', 'Databricks'], 'MachingLearning': ['Scikit-Learn', 'TensorFlow', 'Keras', 'PyTorch'], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': ['Azure'], 'DevTools': ['Git', 'Docker'], 'Os': [], 'DBMS': ['Snowflake', 'Snowflake'], 'SoftBigDataProcessing': [], 'Automation': ['Kubernetes', 'Airflow'], 'InfrastructureAsCode': ['Terraform', 'CloudFormation'], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': ['Docker', 'Kubernetes'], 'Collaboration': ['Teams'], 'Other': ['DevOps', 'Big Data', 'ML', 'Machine Learning', 'Cloud', 'CI/CD'], 'FrSoftSkills': ['Communication', 'Collaboration'], 'EnSoftSkils': ['Communication', 'Creativity', 'Collaboration', 'Organization', 'Initiative', 'Interpersonal Skills']}","{'JobDetail': ['Remote'], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's']}"
Data Scientist– Machine Learning,EyeTech Solutions,"Paris, Île-de-France, France",https://fr.linkedin.com/jobs/view/data-scientist%E2%80%93-machine-learning-at-eyetech-solutions-3913336440?position=12&pageNum=0&refId=lBTWbVudNP%2F9XLZiNl1XvQ%3D%3D&trackingId=OBLuKNj%2BOSZ8vsHN5RkkUA%3D%3D&trk=public_jobs_jserp-result_search-card,"Data Scientist– Machine Learning
Travailler sur le développement de modèle de machine learning prédictif.
Pour une Solution SaaS de monitoring analytique, prédictif et prescriptif en milieu industriel.
Data Scientist– Machine Learning
Fondée en 2016, notre société développe une solution SAAS dédiée au monitoring automatique des lignes de production.
Notre équipe spécialisée dans les données est responsable de la conception, du développement et de la maintenance de la plateforme IA de notre solution, dont les principales fonctionnalités incluent le monitoring analytique, prédictif et prescriptif.
Cette même équipe est également chargée du développement d'une nouvelle plateforme IA qui sera intégrée à nos solutions existantes.
Nos solutions reposent sur une stack technologique moderne, utilisant des outils tels que Airflow, Mlflow, MongoDB, Kubernetes, CI/CD.
Data Scientist– Machine Learning
Travaux sur le développement de modèle de machine learning prédictif
Collaboration avec le Lead Data Scientist et le Lead Tech Senior pour définir les orientations du produit et organiser les tâches.
Contribution au développement des fonctionnalités liées aux données et à l’intelligence artificielle.
Communication et présentation clients.
Veille scientifique et travaux de recherche et développement.
Data Scientist– Machine Learning
3 ans d’expérience minimum en tant que Data Scientist (IA, ML) dans l’industrialisation d’un produit
Capaciter à vulgariser, comprendre et transformer les besoins
Diplome universitaire
Data Scientist– Machine Learning
Locaux à Paris
Salaire selon profil, entre 50K et 55K
Télétravail 2 jours / semaine
Show more
Show less","{'ProgLanguage': ['R', 'Go'], 'DataBase': [' MongoDB'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': ['Kubernetes', 'Airflow'], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': ['Kubernetes'], 'Collaboration': [], 'Other': ['ML', 'Machine Learning', 'CI/CD'], 'FrSoftSkills': ['Communication', 'Collaboration'], 'EnSoftSkils': ['Communication', 'Collaboration']}","{'JobDetail': ['Senior'], 'TypeContract': [], 'Salary': ['50K'], 'Level': [], 'Experience': ['a', 'n', 's', '3', '3', '3']}"
Machine Learning Engineer,Aether Energy (YC W24),"Paris, Île-de-France, France",https://fr.linkedin.com/jobs/view/machine-learning-engineer-at-aether-energy-yc-w24-3911654324?position=13&pageNum=0&refId=lBTWbVudNP%2F9XLZiNl1XvQ%3D%3D&trackingId=nVRKh5HG0HdfA3RkF62Edg%3D%3D&trk=public_jobs_jserp-result_search-card,"We raised a $3M seed recently.
We encourage all applicants from the EU to apply.
Overview
Aether is on a mission to develop a comprehensive AI-driven platform for the solar energy industry. Our founders have strong technical academic background from UC Berkeley, complemented by extensive technical experience gained at some of the most influential companies in the energy sector.
Aether is seeking a machine learning engineer with a strong background in software engineering.
Ideal candidates should have backgrounds in Physics, Mechanical Engineering, Electrical Engineering, or Materials Science, coupled with expertise in Computational Mathematics. A Master's degree is essential for this role, while a PhD, though not mandatory, would be highly valuable.
We are proud of our recent success and invite you to check out our YCombinator launch at
this link
.
We're Looking For Someone Who:
Gets things done. This is an emerging Y Combinator seed company, and we require you to make an impact from day one.
Your growth potential here is unlimited.
Qualifications
This role will be 60% Machine Learning/Data Science focused, and 40% backend engineering focused. You will need to be comfortable writing production-level code.
REQUIRED
Strong proficiency in Python
Knowledge of unsupervised and supervised machine learning techniques
A deep understanding of Computer Vision models such as UNET, DeepLab, or HRNet (High-Resolution Network).
Interested in developing foundational LLM models (our use-case is energy)
Proficiency in data exploration (using BigQuery, Jupyter notebooks, and SQL), model development, and the establishment of data/ML pipelines
Comfortable working with APIs and Databases.
Knowledge of best practices in collaborative coding with tools like Git and CI/CD.
Strong software engineering skills and an understanding of good design patterns.
You must be Fluent in English.
Preferred -
We know you won’t know everything but having a good general breadth of the requirements below will set you apart.
A keen interest in the intersection of physical systems and AI.
Knowledge of the Django framework.
Familiarity with Python libraries, including Pandas, NumPy, scikit-learn, PyTorch/Tensorflow, PyTorch Lightning, and vector databases.
Competency in deploying data and code to cloud platforms (GCP/Digital Ocean).
Understanding of energy related data: battery data, solar data, etc.
Ideally, previous experience in high-growth start-ups.
Your math has to be good. We will check for this.
Compensation/Time Commitment/Location:
You will need to work US EST hours from Monday to Thursday. You must be in our Paris office 3x a week starting in August.
1st 3 months will be on a contract basis to assess performance.
Show more
Show less","{'ProgLanguage': ['Python', 'R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['Pandas', 'NumPy', 'R'], 'BigData': [], 'MachingLearning': ['Scikit-Learn', 'TensorFlow', 'PyTorch'], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git'], 'Os': [], 'DBMS': ['BigQuery'], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['ML', 'Machine Learning', 'Cloud', 'CI/CD'], 'FrSoftSkills': [], 'EnSoftSkils': []}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's']}"
Machine Learning Engineer,Mirakl,"Paris, Île-de-France, France",https://fr.linkedin.com/jobs/view/machine-learning-engineer-at-mirakl-3879686188?position=14&pageNum=0&refId=lBTWbVudNP%2F9XLZiNl1XvQ%3D%3D&trackingId=JUeTTFkzbZ7Fxg5zxT%2BBpQ%3D%3D&trk=public_jobs_jserp-result_search-card,"Mirakl, leader et pionnier de l’économie de plateforme, propose aux entreprises une suite unique de solutions leur permettant de transformer significativement leur e-commerce afin d'accélérer de façon durable et rentable leur croissance. Depuis 2012, Mirakl accompagne les entreprises B2C et B2B avec la technologie la plus avancée, sécurisée et évolutive leur permettant de digitaliser leur activité et d'élargir leur offre via la marketplace ou le dropship, faciliter la gestion des catalogues et des paiements de leurs fournisseurs pour plus d'efficacité, offrir une expérience d'achat personnalisée à leurs clients, et augmenter leurs profits grâce au retail media. Basée à Paris et Boston, Mirakl est certifiée Great Place to Work.
A propos de Mirakl Labs
Nos équipes techniques et produits, nommées Mirakl Labs, sont principalement réparties entre nos 2 hubs situés à Paris et à Bordeaux. Elles collaborent au quotidien afin d'adresser les problématiques de nos clients et utilisateurs en répondant à différents challenges liés aux nouvelles fonctionnalités, à la scalabilité, la sécurité et l’ergonomie…
Elles opèrent en mode agile et s'organisent en Squads composées d'un Squad Lead, de 5 développeurs, d'un Product Manager et d'un QA. Chaque Squad est spécialisée sur un scope fonctionnel afin de concevoir et réaliser de nouvelles features, leurs évolutions et des APIs (avec un découpage en micro-services). Nos équipes Infrastructure, Architecture, Sécurité, Documentation, Product Design, Data et Support opèrent en transverse en apportant leur expertise et de la cohérence sur l’ensemble des produits.
Toutes les équipes sont responsables de leur périmètre et chacun des collaborateurs apporte son expérience et ses idées. Innovation, feedback et implication dans les prises de décision sont au cœur de notre philosophie.
Et pour favoriser ce partage avec d’autres passionnés, nous sommes sponsors, speakers, et hôtes de différents événements, meetups, et associations de la scène Tech en France. Au cours des dernières années, nous avons participé à des événements tels que Devoxx, ReactEurope, ProductConf et Flupa UX Days.
A propos du job
Intégré.e dans notre équipe Data Science, votre principale mission sera de prototyper, itérer, et mettre en production des algorithmes en collaboration avec les équipes Produit, les Data Engineers et les équipes de développement. Les sujets que vous traiterez auront un vrai impact sur nos clients : l’ambition est d’exploiter au maximum nos données riches et variées afin de développer leur chiffre d'affaires, d’optimiser la gestion opérationnelle de leur marketplace et de garantir la sécurité des utilisateurs et des transactions.
A propos de l’équipe
Get to Know the Data Science Team That Powers the Mirakl Platform
Ce qu’il y a pour vous dans ce job
Implémenter, optimiser et déployer des algorithmes qui auront un impact visible sur plus de 500 sites e-commerce/marketplaces dans 40 pays dont certains une volumétrie très importantes (millions de produits, de clients, de commandes par an)
Traiter des sujets très divers et variés d’un point de vue:
Business
Machine learning (NLP, Image processing, Time series, LLM, système de recommandation, etc.)
Infrastructure (spark, model endpoints, etc.)
Une plateforme Machine Learning et Data Platform state-of-the-art
Concevoir et déployer des infrastructures à faible latence avec les Data Engineers
Une vraie autonomie et responsabilité dans les projets dont vous avez l’ownership
La possibilité d'avoir un contrat freelance ou CDI
Notre stack et nos outils
Python, Tensorflow, Pytorch, Databricks, Spark, Aws, Airflow, MLflow, Delta Lake, SQL
Au quotidien
,
vous allez :
Designer, optimiser et mettre en production des modèles de machine learning de façon scalable (apprentissage et inférence)
Rassembler et manipuler les données, prototyper des algorithmes de machine learning
Mettre en place et monitorer des serving endpoints
Participer à l’évolution de la plateforme Machine Learning de Mirakl
Continuer à mettre en place des best practices de programmation mais aussi de déploiement
Effectuer de la veille technologique sur les modèles state-of-the-art, ainsi que sur les stack machine learning
Présenter les résultats au weekly data science et aux sessions de brainstorming de l’équipe
Échanger avec les autres équipes pour affiner les cas d’utilisation, l’expérience utilisateur et les modes d’intégration
Vous aimerez ce job si :
Vous avez minimum 3 ans d’expérience en tant que Machine Learning Engineer (le poste est évolutif selon votre séniorité)
Vous avez de solides compétences en développement Python
Vous aimez le software engineering et le machine learning
Vous avez une expérience significative dans la mise en production, le scaling des modèles et des bests practices MLOps
Vous avez l’habitude de chercher, manipuler et analyser des données à forte volumétrie, idéalement avec Spark
Vous avez une bonne connaissance des algorithmes de Deep Learning (texte et/ou image), des architectures State-Of-the-Art - par exemple les Transformers
Vous avez de l’expérience dans l’optimisation de modèles de machine learning et de leur inférence
Vous avez de l’expérience dans la mise en place de serving de modèles
Vous aimez avoir l’ownership de vos sujets et aimez partager votre travail dans le cadre de présentations internes, dans des conférences ou en rédigeant des articles
Petit plus :
Vous avez une expérience en environnement e-commerce, sur des algorithmes de systèmes de recommandations et/ou retail media
Vous avez une expérience dans le serving de modèles à faible latence
Vous êtes spécialiste NLP
Optimisation de LLM
Mirakl est engagée en faveur de la diversité, de l’égalité des chances et de l’inclusion. Nous célébrons nos différences car nous sommes convaincus que les qualités visibles et invisibles de chaque Mirakl Worker sont une source de force et d’innovation. Dans le cadre de cet engagement, nous étudions toutes les candidatures sans distinction de : genre, ethnicité, religion, orientation sexuelle, handicap, âge ou toute autre caractéristique protégée par la loi.
Show more
Show less","{'ProgLanguage': ['Python', 'Scala', 'R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': ['Spark', 'Databricks'], 'MachingLearning': ['TensorFlow', 'PyTorch'], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': ['AWS'], 'DevTools': ['Git'], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': ['Airflow'], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['ML', 'Machine Learning'], 'FrSoftSkills': ['Collaboration'], 'EnSoftSkils': ['Collaboration']}","{'JobDetail': [], 'TypeContract': ['CDI'], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's', '3', '3', '3']}"
Machine Learning Engineer,Mirakl,"Paris, Île-de-France, France",https://fr.linkedin.com/jobs/view/machine-learning-engineer-at-mirakl-3879682593?position=15&pageNum=0&refId=lBTWbVudNP%2F9XLZiNl1XvQ%3D%3D&trackingId=ReSiNFGr9PrA60TUCNr%2FYQ%3D%3D&trk=public_jobs_jserp-result_search-card,"Mirakl, leader et pionnier de l’économie de plateforme, propose aux entreprises une suite unique de solutions leur permettant de transformer significativement leur e-commerce afin d'accélérer de façon durable et rentable leur croissance. Depuis 2012, Mirakl accompagne les entreprises B2C et B2B avec la technologie la plus avancée, sécurisée et évolutive leur permettant de digitaliser leur activité et d'élargir leur offre via la marketplace ou le dropship, faciliter la gestion des catalogues et des paiements de leurs fournisseurs pour plus d'efficacité, offrir une expérience d'achat personnalisée à leurs clients, et augmenter leurs profits grâce au retail media. Basée à Paris et Boston, Mirakl est certifiée Great Place to Work.
A propos de Mirakl Labs
Nos équipes techniques et produits, nommées Mirakl Labs, sont principalement réparties entre nos 2 hubs situés à Paris et à Bordeaux. Elles collaborent au quotidien afin d'adresser les problématiques de nos clients et utilisateurs en répondant à différents challenges liés aux nouvelles fonctionnalités, à la scalabilité, la sécurité et l’ergonomie…
Elles opèrent en mode agile et s'organisent en Squads composées d'un Squad Lead, de 5 développeurs, d'un Product Manager et d'un QA. Chaque Squad est spécialisée sur un scope fonctionnel afin de concevoir et réaliser de nouvelles features, leurs évolutions et des APIs (avec un découpage en micro-services). Nos équipes Infrastructure, Architecture, Sécurité, Documentation, Product Design, Data et Support opèrent en transverse en apportant leur expertise et de la cohérence sur l’ensemble des produits.
Toutes les équipes sont responsables de leur périmètre et chacun des collaborateurs apporte son expérience et ses idées. Innovation, feedback et implication dans les prises de décision sont au cœur de notre philosophie.
Et pour favoriser ce partage avec d’autres passionnés, nous sommes sponsors, speakers, et hôtes de différents événements, meetups, et associations de la scène Tech en France. Au cours des dernières années, nous avons participé à des événements tels que Devoxx, ReactEurope, ProductConf et Flupa UX Days.
A propos du job
Intégré.e dans notre équipe Data Science, votre principale mission sera de prototyper, itérer, et mettre en production des algorithmes en collaboration avec les équipes Produit, les Data Engineers et les équipes de développement. Les sujets que vous traiterez auront un vrai impact sur nos clients : l’ambition est d’exploiter au maximum nos données riches et variées afin de développer leur chiffre d'affaires, d’optimiser la gestion opérationnelle de leur marketplace et de garantir la sécurité des utilisateurs et des transactions.
A propos de l’équipe
Get to Know the Data Science Team That Powers the Mirakl Platform
Ce qu’il y a pour vous dans ce job
Implémenter, optimiser et déployer des algorithmes qui auront un impact visible sur plus de 500 sites e-commerce/marketplaces dans 40 pays dont certains une volumétrie très importantes (millions de produits, de clients, de commandes par an)
Traiter des sujets très divers et variés d’un point de vue:
Business
Machine learning (NLP, Image processing, Time series, LLM, système de recommandation, etc.)
Infrastructure (spark, model endpoints, etc.)
Une plateforme Machine Learning et Data Platform state-of-the-art
Concevoir et déployer des infrastructures à faible latence avec les Data Engineers
Une vraie autonomie et responsabilité dans les projets dont vous avez l’ownership
La possibilité d'avoir un contrat freelance ou CDI
Notre stack et nos outils
Python, Tensorflow, Pytorch, Databricks, Spark, Aws, Airflow, MLflow, Delta Lake, SQL
Au quotidien
,
vous allez :
Designer, optimiser et mettre en production des modèles de machine learning de façon scalable (apprentissage et inférence)
Rassembler et manipuler les données, prototyper des algorithmes de machine learning
Mettre en place et monitorer des serving endpoints
Participer à l’évolution de la plateforme Machine Learning de Mirakl
Continuer à mettre en place des best practices de programmation mais aussi de déploiement
Effectuer de la veille technologique sur les modèles state-of-the-art, ainsi que sur les stack machine learning
Présenter les résultats au weekly data science et aux sessions de brainstorming de l’équipe
Échanger avec les autres équipes pour affiner les cas d’utilisation, l’expérience utilisateur et les modes d’intégration
Vous aimerez ce job si :
Vous avez minimum 3 ans d’expérience en tant que Machine Learning Engineer (le poste est évolutif selon votre séniorité)
Vous avez de solides compétences en développement Python
Vous aimez le software engineering et le machine learning
Vous avez une expérience significative dans la mise en production, le scaling des modèles et des bests practices MLOps
Vous avez l’habitude de chercher, manipuler et analyser des données à forte volumétrie, idéalement avec Spark
Vous avez une bonne connaissance des algorithmes de Deep Learning (texte et/ou image), des architectures State-Of-the-Art - par exemple les Transformers
Vous avez de l’expérience dans l’optimisation de modèles de machine learning et de leur inférence
Vous avez de l’expérience dans la mise en place de serving de modèles
Vous aimez avoir l’ownership de vos sujets et aimez partager votre travail dans le cadre de présentations internes, dans des conférences ou en rédigeant des articles
Petit plus :
Vous avez une expérience en environnement e-commerce, sur des algorithmes de systèmes de recommandations et/ou retail media*
Vous avez une expérience dans le serving de modèles à faible latence
Vous êtes spécialiste NLP
Optimisation de LLM
Mirakl est engagée en faveur de la diversité, de l’égalité des chances et de l’inclusion. Nous célébrons nos différences car nous sommes convaincus que les qualités visibles et invisibles de chaque Mirakl Worker sont une source de force et d’innovation. Dans le cadre de cet engagement, nous étudions toutes les candidatures sans distinction de : genre, ethnicité, religion, orientation sexuelle, handicap, âge ou toute autre caractéristique protégée par la loi.
Show more
Show less","{'ProgLanguage': ['Python', 'Scala', 'R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': ['Spark', 'Databricks'], 'MachingLearning': ['TensorFlow', 'PyTorch'], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': ['AWS'], 'DevTools': ['Git'], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': ['Airflow'], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['ML', 'Machine Learning'], 'FrSoftSkills': ['Collaboration'], 'EnSoftSkils': ['Collaboration']}","{'JobDetail': [], 'TypeContract': ['CDI'], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's', '3', '3', '3']}"
Machine Learning Scientist/Engineer,NuMind (YC S22),"Paris, Île-de-France, France",https://fr.linkedin.com/jobs/view/machine-learning-scientist-engineer-at-numind-yc-s22-3856851886?position=16&pageNum=0&refId=lBTWbVudNP%2F9XLZiNl1XvQ%3D%3D&trackingId=%2BaSTUFC%2FiDjmT8UipkyumA%3D%3D&trk=public_jobs_jserp-result_search-card,"About Us
NuMind (https://www.numind.ai/) is a software company developing a tool to create custom NLP models specialized in information extraction (see https://www.youtube.com/watch?v=MQhYe5HXqss). We also develop open-source foundation models (https://huggingface.co/numind), and write research papers (see https://arxiv.org/abs/2402.15343).
We aim to become leader in the field of custom information extraction.
We are a team of 7: CEO, CTO, COO, 2 senior software engineers, and 2 machine learning scientists. Our CEO was head of ML at Wolfram Research and our CTO co-founded Make.org.
Most of the team are located in France (Paris).
We were part of YCombinator’s S22 batch, and raised a good seed round.
Job Description
NuMind is a tool to create NLP models (e.g. classifiers and entity recognizers). The user provides information about the task (e.g. by labeling documents), and the computer creates models automatically.
Your job will be to make this happen in the most effective way. This will involve designing & testing various machine learning solutions, and implementing these solutions directly into NuMind.
R&D topics include:
Transfer learning, few-shot learning
Active learning
Automatic machine learning
Performance measurements
Distillation
Probability calibration
Out-of-domain robustness
Model explanations
This position is for someone who has both a researcher and engineer mindset.
Responsibilities
Training task-specific foundation models
Setting up benchmarks to test ML solutions
Identifying & testing existing ML solutions
Designing & testing new ML solutions from scratch
Implementing selected solutions into the product
Staying up to date with relevant NLP research
Qualifications
Expert-level understanding of machine learning.
Ability to design, train, test deep learning models
Ability to conduct machine learning research (e.g. conducting experiments, drawing conclusions, communicating results)
Ability to develop production-grade code
Good understanding of the following field: statistics, computer science (esp. data structures & algorithms), and numerical analysis
Show more
Show less","{'ProgLanguage': ['R', 'Go'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': ['Statistics'], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['ML', 'Machine Learning'], 'FrSoftSkills': [], 'EnSoftSkils': []}","{'JobDetail': ['Senior'], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's']}"
Data Scientist - Toulouse,Capgemini,"Toulouse, Occitanie, France",https://fr.linkedin.com/jobs/view/data-scientist-toulouse-at-capgemini-3913358664?position=17&pageNum=0&refId=lBTWbVudNP%2F9XLZiNl1XvQ%3D%3D&trackingId=3eobZv4EwwTVzSjOeUjfmg%3D%3D&trk=public_jobs_jserp-result_search-card,"Capgemini en quelques mots
Choisir Capgemini, c'est choisir une entreprise où vous serez en mesure de façonner votre carrière selon vos aspirations, où vous serez soutenu et inspiré par une communauté d’experts dans le monde entier, où vous pourrez réécrire votre futur. Rejoignez-nous pour redéfinir les limites de ce qui est possible, contribuer à libérer la valeur de la technologie pour les plus grandes organisations et participez à la construction d’un monde plus durable et inclusif.
Vos missions
En tant que
Lead Technique Data Science
au sein de la practice Insights & Data, vous serez amener à intervenir sur des projets data pour :
Idéaliser les cas d’usages et cadrer le projet afin de répondre aux exigences métiers à partir de solutions innovantes d’Intelligence Artificielle
Promouvoir les bonnes pratiques au sein de l’équipe avec le développement d’une méthodologie de travail et d’amélioration continue appropriés
Participer aux propositions commerciales sur la partie Data
Construire une relation de confiance avec le client en tant qu’interlocuteur privilégié et assurer la qualité des rendus finaux ainsi que le développement de nouveaux enjeux business
Faire parti des leaders de la communauté Data Science et influencer sur la stratégie Data d’Insights & Data
Continuer de vous former sur tous les aspects de votre métier et assurer une veille technologique sur les innovations les plus pertinentes à mettre en place
Votre profil
De formation Bac + 5 en école d’ingénieur ou équivalent universitaire avec une spécialisation Data Science
A partir de 6 ans d’expériences
Compréhension fine des enjeux business et pilotage d'une équipe
Connaissance de plusieurs langages de programmation (Python, Scala, Spark…) et Cloud (AWS, GCP, Azure, OVH)
Le Machine Learning, le NLP et le Deep Learning n’ont plus de secret pour vous
Bon niveau d'anglais
3 raisons de nous rejoindre
Qualité de vie au travail :
accord de télétravail en France et à l’international, accord sur l’égalité
professionnelle, la parentalité, l’équilibre des temps et la mobilité durable.
Apprentissage en continu :
certifications et formations en libre accès, accompagnement sur mesure avec
votre carreer manager, parcours d’intégration sur 9 mois.
Avantages groupe & CSE :
plan actionnariat, activités à tarifs préférentiels, remboursement partiel
vacances, remboursement de votre abonnement sportif ou culturel
Nos engagements et priorités
Le groupe Capgemini encourage une
culture inclusive dans un cadre multiculturel et handi-accueillant.
En nous rejoignant, vous intégrez un collectif qui valorise la diversité, développe le potentiel de ses talents, s’engage dans des
initiatives solidaires avec ses partenaires, et se mobilise pour réduire son impact environnemental sur tous ses sites et auprès de ses clients.
Capgemini
est un
leader mondial
, responsable et multiculturel, regroupant près de 350 000 personnes dans plus de 50 pays. Fort de
55 ans d’expérience
, nous sommes un partenaire stratégique des entreprises pour la transformation de leurs activités en tirant profit de toute la puissance de la technologie et des innovations dans les domaines en perpétuelle évolution tels que
le cloud, la data, l’Intelligence Artificielle, la connectivité, les logiciels, l’ingénierie digitale ou les plateformes.
Get The Future You Want* | www.capgemini.com/fr-fr
*Capgemini, le futur que vous voulez
Show more
Show less","{'ProgLanguage': ['Python', 'Scala', 'R'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': ['Spark'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': ['AWS', 'Azure'], 'DevTools': ['Git'], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Machine Learning', 'Cloud'], 'FrSoftSkills': ['Organisation'], 'EnSoftSkils': ['Initiative']}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's', '6', '6', '6']}"
Data Scientist,Enzo Tech Group,"Île-de-France, France",https://fr.linkedin.com/jobs/view/data-scientist-at-enzo-tech-group-3914681877?position=18&pageNum=0&refId=lBTWbVudNP%2F9XLZiNl1XvQ%3D%3D&trackingId=ZYLxYkcx1lH%2BpIs29xRmjg%3D%3D&trk=public_jobs_jserp-result_search-card,"Role:
Data Scientist
Location:
Paris (3 days) / Remote (2 days)
Searching for a
Data Scientist
partnering with a global customer who are searching for multiple Data Scientist's as they continue to invest in designing and building high-quality AI solutions.
Responsibilities
Analyze raw data: assessing quality, cleansing, structuring for downstream processing
Design accurate and scalable prediction algorithms
Collaborate with engineering team to bring analytical prototypes to production
Generate actionable insights for business improvements
Qualifications
Bachelor's degree or equivalent experience in quantative field (Statistics, Mathematics, Computer Science, Engineering, etc.)
Tech Stack: GenAI, Databricks, Azure
At least 1 - 2 years' of experience in quantitative analytics or data modelling
Deep understanding of predictive modelling, machine-learning, clustering and classification techniques, and algorithms
Fluency in a programming language (Python, C,C++, Java, SQL)
CVs:
Apply via job post or directly
@
k.downs@enzotechgroup.com
Show more
Show less","{'ProgLanguage': ['Python', 'Java', 'C++', 'Scala', 'R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': ['Databricks'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': ['Statistics'], 'CloudComputing': ['Azure'], 'DevTools': [], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': [], 'FrSoftSkills': [], 'EnSoftSkils': []}","{'JobDetail': ['Remote'], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's']}"
Data Scientist,Sidetrade,"Boulogne-Billancourt, Île-de-France, France",https://fr.linkedin.com/jobs/view/data-scientist-at-sidetrade-3894699040?position=19&pageNum=0&refId=lBTWbVudNP%2F9XLZiNl1XvQ%3D%3D&trackingId=Y5c0uvjp9E2Mchkh1aosgw%3D%3D&trk=public_jobs_jserp-result_search-card,"Calling all tech enthusiasts! Are you a problem-solving, curious, and strategic Data Scientist ? Join us at Sidetrade, the leading global SaaS provider recognized by Gartner.(https://go.sidetrade.com/GartnerMagicQuadrant22.ht)
Indulge your passion for high-availability software and performance enhancement as part of our dynamic team. Embrace the challenge, embrace the excitement - become a Data Scientist and thrive! Shape the future of AI-powered Order-to-Cash at Sidetrade today. Join us in creating innovative solutions that redefine the industry!
About Sidetrade and its amazing R&D team
Sidetrade is a fast-growing international software company that is transforming the Order-to-Cash process for global enterprises. Its AI-powered SaaS platform digitizes the financial customer journey, empowering CFOs to secure and accelerate cash flow generation. Recognized as a Leader in Gartner's Magic Quadrant for two consecutive years, Sidetrade fosters a culture of innovation, collaboration, and customer-centricity from its headquarters in Europe and North America.
The R&D team comprises experienced tech professionals who share a deep passion for technology. Together, they are dedicated to developing cutting-edge software solutions that drive the transformation of our customers' work processes. We provide comprehensive training, coaching, resources, and mentorship to empower every team member's growth and nurture their success.
What you will love at Sidetrade:
We are seeking a passionate and knowledgeable Data Scientist with a multifaceted skill set. Immerse yourself in the exhilarating world of AI and Data Science within our cutting-edge tech environment. Collaborate with like-minded individuals, embracing the latest tools, techniques, and technologies. Fuel your professional growth and innovation within our agile development ecosystem.
Your missions :
Build solutions with AI, GenAI, LLM, Machine learning, Deep learning, Big Data for our products
Define the technical and functional orientations of the product in interaction with our Product, Marketing and Sales teams.
Participate in developing the architecture (LakeHouse, DataWareHouse, DataLake, ETL, Search Engine, NoSQL, SQL) and designing scalable and smart algorithms
Enhance your skills through constant discussions with specialists in their fields, and internal hackathons
Participate in data science guild projects: Exploratory research, Data mining, Data analysis, POC Machine learning,..
You will be involved in the entire development cycle: design, implementation, testing, release and maintenance.
Through your expertise, you will reinforce the continuous improvement of development processes.
Technical environment :
Languages : Python & SQL
Data Storage : Oracle, Postgres, Elasticsearch, Greenplum, MongoDB
Data Science framework : Dataiku, Jupyter Notebook, Metaflow
Dataviz : Tableau Server, PowerBI
Data processing : Talend, Python, DBT, Kafka
Source control : Git
Déployment: Bash, Ansible, Docker
Confluence, Jira, Teams
Requirements
Master degree
2 to 5 years' experience in a similar position
Proven data science experience with production launch of Machine Learning models
Applied knowledge of AI, GenAI and LLM
Solid knowledge of Python and object-oriented programming
Good knowledge of SQL and NoSQL databases
Familiarity with API Rest and Web development issues
Sensitivy to the performance of your algorithms, both in terms of relevance and hardware impact
A taste for discovery and technology watch
You know how to grasp a rich technical stack (Scheduling/Message queuing/Front/API/Data Workflow / Distributed Computing Framework / Machine Learning / SQL & NoSQL databases) and challenge it
Fluent in English (written and spoken) is a must (most of the meeting are in English).
Benefits
Join our Immersive Bootcamp
Review your onboarding plan with your manager and develop an action plan to achieve your goals
Collaborate with the team and participate to the roadmap to optimize software performancebuild your internal network across all departments
Expand your skill set, share your expertise and unlock your full potential
At Sidetrade, we cultivate a multicultural environment that fuels innovation. With over 22 nationalities represented, we strongly value diversity, gender equality, inclusivity, and fairness. As an equal opportunity employer, we reject all forms of discrimination and harassment. Your unique contributions are celebrated, driving collective success in our inclusive workplace.
Discover more on www.sidetrade.com
Agencies
Only applications from invited agencies through the Workable portal will be accepted. Unsolicited CVs sent directly to managers or HR will not incur any fees.
Apply for this job
Show more
Show less","{'ProgLanguage': ['Python', 'Scala', 'R', 'Go', 'Bash'], 'DataBase': ['SQL', 'NoSQL', ' MongoDB', 'Elasticsearch'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': ['Tableau', 'PowerBI'], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git', 'Docker'], 'Os': [], 'DBMS': ['Oracle'], 'SoftBigDataProcessing': [], 'Automation': ['Ansible'], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': ['Docker'], 'Collaboration': ['JIRA', 'Confluence', 'Teams'], 'Other': ['Big Data', 'Machine Learning'], 'FrSoftSkills': ['Collaboration'], 'EnSoftSkils': ['Collaboration']}","{'JobDetail': ['Full'], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's']}"
Data Scientist H/F,Lincoln France,"Île-de-France, France",https://fr.linkedin.com/jobs/view/data-scientist-h-f-at-lincoln-france-3892490370?position=20&pageNum=0&refId=lBTWbVudNP%2F9XLZiNl1XvQ%3D%3D&trackingId=GK%2BlkTopEO6Ybk%2F8QnLYaQ%3D%3D&trk=public_jobs_jserp-result_search-card,"CDI
📊
4 ans minimum
Chez Lincoln
, nous formons une communauté d'innovateurs passionnés qui redéfinissent l'analyse de données depuis
plus de 30 ans
. En tant que
Pure Player Data
, notre expertise est reconnue dans les domaines
de la Modern BI, du Big Data et de la Science des données
.
Notre mission ?
Transformer les données en solutions concrètes pour nos clients grands comptes dans divers secteurs tels que la banque, le retail, les télécoms, l'industrie, la santé, etc.
Description du poste
Nous recherchons un
Data Scientist H/F
pour accompagner nos clients dans leurs projets stratégiques.
Vos missions
Collecter, nettoyer et préparer les données pour l'analyse.
Concevoir, développer et mettre en œuvre des modèles prédictifs et analytiques en utilisant des techniques avancées d'apprentissage automatique et de science des données.
Analyser les résultats des modèles et fournir des insights exploitables aux équipes clients.
Collaborer avec les équipes interfonctionnelles pour comprendre les besoins commerciaux et recommander des solutions basées sur les données.
Prérequis :
Solides compétences en programmation (
Python, R, SQL, etc.)
et en manipulation de données.
Expérience pratique avec des frameworks et des bibliothèques d'apprentissage automatique (
TensorFlow, PyTorch, Scikit-learn
,
etc
.).
Maîtrise des techniques avancées d'analyse de données, y compris l'apprentissage automatique, l'apprentissage profond, la vision par ordinateur, le traitement du langage naturel, etc.
Expérience de travail en
méthode Agile
pour la gestion de projet et le développement de solutions.
Capacité à travailler de manière autonome et en équipe.
Excellentes compétences en communication et en présentation.
Les plus du poste
Environnement Collaboratif
: projets innovants favorisant le partage des connaissances.
Accompagnement individualisé et de proximité
: formations certifiantes, attribution d’un Career Manager pour vous orienter dans votre trajectoire professionnelle, opportunités d’évolution de carrière.
Flexibilité du Travail
: Télétravail et horaires flexibles pour votre équilibre vie professionnelle-personnelle.
Rémunération Compétitive
: Salaire compétitif avec des avantages sociaux attrayants.
Mobilité
: Possibilité de mobilité à Lille, Lyon ou Aix-en-Provence offrant des expériences diversifiées au sein de Lincoln.
Notre processus de recrutement :
Un entretien RH (1h) et entretien technique (1h)
Cette annonce n’est pas faite pour vous si :
Vous êtes freelance et vous comptez le rester !
Toujours là ? Postulez et rejoignez nos
400 experts en Data
😉.
Show more
Show less","{'ProgLanguage': ['Python', 'R'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': ['Scikit-Learn', 'TensorFlow', 'PyTorch'], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Big Data'], 'FrSoftSkills': ['Communication', 'Flexibilité'], 'EnSoftSkils': ['Communication']}","{'JobDetail': [], 'TypeContract': ['CDI'], 'Salary': ['400'], 'Level': [], 'Experience': ['a', 'n', 's', '4', '4', '4']}"
Machine Learning Engineer,Mirakl,"Bordeaux, Nouvelle-Aquitaine, France",https://fr.linkedin.com/jobs/view/machine-learning-engineer-at-mirakl-3879681732?position=21&pageNum=0&refId=lBTWbVudNP%2F9XLZiNl1XvQ%3D%3D&trackingId=A9%2BxMI2ZEzNhLfZ7CDQdOA%3D%3D&trk=public_jobs_jserp-result_search-card,"Mirakl, leader et pionnier de l’économie de plateforme, propose aux entreprises une suite unique de solutions leur permettant de transformer significativement leur e-commerce afin d'accélérer de façon durable et rentable leur croissance. Depuis 2012, Mirakl accompagne les entreprises B2C et B2B avec la technologie la plus avancée, sécurisée et évolutive leur permettant de digitaliser leur activité et d'élargir leur offre via la marketplace ou le dropship, faciliter la gestion des catalogues et des paiements de leurs fournisseurs pour plus d'efficacité, offrir une expérience d'achat personnalisée à leurs clients, et augmenter leurs profits grâce au retail media. Basée à Paris et Boston, Mirakl est certifiée Great Place to Work.
A propos de Mirakl Labs
Nos équipes techniques et produits, nommées Mirakl Labs, sont principalement réparties entre nos 2 hubs situés à Paris et à Bordeaux. Elles collaborent au quotidien afin d'adresser les problématiques de nos clients et utilisateurs en répondant à différents challenges liés aux nouvelles fonctionnalités, à la scalabilité, la sécurité et l’ergonomie…
Elles opèrent en mode agile et s'organisent en Squads composées d'un Squad Lead, de 5 développeurs, d'un Product Manager et d'un QA. Chaque Squad est spécialisée sur un scope fonctionnel afin de concevoir et réaliser de nouvelles features, leurs évolutions et des APIs (avec un découpage en micro-services). Nos équipes Infrastructure, Architecture, Sécurité, Documentation, Product Design, Data et Support opèrent en transverse en apportant leur expertise et de la cohérence sur l’ensemble des produits.
Toutes les équipes sont responsables de leur périmètre et chacun des collaborateurs apporte son expérience et ses idées. Innovation, feedback et implication dans les prises de décision sont au cœur de notre philosophie.
Et pour favoriser ce partage avec d’autres passionnés, nous sommes sponsors, speakers, et hôtes de différents événements, meetups, et associations de la scène Tech en France. Au cours des dernières années, nous avons participé à des événements tels que Devoxx, ReactEurope, ProductConf et Flupa UX Days.
A propos du job
Intégré.e dans notre équipe Data Science, votre principale mission sera de prototyper, itérer, et mettre en production des algorithmes en collaboration avec les équipes Produit, les Data Engineers et les équipes de développement. Les sujets que vous traiterez auront un vrai impact sur nos clients : l’ambition est d’exploiter au maximum nos données riches et variées afin de développer leur chiffre d'affaires, d’optimiser la gestion opérationnelle de leur marketplace et de garantir la sécurité des utilisateurs et des transactions.
A propos de l’équipe
Get to Know the Data Science Team That Powers the Mirakl Platform
Ce qu’il y a pour vous dans ce job
Implémenter, optimiser et déployer des algorithmes qui auront un impact visible sur plus de 500 sites e-commerce/marketplaces dans 40 pays dont certains une volumétrie très importantes (millions de produits, de clients, de commandes par an)
Traiter des sujets très divers et variés d’un point de vue:
Business
Machine learning (NLP, Image processing, Time series, LLM, système de recommandation, etc.)
Infrastructure (spark, model endpoints, etc.)
Une plateforme Machine Learning et Data Platform state-of-the-art
Concevoir et déployer des infrastructures à faible latence avec les Data Engineers
Une vraie autonomie et responsabilité dans les projets dont vous avez l’ownership
La possibilité d'avoir un contrat freelance ou CDI
Notre stack et nos outils
Python, Tensorflow, Pytorch, Databricks, Spark, Aws, Airflow, MLflow, Delta Lake, SQL
Au quotidien
,
vous allez :
Designer, optimiser et mettre en production des modèles de machine learning de façon scalable (apprentissage et inférence)
Rassembler et manipuler les données, prototyper des algorithmes de machine learning
Mettre en place et monitorer des serving endpoints
Participer à l’évolution de la plateforme Machine Learning de Mirakl
Continuer à mettre en place des best practices de programmation mais aussi de déploiement
Effectuer de la veille technologique sur les modèles state-of-the-art, ainsi que sur les stack machine learning
Présenter les résultats au weekly data science et aux sessions de brainstorming de l’équipe
Échanger avec les autres équipes pour affiner les cas d’utilisation, l’expérience utilisateur et les modes d’intégration
Vous aimerez ce job si :
Vous avez minimum 3 ans d’expérience en tant que Machine Learning Engineer (le poste est évolutif selon votre séniorité)
Vous avez de solides compétences en développement Python
Vous aimez le software engineering et le machine learning
Vous avez une expérience significative dans la mise en production, le scaling des modèles et des bests practices MLOps
Vous avez l’habitude de chercher, manipuler et analyser des données à forte volumétrie, idéalement avec Spark
Vous avez une bonne connaissance des algorithmes de Deep Learning (texte et/ou image), des architectures State-Of-the-Art - par exemple les Transformers
Vous avez de l’expérience dans l’optimisation de modèles de machine learning et de leur inférence
Vous avez de l’expérience dans la mise en place de serving de modèles
Vous aimez avoir l’ownership de vos sujets et aimez partager votre travail dans le cadre de présentations internes, dans des conférences ou en rédigeant des articles
Petit plus :
Vous avez une expérience en environnement e-commerce, sur des algorithmes de systèmes de recommandations et/ou retail media*
Vous avez une expérience dans le serving de modèles à faible latence
Vous êtes spécialiste NLP
Optimisation de LLM
Mirakl est engagée en faveur de la diversité, de l’égalité des chances et de l’inclusion. Nous célébrons nos différences car nous sommes convaincus que les qualités visibles et invisibles de chaque Mirakl Worker sont une source de force et d’innovation. Dans le cadre de cet engagement, nous étudions toutes les candidatures sans distinction de : genre, ethnicité, religion, orientation sexuelle, handicap, âge ou toute autre caractéristique protégée par la loi.
Show more
Show less","{'ProgLanguage': ['Python', 'Scala', 'R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': ['Spark', 'Databricks'], 'MachingLearning': ['TensorFlow', 'PyTorch'], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': ['AWS'], 'DevTools': ['Git'], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': ['Airflow'], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['ML', 'Machine Learning'], 'FrSoftSkills': ['Collaboration'], 'EnSoftSkils': ['Collaboration']}","{'JobDetail': [], 'TypeContract': ['CDI'], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's', '3', '3', '3']}"
Data Scientist H/F,Harmonie Mutuelle,"Rennes, Brittany, France",https://fr.linkedin.com/jobs/view/data-scientist-h-f-at-harmonie-mutuelle-3903667706?position=22&pageNum=0&refId=lBTWbVudNP%2F9XLZiNl1XvQ%3D%3D&trackingId=JKFzM%2BSP0G5cyF2d4cuXSQ%3D%3D&trk=public_jobs_jserp-result_search-card,"Vous êtes en quête d'une nouvelle aventure professionnelle collective et porteuse de sens ?
Vous voulez un parcours qui vous ressemble ? Vous avez envie d'évoluer dans un
environnement de travail épanouissant fondé sur la confiance, la diversité et l'égalité des
chances ?
Vous êtes au bon endroit ! Ensemble, nous pouvons faire la différence.
Le poste :
Nous opérons notre transformation digitale et renforçons le besoin de pilotage de nos flux et activités au sein de la Direction des Services et de la Satisfaction Clients. Dans ce cadre, nous recherchons un(e) Data Scientist pour renforcer l'équipe Pilotage et Analyse Data Science. Parmi nos sujets : analyser les activités des centres de gestion, mesurer l'efficacité des actions de digitalisation, robotisation et dématérialisation, analyser et détecter les fraudes à la mutuelle, modéliser des dimensionnements de flux et d'équipes...
Vos missions principales :
Vous participez au développement de cette équipe avec pour mission principale la production opérationnelle d'algorithmes data science de détection de fraude :
- Exécuter des algorithmes existants, monitorer, valider les productions
- Maintenir ces modèles mathématiques. Suivre leurs performances réelles
- Collecter l'ensemble des informations (hypothèses, roadmap, projet, nouvelles données) nécessaires à l'amélioration continue des modèles et au développement de nouveaux
- Explorer et croiser les données, à des fins d'investigation et de détection unitaires de cas de fraudes
- Interpréter les données collectées, structurer et partager les résultats
En complément de cette activité, vous interviendrez sur les missions suivantes :
- Participer aux analyses de performances et de pilotage de cette activité globale de gestion de la fraude
- Intervenir sur des projets transverses au sein de l'équipe et d'Harmonie Mutuelle (datalab, analyse d'impact...)
Le profil recherché :
Issu(e) d'une formation Bac +5 avec une spécialisation en Statistiques / Econométrie / Analyse de données, vous avez au moins 2 ans d'expérience en data science. Vous maitrisez les techniques de data mining, machine learning, modélisations supervisées ou non et le pragmatisme.
Vous êtes à l'aise sous SAS, SQL, et Python.
Vous savez et aimez développer. Vous avez une appétence et expérience sur les sujets d'investigation de fautes/fraudes à impact directs sur notre société.
Vous êtes curieux(se), rigoureux(se) et doté(e) d'un bon esprit d'analyse et de synthèse. Vous êtes force de proposition, autonome, dynamique, innovant, créatif.
Vous aimez le travail en équipe.
Une connaissance des métiers de la mutuelle serait un plus.
Infos complémentaires :
- 22, 5 jours de RTT par an
- Des horaires flexibles pour la majorité des postes
- Jusqu'à 3 jours de télétravail par semaine (à partir de 6 mois d'ancienneté)
- Carte déjeuner et CSE (enveloppes loisirs, culture, avantages vacances...)
- Compte Epargne Temps
- Forfait mobilité durable : jusqu'à 300 € par an (cumulable avec le remboursement de l'abonnement aux transports en commun, dans la limite de 500 Euros au total)
- Contrat collectif santé et prévoyance
- PEE et Retraite
- Prime d'intéressement
Show more
Show less","{'ProgLanguage': ['Python', 'R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': ['Statistiques'], 'CloudComputing': [], 'DevTools': ['Git'], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Machine Learning', 'Statistiques'], 'FrSoftSkills': [], 'EnSoftSkils': []}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's', '2', '2', '2']}"
Data Scientist,Withings,"Paris, Île-de-France, France",https://fr.linkedin.com/jobs/view/data-scientist-at-withings-3888804341?position=23&pageNum=0&refId=lBTWbVudNP%2F9XLZiNl1XvQ%3D%3D&trackingId=dp9PuUXSxc09XiXQbeijMg%3D%3D&trk=public_jobs_jserp-result_search-card,"Vos missions
L'équipe Machine Learning est responsable du développement de tous les algorithmes de prédiction des produits Withings. Intégré.e en son sein, tu auras les responsabilités suivantes:
Recherche algorithmique pour analyser les données pertinentes et les partager avec l’équipe
Réalisation de prototypes par la mise en pratique des méthodes retenues
Implémentation de services sur la plateforme / produits Withings, en tenant compte des contraintes de ressources et de temps d’exécution
Mise en avant de nouvelles fonctionnalités pour les applications et produits Withings
Maintien du lien avec les équipes de Recherche Appliquée et de Développement Produit pour comprendre et exploiter les données recueillies
REQUIREMENTS
Formation Bac+5 type grande école d’ingénieur ou équivalent
Un
doctorat
dans un domaine connexe est très apprécié
Une première expérience réussie dans le domaine du Machine Learning, de l'algorithmie appliqué aux données de santé ou à l'embarqué est fortement appréciée
Fortes compétences informatiques : calculs scientifiques, Python...
Rigueur, autonomie, prise d'initiatives, curiosité...
Connaissances en traitement de signal, C/C++ appréciées
Maîtrise parfaite de la communication en français et en anglais, aussi bien à l’écrit qu’à l’oral
Rejoindre l’aventure Withings, c’est :
Intégrer un des pionniers et leaders mondiaux de la santé connectée, plusieurs fois primé au Consumer Electronic Show
Contribuer à des projets innovants et ambitieux pour la santé de demain dans un environnement agile et en constante évolution
Intégrer une entreprise internationale, membre de la FrenchTech 120, dont les équipes sont basées à Issy-les-Moulineaux, Boston, Hong-Kong et Shenzhen
Participer à l’amélioration continue de nos produits et services en les bêta-testant avant leur sortie, notamment lors de nos nombreuses sessions sportives entre collègues
Bénéficier de nombreux avantages : Stock Options, smartphone et ordinateur de votre choix, réductions pour des activités culturelles et sportives, restaurant d’entreprise, et bien plus encore
Participer à la Withings Med Academy en assistant à des conférences de professionnels de santé afin de renforcer ses connaissances dans le domaine médical
Collaborer avec des collègues passionnés et célébrer ensemble chacune de nos réussites !
Toutes les candidatures reçues sont étudiées indépendamment de l’origine ethnique, des croyances, de la religion, du genre, de l’orientation sexuelle ou de la santé des candidats. Withings aspire à offrir et garantir l’égalité des chances aux candidats et seules les personnes habilitées (RH et Management) auront accès aux informations concernant votre candidature.
Show more
Show less","{'ProgLanguage': ['Python', 'C++', 'R', 'Go'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Machine Learning'], 'FrSoftSkills': ['Communication'], 'EnSoftSkils': ['Communication', 'Initiative']}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': ['Bac+5'], 'Experience': ['a', 'n', 's']}"
Data scientist H/F,Manpower,Greater Saint-Etienne Metropolitan Area,https://fr.linkedin.com/jobs/view/data-scientist-h-f-at-manpower-3909184596?position=24&pageNum=0&refId=lBTWbVudNP%2F9XLZiNl1XvQ%3D%3D&trackingId=5AeaLBTP1yQ4XOhNdnQT7Q%3D%3D&trk=public_jobs_jserp-result_search-card,"Vous le saviez ?
​Le métier de DATA SCIENTIST H/F a été élu le « métier le plus sexy du XXIe siècle », par le Harvard Business Review !
​
Rejoignez donc une équipe passionnée et dynamique au sein d'une entreprise incontestée des systèmes automatisés et d'énergie, qui repousse constamment les limites de la technologie et en pleine croissance !
Les missions
En tant que Data Scientist H/F, vous êtes sensibilisés aux risques éventuels et vous pouvez envisager de mettre en place des mesures adéquates pour sécuriser les données et les systèmes contre les menaces.
Vos missions seront donc :
Rassemblement, purification et manipulation d'ensembles de données massifs provenant de diverses sources telles que des bases de données internes et externes, des API et des données non structurées.
Conception et implémentation de modèles prédictifs et d'algorithmes d'apprentissage automatique pour résoudre des défis commerciaux complexes.
Réalisation d'analyses statistiques approfondies afin d'identifier des tendances, des schémas et des insights significatifs.
Collaboration étroite avec les équipes interfonctionnelles pour comprendre leurs besoins en données et proposer des solutions analytiques.
Création de tableaux de bord interactifs, de visualisations de données et de rapports pour une communication efficace des résultats d'analyse aux parties prenantes.
Veille constante sur les avancées technologiques en science des données et proposition d'améliorations continues pour les processus et méthodologies existants.
Le profil
Et si on parlait de vous...
​Vous disposez de qualifications dans les domaines des sciences des données, de l'informatique, des mathématiques, des statistiques, de l'économie, de l'informatique, de la gestion, de l'ingénierie industrielle ou dans des domaines connexes.
Vous avez une expérience pertinente dans ce domaine.
Vous êtes familier avec les concepts de collecte, d'extraction et d'analyse de données.
Vous possédez des compétences analytiques et êtes capable de travailler en équipe.
Vous êtes capable de présenter des informations complexes de manière claire et compréhensible.
Vous maitrisez les langages de programmation courants tels que Python, R ou SQL ainsi que l'anglais professionnel.
Vous possédez des compétences avancées en analyse statistique et en modélisation prédictive.
Vous êtes doté d'une expérience pratique avec les bibliothèques et les frameworks d'apprentissage automatique tels que TensorFlow, Scikit-Learn ou PyTorch.
Conditions & avantages :
CDI Temps plein
Déplacements à prévoir en France et à l'international (EMEA Germany, Italy, Spain, UK) selon besoin de l'activité
Salaire ouvert fonction de vos prétentions salariales, adaptable au profil !
Statut cadre forfait jour
RTT
Tickets restaurant
Participation et intéressement
Vous vous reconnaissez ?
N'hésitez plus, postulez !!
Show more
Show less","{'ProgLanguage': ['Python', 'R', ' R ', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R', ' R '], 'BigData': [], 'MachingLearning': ['Scikit-Learn', 'TensorFlow', 'PyTorch'], 'DataSerialization': [], 'DataVisualization': ['Tableau'], 'Statistics': ['Statistiques'], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Statistiques'], 'FrSoftSkills': ['Communication', 'Collaboration'], 'EnSoftSkils': ['Communication', 'Collaboration']}","{'JobDetail': ['Temps plein'], 'TypeContract': ['CDI'], 'Salary': ['Salaire'], 'Level': [], 'Experience': ['a', 'n', 's']}"
APPRENTI.E DATA SCIENTIST,Akademija Oxford,"Val-d'Oise, Île-de-France, France",https://fr.linkedin.com/jobs/view/apprenti-e-data-scientist-at-akademija-oxford-3917868440?position=25&pageNum=0&refId=lBTWbVudNP%2F9XLZiNl1XvQ%3D%3D&trackingId=YG9gn0Q9VYu6pl5AjuRvAw%3D%3D&trk=public_jobs_jserp-result_search-card,"Un acteur majeur et en pleine croissance de la Biologie Médicale en Ile de France, recrute un.e Apprenti.e Data Scientist en alternance. Ce contrat d’apprentissage d’une durée de 12 mois débute en Octobre 2021.
Show more
Show less","{'ProgLanguage': ['R'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': [], 'FrSoftSkills': [], 'EnSoftSkils': []}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's']}"
Data Scientist H/F,MERITIS,"Île-de-France, France",https://fr.linkedin.com/jobs/view/data-scientist-h-f-at-meritis-3869246366?position=26&pageNum=0&refId=lBTWbVudNP%2F9XLZiNl1XvQ%3D%3D&trackingId=ijKn%2B%2FsgXnTHu5UvG0C%2B6w%3D%3D&trk=public_jobs_jserp-result_search-card,"Nous recherchons un
Data Scientist
pour intervenir dans le cadre d'un
projet de détection de document.
Vos missions :
Sujet de
fraude documentaire:
la problématique est de détecter si un document (RIB ou pièce d’identité) a été manipulé (montage, remplacement de la photo d’identité, changement du nom/prénom, ou de l’IBAN etc).
Les technos connues utilisées:
Python avec les libs/framework suivants : pytorch, jupyterlab, pandas
Modèles : layoutLM (techno à priori assez récente), yolo, resnet (classique), docTR (ocr)
Connaitre les transformers
Autre : Labelstudio
Ce poste est-il fait pour vous
? :
Vous êtes diplômé d'un
Bac +5
et justifiez d'
au moins 4 ans d'expérience
Vous êtes
proactif et autonome ​
Vous aimez travailler
au contact de plusieurs équipes métiers
Connaissance du secteur de l'assurance obligatoire
Descriptif de l’entreprise :
​
Meritis est un cabinet de conseil, pilotage et développement IT fondé en 2007 présent à Paris, Sophia-Antipolis, Aix-en-Provence, Montpellier, Toulouse, Nantes... Et bientôt sur de nouveaux territoires ! Notre mission ? Connecter les meilleurs talents aux entreprises pour leur donner un temps d’avance.​
Nous accompagnons nos clients dans l’intégralité de leurs besoins en transformation numérique à travers de nombreux domaines d’expertises : Software Engineering, Finance, Pilotage de projets, Devops, Data, Cloud, Cybersécurité ou encore Agilité.​
Intervenant aussi bien dans les secteurs de la Banque, de l'Assurance, des Télécommunications que de l'Industrie ou des Transports, aujourd'hui 40% des entreprises du CAC40 sont clientes Meritis.​
Fort de nos valeurs d’exigence, d’humilité, de bienveillance et de proximité, nous comptons aujourd’hui plus de 900 collaborateurs.​
Nous mettons un point d’honneur à être proche de nos collaborateurs et à les accompagner de manière individualisée quelles que soient leurs fonctions dans l’entreprise.
Certifiée Great Place To Work depuis 2013, notre conception du bien-être au travail va bien au-delà d'un simple label, ce sont nos collaborateurs qui en parlent le mieux : https://www.glassdoor.fr/Avis/Meritis-Avis-E1163008.htm.​
Vos différences sont nos atouts. C’est pourquoi Meritis est engagée en faveur de la diversité et de la non-discrimination. Tous nos métiers sont accessibles aux personnes en situation de handicap. Si vous avez une question ou pensez être victime ou témoin d’une discrimination, vous pouvez contacter ethiquegroup@meritis.fr. »
Show more
Show less","{'ProgLanguage': ['Python', 'R'], 'DataBase': [], 'DataAnalytics': ['Pandas', 'R'], 'BigData': [], 'MachingLearning': ['PyTorch'], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['DevOps', 'Cloud'], 'FrSoftSkills': ['Communication'], 'EnSoftSkils': ['Communication']}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's', '4', '4', '4']}"
Data Scientist: Flexible working,SoftwareOne,"Levallois-Perret, Île-de-France, France",https://fr.linkedin.com/jobs/view/data-scientist-flexible-working-at-softwareone-3872563771?position=27&pageNum=0&refId=lBTWbVudNP%2F9XLZiNl1XvQ%3D%3D&trackingId=pvL%2B7xvHcWWDqkUho0nRGw%3D%3D&trk=public_jobs_jserp-result_search-card,"Why SoftwareOne?
SoftwareOne is a leading global software and cloud solutions provider that is redefining how companies build, buy and manage everything in the cloud. By helping clients to migrate and modernize their workloads and applications – and in parallel, to navigate and optimize the resulting software and cloud changes – SoftwareOne unlocks the value of technology. The company’s 8,900 employees are driven to deliver a portfolio of 7,500 software brands with sales and delivery capabilities in 90 countries. Headquartered in Switzerland, SoftwareOne is listed on the SIX Swiss Exchange under the ticker symbol SWON. Visit us at https://www.softwareone.com/en
The role
DATA Scientist
The primary focus for a candidate will be in applying different techniques (data mining/statistical analysis/build prediction systems/recommendation systems) using large company data sets to find opportunities for services and products and using models to test the effectiveness of different courses of action. The Candidate must have strong experience using a variety of data mining/data analysis methods, using a variety of data tools, building and implementing models, using/creating algorithms and creating/running simulations.
Work with business cases to identify opportunities for leveraging company data to drive business solutions.
Mine and analyze data from company databases to drive optimization and improvement of product development and sales techniques
Assess the effectiveness and accuracy of new data sources and data gathering
Extending company’s data with third party sources of information when needed
Use predictive modeling to increase revenue generation, ad targeting and other business outcomes.
What We Need To See From You
Core:
Analyze business cases and identify data sources (internal/external) and data mining/analysis methods to use
Develop a normalization engine to execute cleansing/deduplication for a raw data through ETL process for data sources
Create, train and test predictive models to solve defined business cases
Develop algorithms to apply to data sets
Design data structure models for collected data
Facilitate the build of a solution from PoC to production
Work with business owners to gather additional information about business cases
Job Specific:
Work with Google Cloud data and AI tools
Be ready to work in agile style (daily, sprint planning, sprint review, retrospective)
Work in an environment that adapts quickly to creative change using agile principles
Actively work with different development groups inside of organization
Be ready to adapt a new tool/library/technology/platform
Desirable Skills:
Fluent in French and English
At least 4 years experience in Machine learning models creation
Master’s in Statistics, Mathematics, Computer Science preferred
Professional Machine learning engineering certification
Experience with common data science toolkits and libraries, such as pandas, keras, scipy, scikit, tensorflow, NumPy etc
Knowledge and interest in the following:
prediction models, Vertex AI, Tenserflow, BigQuery ML, Python,
natural language processing, deep learning models, dataPROC, Hadoop, SQL
Experience using statistical computer languages namely Python to manipulate data and draw insights from large data sets
Strong knowledge and experience using SQL language
Experience with C++/C# and Java as a plus
Background in technology or professional services preferably in one or more of the domains of GCP and Security,
Strong understanding of consulting business
Strong structural work methods, multitasking and time management skills
Self-driven independent work ethics that drives internal and external accountability
May require periodic travel for workshops
Job Function
Software & Cloud Services
Show more
Show less","{'ProgLanguage': ['Python', 'Java', 'C++', 'C#', 'R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['Pandas', 'NumPy', 'R'], 'BigData': ['Hadoop'], 'MachingLearning': ['TensorFlow', 'Keras'], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': ['Statistics'], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'DBMS': ['BigQuery'], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['ML', 'Machine Learning', 'Cloud'], 'FrSoftSkills': [], 'EnSoftSkils': ['Time Management', 'Organization']}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's']}"
Data Scientist,Capital Fund Management (CFM),"Paris, Île-de-France, France",https://fr.linkedin.com/jobs/view/data-scientist-at-capital-fund-management-cfm-3911800992?position=28&pageNum=0&refId=lBTWbVudNP%2F9XLZiNl1XvQ%3D%3D&trackingId=Dp78j3t7ezqy29KEcVotSQ%3D%3D&trk=public_jobs_jserp-result_search-card,"ABOUT CFM
Founded in 1991, we are a global quantitative and systematic asset management firm applying a scientific approach to finance to develop alternative investment strategies that create value for our clients.
We value innovation, dedication, collaboration and the ability to make an impact and together we create an environment for talented and passionate experts in research, technology and business to explore new ideas and challenge assumptions.
ABOUT THE ROLE
The context :
Data is the fuel that powers our investment strategies: intraday price dynamics are used to better our investment decisions; buy/sell intents of market participants help to trade at the best available price… Cfm Data team is in charge of preparing the data to make quant research easier and trading more reliable.
The position
As a Data Scientist and Tick Data Specialist, your involvement will be crucial to the effectiveness of our strategies. You will be tasked with identifying and specifying new input features from tick data to fuel our alpha predictor, constructing data pipelines, and guaranteeing their smooth functioning. This role necessitates strong collaboration with researchers, primarily aimed at furnishing them with essential data and tools to refine our trading strategies.
Key Responsibilities:
You collaborate with the research team to innovate and introduce new predictive features,
You provide functional and technical support to quantitative researchers,
You design and develop data pipelines,
You contribute to the enhancement of our platform tooling.
SKILLSET REQUIREMENTS/QUALIFICATIONS
You boast significant experience in financial markets, with a tenure of 7 years or more.
You have a comprehensive expertise in Matching Engines, Orderbooks, and High-Frequency Data,
You demonstrate recognized expertise in data science with a thorough mastery of its tools.
Your familiarity with big data technologies like Spark or Dask, coupled with proficiency in machine learning, would be highly advantageous.
Experience with C++ is considered an additional asset.
You exhibit a strong enthusiasm for technology.
As a collaborative team player, you excel in communication, particularly with quant teams.
Proficiency in French is an additional advantage.
EQUAL OPPORTUNITIES STATEMENT
We are continuously striving to be an equal opportunity employer and we prohibit any discrimination based on sex, disability, origin, sexual orientation, gender identity, age, race, or religion. We believe that our diversity, breadth of experience, and multiple points of view are among the leading factors in our success.
CFM is a signatory of the Women Empowerment Principles
FOLLOW US
Follow us on Twitter and LinkedIn or visit our website to find out more about CFM.
Show more
Show less","{'ProgLanguage': ['C++', 'R'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': ['Spark'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': ['Teams'], 'Other': ['Big Data', 'Machine Learning'], 'FrSoftSkills': ['Communication', 'Collaboration'], 'EnSoftSkils': ['Communication', 'Collaboration']}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's']}"
Data Scientist,Keley Consulting,Greater Paris Metropolitan Region,https://fr.linkedin.com/jobs/view/data-scientist-at-keley-consulting-3908861590?position=29&pageNum=0&refId=lBTWbVudNP%2F9XLZiNl1XvQ%3D%3D&trackingId=ZOnz0d7f3eK%2BWWZ8tWxkHg%3D%3D&trk=public_jobs_jserp-result_search-card,"Data Scientist F/H
Description de l'offre d'emploi
Au sein de la practice data, vous accompagnerez nos clients dans la gestion, l’analyse et l’exploitation de leur données notamment grâce au développement de modèles IA et la mise en production de ceux-ci.
Responsabilités
Vous interviendrez dans des secteurs variés sur des problématiques telles que :
Evaluer les solutions technologiques liées à la data en effectuant des benchmarks
Collecter, traiter et analyser des données volumineuses
Communiquer efficacement les résultats des analyses
Créer de la valeur à partir des données en utilisant l’intelligence artificielle et la Data Science
Travailler en étroite collaboration avec les métiers afin de comprendre leurs besoins et les impliquer dans le développement des outils IA
Déployer les outils développés en environnement de prod (MLOps)
A titre d’exemple, nous avons récemment mené les missions suivantes :
Développement d’outils d’optimisation des revenus pour le compte d’une compagnie aérienne
Etude de l’impact du traitement de plaintes sur la customer lifetime value
Industrialisation de proof-of-concepts (ML Ops)
Développement de GPTMaker, un outil de création de chatbot s’appuyant sur des LLM
Profil recherché
Diplôme Bac+5 type école d’ingénieur ou université en Data Science / Statistiques
Expérience de 2 à 5 ans en Data, avec au moins 1 an en tant que Data Scientist / Engineer
Maîtrise des méthodes statistiques et leurs applications opérationnelles, ainsi que Python/Spark
Forte capacité d’organisation, d’analyse, d’écoute et de communication tout en étant force de conviction
Anglais courant
Qualifications supplémentaires (atouts) :
Expérience avec les outils du cloud (GCP, Azure, AWS …)
Expérience dans le NLP (natural language processing)
Pourquoi rejoindre Keley ?
Keley est un cabinet de conseil à taille humaine.
Accélérateur de projet, nous accompagnons nos clients sur des programmes de transformation digitale & Data en apportant sens et performance. Autour de méthodologies produits issues du design et orientées résultat, nous cocréons avec nos clients en les accompagnant dans toutes les étapes de leurs projets, jusqu’à l’autonomie.
Parce que les Humains sont au cœur de la transformation digitale des entreprises, celle-ci est aussi culturelle : nous alignons stratégie produit, culture métiers et modèles opérationnels pour concevoir avec nos clients des solutions qui leur ressemblent et qui font le succès de leurs projets.
Nos valeurs
Passionnés par notre métier, nous sommes des consultants en transformation digitale avec un sens aigu de l’engagement et du partage.
Dans un esprit coopératif et chaleureux, chaque collaborateur pourra trouver sa place, évoluer au cœur de nos métiers et atteindre ses objectifs grâce à des parcours de carrière évolutifs, clairs et transparents.
Nous croyons en la valeur de la diversité et de l'inclusion et encourageons les candidats de tous horizons à postuler.
Keley vous propose une carrière passionnante dans un environnement stimulant, en vous permettant de travailler avec des grands comptes et sur des missions variées.
Pour vous offrir le meilleur environnement de travail possible, nous vous proposons :
Un parcours de carrière clair et partagé pour évoluer rapidement au sein du cabinet
Une politique de rémunération transparente et équitable
Une charte de télétravail
Des bureaux au cœur de Paris dans le 8ème arrondissement
Des mentors et des buddys à l’écoute
Des évènements de team building réguliers
Une direction et un management toujours disponibles pour échanger (organisation flat)
Un programme de formation adapté à vos besoins et incluant des formations externes certifiantes
Des méthodes et outils de partage de connaissance pour vous nourrir mais aussi vous offrir une tribune : conférences internes hebdomadaires, articles, livres blancs, enquêtes et contenus vidéo
Un MacBook car on aime les belles choses (surtout quand elles marchent bien)
Une carte tickets restaurants
Une prise en charge de la mutuelle à 100%
Une prime de vacances
Show more
Show less","{'ProgLanguage': ['Python', 'R'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': ['Spark'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': ['Statistiques'], 'CloudComputing': ['AWS', 'Azure'], 'DevTools': ['Git'], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['ML', 'Statistiques', 'Cloud'], 'FrSoftSkills': ['Communication', 'Collaboration', 'Organisation'], 'EnSoftSkils': ['Communication', 'Collaboration']}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': ['Bac+5'], 'Experience': ['a', 'n', 's', '5', '5', '5']}"
Machine Learning Engineer,HackerPulse,France,https://fr.linkedin.com/jobs/view/machine-learning-engineer-at-hackerpulse-3917868826?position=30&pageNum=0&refId=lBTWbVudNP%2F9XLZiNl1XvQ%3D%3D&trackingId=SWwDdJr%2FukaTp1x9bHeHpg%3D%3D&trk=public_jobs_jserp-result_search-card,"Showcase your software engineering talents using ML-powered profiles. Loved by 11k+ engineers! Backed by Antler.
The Role
You Will Be Responsible For
Developing scripts to process structured and unstructured data.
Recommending, developing and implementing ways to improve data reliability, efficiency and quality.
Supporting translation of data business needs into technical system requirements.
Working with stakeholders to understand needs in order with respect to data structure, availability, scalability and accessibility.
Developing high-quality code to build and deploy machine learning models.
Ideal Profile
You possess a degree in Computer Science, Applied Mathematics, Engineering or related field.
You have at least 1 year experience, ideally within a Data Engineer role.
Demonstrated experience working with large and complex data sets as well as experience analyzing volumes of data.
You are a strong networker & relationship builder
You pay strong attention to detail and deliver work that is of a high standard
You are a self-starter and demonstrate a high level of resilience
What's on Offer?
Great work environment
Excellent career development opportunities
Leadership Role
Show more
Show less","{'ProgLanguage': ['Scala', 'R'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['ML', 'Machine Learning'], 'FrSoftSkills': ['Leadership'], 'EnSoftSkils': ['Leadership']}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's']}"
Data scientist H/F,MP DATA,"Clermont-Ferrand, Auvergne-Rhône-Alpes, France",https://fr.linkedin.com/jobs/view/data-scientist-h-f-at-mp-data-3904074177?position=31&pageNum=0&refId=lBTWbVudNP%2F9XLZiNl1XvQ%3D%3D&trackingId=h%2Bv0FSIpEDs8SO5%2FNs6dRw%3D%3D&trk=public_jobs_jserp-result_search-card,"MP DATA est une société spécialisée dans l’acquisition, le traitement, et la valorisation des données. Depuis sa création en 2015, MP DATA accompagne ses clients, majoritairement industriels, dans le management de leur performance et l’exploitation de leur donnée.
Les collaborateurs, tous issus de grandes écoles, incarnent au quotidien les valeurs d’Excellence, de Partage et d’Engagement. Ils associent savoir-faire technique, méthodologie et passion et mettent leurs compétences au service de missions et projets au sein de grands groupes français.
MP DATA accompagne ses clients sur toute la chaine au travers de 3 pôles d’expertise : Conseil et Stratégie, Infrastructure & CloudOPS, Data Science.
Nous recherchons un(e) Data Scientist passionné(e) pour rejoindre notre équipe dynamique.
En tant que membre clé du pôle Data Science de notre client, un grand acteur du secteur automobile, vous serez chargé(e) d'analyser, interpréter et exploiter les données pour fournir des solutions innovantes à nos clients.
Conception et mise en œuvre de modèles prédictifs et d'algorithmes avancés.
Analyse approfondie des données pour identifier des tendances et des opportunités.
Collaboration étroite avec les équipes clients pour comprendre leurs besoins et définir des solutions sur mesure.
Participation active à la veille technologique et à l'amélioration continue de nos pratiques en Data Science.
Profil :
Diplôme
ingénieur Grande École
en Data Science, Statistiques, Informatique ou domaine connexe.
Expérience pratique dans le développement et l'application de modèles prédictifs,
Maîtrise des langages de programmation tels que Python,
Excellentes compétences analytiques et capacité à traduire des résultats complexes en recommandations claires,
Forte aptitude à travailler en équipe et à communiquer efficacement.
Show more
Show less","{'ProgLanguage': ['Python', 'R', 'Go'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': ['Statistiques'], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Statistiques', 'Cloud'], 'FrSoftSkills': ['Collaboration'], 'EnSoftSkils': ['Collaboration']}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's']}"
Data Scientist (H/F),moOngy Digital Lab,Greater Lille Metropolitan Area,https://fr.linkedin.com/jobs/view/data-scientist-h-f-at-moongy-digital-lab-3888669115?position=32&pageNum=0&refId=lBTWbVudNP%2F9XLZiNl1XvQ%3D%3D&trackingId=R16R4KV2y%2FH5B6FiMul68A%3D%3D&trk=public_jobs_jserp-result_search-card,"Web Transition, c’est qui ?
Fondée en 2011,
Web transition
est une entreprise de services numériques opérant sur le marché de l’IT/Digital !
Constituant une part essentielle de
MoOngy Digital Lab
, Web Transition accompagne ses clients grands comptes sur leurs projets de Webmarketing, de Design, Gestion de projet et également en Data !
Notre objectif : nous implanter comme un acteur principal sur le marché de la Transformation Digitale en accompagnant et valorisant les compétences de nos collaborateurs !
Nous sommes convaincus que le succès de MoOngy Digital Lab réside dans la somme des potentiels de nos équipes 🤝
Ton équipe : La tribu Data
Parce qu’il est indispensable que tu puisses partager tes connaissances mais aussi en acquérir de nouvelles, tu feras partie de l’une de nos tribus : celle de la Data. De plus, cela te permettra d’être acteur dans le développement et la stratégie de Web Transition. Ce système de co-réflexion et co-construction est un fondement essentiel chez nous !
Dans cette aventure, tu :
Recueilles, analyses et formalises
les demandes correspondant aux besoins spécifiques de chaque métier/utilisateur,
Contrôles, sélectionnes et valides
les données pertinentes pour l'analyse & s'assurer de la cohérence et de la structuration de celles-ci avant exploitation,
Conçois, mets en œuvre et déploies
des modèles Machine Learning (ML) et Deep Learning (DL) dans un environnement GCP (BigQuery ML/Vertex AI) : qualité, possibilités d'exploitation, suivi de performances et versioning des mis à jour du modèle en production,
Présentes
les résultats des études réalisées auprès de vos différents interlocuteurs et leur donner du sens, en s’appuyant sur des KPIs adaptés, via les outils de visualisation des données et/ou de documentation,
Améliores
l'efficacité de livraison des modèles ML/DL en industrialisant le processus de livraison et en automatisant la préparation des données, l’entraînement des modèles et leur déploiement,
Effectues
une veille technologique et maintenir une connaissance approfondie des dernières technologies liées au ML/IA.
Rejoins-nous si tu as :
Une expérience de 5 ans au minimum dans l'analyse de données/data science, et plus globalement dans le développement des modèles ML et DL & de préférence sur l'écosystème GCP,
Une maîtrise du langage Python et des librairies d’analyse (Pandas, NumPy et Matplotlib) et ML/DL (Scikit-Learn, TensorFlow, PyTorch, XGBoost),
Une connaissance de l’environnement Retail serait un plus !
Ton savoir-être :
Ouvert d’esprit
Respectueux des différences de chacun
Curieux
Proactif
Par où on commence ?
Un premier entretien RH d’1h pour comprendre ton parcours et tes aspirations
Un second entretien de 45 minutes avec l’un de nos Business Manager afin de valider tes compétences et qu’il se projette sur l’une des missions qu’il pourrait te proposer
Un troisième entretien de quelques minutes avec notre responsable d’agence pour te proposer d’intégrer notre superbe Team Web !
3 entretiens en peu de temps, si ton profil correspond tu intègreras très vite nos équipes 😉
Prêt pour embarquer dans notre grande aventure humaine ? Deviens notre futur Weber en postulant à cette offre ! Voici les avantages qui t’attendent en tant que Weber :
🤩 Des collègues incroyables
🏆 Certifiée Great Place to Work
🎮 Des bureaux sympas (où vous serez toujours les bienvenus)
🎉 Des teambuilding et évents tous les mois
💻 Des tributs métiers pour échanger entre Weber du même métier
Des missions chez le client qui sont accompagnées et coachées par ton manager
Un accompagnement dans ton plan de carrière et tes envies de re skilling
🤓 Un catalogue de formations certifiantes ouvert à tous les salariés
🍽️ Une carte tickets restaurant MyEdenred
❤️ Une mutuelle GrasSavoye
🚎 Une prise en charge des frais de transport à 100%
Show more
Show less","{'ProgLanguage': ['Python', 'R'], 'DataBase': [], 'DataAnalytics': ['Pandas', 'NumPy', 'R'], 'BigData': [], 'MachingLearning': ['Scikit-Learn', 'TensorFlow', 'PyTorch', 'XGBoost'], 'DataSerialization': [], 'DataVisualization': ['Matplotlib'], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git'], 'Os': [], 'DBMS': ['BigQuery'], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['ML', 'Machine Learning'], 'FrSoftSkills': [], 'EnSoftSkils': []}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's', '5', '5', '5']}"
Data Scientist F/H,OUTSCALE,"St.-Cloud, Île-de-France, France",https://fr.linkedin.com/jobs/view/data-scientist-f-h-at-outscale-3891855564?position=33&pageNum=0&refId=lBTWbVudNP%2F9XLZiNl1XvQ%3D%3D&trackingId=fDpwk307qc8MgP%2F7O%2B6LRA%3D%3D&trk=public_jobs_jserp-result_search-card,"OUTSCALE, marque de Dassault Systèmes, est un opérateur souverain et durable de l Expérience en tant que Service qui offre à ses clients des environnements technologiques de confiance.
Nous offrons des expériences uniques grâce au savoir-faire de nos équipes passionnées, qui se reflète notamment par la création de solutions de Business Expériences, le développement de notre propre orchestrateur Cloud, TINA OS, ou encore l obtention de la qualification SecNumCloud.
Notre mission ? Bâtir un monde numérique accessible et meilleur pour tous à travers la création du jumeau virtuel de l organisation.
Nous menons une politique RH engagée et inclusive favorisant le bien-être de nos collaborateur·rices : respect de l équilibre vie privée/vie professionnelle, développement personnel et des compétences professionnelles, onboarding complet
Nous rejoindre, c est partager une passion pour l innovation, des valeurs communes et imaginer ensemble des solutions de confiance pour construire un monde meilleur et durable !
Nous recrutons
un·e
Data Scientist
afin de renforcer notre équipe
Business Experience
.
Vos missions
Analyser des problématiques et proposer des solutions.
Modéliser, implémenter et évaluer des algorithmes.
Traiter des données non structurées.
Optimiser des modèles ML/DL pour la scalabilité, l'efficacité et les performances.
Industrialiser des algorithmes dans les services API.
Déployer des services sur le cloud.
Participer à la rédaction de spécifications et documentations techniques.
Participer à des événements et publications scientifiques.
Stack technique
Python
Frameworks ML/DL (Pytorch)
Architectures de réseaux neuronaux (LLMs)
Implémentation d’algorithmes ML/DL (apprentissage supervisé/non-supervisé)
Votre profil:
Diplômé·e d’un Master en Intelligence Artificielle, Machine Learning.
3 ans d’expérience minimum post-diplôme dans le domaine de l’IA, Data Science, Machine Learning, NLP, Computer Vision.
Vous maîtrisez l’analyse et la transformation des données.
Idéalement, vous avez de l’expérience dans le déploiement des modèles ML/DL sur le cloud.
Motivé·e, organisé·e, curieux·se, vous appréciez travailler en équipe.
La Diversité d’OUTSCALE trouve aussi son expression dans notre politique de recrutement qui privilégie l’égalité des chances, la diversité des individus au sein de nos équipes.
Show more
Show less","{'ProgLanguage': ['Python', 'Scala', 'R', 'Go'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': ['PyTorch'], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['ML', 'Machine Learning', 'Cloud'], 'FrSoftSkills': ['Organisation'], 'EnSoftSkils': []}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's', '3', '3', '3']}"
DATA SCIENTIST (CDI),STATION F,"Annecy, Auvergne-Rhône-Alpes, France",https://fr.linkedin.com/jobs/view/data-scientist-cdi-at-station-f-3918628446?position=34&pageNum=0&refId=lBTWbVudNP%2F9XLZiNl1XvQ%3D%3D&trackingId=Y3VE8RaVXIHeUbC2otXKcg%3D%3D&trk=public_jobs_jserp-result_search-card,"À propos
Campsider est la 1ère marketplace dédiée aux équipements de sport d’occasion, sélectionnés et garantis (vélo, ski, randonnée, trail-running, escalade, alpinisme).
Lancé début 2021 par deux passionnés de sport (ex HEC et emlyon), la plateforme recense plus de 150 000 utilisateurs et 200 000 articles en vente en moins de 3 ans. Soutenu par des athlètes professionnels de renom (Mathieu Blanchard, Camille Bruyas ou encore Victor Galuchot), la start-up est aussi devenue le partenaire privilégié des marques de sport (Millet, Osprey, Mavic, ZAG Ski) pour valoriser leur seconde main.
Leur mission : rendre accessible l’aventure et protéger nos terrains de jeu grâce à une consommation plus responsable.
Avec l’objectif de s’imposer comme la plateforme de référence des sportifs engagés qui souhaitent s’équiper moins cher et plus durable, la plateforme a levé plus de 5m€ auprès d’investisseurs réputés dont le fonds Founders Future (Marc Menasé) et des investisseurs privés (fondateur Vestiaire Collective, fondateur Selency, C-level Salomon, etc) et a été sélectionnée au Future40 de Station F.
Descriptif du poste
En tant que
Data Scientist
, rattaché aux fondateurs, tu seras la pierre angulaire du sujet catalogue / PIM au sein de Campsider pour définir la stratégie data et l'enrichissement des produits présents sur le site.
Concrètement, quelles seront tes missions ?
1/
Optimiser les connexions marchands
Gestion et optimisation des process de mise en ligne et de mise à jour des catalogues partenaires sur la plateforme ;
Uniformisation et standardisation de la donnée partenaire ;
2/
Enrichissement de la data produit
Garant de la qualité permanente du contenu produit et de l’enrichissement des données catalogues ;
Optimisation des process de catégorisation, taxonomie, mapping, remplissage d’attribut et de mise en forme du contenu partenaire pour valoriser les produits. KPI clé : taux de remplissage attribut et taux de conversion ;
Définition et mise en place d’une stratégie d’enrichissement automatiques des attributs techniques des produits mis en ligne sur la plateforme. KPI clé : taux de remplissage attribut et taux de conversion ;
3/
Manager
Gestion de l’équipe Catalog Enricher (2 personnes).
Profil recherché
Tu as de bonnes connaissances dans la transformation des données (ETL), la conception de modèles de données et les stratégies d'optimisation des requêtes
Tu as des compétences en DevOps pour le déploiement et la gestion efficace des pipelines de données
Tu as une bonne maîtrise de Python, SQL & Github
Tu maîtrises l’un des data warehouse suivants : BigQuery, Refshift, Snowflake, Synapse Analytics
Tu es passionné(e) de sport !
Process de recrutement
Un 1er entretien court (20 minutes) par téléphone ou visio
Un 2ème entretien physique avec les fondateurs (1h)
Un café avec l'équipe !
Informations complémentaires
Type de contrat : CDI
Lieu : Annecy, Paris
Télétravail ponctuel autorisé
Show more
Show less","{'ProgLanguage': ['Python', 'Scala', 'R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git'], 'Os': [], 'DBMS': ['Snowflake', 'Snowflake', 'BigQuery'], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['DevOps', 'ML'], 'FrSoftSkills': [], 'EnSoftSkils': []}","{'JobDetail': [], 'TypeContract': ['CDI'], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's', '3', '3', '3']}"
Data Scientist H/F,IT&M STATS,"Île-de-France, France",https://fr.linkedin.com/jobs/view/data-scientist-h-f-at-it-m-stats-3803674187?position=35&pageNum=0&refId=lBTWbVudNP%2F9XLZiNl1XvQ%3D%3D&trackingId=7etdSoERHQJwXooZzDvMmw%3D%3D&trk=public_jobs_jserp-result_search-card,"IT&M Stats intervient dans le domaine des statistiques, de la programmation et de la data science, principalement dans les secteurs de l’Industrie Pharmaceutique, Cosmétique, dans la Santé et l’Agro-alimentaire et auprès des Banques et Assurances. IT&M Stats est une filiale du Groupe Astek, acteur mondial de l’ingénierie et du conseil en technologies.
Nous basons notre relation sur :
Un respect des collaborateurs et des clients, de leurs aspirations,
Un suivi personnalisé des collaborateurs et des clients,
Une gestion régulière des carrières des collaborateurs,
Des échanges transparents,
Une réactivité, une disponibilité et une écoute permanentes.
Nous recherchons un
Data Scientist
pour intervenir dans le secteur
cosmétique
.
Cela vous intéresse ? Voici la suite !
👇
Maintenance et mise à jour de dashboards de suivi de tests sous PowerBi
Analyser les données générées en interne et externe et réaliser des analyses croisées /meta analyse pour une meilleure compréhension de la performance de nos produits/services
Réaliser des analyses prédictives de la performance cosmétique en fonction de la formulation
Réaliser des interfaces dynamiques sous R Shiny
Ré-analyser et vérifier les analyses statistiques réalisées par les prestataires externes le cas échéant
Contribuer à la mise en place des études et aider le département à l’amélioration des process (Plan d’expérience, calcul du nombre de sujets nécessaires, etc…)
Vous pensez être la perle rare ?
Vous êtes titulaire d’un diplôme de type Bac+5 (Master 2 ou école d’ingénieur) avec une spécialisation en statistiques, mathématiques ou data science
Vous justifiez d’une expérience professionnelle de 2 à 3 ans
Une bonne maitrise de R (dont R Shiny) est attendue
Vous maitrisez PowerBI
Vous êtes organisé, rigoureux, autonome, flexible, vous aimez communiquer et travailler en équipe et vous avez un bon esprit de synthèse et d’analyse
Vous avez un bon niveau d’anglais
🍀
Voici ce que nous pouvons vous offrir…
Un poste en CDI à pourvoir dès que possible, de la bonne humeur, des formations, des soirées, de la bienveillance, un suivi personnalisé, une gestion régulière de votre carrière, des échanges transparents et une écoute permanente.
Si vous êtes convaincu que vous êtes la perle rare, postulez ! Nous sommes impatients de vous rencontrer.
Show more
Show less","{'ProgLanguage': ['R', ' R ', 'Go'], 'DataBase': [], 'DataAnalytics': ['R', ' R '], 'BigData': [], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': ['PowerBI'], 'Statistics': ['Statistiques'], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Statistiques'], 'FrSoftSkills': [], 'EnSoftSkils': []}","{'JobDetail': [], 'TypeContract': ['CDI'], 'Salary': [], 'Level': ['Bac+5'], 'Experience': ['a', 'n', 's', '3', '3', '3']}"
"Data Scientist - Python (Mid-senior, Senior)",Pathway,"Paris, Île-de-France, France",https://fr.linkedin.com/jobs/view/data-scientist-python-mid-senior-senior-at-pathway-3887683294?position=36&pageNum=0&refId=lBTWbVudNP%2F9XLZiNl1XvQ%3D%3D&trackingId=x%2B0AXnfagJwo9TZnYdLmoA%3D%3D&trk=public_jobs_jserp-result_search-card,"About Pathway
Deeptech start-up, founded in March 2020.
Our primary developer offering is an ultra-performant Data Processing Framework (unified streaming + batch) with a Python API, distributed Rust engine, and capabilities for data source integration & transformation at scale (Kafka, S3, databases/CDC,...)
The single-machine version is provided on a free-to-use license (`pip install pathway`)
Major data use cases are around event-stream data (including real-world data such as IoT), and graph data that changes over time
Our enterprise offering is currently used by leaders of the logistics industry, such as DB Schenker or La Poste, and tested across multiple industries. Pathway has been featured in Gartner's market guide for Event Stream Processing
Learn more at http://pathway.com/ and https://github.com/pathwaycom/
Pathway is VC-funded, with amazing BAs from the AI space and industry. We have operations across Europe and in the US. We are headquartered in Paris, with significant support from the French ecosystem (BPI, Agoranov, WILCO,...).
The Team
Pathway is built by and for overachievers. Its co-founders and employees have worked in the best AI labs in the world (Microsoft Research, Google Brain, ETH Zurich), worked at Google, and graduated from top universities (Polytechnique, ENSAE, Sciences Po, HEC Paris, PhD obtained at the age of 20, etc...). Pathway's CTO is a co-author with Goeff Hinton and Yoshua Bengio. The management team also includes the co-founder of Spoj.com (1M+ developer users) and NK.pl (13.5M+ users) and experienced growth leader who has scaled companies with multiple exits.
The opportunity
We are currently searching for
Data Scientists
with
experience in the Python stack
, to help explore and discover the most pertinent insights in datasets on spatio-temporal event streams. In this job, statistical rigor and beauty of visualization meet on equal footing.
You Will
be working with spatiotemporal data with advanced schemas (time-changing graph models)/
be designing data cross-sections, proposing analytics metrics and KPI's in line with clients' objectives, selecting clustering algorithms, and preparing visualizations, to enable fast data exploration and insight discovery - all within our product
be designing dashboards in SQL with some Python elements/extensions
be directly helping us with Customer Conversion and Adoption within Customer organizations, by contributing to both deployment instances and ""demonstrators"" of our product, performed on client data sets
work directly with our Product Owner and CTO to propose and implement extensions to our product, based on repetitive client needs
depending on your seniority, implement machine learning algorithms on spatiotemporal event streams and other geospatial data
The results of your work will play a crucial role in proving how our technology can help with compelling industry use cases.
Requirements
You Are
Ready for hands-on contribution to the product, helping to ensure the success of demonstrators for clients, and contribution to product codebase
Intuitive, with good visual taste, and good common sense judgment
Committed to beautiful user-centered design: you know that stories are made for people, and you are willing to listen to what they have to say
Curious at heart and thrilled to work with real-world data, especially spatio-temporal data
Like trains, trucks, cranes, pythons, pandas, and other things that move
Not afraid to switch between the roles of data scientist, data-vis magician, statistician, engineer, and detective, at a moment's notice
Have 2 years+ experience in positions related to Data Science.
Have a very good working knowledge of Python
Know SQL. Are able to work with tables and other data types (arrays, json,...)
Would be able to implement the Transit Node Routing algorithm in Python just based on reading its Wikipedia article
Have experience with git, build systems, and CI/CD
Have at least basic undergrad textbook familiarity with graph algorithms, finite automata, and text (string) search algorithms
Understand statistical concepts, such as correlated random variables, significance, and non-Gaussian noise
Prepared to be quizzed & grilled by the datasets you encounter, everyday. Here are some questions you should be able to answer off the top of your head: what can ""-273.15"" signify; why ""65535"" is a suspicious integer value; how many months does it take a containership to go around the world; and, roughly what order of g-force is attained by an astronaut in a space rocket at liftoff?
Respectful of others
Fluent in English
Bonus Points
Showing a portfolio: code on github, visualization works, a research paper or a PhD thesis with an original statistical / probabilistic analysis or experiment design,..
Successful track-record in Data Science or algorithms contests (Kaggle, Codeforces,...)
Experience in topics linked to logistics/moving assets
Familiarity with some form of GIS software
Familiarity with Pandas, SciPy, NetworkX, and similar tools from the Python stack
Experience in Data Visualization and UX
Some knowledge of French, Polish, or German
Why You Should Apply
Join an intellectually stimulating work environment
Be a pioneer: you get to work with a new type of data processing
Work in one of the hottest data/AI startups in France
Uncover exciting career prospects
Make significant contribution to our success
Join & co-create an inclusive workplace culture
Benefits
Type of contract: Permanent employment contract
Preferable joining date: February 2023. The positions (at least 2) are open until filled
Compensation: annual salary of €50K-€70K (mid) up to €60K-€90K (senior, upper band negotiable) + Employee stock option plan
Location: Remote work from home. Possibility to work or meet with other team members in one of our offices:
Paris Area - Drahi X-Novation Center, Ecole Polytechnique, Palaiseau
Paris - Agoranov (where Doctolib, Alan, and Criteo were born) near Saint-Placide Metro (75006)
Wroclaw - University area
Permanent residence will be required in France or Poland, exceptional candidates will be considered anywhere in the EU.
If you meet our broad requirements but are missing some experience, don't hesitate to reach out to us.
Note
: CS & engineering school students with exceptional profiles and/or strong motivation to join Pathway are invited to apply for Data Science internships. (Minimum duration: 5-6 months, remuneration level: €1500 / month.)
Show more
Show less","{'ProgLanguage': ['Python', 'R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['Pandas', 'R'], 'BigData': [], 'MachingLearning': [], 'DataSerialization': ['Json'], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git'], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Machine Learning', 'CI/CD'], 'FrSoftSkills': [], 'EnSoftSkils': ['Organization']}","{'JobDetail': ['Remote', 'Senior'], 'TypeContract': [], 'Salary': ['50K'], 'Level': [], 'Experience': ['a', 'n', 's']}"
Data scientist (H/F),METEO FRANCE,"Toulouse, Occitanie, France",https://fr.linkedin.com/jobs/view/data-scientist-h-f-at-meteo-france-3914118639?position=37&pageNum=0&refId=lBTWbVudNP%2F9XLZiNl1XvQ%3D%3D&trackingId=vxHBOG9T3NcFXtS1fEMmsA%3D%3D&trk=public_jobs_jserp-result_search-card,"Cette offre d’emploi est fournie par Pôle emploi
Description
L'offre d'apprentissage concerne un travail autour de la thématique de l'intelligence artificielle pour la prévision numérique du temps avec notamment pour cible principale la partie assimilation. Le travail consistera à voir l'apport de l'intelligence artificielle sur différentes thématiques : émulateur de modèle météorologique, apprentissage d'erreur modèle, ... Ce travail peut aussi inclure une partie sur le traitement initial des données, notamment sous la forme de la création de jeux de données, l'optimisation du chargement en mémoire des données, ou la visualisation de données. Le diplôme préparé doit être un diplôme d'ingénieur ou un master spécialisé dans une filière data. Les compétences de bases attendues sont celles d'un apprentis datascientist. Des compétences en mathématiques, en statistiques et en informatique (de préférence python) sont attendues. Une première expérience en deep learning serait intéressante. La pratique de git est un plus.
PROFIL SOUHAITÉ
Expérience
Expérience exigée de 1 An(s)
Langue
Français
Source: Pole emploi (https://www.pole-emploi.fr)
Show more
Show less","{'ProgLanguage': ['Python', 'R'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': ['Statistiques'], 'CloudComputing': [], 'DevTools': ['Git'], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Statistiques'], 'FrSoftSkills': [], 'EnSoftSkils': []}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's']}"
Machine Learning Developer,MindPal,"Marseille, Provence-Alpes-Côte d'Azur, France",https://fr.linkedin.com/jobs/view/machine-learning-developer-at-mindpal-3911352774?position=38&pageNum=0&refId=lBTWbVudNP%2F9XLZiNl1XvQ%3D%3D&trackingId=2HwOBPhD6kJBBGK8GQUYZg%3D%3D&trk=public_jobs_jserp-result_search-card,"We are looking for
Machine Learning Developer
Job Responsibilities
Working on machine learning projects
Analyzing and processing data to create machine learning models
Implementing and optimizing machine learning algorithms
Testing and evaluating models
Collaborating with the programming team and other departments within the company to develop innovative solutions
Requirements
Minimum 2 years of experience in the field of machine learning
Knowledge of machine learning algorithms and techniques
Ability to analyze and process data
Familiarity with machine learning tools and technologies
Proficient in English communication
Education in computer science
We Offer
B2B contract type
Full-time employment
Remote and flexible working hours
Show more
Show less","{'ProgLanguage': ['R', 'Go'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Machine Learning'], 'FrSoftSkills': ['Communication'], 'EnSoftSkils': ['Communication']}","{'JobDetail': ['Remote', 'Full'], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's']}"
Data Scientist F/H,TotalEnergies,"Courbevoie, Île-de-France, France",https://fr.linkedin.com/jobs/view/data-scientist-f-h-at-totalenergies-3892558727?position=39&pageNum=0&refId=lBTWbVudNP%2F9XLZiNl1XvQ%3D%3D&trackingId=j494QOc0cWfvukapPH9sow%3D%3D&trk=public_jobs_jserp-result_search-card,"TotalEnergies est une compagnie multi-énergies mondiale de production et de fourniture d'énergies : pétrole et biocarburants, gaz naturel et gaz verts, renouvelables et électricité. Ses 105 000 collaborateurs s'engagent pour une énergie toujours plus abordable, propre, fiable et accessible au plus grand nombre. Présent dans plus de 130 pays, TotalEnergies inscrit le développement durable dans toutes ses dimensions au cœur de ses projets et opérations pour contribuer au bien-être des populations.
Contexte & Environnement :
Environnement de travail international et multiculturel sur l'ensemble des domaines fonctionnels des activités commerciales de la Compagnie.
Participation active à la communauté Data de TotalEnergies.
Large éventail de métiers utilisateurs (activités historiques, nouvelles énergies, efficacité énergétique, etc.)
Multiplicité des intervenants en interne et externe
Poste :
Au sein de l'équipe Valorisation des Données, le titulaire du poste aura 2 types d'activités :
1. Data Scientist
, représentant environ 80% du temps de travail, pour laquelle il/elle :
est au contact direct des clients internes et participe à l'expression du besoin;
propose l'approche à mettre en œuvre pour répondre au besoin métier (bibliographie, méthodologie);
identifie, sur la base de l'analyse des données et de sa connaissance du métier des cas d'usages améliorant l'expérience utilisateur;
élabore et entraine des modèles (machine/deep learning) sur-mesure pour répondre aux besoins métier;
participe, au-delà de la création des modèles, à l'ensemble de la chaine de traitement de la donnée (nettoyage, enrichissement …);
assure une veille technologique en data science et plus généralement en architecture des données, pour être force de proposition sur de nouvelles études à fort impact potentiel pour l'entreprise ou le développement de nouvelles technologies;
rapporte les résultats des travaux, en s'assurant de leur robustesse, à l'écrit et/ou avec des présentations internes/externes.
2. Business Analyst
, représentant environ 20% du temps de travail, pour laquelle il/elle :
participe à la mise en production, en collaboration avec la Tierce Maintenance Applicative (TMA) et les équipes TGITS (TotalEnergies Global Information Technology Services);
accompagne également les métiers sur le delivery (run et projets) et garantit le « move to run »;
s'assure du maintien en conditions opérationnelles du parc applicatif;
met en place les KPIs appropriés et pilote le planning, le budget, la qualité des livrables et les risques des projets.
Profil recherché :
BAC +5 en mathématiques ou statistiques, une thèse de doctorat (PhD) ou une expérience professionnelle dans un domaine lié aux bases de données, BI et Datamining / Analytics
Minimum 6 ans d'expérience
Capacité à développer des algorithmes et coder, notamment en Python
Connaissance Databricks et ML Ops est un plus
Connaissance des environnements cloud, idéalement AWS sur des sujets data, est un plus
Anglais courant obligatoire
Show more
Show less","{'ProgLanguage': ['Python', 'R', 'Go'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': ['Databricks'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': ['Statistiques'], 'CloudComputing': ['AWS'], 'DevTools': ['Git'], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['ML', 'Statistiques', 'Cloud'], 'FrSoftSkills': ['Collaboration'], 'EnSoftSkils': ['Collaboration']}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's', '6', '6', '6']}"
Data Scientist,DxO Labs,"Boulogne-Billancourt, Île-de-France, France",https://fr.linkedin.com/jobs/view/data-scientist-at-dxo-labs-3915441544?position=40&pageNum=0&refId=lBTWbVudNP%2F9XLZiNl1XvQ%3D%3D&trackingId=m4gdJPTRE6km02VBZmAJsA%3D%3D&trk=public_jobs_jserp-result_search-card,"En 20 ans, DxO Labs s’est affirmée comme l’une des entreprises françaises les plus innovantes du secteur de la photographie numérique et du traitement d’image.
Nous concevons et commercialisons des logiciels d’édition photo avancée pour les photographes, amateurs ou experts. Nos solutions, issues de l’excellence et du savoir-faire incomparable de nos équipes d’experts internationales et multiculturelles, offrent les outils de correction et de traitement les plus performants.
DxO Labs s’appuie depuis toujours sur l’excellence et le savoir-faire incomparable de ses équipes d’experts internationales et multiculturelles.
Si vous souhaitez vous projeter et découvrir nos produits; cliquez sur https://www.dxo.com/fr/
Afin de renforcer notre équipe R&D, nous recrutons, dans le cadre d’un contrat en CDI plein temps un
Data Scientist
Basé à notre siège social de Boulogne-Billancourt et rapportant au Directeur Traitement Images.
Au sein de notre équipe R&D Image et en étroite collaboration avec nos équipes UX et produit, votre rôle sera de nous aider à doter nos logiciels fonctionnalités IA innovantes basées sur l’analyse d’une grande quantité de données.
Vos missions :
Avec nos product managers et nos chercheurs en traitement d’image, définir de nouvelles fonctionnalités utilisateur.
Constituer les bases d’apprentissage nécessaires.
Concevoir, implémenter et entrainer des modèles de deep learning.
Evaluer ces modèles grâce à des prototypes.
Aider nos experts logiciel à intégrer ces nouvelles fonctionnalités utilisateur dans nos produits.
Être au fait des dernières recherches et méthodes au croisement entre la data science, la vision par ordinateur et la retouche photo.
Votre profil :
Au moins 5 ans d'expérience en tant que Data Scientist, de préférence dans le secteur technologique ou des logiciels
Deep learning (connaissances à jour par rapport à l’état de l’art en 2024)
Python, PyTorch
Au moins B2 en Anglais et Français
Capacité à travailler de manière autonome et en équipe, avec un esprit curieux et tourné innovation
Idéalement
Connaissance en Traitement d’image (p.ex. analyse sémantique, génération d'images)
Traitement de la langue (LLM)
TensorFlow, AWS, WinML, CoreML, C++
Un vrai + : Passionné de photographie
Si vous vous retrouvez dans le descriptif candidat : Postulez sans attendre sur recruit@dxo.com
Nous verrons ensemble si vos compétences et votre savoir-être correspondent à notre ADN
Localisation :
Basé à Boulogne-Billancourt (Métro 9 station Billancourt – Tramway T2 station Les Moulineaux),
Télétravail possible à hauteur de 2j/semaine
Show more
Show less","{'ProgLanguage': ['Python', 'C++', 'R'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': ['TensorFlow', 'PyTorch'], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': ['AWS'], 'DevTools': [], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['ML'], 'FrSoftSkills': ['Collaboration'], 'EnSoftSkils': ['Collaboration']}","{'JobDetail': [], 'TypeContract': ['CDI'], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's', '20', '20', '20']}"
Machine Learning Engineer,Alki,"Paris, Île-de-France, France",https://fr.linkedin.com/jobs/view/machine-learning-engineer-at-alki-3916860370?position=41&pageNum=0&refId=lBTWbVudNP%2F9XLZiNl1XvQ%3D%3D&trackingId=BwYc7zYF3bFjsQiMzNVNHQ%3D%3D&trk=public_jobs_jserp-result_search-card,"Full Stack Machine Learning Engineer (Time Series Forecasting)
Location:
Remote or Paris
Job Type
: Full-Time
Company overview
: At Alki, we’re leveraging cutting edge AI technologies to transform logistics warehouses and drive innovation. Our mission is to bridge the gap between Amazon and other logistics players. We are looking for a skilled full stack ML engineer with a strong focus on time series forecasting to industrialize and streamline our machine learning operations (MLOps) capabilities from R&D to production.
Responsibilities:
Design & build robust data pipelines specifically tailored for time series data, ensuring efficient data ingestion, pre-processing & exploration to support ML models
Design, implement, and optimize sophisticated time series forecasting algorithms
Translate advanced statistical and machine learning models from R&D into scalable production solutions
Manage the deployment of machine learning systems, including setting up continuous integration and delivery pipelines (CI/CD) for automated model training and deployment
Monitor and maintain operational ML models (thousands), quickly identifying and addressing performance degradation or shifts in model accuracy/data
Collaborate with cross-functional teams, including CTO, AI researcher, software engineer, to ensure models effectively address business needs and enhance decision-making
Stay abreast of the latest developments in machine learning, artificial intelligence, and related technologies to continuously improve our MLOps practices and time series models
Qualifications
Master’s/PhD degree in Computer Science, Applied Maths, Statistics, or a related field
Strong experience with a proven track record of deploying ML models to production
Strong understanding of the challenges associated with deploying, monitoring, and maintaining thousands of ML models in a production environment
Strong experience with AutoML, HPO, NAS
Proficient in Python, including extensive experience with ML libraries such as TensorFlow or PyTorch, and statistical modeling tools
Knowledge of AWS cloud services related to machine learning and data processing, including Amazon S3, EC2, RDS, Lambda, and SageMaker
Familiarity with data orchestration tools
Experience in building and maintaining CI/CD pipelines for automated model deployment
Excellent analytical and problem-solving abilities, with a strong collaborative mindset
Experience in time series analysis and forecasting is a plus
Benefits:
Competitive salary
Strong opportunities for professional development and career advancement
Flexible working hours and remote work options
Dynamic and innovative work environment
How to apply:
Please submit your resume and any relevant project portfolio to tanguy@alki.io. We are excited to hear how you can contribute to our team at Alki!
Show more
Show less","{'ProgLanguage': ['Python', 'Scala', 'R', 'Go'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': ['TensorFlow', 'PyTorch'], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': ['Statistics'], 'CloudComputing': ['AWS'], 'DevTools': [], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': ['Teams'], 'Other': ['ML', 'Machine Learning', 'Cloud', 'CI/CD'], 'FrSoftSkills': [], 'EnSoftSkils': []}","{'JobDetail': ['Remote', 'Full'], 'TypeContract': [], 'Salary': ['Salary'], 'Level': [], 'Experience': ['a', 'n', 's']}"
Machine Learning Engineer,Enzo Tech Group,"Paris, Île-de-France, France",https://fr.linkedin.com/jobs/view/machine-learning-engineer-at-enzo-tech-group-3914687840?position=42&pageNum=0&refId=lBTWbVudNP%2F9XLZiNl1XvQ%3D%3D&trackingId=ByXQC3%2BqZEdYMCursYrz5Q%3D%3D&trk=public_jobs_jserp-result_search-card,"Position:
Machine Learning Engineer / MLOps Engineer / AI Engineer
Location:
Paris
Type:
Freelance, Contract
Duration:
6 months
Searching for a
MLOps Engineer
to lead the implementation of
MLOps
practices at scale with a focus on
large language models
(LLM)
.
Role:
Lead the implementation of
MLOps
practices at scale, focusing on industrialising AI solutions and ensuring their efficient deployment.
Collaborate with software engineering teams to integrate machine learning models into production environments.
Manage and optimise
AI infrastructure
on
Azure
, including
Databricks
clusters and other relevant technologies.
Develop and maintain automation pipelines for model training, testing, monitoring, and retraining.
Requirements
Proven experience as an MLOps Engineer or similar role, with expertise in large-scale AI deployments.
Deep understanding of MLOps principles, including model versioning
Expertise and support to data scientists and engineers working on AI initiatives.
CVs: s.allenby@enzotechgroup.com
Show more
Show less","{'ProgLanguage': ['R'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': ['Databricks'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': ['Azure'], 'DevTools': [], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': ['Teams'], 'Other': ['ML', 'Machine Learning'], 'FrSoftSkills': [], 'EnSoftSkils': ['Initiative']}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's']}"
DATA SCIENTIST F/H,Hôpitaux de Vendée,"La Roche-sur-Yon, Pays de la Loire, France",https://fr.linkedin.com/jobs/view/data-scientist-f-h-at-h%C3%B4pitaux-de-vend%C3%A9e-3845962350?position=44&pageNum=0&refId=lBTWbVudNP%2F9XLZiNl1XvQ%3D%3D&trackingId=72W%2FuJCZhdFHSh8DsXMZ7Q%3D%3D&trk=public_jobs_jserp-result_search-card,"Vos futures missionsAu CHD Vendée, le Data Scientist intervient sur divers projets et notamment le déploiement d’une solution innovante d’interrogation des données médicales à partir d’un entrepôt de données de santé (eHOP).Vos missions en lien avec eHOP seront le traitement et l'analyse des données avec les équipes médicales de l’établissement en réponse aux cas d’usages (projets de l’établissement). Vous serez en charge de créer, modifier, supprimer des études, gérer les datamarts. Vous participerez à la conception méthodologique des projets en analyse de données de santé. Vous développerez au sein de l’équipe l’axe apprentissage automatique qui puisse répondre aux cas d’usages (machine learning, analyse de texte notamment à visée d’optimisation du codage PMSI). Enfin votre rôle sera également de développer, implémenter et évaluer des méthodes d’apprentissage automatique pour tirer parti des larges volumes de données de santé (prescriptions, biologie …).Au sein du Département d'Information Médicale (DIM), vous participerez à tous les travaux du DIM au sein de l’équipe des statisticiens et vous collaborerez avec l’Unité de Recherche Clinique en particulier pour les faisabilités des études ou les recherches en données de santé.Mais ce n'est pas tout, d'autres missions vous serons confiées. En effet vous participerez aux cycles R&D des environnements techniques (veille technologique), en lien avec l’équipe d’ingénieurs : prospective/prototypage, évaluation, conception et développements, transfert industriel. Vous valoriserez les travaux au travers de publications scientifiques dans des journaux et des conférences de référence. Vous participerez aux réponses d’appel d’offre inter-régionaux (plateforme HUGO) ainsi qu'aux ateliers et aux travaux du GCS HUGO.
Les petits plus chez nous :
Horaires de travail du lundi au vendredi avec une amplitude de 7h45
Du temps pour soi : 19 jours de RTT, 28 jours de CA par an
Possibilité de télétravail partiel hors période d'intégration
Un accompagnement et des formations dispensées au sein du service
Votre meilleur profilVous êtes détenteur(trice) d'un diplôme d'Ingénieur/universitaire BAC+5 ou un doctorat spécialisé en mathématiques, statistiques, apprentissage automatique/profond? C'est super!Vous disposez déjà d'une expertise d’au moins un langage parmi python et R et d’une expérience en programmation et en gestion de base de données (relationnelles et noSQL)? Vous avez une certaine maîtrise de l’écosystème Big Data (Hadoop, Spark), traitements batch et/ou streaming, calcul GPU, framework Deep Learning (Tensorflow, Keras, PyTorch). C'est un vrai plus !On vous décrit comme quelqu'un de rigoureux(se), d'autonome avec un bon esprit d'analyse, vous êtes méthodique et vous avez un bon relationnel ?
On attend avec impatience votre candidature !
Les bonnes raisons de nous rejoindre
Ce Qui Vous Attend Au CHD Vendée
Des conditions de recrutement attractives
L'opportunité de suivre des formations
Des perspectives d'épanouissement professionnel grâce à notre politique de mobilité interne
Un Comité de Gestion des Œuvres Sociales dynamique proposant de nombreux avantages (prestations sociales, culturelles et de loisirs)
Des opérations bien-être pour prendre bien soin de vous
Un abonnement Gymlib donnant accès à des activités sportives et de loisirs en dehors de l'établissement pour adopter un mode de vie sain et actif au quotidien
L'accès à des avantages pour vos trajets domicile-travail car c'est bon pour votre santé, pour la planète et aussi pour votre porte-monnaie (prise en charge de 75% des frais de transport en commun et location de vélo jusqu'à 96,35€ mensuels, offre de covoiturage Karos et forfait mobilités durables de 100€ à 300€ par an).
Un service de conciergerie Happytal qui vous fera bénéficier de services et d’offres avantageuses pour vous accompagner au quotidien !
Une crèche hospitalière et des crèches partenaires pour prendre soin de vos bambins
Et un self qui ne sert pas que de la mogette vendéenne (coût moyen de 4€/repas)
Et encore on ne vous dit pas tout ! Découvrez bien d'autres avantages en cliquant ici !
Notre mission : prendre soin de nos agents autant que de nos patients.
N’hésitez plus, rejoignez-nous !
Ouverts à tous, nos postes sont handi-accueillants.
Show more
Show less","{'ProgLanguage': ['Python', 'R', ' R ', 'Go'], 'DataBase': ['SQL', 'NoSQL'], 'DataAnalytics': ['R', ' R '], 'BigData': ['Hadoop', 'Spark'], 'MachingLearning': ['TensorFlow', 'Keras', 'PyTorch'], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': ['Statistiques'], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Big Data', 'ML', 'Machine Learning', 'Statistiques'], 'FrSoftSkills': [], 'EnSoftSkils': []}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': ['Bac+5'], 'Experience': ['a', 'n', 's']}"
Data scientist F/H,METEOJOB by CleverConnect,"Rontignon, Nouvelle-Aquitaine, France",https://fr.linkedin.com/jobs/view/data-scientist-f-h-at-meteojob-by-cleverconnect-3916294538?position=45&pageNum=0&refId=lBTWbVudNP%2F9XLZiNl1XvQ%3D%3D&trackingId=UoH5AAw5AlbO5oKBsolOqg%3D%3D&trk=public_jobs_jserp-result_search-card,"Entreprise
Cabinet de recrutement de dimension internationale, bénéficiant de l'expérience d'un grand Groupe RH, S&you est spécialisé dans le recrutement d'Experts, Cadres et Métiers du tertiaire. Nos 50 consultants expérimentés mettent en œuvre tout notre savoir-faire pour vous accompagner au mieux dans vos projets (recrutement, bilan professionnel, coaching, formation…). La relation de confiance que nous créons avec nos candidats et nos clients représente pour nous le facteur-clé de la performance.
Description Du Poste
Votre profil Vous disposez des compétences et aptitudes nécessaires à l'appropriation du périmètre du poste :
Formation supérieure Bac + 5 (statistiques, mathématiques appliquées …)
Expérience significative (2 ans alternance incluse) en qualité de data scientist / data analyst incluant idéalement une expérience en secteur assurantiel.
Maîtrise / connaissance de l'environnement technique : Python, SQL, R, algorithmes et frameworks, machine learning, RPA, datavisualisation (Power BI, Tableau)
Curiosité, discernement, agilité et esprit d'initiative : appropriation de données complexes, compréhension de problématiques transverses, veille technologique, proposition de solutions
Description Du Profil
Notre client est un acteur clé du secteur assurantiel dont les 250 collaborateurs accompagnent les compagnies et intermédiaires d'assurance sur l'ensemble des sujets intéressant la profession (information, concertation, mise en œuvre) : assurance de biens et responsabilités, assurance de personne, réassurance, co-assurance, évolutions réglementaires et conventionnelles, maîtrise des risques, médiation, intermédiation, référentiels …Notre client recrute un.e Data Scientist dans le cadre d'une création de poste (CDI) en vue d'accompagner le développement de sa stratégie Data.
Show more
Show less","{'ProgLanguage': ['Python', 'R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': ['Tableau', 'Power BI'], 'Statistics': ['Statistiques'], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Machine Learning', 'Statistiques'], 'FrSoftSkills': [""Esprit d'initiative""], 'EnSoftSkils': ['Initiative']}","{'JobDetail': [], 'TypeContract': ['CDI'], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's', '2', '2', '2']}"
Data Scientist - IA Défense F/H,Thales,"Paris, Île-de-France, France",https://fr.linkedin.com/jobs/view/data-scientist-ia-d%C3%A9fense-f-h-at-thales-3880160252?position=46&pageNum=0&refId=lBTWbVudNP%2F9XLZiNl1XvQ%3D%3D&trackingId=oohdNdt9V1qReSisQ0KiLQ%3D%3D&trk=public_jobs_jserp-result_search-card,"QUI SOMMES-NOUS ?
Thales Digital Factory s’inscrit dans le programme de transformation de Thales qui a pour ambition de devenir un acteur incontournable et exemplaire du digital, et ce dans l’ensemble de ses marchés. Notre mission consiste à accélérer la transition numérique du Groupe Thales en s'aventurant dans de nouveaux modes de travail et de décision. Notre stratégie s’articule autour de 6 valeurs : Responsabilisation, Orientée sur la donnée, Centrée sur l’utilisateur, Collaboration, Amélioration continue et Culture de l’échec. Nos bureaux se répartissent de Paris à Singapour en passant par Montréal au cœur d'écosystèmes innovants. Thales Digital Factory se distingue également grâce à son incubateur qui accompagne des start-ups internes et externes, ses plateformes digitales, son centre d’excellence Cloud et le développement de MVP, porteurs d’innovation pour l’offre digitale du Groupe et de nos clients.
Avec plus de 600 experts IA et une centaine de doctorants en IA chaque année, et disposant d’un réseau de partenaires industriels, start-up et académiques de premier ordre, Thales est, depuis une décennie, un acteur majeur de l’IA de confiance, transparente, explicable et éthique. Le Groupe figure en tête, en Europe, dans le classement des déposants de brevets dans l’IA des systèmes critiques. Il intègre de l’IA dans plus d’une centaine de ses produits et services.
Nous recherchons notre futur
Data Scientist
dans le cadre du lancement de notre nouvelle entité CortAix :
CortAIx
est l’accélérateur IA qui dotera les forces armées, les avionneurs et tous les opérateurs d’infrastructures critiques, de solutions hautement sécurisées leur apportant plus d’efficacité dans l’analyse des données et la prise de décision, tout en tenant compte des contraintes spécifiques, telles que la cybersécurité, l’embarquabilité et la frugalité, liées aux environnements critiques.
Au sein de cette nouvelle organisation, nous représentons l'axe
""
cortAIx Factory""
qui vise à accélérer la qualification et l’industrialisation des outils de développement de l’IA ainsi que les cas d’usage pour les données des systèmes. Thales dote déjà ses systèmes d’IA et continue d’identifier de nouveaux cas d’usages pour accélérer la performance, comme par exemple la planification de missions, la gestion du trafic aérien, le pilotage de drones et de robots.
QUI ETES-VOUS ?
Vous êtes titulaire d'un Master 2 (BAC +5) d'une école d'Ingénieur ou d'un parcours universitaire et vous avez un minimum de 5 à 7 ans d'expérience pratique en IA, avec une solide expérience dans le déploiement de solutions ML
Vous faites preuve de motivation, d'autonomie et d'initiative
Vous avez une expérience de mise en place de solutions embarquant du machine learning, depuis la collecte de la donnée jusqu’à la mise en production de la solution par des utilisateurs
Vous faites preuve d'une grande disponibilité et d'une très forte réactivité
Vous êtes reconnu pour votre esprit d'équipe et aimez le travail collaboratif
Une expérience dans des environnements de projet agiles et dynamiques est un plus
Une expérience dans la conduite d'ateliers clients et de réunions face aux clients
Vous vous reconnaissez ?
Parlons missions !
COMPÉTENCES :
Vous comprenez les enjeux business autours de l’exploitation des données et le déploiement des solutions de Machine Learning et/ou de Deep Learning, ainsi que les problématiques inhérentes à la mise en production de telles solutions innovantes.
Vous maitrisez les statistiques, le Machine Learning et de Deep Learning.
Vous avez une écoute développée et une communication fluide et claire, ainsi, vous êtes à l’aise pour vous exprimer et convaincre sur les objectifs, la rentabilité et les étapes de résolution de problèmes associés à vos modèles, permettant de convaincre un interlocuteur peu au fait des techniques ML ou DL.
Maîtrise du ML/DL, y compris des principaux frameworks (TensorFlow, PyTorch) et des statistiques.
Solide connaissance de Python (Java, Spark, Scala sont un plus).
Expérience dans l'utilisation d'outils tels que Gitlab et Docker.
Familiarité avec l'ensemble du cycle de vie de développement et de déploiement de modèles d'IA (MLOps).
En collaboration avec les autres membres de CortAIx, composés d'experts en intelligence artificielle :
Vous participez activement à l'identification des besoins spécifiques des différentes branches de Thales ou de ses clients, à travers des ateliers d'idéation, et proposez des solutions algorithmiques sur mesure adaptées à chaque situation. Votre rôle ne se limite pas à répondre à une question technique, mais à imaginer et concevoir des solutions innovantes qui répondent aux défis et objectifs spécifiques identifiés lors des discussions avec les parties prenantes
Vous analysez rapidement les données disponibles pour sélectionner les modèles d'IA les plus pertinents face aux défis identifiés, en tenant compte des spécificités de chaque cas d'usage
Vous développez, testez et validez les algorithmes de traitement des données en utilisant des méthodes statistiques, mathématiques et de machine learning, adaptés à une variété d'environnements techniques prenant en compte des besoins précis en termes de sensibilité des données
Vous jouez un rôle clé dans la diffusion de la connaissance au sein de CortAIx, en partageant régulièrement des insights et des innovations issues de vos projets récents, contribuant ainsi à l'enrichissement collectif
Vous communiquez efficacement au sein de Thales et en externe pour mettre en valeur les succès, les avancées réalisées et les leçons apprises des différents projets, renforçant ainsi la réputation de Thales comme leader de l'IA dans les domaines de la défense et au-delà
Nous sommes toujours en phase ?
Rejoignez-nous !
Innovation, passion, ambition : rejoignez Thales et créez le monde de demain, dès aujourd’hui.
Show more
Show less","{'ProgLanguage': ['Python', 'Java', 'Scala', 'R', 'Go'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': ['Spark'], 'MachingLearning': ['TensorFlow', 'PyTorch'], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': ['Statistiques'], 'CloudComputing': [], 'DevTools': ['Git', 'Docker'], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': ['Docker'], 'Collaboration': [], 'Other': ['ML', 'Machine Learning', 'Statistiques', 'Cloud'], 'FrSoftSkills': ['Communication', 'Résolution de problèmes', 'Collaboration', 'Organisation'], 'EnSoftSkils': ['Communication', 'Collaboration', 'Initiative']}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's', '7', '7', '7']}"
Data Scientist H/F,Crédit Agricole Assurances,"Paris, Île-de-France, France",https://fr.linkedin.com/jobs/view/data-scientist-h-f-at-cr%C3%A9dit-agricole-assurances-3915760690?position=47&pageNum=0&refId=lBTWbVudNP%2F9XLZiNl1XvQ%3D%3D&trackingId=mKT4BNj1dnlhyYHMg77qBw%3D%3D&trk=public_jobs_jserp-result_search-card,"Premier assureur en France et premier bancassureur en Europe, nous voulons aller plus loin en devenant l'assureur digital de référence et le n°1 de la satisfaction client. La Direction de la Transformation accompagne notre Groupe pour mener à bien cette transformation digitale. Pour vous, c’est l’opportunité de vivre une riche aventure humaine, dans une structure en pleine transformation, avec de nombreuses possibilités d'évolution.
Au sein de le Direction de la Transformation CAA, vous serez rattaché à l’équipe AI Factory (équipe composée de data scientist, ingénieurs IT IA et pilotes de projets IA). Cette équipe a en charge le développement de moteurs d’intelligence artificielle intégrés au cœur des processus de production.
Concrètement, de quoi s'agit-il sur le terrain ?
Prédiction des anomalies dans l’infocentre avec de l’IA (XGB / réseaux de neurones).
Analyse de texte libre (IA Générative, Topic Modeling, TFIDF, etc.)
Traitement automatiques des documents (IA Générative, OCR, Computer Vision, NLP)
Classification de document
Lecture d’information dans les documents (ex. factures, carte grise, etc.)
Identification d’intention des clients
Surveillance des comportements clients ""anormaux"" (RNNS, XGB)
Détection de Fraude à l’assurance
À ces missions s'ajoutent des missions plus générales :
- Interagir avec l’ensemble des filiales du groupe Crédit Agricole
Mener des développements R&D au sein des projets, qui sont ensuite partagés dans l'équipe
Participer à la vie de la communauté Data Science dans le groupe Crédit Agricole Assurances
Participer à la veille technologique en Data Science et échanger avec le DataLab groupe CASA Voici la description des avantages et de la rémunération qui sera publiée à la suite des missions.
Lors de votre prise de poste, vous serez bien entendu accompagné par l’équipe dans la prise en main de vos missions.
Vos avantages
- Un modèle managérial bienveillant favorisant la mise en responsabilité.
Des opportunités professionnelles dans l’ensemble du Groupe Crédit Agricole.
Télétravail : forfait de 82 jours à poser de façon flexible, soit 40 % d’un temps plein annuel.
34 CP + 12 RTT.
Rémunérations fixe et variable individuelle.
Intéressement et épargne salariale avec abondement.
Avantages bancaires, avantages CSE, compte épargne temps.
Mutuelle prise en charge à 75 %, forfait mobilité durable...
Python (et les librairies type PyTorch, Keras, Seaborn, etc.)
Plateforme IA AWS
Un premier niveau de connaissance des assets de MLOps type Docker
Gitlab
Bac+5
Show more
Show less","{'ProgLanguage': ['Python', 'R'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': ['Keras', 'PyTorch'], 'DataSerialization': [], 'DataVisualization': ['Seaborn'], 'Statistics': [], 'CloudComputing': ['AWS'], 'DevTools': ['Git', 'Docker'], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': ['Docker'], 'Collaboration': [], 'Other': ['ML'], 'FrSoftSkills': [], 'EnSoftSkils': []}","{'JobDetail': ['Temps plein'], 'TypeContract': [], 'Salary': [], 'Level': ['Bac+5'], 'Experience': ['a', 'n', 's']}"
Data Scientist F/H,Orange,France,https://fr.linkedin.com/jobs/view/data-scientist-f-h-at-orange-3905556668?position=48&pageNum=0&refId=lBTWbVudNP%2F9XLZiNl1XvQ%3D%3D&trackingId=4w56ArCaKPd7I7Nm6Fa6Jg%3D%3D&trk=public_jobs_jserp-result_search-card,"Et si Business & Décision et le groupe Orange conjuguaient leurs forces pour devenir l'un des leaders européens de la Data transformation ?
Nous l'avons fait ! Notre alchimie nous positionne comme un acteur unique intervenant sur toutes les étapes du voyage de la donnée.
Business & Décision en croissance sur l'année 2021, continue sur sa lancée avec un nouvel objectif de plus de 500 recrutements de profils #DataSpecialist.
Nous intervenons sur l'ensemble du cycle de vie des projets de clients du CAC40 :
Dès la phase de réflexion d'un projet, en passant par le management consulting, le cadrage, les études métiers, le cadrage de l'architecture, jusqu'au run, et expertises.
Nous formons et certifions régulièrement nos consultants sur les technologies du marché ; la formation étant l'une de nos priorités afin de vous accompagner dans le développement de vos compétences et vos perspectives d'évolutions.
Nous recherchons aujourd'hui, un Data Scientist afin d'intervenir chez nos clients pour les accompagner sur les missions suivantes :
- Analyse et cadrage des besoins métiers,
- Préparation des données,
- Choix des algorithmes à mettre en oeuvre,
- Programmation et développement,
- Interprétation des résultats,
- Mise en production,
- Veille technologique,
En tant que Data Scientist expert, vous êtes capable de manipuler une grande quantité de bases de données et de sources, quels que soit leurs formats, de mettre en oeuvre les algorithmes nécessaires, de prendre de la hauteur par rapport aux résultats obtenus, et d'assurer une interaction avec le client sur les résultats obtenus.
De formation Bac +5 en Mathématiques, Statistiques ou IT
Vous maitrisez au moins un des langages de programmation suivants : Python, R, Scala, SQL, ... Vous avez des notions sur les solutions de studios Data Science (KNIME, Dataiku, H2O, Alteryx, SAS, SPSS, ...) et sur les environnements Cloud (Azure, AWS, GCP).
Vous avez déjà travaillé sur des problématiques de type : Machine Learning, Deep Learning, Time Series, Clustering, Anomly detection,
Un intérêt ou une première expérience sur les sujets d'IA Générative est un plus.
Ref : 20521918
Show more
Show less","{'ProgLanguage': ['Python', 'Scala', 'R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': ['Orange'], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': ['Statistiques'], 'CloudComputing': ['AWS', 'Azure'], 'DevTools': [], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['ML', 'Machine Learning', 'Statistiques', 'Cloud'], 'FrSoftSkills': [], 'EnSoftSkils': []}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's']}"
Geospatial Data Scientist,EarthDaily Agro,"Balma, Occitanie, France",https://fr.linkedin.com/jobs/view/geospatial-data-scientist-at-earthdaily-agro-3884744208?position=49&pageNum=0&refId=lBTWbVudNP%2F9XLZiNl1XvQ%3D%3D&trackingId=6HE16EMukDtg7FsUwF7kpQ%3D%3D&trk=public_jobs_jserp-result_search-card,"STRUCTURE D’ACCUEIL
EarthDaily Agro fournit des données et des analyses de l'ère spatiale aux organisations et aux personnes qui nourrissent la planète !
Avec 35 ans d'expérience dans le secteur, EarthDaily Agro fournit à ses clients les données, les analyses et les connaissances dont ils ont besoin pour prendre des décisions plus efficaces. Les services B2B vont de la gestion globale des risques et du suivi des produits agricoles à la commercialisation d'intrants et au conseil en agriculture de précision, en utilisant les dernières recherches en agronomie, en technologies de l'information et en télédétection.
EarthDaily Agro développe également des solutions commerciales hautement personnalisées pour les prêteurs agricoles, les assureurs, les fournisseurs d'intrants et les entreprises alimentaires, avec des analyses faciles à utiliser, qui aident à réduire les risques quotidiens de l'agriculture.
EarthDaily Agro, dont le siège social se trouve à Minneapolis, MN, USA, et qui possède des bureaux en France, au Brésil, en Australie et en Suisse, est une division de EarthDaily Analytics Corp.
EarthDaily Analytics Corp, une société de traitement et d'analyse de données verticalement intégrée, lance une nouvelle constellation de satellites d'observation de la terre. La constellation de satellites EarthDaily améliorera considérablement les capacités d'analyse géospatiale dans les secteurs de l'agriculture, de la sylviculture, de l'environnement, des services financiers et du renseignement, parmi de nombreux autres segments.
RESPONSABILITÉS
Vous serez en charge de résoudre des challenges liés à l’agriculture en utilisant la télédétection, en particulier les images de la future constellation EarthDaily, et des données météo. Basé à Balma, à proximité de Toulouse, vous intégrerez une équipe internationale avec des collègues au Brésil et aux USA.
VOS RESPONSABILITÉS INCLURONT :
L’agriculture fait face à des challenges sans précédent : le changement climatique induit des risques accrus, et les agriculteurs doivent maintenir voire améliorer leur productivité tout en réduisant leur impact environnemental. Avec la future constellation EarthDaily (jusqu’à 5 m de résolution, revisite quotidienne avec 22 bandes spectrales du visible à l’infra-rouge thermique), EarthDaily Agro disposera d’une technologie clef pour répondre à ces problématiques. Rejoignez EarthDaily Agro pour contribuer à minimiser ces risques avec la technologie.
EarthDaily Agro est à la recherche d’un.e Data Scientist en télédétection pour rejoindre son équipe R&D et construire des analytiques à valeur ajoutée à destination de ses clients dans le monde agricole.
Vous mettez en place des solutions inventives pour répondre aux problématiques des clients, demandant des compétences fortes en analyse de données et en machine learning, dans un contexte de larges volumes de données et d’une base existante de plus de 100 analytiques. Vous développez des POCs et prototypes, définissez / testez / validez et spécifiez les algorithmes appropriés. Vous êtes activement impliqué.e dans le design et la mise en place de la solution opérationnelle sur notre plateforme Cloud.
Vos missions :
Comprendre les problématiques métier et les traduire en solution algorithmique basée sur les données issues de la télédétection.
Créer et implémenter des modèles basés sur l’état de l’art, pour extraire l’information pertinente d’un large volume de données
Collaborer au sein d’une équipe Agile pluridisciplinaire et internationale de Data Scientists, Data Engineers et experts métiers dans toutes les phases du projet : de l’idéation à l’industrialisation et déploiement opérationnel
Rédiger des supports de présentation des résultats, conditions d’utilisation, et défendre la solution proposée par une approche pragmatique
Être proactif(ve) pour alimenter le pipeline d’innovation avec des nouvelles idées, contribuer à définir la roadmap R&D
EDUCATION, CONNAISSANCES ET CAPACITÉS
Master ou doctorat en Machine Learning / Mathématiques appliquées, télédétection, ou domaine associé
Au moins 3 ans d’expérience professionnelle, expérience dans un domaine associé à l’agriculture et en entreprise privée appréciée
Etat d’esprit orienté résultats et pragmatique pour évoluer dans un contexte de plannings serrés
Maîtrise de Python, connaissance en SIG (QGIS, GDAL/OGR),
La connaissance des bibliothèques de Machine Learning / Deep Learning (Scikit-learn, Pytorch, Tensorflow…), des outils de MLOps (ZenML, MLFlow), des systèmes de gestion de version (git), de Docker, Kubernetes et du fonctionnement des workflows sur AWS (et Azure) est appréciée
Facilités de communication pour le travail en équipe dans un contexte international
Anglais courant (oral et écrit) : l’équipe d’accueil est internationale, les réunions internes se déroulent principalement en anglais.
Vous êtes curieux(se) et créatif(ve), collaboratif(ve) et adaptable ? Rejoignez-nous !
CONDITIONS
Emploi en CDI, démarrage dès que possible
Poste basé à Balma, première couronne de Toulouse accessible en transports en commun. Possibilité de télétravail partiel.
Powered by JazzHR
m5SHCur65r
Show more
Show less","{'ProgLanguage': ['Python', 'R', 'Go'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': ['Scikit-Learn', 'TensorFlow', 'PyTorch'], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': ['AWS', 'Azure'], 'DevTools': ['Git', 'Docker'], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': ['Kubernetes'], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': ['Docker', 'Kubernetes'], 'Collaboration': [], 'Other': ['ML', 'Machine Learning', 'Cloud'], 'FrSoftSkills': ['Communication', 'Organisation'], 'EnSoftSkils': ['Communication']}","{'JobDetail': [], 'TypeContract': ['CDI'], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's', '35', '35', '35']}"
Data Scientist F/H,Saint-Gobain,"Courbevoie, Île-de-France, France",https://fr.linkedin.com/jobs/view/data-scientist-f-h-at-saint-gobain-3915274420?position=50&pageNum=0&refId=lBTWbVudNP%2F9XLZiNl1XvQ%3D%3D&trackingId=Aadc%2BAlZtrV1jIXqu%2FNxLQ%3D%3D&trk=public_jobs_jserp-result_search-card,"Why do we need you ?
Vous rejoindrez l’équipe « AI & Data Analytics », intégrée au département «Data & Analytics» dans l’organisation « Global Digital & IT». «Data & Analytics» regroupe les activités suivantes :
Data Engineering, Data Capture & Delivery, BI & Visualization, Platform & Architecture, Data Governance and Data Engagement.
Au Sein De L’équipe Data Science, Sous La Responsabilité Du Head Of AI & Data Analytics, Vous Aurez Le Rôle De Data Scientist (H/F). En Tant Que Tel, Vous Aurez Les Responsabilités Suivantes
Construire des modèles descriptifs et prédictifs sur des sujets en constante évolution ;
Mener des projets exploratoires faisant appel à des techniques avancées de Data Science (NLP, deep learning, Generative AI, apprentissage par renforcement ou par transfert), de façon autonome ou avec des partenaires externes ;
Assurer une veille technologique permanente sur ces sujets ;
Participer à l’industrialisation des algorithmes en lien avec les équipes engineering basée sur MLOps;
Accompagner les équipes opérationnelles dans le déploiement des algorithmes, notamment sur le volet analytics ;
Mener des ateliers d’idéation avec les équipes métiers (industrie, marketing, ventes, logistique, e-commerce, finance, RH) pour identifier les opportunités d’exploitation de la donnée et diffuser la culture data au sein de l’entreprise.
Si vous recherchez des défis passionnants, pouvant impacter des centaines de milliers de clients, et aimez travailler avec des outils à la pointe de la technologie, venez et rejoignez-nous !
Vous participerez donc à la montée en puissance de l’équipe créée récemment, tout en intervenant sur un ou plusieurs cas d’utilisation.
Is this job for you ?
En complément des missions évoquées, une réelle appétence pour la gestion et la facilitation de projet, avec une certaine aisance en termes de communication, seraient fortement appréciées.
Notre équipe ayant vocation à travailler pour des clients internes pouvant être basés en France comme à l’étranger, la maitrise de l’anglais (écrite et orale) est obligatoire.
Profil recherché
Ingénieur diplômé d’une école généraliste (Centrale, X, Mines, ENS etc.) ayant au minimum 3 années d'expérience après le diplôme.
Grande connaissance du Machine Learning, des statistiques et des probabilités.
SQL et Python, packages de ML: scikit, xgboost, keras
Expérience de travail sur un cloud provider et savoir construire des data pipelines serait un plus
Gestion de code : Git, Gitlab, CI/CD
Maitriser la modélisation à la fois prédictive et descriptive
Savoir implémenter des dashboards et autres outils de data viz
Posséder de bonnes qualités de communication : vous pouvez expliquer vos modèles clairement à la fois à des data analysts mais aussi à des Directeurs Généraux ou des responsables opérationnels.
Etre organisé, structuré et motivé par l’innovation
Aimer le travail en équipe et savoir apprendre de chacun.
Un état d’esprit orienté business et apport de valeur pour les équipes métiers
A Little More About Us
Saint-Gobain est une entreprise française spécialisée dans la production, la transformation et distribution de matériaux.
Fondée en 1665 par Jean-Baptiste Colbert sous le nom de Manufacture royale des glaces, l'entreprise est présente dans soixante-sept pays et emploie en 2018 près de 180 000 personnes
To make sure nothing is forgotten
Détails pratiques du rôle
Début : Dès que vous êtes prêts
Localisation : La Tour Saint-Gobain, La Défense
Contrat: CDI
Saint-Gobain encourage la diversité des équipes et favorise notamment l’inclusion des personnes en situation de handicap.
Show more
Show less","{'ProgLanguage': ['Python', 'R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': ['Keras', 'XGBoost'], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': ['Statistiques'], 'CloudComputing': [], 'DevTools': ['Git'], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['ML', 'Machine Learning', 'Statistiques', 'Cloud', 'CI/CD'], 'FrSoftSkills': ['Communication', 'Organisation'], 'EnSoftSkils': ['Communication']}","{'JobDetail': [], 'TypeContract': ['CDI'], 'Salary': ['1665'], 'Level': [], 'Experience': ['a', 'n', 's']}"
Data Scientist H/F,ADHERENCE CONSULTING,"Capinghem, Hauts-de-France, France",https://fr.linkedin.com/jobs/view/data-scientist-h-f-at-adherence-consulting-3913994542?position=51&pageNum=0&refId=lBTWbVudNP%2F9XLZiNl1XvQ%3D%3D&trackingId=JLpOwSxM9vm4%2FNqsJ2bjBA%3D%3D&trk=public_jobs_jserp-result_search-card,"Adherence Consulting : Votre partenaire IT de choix !
Implantés à Paris, Lille et Marseille, nous sommes au coeur de l'innovation technologique et organisationnelle.
Notre mission ? Booster votre performance et vous accompagner dans chaque étape de votre transformation digitale.
Si vous êtes prêt(e) pour une carrière qui dépasse vos attentes, c'est le moment !
https://www.adherence-consulting.fr/
Les missions du poste
Contexte
Adhérence Consulting est une ESN implanté à Paris, Lille et Marseille. Nous sommes au coeur de l'innovation technologique et organisationnelle.
Notre mission ? Booster les performances et accompagner nos clients à chaque étape de leur transformation digitale. Nous cherchons actuellement un Data Scientist (F/H) pour le projet de notre client.
Vous participerez à la construction de nombreux projets tous aussi ambitieux les uns que les autres.
Quelles sont vos missions au quotidien ?
Applique des techniques (statistiques, text mining, comportementale, géolocalisation,) d'extraction et d'analyse d'informations, obtenues à partir de gisements de données (Big Data)
Obtient des données adéquates, trouve les sources de données pertinentes, fait des recommandations sur les bases de données à consolider, modifier, rapatrier, externaliser, internaliser, conçoit des datamarts, voire des entrepôts de données (data warehouses).
Évalue la qualité et la richesse des données, les analyse et en restitue les résultats pour ensuite les intégrer dans le système d'information cible du Métier.
Analyse les données pour traduire une problématique Métier en problème mathématiques/statistiques et réciproquement.
Compare et évalue différents modèles ou méthodes de calcul et anticipe les avantages et inconvénients dans un environnement Métier.
Intervenant auprès des Métiers, il exploite, analyse et évalue la richesse, de données structurées ou non, appartenant à l'entreprise ou non, pour établir des scénarios permettant de comprendre et d'anticiper de futurs levier Métiers ou opérationnels pour l'entreprise
Show more
Show less","{'ProgLanguage': ['R'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': ['Statistiques'], 'CloudComputing': [], 'DevTools': ['Git'], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Big Data', 'Statistiques'], 'FrSoftSkills': ['Organisation'], 'EnSoftSkils': []}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's']}"
Data Scientist (confirmé/sénior) - H/F - CDI,Talan,"Paris, Île-de-France, France",https://fr.linkedin.com/jobs/view/data-scientist-confirm%C3%A9-s%C3%A9nior-h-f-cdi-at-talan-3909648101?position=52&pageNum=0&refId=lBTWbVudNP%2F9XLZiNl1XvQ%3D%3D&trackingId=CY%2FAOHp7GNWOybal4gYTDA%3D%3D&trk=public_jobs_jserp-result_search-card,"Talan est un groupe international de conseil en transformation et en innovation par la technologie, créé en 2002.
Nos 5000 consultantes et consultants partagent à travers le monde l’audace d’innover, le goût de l’excellence, et l’envie de relever les défis les plus complexes.
Nous accompagnons les entreprises dans des secteurs variés : énergie, industrie, transport, finance, luxe… à travers 3 grandes expertises :
Le Conseil en Management et Innovation (320 Consultants en France)
La valorisation des données, leurs structurations, et leurs usages (Data et Technologies)
L’intégration de solutions logicielles (Cloud et Applications Services)
Nos valeurs : engagement, respect, partage, esprit d’équipe et optimisme.
Talan est une entreprise responsable, reconnue par ses collaborateurs et attachée à la diversité. Des aménagements peuvent être proposés si vous êtes en situation de handicap.
Retrouvez nos engagements RSEiciet nos actions en faveur de la diversitéici
Job Description
Nous sommes à la recherche d’un Data Scientist capable de participer à des projets techniques Data Science et IA. Vous devrez faire preuve d’un état d’esprit à la fois innovant, méthodique, orienté solution (et non problème!), et communiquant.
Votre but ultime sera de garantir l’excellence de vos solutions Data Science/IA, pièces maitresses de la réalisation de projets disruptifs pour nos clients.
VOTRE ROLE SUR NOS PROJETS
:
En mission: analyse des besoins métiers, définition des principes et méthodes de collecte et de traitement des données, choix des modèles de Machine Learning ou de Deep Learning, mise en application des techniques de traitement et de visualisation de la data, restitution des analyses et résultats obtenus auprès des métiers et des sponsors
Partager techniquement les membres de l’équipe: solutions et code reviews, recommandations, certifications à réaliser, …
Participation à des meet-up, coding dogo,…
Communication: écriture d’articles, retours d’expérience…
VOTRE ROLE CHEZ TALAN :
Benchmark de solutions et conseil auprès de nos clients sur les solutions technologiques à adopter, en lien avec leurs besoins
Réalisation de POC (Proof Of Concept)
Participation à des projets internes et partage de connaissances au sein de nos équipes.
Partage de connaissances et formations interne
Qualifications
VOTRE PROFIL:
Issu d’une formation Grande École d’Ingénieur/Doctorant, spécialisée en Data Science ou Intelligence Artificielle
Vous disposez d’au moins 3 années d’expérience dans le domaine
Maitrise des techniques d’analyses statistiques, de modélisations prédictives, de Machine Learning, de Deep Learning,...
Maitrise des techniques de data management et de DataViz
Maitrise de Python, R, RShiny, SQL…
Maitrise de l’utilisation des outils DevOps: Git, Docker, Jenkins/Nexus,…
Bonnes connaissances Big Data: pySpark, Spark, NoSQL…
Connaissance d’outils tels que Dataiku, AWS SageMaker, Azure ML,…
Autonomie, organisation, sens du partage
Excellente communication
Orientation métier
Additional Information
AVANTAGES
:
Plan de formation pour accompagner votre carrière (formations éditeurs, certifications) grâce à nos partenariats nous accordant une position de partenaire privilégié, et management de proximité par des experts
Locaux modernes en centre-ville
Top 5 du Palmarès Great Place to Work
Télétravail jusqu’à 5 jours selon les missions, prime d’équipement de 100€
Mobilité en France et à l’étranger
Top 1% des entreprises évaluées par Ecovadis dans le domaine social, environnemental et éthique
Tickets restaurant, prime vacances, 50% transport (abonnement transport public), mutuelle
Permanence handicap (consultant dédié aux collaborateurs en situation de handicap et aux proches aidants)
Actionnariat salarié
Prime de cooptations
RTT
PROCESS RECRUTEMENT
:
L’équipe recrutement s’engage à vous proposer un processus de recrutement rapide et fluide
1 entretien RHpar Teams (45min)
1 test technique
1 entretien opérationnel avec le responsable de domaine, au siège (1heure)
1 entretien avec le directeur de pôle, au siège(1heure)
Show more
Show less","{'ProgLanguage': ['Python', 'R', 'Go'], 'DataBase': ['SQL', 'NoSQL'], 'DataAnalytics': ['R'], 'BigData': ['Spark'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': ['Statistiques'], 'CloudComputing': ['AWS', 'Azure'], 'DevTools': ['Git', 'Docker', 'Jenkins'], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': ['Docker'], 'Collaboration': ['Teams'], 'Other': ['DevOps', 'Big Data', 'ML', 'Machine Learning', 'Statistiques', 'Cloud'], 'FrSoftSkills': ['Communication', 'Organisation'], 'EnSoftSkils': ['Communication']}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's']}"
Data Scientist (H/F),Assurances Crédit Mutuel,"Strasbourg, Grand Est, France",https://fr.linkedin.com/jobs/view/data-scientist-h-f-at-assurances-cr%C3%A9dit-mutuel-3881495295?position=53&pageNum=0&refId=lBTWbVudNP%2F9XLZiNl1XvQ%3D%3D&trackingId=qfcN45kF%2FbnBoxDD66wQ7g%3D%3D&trk=public_jobs_jserp-result_search-card,"Qui sommes nous
Depuis 1971, nous imaginons, concevons et orientons les offres et services qui contribuent au développement de l’activité assurance de Crédit Mutuel Alliance Fédérale, inventeur du concept de bancassurance.
Les Assurances du Crédit Mutuel sont présentes sur les marchés des assurances de biens, des assurances de personnes comme de l’assurance-vie. Nous proposons des solutions à tous ceux qui désirent se protéger et anticiper demain, qu’ils soient particuliers, professionnels ou entreprises.
Ce sont nos valeurs mutualistes et notre philosophie innovante qui guident nos actions. Loin de nous contenter de couvrir nos assurés aujourd’hui, nous cherchons à prévenir les risques futurs et à construire une assurance de demain plus juste.
Les Assurances du Crédit Mutuel, ce sont ainsi environ 3500 talents au service de près de 13 millions d’assurés, générant un chiffre d’affaires de 13,9 milliards d’euros. Nos offres et services sont principalement distribués par les réseaux bancaires Crédit Mutuel, CIC et Cofidis. Nous sommes parmi les acteurs majeurs de l’assurance en France.
Rejoindre les Assurances du Crédit Mutuel, c’est rejoindre un groupe qui porte haut et fort ses valeurs et où l’humain est toujours au centre. C’est rejoindre une entreprise où les innovations sont sources de simplicité et de solidarité et où chacun est engagé pour une société plus juste et plus durable. Intégrer les ACM c’est également intégrer le groupe Crédit Mutuel Alliance Fédérale et ses multiples opportunités de carrières.
Pourquoi nous recrutons
Dans un contexte de recherche constante d'une croissance responsable et durable, Les assurances du Crédit Mutuel continuent d'innover, de se développer et de renforcer leurs équipes dans de nombreux domaines.
Vos missions
Au sein de la Direction du Développement, de la transformation et de la Communication, vous intégrez l'équipe « Data et connaissance client » pour mener des projets de data science visant à accompagner la transformation de l'entreprise et favoriser le développement via l’analyse des profils clients.
En intégrant cette équipe, vous prendrez en main des projets de data science, avec le cadrage des problématiques, le recueil et l’analyse des données nécessaires. Vous testerez et comparerez différents modèles et études de performances.
Vous jouerez un rôle majeur dans la connaissance et l’anticipation des besoins de nos clients et travaillerez ainsi en relation avec les autres services de la direction (marketing, parcours client, projets digitaux, …), avec les différents services métiers des ACM et la direction commerciale du Groupe.
Vous serez aussi amené(e) à mener des études en collaboration avec d’autres Data Scientists du Groupe.
Activités / Tâches spécifiques du poste
Vos missions seront entre autres les suivantes :
Détenir, comprendre et exploiter la connaissance client
Proposer et développer des outils statistiques prédictifs et prescriptifs tels que des scores d’appétence ou d’attrition en mettant en œuvre des techniques de type scoring et segmentation via l’utilisation de méthodes classiques (régression logistique …) ou plus innovantes de type machine learning (random forest …).
Analyser, interpréter et synthétiser les données pour dégager des tendances et constats qui alimenteront la compréhension et la réflexion au sein de la direction dans le cadre d’études spécifiques (profils clients …).
Identifier les données existantes et de nouvelles sources de données pertinentes à collecter pour enrichir la connaissance client et modéliser leur comportement (données internes ou externes, structurées ou non structurées).
Etablir les suivis de l’activité commerciale et analyser les performances des actions commerciales et marketing pour améliorer leur efficacité.
Participer à différentes missions de type veille et partage de connaissance
Assurer une veille active sur les sujets de type Big Data et modélisation de données.
Aider au partage de bonnes pratiques au sein du groupe en tant qu’expert des données et des méthodes de modélisation.
Contribuer à la diffusion des travaux de l’équipe au sein de l’entreprise
Pouvoir représenter l'activité en intervenant dans des groupes de travail transverses.
Restituer et communiquer régulièrement les résultats des analyses et les préconisations associées de manière rigoureuse, pédagogique, accessible et exploitable
Ce que vous allez vivre chez nous
Concrètement, aux Assurances du Crédit Mutuel, nos collaborateurs bénéficient:
D'une rémunération fixe versée sur 13 mois
De l'intéressement, participation et de l'abondement pouvant atteindre plus de deux mois de salaire en fonction des résultats du groupe
D'un plan épargne entreprise (PEE), d’un plan épargne retraite collectif (PERECOL) et d’un compte épargne temps (CET),
D'un rythme de travail adapté fort d'un accord QVT groupe qui permet de télétravailler jusqu'à deux jours par semaine
De 22 jours de RTT par an selon le rythme de travail défini
D'une politique de protection sociale renforcée (régimes de remboursement de frais de santé et de prévoyance)
D'un régime de retraite supplémentaire (PERO) prise en charge à 100% par l’employeur
De conditions bancaires et assurances préférentielles
D'une politique parentale avantageuse
D'un parcours d'intégration pour tout nouvel arrivant
D'au moins une action de formation chaque année (95% des salariés)
D'un accompagnement pour favoriser votre mobilité géographique et fonctionnelle.
Ce que nous allons aimer chez vous
Connaissances et compétences
De formation supérieure Bac+5 minimum orientée statistiques, mathématiques, Data Science.
Un minimum de six ans d’expérience à un poste équivalent est demandé.
Vous possédez une expertise confirmée en Python (pandas, scikit-learn) ainsi que des connaissances poussées en Data Science (random forest, boosting, classification …).
Vous maîtrisez des langages / outils de traitement et d’analyse de données (SQL, SAS, Excel, …)
Vous possédez des compétences en présentation (PowerPoint) et êtes capable de mettre en valeur votre travail.
Une expérience en assurance constituerait un plus.
Une expérience en compétition de Data Science ou programmation (Kaggle, leetcode ...) constituerait un plus.
Savoir-être - savoir-faire
Vous appréciez le travail en équipe et faîtes preuve d'une bonne aisance relationnelle.
Curieux, vous possédez un bon esprit d'initiative et vous tenez au courant des dernières nouveautés en terme de Data Science.
Vous possédez un esprit analytique et créatif et êtes en mesure d’imaginer et de proposer des solutions innovantes.
Rigoureux et autonome, vous disposez d'excellentes capacités d'analyse et de synthèse.
Show more
Show less","{'ProgLanguage': ['Python', 'R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['Pandas', 'R'], 'BigData': [], 'MachingLearning': ['Scikit-Learn'], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': ['Statistiques'], 'CloudComputing': [], 'DevTools': ['Git'], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Big Data', 'Machine Learning', 'Statistiques'], 'FrSoftSkills': ['Communication', 'Collaboration', ""Esprit d'initiative""], 'EnSoftSkils': ['Communication', 'Collaboration', 'Initiative']}","{'JobDetail': ['Confirmé'], 'TypeContract': [], 'Salary': ['22'], 'Level': ['Bac+5'], 'Experience': ['a', 'n', 's']}"
Data Scientist H/F,METEOJOB by CleverConnect,"Rennes, Brittany, France",https://fr.linkedin.com/jobs/view/data-scientist-h-f-at-meteojob-by-cleverconnect-3907968677?position=54&pageNum=0&refId=lBTWbVudNP%2F9XLZiNl1XvQ%3D%3D&trackingId=TiO%2FS3IKY%2BwjMf%2FLvjZoFw%3D%3D&trk=public_jobs_jserp-result_search-card,"Entreprise
Qui sommes-nous ?
Nous sommes passionnés par les nouvelles technologies, et vous ?
Rejoindre Amiltone, c'est intégrer des équipes dynamiques et soudées dans le cadre de projets novateurs et ambitieux. Nous relevons les challenges techniques de nos clients et les accompagnons dans leur transformation digitale.
Pourquoi choisir Amiltone ?
Amiltone, plus qu'une entreprise, un état d'esprit !
Notre objectif ? Votre épanouissement professionnel !
Nous Avons à Cœur De
Vous accompagner au mieux au travers d'un suivi personnalisé
Vous faire monter en compétences en vous proposant des formations tout au long de votre carrière
Comprendre vos besoins et respecter nos engagements
Vous proposer des missions de qualité avec des technologies innovantes
Cultiver votre potentiel grâce à notre programme de développement personnel Addvise
Votre bien-être passe aussi par des activités extraprofessionnelles, c'est pourquoi nous vous proposons des séances sportives animées par nos coachs, soirées pour se retrouver et animations (à l'agence ou en visio), Gaming nights...
Description Du Poste
Vos missions ?
Intégré à notre équipe de 10 personnes, vous assurez les missions suivantes :
Réceptionner et analyser la donnée brute
Traiter la donnée en streaming ou en statique
Adapter ou créer des modèles de machine learning
Evaluer la précision/robustesse d'un modèle
Outils de monitoring et de visualisation
Développement des modèles
Maintenir et documenter les codes et les process
La stack Technique :
Outils : MongoDB, PostgreSQL
NLP (IA générative)
Qlik Sense
Docker, Jenkins
Gitlab/Github
Description Du Profil
Alors ? Prêt à devenir Amiltonien ?
N'hésitez Pas à Postuler Si Vous Vous Reconnaissez
Diplômé bac+5 (école d'ingénieur ou master), vous avez au moins 2 ans d'expérience en tant que Data Scientist.
Vous aimez découvrir de nouveaux contextes fonctionnels et comprendre les objectifs des applications que vous développez.
A l'aise dans une organisation agile, vous faites preuve de rigueur et appliquez les standards de qualité Amiltone durant toute la durée des développements.
Outre vos compétences techniques, nous nous intéressons également à votre potentiel et votre motivation.
Nos postes sont ouverts aux personnes en situation de handicap.
Show more
Show less","{'ProgLanguage': ['R', 'Go'], 'DataBase': ['SQL', ' MongoDB'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git', 'Docker', 'Jenkins'], 'Os': [], 'DBMS': ['PostgreSQL'], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': ['Docker'], 'Collaboration': [], 'Other': ['Machine Learning'], 'FrSoftSkills': ['Organisation'], 'EnSoftSkils': []}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': ['Bac+5'], 'Experience': ['a', 'n', 's', '2', '2', '2']}"
"Machine Learning Engineer, Fast Optimized Inference - EMEA Remote",Hugging Face,France,https://fr.linkedin.com/jobs/view/machine-learning-engineer-fast-optimized-inference-emea-remote-at-hugging-face-3848456024?position=55&pageNum=0&refId=lBTWbVudNP%2F9XLZiNl1XvQ%3D%3D&trackingId=KsNWMSDFzUICjtrplvjaxA%3D%3D&trk=public_jobs_jserp-result_search-card,"Here at Hugging Face, we're on a journey to advance good Machine Learning and make it more accessible. Along the way, we contribute to the development of technology for the better.
We have built the fastest-growing, open-source, library of pre-trained models in the world. With more than 1 Million+ models and 320K+ stars on GitHub, over 15.000 companies are using HF technology in production, including leading AI organizations such as Google, Elastic, Salesforce, Algolia, Grammarly and NASA.
About the role:
As a Machine learning Engineer, you work mainly on creating great libraries highly focused on real world ML use cases. We're building on top of our open-source to create more specialized code with a focus on industrial level of usage.
We are searching for someone who brings fresh ideas, demonstrates a unique and informed viewpoint, and enjoys collaborating with a progressive, nimble and decentralized approach to develop real-world solutions and positive user experiences at every interaction.
Objectives of this role:
Develop specialized software for specific machine learning (ML) use cases that have broad applications, similar to [text-generation-inference](https://github.com/huggingface/text-generation-inference).
Utilize existing library frameworks to create scalable software solutions for industrial purposes.
Enhance the reliability, quality, and time-to-market of our software suite. Measure and optimize system performance to stay ahead of customer needs and drive innovation.
Manage the production environment by monitoring availability and ensuring overall system health. We run our own tools
About you:
If you are a passionate Machine Learning Engineer with a keen interest in AI and proficient with Python, Rust and specialized Cuda kernels Frameworks (transformers of course + Keras or PyTorch), we would love to hear from you. Join our team and contribute to the advancement of AI technologies while working alongside talented professionals in a collaborative and stimulating environment.
More about Hugging Face
We are actively working to build a culture that values diversity, equity, and inclusivity
.
We are intentionally building a workplace where people feel respected and supported—regardless of who you are or where you come from. We believe this is foundational to building a great company and community. Hugging Face is an equal opportunity employer and we do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.
We value development.
You will work with some of the smartest people in our industry. We are an organization that has a bias for impact and is always challenging ourselves to continuously grow. We provide all employees with reimbursement for relevant conferences, training, and education.
We care about your well-being
.
We offer flexible working hours and remote options. We offer health, dental, and vision benefits for employees and their dependents. We also offer flexible parental leave and paid time off.
We support our employees wherever they are
.
While we have office spaces in NYC and Paris, we're very distributed and all remote employees have the opportunity to visit our offices. If needed, we'll also outfit your workstation to ensure you succeed.
We want our teammates to be shareholders
.
All employees have company equity as part of their compensation package. If we succeed in becoming a category-defining platform in machine learning and artificial intelligence, everyone enjoys the upside.
We support the community
.
We believe major scientific advancements are the result of collaboration across the field. Join a community supporting the ML/AI community.
Show more
Show less","{'ProgLanguage': ['Python', 'Scala', 'R', 'Go'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': ['Keras', 'PyTorch'], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git'], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['ML', 'Machine Learning'], 'FrSoftSkills': ['Collaboration'], 'EnSoftSkils': ['Collaboration', 'Organization']}","{'JobDetail': ['Remote'], 'TypeContract': [], 'Salary': ['Package'], 'Level': [], 'Experience': ['a', 'n', 's']}"
Data Scientist F/H,Saint-Gobain,"Courbevoie, Île-de-France, France",https://fr.linkedin.com/jobs/view/data-scientist-f-h-at-saint-gobain-3916726404?position=56&pageNum=0&refId=lBTWbVudNP%2F9XLZiNl1XvQ%3D%3D&trackingId=GfLdHdyLyrtmrUjG2rnIvA%3D%3D&trk=public_jobs_jserp-result_search-card,"Why do we need you ?
Vous rejoindrez l’équipe « AI & Data Analytics », intégrée au département «Data & Analytics» dans l’organisation « Global Digital & IT». «Data & Analytics» regroupe les activités suivantes :
Data Engineering, Data Capture & Delivery, BI & Visualization, Platform & Architecture, Data Governance and Data Engagement.
Au Sein De L’équipe Data Science, Sous La Responsabilité Du Head Of AI & Data Analytics, Vous Aurez Le Rôle De Data Scientist (H/F). En Tant Que Tel, Vous Aurez Les Responsabilités Suivantes
Construire des modèles descriptifs et prédictifs sur des sujets en constante évolution ;
Mener des projets exploratoires faisant appel à des techniques avancées de Data Science (NLP, deep learning, Generative AI, apprentissage par renforcement ou par transfert), de façon autonome ou avec des partenaires externes ;
Assurer une veille technologique permanente sur ces sujets ;
Participer à l’industrialisation des algorithmes en lien avec les équipes engineering basée sur MLOps;
Accompagner les équipes opérationnelles dans le déploiement des algorithmes, notamment sur le volet analytics ;
Mener des ateliers d’idéation avec les équipes métiers (industrie, marketing, ventes, logistique, e-commerce, finance, RH) pour identifier les opportunités d’exploitation de la donnée et diffuser la culture data au sein de l’entreprise.
Si vous recherchez des défis passionnants, pouvant impacter des centaines de milliers de clients, et aimez travailler avec des outils à la pointe de la technologie, venez et rejoignez-nous !
Vous participerez donc à la montée en puissance de l’équipe créée récemment, tout en intervenant sur un ou plusieurs cas d’utilisation.
Is this job for you ?
En complément des missions évoquées, une réelle appétence pour la gestion et la facilitation de projet, avec une certaine aisance en termes de communication, seraient fortement appréciées.
Notre équipe ayant vocation à travailler pour des clients internes pouvant être basés en France comme à l’étranger, la maitrise de l’anglais (écrite et orale) est obligatoire.
Profil recherché
Ingénieur diplômé d’une école généraliste (Centrale, X, Mines, ENS etc.) ayant au minimum 3 années d'expérience après le diplôme.
Grande connaissance du Machine Learning, des statistiques et des probabilités.
SQL et Python, packages de ML: scikit, xgboost, keras
Expérience de travail sur un cloud provider et savoir construire des data pipelines serait un plus
Gestion de code : Git, Gitlab, CI/CD
Maitriser la modélisation à la fois prédictive et descriptive
Savoir implémenter des dashboards et autres outils de data viz
Posséder de bonnes qualités de communication : vous pouvez expliquer vos modèles clairement à la fois à des data analysts mais aussi à des Directeurs Généraux ou des responsables opérationnels.
Etre organisé, structuré et motivé par l’innovation
Aimer le travail en équipe et savoir apprendre de chacun.
Un état d’esprit orienté business et apport de valeur pour les équipes métiers
A Little More About Us
Saint-Gobain est une entreprise française spécialisée dans la production, la transformation et distribution de matériaux.
Fondée en 1665 par Jean-Baptiste Colbert sous le nom de Manufacture royale des glaces, l'entreprise est présente dans soixante-sept pays et emploie en 2018 près de 180 000 personnes
To make sure nothing is forgotten
Détails pratiques du rôle
Début : Dès que vous êtes prêts
Localisation : La Tour Saint-Gobain, La Défense
Contrat: CDI
Saint-Gobain encourage la diversité des équipes et favorise notamment l’inclusion des personnes en situation de handicap.
Show more
Show less","{'ProgLanguage': ['Python', 'R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': ['Keras', 'XGBoost'], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': ['Statistiques'], 'CloudComputing': [], 'DevTools': ['Git'], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['ML', 'Machine Learning', 'Statistiques', 'Cloud', 'CI/CD'], 'FrSoftSkills': ['Communication', 'Organisation'], 'EnSoftSkils': ['Communication']}","{'JobDetail': [], 'TypeContract': ['CDI'], 'Salary': ['1665'], 'Level': [], 'Experience': ['a', 'n', 's']}"
"Ingénieur Data scientist –Intelligence artificielle-  IDF, France (H/F)",Astek,"Île-de-France, France",https://fr.linkedin.com/jobs/view/ing%C3%A9nieur-data-scientist-%E2%80%93intelligence-artificielle-idf-france-h-f-at-astek-3886897805?position=57&pageNum=0&refId=lBTWbVudNP%2F9XLZiNl1XvQ%3D%3D&trackingId=6CSQSAZ1dhsTRymqQBf7Hw%3D%3D&trk=public_jobs_jserp-result_search-card,"Ce que nous allons accomplir ensemble :
Pour l’un de nos projets dans le domaine aéronautique, vous interviendrez en tant
qu’ingénieur Data scientist / Intelligence artificielle
sur la mise en place de systèmes experts destinés aux avions civils et militaires.
Votre future équipe :
Team IT de 12 personnes
Data scientist, ingénieurs systèmes, intégrateurs, architectes
Vous travaillerez avec de véritables passionnés !
Votre mission (...si vous l’acceptez !) :
Vous participerez au développement des fonctions d’analyses multisystèmes. Pour cela vous assurerez l’établissement d’une spécification formelles sur les modèles d’analyses.
Vous assurerez l’analyse des données et la proposition de méthodes pour le traitement des signaux.
Vous développerez les outils capables de traiter de manière automatique les données systèmes.
Vous assurerez la réalisation des scénarios, ainsi que les tests et simulations.
Vous réaliserez également une activité de support.
Votre stack de jeu :
Data scientist, python, principe de gestion de configuration, et traçabilité, systèmes aéronautiques, intelligence artificielle
Les petits plus du projet :
Vous évoluerez au sein d’équipes agiles impliquées et réactives.
Vous interviendrez de A à Z sur des projets riches fonctionnellement et ambitieux techniquement :
forte volumétrie, haut niveau de performance, exigence maximale en termes d’intelligence artificielle et encore bien d'autres sujets captivants.
Vous ?
De formation Ingénieur, vous justifiez d’une expérience significative en Data scientist et ou Intelligence artificielle.
Une connaissance des méthodes d’analyse de données serait un plus.
Idéalement vous avez une connaissance des systèmes aéronautiques.
Des postes également ouverts aux débutants si stages significatifs.
Nous ?
Créé en France en 1988, Astek est un acteur mondial de l’ingénierie et du conseil en technologies, présent sur les 5 continents. Fort de son expertise dans de nombreux secteurs industriels et tertiaires, Astek accompagne ses clients internationaux dans le déploiement intelligent de leurs produits et de leurs services, et dans la mise en œuvre de leur transformation digitale.
Depuis sa création, le Groupe a fondé son développement sur une forte culture d’entrepreneuriat et d’innovation, et sur l’accompagnement et la montée en compétence de ses 5 200 collaborateurs qui s’engagent chaque jour à promouvoir la complémentarité entre les technologies numériques et l’ingénierie des systèmes complexes.
Rejoignez un Groupe en fort développement en France et à travers le monde grâce à une levée de fonds de 200M€ réalisée en 2021. Ensemble « Let’s move forward! »
✨ Tous les détails sur le Groupe sur le site
https://astekgroup.fr.
Et vous pouvez aussi nous suivre sur
notre blog : https://blog.groupeastek.com
.
Rencontrons-nous !
Vous vous êtes reconnu sur l’annonce et Astek vous plaît !
Pour en savoir plus sur vous, Franck , notre Talent Acquisition vous contacte. Puis, vous aurez 3 entretiens max, avec Léonard (votre futur n+1), Léonard notre Directeur !
Nos plus
Astek est green et fait bénéficier ses salariés d’une indemnité kilométrique vélo
Un programme CARE sur-mesure déployé par nos équipes RH pour nos collaborateurs : https://astekgroup.fr/engagements
Notre charte de la Diversité
Bienvenue dans la team ! Allez-y, maintenant c’est à vous de jouer !
Show more
Show less","{'ProgLanguage': ['Python', 'R'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git'], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': [], 'FrSoftSkills': [], 'EnSoftSkils': []}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's']}"
Machine Learning Developer,MindPal,"Lyon, Auvergne-Rhône-Alpes, France",https://fr.linkedin.com/jobs/view/machine-learning-developer-at-mindpal-3910999113?position=58&pageNum=0&refId=lBTWbVudNP%2F9XLZiNl1XvQ%3D%3D&trackingId=wV5%2FamBbilXcHRTqpwCCWA%3D%3D&trk=public_jobs_jserp-result_search-card,"We are looking for
Machine Learning Developer
Job Responsibilities
Working on machine learning projects
Analyzing and processing data to create machine learning models
Implementing and optimizing machine learning algorithms
Testing and evaluating models
Collaborating with the programming team and other departments within the company to develop innovative solutions
Requirements
Minimum 2 years of experience in the field of machine learning
Knowledge of machine learning algorithms and techniques
Ability to analyze and process data
Familiarity with machine learning tools and technologies
Proficient in English communication
Education in computer science
We Offer
B2B contract type
Full-time employment
Remote and flexible working hours
Show more
Show less","{'ProgLanguage': ['R', 'Go'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Machine Learning'], 'FrSoftSkills': ['Communication'], 'EnSoftSkils': ['Communication']}","{'JobDetail': ['Remote', 'Full'], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's']}"
Data Scientist H/F,Harry Hope.,"Nancy, Grand Est, France",https://fr.linkedin.com/jobs/view/data-scientist-h-f-at-harry-hope-3917429026?position=59&pageNum=0&refId=lBTWbVudNP%2F9XLZiNl1XvQ%3D%3D&trackingId=mbQHFJkYV14nOSpqQ55Jbg%3D%3D&trk=public_jobs_jserp-result_search-card,"Jean, consultant spécialisé sur les métiers de l'IT sur la lorraine au sein du cabinet de recrutement Harry Hope accompagne les candidats dans leurs recherches d'une meilleure opportunité professionnelle sur leur secteur géographique privilégié. Nous ne sommes pas une ESN, nous intervenons dans la mise en relation avec des clients finaux sur des postes en CDI. Notre client, une société en pleine croissance dans le secteur de l'IA, recherche un Data Scientist (H/F) pour compléter son équipe dédiée.
Intégré à une équipe technique composée de Data scientist, de développeurs et de chercheurs, vous aurez l'occasion d'intervenir dans la récupération, l'exploitation, la modélisation, l'évaluation et l'interprétation de données stockées dans les bases de données de la structure permettant de les exploiter selon les besoins. En parallèle de vos missions concernant les données propre à l'activité principale de l'entreprise, vous intervenez également dans l'exploitation et la structuration des datas récupérées sur internet en lien avec l'IA en cours de développement.
Diplômé en informatique, vous disposez à minima d'une première expérience à un poste similaire (alternance ou premier emploi). Techniquement, vous avez une grande expertise en statistiques et en mathématiques appliquées. Vous maitrisez les domaines du Big Data, du machine learning et de la programmation informatique (Python, Java, R, SQL). Humainement, vous êtes reconnu pour votre dynamisme, votre flexibilité et votre engagement. Vous êtes capable de vous impliquer à fond dans les projets qui vous sont confiés et vous appréciez le travail collaboratif. Passionné par la Data, vous assurez une veille constante sur les nouvelles technologies en lien avec votre activité. Enfin, vous maitrisez l'anglais à l'oral comme à l'écrit.
Informations complémentaires : Salaire selon profil et expériences (38/42kEUR), possibilité d'évoluer rapidement, CDI à pouvoir rapidement à Nancy.
Si cette opportunité correspond à vos aspirations professionnelles alors faites-moi parvenir votre candidature. J'étudierai cette dernière et reviendrai vers vous dans les meilleurs délais pour un suivi personnalisé de votre profil !
Show more
Show less","{'ProgLanguage': ['Python', 'Java', 'R'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': ['Statistiques'], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Big Data', 'Machine Learning', 'Statistiques'], 'FrSoftSkills': ['Flexibilité'], 'EnSoftSkils': []}","{'JobDetail': [], 'TypeContract': ['CDI'], 'Salary': ['38'], 'Level': [], 'Experience': ['a', 'n', 's']}"
DATASCIENTIST,GROUPE ALLIANCE,"Île-de-France, France",https://fr.linkedin.com/jobs/view/datascientist-at-groupe-alliance-3916080098?position=60&pageNum=0&refId=lBTWbVudNP%2F9XLZiNl1XvQ%3D%3D&trackingId=N5XZlrMQw3F8lUSYY5%2FM2A%3D%3D&trk=public_jobs_jserp-result_search-card,"SI LA GESTION DES DONNEES EST TON DADA, TU PEUX GAGNER LA COURSE EN LISANT CETTE ANNONCE …
Ce que tu recherches :
au sein d’une équipe dynamique
à des projets innovants d’envergure
des défis
un nouveau souffle à ta carrière
Alors nous avons la mission idéale pour toi.
Au sein d’acteurs majeurs du secteur Bancaire, tu participeras des projets d’envergure sur des évolutions majeures à mettre en œuvre dans le SI du client :
des besoins, tu feras
techniques, tu rédigeras
et/ou socle technique, tu définiras
pratiques, tu instaureras
nouvelles fonctionnalités, tu développeras
bug, tu laisseras
équipe, tu accompagneras
instances de pilotage, tu participeras
Qui tu es :
de la formation qui va bien
ou dôté(e) d’une expérience de 3 ans minimum
de la Stack technique machine learning et python
avec les Frameworks et Outils : Ttensorflow, pytorch,scikit-learn, numpy, pandas
Au-delà des compétences techniques, tu es :
: tu n’aimes pas rester les deux pieds dans le même sabot
: un guide du Routard te suffira
de synthèse : tu sais aller à l’essentiel
d’adaptation : tu es un vrai caméléon
de la communication : les mots n’ont pas de secret pour toi
de proposition : tu es l’Aladdin de l’informatique
d’équipe : un pour tous et tous pour un !
Show more
Show less","{'ProgLanguage': ['Python', 'R'], 'DataBase': [], 'DataAnalytics': ['Pandas', 'NumPy', 'R'], 'BigData': [], 'MachingLearning': ['Scikit-Learn', 'TensorFlow', 'PyTorch'], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Machine Learning'], 'FrSoftSkills': ['Communication'], 'EnSoftSkils': ['Communication']}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's', '3', '3', '3']}"
Data Scientist H/F,MERITIS,"Île-de-France, France",https://fr.linkedin.com/jobs/view/data-scientist-h-f-at-meritis-3869246366?position=1&pageNum=2&refId=S1z0rLITVg9wz0fKVsEOAQ%3D%3D&trackingId=1MQ0NVky3A9c6dXNVQs8wA%3D%3D&trk=public_jobs_jserp-result_search-card,"Nous recherchons un
Data Scientist
pour intervenir dans le cadre d'un
projet de détection de document.
Vos missions :
Sujet de
fraude documentaire:
la problématique est de détecter si un document (RIB ou pièce d’identité) a été manipulé (montage, remplacement de la photo d’identité, changement du nom/prénom, ou de l’IBAN etc).
Les technos connues utilisées:
Python avec les libs/framework suivants : pytorch, jupyterlab, pandas
Modèles : layoutLM (techno à priori assez récente), yolo, resnet (classique), docTR (ocr)
Connaitre les transformers
Autre : Labelstudio
Ce poste est-il fait pour vous
? :
Vous êtes diplômé d'un
Bac +5
et justifiez d'
au moins 4 ans d'expérience
Vous êtes
proactif et autonome ​
Vous aimez travailler
au contact de plusieurs équipes métiers
Connaissance du secteur de l'assurance obligatoire
Descriptif de l’entreprise :
​
Meritis est un cabinet de conseil, pilotage et développement IT fondé en 2007 présent à Paris, Sophia-Antipolis, Aix-en-Provence, Montpellier, Toulouse, Nantes... Et bientôt sur de nouveaux territoires ! Notre mission ? Connecter les meilleurs talents aux entreprises pour leur donner un temps d’avance.​
Nous accompagnons nos clients dans l’intégralité de leurs besoins en transformation numérique à travers de nombreux domaines d’expertises : Software Engineering, Finance, Pilotage de projets, Devops, Data, Cloud, Cybersécurité ou encore Agilité.​
Intervenant aussi bien dans les secteurs de la Banque, de l'Assurance, des Télécommunications que de l'Industrie ou des Transports, aujourd'hui 40% des entreprises du CAC40 sont clientes Meritis.​
Fort de nos valeurs d’exigence, d’humilité, de bienveillance et de proximité, nous comptons aujourd’hui plus de 900 collaborateurs.​
Nous mettons un point d’honneur à être proche de nos collaborateurs et à les accompagner de manière individualisée quelles que soient leurs fonctions dans l’entreprise.
Certifiée Great Place To Work depuis 2013, notre conception du bien-être au travail va bien au-delà d'un simple label, ce sont nos collaborateurs qui en parlent le mieux : https://www.glassdoor.fr/Avis/Meritis-Avis-E1163008.htm.​
Vos différences sont nos atouts. C’est pourquoi Meritis est engagée en faveur de la diversité et de la non-discrimination. Tous nos métiers sont accessibles aux personnes en situation de handicap. Si vous avez une question ou pensez être victime ou témoin d’une discrimination, vous pouvez contacter ethiquegroup@meritis.fr. »
Show more
Show less","{'ProgLanguage': ['Python', 'R'], 'DataBase': [], 'DataAnalytics': ['Pandas', 'R'], 'BigData': [], 'MachingLearning': ['PyTorch'], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['DevOps', 'Cloud'], 'FrSoftSkills': ['Communication'], 'EnSoftSkils': ['Communication']}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's', '4', '4', '4']}"
Data Scientist: Flexible working,SoftwareOne,"Levallois-Perret, Île-de-France, France",https://fr.linkedin.com/jobs/view/data-scientist-flexible-working-at-softwareone-3872563771?position=2&pageNum=2&refId=S1z0rLITVg9wz0fKVsEOAQ%3D%3D&trackingId=wGBlkl6HYUFUQksGDYuArQ%3D%3D&trk=public_jobs_jserp-result_search-card,"Why SoftwareOne?
SoftwareOne is a leading global software and cloud solutions provider that is redefining how companies build, buy and manage everything in the cloud. By helping clients to migrate and modernize their workloads and applications – and in parallel, to navigate and optimize the resulting software and cloud changes – SoftwareOne unlocks the value of technology. The company’s 8,900 employees are driven to deliver a portfolio of 7,500 software brands with sales and delivery capabilities in 90 countries. Headquartered in Switzerland, SoftwareOne is listed on the SIX Swiss Exchange under the ticker symbol SWON. Visit us at https://www.softwareone.com/en
The role
DATA Scientist
The primary focus for a candidate will be in applying different techniques (data mining/statistical analysis/build prediction systems/recommendation systems) using large company data sets to find opportunities for services and products and using models to test the effectiveness of different courses of action. The Candidate must have strong experience using a variety of data mining/data analysis methods, using a variety of data tools, building and implementing models, using/creating algorithms and creating/running simulations.
Work with business cases to identify opportunities for leveraging company data to drive business solutions.
Mine and analyze data from company databases to drive optimization and improvement of product development and sales techniques
Assess the effectiveness and accuracy of new data sources and data gathering
Extending company’s data with third party sources of information when needed
Use predictive modeling to increase revenue generation, ad targeting and other business outcomes.
What We Need To See From You
Core:
Analyze business cases and identify data sources (internal/external) and data mining/analysis methods to use
Develop a normalization engine to execute cleansing/deduplication for a raw data through ETL process for data sources
Create, train and test predictive models to solve defined business cases
Develop algorithms to apply to data sets
Design data structure models for collected data
Facilitate the build of a solution from PoC to production
Work with business owners to gather additional information about business cases
Job Specific:
Work with Google Cloud data and AI tools
Be ready to work in agile style (daily, sprint planning, sprint review, retrospective)
Work in an environment that adapts quickly to creative change using agile principles
Actively work with different development groups inside of organization
Be ready to adapt a new tool/library/technology/platform
Desirable Skills:
Fluent in French and English
At least 4 years experience in Machine learning models creation
Master’s in Statistics, Mathematics, Computer Science preferred
Professional Machine learning engineering certification
Experience with common data science toolkits and libraries, such as pandas, keras, scipy, scikit, tensorflow, NumPy etc
Knowledge and interest in the following:
prediction models, Vertex AI, Tenserflow, BigQuery ML, Python,
natural language processing, deep learning models, dataPROC, Hadoop, SQL
Experience using statistical computer languages namely Python to manipulate data and draw insights from large data sets
Strong knowledge and experience using SQL language
Experience with C++/C# and Java as a plus
Background in technology or professional services preferably in one or more of the domains of GCP and Security,
Strong understanding of consulting business
Strong structural work methods, multitasking and time management skills
Self-driven independent work ethics that drives internal and external accountability
May require periodic travel for workshops
Job Function
Software & Cloud Services
Show more
Show less","{'ProgLanguage': ['Python', 'Java', 'C++', 'C#', 'R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['Pandas', 'NumPy', 'R'], 'BigData': ['Hadoop'], 'MachingLearning': ['TensorFlow', 'Keras'], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': ['Statistics'], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'DBMS': ['BigQuery'], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['ML', 'Machine Learning', 'Cloud'], 'FrSoftSkills': [], 'EnSoftSkils': ['Time Management', 'Organization']}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's']}"
Data Scientist,Capital Fund Management (CFM),"Paris, Île-de-France, France",https://fr.linkedin.com/jobs/view/data-scientist-at-capital-fund-management-cfm-3911800992?position=3&pageNum=2&refId=S1z0rLITVg9wz0fKVsEOAQ%3D%3D&trackingId=ZtngvvQtBAJWxzTn3w0UgQ%3D%3D&trk=public_jobs_jserp-result_search-card,"ABOUT CFM
Founded in 1991, we are a global quantitative and systematic asset management firm applying a scientific approach to finance to develop alternative investment strategies that create value for our clients.
We value innovation, dedication, collaboration and the ability to make an impact and together we create an environment for talented and passionate experts in research, technology and business to explore new ideas and challenge assumptions.
ABOUT THE ROLE
The context :
Data is the fuel that powers our investment strategies: intraday price dynamics are used to better our investment decisions; buy/sell intents of market participants help to trade at the best available price… Cfm Data team is in charge of preparing the data to make quant research easier and trading more reliable.
The position
As a Data Scientist and Tick Data Specialist, your involvement will be crucial to the effectiveness of our strategies. You will be tasked with identifying and specifying new input features from tick data to fuel our alpha predictor, constructing data pipelines, and guaranteeing their smooth functioning. This role necessitates strong collaboration with researchers, primarily aimed at furnishing them with essential data and tools to refine our trading strategies.
Key Responsibilities:
You collaborate with the research team to innovate and introduce new predictive features,
You provide functional and technical support to quantitative researchers,
You design and develop data pipelines,
You contribute to the enhancement of our platform tooling.
SKILLSET REQUIREMENTS/QUALIFICATIONS
You boast significant experience in financial markets, with a tenure of 7 years or more.
You have a comprehensive expertise in Matching Engines, Orderbooks, and High-Frequency Data,
You demonstrate recognized expertise in data science with a thorough mastery of its tools.
Your familiarity with big data technologies like Spark or Dask, coupled with proficiency in machine learning, would be highly advantageous.
Experience with C++ is considered an additional asset.
You exhibit a strong enthusiasm for technology.
As a collaborative team player, you excel in communication, particularly with quant teams.
Proficiency in French is an additional advantage.
EQUAL OPPORTUNITIES STATEMENT
We are continuously striving to be an equal opportunity employer and we prohibit any discrimination based on sex, disability, origin, sexual orientation, gender identity, age, race, or religion. We believe that our diversity, breadth of experience, and multiple points of view are among the leading factors in our success.
CFM is a signatory of the Women Empowerment Principles
FOLLOW US
Follow us on Twitter and LinkedIn or visit our website to find out more about CFM.
Show more
Show less","{'ProgLanguage': ['C++', 'R'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': ['Spark'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': ['Teams'], 'Other': ['Big Data', 'Machine Learning'], 'FrSoftSkills': ['Communication', 'Collaboration'], 'EnSoftSkils': ['Communication', 'Collaboration']}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's']}"
Data Scientist,Keley Consulting,Greater Paris Metropolitan Region,https://fr.linkedin.com/jobs/view/data-scientist-at-keley-consulting-3908861590?position=4&pageNum=2&refId=S1z0rLITVg9wz0fKVsEOAQ%3D%3D&trackingId=LgHagtFhe6wrtXZesVraig%3D%3D&trk=public_jobs_jserp-result_search-card,"Data Scientist F/H
Description de l'offre d'emploi
Au sein de la practice data, vous accompagnerez nos clients dans la gestion, l’analyse et l’exploitation de leur données notamment grâce au développement de modèles IA et la mise en production de ceux-ci.
Responsabilités
Vous interviendrez dans des secteurs variés sur des problématiques telles que :
Evaluer les solutions technologiques liées à la data en effectuant des benchmarks
Collecter, traiter et analyser des données volumineuses
Communiquer efficacement les résultats des analyses
Créer de la valeur à partir des données en utilisant l’intelligence artificielle et la Data Science
Travailler en étroite collaboration avec les métiers afin de comprendre leurs besoins et les impliquer dans le développement des outils IA
Déployer les outils développés en environnement de prod (MLOps)
A titre d’exemple, nous avons récemment mené les missions suivantes :
Développement d’outils d’optimisation des revenus pour le compte d’une compagnie aérienne
Etude de l’impact du traitement de plaintes sur la customer lifetime value
Industrialisation de proof-of-concepts (ML Ops)
Développement de GPTMaker, un outil de création de chatbot s’appuyant sur des LLM
Profil recherché
Diplôme Bac+5 type école d’ingénieur ou université en Data Science / Statistiques
Expérience de 2 à 5 ans en Data, avec au moins 1 an en tant que Data Scientist / Engineer
Maîtrise des méthodes statistiques et leurs applications opérationnelles, ainsi que Python/Spark
Forte capacité d’organisation, d’analyse, d’écoute et de communication tout en étant force de conviction
Anglais courant
Qualifications supplémentaires (atouts) :
Expérience avec les outils du cloud (GCP, Azure, AWS …)
Expérience dans le NLP (natural language processing)
Pourquoi rejoindre Keley ?
Keley est un cabinet de conseil à taille humaine.
Accélérateur de projet, nous accompagnons nos clients sur des programmes de transformation digitale & Data en apportant sens et performance. Autour de méthodologies produits issues du design et orientées résultat, nous cocréons avec nos clients en les accompagnant dans toutes les étapes de leurs projets, jusqu’à l’autonomie.
Parce que les Humains sont au cœur de la transformation digitale des entreprises, celle-ci est aussi culturelle : nous alignons stratégie produit, culture métiers et modèles opérationnels pour concevoir avec nos clients des solutions qui leur ressemblent et qui font le succès de leurs projets.
Nos valeurs
Passionnés par notre métier, nous sommes des consultants en transformation digitale avec un sens aigu de l’engagement et du partage.
Dans un esprit coopératif et chaleureux, chaque collaborateur pourra trouver sa place, évoluer au cœur de nos métiers et atteindre ses objectifs grâce à des parcours de carrière évolutifs, clairs et transparents.
Nous croyons en la valeur de la diversité et de l'inclusion et encourageons les candidats de tous horizons à postuler.
Keley vous propose une carrière passionnante dans un environnement stimulant, en vous permettant de travailler avec des grands comptes et sur des missions variées.
Pour vous offrir le meilleur environnement de travail possible, nous vous proposons :
Un parcours de carrière clair et partagé pour évoluer rapidement au sein du cabinet
Une politique de rémunération transparente et équitable
Une charte de télétravail
Des bureaux au cœur de Paris dans le 8ème arrondissement
Des mentors et des buddys à l’écoute
Des évènements de team building réguliers
Une direction et un management toujours disponibles pour échanger (organisation flat)
Un programme de formation adapté à vos besoins et incluant des formations externes certifiantes
Des méthodes et outils de partage de connaissance pour vous nourrir mais aussi vous offrir une tribune : conférences internes hebdomadaires, articles, livres blancs, enquêtes et contenus vidéo
Un MacBook car on aime les belles choses (surtout quand elles marchent bien)
Une carte tickets restaurants
Une prise en charge de la mutuelle à 100%
Une prime de vacances
Show more
Show less","{'ProgLanguage': ['Python', 'R'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': ['Spark'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': ['Statistiques'], 'CloudComputing': ['AWS', 'Azure'], 'DevTools': ['Git'], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['ML', 'Statistiques', 'Cloud'], 'FrSoftSkills': ['Communication', 'Collaboration', 'Organisation'], 'EnSoftSkils': ['Communication', 'Collaboration']}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': ['Bac+5'], 'Experience': ['a', 'n', 's', '5', '5', '5']}"
Machine Learning Engineer,HackerPulse,France,https://fr.linkedin.com/jobs/view/machine-learning-engineer-at-hackerpulse-3917868826?position=5&pageNum=2&refId=S1z0rLITVg9wz0fKVsEOAQ%3D%3D&trackingId=GsGVdBtiEzONCYbNvhwQuA%3D%3D&trk=public_jobs_jserp-result_search-card,"Showcase your software engineering talents using ML-powered profiles. Loved by 11k+ engineers! Backed by Antler.
The Role
You Will Be Responsible For
Developing scripts to process structured and unstructured data.
Recommending, developing and implementing ways to improve data reliability, efficiency and quality.
Supporting translation of data business needs into technical system requirements.
Working with stakeholders to understand needs in order with respect to data structure, availability, scalability and accessibility.
Developing high-quality code to build and deploy machine learning models.
Ideal Profile
You possess a degree in Computer Science, Applied Mathematics, Engineering or related field.
You have at least 1 year experience, ideally within a Data Engineer role.
Demonstrated experience working with large and complex data sets as well as experience analyzing volumes of data.
You are a strong networker & relationship builder
You pay strong attention to detail and deliver work that is of a high standard
You are a self-starter and demonstrate a high level of resilience
What's on Offer?
Great work environment
Excellent career development opportunities
Leadership Role
Show more
Show less","{'ProgLanguage': ['Scala', 'R'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['ML', 'Machine Learning'], 'FrSoftSkills': ['Leadership'], 'EnSoftSkils': ['Leadership']}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's']}"
Data scientist H/F,MP DATA,"Clermont-Ferrand, Auvergne-Rhône-Alpes, France",https://fr.linkedin.com/jobs/view/data-scientist-h-f-at-mp-data-3904074177?position=6&pageNum=2&refId=S1z0rLITVg9wz0fKVsEOAQ%3D%3D&trackingId=8gpQHak5D4HLWGB8jIGzzQ%3D%3D&trk=public_jobs_jserp-result_search-card,"MP DATA est une société spécialisée dans l’acquisition, le traitement, et la valorisation des données. Depuis sa création en 2015, MP DATA accompagne ses clients, majoritairement industriels, dans le management de leur performance et l’exploitation de leur donnée.
Les collaborateurs, tous issus de grandes écoles, incarnent au quotidien les valeurs d’Excellence, de Partage et d’Engagement. Ils associent savoir-faire technique, méthodologie et passion et mettent leurs compétences au service de missions et projets au sein de grands groupes français.
MP DATA accompagne ses clients sur toute la chaine au travers de 3 pôles d’expertise : Conseil et Stratégie, Infrastructure & CloudOPS, Data Science.
Nous recherchons un(e) Data Scientist passionné(e) pour rejoindre notre équipe dynamique.
En tant que membre clé du pôle Data Science de notre client, un grand acteur du secteur automobile, vous serez chargé(e) d'analyser, interpréter et exploiter les données pour fournir des solutions innovantes à nos clients.
Conception et mise en œuvre de modèles prédictifs et d'algorithmes avancés.
Analyse approfondie des données pour identifier des tendances et des opportunités.
Collaboration étroite avec les équipes clients pour comprendre leurs besoins et définir des solutions sur mesure.
Participation active à la veille technologique et à l'amélioration continue de nos pratiques en Data Science.
Profil :
Diplôme
ingénieur Grande École
en Data Science, Statistiques, Informatique ou domaine connexe.
Expérience pratique dans le développement et l'application de modèles prédictifs,
Maîtrise des langages de programmation tels que Python,
Excellentes compétences analytiques et capacité à traduire des résultats complexes en recommandations claires,
Forte aptitude à travailler en équipe et à communiquer efficacement.
Show more
Show less","{'ProgLanguage': ['Python', 'R', 'Go'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': ['Statistiques'], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Statistiques', 'Cloud'], 'FrSoftSkills': ['Collaboration'], 'EnSoftSkils': ['Collaboration']}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's']}"
Data Scientist (H/F),moOngy Digital Lab,Greater Lille Metropolitan Area,https://fr.linkedin.com/jobs/view/data-scientist-h-f-at-moongy-digital-lab-3888669115?position=7&pageNum=2&refId=S1z0rLITVg9wz0fKVsEOAQ%3D%3D&trackingId=%2BgR3mJ%2Fwiwgx%2FEOPiYifUg%3D%3D&trk=public_jobs_jserp-result_search-card,"Web Transition, c’est qui ?
Fondée en 2011,
Web transition
est une entreprise de services numériques opérant sur le marché de l’IT/Digital !
Constituant une part essentielle de
MoOngy Digital Lab
, Web Transition accompagne ses clients grands comptes sur leurs projets de Webmarketing, de Design, Gestion de projet et également en Data !
Notre objectif : nous implanter comme un acteur principal sur le marché de la Transformation Digitale en accompagnant et valorisant les compétences de nos collaborateurs !
Nous sommes convaincus que le succès de MoOngy Digital Lab réside dans la somme des potentiels de nos équipes 🤝
Ton équipe : La tribu Data
Parce qu’il est indispensable que tu puisses partager tes connaissances mais aussi en acquérir de nouvelles, tu feras partie de l’une de nos tribus : celle de la Data. De plus, cela te permettra d’être acteur dans le développement et la stratégie de Web Transition. Ce système de co-réflexion et co-construction est un fondement essentiel chez nous !
Dans cette aventure, tu :
Recueilles, analyses et formalises
les demandes correspondant aux besoins spécifiques de chaque métier/utilisateur,
Contrôles, sélectionnes et valides
les données pertinentes pour l'analyse & s'assurer de la cohérence et de la structuration de celles-ci avant exploitation,
Conçois, mets en œuvre et déploies
des modèles Machine Learning (ML) et Deep Learning (DL) dans un environnement GCP (BigQuery ML/Vertex AI) : qualité, possibilités d'exploitation, suivi de performances et versioning des mis à jour du modèle en production,
Présentes
les résultats des études réalisées auprès de vos différents interlocuteurs et leur donner du sens, en s’appuyant sur des KPIs adaptés, via les outils de visualisation des données et/ou de documentation,
Améliores
l'efficacité de livraison des modèles ML/DL en industrialisant le processus de livraison et en automatisant la préparation des données, l’entraînement des modèles et leur déploiement,
Effectues
une veille technologique et maintenir une connaissance approfondie des dernières technologies liées au ML/IA.
Rejoins-nous si tu as :
Une expérience de 5 ans au minimum dans l'analyse de données/data science, et plus globalement dans le développement des modèles ML et DL & de préférence sur l'écosystème GCP,
Une maîtrise du langage Python et des librairies d’analyse (Pandas, NumPy et Matplotlib) et ML/DL (Scikit-Learn, TensorFlow, PyTorch, XGBoost),
Une connaissance de l’environnement Retail serait un plus !
Ton savoir-être :
Ouvert d’esprit
Respectueux des différences de chacun
Curieux
Proactif
Par où on commence ?
Un premier entretien RH d’1h pour comprendre ton parcours et tes aspirations
Un second entretien de 45 minutes avec l’un de nos Business Manager afin de valider tes compétences et qu’il se projette sur l’une des missions qu’il pourrait te proposer
Un troisième entretien de quelques minutes avec notre responsable d’agence pour te proposer d’intégrer notre superbe Team Web !
3 entretiens en peu de temps, si ton profil correspond tu intègreras très vite nos équipes 😉
Prêt pour embarquer dans notre grande aventure humaine ? Deviens notre futur Weber en postulant à cette offre ! Voici les avantages qui t’attendent en tant que Weber :
🤩 Des collègues incroyables
🏆 Certifiée Great Place to Work
🎮 Des bureaux sympas (où vous serez toujours les bienvenus)
🎉 Des teambuilding et évents tous les mois
💻 Des tributs métiers pour échanger entre Weber du même métier
Des missions chez le client qui sont accompagnées et coachées par ton manager
Un accompagnement dans ton plan de carrière et tes envies de re skilling
🤓 Un catalogue de formations certifiantes ouvert à tous les salariés
🍽️ Une carte tickets restaurant MyEdenred
❤️ Une mutuelle GrasSavoye
🚎 Une prise en charge des frais de transport à 100%
Show more
Show less","{'ProgLanguage': ['Python', 'R'], 'DataBase': [], 'DataAnalytics': ['Pandas', 'NumPy', 'R'], 'BigData': [], 'MachingLearning': ['Scikit-Learn', 'TensorFlow', 'PyTorch', 'XGBoost'], 'DataSerialization': [], 'DataVisualization': ['Matplotlib'], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git'], 'Os': [], 'DBMS': ['BigQuery'], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['ML', 'Machine Learning'], 'FrSoftSkills': [], 'EnSoftSkils': []}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's', '5', '5', '5']}"
Data Scientist F/H,OUTSCALE,"St.-Cloud, Île-de-France, France",https://fr.linkedin.com/jobs/view/data-scientist-f-h-at-outscale-3891855564?position=8&pageNum=2&refId=S1z0rLITVg9wz0fKVsEOAQ%3D%3D&trackingId=JGMe1zv%2B0nWaFz5YxeBpmw%3D%3D&trk=public_jobs_jserp-result_search-card,"OUTSCALE, marque de Dassault Systèmes, est un opérateur souverain et durable de l Expérience en tant que Service qui offre à ses clients des environnements technologiques de confiance.
Nous offrons des expériences uniques grâce au savoir-faire de nos équipes passionnées, qui se reflète notamment par la création de solutions de Business Expériences, le développement de notre propre orchestrateur Cloud, TINA OS, ou encore l obtention de la qualification SecNumCloud.
Notre mission ? Bâtir un monde numérique accessible et meilleur pour tous à travers la création du jumeau virtuel de l organisation.
Nous menons une politique RH engagée et inclusive favorisant le bien-être de nos collaborateur·rices : respect de l équilibre vie privée/vie professionnelle, développement personnel et des compétences professionnelles, onboarding complet
Nous rejoindre, c est partager une passion pour l innovation, des valeurs communes et imaginer ensemble des solutions de confiance pour construire un monde meilleur et durable !
Nous recrutons
un·e
Data Scientist
afin de renforcer notre équipe
Business Experience
.
Vos missions
Analyser des problématiques et proposer des solutions.
Modéliser, implémenter et évaluer des algorithmes.
Traiter des données non structurées.
Optimiser des modèles ML/DL pour la scalabilité, l'efficacité et les performances.
Industrialiser des algorithmes dans les services API.
Déployer des services sur le cloud.
Participer à la rédaction de spécifications et documentations techniques.
Participer à des événements et publications scientifiques.
Stack technique
Python
Frameworks ML/DL (Pytorch)
Architectures de réseaux neuronaux (LLMs)
Implémentation d’algorithmes ML/DL (apprentissage supervisé/non-supervisé)
Votre profil:
Diplômé·e d’un Master en Intelligence Artificielle, Machine Learning.
3 ans d’expérience minimum post-diplôme dans le domaine de l’IA, Data Science, Machine Learning, NLP, Computer Vision.
Vous maîtrisez l’analyse et la transformation des données.
Idéalement, vous avez de l’expérience dans le déploiement des modèles ML/DL sur le cloud.
Motivé·e, organisé·e, curieux·se, vous appréciez travailler en équipe.
La Diversité d’OUTSCALE trouve aussi son expression dans notre politique de recrutement qui privilégie l’égalité des chances, la diversité des individus au sein de nos équipes.
Show more
Show less","{'ProgLanguage': ['Python', 'Scala', 'R', 'Go'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': ['PyTorch'], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['ML', 'Machine Learning', 'Cloud'], 'FrSoftSkills': ['Organisation'], 'EnSoftSkils': []}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's', '3', '3', '3']}"
DATA SCIENTIST (CDI),STATION F,"Annecy, Auvergne-Rhône-Alpes, France",https://fr.linkedin.com/jobs/view/data-scientist-cdi-at-station-f-3918628446?position=9&pageNum=2&refId=S1z0rLITVg9wz0fKVsEOAQ%3D%3D&trackingId=eWPmXEDEmgxF%2FSW6e8AL7A%3D%3D&trk=public_jobs_jserp-result_search-card,"À propos
Campsider est la 1ère marketplace dédiée aux équipements de sport d’occasion, sélectionnés et garantis (vélo, ski, randonnée, trail-running, escalade, alpinisme).
Lancé début 2021 par deux passionnés de sport (ex HEC et emlyon), la plateforme recense plus de 150 000 utilisateurs et 200 000 articles en vente en moins de 3 ans. Soutenu par des athlètes professionnels de renom (Mathieu Blanchard, Camille Bruyas ou encore Victor Galuchot), la start-up est aussi devenue le partenaire privilégié des marques de sport (Millet, Osprey, Mavic, ZAG Ski) pour valoriser leur seconde main.
Leur mission : rendre accessible l’aventure et protéger nos terrains de jeu grâce à une consommation plus responsable.
Avec l’objectif de s’imposer comme la plateforme de référence des sportifs engagés qui souhaitent s’équiper moins cher et plus durable, la plateforme a levé plus de 5m€ auprès d’investisseurs réputés dont le fonds Founders Future (Marc Menasé) et des investisseurs privés (fondateur Vestiaire Collective, fondateur Selency, C-level Salomon, etc) et a été sélectionnée au Future40 de Station F.
Descriptif du poste
En tant que
Data Scientist
, rattaché aux fondateurs, tu seras la pierre angulaire du sujet catalogue / PIM au sein de Campsider pour définir la stratégie data et l'enrichissement des produits présents sur le site.
Concrètement, quelles seront tes missions ?
1/
Optimiser les connexions marchands
Gestion et optimisation des process de mise en ligne et de mise à jour des catalogues partenaires sur la plateforme ;
Uniformisation et standardisation de la donnée partenaire ;
2/
Enrichissement de la data produit
Garant de la qualité permanente du contenu produit et de l’enrichissement des données catalogues ;
Optimisation des process de catégorisation, taxonomie, mapping, remplissage d’attribut et de mise en forme du contenu partenaire pour valoriser les produits. KPI clé : taux de remplissage attribut et taux de conversion ;
Définition et mise en place d’une stratégie d’enrichissement automatiques des attributs techniques des produits mis en ligne sur la plateforme. KPI clé : taux de remplissage attribut et taux de conversion ;
3/
Manager
Gestion de l’équipe Catalog Enricher (2 personnes).
Profil recherché
Tu as de bonnes connaissances dans la transformation des données (ETL), la conception de modèles de données et les stratégies d'optimisation des requêtes
Tu as des compétences en DevOps pour le déploiement et la gestion efficace des pipelines de données
Tu as une bonne maîtrise de Python, SQL & Github
Tu maîtrises l’un des data warehouse suivants : BigQuery, Refshift, Snowflake, Synapse Analytics
Tu es passionné(e) de sport !
Process de recrutement
Un 1er entretien court (20 minutes) par téléphone ou visio
Un 2ème entretien physique avec les fondateurs (1h)
Un café avec l'équipe !
Informations complémentaires
Type de contrat : CDI
Lieu : Annecy, Paris
Télétravail ponctuel autorisé
Show more
Show less","{'ProgLanguage': ['Python', 'Scala', 'R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git'], 'Os': [], 'DBMS': ['Snowflake', 'Snowflake', 'BigQuery'], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['DevOps', 'ML'], 'FrSoftSkills': [], 'EnSoftSkils': []}","{'JobDetail': [], 'TypeContract': ['CDI'], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's', '3', '3', '3']}"
Data Scientist H/F,IT&M STATS,"Île-de-France, France",https://fr.linkedin.com/jobs/view/data-scientist-h-f-at-it-m-stats-3803674187?position=10&pageNum=2&refId=S1z0rLITVg9wz0fKVsEOAQ%3D%3D&trackingId=4UUzj8YGAEsYLkWhXzj2ag%3D%3D&trk=public_jobs_jserp-result_search-card,"IT&M Stats intervient dans le domaine des statistiques, de la programmation et de la data science, principalement dans les secteurs de l’Industrie Pharmaceutique, Cosmétique, dans la Santé et l’Agro-alimentaire et auprès des Banques et Assurances. IT&M Stats est une filiale du Groupe Astek, acteur mondial de l’ingénierie et du conseil en technologies.
Nous basons notre relation sur :
Un respect des collaborateurs et des clients, de leurs aspirations,
Un suivi personnalisé des collaborateurs et des clients,
Une gestion régulière des carrières des collaborateurs,
Des échanges transparents,
Une réactivité, une disponibilité et une écoute permanentes.
Nous recherchons un
Data Scientist
pour intervenir dans le secteur
cosmétique
.
Cela vous intéresse ? Voici la suite !
👇
Maintenance et mise à jour de dashboards de suivi de tests sous PowerBi
Analyser les données générées en interne et externe et réaliser des analyses croisées /meta analyse pour une meilleure compréhension de la performance de nos produits/services
Réaliser des analyses prédictives de la performance cosmétique en fonction de la formulation
Réaliser des interfaces dynamiques sous R Shiny
Ré-analyser et vérifier les analyses statistiques réalisées par les prestataires externes le cas échéant
Contribuer à la mise en place des études et aider le département à l’amélioration des process (Plan d’expérience, calcul du nombre de sujets nécessaires, etc…)
Vous pensez être la perle rare ?
Vous êtes titulaire d’un diplôme de type Bac+5 (Master 2 ou école d’ingénieur) avec une spécialisation en statistiques, mathématiques ou data science
Vous justifiez d’une expérience professionnelle de 2 à 3 ans
Une bonne maitrise de R (dont R Shiny) est attendue
Vous maitrisez PowerBI
Vous êtes organisé, rigoureux, autonome, flexible, vous aimez communiquer et travailler en équipe et vous avez un bon esprit de synthèse et d’analyse
Vous avez un bon niveau d’anglais
🍀
Voici ce que nous pouvons vous offrir…
Un poste en CDI à pourvoir dès que possible, de la bonne humeur, des formations, des soirées, de la bienveillance, un suivi personnalisé, une gestion régulière de votre carrière, des échanges transparents et une écoute permanente.
Si vous êtes convaincu que vous êtes la perle rare, postulez ! Nous sommes impatients de vous rencontrer.
Show more
Show less","{'ProgLanguage': ['R', ' R ', 'Go'], 'DataBase': [], 'DataAnalytics': ['R', ' R '], 'BigData': [], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': ['PowerBI'], 'Statistics': ['Statistiques'], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Statistiques'], 'FrSoftSkills': [], 'EnSoftSkils': []}","{'JobDetail': [], 'TypeContract': ['CDI'], 'Salary': [], 'Level': ['Bac+5'], 'Experience': ['a', 'n', 's', '3', '3', '3']}"
Data Scientist H/F,ADHERENCE CONSULTING,"Capinghem, Hauts-de-France, France",https://fr.linkedin.com/jobs/view/data-scientist-h-f-at-adherence-consulting-3913994542?position=1&pageNum=5&refId=l6Zpg44EBlmc2ek5NGQhDA%3D%3D&trackingId=caioBwxuBI18uDsAWslSQQ%3D%3D&trk=public_jobs_jserp-result_search-card,"Adherence Consulting : Votre partenaire IT de choix !
Implantés à Paris, Lille et Marseille, nous sommes au coeur de l'innovation technologique et organisationnelle.
Notre mission ? Booster votre performance et vous accompagner dans chaque étape de votre transformation digitale.
Si vous êtes prêt(e) pour une carrière qui dépasse vos attentes, c'est le moment !
https://www.adherence-consulting.fr/
Les missions du poste
Contexte
Adhérence Consulting est une ESN implanté à Paris, Lille et Marseille. Nous sommes au coeur de l'innovation technologique et organisationnelle.
Notre mission ? Booster les performances et accompagner nos clients à chaque étape de leur transformation digitale. Nous cherchons actuellement un Data Scientist (F/H) pour le projet de notre client.
Vous participerez à la construction de nombreux projets tous aussi ambitieux les uns que les autres.
Quelles sont vos missions au quotidien ?
Applique des techniques (statistiques, text mining, comportementale, géolocalisation,) d'extraction et d'analyse d'informations, obtenues à partir de gisements de données (Big Data)
Obtient des données adéquates, trouve les sources de données pertinentes, fait des recommandations sur les bases de données à consolider, modifier, rapatrier, externaliser, internaliser, conçoit des datamarts, voire des entrepôts de données (data warehouses).
Évalue la qualité et la richesse des données, les analyse et en restitue les résultats pour ensuite les intégrer dans le système d'information cible du Métier.
Analyse les données pour traduire une problématique Métier en problème mathématiques/statistiques et réciproquement.
Compare et évalue différents modèles ou méthodes de calcul et anticipe les avantages et inconvénients dans un environnement Métier.
Intervenant auprès des Métiers, il exploite, analyse et évalue la richesse, de données structurées ou non, appartenant à l'entreprise ou non, pour établir des scénarios permettant de comprendre et d'anticiper de futurs levier Métiers ou opérationnels pour l'entreprise
Show more
Show less","{'ProgLanguage': ['R'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': ['Statistiques'], 'CloudComputing': [], 'DevTools': ['Git'], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Big Data', 'Statistiques'], 'FrSoftSkills': ['Organisation'], 'EnSoftSkils': []}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's']}"
Data Scientist (confirmé/sénior) - H/F - CDI,Talan,"Paris, Île-de-France, France",https://fr.linkedin.com/jobs/view/data-scientist-confirm%C3%A9-s%C3%A9nior-h-f-cdi-at-talan-3909648101?position=2&pageNum=5&refId=l6Zpg44EBlmc2ek5NGQhDA%3D%3D&trackingId=9NcQL7Q45i%2FezbwXP0yChA%3D%3D&trk=public_jobs_jserp-result_search-card,"Talan est un groupe international de conseil en transformation et en innovation par la technologie, créé en 2002.
Nos 5000 consultantes et consultants partagent à travers le monde l’audace d’innover, le goût de l’excellence, et l’envie de relever les défis les plus complexes.
Nous accompagnons les entreprises dans des secteurs variés : énergie, industrie, transport, finance, luxe… à travers 3 grandes expertises :
Le Conseil en Management et Innovation (320 Consultants en France)
La valorisation des données, leurs structurations, et leurs usages (Data et Technologies)
L’intégration de solutions logicielles (Cloud et Applications Services)
Nos valeurs : engagement, respect, partage, esprit d’équipe et optimisme.
Talan est une entreprise responsable, reconnue par ses collaborateurs et attachée à la diversité. Des aménagements peuvent être proposés si vous êtes en situation de handicap.
Retrouvez nos engagements RSEiciet nos actions en faveur de la diversitéici
Job Description
Nous sommes à la recherche d’un Data Scientist capable de participer à des projets techniques Data Science et IA. Vous devrez faire preuve d’un état d’esprit à la fois innovant, méthodique, orienté solution (et non problème!), et communiquant.
Votre but ultime sera de garantir l’excellence de vos solutions Data Science/IA, pièces maitresses de la réalisation de projets disruptifs pour nos clients.
VOTRE ROLE SUR NOS PROJETS
:
En mission: analyse des besoins métiers, définition des principes et méthodes de collecte et de traitement des données, choix des modèles de Machine Learning ou de Deep Learning, mise en application des techniques de traitement et de visualisation de la data, restitution des analyses et résultats obtenus auprès des métiers et des sponsors
Partager techniquement les membres de l’équipe: solutions et code reviews, recommandations, certifications à réaliser, …
Participation à des meet-up, coding dogo,…
Communication: écriture d’articles, retours d’expérience…
VOTRE ROLE CHEZ TALAN :
Benchmark de solutions et conseil auprès de nos clients sur les solutions technologiques à adopter, en lien avec leurs besoins
Réalisation de POC (Proof Of Concept)
Participation à des projets internes et partage de connaissances au sein de nos équipes.
Partage de connaissances et formations interne
Qualifications
VOTRE PROFIL:
Issu d’une formation Grande École d’Ingénieur/Doctorant, spécialisée en Data Science ou Intelligence Artificielle
Vous disposez d’au moins 3 années d’expérience dans le domaine
Maitrise des techniques d’analyses statistiques, de modélisations prédictives, de Machine Learning, de Deep Learning,...
Maitrise des techniques de data management et de DataViz
Maitrise de Python, R, RShiny, SQL…
Maitrise de l’utilisation des outils DevOps: Git, Docker, Jenkins/Nexus,…
Bonnes connaissances Big Data: pySpark, Spark, NoSQL…
Connaissance d’outils tels que Dataiku, AWS SageMaker, Azure ML,…
Autonomie, organisation, sens du partage
Excellente communication
Orientation métier
Additional Information
AVANTAGES
:
Plan de formation pour accompagner votre carrière (formations éditeurs, certifications) grâce à nos partenariats nous accordant une position de partenaire privilégié, et management de proximité par des experts
Locaux modernes en centre-ville
Top 5 du Palmarès Great Place to Work
Télétravail jusqu’à 5 jours selon les missions, prime d’équipement de 100€
Mobilité en France et à l’étranger
Top 1% des entreprises évaluées par Ecovadis dans le domaine social, environnemental et éthique
Tickets restaurant, prime vacances, 50% transport (abonnement transport public), mutuelle
Permanence handicap (consultant dédié aux collaborateurs en situation de handicap et aux proches aidants)
Actionnariat salarié
Prime de cooptations
RTT
PROCESS RECRUTEMENT
:
L’équipe recrutement s’engage à vous proposer un processus de recrutement rapide et fluide
1 entretien RHpar Teams (45min)
1 test technique
1 entretien opérationnel avec le responsable de domaine, au siège (1heure)
1 entretien avec le directeur de pôle, au siège(1heure)
Show more
Show less","{'ProgLanguage': ['Python', 'R', 'Go'], 'DataBase': ['SQL', 'NoSQL'], 'DataAnalytics': ['R'], 'BigData': ['Spark'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': ['Statistiques'], 'CloudComputing': ['AWS', 'Azure'], 'DevTools': ['Git', 'Docker', 'Jenkins'], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': ['Docker'], 'Collaboration': ['Teams'], 'Other': ['DevOps', 'Big Data', 'ML', 'Machine Learning', 'Statistiques', 'Cloud'], 'FrSoftSkills': ['Communication', 'Organisation'], 'EnSoftSkils': ['Communication']}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's']}"
Data Scientist (H/F),Assurances Crédit Mutuel,"Strasbourg, Grand Est, France",https://fr.linkedin.com/jobs/view/data-scientist-h-f-at-assurances-cr%C3%A9dit-mutuel-3881495295?position=3&pageNum=5&refId=l6Zpg44EBlmc2ek5NGQhDA%3D%3D&trackingId=pkDKgBvmqGaCLOgcaA3eDw%3D%3D&trk=public_jobs_jserp-result_search-card,"Qui sommes nous
Depuis 1971, nous imaginons, concevons et orientons les offres et services qui contribuent au développement de l’activité assurance de Crédit Mutuel Alliance Fédérale, inventeur du concept de bancassurance.
Les Assurances du Crédit Mutuel sont présentes sur les marchés des assurances de biens, des assurances de personnes comme de l’assurance-vie. Nous proposons des solutions à tous ceux qui désirent se protéger et anticiper demain, qu’ils soient particuliers, professionnels ou entreprises.
Ce sont nos valeurs mutualistes et notre philosophie innovante qui guident nos actions. Loin de nous contenter de couvrir nos assurés aujourd’hui, nous cherchons à prévenir les risques futurs et à construire une assurance de demain plus juste.
Les Assurances du Crédit Mutuel, ce sont ainsi environ 3500 talents au service de près de 13 millions d’assurés, générant un chiffre d’affaires de 13,9 milliards d’euros. Nos offres et services sont principalement distribués par les réseaux bancaires Crédit Mutuel, CIC et Cofidis. Nous sommes parmi les acteurs majeurs de l’assurance en France.
Rejoindre les Assurances du Crédit Mutuel, c’est rejoindre un groupe qui porte haut et fort ses valeurs et où l’humain est toujours au centre. C’est rejoindre une entreprise où les innovations sont sources de simplicité et de solidarité et où chacun est engagé pour une société plus juste et plus durable. Intégrer les ACM c’est également intégrer le groupe Crédit Mutuel Alliance Fédérale et ses multiples opportunités de carrières.
Pourquoi nous recrutons
Dans un contexte de recherche constante d'une croissance responsable et durable, Les assurances du Crédit Mutuel continuent d'innover, de se développer et de renforcer leurs équipes dans de nombreux domaines.
Vos missions
Au sein de la Direction du Développement, de la transformation et de la Communication, vous intégrez l'équipe « Data et connaissance client » pour mener des projets de data science visant à accompagner la transformation de l'entreprise et favoriser le développement via l’analyse des profils clients.
En intégrant cette équipe, vous prendrez en main des projets de data science, avec le cadrage des problématiques, le recueil et l’analyse des données nécessaires. Vous testerez et comparerez différents modèles et études de performances.
Vous jouerez un rôle majeur dans la connaissance et l’anticipation des besoins de nos clients et travaillerez ainsi en relation avec les autres services de la direction (marketing, parcours client, projets digitaux, …), avec les différents services métiers des ACM et la direction commerciale du Groupe.
Vous serez aussi amené(e) à mener des études en collaboration avec d’autres Data Scientists du Groupe.
Activités / Tâches spécifiques du poste
Vos missions seront entre autres les suivantes :
Détenir, comprendre et exploiter la connaissance client
Proposer et développer des outils statistiques prédictifs et prescriptifs tels que des scores d’appétence ou d’attrition en mettant en œuvre des techniques de type scoring et segmentation via l’utilisation de méthodes classiques (régression logistique …) ou plus innovantes de type machine learning (random forest …).
Analyser, interpréter et synthétiser les données pour dégager des tendances et constats qui alimenteront la compréhension et la réflexion au sein de la direction dans le cadre d’études spécifiques (profils clients …).
Identifier les données existantes et de nouvelles sources de données pertinentes à collecter pour enrichir la connaissance client et modéliser leur comportement (données internes ou externes, structurées ou non structurées).
Etablir les suivis de l’activité commerciale et analyser les performances des actions commerciales et marketing pour améliorer leur efficacité.
Participer à différentes missions de type veille et partage de connaissance
Assurer une veille active sur les sujets de type Big Data et modélisation de données.
Aider au partage de bonnes pratiques au sein du groupe en tant qu’expert des données et des méthodes de modélisation.
Contribuer à la diffusion des travaux de l’équipe au sein de l’entreprise
Pouvoir représenter l'activité en intervenant dans des groupes de travail transverses.
Restituer et communiquer régulièrement les résultats des analyses et les préconisations associées de manière rigoureuse, pédagogique, accessible et exploitable
Ce que vous allez vivre chez nous
Concrètement, aux Assurances du Crédit Mutuel, nos collaborateurs bénéficient:
D'une rémunération fixe versée sur 13 mois
De l'intéressement, participation et de l'abondement pouvant atteindre plus de deux mois de salaire en fonction des résultats du groupe
D'un plan épargne entreprise (PEE), d’un plan épargne retraite collectif (PERECOL) et d’un compte épargne temps (CET),
D'un rythme de travail adapté fort d'un accord QVT groupe qui permet de télétravailler jusqu'à deux jours par semaine
De 22 jours de RTT par an selon le rythme de travail défini
D'une politique de protection sociale renforcée (régimes de remboursement de frais de santé et de prévoyance)
D'un régime de retraite supplémentaire (PERO) prise en charge à 100% par l’employeur
De conditions bancaires et assurances préférentielles
D'une politique parentale avantageuse
D'un parcours d'intégration pour tout nouvel arrivant
D'au moins une action de formation chaque année (95% des salariés)
D'un accompagnement pour favoriser votre mobilité géographique et fonctionnelle.
Ce que nous allons aimer chez vous
Connaissances et compétences
De formation supérieure Bac+5 minimum orientée statistiques, mathématiques, Data Science.
Un minimum de six ans d’expérience à un poste équivalent est demandé.
Vous possédez une expertise confirmée en Python (pandas, scikit-learn) ainsi que des connaissances poussées en Data Science (random forest, boosting, classification …).
Vous maîtrisez des langages / outils de traitement et d’analyse de données (SQL, SAS, Excel, …)
Vous possédez des compétences en présentation (PowerPoint) et êtes capable de mettre en valeur votre travail.
Une expérience en assurance constituerait un plus.
Une expérience en compétition de Data Science ou programmation (Kaggle, leetcode ...) constituerait un plus.
Savoir-être - savoir-faire
Vous appréciez le travail en équipe et faîtes preuve d'une bonne aisance relationnelle.
Curieux, vous possédez un bon esprit d'initiative et vous tenez au courant des dernières nouveautés en terme de Data Science.
Vous possédez un esprit analytique et créatif et êtes en mesure d’imaginer et de proposer des solutions innovantes.
Rigoureux et autonome, vous disposez d'excellentes capacités d'analyse et de synthèse.
Show more
Show less","{'ProgLanguage': ['Python', 'R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['Pandas', 'R'], 'BigData': [], 'MachingLearning': ['Scikit-Learn'], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': ['Statistiques'], 'CloudComputing': [], 'DevTools': ['Git'], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Big Data', 'Machine Learning', 'Statistiques'], 'FrSoftSkills': ['Communication', 'Collaboration', ""Esprit d'initiative""], 'EnSoftSkils': ['Communication', 'Collaboration', 'Initiative']}","{'JobDetail': ['Confirmé'], 'TypeContract': [], 'Salary': ['22'], 'Level': ['Bac+5'], 'Experience': ['a', 'n', 's']}"
Data Scientist H/F,METEOJOB by CleverConnect,"Rennes, Brittany, France",https://fr.linkedin.com/jobs/view/data-scientist-h-f-at-meteojob-by-cleverconnect-3907968677?position=4&pageNum=5&refId=l6Zpg44EBlmc2ek5NGQhDA%3D%3D&trackingId=3O3JQ37r2ODgYweh9qjbWw%3D%3D&trk=public_jobs_jserp-result_search-card,"Entreprise
Qui sommes-nous ?
Nous sommes passionnés par les nouvelles technologies, et vous ?
Rejoindre Amiltone, c'est intégrer des équipes dynamiques et soudées dans le cadre de projets novateurs et ambitieux. Nous relevons les challenges techniques de nos clients et les accompagnons dans leur transformation digitale.
Pourquoi choisir Amiltone ?
Amiltone, plus qu'une entreprise, un état d'esprit !
Notre objectif ? Votre épanouissement professionnel !
Nous Avons à Cœur De
Vous accompagner au mieux au travers d'un suivi personnalisé
Vous faire monter en compétences en vous proposant des formations tout au long de votre carrière
Comprendre vos besoins et respecter nos engagements
Vous proposer des missions de qualité avec des technologies innovantes
Cultiver votre potentiel grâce à notre programme de développement personnel Addvise
Votre bien-être passe aussi par des activités extraprofessionnelles, c'est pourquoi nous vous proposons des séances sportives animées par nos coachs, soirées pour se retrouver et animations (à l'agence ou en visio), Gaming nights...
Description Du Poste
Vos missions ?
Intégré à notre équipe de 10 personnes, vous assurez les missions suivantes :
Réceptionner et analyser la donnée brute
Traiter la donnée en streaming ou en statique
Adapter ou créer des modèles de machine learning
Evaluer la précision/robustesse d'un modèle
Outils de monitoring et de visualisation
Développement des modèles
Maintenir et documenter les codes et les process
La stack Technique :
Outils : MongoDB, PostgreSQL
NLP (IA générative)
Qlik Sense
Docker, Jenkins
Gitlab/Github
Description Du Profil
Alors ? Prêt à devenir Amiltonien ?
N'hésitez Pas à Postuler Si Vous Vous Reconnaissez
Diplômé bac+5 (école d'ingénieur ou master), vous avez au moins 2 ans d'expérience en tant que Data Scientist.
Vous aimez découvrir de nouveaux contextes fonctionnels et comprendre les objectifs des applications que vous développez.
A l'aise dans une organisation agile, vous faites preuve de rigueur et appliquez les standards de qualité Amiltone durant toute la durée des développements.
Outre vos compétences techniques, nous nous intéressons également à votre potentiel et votre motivation.
Nos postes sont ouverts aux personnes en situation de handicap.
Show more
Show less","{'ProgLanguage': ['R', 'Go'], 'DataBase': ['SQL', ' MongoDB'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git', 'Docker', 'Jenkins'], 'Os': [], 'DBMS': ['PostgreSQL'], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': ['Docker'], 'Collaboration': [], 'Other': ['Machine Learning'], 'FrSoftSkills': ['Organisation'], 'EnSoftSkils': []}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': ['Bac+5'], 'Experience': ['a', 'n', 's', '2', '2', '2']}"
"Machine Learning Engineer, Fast Optimized Inference - EMEA Remote",Hugging Face,France,https://fr.linkedin.com/jobs/view/machine-learning-engineer-fast-optimized-inference-emea-remote-at-hugging-face-3848456024?position=5&pageNum=5&refId=l6Zpg44EBlmc2ek5NGQhDA%3D%3D&trackingId=98kAvTNjuAoLXNtHzON%2B2g%3D%3D&trk=public_jobs_jserp-result_search-card,"Here at Hugging Face, we're on a journey to advance good Machine Learning and make it more accessible. Along the way, we contribute to the development of technology for the better.
We have built the fastest-growing, open-source, library of pre-trained models in the world. With more than 1 Million+ models and 320K+ stars on GitHub, over 15.000 companies are using HF technology in production, including leading AI organizations such as Google, Elastic, Salesforce, Algolia, Grammarly and NASA.
About the role:
As a Machine learning Engineer, you work mainly on creating great libraries highly focused on real world ML use cases. We're building on top of our open-source to create more specialized code with a focus on industrial level of usage.
We are searching for someone who brings fresh ideas, demonstrates a unique and informed viewpoint, and enjoys collaborating with a progressive, nimble and decentralized approach to develop real-world solutions and positive user experiences at every interaction.
Objectives of this role:
Develop specialized software for specific machine learning (ML) use cases that have broad applications, similar to [text-generation-inference](https://github.com/huggingface/text-generation-inference).
Utilize existing library frameworks to create scalable software solutions for industrial purposes.
Enhance the reliability, quality, and time-to-market of our software suite. Measure and optimize system performance to stay ahead of customer needs and drive innovation.
Manage the production environment by monitoring availability and ensuring overall system health. We run our own tools
About you:
If you are a passionate Machine Learning Engineer with a keen interest in AI and proficient with Python, Rust and specialized Cuda kernels Frameworks (transformers of course + Keras or PyTorch), we would love to hear from you. Join our team and contribute to the advancement of AI technologies while working alongside talented professionals in a collaborative and stimulating environment.
More about Hugging Face
We are actively working to build a culture that values diversity, equity, and inclusivity
.
We are intentionally building a workplace where people feel respected and supported—regardless of who you are or where you come from. We believe this is foundational to building a great company and community. Hugging Face is an equal opportunity employer and we do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.
We value development.
You will work with some of the smartest people in our industry. We are an organization that has a bias for impact and is always challenging ourselves to continuously grow. We provide all employees with reimbursement for relevant conferences, training, and education.
We care about your well-being
.
We offer flexible working hours and remote options. We offer health, dental, and vision benefits for employees and their dependents. We also offer flexible parental leave and paid time off.
We support our employees wherever they are
.
While we have office spaces in NYC and Paris, we're very distributed and all remote employees have the opportunity to visit our offices. If needed, we'll also outfit your workstation to ensure you succeed.
We want our teammates to be shareholders
.
All employees have company equity as part of their compensation package. If we succeed in becoming a category-defining platform in machine learning and artificial intelligence, everyone enjoys the upside.
We support the community
.
We believe major scientific advancements are the result of collaboration across the field. Join a community supporting the ML/AI community.
Show more
Show less","{'ProgLanguage': ['Python', 'Scala', 'R', 'Go'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': ['Keras', 'PyTorch'], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git'], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['ML', 'Machine Learning'], 'FrSoftSkills': ['Collaboration'], 'EnSoftSkils': ['Collaboration', 'Organization']}","{'JobDetail': ['Remote'], 'TypeContract': [], 'Salary': ['Package'], 'Level': [], 'Experience': ['a', 'n', 's']}"
Data Scientist F/H,Saint-Gobain,"Courbevoie, Île-de-France, France",https://fr.linkedin.com/jobs/view/data-scientist-f-h-at-saint-gobain-3916726404?position=6&pageNum=5&refId=l6Zpg44EBlmc2ek5NGQhDA%3D%3D&trackingId=KwSgUF9t%2FMZZCkbsgByMGw%3D%3D&trk=public_jobs_jserp-result_search-card,"Why do we need you ?
Vous rejoindrez l’équipe « AI & Data Analytics », intégrée au département «Data & Analytics» dans l’organisation « Global Digital & IT». «Data & Analytics» regroupe les activités suivantes :
Data Engineering, Data Capture & Delivery, BI & Visualization, Platform & Architecture, Data Governance and Data Engagement.
Au Sein De L’équipe Data Science, Sous La Responsabilité Du Head Of AI & Data Analytics, Vous Aurez Le Rôle De Data Scientist (H/F). En Tant Que Tel, Vous Aurez Les Responsabilités Suivantes
Construire des modèles descriptifs et prédictifs sur des sujets en constante évolution ;
Mener des projets exploratoires faisant appel à des techniques avancées de Data Science (NLP, deep learning, Generative AI, apprentissage par renforcement ou par transfert), de façon autonome ou avec des partenaires externes ;
Assurer une veille technologique permanente sur ces sujets ;
Participer à l’industrialisation des algorithmes en lien avec les équipes engineering basée sur MLOps;
Accompagner les équipes opérationnelles dans le déploiement des algorithmes, notamment sur le volet analytics ;
Mener des ateliers d’idéation avec les équipes métiers (industrie, marketing, ventes, logistique, e-commerce, finance, RH) pour identifier les opportunités d’exploitation de la donnée et diffuser la culture data au sein de l’entreprise.
Si vous recherchez des défis passionnants, pouvant impacter des centaines de milliers de clients, et aimez travailler avec des outils à la pointe de la technologie, venez et rejoignez-nous !
Vous participerez donc à la montée en puissance de l’équipe créée récemment, tout en intervenant sur un ou plusieurs cas d’utilisation.
Is this job for you ?
En complément des missions évoquées, une réelle appétence pour la gestion et la facilitation de projet, avec une certaine aisance en termes de communication, seraient fortement appréciées.
Notre équipe ayant vocation à travailler pour des clients internes pouvant être basés en France comme à l’étranger, la maitrise de l’anglais (écrite et orale) est obligatoire.
Profil recherché
Ingénieur diplômé d’une école généraliste (Centrale, X, Mines, ENS etc.) ayant au minimum 3 années d'expérience après le diplôme.
Grande connaissance du Machine Learning, des statistiques et des probabilités.
SQL et Python, packages de ML: scikit, xgboost, keras
Expérience de travail sur un cloud provider et savoir construire des data pipelines serait un plus
Gestion de code : Git, Gitlab, CI/CD
Maitriser la modélisation à la fois prédictive et descriptive
Savoir implémenter des dashboards et autres outils de data viz
Posséder de bonnes qualités de communication : vous pouvez expliquer vos modèles clairement à la fois à des data analysts mais aussi à des Directeurs Généraux ou des responsables opérationnels.
Etre organisé, structuré et motivé par l’innovation
Aimer le travail en équipe et savoir apprendre de chacun.
Un état d’esprit orienté business et apport de valeur pour les équipes métiers
A Little More About Us
Saint-Gobain est une entreprise française spécialisée dans la production, la transformation et distribution de matériaux.
Fondée en 1665 par Jean-Baptiste Colbert sous le nom de Manufacture royale des glaces, l'entreprise est présente dans soixante-sept pays et emploie en 2018 près de 180 000 personnes
To make sure nothing is forgotten
Détails pratiques du rôle
Début : Dès que vous êtes prêts
Localisation : La Tour Saint-Gobain, La Défense
Contrat: CDI
Saint-Gobain encourage la diversité des équipes et favorise notamment l’inclusion des personnes en situation de handicap.
Show more
Show less","{'ProgLanguage': ['Python', 'R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': ['Keras', 'XGBoost'], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': ['Statistiques'], 'CloudComputing': [], 'DevTools': ['Git'], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['ML', 'Machine Learning', 'Statistiques', 'Cloud', 'CI/CD'], 'FrSoftSkills': ['Communication', 'Organisation'], 'EnSoftSkils': ['Communication']}","{'JobDetail': [], 'TypeContract': ['CDI'], 'Salary': ['1665'], 'Level': [], 'Experience': ['a', 'n', 's']}"
"Ingénieur Data scientist –Intelligence artificielle-  IDF, France (H/F)",Astek,"Île-de-France, France",https://fr.linkedin.com/jobs/view/ing%C3%A9nieur-data-scientist-%E2%80%93intelligence-artificielle-idf-france-h-f-at-astek-3886897805?position=7&pageNum=5&refId=l6Zpg44EBlmc2ek5NGQhDA%3D%3D&trackingId=5Q%2F4tfJdKWujFOsNqsN78Q%3D%3D&trk=public_jobs_jserp-result_search-card,"Ce que nous allons accomplir ensemble :
Pour l’un de nos projets dans le domaine aéronautique, vous interviendrez en tant
qu’ingénieur Data scientist / Intelligence artificielle
sur la mise en place de systèmes experts destinés aux avions civils et militaires.
Votre future équipe :
Team IT de 12 personnes
Data scientist, ingénieurs systèmes, intégrateurs, architectes
Vous travaillerez avec de véritables passionnés !
Votre mission (...si vous l’acceptez !) :
Vous participerez au développement des fonctions d’analyses multisystèmes. Pour cela vous assurerez l’établissement d’une spécification formelles sur les modèles d’analyses.
Vous assurerez l’analyse des données et la proposition de méthodes pour le traitement des signaux.
Vous développerez les outils capables de traiter de manière automatique les données systèmes.
Vous assurerez la réalisation des scénarios, ainsi que les tests et simulations.
Vous réaliserez également une activité de support.
Votre stack de jeu :
Data scientist, python, principe de gestion de configuration, et traçabilité, systèmes aéronautiques, intelligence artificielle
Les petits plus du projet :
Vous évoluerez au sein d’équipes agiles impliquées et réactives.
Vous interviendrez de A à Z sur des projets riches fonctionnellement et ambitieux techniquement :
forte volumétrie, haut niveau de performance, exigence maximale en termes d’intelligence artificielle et encore bien d'autres sujets captivants.
Vous ?
De formation Ingénieur, vous justifiez d’une expérience significative en Data scientist et ou Intelligence artificielle.
Une connaissance des méthodes d’analyse de données serait un plus.
Idéalement vous avez une connaissance des systèmes aéronautiques.
Des postes également ouverts aux débutants si stages significatifs.
Nous ?
Créé en France en 1988, Astek est un acteur mondial de l’ingénierie et du conseil en technologies, présent sur les 5 continents. Fort de son expertise dans de nombreux secteurs industriels et tertiaires, Astek accompagne ses clients internationaux dans le déploiement intelligent de leurs produits et de leurs services, et dans la mise en œuvre de leur transformation digitale.
Depuis sa création, le Groupe a fondé son développement sur une forte culture d’entrepreneuriat et d’innovation, et sur l’accompagnement et la montée en compétence de ses 5 200 collaborateurs qui s’engagent chaque jour à promouvoir la complémentarité entre les technologies numériques et l’ingénierie des systèmes complexes.
Rejoignez un Groupe en fort développement en France et à travers le monde grâce à une levée de fonds de 200M€ réalisée en 2021. Ensemble « Let’s move forward! »
✨ Tous les détails sur le Groupe sur le site
https://astekgroup.fr.
Et vous pouvez aussi nous suivre sur
notre blog : https://blog.groupeastek.com
.
Rencontrons-nous !
Vous vous êtes reconnu sur l’annonce et Astek vous plaît !
Pour en savoir plus sur vous, Franck , notre Talent Acquisition vous contacte. Puis, vous aurez 3 entretiens max, avec Léonard (votre futur n+1), Léonard notre Directeur !
Nos plus
Astek est green et fait bénéficier ses salariés d’une indemnité kilométrique vélo
Un programme CARE sur-mesure déployé par nos équipes RH pour nos collaborateurs : https://astekgroup.fr/engagements
Notre charte de la Diversité
Bienvenue dans la team ! Allez-y, maintenant c’est à vous de jouer !
Show more
Show less","{'ProgLanguage': ['Python', 'R'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git'], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': [], 'FrSoftSkills': [], 'EnSoftSkils': []}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's']}"
Machine Learning Developer,MindPal,"Lyon, Auvergne-Rhône-Alpes, France",https://fr.linkedin.com/jobs/view/machine-learning-developer-at-mindpal-3910999113?position=8&pageNum=5&refId=l6Zpg44EBlmc2ek5NGQhDA%3D%3D&trackingId=oFa%2BTnQJthOu3kdD2GXgZA%3D%3D&trk=public_jobs_jserp-result_search-card,"We are looking for
Machine Learning Developer
Job Responsibilities
Working on machine learning projects
Analyzing and processing data to create machine learning models
Implementing and optimizing machine learning algorithms
Testing and evaluating models
Collaborating with the programming team and other departments within the company to develop innovative solutions
Requirements
Minimum 2 years of experience in the field of machine learning
Knowledge of machine learning algorithms and techniques
Ability to analyze and process data
Familiarity with machine learning tools and technologies
Proficient in English communication
Education in computer science
We Offer
B2B contract type
Full-time employment
Remote and flexible working hours
Show more
Show less","{'ProgLanguage': ['R', 'Go'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Machine Learning'], 'FrSoftSkills': ['Communication'], 'EnSoftSkils': ['Communication']}","{'JobDetail': ['Remote', 'Full'], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's']}"
Data Scientist H/F,Harry Hope.,"Nancy, Grand Est, France",https://fr.linkedin.com/jobs/view/data-scientist-h-f-at-harry-hope-3917429026?position=9&pageNum=5&refId=l6Zpg44EBlmc2ek5NGQhDA%3D%3D&trackingId=rrG4PDv1VmURIhywx%2FVTsA%3D%3D&trk=public_jobs_jserp-result_search-card,"Jean, consultant spécialisé sur les métiers de l'IT sur la lorraine au sein du cabinet de recrutement Harry Hope accompagne les candidats dans leurs recherches d'une meilleure opportunité professionnelle sur leur secteur géographique privilégié. Nous ne sommes pas une ESN, nous intervenons dans la mise en relation avec des clients finaux sur des postes en CDI. Notre client, une société en pleine croissance dans le secteur de l'IA, recherche un Data Scientist (H/F) pour compléter son équipe dédiée.
Intégré à une équipe technique composée de Data scientist, de développeurs et de chercheurs, vous aurez l'occasion d'intervenir dans la récupération, l'exploitation, la modélisation, l'évaluation et l'interprétation de données stockées dans les bases de données de la structure permettant de les exploiter selon les besoins. En parallèle de vos missions concernant les données propre à l'activité principale de l'entreprise, vous intervenez également dans l'exploitation et la structuration des datas récupérées sur internet en lien avec l'IA en cours de développement.
Diplômé en informatique, vous disposez à minima d'une première expérience à un poste similaire (alternance ou premier emploi). Techniquement, vous avez une grande expertise en statistiques et en mathématiques appliquées. Vous maitrisez les domaines du Big Data, du machine learning et de la programmation informatique (Python, Java, R, SQL). Humainement, vous êtes reconnu pour votre dynamisme, votre flexibilité et votre engagement. Vous êtes capable de vous impliquer à fond dans les projets qui vous sont confiés et vous appréciez le travail collaboratif. Passionné par la Data, vous assurez une veille constante sur les nouvelles technologies en lien avec votre activité. Enfin, vous maitrisez l'anglais à l'oral comme à l'écrit.
Informations complémentaires : Salaire selon profil et expériences (38/42kEUR), possibilité d'évoluer rapidement, CDI à pouvoir rapidement à Nancy.
Si cette opportunité correspond à vos aspirations professionnelles alors faites-moi parvenir votre candidature. J'étudierai cette dernière et reviendrai vers vous dans les meilleurs délais pour un suivi personnalisé de votre profil !
Show more
Show less","{'ProgLanguage': ['Python', 'Java', 'R'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': ['Statistiques'], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Big Data', 'Machine Learning', 'Statistiques'], 'FrSoftSkills': ['Flexibilité'], 'EnSoftSkils': []}","{'JobDetail': [], 'TypeContract': ['CDI'], 'Salary': ['38'], 'Level': [], 'Experience': ['a', 'n', 's']}"
DATASCIENTIST,GROUPE ALLIANCE,"Île-de-France, France",https://fr.linkedin.com/jobs/view/datascientist-at-groupe-alliance-3916080098?position=10&pageNum=5&refId=l6Zpg44EBlmc2ek5NGQhDA%3D%3D&trackingId=FEkQOYpIhaFS1Cnr8rb90A%3D%3D&trk=public_jobs_jserp-result_search-card,"SI LA GESTION DES DONNEES EST TON DADA, TU PEUX GAGNER LA COURSE EN LISANT CETTE ANNONCE …
Ce que tu recherches :
au sein d’une équipe dynamique
à des projets innovants d’envergure
des défis
un nouveau souffle à ta carrière
Alors nous avons la mission idéale pour toi.
Au sein d’acteurs majeurs du secteur Bancaire, tu participeras des projets d’envergure sur des évolutions majeures à mettre en œuvre dans le SI du client :
des besoins, tu feras
techniques, tu rédigeras
et/ou socle technique, tu définiras
pratiques, tu instaureras
nouvelles fonctionnalités, tu développeras
bug, tu laisseras
équipe, tu accompagneras
instances de pilotage, tu participeras
Qui tu es :
de la formation qui va bien
ou dôté(e) d’une expérience de 3 ans minimum
de la Stack technique machine learning et python
avec les Frameworks et Outils : Ttensorflow, pytorch,scikit-learn, numpy, pandas
Au-delà des compétences techniques, tu es :
: tu n’aimes pas rester les deux pieds dans le même sabot
: un guide du Routard te suffira
de synthèse : tu sais aller à l’essentiel
d’adaptation : tu es un vrai caméléon
de la communication : les mots n’ont pas de secret pour toi
de proposition : tu es l’Aladdin de l’informatique
d’équipe : un pour tous et tous pour un !
Show more
Show less","{'ProgLanguage': ['Python', 'R'], 'DataBase': [], 'DataAnalytics': ['Pandas', 'NumPy', 'R'], 'BigData': [], 'MachingLearning': ['Scikit-Learn', 'TensorFlow', 'PyTorch'], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Machine Learning'], 'FrSoftSkills': ['Communication'], 'EnSoftSkils': ['Communication']}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's', '3', '3', '3']}"
Data Scientist IA GEN,eXalt,"Paris, Île-de-France, France",https://fr.linkedin.com/jobs/view/data-scientist-ia-gen-at-exalt-3856618698?position=1&pageNum=7&refId=Qh1H6EZ9SMjMA1acpT5AdQ%3D%3D&trackingId=YYXB866JuiDSrzENK%2Ftv0w%3D%3D&trk=public_jobs_jserp-result_search-card,"Descriptif du poste
Nous recherchons un
Data Scientist IA Gen H/F
pour rejoindre notre communauté sur le
pilier Data Science & IA.
Vos missions:
Identifier les besoins spécifiques des différentes équipes, à travers des ateliers d’idéation, et proposition de solutions algorithmiques innovantes et adaptées à chaque situation.
Analyser les données disponibles pour sélectionner les modèles d’IA les plus pertinents face aux besoins identifiés, en tenant compte des particularités de chaque cas d’usage.
Développer, tester et déployer les algorithmes des modèles d’apprentissage automatique et des algorithmes avancés pour résoudre des problèmes complexes grâce à des méthodes statistiques, mathématiques et de machine learning.
Collaborer avec les Data Engineer afin d’intégrer les solutions IA dans les produits et les applications existants.
Exploiter les dernières avancées en matière d’IA, notamment le Deep Learning, le Reinforcement Learning, le Traitement du Langage Naturel (NLP), la vision par ordinateur, etc., pour créer des solutions innovantes.
Conseiller les clients tout au long du cycle de vie des projets sur les solutions techniques les plus adaptées à leurs environnements.
Profil recherché
Compréhension des enjeux business autours de l’exploitation des données et le déploiement des solutions IA
Maîtrise du Machine Learning et du Deep Learning, y compris des principaux frameworks (TensorFlow, PyTorch, Scikit-learn, Pandas, NumPy,) et des méthodes statistiques.
Solide connaissance de Python (Java, Spark, Scala sont un plus).
Expérience dans l’utilisation d’outils tels que Gitlab et Docker.
Aisance avec l’ensemble du cycle de vie de développement et de déploiement de modèles d’IA (MLOps).
Expérience de travail en méthode Agile
Capacité à travailler de manière autonome et en équipe.
Excellentes compétences en communication et présentation.
Maîtrise de l’anglais (oral & écrit dans un contexte international professionnel).
Déroulement des entretiens
Un entretien RH avec Estelle, à la suite duquel vous saurez tout (ou presque) d’eXalt Value,
Un entretien technique avec un Manager IA assorti d’un test technique, lors duquel vous aurez l’occasion de démontrer vos talents mais aussi d’apprendre avant même de dire oui,
Un entretien final avec la Directrice Associée ou le Directeur Opérationnel, pour finir de vous convaincre de nous rejoindre 😊
Votre environnement eXalté:
Rejoindre
eXalt Value
, c’est également :
Un Lab IA au sein duquel vous pourrez expérimenter les divers outils et techniques, autour de use cases internes et externes.
Un environnement de travail Collaboratif favorisant les initiatives et projets transverses à la Practice Data & IA (Data Hub, etc ;)
Un collectif de consultants passionnés, s’intéressant aux tendances innovantes du secteur
Une Practice de proximité, privilégiant la montée en compétence de ses collaborateurs (formations, coachings, mentorats, etc.)
Un suivi individualisé et de proximité par un.e Data Sales Manager référent du compte client, un.e Chargé.e RH et un.e Practice Manager
Une équipe sympa et dynamique, qui privilégie des moments de partage (séminaires, eXaltemps, meet-ups, déjeuners d’équipe,etc.)
Qui sont-ils ?
eXalt
est un cabinet de conseil IT
Pure player Data
& IA basé à Paris (1er arrondissement).
Notre offre s’articule autour de 4 piliers réunis au sein d’une même communauté pour un accompagnement à 360° alliant une expertise technique et méthodologique à une approche conseil métier:
Data Gouvernance & Project
Data Engineering & Big Data
Data Performance & Analytics
Data Science & IA
Filiale du groupe eXalt créé en 2018,
regroupant plus de
950 collaborateurs en France
(Paris, Lyon, Bordeaux, Lille, Nantes, Marseille)
et à l’international
(Colombie, Etats-Unis, Espagne, Belgique),
eXalt Value
démontre une
expertise approfondie
dans le domaine de la Data & IA et conseille les entreprises dans le déploiement de leurs stratégies data-driven.
Bénéficiant de la renommée et des relations client du groupe eXalt
(1er dans la catégorie Conseil & Audit au classement des Champions de la Croissance 2024), eXalt Value
est en pleine croissance et regroupe aujourd’hui une communauté d’expertise de plus de 60 collaborateurs en région parisienne.
Nos consultants interviennent sur d
es projets d’envergure stimulants
dans divers secteurs d’activité, Banque & Assurance, Médias, Transports, Retail, Tourisme, etc.
Show more
Show less","{'ProgLanguage': ['Python', 'Java', 'Scala', 'R', 'Go'], 'DataBase': [], 'DataAnalytics': ['Pandas', 'NumPy', 'R'], 'BigData': ['Spark'], 'MachingLearning': ['Scikit-Learn', 'TensorFlow', 'PyTorch'], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': ['Statistiques'], 'CloudComputing': [], 'DevTools': ['Git', 'Docker'], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': ['Docker'], 'Collaboration': [], 'Other': ['Big Data', 'ML', 'Machine Learning', 'Statistiques'], 'FrSoftSkills': ['Communication'], 'EnSoftSkils': ['Communication', 'Initiative']}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's']}"
Machine Learning Developer,MindPal,"Paris, Île-de-France, France",https://fr.linkedin.com/jobs/view/machine-learning-developer-at-mindpal-3896993704?position=2&pageNum=7&refId=Qh1H6EZ9SMjMA1acpT5AdQ%3D%3D&trackingId=2h75JiwS%2BhDoETgkzdQPdA%3D%3D&trk=public_jobs_jserp-result_search-card,"We are looking for
Machine Learning Developer
Job Responsibilities
Working on machine learning projects
Analyzing and processing data to create machine learning models
Implementing and optimizing machine learning algorithms
Testing and evaluating models
Collaborating with the programming team and other departments within the company to develop innovative solutions
Requirements
Minimum 2 years of experience in the field of machine learning
Knowledge of machine learning algorithms and techniques
Ability to analyze and process data
Familiarity with machine learning tools and technologies
Proficient in English communication
Education in computer science
We Offer
B2B contract type
Full-time employment
Remote and flexible working hours
Show more
Show less","{'ProgLanguage': ['R', 'Go'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Machine Learning'], 'FrSoftSkills': ['Communication'], 'EnSoftSkils': ['Communication']}","{'JobDetail': ['Remote', 'Full'], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's']}"
Data Scientist (H/F),Harry Hope.,"Nancy, Grand Est, France",https://fr.linkedin.com/jobs/view/data-scientist-h-f-at-harry-hope-3917140355?position=3&pageNum=7&refId=Qh1H6EZ9SMjMA1acpT5AdQ%3D%3D&trackingId=lSyOdirUX%2FfMdkOti7YgZQ%3D%3D&trk=public_jobs_jserp-result_search-card,"Jean, consultant spécialisé sur les métiers de l'IT sur la lorraine au sein du cabinet de recrutement Harry Hope accompagne les candidats dans leurs recherches d'une meilleure opportunité professionnelle sur leur secteur géographique privilégié. Nous ne sommes pas une ESN, nous intervenons dans la mise en relation avec des clients finaux sur des postes en CDI. Notre client, une société en pleine croissance dans le secteur de l'IA, recherche un Data Scientist (H/F) pour compléter son équipe dédiée.
Intégré à une équipe technique composée de Data scientist, de développeurs et de chercheurs, vous aurez l'occasion d'intervenir dans la récupération, l'exploitation, la modélisation, l'évaluation et l'interprétation de données stockées dans les bases de données de la structure permettant de les exploiter selon les besoins. En parallèle de vos missions concernant les données propre à l'activité principale de l'entreprise, vous intervenez également dans l'exploitation et la structuration des datas récupérées sur internet en lien avec l'IA en cours de développement.
Diplômé en informatique, vous disposez à minima d'une première expérience à un poste similaire (alternance ou premier emploi). Techniquement, vous avez une grande expertise en statistiques et en mathématiques appliquées. Vous maitrisez les domaines du Big Data, du machine learning et de la programmation informatique (Python, Java, R, SQL ...). Humainement, vous êtes reconnu pour votre dynamisme, votre flexibilité et votre engagement. Vous êtes capable de vous impliquer à fond dans les projets qui vous sont confiés et vous appréciez le travail collaboratif. Passionné par la Data, vous assurez une veille constante sur les nouvelles technologies en lien avec votre activité. Enfin, vous maitrisez l'anglais à l'oral comme à l'écrit.
Informations complémentaires : Salaire selon profil et expériences (38/42kEUR), possibilité d'évoluer rapidement, CDI à pouvoir rapidement à Nancy.
Si cette opportunité correspond à vos aspirations professionnelles alors faites-moi parvenir votre candidature. J'étudierai cette dernière et reviendrai vers vous dans les meilleurs délais pour un suivi personnalisé de votre profil !
20624921-55584
Show more
Show less","{'ProgLanguage': ['Python', 'Java', 'R'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': ['Statistiques'], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Big Data', 'Machine Learning', 'Statistiques'], 'FrSoftSkills': ['Flexibilité'], 'EnSoftSkils': []}","{'JobDetail': [], 'TypeContract': ['CDI'], 'Salary': ['38'], 'Level': [], 'Experience': ['a', 'n', 's']}"
CDI - DATA SCIENTIST / IA CONFIRME H/F,ITNOVEM.,"Paris, Île-de-France, France",https://fr.linkedin.com/jobs/view/cdi-data-scientist-ia-confirme-h-f-at-itnovem-3899543583?position=4&pageNum=7&refId=Qh1H6EZ9SMjMA1acpT5AdQ%3D%3D&trackingId=55G4o0phy5TZvsKCX%2BByyw%3D%3D&trk=public_jobs_jserp-result_search-card,"L’ENTREPRISE
Filiale privée technologique du
Groupe SNCF
, ITNOVEM se positionne comme accélérateur des projets Digitaux, numériques et de la transformation des Systèmes d’information du groupe. Porteuse de grands projets de la révolution digitale, notre société est en constante recherche de profils pour rejoindre la grande aventure de l’Internet des objets, de la data science, de la cybersécurité et de l’accompagnement des projets digitaux. Qu’il s’agisse de maintenance prédictive, d’aide à la décision sur la maintenance des infrastructures, de gare 4.0, d’usine du futur, ou de sécurisation des assets, nos équipes font valoir à la fois une expérience métier et une expertise technique sans cesse renouvelée, dans le respect des valeurs du groupe :
Excellence
,
Innovation
,
Collectif
,
Agile
,
Engagement.
LE POSTE
Au sein d’ITNOVEM, la « Factory Data & IA » accompagne les différentes entités du Groupe SNCF à répondre à leurs enjeux métiers via l’exploitation des données dont le groupe dispose et en mobilisant des compétences et expertises techniques en data science, data engineering et technologies Big Data & Cloud. Elle conçoit, construit, déploie, et exploite les projets data pour le Groupe SNCF (socles de données, traitements de données massives, transformations complexes, développement d'algorithmes, intelligence artificielle ...).
Au sein de la « Factory Data & IA », l’équipe « Data Science » intervient auprès des métiers et DSI de SNCF avec une forte ambition en matière d’industrialisation et des technologies Data et IA qui correspondent à l’état de l’art. Les problématiques sont variées et liées aux grands enjeux industriels, opérationnels et stratégiques du groupe SNCF, par exemple :
Maintenance du matériel roulant ;
Surveillance et la maintenance de l'infrastructure ferroviaire (voies et caténaires) ;
Mise en œuvre de l’IA Générative pour des applications ferroviaires ;
Construction de modèles IA pour améliorer la performance opérationnelle ;
Mise en place de solutions d’IA autour de l’image et la vidéo (computer vision) ;
Analyse et valorisation des données de capteurs (par ex., mesures, vidéo).
L’
Ingénieur Data Scientist
contribue au développement de l’activité de l’équipe « Data Science ». Il analyse, valorise et exploite l’ensemble des données mises à sa disposition. Il proposer, en proche collaboration avec les métiers, des solutions pour répondre aux cas d’usage identifiés.
MISSIONS ET RESPONSABILITÉS
Au sein de l’équipe « Data Science », le
Data Scientist
porte les responsabilités suivantes :
Accompagner, en tant que lead technique, les projets Data Science / IA (cadrages, études, prototypes et industrialisation) de la Factory, à la fois sur les aspects techniques / scientifiques et sur la relation client.
Mener des activités de conseil technique et scientifique sur l’usage et la valorisation de la donnée au sein du Groupe SNCF. Accompagner l’identification et la mise en œuvre de cas d’usage auprès des métiers.
Construire des solutions d’IA et de valorisation des données appliquées aux cas d’usage du Groupe SNCF.
Contribuer à la veille scientifique et technique, aux projets R&D internes, et à la construction de produits et de services techniques orientés data. Proposer des axes de développement des activités Data Science.
Être un référent technique de l'équipe sur les questions data science et accompagner les data scientists plus juniors dans leur montée en compétences.
Participer et contribuer à la vie de l’équipe Data Science : partage de connaissance, mise en place de bonnes pratiques, communication interne et externe, collaborations externes.
COMPETENCES ATTENDUES
Compétences techniques / métier
Maitrise des outils mathématiques de la Science des Données (statistiques, recherche opérationnelle, traitement du signal, traitement de l’image …).
Capacité à aborder et à résoudre des problèmes complexes avec méthode.
Capacité avérée de modélisation de problématiques métier en termes de données et d’analyse statistique.
Expérience en développement Python et une bonne capacité à produire du code industriel (modulaire, testé, non redondant, automatisé, robuste, optimisé).
Maîtrise des algorithmes de Machine Learning et de Deep Learning, ainsi que des outils associés (scikit-learn, TensorFlow, PyTorch, SparkML ...) pour le traitement de données structurées et non structurées.
Maitrise des outils de NLP et de l’IA générative / LLM / RAG.
Bonne connaissance des principes de la gestion de projet Data. Capacité à piloter, cadrer et chiffrer un projet et gérer des collaborateurs.
Maitrise de l’anglais technique.
Connaissance d’un écosystème cloud (Azure ou AWS) et de Databricks est un plus.
Idéalement, des connaissances du contexte et enjeux liés à l’industrie.
Compétences personnelles / transverses
Communication écrite et orale rigoureuse et claire. Sens de la pédagogie. Capacité à effectuer et synthétiser de la veille scientifique et technique.
Orienté résolution de problème.
Transversalité et capacité à travailler avec des équipes pluridisciplinaires.
Orientation client, qualité et résultats.
Capacité à piloter une équipe, cadrer et chiffrer un projet, manager des collaborateurs.
Capacité à mener des activités de conseil technique et scientifique auprès de non spécialistes.
Rigueur, gestion et organisation.
Curiosité fonctionnelle et technologique.
Appétence pour le milieu industriel, et particulièrement le domaine ferroviaire.
EXPÉRIENCES ET FORMATIONS
Vous avec obtenu une diplôme d’une formation scientifique Bac+5 ou supérieur (doctorat, école d’ingénieur), dans un domaine lié à l’usage de la données (par exemple, physique, mécanique, traitement du signal et de l’image, mathématiques appliquées).
Vous disposez d'au moins 4 ans d'expérience professionnelle dans le traitement avancé des données et le développement d'applications en Analyse / Intelligence Artificielle / Science des Données. Sont notamment appréciées les expériences en relation avec un domaine industriel.
D’autres raisons de rejoindre ITNOVEM !
🚀 En tant que filiale SNCF, des opportunités de carrières internes vous sont offertes.
📚 ITNOVEM croit en la formation continue de ses collaborateurs et leur donne l’opportunité de s’inscrire à une formation par an minimum.
🚊 Vos titres de transport sont pris en charge à hauteur de 75%.
🍽️ Via la carte titres-restaurant Swile, vous bénéficiez de 9,25 € par jour dont 60% pris en charge par ITNOVEM.
💻 Chez ITNOVEM, vous bénéficiez jusqu’à 3 jours de télétravail par semaine.
🏖️ ITNOVEM vous permet de profiter de 28 congés et de 16 RTT pour les cadres et 10 pour les non-cadres. Par ailleurs, 2 des 3 jours de congés pour enfant malade sont rémunérés.
👫 La mise en œuvre de l’égalité professionnelle femmes/hommes est primordiale chez ITNOVEM. A chaque nouvelle embauche, l'entreprise s'engage à proposer une rémunération équivalente tant aux femmes qu'aux hommes.
♻️ ITNOVEM incite tous les collaborateurs à trier leurs déchets et les gobelets ont été bannis. Par ailleurs, chaque année, ITNOVEM participe à « La grande collecte », une initiative SNCF qui permet de collecter les PC devenus obsolètes en leur offrant une seconde vie
Show more
Show less","{'ProgLanguage': ['Python', 'R', 'Go'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': ['Spark', 'Databricks'], 'MachingLearning': ['Scikit-Learn', 'TensorFlow', 'PyTorch'], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': ['Statistiques'], 'CloudComputing': ['AWS', 'Azure'], 'DevTools': ['Git'], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Big Data', 'ML', 'Machine Learning', 'Statistiques', 'Cloud'], 'FrSoftSkills': ['Communication', 'Collaboration', 'Organisation'], 'EnSoftSkils': ['Communication', 'Collaboration', 'Initiative']}","{'JobDetail': ['Junior'], 'TypeContract': [], 'Salary': [], 'Level': ['Bac+5'], 'Experience': ['a', 'n', 's', '4', '4', '4']}"
Data scientist - Monaco,Klanik,"Nice, Provence-Alpes-Côte d'Azur, France",https://fr.linkedin.com/jobs/view/data-scientist-monaco-at-klanik-3912534166?position=5&pageNum=7&refId=Qh1H6EZ9SMjMA1acpT5AdQ%3D%3D&trackingId=kXe4mVP7Ffpck0wsgMPpIQ%3D%3D&trk=public_jobs_jserp-result_search-card,"Le consultant travaillera sur des analyses de données et de participer au développement de modèles prédictifs et d'algorithmes d'apprentissage automatique.
Activités :
- Nettoyage / préparation / structuration / normalisation des données pour garantir leur qualité et leur fiabilité ;
- Exploration de données : utiliser des statistiques descriptives et des visualisations de données pour explorer les jeux de données, identifier des tendances, des anomalies éventuelles ;
- Modélisations : concevoir, développer et déployer des modèles statistiques et d'apprentissage automatique pour répondre à des questions spécifiques ou résoudre des problèmes métiers ;
- Développement et optimisation de pipelines de données pour faciliter l'acquisition, le traitement et la mise à disposition des données pour l'analyse ;
- Communication des résultats des analyses et des modélisations à travers des rapports et des visualisations de données claires et impactantes, permettant aux parties prenantes de prendre des décisions basées sur les données.
Profil
Être titulaire, d’un diplôme national d’ingénieur sanctionnant cinq années d’études supérieures ou d’un diplôme reconnu équivalent
Entre 2 et 5 ans d'expérience en tant que Data Scientist
Compétences Techniques :
Maîtrise des langages de programmation tels que Python ou R, et des bibliothèques de data science comme pandas, TensorFlow ou PyTorch ;
Expérience en Modélisation Statistique : Solide compréhension des techniques statistiques et de machine learning, avec une capacité à appliquer ces techniques pour résoudre des problèmes complexes ;
Gestion de Bases de Données : Expérience avec les bases de données SQL, NoSQL, Time Series, ainsi qu'avec les technologies de traitement de données en temps réel ;
Visualisation de Données : Compétence dans l'utilisation d'outils de visualisation de données tels que Tableau, Power BI, ou des bibliothèques Python de visualisation de données.
Show more
Show less","{'ProgLanguage': ['Python', 'R', 'Go'], 'DataBase': ['SQL', 'NoSQL'], 'DataAnalytics': ['Pandas', 'R'], 'BigData': [], 'MachingLearning': ['TensorFlow', 'PyTorch'], 'DataSerialization': [], 'DataVisualization': ['Tableau', 'Power BI'], 'Statistics': ['Statistiques', 'Statistiques Descriptives'], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Machine Learning', 'Statistiques'], 'FrSoftSkills': ['Communication'], 'EnSoftSkils': ['Communication']}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's', '5', '5', '5']}"
Machine Learning Developer,MindPal,"Toulouse, Occitanie, France",https://fr.linkedin.com/jobs/view/machine-learning-developer-at-mindpal-3896992755?position=6&pageNum=7&refId=Qh1H6EZ9SMjMA1acpT5AdQ%3D%3D&trackingId=vapcTaZaDZsM0y%2F7u3DmEQ%3D%3D&trk=public_jobs_jserp-result_search-card,"We are looking for
Machine Learning Developer
Job Responsibilities
Working on machine learning projects
Analyzing and processing data to create machine learning models
Implementing and optimizing machine learning algorithms
Testing and evaluating models
Collaborating with the programming team and other departments within the company to develop innovative solutions
Requirements
Minimum 2 years of experience in the field of machine learning
Knowledge of machine learning algorithms and techniques
Ability to analyze and process data
Familiarity with machine learning tools and technologies
Proficient in English communication
Education in computer science
We Offer
B2B contract type
Full-time employment
Remote and flexible working hours
Show more
Show less","{'ProgLanguage': ['R', 'Go'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Machine Learning'], 'FrSoftSkills': ['Communication'], 'EnSoftSkils': ['Communication']}","{'JobDetail': ['Remote', 'Full'], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's']}"
Machine Learning Engineer H/F,ADHERENCE CONSULTING,"Capinghem, Hauts-de-France, France",https://fr.linkedin.com/jobs/view/machine-learning-engineer-h-f-at-adherence-consulting-3913991636?position=7&pageNum=7&refId=Qh1H6EZ9SMjMA1acpT5AdQ%3D%3D&trackingId=CqeKDOX0a6WZ%2Be5BKErG%2Bg%3D%3D&trk=public_jobs_jserp-result_search-card,"Adherence Consulting : Votre partenaire IT de choix !
Implantés à Paris, Lille et Marseille, nous sommes au coeur de l'innovation technologique et organisationnelle.
Notre mission ? Booster votre performance et vous accompagner dans chaque étape de votre transformation digitale.
Si vous êtes prêt(e) pour une carrière qui dépasse vos attentes, c'est le moment !
https://www.adherence-consulting.fr/
Nous recherchons un ML Engineer qui rejoindra l'équipe MLOPS. Les missions de cette équipe sont :
D'accompagner les Data Scientists sur toutes les parties techniquement complexes de leur projet (mise en production, entraînement avec gros volumes de data)
De mettre à disposition des Data Scientists tous les outils techniques permettant d'entraîner / réentraîner, de mettre en production des modèles de ML
Le ML Engineer devra avoir des compétences en Data Science (ie. comprendre les algorithmes de ML ""connus"") et avoir une bonne maîtrise sur le build de pipeline ML.
Il devra également avoir une expérience de mise en production / run de modèles de ML (expérience indispensable)
En termes de technologies, l'écosystème est constitué de :
Python (avec tensorflow) et SQL
Big Query, GCS, Data Flow, Vertex AI
Docker, Github, Github Actions
Datadog
MLOPS
Data science
Python
Cloud
Show more
Show less","{'ProgLanguage': ['Python', 'R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': ['TensorFlow'], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git', 'Docker'], 'Os': [], 'DBMS': ['Big Query'], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': ['Docker'], 'Collaboration': [], 'Other': ['ML', 'Cloud'], 'FrSoftSkills': ['Organisation'], 'EnSoftSkils': []}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's']}"
Senior Data Scientist,Artefact,"Paris, Île-de-France, France",https://fr.linkedin.com/jobs/view/senior-data-scientist-at-artefact-3462569322?position=8&pageNum=7&refId=Qh1H6EZ9SMjMA1acpT5AdQ%3D%3D&trackingId=%2FiYUEEwpKP9xXcpMUmaOFA%3D%3D&trk=public_jobs_jserp-result_search-card,"Who We Are
Artefact is a new generation of a data service provider, specialising in data consulting and data-driven digital marketing, dedicated to transforming data into business impact across the entire value chain of organisations. We are proud to say we’re enjoying skyrocketing growth.
Our broad range of data-driven solutions in data consulting and digital marketing are designed to meet our clients’ specific needs, always conceived with a business-centric approach and delivered with tangible results. Our data-driven services are built upon the deep AI expertise we’ve acquired with our 1000+ client base around the globe.
We have 850 employees across 20 offices who are focused on accelerating digital transformation. Thanks to a unique mix of company assets: State of the art data technologies, lean AI agile methodologies for fast delivery, and cohesive teams of the finest business consultants, data analysts, data scientists, data engineers, and digital experts, all dedicated to bringing extra value to every client.
What You Will Be Doing
As a Senior Data Scientist, your role will encompass:
Leading and conducting ambitious projects in the transformation of clients through data
Developing data science products and solutions for clients as well as for our data science team
Working closely with your Consulting counterpart to build and maintain strong relationships with your clients and best understand their needs
Having a contributor role in upskilling our data science team and promoting our work within the other data departments
Caring for the happiness of the team, ensuring that missions are delivered to a high standard and providing feedback and mentoring to less experienced Data Scientists
Writing highly optimised code to advance Artefact’s internal tool box and knowledge
What You Will Learn With Us
Deliver impactful and successful projects on real-world problems across a variety of industries by delivering end-to-end machine learning pipelines
Build complex solutions in feature teams with the help of your other data scientists but also ML Engineers, Data Engineers, Software Engineers and Product Owners
Improve your software engineering skills by applying ML Ops best practises and working with the Machine Learning teams
Become an expert in one of our data science practises: Time Series Forecasting, MLOPs, NLP, Computer Vision, Optimization or Customer Intelligence
Discover state of the art algorithms and test them during your client projects, on real world data
What We Are Looking For
A Doer: you get things done and inspire your teams to do the same
An Analyst: you LOVE data and think every company should take their decisions with facts
A Pragmatist: you have a hacker mindset and always find the quick wins
A Mentor: your clients and teams naturally seek for your advice
An Adventurer: you’re an entrepreneur constantly looking for problems to solve
A french speacking person who can learn and share with our french team.
Qualifications: Education & experience required
A Master’s degree in machine learning, mathematics, computer science, or related fields
3+ years of hands-on experience developing and applying data-driven solutions in a corporate or consulting setting
Strong experience and knowledge of data processing, data modelling, algorithms, and data architecture
Fluent in at least one of the following languages: Python, R, SQL, etc…
Experience in leading a technical project in a business context
Intellectual curiosity and excellent problem-solving skills, including the ability to structure and prioritise an approach for maximum impact
Why you should join us
Artefact is the place to be: we train the data leaders of tomorrow
Innovation: every day offers new challenges and new opportunities to learn
Culture: join the best team you could ever imagine
Entrepreneurship: you will be joining a team of driven entrepreneurs. We won’t give up until we make a huge dent in this industry!
Still hesitating, check our medium blog to discover concrete projects!
At Artefact, we recruit our employees only on the basis of our needs and the individual qualities of each candidate. We ensure the development of their professional skills and responsibilities without discrimination of any kind, including belief, gender, age, disability, ethnic origin, sexual orientation, membership of a political organization, religion, trade union or minority group.
Show more
Show less","{'ProgLanguage': ['Python', 'R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git'], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': ['Teams'], 'Other': ['ML', 'Machine Learning'], 'FrSoftSkills': ['Organisation'], 'EnSoftSkils': ['Organization']}","{'JobDetail': ['Senior'], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's']}"
Data Scientist F/H,ANSSI - Agence nationale de la sécurité des systèmes d'information,"Paris, Île-de-France, France",https://fr.linkedin.com/jobs/view/data-scientist-f-h-at-anssi-agence-nationale-de-la-s%C3%A9curit%C3%A9-des-syst%C3%A8mes-d-information-3908568608?position=9&pageNum=7&refId=Qh1H6EZ9SMjMA1acpT5AdQ%3D%3D&trackingId=onsVPW8Dbboiy9JsON2IAA%3D%3D&trk=public_jobs_jserp-result_search-card,"Télécharger en PDF
Descriptif de l'organisation
Rejoindre l’Agence nationale de la sécurité des systèmes d’information (ANSSI), c’est mettre ses compétences au service de l’intérêt général en participant à une mission capitale, d’actualité et porteuse de grandes responsabilités dans un monde où la cybersécurité est devenue l’affaire de tous !
Au sein de la Sous-direction-Opération (SDO), se trouve la division-détection (DD) dont le bureau Dispositifs de Détection Système (DDS) met en œuvre la capacité de détection système, c’est-à-dire l’ensemble des procédés adaptés à la caractérisation d’activités malveillantes à partir d’évènements générés au niveau des systèmes d’exploitation.
Descriptif des missions
En s’appuyant sur les connaissances des ingénieurs en cyberdéfense, vous êtes responsable des algorithmes de détection, de la phase de conception à la mise en production. Vous avez à votre disposition les données collectées par le bureau, issues de journaux d’événements de postes de travail ou de serveurs (Windows Security, Sysmon, Auditd…).
Véritable référent au sein de l'équipe, vous êtes est en mesure de proposer et tester de nouvelles idées en liens avec des problématiques concrètes, d'améliorer des algorithmes existant, mais aussi d'accompagner les analystes dans l'interprétation des résultats.
Le Caractère Opérationnel Des Missions Assurées Par Le Bureau Nécessite Que Les Travaux Menés Répondent à Un Fort Enjeu D'exploitabilité. A Cette Fin, L’agent Data-Scientiste Aura Pour Missions De
Proposer et mettre en place des algorithmes de détection d’intrusions ;
Assurer une veille des derniers papiers de recherche sur les sujets de Data Science, en particulier sur la détection d’anomalies et le NLP ;
Travailler avec d’autres équipes expertes en traitement de la donnée, et des équipes expertes en sécurité informatique ;
Concevoir des méthodes de réduction du taux de faux positifs ;
Préparer et assurer le maintien en condition opérationnelle et de sécurité, notamment via l'amélioration d'outils de monitoring ;
Rédiger des documents techniques.
Profil recherché
Vous êtes diplômé(e) d’une formation de type école d’ingénieur ou d’un cursus universitaire équivalent dans le domaine du traitement de la donnée. Une expérience d’au moins 3 ans est souhaitée.
Compétences Requises
Maitrise de Python et des principales bibliothèques de data science : pandas, numpy, scikit-learn… ;
Maitrise des principales méthodes de Machine Learning et Deep Learning ;
Connaissances en NLP ;
Maitrise des concepts statistiques sous-jacents aux méthodes d’analyses de données, et des biais éventuels
Des connaissances dans les domaines suivants seront des atouts importants :
Scripting PowerShell et Bash ;
Git, DevSecOps, orchestration de conteneurs ;
Fonctionnement des systèmes d’exploitation (Windows, Linux…) ;
Autonomie, rigueur et capacité à travailler seul ou en équipe sont des compétences indispensables.
Savoir Être
Avoir le sens du service public ;
Autonomie et capacité d'adaptation ;
Dynamique et rigoureux/euse.
Process de recrutement
Si votre candidature est présélectionnée, vous serez contacté(e) pour apprécier vos attentes et vos motivations au cours d'un entretien téléphonique ou physique.
Des tests techniques pourront vous être proposés.
Vous ferez l'objet d'une procédure d'habilitation.
Je postule
Show more
Show less","{'ProgLanguage': ['Python', 'R', 'Go', 'Bash'], 'DataBase': [], 'DataAnalytics': ['Pandas', 'NumPy', 'R'], 'BigData': [], 'MachingLearning': ['Scikit-Learn'], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': ['Statistiques'], 'CloudComputing': [], 'DevTools': ['Git'], 'Os': ['Linux', 'Windows'], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Machine Learning', 'Statistiques'], 'FrSoftSkills': ['Organisation'], 'EnSoftSkils': []}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's', '3', '3', '3']}"
Data scientist F/H,METEOJOB by CleverConnect,"Ivry-sur-Seine, Île-de-France, France",https://fr.linkedin.com/jobs/view/data-scientist-f-h-at-meteojob-by-cleverconnect-3811216934?position=10&pageNum=7&refId=Qh1H6EZ9SMjMA1acpT5AdQ%3D%3D&trackingId=vwfrkjZuzzGoVzZIiixoEA%3D%3D&trk=public_jobs_jserp-result_search-card,"Description Du Poste
Le groupe Fnac-Darty accélère sa trajectoire dans la data et l'IA.
Vous souhaitez mettre en oeuvre et développer vos compétences en data science sur des projets à fort impact dans un marché en évolution rapide ? Vous voulez travailler dans une équipe dynamique aussi passionnée que compétente et développer votre carrière ? Alors n'hésitez plus et rejoignez-nous au sein du groupe Fnac-Darty !
Vous rejoindrez la direction de la Transformation Data & IA du Groupe au sein du département Stratégie et Transformation et travaillerez sur des sujets-clés visant impact et transformation de nos métiers dans l'ensemble des activités du groupe. Sujets parmi lesquels peuvent figurer par exemple l'amélioration de l'expérience client et de l'efficience de nos interactions (service après-vente,…), l'optimisation de nos budgets promotionnels, le scoring d'appétence des utilisateurs, le churn, l'activation d'audiences, la personnalisation des parcours, la détection d'anomalies, etc…
Forts d'une implantation particulièrement forte en France et à l'international tant via Internet que via nos magasins, experts reconnus et marques appréciées, nous agissons sur une gamme de produits, de services et d'événements extrêmement large auprès d'une large partie des populations de ces pays. Vous travaillerez donc sur des données très riches dans un environnement technologique à la pointe.
Votre profil
Ecole d'ingénieurs (Centrale, ENS, Mines, Ecole Polytechnique, etc…) en formation initiale, avec spécialisation en mathématiques / data science / machine learning
Vous connaissez les mathématiques derrière les algorithmes et êtes capable de réfléchir un algorithme dédié si besoin et de le mettre en oeuvre
Vous êtes expérimenté sur le cloud, Google Cloud apprécié (dont en particulier BigQuery, Compute Engine, Cloud Storage) et vous maîtrisez les librairies dédiées (command-line + Python) ainsi que les outils de versioning tel git
Bash, SQL et Python sont des langages que vous maîtrisez à un niveau avancé
Vous êtes capables d'intégrer les flux de données nécessaires de manière automatique et pérenne
Vous savez passer vos algorithmes à l'échelle et mettre en oeuvre un ensemble robuste et stable sur de grosses volumétries pour déploiement en production ; mieux, vous pensez le passage à l'échelle et l'industrialisation dès le début du projet
Vous êtes capables de construire les analyses et algorithmes pertinents avec une palette large et complète d'outils (librairies Python dédiées ; features GCP exploitables ; BigQuery ; …), mais aussi de construire des visualisations
Show more
Show less","{'ProgLanguage': ['Python', 'R', 'Go', 'Bash'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git'], 'Os': [], 'DBMS': ['BigQuery'], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Machine Learning', 'Cloud'], 'FrSoftSkills': [], 'EnSoftSkils': []}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's']}"
Data Scientist - Tech Lead H/F,LEA Recrutement,"Montpellier, Occitanie, France",https://fr.linkedin.com/jobs/view/data-scientist-tech-lead-h-f-at-lea-recrutement-3911193777?position=1&pageNum=10&refId=qbIMrhG4cCFECZwbb6jFlQ%3D%3D&trackingId=ShjZ9YcH3LmUcw5dpDer4A%3D%3D&trk=public_jobs_jserp-result_search-card,"Cette offre d’emploi est fournie par Pôle emploi
Description
Rejoignez une entreprise leader dans les secteurs de l'IoT et de la Data Science, solide et à la pointe de l'innovation ! LEA Recrutement présente, pour le compte de notre partenaire, une nouvelle offre d'emploi. Nous accompagnons notre client, très belle référence dans le monde l'IoT et de la Data Science, à recruter son Lead Developer Data Science/IA H/F en CDI à Montpellier. La confidentialité de votre candidature est assurée. Vous intégrez une entreprise faisant partie des acteurs majeurs du secteur de l'IoT et déployant cette technologie afin de la rendre accessible au plus grand nombre dans les secteurs publics comme privés. Vous occupez le rôle de référent technique au sein de l'équipe de développement sous la supervision d'un chef de projet et/ou d'un responsable de produit. Vous soutenez l'équipe dans des aspects techniques avancés afin d'assurer la sécurité des projets et de maintenir le niveau de qualité requis. Vos missions : * Conception et optimisation des modèles d'analyse de données * Pilotage des projets en coordonnant les aspects techniques et opérationnels * Analyse des flux de données * Amélioration de la collecte, du traitement et de l'utilisation des données pour maximiser l'efficacité des dispositifs et des systèmes * Assurer la sécurité et la confidentialité des données collectées * Explorer de nouvelles approches et technologies dans une optique d'amélioration des produits * Formation et accompagnement des développeurs juniors Stack technologique : Python, Spark, Hadoop, BigQuery, Kafka, ElasticSearch, FastAPI, Panda, Scikit learn, Tensorflow.. Avantages: * Tickets restaurant * Mutuelle 100% * Equipe dynamique * Pluralité des projets * Belles perspectives d'évolution et de carrière . Votre profil : * De formation Bac+5 Ingénieur (idéalement en robotique / systèmes embarqués) * Expérience de 2 ans minimum * Expérience en contexte Open Source et IoT * Attrait pour la méthodologie Agile/Scrum * Fort esprit d'équipe * Rigueur * Excellentes capacités de communication et de partage de connaissances * Attrait pour les environnements complexes Vous êtes intéressé ? N'hésitez pas à postuler LEA Recrutement
PROFIL SOUHAITÉ
Expérience
Expérience exigée de 1 An(s)
Source: Pole emploi (https://www.pole-emploi.fr)
Show more
Show less","{'ProgLanguage': ['Python', 'R'], 'DataBase': ['Elasticsearch'], 'DataAnalytics': ['R'], 'BigData': ['Hadoop', 'Spark'], 'MachingLearning': ['TensorFlow'], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'DBMS': ['BigQuery'], 'SoftBigDataProcessing': [], 'Automation': ['Chef'], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': [], 'FrSoftSkills': ['Communication'], 'EnSoftSkils': ['Communication']}","{'JobDetail': ['Junior'], 'TypeContract': ['CDI'], 'Salary': [], 'Level': ['Bac+5'], 'Experience': ['a', 'n', 's', '2', '2', '2']}"
Senior Machine Learning Engineer,FarmWise,"Paris, Île-de-France, France",https://fr.linkedin.com/jobs/view/senior-machine-learning-engineer-at-farmwise-3831137831?position=2&pageNum=10&refId=qbIMrhG4cCFECZwbb6jFlQ%3D%3D&trackingId=GfgOk0QX2T%2BfLFce31r63A%3D%3D&trk=public_jobs_jserp-result_search-card,"Company Overview:
At FarmWise, we harness the power of AI to find solutions to combat food production challenges, and help growers thrive in this new farming era. We work hand in hand with growers to understand their constraints, address their priorities, and build products that are changing their lives for good. We’re a diverse team of analytical problem-solvers who are deeply motivated by challenges. We value open communication and a dedication to self-improvement. If you are interested in working on technology that will have a big impact on agriculture. Join us!
Job Overview:
As a Sr. Machine Learning Engineer at FarmWise, you will play a pivotal role in leading and executing research and development initiatives. You will focus on advanced topics such as panoptic segmentation models for plant and weed detection, optimization of embedded models, 3D visual odometry, etc. You’ll be part of a team of Data and Machine Learning engineers. This role encompasses the entire machine learning lifecycle, from defining state-of-the-art methodologies to deploying sophisticated solutions into production environments and maintaining automated and robust data pipelines.
Responsibilities:
Lead and collaborate with cross-functional teams to identify and define complex machine learning challenges in agriculture.
Design, develop, and implement advanced machine learning algorithms, with a focus on automated diagnosis of mislabeled images and model robustness.
Conduct in-depth research to establish and integrate state-of-the-art approaches in machine learning domains.
Design and execute comprehensive experiments to evaluate and optimize machine learning models.
Collaborate closely with the engineering team to successfully deploy advanced models into production environments.
Mentor and guide junior team members, fostering a culture of continuous learning and improvement.
Qualifications:
Extensive experience in Python, PyTorch, and other relevant machine learning frameworks.
Proven track record of successfully leading and implementing machine learning projects, with a focus on computer vision and related domains.
Strong problem-solving skills, analytical mindset, and ability to thrive in a fast-paced environment.
Excellent communication skills, both technical and non-technical, and a commitment to mentorship.
What We Offer:
Join a dynamic team of industry experts dedicated to making a positive impact on agriculture through technological innovation.
Work with cutting-edge technologies and contribute to the development of groundbreaking solutions.
Enjoy a hybrid-remote work policy, providing flexibility to accommodate your work preferences.
Hiring Process:
HR Interview
Technical Interview
Take-home challenge
In person interviews with various team members
FarmWise is an equal opportunity employer, and we encourage applicants from all backgrounds to apply. If you are passionate about pushing the boundaries of technology in agriculture, we look forward to receiving your application!
Show more
Show less","{'ProgLanguage': ['Python', 'R', 'Go'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': ['PyTorch'], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': ['Teams'], 'Other': ['Machine Learning'], 'FrSoftSkills': ['Communication'], 'EnSoftSkils': ['Communication', 'Flexibility', 'Initiative']}","{'JobDetail': ['Remote', 'Full', 'Junior'], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's']}"
Senior Data Scientist (H/F),Technology & Strategy,"Paris, Île-de-France, France",https://fr.linkedin.com/jobs/view/senior-data-scientist-h-f-at-technology-strategy-3873419835?position=3&pageNum=10&refId=qbIMrhG4cCFECZwbb6jFlQ%3D%3D&trackingId=6SnCjAAFoD35j0VOHylyDA%3D%3D&trk=public_jobs_jserp-result_search-card,"Découvrez Novencia
:
Expert en Data et Intelligence Artificielle, nous aidons nos clients à exploiter et à valoriser leurs données sous toutes ses formes en les accompagnant sur des projets de Data Analyse, Data Gourvernance, Data Architecture, Data Science, et Data Engineering…
Vous avez une solide expérience de minimum 4 ans dans la science des données et vous êtes à la recherche de nouveaux défis ? N'hésitez plus !
Type de contrat : CDI
Démarrage : Dès que possible
Lieu : Paris
En qualité de Senior Data Scientist (H/F), votre rôle sera :
Cadrer et challenger les besoins des utilisateurs, contribuer à la définition des Use Case
Traiter les données, structurées ou non structurées pour extraire des insights à valeur ajoutée
Contrôler la qualité des données, détecter des patterns, des outliers
Proposer et mettre en pratique les modèles statistiques (régressions…) ou de datascience (machine learning…) pour résoudre les problématiques métier
Mener le projet de la phase de POC à l’industrialisation, le plus souvent intégré au sein d’une Feature team
Restituer les résultats (rapports, présentations…)
Pré-requis :
Capacité de comprendre les besoins et enjeux métiers et de les reformuler sous forme d’une problématique Data
Capacité d’expliquer des idées complexes avec des mots simples, claires et précis
Bonne connaissance et maîtrise des algorithmes de Data Science et de Machine Learning
Très bonnes compétences en programmation sur Python avec une maîtrise des librairies python
Bonnes bases des outils de versioning comme git
Une maîtrise des librairies ou d'outils de data visualisation
Maîtrise d’autres langages (comme R et SAS) est un plus
Familier avec une plateforme cloud (AWS, GCP et Azure)
Compréhension des enjeux de mise en production
Compétences dans les technologies Big Data est un plus
Bon niveau d’anglais à l’oral comme à l’écrit
Notre objectif commun est de co-construire votre carrière en fonction de vos aspirations et de vos compétences.
Contactez-moi en message privé ou par mail à s.ziki@technologyandstrategy.com !
Let's make it possible #together
*Nos postes sont ouverts aux personnes bénéficiant d’une Reconnaissance de la Qualité de Travailleur Handicapé (RQTH). T&S Groupe encourage la diversité et l’égalité sur le lieu de travail. Tous les candidats qualifiés H/F/* sont pris en considération pour un emploi sur un même pied d'égalité.
Show more
Show less","{'ProgLanguage': ['Python', 'R', ' R ', 'Go'], 'DataBase': [], 'DataAnalytics': ['R', ' R '], 'BigData': [], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': ['Statistiques'], 'CloudComputing': ['AWS', 'Azure'], 'DevTools': ['Git'], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Big Data', 'Machine Learning', 'Statistiques', 'Cloud'], 'FrSoftSkills': [], 'EnSoftSkils': []}","{'JobDetail': ['Senior'], 'TypeContract': ['CDI'], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's', '4', '4', '4']}"
Docteur en IA/ML/NLP – H/F,Novelis,"Paris, Île-de-France, France",https://fr.linkedin.com/jobs/view/docteur-en-ia-ml-nlp-%E2%80%93-h-f-at-novelis-3903772419?position=4&pageNum=10&refId=qbIMrhG4cCFECZwbb6jFlQ%3D%3D&trackingId=Kv%2ByAM8wNlN4BBND6YLjLA%3D%3D&trk=public_jobs_jserp-result_search-card,"Doctor in AI/ML/NLP
Novelis is a dynamic and agile organization that has chosen to focus on innovation and research. We strongly believe in investment as a tool for progress and a driver of growth; it's part of our DNA. With our Intelligent Automation division and our R&D laboratory, we assist our partners in developing innovative architectures and solutions that combine Data, Artificial Intelligence, and Smart Automation (RPA, OCR, Semantic Analysis).
We are looking for a PhD Doctor to strengthen our R&D Lab in the Paris region.
The Novelis Lab is our dedicated research and development structure. It is the nerve center of Novelis, whose objective is to implement our Innovation and Research strategy.
Your missions
Work on multidisciplinary topics that combine artificial intelligence (machine learning), natural language processing (NLP), and computer vision, reasoning
,
planification
and
optimization
tasks
,
process
automation.
Conduct research and stay up to date with the scientific state of the art related to our research work.
Design, develop, test, and document innovative solutions that meet the challenges of our R&D laboratory.
Contribute to the writing of scientific publications.
Required Profil
We are seeking a highly skilled and motivated individual to join our R&D laboratory as a Doctor of Artificial Intelligence. The successful candidate will have a PhD in artificial intelligence, machine learning, or a related field and will possess knowledge in NLP and/or machine vision and/or machine learning methods. Strong programming skills in Python (Java is a plus) and experience in software modeling, design (UML/Merise), and development are required.
In addition, excellent written and verbal communication skills, a creative mindset, scientific curiosity, and a passion for research are essential for this role. Fluency in English is required, and proficiency in French is a plus. If you are looking for an exciting opportunity to be part of a dynamic R&D team and contribute to cutting-edge research in the field of artificial intelligence, we encourage you to apply.
jobs@novelis.io
As part of its diversity policy, Novelis studies, with equal skills, all applications including those of people with disabilities.
Show more
Show less","{'ProgLanguage': ['Python', 'Java', 'R'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['ML', 'Machine Learning'], 'FrSoftSkills': ['Communication'], 'EnSoftSkils': ['Communication', 'Organization']}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's']}"
Senior Data Scientist,Mirakl,France,https://fr.linkedin.com/jobs/view/senior-data-scientist-at-mirakl-3879684286?position=5&pageNum=10&refId=qbIMrhG4cCFECZwbb6jFlQ%3D%3D&trackingId=TlCTV9up1qvYp4F9cjL7bg%3D%3D&trk=public_jobs_jserp-result_search-card,"Mirakl, leader et pionnier de l’économie de plateforme, propose aux entreprises une suite unique de solutions leur permettant de transformer significativement leur e-commerce afin d'accélérer de façon durable et rentable leur croissance. Depuis 2012, Mirakl accompagne les entreprises B2C et B2B avec la technologie la plus avancée, sécurisée et évolutive leur permettant de digitaliser leur activité et d'élargir leur offre via la marketplace ou le dropship, faciliter la gestion des catalogues et des paiements de leurs fournisseurs pour plus d'efficacité, offrir une expérience d'achat personnalisée à leurs clients, et augmenter leurs profits grâce au retail media. Basée à Paris et Boston, Mirakl est certifiée Great Place to Work.
A propos de Mirakl Labs
Nos équipes techniques et produits, nommées Mirakl Labs, sont principalement réparties entre nos 2 hubs situés à Paris et à Bordeaux. Elles collaborent au quotidien afin d'adresser les problématiques de nos clients et utilisateurs en répondant à différents challenges liés aux nouvelles fonctionnalités, à la scalabilité, la sécurité et l’ergonomie…
Elles opèrent en mode agile et s'organisent en Squads composées d'un Squad Lead, de 5 développeurs, d'un Product Manager et d'un QA. Chaque Squad est spécialisée sur un scope fonctionnel afin de concevoir et réaliser de nouvelles features, leurs évolutions et des APIs (avec un découpage en micro-services). Nos équipes Infrastructure, Architecture, Sécurité, Documentation, Product Design, Data et Support opèrent en transverse en apportant leur expertise et de la cohérence sur l’ensemble des produits.
Toutes les équipes sont responsables de leur périmètre et chacun des collaborateurs apporte son expérience et ses idées. Innovation, feedback et implication dans les prises de décision sont au cœur de notre philosophie.
Et pour favoriser ce partage avec d’autres passionnés, nous sommes sponsors, speakers, et hôtes de différents événements, meetups, et associations de la scène Tech en France. Au cours des dernières années, nous avons participé à des événements tels que Devoxx, ReactEurope, ProductConf et Flupa UX Days.
A propos du job
Intégré(e) dans notre équipe Data Science, votre principale mission sera de prototyper, itérer, et mettre en production des algorithmes en collaboration avec les équipes Produit, les Data Engineers et les équipes de développement. Les sujets que vous traiterez auront un vrai impact sur nos clients : l’ambition est d’exploiter au maximum nos données riches et variées afin de développer leur chiffre d'affaires, d’optimiser la gestion opérationnelle de leur marketplace et de garantir la sécurité des utilisateurs et des transactions.
A propos de l’équipe
Get to Know the Data Science Team That Powers the Mirakl Platform
Voici quelques sujets actuels & futurs :
Catégorisation de produits
Mappings de données produit
Extraction de caractéristiques produit à partir du texte et des images
Détection de comportements frauduleux
Estimation de la date de livraison d’une commande
Monitoring de la qualité de service des vendeurs
Recommandations de produits (upsell, cross-sell, retargeting, …)
Personnalisation des résultats de recherche
Personnalisation de l’affichage de contenu
Prédiction de produits tendance
Aide/Suggestion de réponses au customer service
Affichage de produits sponsorisés ou de publicités maximisant le taux de clic
Ce qu’il y a pour vous dans ce job
Implémenter des algorithmes qui auront un impact visible sur plus de 500 sites e-commerce/marketplaces dans 40 pays dont certains une volumétrie très importantes (millions de produits, de clients, de commandes par an)
Des techniques diverses et variées (Heuristiques, Deep Learning, NLP, Image Processing, Time Series, LLM, etc.)
Une vraie autonomie et responsabilité dans les projets dont vous avez l’ownership
La possibilité d'avoir un contrat freelance ou CDI
Notre stack et nos outils
Python, Tensorflow, Keras, Pytorch, Databricks, Spark, Aws (Amazon Redshift, s3, etc.), SQL, Airflow, Delta Lake
Au quotidien
, vous allez :
Analyser, préparer les données, prototyper des algorithmes
Les mettre en production en collaboration avec les Data Engineers et les équipes de développement
Faire des dashboards afin d’illustrer la pertinence des algorithmes et de monitorer la production
Présenter les résultats au weekly data science
Participer aux sessions de brainstorming de l’équipe
Échanger avec les autres équipes pour affiner les cas d’utilisation, l’expérience utilisateur et les modes d’intégration
Vous aimerez ce job si :
Vous avez 4 à 5 ans d'expérience minimum en tant que Data Scientist, avec une expérience significative en machine learning appliqué en entreprise
Vous avez déjà mis en production des algorithmes de Machine Learning
Vous avez une bonne connaissance des algorithmes de Deep Learning (image et/ou texte) et des architectures State-Of-the-Art - par exemple les Transformers
Vous maîtrisez Python, Tensorflow ou/et PyTorch
Vous avez une expérience en développement Spark
Vous êtes pragmatique, data-driven et orienté métier
Vous aimez avoir l’ownership de vos sujets
Vous êtes autonome et avez un très bon esprit d’équipe
Vous avez un esprit positif : respect et bienveillance font partie de vos valeurs
Vous aimez partager votre travail dans le cadre de présentations internes, dans des conférences ou en rédigeant des articles
Petit plus :
Vous avez une expérience en environnement e-commerce et sur des algorithmes de systèmes de recommandations
Mirakl est engagée en faveur de la diversité, de l’égalité des chances et de l’inclusion. Nous célébrons nos différences car nous sommes convaincus que les qualités visibles et invisibles de chaque Mirakl Worker sont une source de force et d’innovation. Dans le cadre de cet engagement, nous étudions toutes les candidatures sans distinction de : genre, ethnicité, religion, orientation sexuelle, handicap, âge ou toute autre caractéristique protégée par la loi.
Show more
Show less","{'ProgLanguage': ['Python', 'Scala', 'R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': ['Spark', 'Databricks'], 'MachingLearning': ['TensorFlow', 'Keras', 'PyTorch'], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': ['AWS'], 'DevTools': ['Git'], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': ['Airflow'], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Machine Learning'], 'FrSoftSkills': ['Collaboration'], 'EnSoftSkils': ['Collaboration']}","{'JobDetail': [], 'TypeContract': ['CDI'], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's', '5', '5', '5']}"
Data Scientist,SMARTIUM Group,"Strasbourg, Grand Est, France",https://fr.linkedin.com/jobs/view/data-scientist-at-smartium-group-3835671392?position=6&pageNum=10&refId=qbIMrhG4cCFECZwbb6jFlQ%3D%3D&trackingId=KzjUTY3gXkw4%2Fl8yAsMGUw%3D%3D&trk=public_jobs_jserp-result_search-card,"SMARTIUM Group est une jeune startup basée à Starsbourg qui propose des technologies de mesure des rayonnements ionisants dans les domaines de l'industrie, de la santé et de la sécurité. Dans le cadre de notre développement nous recherchons
un(e) Data Scientist
.
Nos solutions embarquées à forte valeur ajoutée permettent une analyse avancée des dnnées fournies par les systèmes de mesure et par la modélisation numérique (monte carlo).
Issue de la valorisation des travaux de recherche, SMARTIUM Group bénéficie d'un lien renforcé avec la recherche (CNRS) et les universités.
Vos missions
Vous êtes titulaire d'un Bac+5 et/ou doctorat en science de préférence, et vous avez pu développer des compétences en simulation Monte Carlo (Genat4, MCNP, ...) et/ou en science des données (analyse statistique, apprentissage automatique, intelligence artificielle). Vous souhaitez valoriser ces compétences dans un environnement professionnel dynamique d'une jeune startup Deeptech en lien direct avec la recherche.
Rattaché directement au CEO vous contriburez au développement de solutions innovantes variées pour des problématiques santés, industrielles et environnementales.
Votre implication et votre réussite feront de vous un élément clé du développement de l'entreprise. Des prerspectives d'encadrement d'équipe sont envisagées pour les profils faisant preuve de qualités managériales.
Vos compétences
Bac +5 en science/ physique nucléaire ; Intérêt fort pour la science des données ; une expérience/formation en simulation Monte Carlo serait un plus ; une apétence pour l'analyse des données ; des connaissance en Intelligence Artificielle serait un plus ;
Avantages
Ambiance startup - Equipe dynamique - Salaire suivant profil + avantages
Show more
Show less","{'ProgLanguage': ['R'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': [], 'FrSoftSkills': [], 'EnSoftSkils': []}","{'JobDetail': [], 'TypeContract': [], 'Salary': ['Salaire'], 'Level': ['Bac+5'], 'Experience': ['a', 'n', 's']}"
"Ingénieur Machine Learning – Paris, France (H/F)",Astek,"Paris, Île-de-France, France",https://fr.linkedin.com/jobs/view/ing%C3%A9nieur-machine-learning-%E2%80%93-paris-france-h-f-at-astek-3882492554?position=7&pageNum=10&refId=qbIMrhG4cCFECZwbb6jFlQ%3D%3D&trackingId=3WYxBQ1r9JujYsvXt49NRQ%3D%3D&trk=public_jobs_jserp-result_search-card,"CDI
Paris - France
Publiée il y a 1 mois
Le Groupe Astek
Ce Que Nous Allons Accomplir Ensemble :
Rejoignez nos équipes et intervenons ensemble sur les projets de nos partenaires autour des enheux d’innovation.
Votre Mission, Si Vous L’acceptez :
Cadrer techniquement les projets et accompagner les Data Scientists dans la construction des modèles en veillant à respecter les bonnes pratiques d’ingénierie logicielle.
Mettre en place la démarche ML OPS
Déployer les modèles en production en respectant des contraintes de coûts, précisions et performances techniques.
Implémenter les outils permettant de monitorer ces modèles en production
Vous ?
Vous êtes issu(e) d’une formation Bac+5 (École d’ingénieur, Université ou équivalent …) en informatique
Vous justifiez d’une expérience significative d’au moins 5 ans au sein d’une équipe dans un environnement Data à l’échelle du SI d’un grand groupe
Vous êtes un bon communiquant et disposez de capacités d’analyse et de synthèse éprouvées
Vous accordez de l’importance à la veille technologique
Compétences Techniques :
Expertise en SPARK et PySpark
Connaissance de Kubernetes
Connaissance de d’Apache Kafka
Une expérience sur un cloud provider public comme Azure (idéalement), AWS, ou GCP
Expertise de développement en Python
Expertise du ML OPS
Compétences Transverses :
Capacité à interagir avec des parties prenantes diverses : Data Scientists, Business analyst, Architectes, Métier
Forte expérience en mode de Delivery Agile (Scrum, Kanban, etc.…)
Etre expert dans les pratiques du Software Craftsmanship (Test Driven, Development, Behavior Driven Development, Clean Code, Code Reviews, etc.)
Et :
Des Connaissances sur Azure DevOps, Azure Pipeline, GIT
Maitrise des Traitements Big Data en mode Streaming
Maitrise des Bases de données relationnelles et NoSQL
Une expérience professionnelle avec des outils comme Azure Databricks, Azure, Machine Learning , Azure Data Lake Storage ou encore Azure Data Factory
Le Groupe Astek
Créé en France en 1988, Astek est un acteur mondial de l’ingénierie et du conseil en technologies. Fort de son expertise dans de nombreux secteurs industriels et tertiaires, Astek accompagne ses clients internationaux dans le déploiement intelligent de leurs produits et de leurs services, et dans la mise en œuvre de leur transformation digitale.
Depuis sa création, le Groupe a fondé son développement sur une forte culture d’entrepreneuriat et d’innovation, et sur l’accompagnement et la montée en compétence de
ses 7800 collaborateurs
qui s’engagent chaque jour à promouvoir la complémentarité entre les technologies numériques et l’ingénierie des systèmes complexes.
Rejoignez un Groupe en fort développement en France et à travers le monde ayant réalisé un chiffre d’affaires de 600 M€ en 2023.
Tous les détails sur le Groupe sur le site https://astekgroup.fr. Et vous pouvez aussi nous suivre sur notre blog : https://blog.groupeastek.com.
Rencontrons-nous
Notre projet commun vous plait ?
Postulez à cette annonce, et soyez transparent !
Notre Talent Acquisition Officer, vous contactera pour un premier échange téléphonique.
Puis vous rencontrerez votre futur manager, avec lequel vous échangerez autour d’Astek, de votre parcours, de vos attentes et de votre future mission .
Enfin, vous rencontrerez notre Directeur de département, avec lequel vous pourrez valider votre intérêt et adéquation pour le poste et finaliser les éléments contractuels.
Nos Plus
Astek est green et fait bénéficier ses salariés d’une indemnité kilométrique vélo
Une politique CARE sur-mesure déployée par nos équipes RH pour nos collaborateurs (https://astekgroup.fr/engagements)
Notre charte de la Diversité
Bienvenue dans la team ! Allez-y, maintenant c’est à vous de jouer !
Mots-clés :
ingénieur – ingénieure – consultant – consultante
Caractéristiques de l'emploi
Catégorie Chef de Projet
Job Industry Aérospatial / Défense / Sécurité, Distribution / Services Internet, Energie / Sciences de la Vie / Autres industries, Finance / Gouvernement, Télécom / Média, Transports Terrestres
Postuler en ligne
Nom *
Prénom *
Email *
Un email valide est requis.
Téléphone *
Un numéro de téléphone valide est requis.
Joindre un CV *
Mots-clés :
ingénieur – ingénieure – consultant – consultante
Show more
Show less","{'ProgLanguage': ['Python', 'R', 'Go'], 'DataBase': ['SQL', 'NoSQL'], 'DataAnalytics': ['R'], 'BigData': ['Spark', 'Databricks'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': ['AWS', 'Azure'], 'DevTools': ['Git'], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': ['Apache Kafka'], 'Automation': ['Kubernetes', 'Chef'], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': ['Kubernetes'], 'Collaboration': [], 'Other': ['DevOps', 'Big Data', 'ML', 'Machine Learning', 'Cloud'], 'FrSoftSkills': [], 'EnSoftSkils': []}","{'JobDetail': [], 'TypeContract': ['CDI'], 'Salary': [], 'Level': ['Bac+5'], 'Experience': ['a', 'n', 's', '5', '5', '5']}"
ALTERNANCE - Data Scientist,Moët Hennessy,"Paris, Île-de-France, France",https://fr.linkedin.com/jobs/view/alternance-data-scientist-at-mo%C3%ABt-hennessy-3840470791?position=8&pageNum=10&refId=qbIMrhG4cCFECZwbb6jFlQ%3D%3D&trackingId=fFBSXJet%2FH15eCJsxVvYKg%3D%3D&trk=public_jobs_jserp-result_search-card,"Moët Hennessy est à la recherche d'une personne motivée pour rejoindre son Centre d'Expertise (CoE) Data & AI en tant qu'alternant.e Data Scientist.
Dans ce rôle, vous aurez l'opportunité de contribuer au développement d'un ""compliance bridge"" visant à valider automatiquement la conformité aux différentes réglementations en vigueur du contenu produit par ou pour Moët Hennessy (texte, image, vidéo, etc.).
Cela nécessitera, notamment, de mettre en œuvre des compétences en Machine Learning (Object Detection, Object Segmentation, NLP, GenAI...).
En plus de cette mission principale, vous serez amené.e à travailler sur d'autres sujets selon les besoins (implémentation de démonstrateur IA, acculturation des métiers, veille technologique...).
Le CoE Data & AI est une équipe au sein du département Data & AI de la DSI de Moët Hennessy. Cette direction a pour mission d'accélérer la transformation de nos différents métiers, de la vigne jusqu'au verre.
Descriptif du poste
:
Participer au développement de la ""couche de conformité"" afin d'assurer la conformité du contenu avec les réglementations locales (par exemple, la Loi Evin) et les normes internes.
Participer aux phases d'idéation, d'étude de faisabilité et de lancement de projets IA
Participer pour ces projets aux phases de modélisation mathématique
Effectuer des analyses exploratoires des données
Contribuer aux activités de préparation des données (nettoyage de donnée, feature engineering, feature selection…)
Soutenir la conception et la mise en œuvre des modèles
Contribuer au design des pipelines de machine learning incluant notamment la mesure de performance des modèles et à leur monitoring
Contribuer à l'industrialisation des modèles tout en respectant les normes du groupe et les principes MLOps
Documenter les projets d'intelligence artificielle
Contribuer à la veille technologique du COE Data & AI
Nous recherchons une personne en alternance inscrite dans un programme master 1 ou master 2 en data science.
Rythme d'alternance souhaité :
15j / 15j de préférence (autres rythmes possibles).
Durée de l'alternance souhaitée :
1 an
Compétences recherchées :
Maitrise de Python
Bonne compréhension des bonnes pratiques de développement logiciel
Connaissance de Dataiku
Connaissance des services GCP (en particulier Cloud Run, Vertex AI
Anglais professionnel
Français courant
Autonomie et pro activité
Esprit de synthèse
Capacité de vulgarisation
Qualités relationnelles et rédactionnelles
Informations complémentaires :
Période : rentrée de septembre 2024
Localisation géographique de l'offre : PARIS
Déplacements occasionnels à prévoir en Champagne (Epernay)
Show more
Show less","{'ProgLanguage': ['Python', 'R'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['ML', 'Machine Learning', 'Cloud'], 'FrSoftSkills': [], 'EnSoftSkils': []}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's']}"
ML Engineer - CDI - F/H,Modjo,"Paris, Île-de-France, France",https://fr.linkedin.com/jobs/view/ml-engineer-cdi-f-h-at-modjo-3909458542?position=9&pageNum=10&refId=qbIMrhG4cCFECZwbb6jFlQ%3D%3D&trackingId=7SkUGLBN2gIeKFsaIVLtGw%3D%3D&trk=public_jobs_jserp-result_search-card,"Modjo:
Modjo is the leader European AI Revenue Platform whose mission is to drive revenue teams productivity & performance with AI-extracted knowledge from customers interactions.
While AI is challenging how companies work across the world and all industries, Modjo brings these new capabilities to sales teams thanks to a platform that analyzes all interactions sales people have with their customers to improve sales teams productivity, drive strategy, and increase revenue.
We are a growing team of over 65 people, helping over 400 clients like BouyguesTelecom, Doctolib, Spendesk and Payfit in France and abroad. 🌎
Just like Slack, Zoom or Hubspot, Modjo is a product company. This means that our product is the core of what we are doing and how we are creating value to customers. Therefore, the success of the company relies on the capacity of its Tech & Product teams to deliver together the best product to its users.
Team organization :
The overall tech department is composed of 10 Software Engineers (2 squads), 2 ML Engineers, a Data Team (1 team lead + 1 analyst) and the CTO. You will be part of the Data Science team alongside the other ML Engineers.
Mission:
Modjo's core capabilities include capturing conversations between sales teams and their customers (video & audio recordings, emails..) and leveraging this data thanks to speech-to-text and various LLM-based processings to extract and structure data out of it.
As part of this, your main missions will be:
Collaborating with Product and Engineering to build features that require machine-learning expertise
Build, maintain and optimize our infrastructure for doing production machine learning including our speech-to-text stack (processing thousands of hours of audio every day) and our infrastructure for using LLMs
Design and implement processes, tools and pipelines in order to work efficiently with LLMs for our multiple use cases
Stay up to date with latest speech-to-text and LLM technologies in order to include them in the product and build the relevant technological asset for Modjo to differentiate from basic competition. This includes exploring model-finetuning models and RAGs
Your profile :
We think you would be a great fit if :
You have 3y+ experience in Machine Learning and Engineering
You have experience working with and knowledge about NLP, LLM and speech-to-text
You have experience with putting models in production, including monitoring and CI/CD
You are interested in solving real world use cases with LLMs and building the proper technology around it
You are eager to learn a lot in an autonomous way, both in Science and Engineering fields
You are willing to work in English (language of the team)
You want to join a company where the product you will be building is core to our strategy
You are looking for a challenging job, but also an environment where you can thrive and have fun on a day-to-day basis :)
We are looking for someone who will thrive and share our values:
😃 Pleasure
“If you Smile, things will work out” - Serena Williams
✅ Action
“Done is better than perfect” - Sheryl Sandberg
📚 Continuous Learning
“Amateurs call it Genius, masters call it practice” - Thierry Henry
🤲 Team Spirit
“Great things in business are never done by one person; they’re done by a team of people” - Steve Jobs
Show more
Show less","{'ProgLanguage': ['R'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': ['Slack', 'Teams'], 'Other': ['ML', 'Machine Learning', 'CI/CD'], 'FrSoftSkills': [], 'EnSoftSkils': ['Organization']}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's']}"
