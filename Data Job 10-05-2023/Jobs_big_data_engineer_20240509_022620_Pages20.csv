srouce,title,company,location,link,description,skills,details
LinkedIn,INGÉNIEUR DATA,Akademija Oxford,"Ille-et-Vilaine, Brittany, France",https://fr.linkedin.com/jobs/view/ing%C3%A9nieur-data-at-akademija-oxford-3912800588?position=2&pageNum=0&refId=TDTc9UZJy78L%2BED7EV%2BMrg%3D%3D&trackingId=qxkAxO3kCKPFsjtGrF%2F6AA%3D%3D&trk=public_jobs_jserp-result_search-card,"Vous souhaitez intégrer une école à taille humaine ? Vous êtes intéressé.es par la donnée ? Sup de Vinci propose une formation complète, en Mastère Big Data & Intelligence Artificielle (2 années en alternance).
L’école Sup de Vinci, Rennes, accompagne l’une de ses entreprises partenaires dans son projet de recrutement d’un profil ingénieur data, en alternance pour la rentrée 2022.
Show more
Show less","{'ProgLanguage': ['R'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Big Data'], 'FrSoftSkills': [], 'EnSoftSkils': []}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's']}"
LinkedIn,Hadoop Data Engineer (F/H),Thales,"Vélizy-Villacoublay, Île-de-France, France",https://fr.linkedin.com/jobs/view/hadoop-data-engineer-f-h-at-thales-3890949542?position=3&pageNum=0&refId=TDTc9UZJy78L%2BED7EV%2BMrg%3D%3D&trackingId=NUzkjoDiCgv%2B68vSb9TBHw%3D%3D&trk=public_jobs_jserp-result_search-card,"QUI SOMMES-NOUS ?
Thales est un leader mondial des hautes technologies comptant plus de 81 000 collaborateurs présents sur tous les continents. Le Groupe investit dans les innovations du numérique et de la « deep tech » – big data, intelligence artificielle, connectivité, cybersécurité et quantique – pour construire un avenir de confiance, essentiel au développement de nos sociétés, en plaçant l’humain au cœur des décisions.
Thales propose des solutions, services et produits qui aident ses clients – entreprises, organisations, Etats – dans cinq grands marchés vitaux pour le fonctionnement de nos sociétés : identité et sécurité numériques, défense, aéronautique, espace, et transport.
QUI ETES-VOUS ?
Diplômé d’un Bac+5 en école d’ingénieur ou équivalent universitaire avec une spécialisation en informatique, vous avez au moins 3 ans d'expérience dans les technologies Big Data.
CE QUE NOUS POUVONS ACCOMPLIR ENSEMBLE :
En tant que Data Engineer, vous jouerez un rôle clé dans la conception, le développement et la maintenance de notre infrastructure de données, ainsi que dans la transformation et la gestion des flux de données.
VOS MISSIONS :
• Concevoir, développer et déployer des solutions Big Data en utilisant les technologies Hadoop.
• Mettre en place des pipelines de données performants pour l'ingestion, le traitement et le stockage des données massives.
• Collaborer étroitement avec les équipes métier pour comprendre leurs besoins en matière d'analyse de données et proposer des solutions adaptées.
• Optimiser les performances des clusters Hadoop pour garantir une exploitation efficace des données.
• Assurer la qualité et la fiabilité des données traitées, en mettant en place des processus de validation et de nettoyage.
• Identifier et résoudre les problèmes liés à l'infrastructure Big Data et proposer des améliorations.
• Travailler en étroite collaboration avec les Data Scientists et les Data Analysts pour fournir des insights pertinents à partir des données.
Innovation, passion, ambition : rejoignez Thales et créez le monde de demain, dès aujourd’hui.
Show more
Show less","{'ProgLanguage': ['R'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': ['Hadoop'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Big Data'], 'FrSoftSkills': ['Collaboration', 'Organisation'], 'EnSoftSkils': ['Collaboration']}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': ['Bac+5'], 'Experience': ['a', 'n', 's', '3', '3', '3']}"
LinkedIn,Data Engineer / Développeur Big Data # H/F,Air France,"Provence-Alpes-Côte d'Azur, France",https://fr.linkedin.com/jobs/view/data-engineer-d%C3%A9veloppeur-big-data-%23-h-f-at-air-france-3900080172?position=4&pageNum=0&refId=TDTc9UZJy78L%2BED7EV%2BMrg%3D%3D&trackingId=r6G3xtDtwyoSIYOezOARsw%3D%3D&trk=public_jobs_jserp-result_search-card,"Description du poste
Intitulé du poste
Data Engineer / Développeur Big Data # H/F
Métier
Systèmes d'informations - Développement
Catégorie socio-professionnelle
Cadre
Présentation du contexte
Vous avez peut-être déjà voyagé avec nous, mais que connaissez-vous de nos métiers et de la richesse des données qu’ils génèrent au quotidien ? Comment le traitement et l’exploitation de ces données peut contribuer à notre stratégie de Revenue Management, ou encore aux multiples opérations à réaliser pour permettre à un vol de partir à l’heure ?
Air France-KLM fait rêver 104 millions de passagers par an, en les emmenant vers plus de 250 destinations, grâce à une flotte de plus de 500 appareils. Le Groupe emploie 80 000 collaborateurs partout dans le monde :les opportunités sont vastes pour mettre à profit ses compétences, apprendre et se développer !
Le département de développement DATA, OR & AI d’Air France, au sein de la direction des Systèmes d’Information, intervient dans toute la chaîne de captation et de traitement des données du groupe pour délivrer à nos métiers des solutions applicatives clés en main.
Le département est également en charge de l’ensemble des outils techniques (ETL, DataLakes, DataWarehouses, Data visualisation) et du développement des talents et compétences de Data Engineering.
Notre mission ? Transformer la donnée brute en décision intelligente, pour mieux optimiser les métiers d’Air France – KLM !
Pour cela, nous avons chacun un rôle essentiel à jouer, pourquoi le vôtre ne serait pas celui de Data Engineer et de développeur Big Data ?
Description de la mission
Au sein de notre département, vous travaillerez main dans la main avec d’autres Data Engineers et développeurs Big Data ainsi qu’avec des spécialistes des métiers.
Intégré au sein d’une product team agile passionnée et dynamique :
Vous participez à l’analyse des besoins métiers du commercial, des opérations aériennes, de l’exploitation sol en aéroport, de la maintenance aéronautique ou encore du Cargo.
Vous contribuez à la définition, au développement, à l’industrialisation et à la maintenance d’applications Big Data ou en Business Intelligence
Vous présentez la restitution de vos travaux et accompagnez les utilisateurs d’un point de vue fonctionnel ou méthodologique
Vous serez en contact avec les directions métier du groupe Air France KLM.
Nous attachons beaucoup d'importance au développement des compétences de nos collaborateurs ainsi qu’à leur offrir des conditions de travail favorables à l’autonomie et aux missions à forte valeur ajoutée. L'ouverture, le respect, la bienveillance et le partage sont des valeurs humaines portées par l'entreprise.
Profil recherché
Vous êtes diplômé de niveau Master ou Ingénieur dans les domaines informatiques, vous avez acquis une expérience professionnelle dans le développement d’applications.
Vous disposez d’une expérience du développement indispensable en Backend / Java
Vous maîtrisez les bases de données relationnelles et le langage SQL
En Complément, Vous Avez Une Connaissance Ou Une Expérience Dans Tout Ou Partie Des Concepts Ou Outils Suivants
Environnement Big Data (Spark, Hadoop, Elasticsearch, Kafka, ...)
Base de données noSQL (MongoDB, HBase, REDIS) ou Data Warehouse Teradata
Outil de Datavisualisation (Spotfire, PowerBI, Qlik ou Kibana)
Solutions de Cloud (GCP) et hybride (GCP / AZURE)
(Ces compétences complémentaires ou manquantes pouvant aussi s'acquérir à travers un parcours de reskilling et de formations aux outils du data engineering dispensé en interne).
Vous avez participé à des projets organisés en Scrum ou Kanban, et avez peut-être même œuvré comme Scrum-Master, ce qui vous permettra de vous intégrer aisément au sein d’une Product Team. Votre esprit de synthèse, votre force de conviction et votre maîtrise de la communication facilitent les décisions avec l’ensemble des collaborateurs de l’équipe, éventuellement en langue anglaise, à l’écrit comme à l’oral.
Vous êtes autonome, rigoureux(se), responsable et curieux(se), vous aimez travailler en équipe. Vous possédez de bonnes capacités d'écoute, d'analyse, de synthèse et de communication.
Et bien sûr, vous êtes passionné(e), enthousiaste et ingénieux(se)
Ce que nous vous offrons
De la création de valeur pour l’ensemble des métiers d’Air France KLM
Des challenges et problématiques complexes à résoudre
L’opportunité de déployer des solutions Data industrielles à l’échelle !
Une grande part de responsabilité dans une structure hiérarchique horizontale
Un important degré de liberté pour apprendre et développer son expertise au sein de l’équipe
On vous attend le plus rapidement possible ! Et pour une durée indéterminée ;)
Type de contrat
CDI
Temps partiel possible
Non
Type d'horaires
Administratif
Profil candidat
Niveau d'études min. requis
Bac + 5 et plus
Langue
Anglais (4 - Confirmé / C1)
Localisation du poste
Localisation du poste
France, Provence-Alpes-Côte d'Azur, Alpes Maritimes (06)
Site
Valbonne
Show more
Show less","{'ProgLanguage': ['Java', 'R', 'Go'], 'DataBase': ['SQL', 'NoSQL', 'HBase', 'Elasticsearch'], 'DataAnalytics': ['R'], 'BigData': ['Hadoop', 'Spark'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': ['PowerBI'], 'Statistics': [], 'CloudComputing': ['Azure'], 'DevTools': [], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': ['HBase'], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Big Data', 'Cloud'], 'FrSoftSkills': ['Communication'], 'EnSoftSkils': ['Communication']}","{'JobDetail': ['Hybride', 'Confirmé'], 'TypeContract': ['CDI'], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's']}"
LinkedIn,APPRENTI DATA ENGINEER (H/F),Akademija Oxford,"Paris, Île-de-France, France",https://fr.linkedin.com/jobs/view/apprenti-data-engineer-h-f-at-akademija-oxford-3917872047?position=5&pageNum=0&refId=TDTc9UZJy78L%2BED7EV%2BMrg%3D%3D&trackingId=rmaFYM2oHNOKTV4fxpDKVg%3D%3D&trk=public_jobs_jserp-result_search-card,"Une de nos entreprises partenaires, ESN située à Paris, recherche un Apprenti Data Engineer (H/F) préparant un bac +4/+5 spécialité Big Data pour la rentrée de Septembre 2021.
Show more
Show less","{'ProgLanguage': ['R'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Big Data'], 'FrSoftSkills': [], 'EnSoftSkils': []}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's']}"
LinkedIn,APPRENTI.E INGÉNIEUR DATA,Akademija Oxford,"Bordeaux, Nouvelle-Aquitaine, France",https://fr.linkedin.com/jobs/view/apprenti-e-ing%C3%A9nieur-data-at-akademija-oxford-3912806043?position=6&pageNum=0&refId=TDTc9UZJy78L%2BED7EV%2BMrg%3D%3D&trackingId=UHqnpuGea9Itifl0Aoj1Lg%3D%3D&trk=public_jobs_jserp-result_search-card,"Vous souhaitez intégrer une école à taille humaine ? Vous êtes intéressé par le secteur du développement informatique ? Sup de Vinci propose une formation complète en Mastère Big Data.
L’école Sup de Vinci à Bordeaux, accompagne l’une de ses entreprises partenaires dans son projet de recrutement d’un profil Ingénieur Data, en alternance pour la rentrée 2022.
Show more
Show less","{'ProgLanguage': ['R'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Big Data'], 'FrSoftSkills': [], 'EnSoftSkils': []}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's']}"
LinkedIn,Data Engineer (H/F) | POEI,DataScientest.com,"Puteaux, Île-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-h-f-poei-at-datascientest-com-3909358387?position=7&pageNum=0&refId=TDTc9UZJy78L%2BED7EV%2BMrg%3D%3D&trackingId=dzcO8ZpLWKV7kVqbDMyaZA%3D%3D&trk=public_jobs_jserp-result_search-card,"Data Engineer (H/F) | POEI
Puteaux
CDI
Postuler
Retour
Datascientest Is Hiring!
Data Engineer (H/F) | POEI
À propos
Vous êtes demandeur d'emploi et vivement intéressé(e) par les métiers de la Data ?
Rejoignez DataScientest en intégrant une formation 100% financée par Pôle Emploi afin d’acquérir les compétences clés qui vous permettront de booster votre carrière en tant que Data Engineer Cloud, un métier en tension et en plein essor.
Cette formation est certifiée par l'Ecole des Mines ParisTech, et inclut le passage de certifications éditeurs (AWS, Microsoft Azure ou encore GCP) qui garantissent votre employabilité.
Après avoir suivi notre formation de Cloud Data Engineer, vous rejoindrez, en CDI , notre entreprise partenaire.
Les candidats retenus bénéficieront d’une formation intensive, entièrement prise en charge par le dispositif POEI (Préparation Opérationnelle à l’Emploi Individuel) avec Pôle-Emploi.
Descriptif du poste
En Tant Que Cloud Data Engineer, Vous Aurez Pour Missions De Proposer Les Meilleures Solutions Aux Entreprises Afin D'optimiser Leur Activité, à Travers Les Missions Suivantes
Développement de solutions permettant de traiter des volumes importants de données,
Conception, collection et fabrication des données brutes,
Création d'outils et algorithmes pour le traitement des données,
Préparation des données pour le Data Analyst,
Sécurisation des Pipelines données pour les Data Analysts et Data Scientists,
Organisation de l'architecture du cloud
Profil recherché
Ce Que Nous Vous Offrons
Une certification de l'Ecole des Mines ParisTech
Un CDI auprès d'un de nos partenaires, expert européen dans le traitement et l'exploitation des données
Un salaire attractif à la clé : 35 000€ à 48 000€ selon le profil
**Votre profil : **
Issu(e) d’une filière scientifique ou informatique vous disposez d'un bac+5 ou d’un diplôme d’ingénieur,
Vous disposez idéalement d’une expérience significative en développement informatique, en architecture réseaux ou dans la Data,
Vous maîtrisez un langage objet type Java, Python, C++, etc.
Vous êtes inscrit(e) à Pôle Emploi
Informations complémentaires
Type de contrat : CDI
Date de début : 01 septembre 2023
Lieu : Puteaux
Niveau d'études : Bac +5 / Master
Expérience : > 1 an
Télétravail ponctuel autorisé
Salaire : entre 35000€ et 48000€ / an
Vous êtes intéressé par cette offre ?
Postuler
Show more
Show less","{'ProgLanguage': ['Python', 'Java', 'C++', 'R', 'Go'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': ['AWS', 'Azure'], 'DevTools': [], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Cloud'], 'FrSoftSkills': ['Organisation'], 'EnSoftSkils': []}","{'JobDetail': [], 'TypeContract': ['CDI'], 'Salary': ['35'], 'Level': ['Bac+5'], 'Experience': ['a', 'n', 's']}"
LinkedIn,"Big Data Engineer – Paris, France (H/F)",Astek,"Paris, Île-de-France, France",https://fr.linkedin.com/jobs/view/big-data-engineer-%E2%80%93-paris-france-h-f-at-astek-3470775874?position=8&pageNum=0&refId=TDTc9UZJy78L%2BED7EV%2BMrg%3D%3D&trackingId=q4j7hA8VWh11yPRBq9Ju3Q%3D%3D&trk=public_jobs_jserp-result_search-card,"CDI
Paris - France
Publiée il y a 2 mois
Le Groupe Astek
Ce Que Nous Allons Accomplir Ensemble :
Nous rejoindre en tant que
Big Data Engineer (H/F),
afin d’accompagner un opérateur télécoms, Leader en Europe dans la création d’une infrastructure cloud (IAAS) performante, robuste et sécurisée.
Un challenge portant sur des millions d’utilisateurs dans un environnement technique innovant, stratégique et où l’entraide et la bonne humeur priment !
Votre Mission, Si Vous L’acceptez :
Qualifier les données et les résultats
Conception technique des solutions
Décliner les impacts de la stratégie et des innovations technologiques au sein des processus et outils de l’exploitant SI
Assurer l’accompagnement et le déploiement des évolutions des processus et outils
Contribuer aux programmes de transformation DevOps, Cloud et catalogues des offres SI
Développer des fonctions transverses et les « uses cases »
Accompagner la phase de mise en production
Votre Future Équipe :
Vous intégrerez une équipe à la fois technique et fonctionnel, qui œuvre chaque jour pour développer et maintenir en conditions opérationnelles l’ensemble des solutions IT !
L’équipe est en interaction avec des clients à la fois internes et externes.
Votre stack de jeu
Système d’exploitation : Linux
Environnement Big data : Hadoop, Spark, Scala
Cloud computing : GCP ou AWS
Base de données : No SQL (Cassandra, Mongo DB)
Dataviz : Power BI ou Kibana
Des notions en développement feront la différence !
Les Petits Plus Du Projet :
Vous évoluerez au sein d’une équipe impliquée et réactive et interviendrez sur un projet polyvalent et à forte valeur ajoutée.
Vous ?
Diplômé(e) d’une école d’ingénieur ou équivalent de niveau Bac+5.
Vous justifiez idéalement d’une expérience d’au moins 3 ans d’expériences sur un poste similaire ?
Vous faite preuve de proactivité et d’esprit d’équipe, êtes doté(e) d’un excellent sens de l’organisation et vous aimez les challenges et la résolution de problème ?
Alors ce poste est fait pour vous, n’hésitez plus et rejoignez l’aventure ASTEK !
Astek
Créé en France en 1988, Astek est un acteur mondial de l’ingénierie et du conseil en technologies. Fort de son expertise dans de nombreux secteurs industriels et tertiaires, Astek accompagne ses clients internationaux dans le déploiement intelligent de leurs produits et de leurs services, et dans la mise en œuvre de leur transformation digitale.
Depuis sa création, le Groupe a fondé son développement sur une forte culture d’entrepreneuriat et d’innovation, et sur l’accompagnement et la montée en compétence de
ses 7800 collaborateurs
qui s’engagent chaque jour à promouvoir la complémentarité entre les technologies numériques et l’ingénierie des systèmes complexes.
Rejoignez un Groupe en fort développement en France et à travers le monde ayant réalisé un chiffre d’affaires de 600 M€ en 2023.
Tous les détails sur le Groupe sur le site https://astekgroup.fr. Et vous pouvez aussi nous suivre sur notre blog : https://blog.groupeastek.com.
Rencontrons-nous
Notre projet commun vous plait ?
Postulez à cette annonce, et soyez transparent !
Maud, notre Talent Acquisition Referent, vous contactera pour un premier échange.
Puis vous rencontrerez Yoram, votre futur manager, avec lequel vous échangerez autour d’Astek, de votre parcours, de vos attentes et de votre future mission .
Enfin, vous rencontrerez Anthime, notre Directeur d’agence avec lequel vous pourrez valider votre intérêt et adéquation pour le poste et finaliser les éléments contractuels.
Nos Plus
Astek est green et fait bénéficier ses salariés d’une indemnité kilométrique vélo
Une politique CARE sur-mesure déployée par nos équipes RH pour nos collaborateurs (https://astekgroup.fr/engagements)
Notre charte de la Diversité
Mots-clés :
ingénieur – ingénieure – consultant – consultante – developpement – Scala – Data
Caractéristiques de l'emploi
Catégorie Ingénieur
Job Industry Télécom / Média
Postuler en ligne
Nom *
Prénom *
Email *
Un email valide est requis.
Téléphone *
Un numéro de téléphone valide est requis.
Joindre un CV *
Mots-clés :
ingénieur – ingénieure – consultant – consultante – developpement – Scala – Data
Show more
Show less","{'ProgLanguage': ['Scala', 'R', 'Go'], 'DataBase': ['SQL', 'Cassandra'], 'DataAnalytics': ['R'], 'BigData': ['Hadoop', 'Spark'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': ['Power BI'], 'Statistics': [], 'CloudComputing': ['AWS'], 'DevTools': ['Git'], 'Os': ['Linux'], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['DevOps', 'Big Data', 'Cloud'], 'FrSoftSkills': ['Organisation'], 'EnSoftSkils': []}","{'JobDetail': [], 'TypeContract': ['CDI'], 'Salary': [], 'Level': ['Bac+5'], 'Experience': ['a', 'n', 's', '3', '3', '3']}"
LinkedIn,Data Engineer - Bordeaux,Capgemini,"Bordeaux, Nouvelle-Aquitaine, France",https://fr.linkedin.com/jobs/view/data-engineer-bordeaux-at-capgemini-3889788624?position=9&pageNum=0&refId=TDTc9UZJy78L%2BED7EV%2BMrg%3D%3D&trackingId=qJ4q4DZbIEQJgFfJAS3paA%3D%3D&trk=public_jobs_jserp-result_search-card,"Choisir Capgemini, c'est choisir une entreprise où vous serez en mesure de façonner votre carrière selon vos aspirations. Avec le soutien et l'inspiration d'une
communauté d’experts dans le monde entier, vous pourrez réécrire votre futur. Rejoignez-nous pour redéfinir les limites de ce qui est possible, contribuer à libérer la
valeur de la technologie pour les plus grandes organisations et participer à la construction d’un monde plus durable et inclusif.
Vos missions :
Vous êtes passionné par le domaine de la Data, vous souhaitez prendre part à des projets d'envergure, concevoir des solutions, les implémenter et les faire évoluer?
Alors rejoignez notre équipe Data Engineering Services au sein de Capgemini Cloud Infrastructure Services en tant que Data Engineer.
Vous avez acquis une expérience solide dans le développement, la mise en œuvre et l’optimisation de solutions pour le traitement d'un grand volume de données, vous êtes capable de créer des solutions qui répondent aux besoins métiers et IT, alors rejoignez notre équipe d’experts.
En qualité de Data engineer, vos missions sont les suivantes :
▪ Concevoir et développer des solutions Data/IA.
▪ Accompagner les Métier dans la compréhension et la mise en œuvre de solution orientées données.
▪ Collaborer avec les Dev, les Ops, les experts infrastructures dans la construction de solutions et d’infrastructures axées sur les données.
▪ Gérer un écosystème de partenaires data et assurer un haut niveau d'expertise
▪ Assurer un rôle de veille technologique sur tous les outils autours de la data, de l’IA et de la BI.
Votre profil :
Vous êtes issu d’une formation ingénieur ou équivalent bac+5 informatique spécialisée en DATA et vous justifiez d’une expérience de 3 à 5 ans dans un rôle similaire. Expert dans une technologie de base de données relationnelle (PostgreSQL, Oracle...)
Expert dans une technologie de base NoSQL (MongoDB, Cassandra...)
Vous maitrisez un framework de manipulation de données (Hadoop, Spark, Kafka...)
Vous maitrisez les concepts DevOps et avez de bonnes notions en scripting et développement
Vous avez une expérience des outils BI et de data visualisation (Kibana, PowerBI...)
La maitrise de l'anglais est nécessaire.
3 raisons de nous rejoindre :
Qualité de vie au travail :
accord de télétravail en France et à l’international, accord sur l’égalité professionnelle, la parentalité, l’équilibre des temps et la mobilité durable.
Apprentissage en continu :
certifications et formations en libre accès, accompagnement sur mesure avec votre career manager, parcours d’intégration sur 9 mois.
Avantages groupe & CSE :
plan actionnariat, tarif préférentiels, remboursement partiel vacances, remboursement de votre abonnement sportif ou culture
Nos engagements et priorités :
Le groupe Capgemini encourage une culture inclusive dans un cadre multiculturel et handi-accueillant. En nous rejoignant, vous intégrez un collectif qui valorise la diversité, développe le potentiel de ses talents, s’engage dans des initiatives solidaires avec ses partenaires, et se mobilise pour réduire son impact environnemental sur tous ses sites et auprès de ses clients.
À propos de Capgemini :
Capgemini est un leader mondial, responsable et multiculturel, regroupant près de 350 000 personnes dans plus de 50 pays. Fort de 55 ans d’expérience, nous sommes un partenaire stratégique des entreprises pour la transformation de leurs activités en tirant profit de toute la puissance de la technologie et des innovations dans les domaines en perpétuelle évolution tels que le cloud, la data, l’Intelligence Artificielle, la connectivité, les logiciels, l’ingénierie digitale ou les plateformes.
Get The Future You Want* | www.capgemini.com/fr-fr
*Capgemini, le futur que vous voulez
Show more
Show less","{'ProgLanguage': ['R', 'Go'], 'DataBase': ['SQL', 'NoSQL', 'Cassandra'], 'DataAnalytics': ['R'], 'BigData': ['Hadoop', 'Spark'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': ['PowerBI'], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git'], 'Os': [], 'DBMS': ['PostgreSQL', 'Oracle'], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['DevOps', 'Cloud'], 'FrSoftSkills': ['Organisation'], 'EnSoftSkils': ['Initiative']}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': ['Bac+5'], 'Experience': ['a', 'n', 's', '5', '5', '5']}"
LinkedIn,Big Data Engineer - H/F,Lincoln France,"Île-de-France, France",https://fr.linkedin.com/jobs/view/big-data-engineer-h-f-at-lincoln-france-3834466740?position=10&pageNum=0&refId=TDTc9UZJy78L%2BED7EV%2BMrg%3D%3D&trackingId=2dHhajJA1zlXIU1bYbcHBA%3D%3D&trk=public_jobs_jserp-result_search-card,"Poste CDI : Consultant Big Data Engineer - H/F (Hadoop, Spark, PySpark, Databricks, Kafka, Python, Scala, Java, Hive, MongoDB, etc.)
Lincoln Pure Player Data
💡: Réinventant l'analyse
depuis 30 ans
. Experts en Modern BI, Big Data et Science des données 📊. Nous transformons les données en solutions pour les grands comptes, des secteurs bancaire, retail, télécoms, industriel, santé, et plus encore 💼.
Description du poste
🎯
Missions
:
Analyser les besoins clients en matière d'analyse de données
Développer et optimiser des pipelines de données distribués
Concevoir et mettre en œuvre des solutions Big Data adaptées
Intégrer les solutions dans les environnements existants
Fournir un support technique et une expertise tout au long des projets
🔍
Prérequis
:
Expertise avérée en Hadoop, Spark, PySpark, Databricks, Kafka, Hive
Maîtrise de Python, Scala, Java
Connaissance des bases de données NoSQL (MongoDB, etc.)
Capacité à travailler en équipe et à communiquer efficacement avec les clients
🌟
Avantages :
Environnement collaboratif et innovant
Formations certifiantes et accompagnement individualisé
Télétravail et horaires flexibles
Rémunération compétitive avec avantages sociaux attrayants
Possibilité de mobilité à Lille, Lyon ou Aix-en-Provence
✨
Processus de recrutement
: 2 entretiens (RH et technique)
Si vous êtes passionné par les défis de la Data et que vous souhaitez rejoindre une équipe dynamique et innovante,
postulez dès maintenant et contribuez à redéfinir l'avenir de l'analyse de données chez Lincoln! 😉
Show more
Show less","{'ProgLanguage': ['Python', 'Java', 'Scala', 'R', 'Go'], 'DataBase': ['SQL', 'NoSQL', ' MongoDB'], 'DataAnalytics': ['R'], 'BigData': ['Hadoop', 'Spark', 'Databricks'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Big Data'], 'FrSoftSkills': [], 'EnSoftSkils': []}","{'JobDetail': [], 'TypeContract': ['CDI'], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's', '30', '30', '30']}"
LinkedIn,Big Data Engineer Databricks Senior - H/F - CDI,Talan,"Paris, Île-de-France, France",https://fr.linkedin.com/jobs/view/big-data-engineer-databricks-senior-h-f-cdi-at-talan-3909664424?position=11&pageNum=0&refId=TDTc9UZJy78L%2BED7EV%2BMrg%3D%3D&trackingId=JOUu%2BSuh85U2DmX%2B5oozDw%3D%3D&trk=public_jobs_jserp-result_search-card,"Talan est un groupe international de conseil en transformation et en innovation par la technologie, créé en 2002.
Nos 5000 consultantes et consultants partagent à travers le monde l’audace d’innover, le goût de l’excellence, et l’envie de relever les défis les plus complexes.
Nous accompagnons les entreprises dans des secteurs variés : énergie, industrie, transport, finance, luxe… à travers 3 grandes expertises :
Le Conseil en Management et Innovation (320 Consultants en France)
La valorisation des données, leurs structurations, et leurs usages (Data et Technologies)
L’intégration de solutions logicielles (Cloud et Applications Services)
Nos valeurs : engagement, respect, partage, esprit d’équipe et optimisme.
Talan est une entreprise responsable, reconnue par ses collaborateurs et attachée à la diversité. Des aménagements peuvent être proposés si vous êtes en situation de handicap.
Retrouvez nos engagements RSEiciet nos actions en faveur de la diversitéici
Job Description
Nous sommes à la recherche d’un Big Data Engineer Databricks Sénior qui sera en charge de l’intégration des données: acquisition, préparation, modélisation et stockage, exposition, . Vous devrez faire preuve d’un état d’esprit à la fois innovant, méthodique, orienté solution (et non problème!), et communiquant.
Responsabilités
Manager des Big Data Engineer et Cloud Engineer
Coacher techniquement les membres de l’équipe: solution et code review sur site, recommandation sur les formations à suivre, certifications à réaliser, …
Analyse des besoins techniques métiers, définition de l’architecture solution et logiciel, référent technique, développement et optimisation, code review, maintenir les pratiques Devops “You build IT, You run IT”, support à recette et mise en production, documentation, et parfois assumer le rôle de Scrum Master,…
Benchmark de solutions et conseil auprès de notre client sur les solutions technologiques à adopter, en lien avec leurs besoins
Partage de connaissances et formations interne
Qualifications
Issu(e) d’une formation supérieure (école d’ingénieur, master,…)
Vous disposez d’au moins 4 années d’expérience dans le domaine du Big Data (et particulièrement sur le framework Spark), et au moins 6 années d’expérience dans le développement logiciel
Vous maîtrisez ledéveloppement logiciel (Scala, Python …), et vous disposez de solides expériences dans la mise en place de pipelines de données
Vous maîtrisez leFramework Spark (idéalement sur Databricks) etson optimisation
Expérience sur une plateforme Cloud serait un plus et idéalement AWS
Expérience sur des flux temps réelserait un plus : Kafka + Spark Streaming
Vous maîtrisez les bases de données SQL et le langage SQL
Vous avez de l'expérience sur les méthodes de stockage: HDFS, S3,,…
Vous avez de bonnes connaissances en devOps : Jenkins, Gitlab, Maven, …
La connaissance des concepts suivants serait un +: DataOps, DataVault, DataMesh..
Connaissance de l’Agilité
Autonome
Organisé(e)
Sens du partage
Bonne communication
Orientation produit et solution
Additional Information
AVANTAGES
:
Plan de formation pour accompagner votre carrière (formations éditeurs, certifications) grâce à nos partenariats nous accordant une position de partenaire privilégié, et management de proximité par des experts
Locaux modernes en centre-ville
Top 5 du Palmarès Great Place to Work
Télétravail jusqu’à 5 jours selon les missions, prime d’équipement de 100€
Mobilité en France et à l’étranger
Top 1% des entreprises évaluées par Ecovadis dans le domaine social, environnemental et éthique
Tickets restaurant, prime vacances, 50% transport (abonnement transport public), mutuelle
Permanence handicap (consultant dédié aux collaborateurs en situation de handicap et aux proches aidants)
Actionnariat salarié
Prime de cooptations
RTT
PROCESS RECRUTEMENT
:
L’équipe recrutement s’engage à vous proposer un processus de recrutement rapide et fluide
1 entretien RHpar Teams (45min)
1 test technique
1 entretien technique par Teams (1heure)
1 entretien opérationnel avec le responsable de domaine, au siège (1heure)
Show more
Show less","{'ProgLanguage': ['Python', 'Scala', 'R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': ['Spark', 'Databricks'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': ['AWS'], 'DevTools': ['Git', 'Jenkins'], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': ['Teams'], 'Other': ['DevOps', 'Big Data', 'Cloud'], 'FrSoftSkills': ['Communication'], 'EnSoftSkils': ['Communication']}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's']}"
LinkedIn,Data Engineer,digiRocks recrute ✅,"Paris, Île-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-at-digirocks-recrute-%E2%9C%85-3903481080?position=12&pageNum=0&refId=TDTc9UZJy78L%2BED7EV%2BMrg%3D%3D&trackingId=DIzHfjsZbaLVQRKIaO5kzQ%3D%3D&trk=public_jobs_jserp-result_search-card,"😎 Envie d'accompagner des organisations dans leurs stratégies, Fan de data?
Rejoins un jeune cabinet de conseil en stratégie spécialisé en data. Le cabinet a été créé il y a 4 ans pas des anciens de grands cabinets de conseil en stratégie qui ne se reconnaissaient plus dans ce qu'est devenu le ""consulting"". Cependant ils n'ont pas perdu espoir de pouvoir apporter du conseil à haute valeur ajoutée dans une ambiance friendly, façon start-up, sans sacrifier l'excellence.
Jean-Patrick recrute un(e) Consultant Data Engineer à Paris en CDI
✅ MISSION :
Vous serez responsable de la mise en œuvre de bout en bout de la pile de données, de la collecte au reporting, avec un accent sur l'infrastructure et les processus techniques. Vous travaillerez avec des Consultants en Stratégie & Data et les soutiendrez dans la résolution des défis liés aux données de leurs clients. Vous contribuerez à la définition des stratégies de données, à la mise en œuvre des systèmes de données et vous soutiendrez l'exploitation des données dans des projets transformationnels. En général, vous serez responsable de comprendre intimement les problèmes, de concevoir une stratégie technique pour les adresser et de faciliter une exécution technique de haute qualité.
✅ RÉSULTATS ATTENDUS :
🚀 Résultat 1: Unificateur de Données : Architecturer, assembler, assimiler, nettoyer et conformer de grands ensembles de données complexes pour livrer des insights commerciaux et alimenter les expériences de produits de données.
🚀 Résultat 2: Agent de Sécurité des Données : Concevoir et construire une infrastructure de données fiable et évolutive avec les techniques de confidentialité et de sécurité de pointe pour protéger les données.
🚀 Résultat 3: DataOps : Posséder la pile de données de bout en bout, y compris la collecte d'événements, la gouvernance des données, les intégrations de données et la modélisation.
🚀 Résultat 4: Gardien des Données : Assurer la cohérence et la qualité de l'environnement technique et de la structure des données à travers des métriques, de la documentation, des processus, des tests de données et de la formation.
Requirements
✅ PROFIL RECHERCHÉ :
Diplômé d'une Grande Ecole de Commerce ou d'ingénieur, avec une première expérience réussie comme Data Engineer, idéalement dans un contexte similaire au Conseil,
Connaissance des services de Data Warehouses Cloud. Expérience avec Google BigQuery, Snowflake, AWS Redshift/Athena, Looker, Azure SQL DWH, ou Azure Databricks est très souhaitable.
Connaissance des architectures de données relationnelles et de grandes données, de l'entreposage de données, de l'intégration de données, de la modélisation de données, de l'optimisation de données et des techniques d'analyse de données.
Expérience dans la construction de pipelines de données de bout en bout en utilisant des plateformes de données sur site ou basées sur le cloud.
Expérience pratique dans la livraison de solutions comprenant des bases de données, SQL avancé et développement logiciel dans des langues telles que Python.
Intéressé et connaissant les technologies Big Data et les technologies de l'écosystème Apache telles que Beam, Spark, Kafka, Airflow, bases de données, intégration, gestion des données de référence, assurance qualité, manipulation de données et technologies de gouvernance des données.
Expérience avec les plateformes cloud publiques et l'infrastructure cloud qui est essentielle.
Exposé aux outils ETL/ELT et de gouvernance.
Intéressé par les technologies et principes IA et ML.
Show more
Show less","{'ProgLanguage': ['Python', 'R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': ['Spark', 'Databricks'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': ['AWS', 'Azure'], 'DevTools': [], 'Os': [], 'DBMS': ['Snowflake', 'Snowflake', 'BigQuery'], 'SoftBigDataProcessing': [], 'Automation': ['Airflow'], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Big Data', 'ML', 'Cloud'], 'FrSoftSkills': ['Organisation'], 'EnSoftSkils': []}","{'JobDetail': [], 'TypeContract': ['CDI'], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's', '4', '4', '4']}"
LinkedIn,"Big Data Engineer – Lille, France (H/F)",Astek,"Lille, Hauts-de-France, France",https://fr.linkedin.com/jobs/view/big-data-engineer-%E2%80%93-lille-france-h-f-at-astek-3839097187?position=13&pageNum=0&refId=TDTc9UZJy78L%2BED7EV%2BMrg%3D%3D&trackingId=g6Iw%2FVj01V51GKbNbzngpQ%3D%3D&trk=public_jobs_jserp-result_search-card,"CDI
Lille - France
Publiée il y a 2 mois
Le Groupe Astek
Ce Que Nous Allons Accomplir Ensemble :
Nous rejoindre en tant que
Big Data Engineer (H/F),
afin d’accompagner un opérateur télécoms, Leader en Europe dans la création d’une infrastructure cloud (IAAS) performante, robuste et sécurisée.
Un challenge portant sur des millions d’utilisateurs dans un environnement technique innovant, stratégique et où l’entraide et la bonne humeur priment !
Votre Mission, Si Vous L’acceptez :
Qualifier les données et les résultats
Conception technique des solutions
Décliner les impacts de la stratégie et des innovations technologiques au sein des processus et outils de l’exploitant SI
Assurer l’accompagnement et le déploiement des évolutions des processus et outils
Contribuer aux programmes de transformation DevOps, Cloud et catalogues des offres SI
Développer des fonctions transverses et les « uses cases »
Accompagner la phase de mise en production
Votre Future Équipe :
Vous intégrerez une équipe à la fois technique et fonctionnel, qui œuvre chaque jour pour développer et maintenir en conditions opérationnelles l’ensemble des solutions IT !
L’équipe est en interaction avec des clients à la fois internes et externes.
Votre stack de jeu
Système d’exploitation : Linux
Environnement Big data : Hadoop, Spark, Scala
Cloud computing : GCP ou AWS
Base de données : No SQL (Cassandra, Mongo DB)
Dataviz : Power BI ou Kibana
Des notions en développement feront la différence !
Les Petits Plus Du Projet :
Vous évoluerez au sein d’une équipe impliquée et réactive et interviendrez sur un projet polyvalent et à forte valeur ajoutée.
Vous ?
Diplômé(e) d’une école d’ingénieur ou équivalent de niveau Bac+5.
Vous justifiez idéalement d’une expérience d’au moins 3 ans d’expériences sur un poste similaire ?
Vous faite preuve de proactivité et d’esprit d’équipe, êtes doté(e) d’un excellent sens de l’organisation et vous aimez les challenges et la résolution de problème ?
Alors ce poste est fait pour vous, n’hésitez plus et rejoignez l’aventure ASTEK !
Astek
Créé en France en 1988, Astek est un acteur mondial de l’ingénierie et du conseil en technologies. Fort de son expertise dans de nombreux secteurs industriels et tertiaires, Astek accompagne ses clients internationaux dans le déploiement intelligent de leurs produits et de leurs services, et dans la mise en œuvre de leur transformation digitale.
Depuis sa création, le Groupe a fondé son développement sur une forte culture d’entrepreneuriat et d’innovation, et sur l’accompagnement et la montée en compétence de
ses 7800 collaborateurs
qui s’engagent chaque jour à promouvoir la complémentarité entre les technologies numériques et l’ingénierie des systèmes complexes.
Rejoignez un Groupe en fort développement en France et à travers le monde ayant réalisé un chiffre d’affaires de 600 M€ en 2023.
Tous les détails sur le Groupe sur le site https://astekgroup.fr. Et vous pouvez aussi nous suivre sur notre blog : https://blog.groupeastek.com.
Rencontrons-nous
Notre projet commun vous plait ?
Postulez à cette annonce, et soyez transparent !
Maud, notre Talent Acquisition Referent, vous contactera pour un premier échange.
Puis vous rencontrerez Yoram, votre futur manager, avec lequel vous échangerez autour d’Astek, de votre parcours, de vos attentes et de votre future mission .
Enfin, vous rencontrerez Anthime, notre Directeur d’agence avec lequel vous pourrez valider votre intérêt et adéquation pour le poste et finaliser les éléments contractuels.
Nos Plus
Astek est green et fait bénéficier ses salariés d’une indemnité kilométrique vélo
Une politique CARE sur-mesure déployée par nos équipes RH pour nos collaborateurs (https://astekgroup.fr/engagements)
Notre charte de la Diversité
Mots-clés :
ingénieur – ingénieure – consultant – consultante – developpement – Scala – Data
Caractéristiques de l'emploi
Catégorie Ingénieur
Job Industry Télécom / Média
Postuler en ligne
Nom *
Prénom *
Email *
Un email valide est requis.
Téléphone *
Un numéro de téléphone valide est requis.
Joindre un CV *
Mots-clés :
ingénieur – ingénieure – consultant – consultante – developpement – Scala – Data
Show more
Show less","{'ProgLanguage': ['Scala', 'R', 'Go'], 'DataBase': ['SQL', 'Cassandra'], 'DataAnalytics': ['R'], 'BigData': ['Hadoop', 'Spark'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': ['Power BI'], 'Statistics': [], 'CloudComputing': ['AWS'], 'DevTools': ['Git'], 'Os': ['Linux'], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['DevOps', 'Big Data', 'Cloud'], 'FrSoftSkills': ['Organisation'], 'EnSoftSkils': []}","{'JobDetail': [], 'TypeContract': ['CDI'], 'Salary': [], 'Level': ['Bac+5'], 'Experience': ['a', 'n', 's', '3', '3', '3']}"
LinkedIn,Big Data Engineer Databricks confirmé - H/F - CDI,Talan,"Paris, Île-de-France, France",https://fr.linkedin.com/jobs/view/big-data-engineer-databricks-confirm%C3%A9-h-f-cdi-at-talan-3902693062?position=14&pageNum=0&refId=TDTc9UZJy78L%2BED7EV%2BMrg%3D%3D&trackingId=YqfrGktg2oFxsRwyJ9Dmfg%3D%3D&trk=public_jobs_jserp-result_search-card,"Talan est un cabinet de conseil en innovation et transformation par la technologie.
Depuis 20 ans, Talan conseille les entreprises et les administrations, les accompagne et met en œuvre leurs projets de transformation et d’innovation en France et à l'international. Présent sur cinq continents, le groupe prévoit de réaliser un chiffre d'affaires de 600 millions d'euros en 2022 pour plus de 6000 consultant·e·s et vise à dépasser la barre du milliard d’€ de CA à horizon 2024.
Le Groupe met l'innovation au cœur de son développement et intervient dans les domaines liés aux mutations technologiques des grands groupes, comme le Big Data, l'IoT, la Blockchain et l'Intelligence Artificielle.
Présent dans les événements incontournables du secteur, comme Viva Technology, Talan prend régulièrement la parole sur les enjeux de ces technologies révolutionnaires aux côtés d'acteurs majeurs du secteur et de parlementaires (Syntec Numérique, Forum de l'intelligence artificielle, French Fab Tour, Forum de Giverny…).
Talan est une entreprise responsable, attachée à la diversité. Des aménagements de poste peuvent être organisés pour tenir compte des personnes en situation de handicap.
Retrouvez nos engagementsRSEiciet nos actions en faveur de la diversitéici
Job Description
Nous sommes à la recherche d’un Big Data Engineer Databricks confirmé qui sera en charge de l’intégration des données: acquisition, préparation, modélisation et stockage, exposition, . Vous devrez faire preuve d’un état d’esprit à la fois innovant, méthodique, orienté solution (et non problème!), et communiquant.
Responsabilités
Analyse des besoins techniques métiers, définition de l’architecture solution et logiciel, référent technique, développement et optimisation, code review, maintenir les pratiques Devops “You build IT, You run IT”, support à recette et mise en production, documentation, et parfois assumer le rôle de Scrum Master,…
Partager techniquement les membres de l’équipe: solutions et code reviews, recommandations, certifications à réaliser, …
Participation à des meet-up, coding dogo,…
Communication: écriture d’articles, retours d’expérience…
Qualifications
Issu d’une formation supérieure (école d’ingénieur, master,…)
Vous disposez d’au moins 3 années d’expérience dans le domaine du Big Data et particulièrement sur le framework Spark (idéalement Databricks)
Maîtrise du développement logiciel (Scala, Python,…) et vous disposez de solides expériences dans la mise en place de pipeline de données
Expérience sur une plateforme Cloud serait un plus et idéalement AWS
Expérience sur des flux temps réelserait un plus : Kafka + Spark Streaming
Maitrise du langage SQL
Expérience sur des méthodes de stockage: HDFS, S3, ,…
Bonnes connaissances en devOps : Jenkins, Gitlab, Maven, …
Connaissance de l’Agilité
Autonomie, organisation, sens du partage
Bonne communication
Orientation produit et solution
Additional Information
AVANTAGES
:
Plan de formation pour accompagner votre carrière (formations éditeurs, certifications) grâce à nos partenariats nous accordant une position de partenaire privilégié, et management de proximité par des experts
Locaux modernes en centre-ville
Top 5 du Palmarès Great Place to Work
Télétravail jusqu’à 5 jours selon les missions, prime d’équipement de 100€
Mobilité en France et à l’étranger
Top 1% des entreprises évaluées par Ecovadis dans le domaine social, environnemental et éthique
Tickets restaurant, prime vacances, 50% transport (abonnement transport public), mutuelle
Permanence handicap (consultant dédié aux collaborateurs en situation de handicap et aux proches aidants)
Actionnariat salarié
Prime de cooptations
RTT
PROCESS RECRUTEMENT
:
L’équipe recrutement s’engage à vous proposer un processus de recrutement rapide et fluide
1 entretien RHpar Teams (45min)
1 entretien opérationnel avec le responsable de domaine, au siège (1heure)
1 entretien avec le directeur de pôle, au siège(1heure)
Show more
Show less","{'ProgLanguage': ['Python', 'Scala', 'R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': ['Spark', 'Databricks'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': ['AWS'], 'DevTools': ['Git', 'Jenkins'], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': ['Teams'], 'Other': ['DevOps', 'Big Data', 'Cloud'], 'FrSoftSkills': ['Communication', 'Organisation'], 'EnSoftSkils': ['Communication']}","{'JobDetail': ['Confirmé'], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's', '20', '20', '20']}"
LinkedIn,Data Engineer – SQL & GCP - F/H,Orange Business,Greater Lille Metropolitan Area,https://fr.linkedin.com/jobs/view/data-engineer-%E2%80%93-sql-gcp-f-h-at-orange-business-3916557264?position=15&pageNum=0&refId=TDTc9UZJy78L%2BED7EV%2BMrg%3D%3D&trackingId=0rGuS34ssXebpVfpSRYJ7w%3D%3D&trk=public_jobs_jserp-result_search-card,"Et si Business & Decision et Orange Business conjuguaient leurs forces pour devenir l’un des leaders européens de la Data transformation ?
Nous l’avons fait ! Notre alchimie nous positionne comme un acteur unique intervenant sur toutes les étapes du voyage de la donnée.
Depuis 30 ans, Business & Decision, entité de Digital Services s'est imposée comme un partenaire stratégique pour la transformation Data de nombreux clients, dans des secteurs très variés. Digital Services est aujourd’hui l’ESN d’Orange Business alliant les expertises historiques Cloud et Digital d’Orange ainsi que le cœur de métier Data/IA de Business & Decision. Son but est d’accompagner les entreprises et les acteurs publics dans leur transformation grâce aux 4000 experts présents dans plusieurs grandes villes françaises comme Montpellier, Niort, Lyon, Bordeaux, Lille et Toulouse …
Description du poste
Orange Business, recherche pour son site de Lille, son futur Data Engineer pour rejoindre sa team Data.
Votre quotidien ?
En intégrant Orange Business, vous pouvez participer à une grande diversité d’activités dans la Data. En voici un aperçu :
Au démarrage du projet :
Recueillir et analyser les besoins du client
Rédiger les spécifications fonctionnelles et techniques
Estimre les charges
Pendant la phase de réalisation :
Modéliser des datawarehouses et datamart (intégration de flux et consolidation des données)
Développer les procédures d’alimentation (ETL)
Développer en SQL
/ PLSQL / Shell
Garantir la qualité des données et leur disponibilité
Concevoir et développer des solutions frontend BI à des fins analytics & dashboarding
Réaliser la recette et les tests
Suivre et mettre en production
En fonction de votre évolution et de nos enjeux, vous pouvez aussi évoluer sur des missions transverses (conseil, coaching, avant-vente, formation, audit, etc.). La prise d’initiative est toujours la bienvenue !
Qualifications
Vous possédez 3 ans d'expérience ou plus dans la mise en œuvre de projets décisionnels et ingénierie ou analyse data.
Vous avez de
solides compétences en développement SQL
(job, scripting, déploiement), vous avez l’habitude de travailler dans un
environnement Google Cloud Plateform
ainsi qu’avec
Power BI
.
Envie d’apprendre de nouvelles technos ? Vous souhaitez partager vos compétences et bénéficier des expertises de la Team Orange Business ?
Outre l’aspect technique, c’est une personnalité qui est recherchée !
Show more
Show less","{'ProgLanguage': ['R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': ['Orange'], 'DataSerialization': [], 'DataVisualization': ['Power BI'], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git'], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Cloud'], 'FrSoftSkills': [], 'EnSoftSkils': ['Initiative']}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's', '30', '30', '30']}"
LinkedIn,Data Engineer (F/H),Thales,"Vélizy-Villacoublay, Île-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-f-h-at-thales-3908228180?position=16&pageNum=0&refId=TDTc9UZJy78L%2BED7EV%2BMrg%3D%3D&trackingId=SR3wNiEahgqu4gp2aczA2g%3D%3D&trk=public_jobs_jserp-result_search-card,"QUI SOMMES-NOUS ?
Thales est un leader mondial des hautes technologies comptant plus de 81 000 collaborateurs présents sur tous les continents. Le Groupe investit dans les innovations du numérique et de la « deep tech » – big data, intelligence artificielle, connectivité, cybersécurité et quantique – pour construire un avenir de confiance, essentiel au développement de nos sociétés, en plaçant l’humain au cœur des décisions.
Thales propose des solutions, services et produits qui aident ses clients – entreprises, organisations, Etats – dans cinq grands marchés vitaux pour le fonctionnement de nos sociétés : identité et sécurité numériques, défense, aéronautique, espace, et transport.
QUI ETES-VOUS ?
Diplômé d’un Bac+5 en école d’ingénieur ou équivalent universitaire avec une spécialisation en informatique, vous avez au moins 3 ans d'expérience dans les technologies Big Data.
CE QUE NOUS POUVONS ACCOMPLIR ENSEMBLE :
En tant que Data Engineer, vous jouerez un rôle clé dans la conception, le développement et la maintenance de notre infrastructure de données, ainsi que dans la transformation et la gestion des flux de données.
VOS MISSIONS :
• Concevoir, développer et déployer des solutions Big Data en utilisant les technologies Hadoop.
• Mettre en place des pipelines de données performants pour l'ingestion, le traitement et le stockage des données massives.
• Collaborer étroitement avec les équipes métier pour comprendre leurs besoins en matière d'analyse de données et proposer des solutions adaptées.
• Optimiser les performances des clusters Hadoop pour garantir une exploitation efficace des données.
• Assurer la qualité et la fiabilité des données traitées, en mettant en place des processus de validation et de nettoyage.
• Identifier et résoudre les problèmes liés à l'infrastructure Big Data et proposer des améliorations.
• Travailler en étroite collaboration avec les Data Scientists et les Data Analysts pour fournir des insights pertinents à partir des données.
Innovation, passion, ambition : rejoignez Thales et créez le monde de demain, dès aujourd’hui.
Show more
Show less","{'ProgLanguage': ['R'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': ['Hadoop'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Big Data'], 'FrSoftSkills': ['Collaboration', 'Organisation'], 'EnSoftSkils': ['Collaboration']}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': ['Bac+5'], 'Experience': ['a', 'n', 's', '3', '3', '3']}"
LinkedIn,Data Engineer - Lille,Capgemini,Greater Lille Metropolitan Area,https://fr.linkedin.com/jobs/view/data-engineer-lille-at-capgemini-3914228495?position=17&pageNum=0&refId=TDTc9UZJy78L%2BED7EV%2BMrg%3D%3D&trackingId=tWBPN1TDM2mx5aVvM0uDjQ%3D%3D&trk=public_jobs_jserp-result_search-card,"Capgemini en quelques mots
Choisir Capgemini, c'est choisir une entreprise où vous serez en mesure de façonner votre carrière selon vos aspirations, où vous serez soutenu et inspiré par une communauté d’experts dans le monde entier, où vous pourrez réécrire votre futur. Rejoignez-nous pour redéfinir les limites de ce qui est possible, contribuer à libérer la valeur de la technologie pour les plus grandes organisations et participez à la construction d’un monde plus durable et inclusif.
Vos missions
Vous maitrisez au minimum un langage de programmation appliqué à l’analyse de données
(Java, Python, Scala et les environnements Spark et / ou Hadoop).
Vous êtes passionné par le Big Data et le Machine Learning et l’analyse de données
Vous concevez et mettez en œuvre des stratégies sécurisées d'acquisition et d'intégration de données
Vous configurez des référentiels de données à la pointe de la technologie dans des environnements distribués
Vous construisez des pipelines de données pour collecter, transformer et traiter des données en collaboration avec des scientifiques de données afin de répondre aux exigences de la modélisation de données d'analyse avancée
Votre profil
Diplômé(e) de Bac+5 en informatique
4 ans d’expérience
(au sein d’une ESN ou chez un intégrateur) en conseil clientèle
Une solide culture technologique
Un bon niveau d’anglais
3 raisons de nous rejoindre
Qualité de vie au travail :
accord de télétravail en France et à l’international, accord sur l’égalité
professionnelle, la parentalité, l’équilibre des temps et la mobilité durable.
Apprentissage en continu :
certifications et formations en libre accès, accompagnement sur mesure avec
votre carreer manager, parcours d’intégration sur 9 mois.
Avantages groupe & CSE :
plan actionnariat, activités à tarifs préférentiels, remboursement partiel
vacances, remboursement de votre abonnement sportif ou culturel
Nos engagements et priorités
Le groupe Capgemini encourage une
culture inclusive dans un cadre multiculturel et handi-accueillant.
En nous rejoignant, vous intégrez un collectif qui valorise la diversité, développe le potentiel de ses talents, s’engage dans des
initiatives solidaires avec ses partenaires, et se mobilise pour réduire son impact environnemental sur tous ses sites et auprès de ses clients.
Capgemini
est un
leader mondial
, responsable et multiculturel, regroupant près de 350 000 personnes dans plus de 50 pays. Fort de
55 ans d’expérience,
nous sommes un partenaire stratégique des entreprises pour la transformation de leurs activités en tirant profit de toute la puissance de la technologie et des innovations dans les domaines en perpétuelle évolution tels que le
cloud, la data, l’Intelligence Artificielle, la connectivité, les logiciels, l’ingénierie digitale ou les plateformes.
Get The Future You Want* | www.capgemini.com/fr-fr
*Capgemini, le futur que vous voulez
Show more
Show less","{'ProgLanguage': ['Python', 'Java', 'Scala', 'R'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': ['Hadoop', 'Spark'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git'], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Big Data', 'Machine Learning', 'Cloud'], 'FrSoftSkills': ['Collaboration', 'Organisation'], 'EnSoftSkils': ['Collaboration', 'Initiative']}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': ['Bac+5'], 'Experience': ['a', 'n', 's', '4', '4', '4']}"
LinkedIn,Data Engineer,EarthDaily Agro,"Balma, Occitanie, France",https://fr.linkedin.com/jobs/view/data-engineer-at-earthdaily-agro-3883708013?position=18&pageNum=0&refId=TDTc9UZJy78L%2BED7EV%2BMrg%3D%3D&trackingId=OstO0NnkVGTi6x0rYb4beg%3D%3D&trk=public_jobs_jserp-result_search-card,"About Us
EarthDaily Agro provides space age data and analytics to the organizations and people who feed the planet!
With 35 years of industry experience, EarthDaily Agro provides customers with the data, analysis and knowledge they need to make more efficient and effective decisions. B2B services range from global risk management and monitoring of agricultural commodities to the marketing of inputs and precision agriculture consulting, using the latest research in agronomy, information technologies and remote sensing.
EarthDaily Agro also develops highly customized business solutions for agricultural lenders, insurers, input suppliers and food companies, with easy-to-use analytics, that help reduce the daily risks of agriculture.
EarthDaily Agro is headquartered in Minneapolis, MN, USA, with offices in France, Brazil, Australia and Switzerland and is a division of EarthDaily Analytics Corp.
EarthDaily Analytics Corp., a vertically-integrated data processing and analytics company, is launching a new constellation of earth observation satellites. The EarthDaily satellite constellation will significantly enhance geospatial analytics capabilities in agriculture, forestry, environment, financial services, and intelligence, among many other verticals.
Main Job Tasks And Responsibilities
As a EarthDailyAgro Data Engineer, your primary responsibility will be to design, develop, and manage data pipelines and infrastructure specialized for geospatial and remote sensing applications. You will work closely with data scientists, geospatial analysts, remote sensing experts, software engineers, and DevOps teams to ensure the successful deployment and scaling of data pipeline to feed geospatial data machine learning models. Your role will be crucial in optimizing the geospatial machine learning ecosystem and ensuring the seamless integration of AI-driven geospatial solutions into real-world applications.
Your Responsibilities Include
Cloud-based data pipeline Conceptualization, Development and Scaling: Build up pipeline to ingest large volumes of geospatial data, pre-process them and meet data scientists’ requirements, in terms of accessibility, speed, format, quality.
Automation and CI/CD: Industrialization of pipeline deployment, orchestration, workflows, and versioning.
Cost & Speed Optimization: Collaborate with infrastructure team to develop, optimize, and fine-tune pipeline.
Cloud and Containerization: Experience with cloud platforms (e.g., AWS, Azure, GCP) and containerization tools.
Infrastructure Management: Utilize containerization technologies and cloud-based services to set up and manage infrastructure, enabling seamless deployment and scalability.
Monitoring and Anomaly Detection: Implement monitoring systems to track pipeline performance and identify anomalies.
Version Control and Data Version Control: Proficient with version control systems like Git and DVC.
Security and Compliance: Ensure the security and privacy of geospatial data, adhering to relevant data protection regulations and industry best practices.
Collaboration and Communication: Collaborate with interdisciplinary teams to integrate data pipeline into existing applications or develop new geospatial products.
Issue Resolution and Troubleshooting: Identify and resolve promptly technical issues related to geospatial data processing, performance, or infrastructure.
Education, Knowledge And Abilities
Requirements
Education: Master's degree in Computer Science, specialisation in Geomatics and/or Remote sensing would be a plus.
Experience: 3+ years experiences with data pipeline processes and deployment is a must-have. Proven hands-on experience in setting up pipelines and data processes with opensource tools (e.g., MLFlow, Argo, Kubeflow) is desirable.
Programming Skills: Proficiency in Python and with data manipulation frameworks (e.g., dataframe, numpy, pandas, xarray, rasterio) and librairies (e.g., Dask).
Problem-Solving Skills: Autonomous, and strong analytical and problem-solving abilities to address complex geospatial data and analysis challenges.
Communication Skills: Excellent communication and interpersonal skills to collaborate effectively with cross-functional teams and stakeholders.
French mandatory (job based in France). Fluent in English (oral and written): meetings with internal are mostly in English.
Preferred Additional Skills
Experience with Earth Observation (EO) data analysis and processing.
Experience with geospatial data formats (e.g., GeoTIFF, Shapefile, NetCDF).
Spatial Analysis Techniques: Understanding of spatial analysis techniques and algorithms commonly used in geospatial data manipulation.
Remote Sensing Integration: Knowledge of remote sensing data sources (e.g., STAC catalog, satellite imagery, LiDAR, SAR) integration into data pipelines for accurate and up-to-date geospatial analysis.
CONDITIONS
Full time job based in Balma, near Toulouse, France.
Fixed + Bonuses
TR / ""Family"" insurance / CSE
Powered by JazzHR
WrfSXQ5YJg
Show more
Show less","{'ProgLanguage': ['Python', 'Scala', 'R', 'Go'], 'DataBase': [], 'DataAnalytics': ['Pandas', 'NumPy', 'R'], 'BigData': [], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': ['AWS', 'Azure'], 'DevTools': ['Git'], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': ['Teams'], 'Other': ['DevOps', 'ML', 'Machine Learning', 'Cloud', 'CI/CD'], 'FrSoftSkills': ['Communication', 'Collaboration'], 'EnSoftSkils': ['Communication', 'Collaboration', 'Organization', 'Interpersonal Skills']}","{'JobDetail': ['Remote', 'Full'], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's']}"
LinkedIn,Data Engineer H/F,Thales,"Lyon, Auvergne-Rhône-Alpes, France",https://fr.linkedin.com/jobs/view/data-engineer-h-f-at-thales-3903089036?position=19&pageNum=0&refId=TDTc9UZJy78L%2BED7EV%2BMrg%3D%3D&trackingId=l0OHDSxc4s3SzSTrRXtmfg%3D%3D&trk=public_jobs_jserp-result_search-card,"📢 Nous recherchons un(e) Data Engineer, basé(e) à Lyon
👉Quelques mots sur les activités numériques de Thales Lyon :
Les activités numériques représentent une entité rattachée au groupe Thales, spécialisée dans l’IT et présente au national.
L’agence de Lyon adresse divers sujets d’expertise : ingénierie logiciels, cybersécurité, infogérance des infrastructures et transformation digitale.
🎯
Votre rôle et missions
En nous rejoignant, vous intégrerez le centre de compétences
Augmented data
,
spécialisé dans la conception, le développement et l’évolution d’applications data centrées. Vous y boosterez votre carrière en travaillant sur des technologies telles que
Spark, Elasticsearch, Kube ...
le plus souvent dans un environnement
Agile
.
Dans le cadre des projets que nous opérons aujourd’hui :
- Vous contribuerez à la conception, au maintien, à la scalabilité des plateformes d’analyse de données au travers de votre expertise sur les sujets data (base de données, gestion de flux, ETL …)
- Vous contribuerez à la conception et à la mise en production des pipelines d’analyses et de transformations de données en veillant à leur bonne adaptation aux besoins métiers et aux contraintes techniques du client
- Vous pourrez intervenir sur des sujets de visualisations, dans le but de notamment accompagnées nos clients sur la conception de Dashboard métier intelligent …
- Vous serez également amenées à échanger directement avec des DevOps/Datascientist pour la mise en place, l’intégration des pipelines et l’élaboration des algorithmes de traitements de données.
- A l’échelle du département, Vous serez un acteur majeur du développement de notre activité et du lancement de nouveaux projets de valorisation de données.
🙋‍♀️ 🙋‍♂️
Votre profil
De formation Bac +5 en informatique (école d’ingénieur, Master ou équivalent), vous justifiez d’une première expérience réussie sur un projet data ? Vous souhaitez participer à la conception et intervenir sur des solutions de récupération et d’exploitation de données métiers dans des contextes critiques et hautement sécurisés ?
Autonome, dynamique, organisé(e) et proactif(ve), vous souhaitez évoluer au sein d’équipes passionnées par l’exploration et l’intégration des technologies nouvelles au service des métiers de nos clients ?
Vous avez des compétences qui couvrent les domaines suivants :
Mise en place et gestion de base de données (SQL, Elasticsearch, Clickhouse ...)
Langages de programmations (Java, Python)
Gestion de flux (Kafka, flink, logstash …)
Environnements big Data (Spark/hadoop )
Principes et outils de type ETL
Vous êtes de plus intéressé(e):
Par les environnements containerisés (docker, kubernetes, helm ...)
Les concepts DevOps (Ansible, CI/CD...)
Les sujets de Datavisualisation (Vega, Kibana, python librairies...)
Vous aimez travailler en équipe ? Vous êtes reconnu(e) pour vos qualités relationnelles et vos capacités de vulgarisation ?
Alors notre poste d’Ingénieur(e) Data(H/F) est fait pour vous !
🙌
Votre carrière chez Thales
Différentes opportunités vous permettront de découvrir d'autres domaines ou sites. Vous pourrez évoluer et développer vos compétences dans différents domaines.
Explorez un espace attentif au développement personnel.
Développez vos talents dans un autre domaine du groupe Thales, en découvrant de nouveaux produits, de nouveaux clients, un nouveau pays ou en vous orientant vers une solution plus complexe.
Choisissez entre une expertise technique ou un parcours de leadership.
Vous travaillerez dans une entreprise résolument humaine avec des valeurs fortes comme la sécurité au travail, l’égalité Homme/Femme et l’équilibre vie personnelle/professionnelle (Accord Télétravail).
Rattaché(e) à la Convention métallurgie, vous bénéficierez aussi de ses multiples avantages (…)
Vous souhaitez en savoir plus ?
N’hésitez pas à contacter notre équipe de recrutement ou nos équipes directement.
Show more
Show less","{'ProgLanguage': ['Python', 'Java', 'Scala', 'R', 'Go'], 'DataBase': ['SQL', 'Elasticsearch'], 'DataAnalytics': ['R'], 'BigData': ['Hadoop', 'Spark', 'Flink'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git', 'Docker'], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': ['Ansible', 'Kubernetes'], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': ['Docker', 'Kubernetes'], 'Collaboration': [], 'Other': ['DevOps', 'Big Data', 'CI/CD'], 'FrSoftSkills': ['Leadership'], 'EnSoftSkils': ['Leadership']}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's']}"
LinkedIn,Data Engineer | Python - Spark - Hadoop | Spécialisé en Big Data | Paris ou Remote Partiel,Octopus IT - Expert du recrutement tech,"Paris, Île-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-python-spark-hadoop-sp%C3%A9cialis%C3%A9-en-big-data-paris-ou-remote-partiel-at-octopus-it-expert-du-recrutement-tech-3837194913?position=20&pageNum=0&refId=TDTc9UZJy78L%2BED7EV%2BMrg%3D%3D&trackingId=pVu5TEtTTwGCsZughQT0Dw%3D%3D&trk=public_jobs_jserp-result_search-card,"La société
Créée il y a 7 ans, cette entreprise de conseil en hyper croissance, se compose d'environ 90 personnes. Elle est devenue experte en Data et IA (NLP, Deep Learning, Machine Learning) et accompagne leurs clients sur l’ensemble de leurs projets data à travers la valorisation de leurs données.
Leur valeur ajoutée ? Leur spécialisation en Data ce qui leur permet d'offrir 3 expertises métiers distinctes : la Data Science, la Data Engineering et le Machine Learning Engineering. Autour de ces expertises gravitent bien sûr les métiers de Lead et d'Architecte.
Une autre de leur force est leur formation interne (avec des profils de seniors ou d'architectes) et externe (avec des partenaires pour passer les certifications).
Chez eux, le collaborateur est placé au centre des préoccupations, permettant ainsi de créer une cohésion et une véritable culture au sein de l'entreprise. Par exemple la majorité des projets se font en équipe et non seul.
Connu et reconnu pour leur expertise en Big Data, ils sont devenu le partenaire principal d'un grand groupe du CAC 40 et ont pris le lead sur tous les sujets touchant à la transformation Big Data de ce groupe.
Pour poursuivre leur croissance, répondre à leurs ambitions et développer de nouveaux marchés, nous recherchons plusieurs profils pour renforcer leurs effectifs.
Le poste
En les rejoignant vous travaillerez sur les problématiques suivantes :
Mise en place et/ou scale d'architectures
Construction de Datalake
Mise en production de model de ML
Pipelining de données
Streaming de données et temps réel
La stack sur laquelle vous travaillerez :
Python, Scala, Spark, Architectures distribuées : Hadoop, HDFS, Cloud : Aws, GCP, Azure
Votre profil
A partir de 3 ans d'expérience en CDI
Vous avez une expérience significative sur des problématiques Big Data
Très bonne compétences en Python et/ou Scala et en Spark
Vous êtes familier avec Hadoop, Hive, Hbase
Une logique cloud (Aws, GCP ou Azure)
Le salaire & avantages
50-60 K€ selon expérience
RTT
Carte Swile & Mutuelle
3/4 jours de télétravail par semaine
Et plus encore…
Ce qu’on préfère
Être impliqué à fond dans une aventure avec de nombreux challenges techniques
Belles opportunités d'évolutions sur des postes d'Architecte, de Lead ou de Ml Ops
Très bonne ambiance, équipe solidaire et orientée partage d’informations
Beaucoup de workshops en interne et catalogue de formations à votre guise
Ce poste a été soigneusement choisi par votre coach. Powered by Octopus IT, cabinet d’Experts en Recrutement Tech (CDI et clients finaux uniquement) – Visitez nous pour plus d’opportunités :
www.octopusit.fr
Show more
Show less","{'ProgLanguage': ['Python', 'Scala', 'R'], 'DataBase': ['HBase'], 'DataAnalytics': ['R'], 'BigData': ['Hadoop', 'Spark'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': ['AWS', 'Azure'], 'DevTools': [], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': ['HBase'], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Big Data', 'ML', 'Machine Learning', 'Cloud'], 'FrSoftSkills': [], 'EnSoftSkils': []}","{'JobDetail': ['Senior'], 'TypeContract': ['CDI'], 'Salary': ['50'], 'Level': [], 'Experience': ['a', 'n', 's', '7', '7', '7']}"
LinkedIn,Data Engineer Talend F/H,Orange Business,Greater Lille Metropolitan Area,https://fr.linkedin.com/jobs/view/data-engineer-talend-f-h-at-orange-business-3916552363?position=21&pageNum=0&refId=TDTc9UZJy78L%2BED7EV%2BMrg%3D%3D&trackingId=nWMEAJ97Rkf7axHPJgu4ww%3D%3D&trk=public_jobs_jserp-result_search-card,"L’ambition d’Orange Business est de devenir l’intégrateur réseau et numérique de référence en Europe, en nous appuyant sur nos forces autour des solutions de connectivité nouvelle génération, du cloud et de la cybersécurité.
Nos 30 000 femmes et hommes présents dans 65 pays, dont chaque voix compte, sont tous animés par la même détermination et le même esprit d’équipe, pour construire les solutions digitales d’aujourd’hui et de demain et créer un impact positif pour nos clients, pour leurs salariés et pour la planète.
Nous offrons des opportunités passionnantes grâce à des projets innovants dans la data et le digital, le cloud, l’IA, la cybersécurité, l’IoT, ou encore le digital workspace et le big data.
Venez vivre cette aventure avec nous !
Afin de développer notre équipe lilloise, nous recherchons aujourd'hui, un Ingénieur DATA à même d’accompagner nos clients dans la structuration de leurs SI autour de la donnée.
Vos principales missions seront les suivantes
:
- Concevoir des solutions de traitement et collecter des volumes importants de données.
- Participer à des études de cadrage pour collecter le besoin métier et concevoir les solutions qui répondent au besoin du client.
- Apporter son expertise sur des problématiques précises rencontrées chez les clients.
- Participer à la veille technologique
- Réaliser les
développements TALEND
- Rester informé et former sur les nouvelles solutions DATA
- Contribuer aux phases d'avant-vente et au développement business.
- Participer à la conception, l'évolution et la présentation de nos offres DATA.
Vous
:
- Êtes issu(e) de formation bac+5 ?
- Vous justifiez d'au moins 3 ans d'expériences en qualité d'Ingénieur DATA sur la solution TALEND Enterprise (Data Integration) et avez idéalement une connaissance des solutions Cloud d'AWS et d'AZURE ?
- Vous êtes intervenu sur des projets intégrant des pratiques DevOps et AGILE ?
Alors postulez, ce poste est fait pour vous !
Vos compétences clés
:
- Expertise sur l'outil
ETL TALEND
Enterprise (administration et développement)
- Fortes connaissances des solutions de bases de données (SQL, NoSQL…)
- Connaissances en langages objets ou scripts (notamment Java mais aussi Javascript, Scala, Python…)
- Divers systèmes d'exploitation : UNIX, Windows
Autonomie, rigueur, curiosité, dynamisme et sens du service sont des qualités nécessaires pour ce poste.
Les compétences complémentaires qui seraient appréciées :
- Connaissances d'autres modules Talend (MDM, ESB, Data Quality, Cloud…)
- Maîtrise des technologies du Big Data (Hadoop, Spark, Kafka…)
- Expertise sur d'autres outils ETL (Informatica, SSIS, DataStage...)
- Notions en architecture des Systèmes d'Information
- Maîtrise de l'anglais (oral et écrit)
Show more
Show less","{'ProgLanguage': ['Python', 'Java', 'Scala', 'R', 'JavaScript'], 'DataBase': ['SQL', 'NoSQL'], 'DataAnalytics': ['R'], 'BigData': ['Hadoop', 'Spark'], 'MachingLearning': ['Orange'], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': ['AWS', 'Azure'], 'DevTools': ['Git'], 'Os': ['Windows'], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['DevOps', 'Big Data', 'Cloud'], 'FrSoftSkills': [], 'EnSoftSkils': []}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': ['Bac+5'], 'Experience': ['a', 'n', 's', '3', '3', '3']}"
LinkedIn,Data Engineer | Python - Azure | IA & Machine Learning  | Paris ou Remote Partiel,Octopus IT - Expert du recrutement tech,"Paris, Île-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-python-azure-ia-machine-learning-paris-ou-remote-partiel-at-octopus-it-expert-du-recrutement-tech-3664568765?position=22&pageNum=0&refId=TDTc9UZJy78L%2BED7EV%2BMrg%3D%3D&trackingId=moygXwPkYJVD30cyjrlNXw%3D%3D&trk=public_jobs_jserp-result_search-card,"La sociét��
Créée il y a plus de 2 ans, cette startup est la première base de connaissance intelligente dédiée aux services clients. Leur mission ? En finir avec la frustration lorsque l'on contact un Help Desk.
Pour cela, elle propose aux entreprises la possibilité de délivrer une expérience client d'exception : rapide et de qualité. Grâce à leur moteur de recherche intelligent, cette entreprise est capable de centraliser toute la connaissance interne de l'entreprise (procédures, produits, modes opératoires, etc.) et la diffuse intelligemment dans les outils de production des conseillers de service client.
Résultat :
Plus besoin de chercher l'information
Des réponses instantanées et de meilleures qualitées
Une autonomie totale des collaborateurs
Après une croissance fulgurante, elle a su séduire à la fois de nombreuses scale up (Luko, OpenClassrooms, Japhy...) et grands groupes (BNP Paribas, La Poste, Fnac Darty...).
Après le recrutement de leur Lead Data (réaliser ensemble) et suite à l'annonce de leur levée de 2,5M€ pour tripler la taille de ses équipes, le but est maintenant de s'imposer très vite comme la base de connaissance de référence en France et en Europe. Pour ce faire, nous recherchons un Data Engineer.
Le poste
En travaillant main dans la main avec le Lead Data, ta mission sera de développer et de maintenir des flux de données complexes et robustes. La donnée étant au coeur de l' entreprise, dans le produit comme dans la stratégie, tu seras amené à travailler avec un panel d’interlocuteurs très variés :
Data Scientists sur des sujets comme le monitoring des modèles de production et l’enrichissement des données d’entrainement.
Product Team sur des sujets de performance et d’acheminement de données au service de fonctionnalités produit telles que le dashboard d’analytics à destination de nos clients.
Customer Success / Strategy sur des sujets de pilotage comme le suivi de l’utilisation de notre plateforme ou la mise en place de KPIs de performance.
Tu travailleras sur les problématiques suivantes :
Tu seras responsable de notre architecture de données et de son outillage, mais aussi de la mise en place de pipelines de données complexes et robustes.
Tu seras amené à mettre en place des outils de monitoring et d’alerting pour suivre de près nos nombreuses pipelines de donnée.
Tu seras garant de la qualité de nos données en assurant l’application des guidelines de code et des tests automatisés pour chacune de nos pipelines.
Tu seras amené à mettre en place des outils de reporting / insights à destination d’interlocuteurs variés (Data Science, Product, Customer Success, Clients, etc.).
Tu créeras et développeras des pipelines de données avec des outils de scheduling et d’orchestration.
La stack sur laquelle vous travaillerez :
Langage : Python, Javascript
Framework data : PyTorch, Transformers (Hugging Face), FastAPI
Database : PostgreSQL, MongoDB, ElasticSearch, Redis
Infrastructure : Azure, Docker, Kubernetes, Spark, RabbitMQ, Serverless, Terraform
Environnement / Test : PyTest, Gitlab (git + ci/cd)
BI : Metabase, Superset
Votre profil
Entre 1 et 3 ans d'expérience en CDI
Tu as une expérience significative sur des problématiques de Data engineering
Tu es quelqu'un de pragmatique
Un très bon niveau en Python et une très bonne rigueur dans le code
Bonne pratique de dev : clean code, TDD, BDD
Une bonne culture Ops
Une logique cloud (Aws, GCP ou Azure)
Le salaire & avantages
50-7O K€ selon expérience
RTT
Carte Swile & Mutuelle
2/3 jours de télétravail par semaine
Et plus encore…
Ce qu’on préfère
Être impliqué à fond dans une aventure avec de nombreux challenges techniques
Belles opportunités d'évolutions sur des postes d'Architecte, de Lead ou de Ml Ops
Beaucoup de workshops en interne et catalogue de formations à votre guise
Une opportunité de travailler sur un produit unique qui a déjà séduit de très beaux clients (BNP Paribas, Fnac Darty, Luko, OpenClassrooms)
La possibilité de travailler sur une stack très moderne, des problématiques complexes aussi bien en traitement de données, qu'en DevOps
Un plan de BSPCE (actions de l'entreprise) très intéressant et motivant !
Une culture d'entreprise fondée sur l'apprentissage, l'autonomie, la bienveillance et l'exigence
Le fait de travailler au quotidien avec des fondateurs passionnés par leur domaine d'expertise
Ce poste a été soigneusement choisi par votre coach. Powered by Octopus IT, cabinet d’Experts en Recrutement Tech (CDI et clients finaux uniquement) – Visitez nous pour plus d’opportunités :
www.octopusit.fr
Show more
Show less","{'ProgLanguage': ['Python', 'Java', 'R', 'Go', 'JavaScript'], 'DataBase': ['SQL', ' MongoDB', 'Elasticsearch'], 'DataAnalytics': ['R'], 'BigData': ['Spark'], 'MachingLearning': ['PyTorch'], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': ['AWS', 'Azure'], 'DevTools': ['Git', 'Docker'], 'Os': [], 'DBMS': ['PostgreSQL'], 'SoftBigDataProcessing': [], 'Automation': ['Kubernetes'], 'InfrastructureAsCode': ['Terraform'], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': ['Docker', 'Kubernetes'], 'Collaboration': [], 'Other': ['DevOps', 'ML', 'Cloud', 'CI/CD'], 'FrSoftSkills': [], 'EnSoftSkils': []}","{'JobDetail': [], 'TypeContract': ['CDI'], 'Salary': ['50'], 'Level': [], 'Experience': ['a', 'n', 's', '2', '2', '2']}"
LinkedIn,Data Engineer - Modélisation SQL - F/H,Orange Business,Greater Lille Metropolitan Area,https://fr.linkedin.com/jobs/view/data-engineer-mod%C3%A9lisation-sql-f-h-at-orange-business-3916551577?position=23&pageNum=0&refId=TDTc9UZJy78L%2BED7EV%2BMrg%3D%3D&trackingId=mXyowhaRMxCj2BN%2Bzc7rrw%3D%3D&trk=public_jobs_jserp-result_search-card,"Et si Business & Decision et Orange Business conjuguaient leurs forces pour devenir l’un des leaders européens de la Data transformation ?
Nous l’avons fait ! Notre alchimie nous positionne comme un acteur unique intervenant sur toutes les étapes du voyage de la donnée.
Depuis 30 ans, Business & Decision, entité de Digital Services s'est imposée comme un partenaire stratégique pour la transformation Data de nombreux clients, dans des secteurs très variés. Digital Services est aujourd’hui l’ESN d’Orange Business alliant les expertises historiques Cloud et Digital d’Orange ainsi que le cœur de métier Data/IA de Business & Decision. Son but est d’accompagner les entreprises et les acteurs publics dans leur transformation grâce aux 4000 experts présents dans plusieurs grandes villes françaises comme Montpellier, Niort, Lyon, Bordeaux, Lille et Toulouse …
Description du poste
Orange Business, recherche pour son site de Lille, son futur Data Engineer pour rejoindre sa team Data.
Votre quotidien ?
En intégrant Orange Business, vous pouvez participer à une grande diversité d’activités dans la Data. En voici un aperçu :
Au démarrage du projet :
Recueillir et analyser les besoins du client
Rédiger les spécifications fonctionnelles et techniques
Estimer les charges
Pendant la phase de réalisation :
Modéliser des datawarehouses et datamart (intégration de flux et consolidation des données)
Développer les procédures d’alimentation (ETL)
Développer en SQL / PLSQL / Shell
Garantir la qualité des données et leur disponibilité
Réaliser la recette et les tests
Suivre et mettre en production
En fonction de votre évolution et de nos enjeux, vous pouvez aussi évoluer sur des missions transverses (conseil, coaching, avant-vente, formation, audit, etc.). La prise d’initiative est toujours la bienvenue !
Qualifications
Vous possédez 5 ans d'expérience ou plus dans la mise en œuvre de projets décisionnels et en modélisation.
Vous avez de s
olides compétences en développement SQL
(job, scripting, déploiement) ainsi que sur Python.
Envie d’apprendre de nouvelles technos ? Vous souhaitez partager vos compétences et bénéficier des expertises de la Team Orange Business ?
Outre l’aspect technique, c’est une personnalité qui est recherchée !
Show more
Show less","{'ProgLanguage': ['Python', 'R'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': ['Orange'], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git'], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Cloud'], 'FrSoftSkills': [], 'EnSoftSkils': ['Initiative']}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's', '30', '30', '30']}"
LinkedIn,DATA ENGINEER (H/F),SFR,"Paris, Île-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-h-f-at-sfr-3879318123?position=24&pageNum=0&refId=TDTc9UZJy78L%2BED7EV%2BMrg%3D%3D&trackingId=FMZDHlMn1O%2FB9TWDKjU5bw%3D%3D&trk=public_jobs_jserp-result_search-card,"En tant que Data Ingénieur expérimenté, vous occuperez un rôle essentiel dans notre équipe Data Science.
Vous serez responsable de la conception, du développement et de la maintenance des pipelines de données ainsi que de l'intégration de sources de données multiples.
Votre expertise sera cruciale pour garantir une gestion efficace des flux de données, ainsi que pour faciliter l'analyse et la visualisation des données en plus du support aux data scientists vos missions seront les suivantes :
Architecture projet des données
: Concevoir et développer des architectures projet de données robustes, évolutives et performantes pour intégrer et gérer de grandes quantités de données provenant de sources multiples. Assurer la fiabilité, l'évolutivité et la sécurité des flux de données entrant d’un projet Data Science.
Intégration des données
: Élaborer des pipelines de données efficaces pour l'extraction, la transformation et le chargement des données (via notre Framework ELT/ETL interne) provenant de différentes sources. Mettre en place des processus d'intégration automatisés et veiller à la qualité des données.
Gestion des bases de données
: Concevoir et optimiser des bases de données pour répondre aux besoins analytiques et de reporting. Assurer la performance, la disponibilité et la sécurité des bases de données, ainsi que la gestion efficace des requêtes.
Collaboration interfonctionnelle
: Support des Data Scientists, vous travaillerez avec les équipes business pour comprendre leurs besoins et fournir des conseils et des recommandations basés sur les données.
Optimisation des performances
: Surveiller et optimiser les performances des pipelines de données, des bases de données et des requêtes. Identifier les goulots d'étranglement et les points d'optimisation, et proposer des améliorations pour garantir des performances optimales.
Sécurité et conformité
: Veiller à ce que les données soient traitées et stockées conformément aux normes de sécurité et de confidentialité. Mettre en place des mécanismes de sécurité pour protéger les données sensibles et garantir la conformité aux réglementations en vigueur.
Votre profil :
Vous avez un
Diplôme universitaire en informatique, en génie logiciel, en science des données ou dans un domaine connexe et vous avez à minima 5 ans d'expérience en tant que Data Ingénieur.
Vous possédez également une solide maîtrise des technologies et des outils suivants :
Hadoop, Spark, SQL, Kafka, GCP BigQuery,
De plus vous avez une bonne compréhension des architectures, des modèles et des concepts de base de donnés avec une expérience avancée dans la mise en œuvre de pipelines ETL et dans la gestion de bases de données.
Vos connaissances en matière de sécurité des données, de conformité aux réglementations ainsi que vos compétences en programmation scripting et en développement logiciel seront un plus.
Vos excellentes compétences en communication seront des qualités appréciées et
un niveau d'anglais (appliquée au domaine technique) est un plus.
Show more
Show less","{'ProgLanguage': ['R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': ['Hadoop', 'Spark'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'DBMS': ['BigQuery'], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': [], 'FrSoftSkills': ['Communication', 'Collaboration'], 'EnSoftSkils': ['Communication', 'Collaboration']}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's', '5', '5', '5']}"
LinkedIn,Data & Cloud Engineer (H/F),fifty-five,"Paris, Île-de-France, France",https://fr.linkedin.com/jobs/view/data-cloud-engineer-h-f-at-fifty-five-3910028674?position=25&pageNum=0&refId=TDTc9UZJy78L%2BED7EV%2BMrg%3D%3D&trackingId=VCniSLmV9FdFUbTN8DKrDw%3D%3D&trk=public_jobs_jserp-result_search-card,"Data & Cloud Engineer
fifty-five est une data-company d'un genre nouveau qui aide les marques à exploiter les données pour améliorer le marketing, les médias et l'expérience client grâce à une combinaison de services de conseil et de technologie spécialisés.
En tant que pilier data et marketing du Brandtech Group, nous offrons des services qui combinent le conseil en stratégie, les services de cloud, le conseil en média et l'expérience client.
fifty-five, c'est plus de 400 experts du numérique. Des digital consultants, des spécialistes du tracking et du média, des ingénieurs et des data scientists, travaillent tous en étroite collaboration pour fournir des conseils marketing de haut niveau et une assistance technique aux marques, dans tout type d'industrie, partout dans le monde.
Partenaire des annonceurs de la collecte à l'activation et l'exploitation des données, nous aidons les organisations à devenir de véritables entités omnicanales maîtrisant l'efficacité de leur écosystème digital et ses synergies avec le monde physique.
Basé à Paris, nous opérons sur 3 fuseaux horaires depuis nos 10 bureaux, situés à Paris, Londres, Genève, Milan, Shanghai, Hong Kong, Shenzhen, Taipei, Singapour et New York. fifty-five attache une importance particulière au bien-être de ses collaborateurs, ce qui lui a permis de figurer dans le classement Best Workplaces France en 2018.
Contexte :
L'équipe d'ingénierie développe et met en œuvre les solutions techniques permettant la réalisation de pipelines de données et l'implémentation de data platform pour nos clients : récupération de datas sur de multiples sources de données (APIs, files, etc.), data cleaning, data processing, automation et monitoring de l'ensemble. L'équipe s'appuie sur des technologies récentes (docker, kubernetes, terraform, notebooks, etc.) et met en place ses projets dans les différents clouds du marché (GCP, Azure, AWS...).
Mission :
Nous sommes à la recherche d'une personne capable de réaliser des projets techniques pour répondre aux besoins de nos clients (par exemple: système de recommandations de produits, détection d'anomalies, ranking). Les activités vont du chiffrage et du sizing technique à la mise en œuvre des architectures, en passant par la revue des spécifications fonctionnelles et la production de code. Le Data & Cloud Engineer sera épaulé par un Lead dans ses missions. Il sera également amené à participer à la R&D et à accompagner les équipes transverses dans la mise en place d'outils de travail internes (librairies pour les data scientists, environnement Notebooks pour les data analysts et data scientists, développement de frameworks sur différents cloud providers, etc.).
Nous souhaitons trouver la bonne personne pour faire évoluer ou créer de nouvelles solutions dans ce cadre. Les missions comprennent aussi bien du prototypage rapide pour des démonstrateurs, que de la production de code robuste qui tourne en production tous les jours.
Compétences et expériences :
2 ans d'expérience en tant que Data Engineer
Maîtrise de Python, SQL
Maîtrise des environnements Cloud. Idéalement certifié GCP, Azure ou AWS
Bonne connaissance de Docker/Kubernetes
Bonne connaissance d'au moins un data warehouse (BigQuery, Snowflake, etc)
Connaissance autour des Notebooks (Jupyter)
A l'aise avec des concepts liés aux APIs (OAuth, REST, etc.)
A l'aise avec les notions d'Infrastructure as Code (Terraform)
Au courant des pratiques GitOps et connaissances des concepts autour du CI/CD
La maîtrise d'un orchestrateur, comme Apache Airflow, est un plus
Esprit d'équipe (collaborer aux tests unitaires, revue de code, partage de code, sprints)
Bon niveau en français et en anglais
A déjà travaillé en mode projet avec des interlocuteurs variés (consultant, data analyst, data scientist)
Une expérience en marketing digital est un plus
Nous proposons :
un bureau au centre de Paris avec terrasse et jardin
un environnement multiculturel avec des collaborateurs aux nationalités multiples (France, Royaume-Uni, Etats-Unis, Chine, Tunisie, Italie et plus)
des projets avec nos bureaux à Londres, Hong Kong, New York, Shanghai, Genève, Shenzhen et Taipei
des TGIF et supers soirées
Show more
Show less","{'ProgLanguage': ['Python', 'R'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': ['Apache Airflow'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': ['AWS', 'Azure'], 'DevTools': ['Git', 'Docker'], 'Os': [], 'DBMS': ['Snowflake', 'Snowflake', 'BigQuery'], 'SoftBigDataProcessing': [], 'Automation': ['Kubernetes', 'Airflow'], 'InfrastructureAsCode': ['Terraform'], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': ['Docker', 'Kubernetes'], 'Collaboration': [], 'Other': ['Cloud', 'CI/CD'], 'FrSoftSkills': ['Collaboration', 'Organisation'], 'EnSoftSkils': ['Collaboration']}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's', '2', '2', '2']}"
LinkedIn,Data Engineer – Grenoble,Capgemini,"Grenoble, Auvergne-Rhône-Alpes, France",https://fr.linkedin.com/jobs/view/data-engineer-%E2%80%93-grenoble-at-capgemini-3905836212?position=26&pageNum=0&refId=TDTc9UZJy78L%2BED7EV%2BMrg%3D%3D&trackingId=phBx1%2BYFP%2BE7q4Dxg28eJw%3D%3D&trk=public_jobs_jserp-result_search-card,"Choisir Capgemini, c'est choisir une entreprise où vous serez en mesure de façonner votre carrière selon vos aspirations. Avec le soutien et l'inspiration d'une communauté d’experts dans le monde entier, vous pourrez réécrire votre futur. Rejoignez-nous pour redéfinir les limites de ce qui est possible, contribuer à libérer la valeur de la technologie pour les plus grandes organisations et participer à la construction d’un monde plus durable et inclusif.
Vos missions :
En tant que Data Engineer au sein d'une équipe multidisciplinaire, vos responsabilités principales seront les suivantes :
Intervenir sur les différentes phases d'un projet dans un environnement Cloud et Agile.
Contribuer à la gestion de la qualité des données et extraction et analyse de celle-ci, ainsi qu’à la présentation des données dans leur forme raffinée.
Proposer des nouvelles lectures de données via un travail de fouille sur les gisements d’information, notamment client.
Adopter une posture de consultant : proposer de nouvelles solutions et accompagner le client dans ses choix.
Votre profil :
Titulaire d'un Bac+5 en école d’ingénieur ou en université.
Connaissances approfondies des ETL (Talend, Informatica ou SSIS), du traitement de données (Spark, Python, Scala) ainsi que des bases de données (Oracle, SQL Server, Postgres).
Faculté pour se montrer curieux, autonome et proactif dans la réalisation de ses tâches.
Capacité à faire preuve de rigueur et à travailler en équipe.
Bon niveau d’anglais (B2 minimum).
3 raisons de nous rejoindre :
Qualité de vie au travail
: accord de télétravail en France et à l’international, accord sur l’égalité professionnelle, la parentalité, l’équilibre des temps et la mobilité durable.
Apprentissage en continu
: certifications et formations en libre accès, accompagnement sur mesure avec votre career manager, parcours d’intégration sur 9 mois.
Avantages groupe & CSE
: plan actionnariat, tarif préférentiels, remboursement partiel vacances, remboursement de votre abonnement sportif ou culturel.
Nos engagements et priorités
:
Le groupe Capgemini encourage une culture inclusive dans un cadre multiculturel et handi-accueillant. En nous rejoignant, vous intégrez un collectif qui valorise la diversité, développe le potentiel de ses talents, s’engage dans des initiatives solidaires avec ses partenaires, et se mobilise pour réduire son impact environnemental sur tous ses sites et auprès de ses clients.
À propos de Capgemini :
Capgemini est un leader mondial, responsable et multiculturel, regroupant près de 350 000 personnes dans plus de 50 pays. Fort de 55 ans d’expérience, nous sommes un partenaire stratégique des entreprises pour la transformation de leurs activités en tirant profit de toute la puissance de la technologie et des innovations dans les domaines en perpétuelle évolution tels que le cloud, la data, l’Intelligence Artificielle, la connectivité, les logiciels, l’ingénierie digitale ou les plateformes.
Get The Future You Want* | www.capgemini.com/fr-fr
*Capgemini, le futur que vous voulez
Show more
Show less","{'ProgLanguage': ['Python', 'Scala', 'R'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': ['Spark'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git'], 'Os': [], 'DBMS': ['Oracle', 'SQL Server'], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Cloud'], 'FrSoftSkills': ['Organisation'], 'EnSoftSkils': ['Initiative']}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': ['Bac+5'], 'Experience': ['a', 'n', 's', '55', '55', '55']}"
LinkedIn,Data Engineer,eXalt Value,"Île-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-at-exalt-value-3897767649?position=27&pageNum=0&refId=TDTc9UZJy78L%2BED7EV%2BMrg%3D%3D&trackingId=NbB%2F19lo6taC1wWs893b8w%3D%3D&trk=public_jobs_jserp-result_search-card,"eXalt
est un cabinet de conseil IT
Pure player Data
& IA basé à Paris.
Notre offre s’articule autour de 4 piliers réunis au sein d’une même communauté pour un accompagnement à 360° alliant une expertise technique et méthodologique à une approche conseil métier:
Data Gouvernance & Project
Data Engineering & Big Data
Data Performance & Analytics
Data Science & IA
Filiale du groupe eXalt, créé en 2018,
regroupant plus de
950 collaborateurs en France
(Paris, Lyon, Bordeaux, Lille, Nantes, Marseille)
et à l’international
(Colombie, Etats-Unis, Espagne, Belgique),
eXalt Value
apporte une
expertise approfondie
dans le domaine de la Data & IA et conseille les entreprises dans le déploiement de leurs stratégies data-driven.
Bénéficiant du support du groupe eXalt
(1er dans la catégorie Conseil & Audit au classement des Champions de la Croissance 2024), eXalt Value
est en pleine croissance et regroupe aujourd’hui une communauté d’expertise de plus de 60 collaborateurs en région parisienne.
Nos consultants interviennent sur d
es projets d’envergure
dans divers secteurs d’activité,
Banque & Assurance, Médias, Transports, Retail, Tourisme, etc.
Nous recherchons un
Data Engineer Confirmé H/F (minimum 4 ans d'expérience dans la fonction)
pour rejoindre notre communauté sur le
pilier Data Engineering & Big Data.
Vos missions:
Concevoir et développer des pipelines et des flux de données.
Intégrer et transformer des données provenant de différentes sources.
Développer et mettre en œuvre des algorithmes de traitement de données avancés.
Collaborer étroitement avec les équipes clients pour comprendre leurs besoins et fournir des solutions adaptées.
Assurer la qualité et la fiabilité des solutions développées.
Conseiller les équipes clients sur les solutions à mettre en place.
Les Prérequis :
Titulaire d'un Bac+5, Ecole d'Ingénieur
Maîtrise d'un ou plusieurs langages de programmation (
Python, Scala, Spark, etc
.).
Expérience approfondie des technologies
Big Data (Hadoop, Spark, Kafka, Talend, etc.)
Expérience avérée
en
environnement Cloud (AWS, GCP, ou Azure)
.
Solides compétences en conception et en optimisation de pipelines de données.
Expérience de travail en
méthode Agile
Capacité à travailler de manière autonome et en équipe.
Excellentes compétences en communication et en résolution de problèmes.
Maîtrise de l’anglais (oral & écrit dans un contexte international professionnel).
Votre environnement eXalté:
Un environnement de travail Collaboratif
favorisant les initiatives et projets transverses à la Practice Data & IA (Lab IA, Data Hub, etc.).
Un collectif de consultants passionnés,
s’intéressant aux tendances innovantes du secteur.
Une Practice de proximité,
privilégiant la montée en compétence de ses collaborateurs (formations, coachings, mentorats, etc.)
Un suivi individualisé et de proximité
par un.e Data Sales Manager référent du compte client, un.e Chargé.e RH et un.e Practice Manager
Une équipe ouverte et dynamique,
qui privilégie les moments de partage et de convivialité (séminaires, eXaltemps, meet-up, déjeuners d’équipe, etc.)
Notre processus de recrutement :
Un entretien RH avec Estelle,
à la suite duquel vous saurez tout (ou presque) d’eXalt Value,
Un entretien technique avec un Manager assorti d’un test technique,
lors duquel vous aurez l’occasion de démontrer vos talents mais aussi d’apprendre avant même de dire oui,
Un entretien final avec la Directrice Associée ou le Directeur Opérationnel,
pour finir de vous convaincre de nous rejoindre 😊
Nous avons hâte de recevoir vos CV, et de faire votre connaissance!
Show more
Show less","{'ProgLanguage': ['Python', 'Scala', 'R', 'Go'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': ['Hadoop', 'Spark'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': ['AWS', 'Azure'], 'DevTools': [], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Big Data', 'Cloud'], 'FrSoftSkills': ['Communication', 'Résolution de problèmes'], 'EnSoftSkils': ['Communication', 'Initiative']}","{'JobDetail': ['Confirmé'], 'TypeContract': [], 'Salary': [], 'Level': ['Bac+5'], 'Experience': ['a', 'n', 's', '4', '4', '4']}"
LinkedIn,Data Engineer | Python - Spark - Hadoop | Spécialisé en Big Data | Paris ou Remote Partiel,Octopus IT - Expert du recrutement tech,"Paris, Île-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-python-spark-hadoop-sp%C3%A9cialis%C3%A9-en-big-data-paris-ou-remote-partiel-at-octopus-it-expert-du-recrutement-tech-3685740787?position=28&pageNum=0&refId=TDTc9UZJy78L%2BED7EV%2BMrg%3D%3D&trackingId=95UUn0EtXS4JBMe178TvPw%3D%3D&trk=public_jobs_jserp-result_search-card,"La société
Créée il y a 7 ans, cette entreprise de conseil en hyper croissance, se compose d'environ 90 personnes. Elle est devenue experte en Data et IA (NLP, Deep Learning, Machine Learning) et accompagne leurs clients sur l’ensemble de leurs projets data à travers la valorisation de leurs données.
Leur valeur ajoutée ? Leur spécialisation en Data ce qui leur permet d'offrir 3 expertises métiers distinctes : la Data Science, la Data Engineering et le Machine Learning Engineering. Autour de ces expertises gravitent bien sûr les métiers de Lead et d'Architecte.
Une autre de leur force est leur formation interne (avec des profils de seniors ou d'architectes) et externe (avec des partenaires pour passer les certifications).
Chez eux, le collaborateur est placé au centre des préoccupations, permettant ainsi de créer une cohésion et une véritable culture au sein de l'entreprise. Par exemple la majorité des projets se font en équipe et non seul.
Connu et reconnu pour leur expertise en Big Data, ils sont devenu le partenaire principal d'un grand groupe du CAC 40 et ont pris le lead sur tous les sujets touchant à la transformation Big Data de ce groupe.
Pour poursuivre leur croissance, répondre à leurs ambitions et développer de nouveaux marchés, nous recherchons plusieurs profils pour renforcer leurs effectifs.
Le poste
En les rejoignant vous travaillerez sur les problématiques suivantes :
Mise en place et/ou scale d'architectures
Construction de Datalake
Mise en production de model de ML
Pipelining de données
Streaming de données et temps réel
La stack sur laquelle vous travaillerez :
Python, Scala, Spark, Architectures distribuées : Hadoop, HDFS, Cloud : Aws, GCP, Azure
Votre profil
A partir de 3 ans d'expérience en CDI
Vous avez une expérience significative sur des problématiques Big Data
Très bonne compétences en Python et/ou Scala et en Spark
Vous êtes familier avec Hadoop, Hive, Hbase
Une logique cloud (Aws, GCP ou Azure)
Le salaire & avantages
50-60 K€ selon expérience
RTT
Carte Swile & Mutuelle
3/4 jours de télétravail par semaine
Et plus encore…
Ce qu’on préfère
Être impliqué à fond dans une aventure avec de nombreux challenges techniques
Belles opportunités d'évolutions sur des postes d'Architecte, de Lead ou de Ml Ops
Très bonne ambiance, équipe solidaire et orientée partage d’informations
Beaucoup de workshops en interne et catalogue de formations à votre guise
Ce poste a été soigneusement choisi par votre coach. Powered by Octopus IT, cabinet d’Experts en Recrutement Tech (CDI et clients finaux uniquement) – Visitez nous pour plus d’opportunités :
www.octopusit.fr
Show more
Show less","{'ProgLanguage': ['Python', 'Scala', 'R'], 'DataBase': ['HBase'], 'DataAnalytics': ['R'], 'BigData': ['Hadoop', 'Spark'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': ['AWS', 'Azure'], 'DevTools': [], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': ['HBase'], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Big Data', 'ML', 'Machine Learning', 'Cloud'], 'FrSoftSkills': [], 'EnSoftSkils': []}","{'JobDetail': ['Senior'], 'TypeContract': ['CDI'], 'Salary': ['50'], 'Level': [], 'Experience': ['a', 'n', 's', '7', '7', '7']}"
LinkedIn,Data Engineer (H/F),MP DATA,"Toulouse, Occitanie, France",https://fr.linkedin.com/jobs/view/data-engineer-h-f-at-mp-data-3908719610?position=29&pageNum=0&refId=TDTc9UZJy78L%2BED7EV%2BMrg%3D%3D&trackingId=wOEylaAHBy4c%2BGNI5PQ6tg%3D%3D&trk=public_jobs_jserp-result_search-card,"MP DATA est une société spécialisée dans l’acquisition, le traitement, et la valorisation des données.
Depuis sa création en 2015, MP DATA accompagne ses clients, majoritairement industriels, dans le management de leur performance et l’exploitation de leurs données.
Les collaborateurs, tous issus de grandes écoles, incarnent au quotidien les valeurs d’Excellence, de Partage et d’Engagement.
Ils associent savoir-faire technique, méthodologie et passion et mettent leurs compétences au service de missions et projets au sein de grands groupes français.
MP DATA accompagne ses clients sur toute la chaine au travers de 3 pôles d’expertise : Conseil et Stratégie, Infrastructure & CloudOPS, Data Science.
Chez MP DATA, les équipes commerciales cherchent des missions en fonction des envies des collaborateurs et non pas l’inverse. Les consultants sont accompagnés dans tous leurs projets, de la mobilité géographique, au changement de secteur d’activité en passant par le développement de nouvelles compétences.
Rejoindre MP DATA, c’est la garantie de travailler sur des sujets passionnants avec un cadre technique fort.
Descriptif du poste :
Nous recherchons un Data Engineer expérimenté pour rejoindre notre équipe.
En tant que Data Engineer, vous serez responsable de la conception, du développement et de la mise en œuvre de pipelines de traitement de données en temps réel à grande échelle.
Vous travaillerez avec des technologies telles que Kafka, Flink, Kinesis et vous utiliserez les services du cloud AWS pour stocker et traiter les données.
Vos responsabilités :
Utiliser Kafka pour le traitement de flux de données en temps réel à grande échelle, en travaillant avec les producteurs, les consommateurs et les topics.
Mettre en œuvre des pipelines de traitement de données en streaming avec Flink, en appliquant des transformations complexes et en gérant les états.
Écrire du code efficace et maintenable en Java / Python pour manipuler et analyser les données en temps réel.
Utiliser Kubernetes pour déployer et gérer des applications conteneurisées à grande échelle, en assurant la résilience et l’évolutivité des services.
Utiliser les services AWS tels que Amazon S3, AWS Lambda, Elastic Kubernetes Service (EKS), Elastic Container Service (ECS) et Elastic Compute Cloud (EC2) pour le stockage, le traitement et le calcul des données en temps réel.
Suivre les meilleures pratiques pour une utilisation efficace du cloud, en assurant la gestion des coûts, la sécurité des données et la disponibilité des services.
Collaborer avec l’équipe de développement logiciel et la gestion de projets pour assurer un flux de développement fluide et une livraison efficace des fonctionnalités.
Bon à savoir :
CDI / ASAP / Toulouse
Profil recherché:
Nous recherchons un candidat diplômé d'une grande école d'Ingénieur avec une première expérience.
Compétences nécessaires :
Expérience significative dans un environnement industriel en mode DevOps, avec des outils tels que CICD, gitlab, Jenkins, Sonar, Nexus, XLdeploy, Camunda, etc.
Maîtrise des langages de programmation tels que Python, Java et expertise dans l’écriture et l’optimisation du code SQL
Maîtrise du français et bonne maitrise de l’anglais.
Capacité à travailler en équipe et esprit d’équipe.
Le processus de recrutement se déroule en 3 entretiens :
Prise de contact
1er entretien : Présentation et projet du candidat + présentation MP DATA
2ème entretien : Entretien de qualification technique
3ème entretien : Rencontre avec les équipes dans les locaux MP DATA + Proposition de collaboration
Show more
Show less","{'ProgLanguage': ['Python', 'Java', 'R'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': ['Flink'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': ['AWS'], 'DevTools': ['Git', 'Jenkins'], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': ['Kubernetes'], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': ['Kubernetes'], 'Collaboration': [], 'Other': ['DevOps', 'Cloud'], 'FrSoftSkills': ['Collaboration'], 'EnSoftSkils': ['Collaboration']}","{'JobDetail': [], 'TypeContract': ['CDI'], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's']}"
LinkedIn,Data Engineer (H/F),Technology & Strategy,"Lyon, Auvergne-Rhône-Alpes, France",https://fr.linkedin.com/jobs/view/data-engineer-h-f-at-technology-strategy-3881556102?position=30&pageNum=0&refId=TDTc9UZJy78L%2BED7EV%2BMrg%3D%3D&trackingId=6Bqksdqvzmsz9cNBZny65A%3D%3D&trk=public_jobs_jserp-result_search-card,"Découvrez Novencia
:
Expert en Data et Intelligence Artificielle, nous aidons nos clients à exploiter et à valoriser leurs données sous toutes ses formes en les accompagnant sur des projets de Data Analyse, Data Gourvernance, Data Architecture, Data Science, et Data Engineering…
Vous avez une solide expérience de minimum 2 ans dans l'ingénierie des données et vous êtes à la recherche de nouveaux défis ? Bouclez votre ceinture, la suite est pour vous !
Type de contrat : CDI
Lieu : Lyon
En qualité de Data Engineer (H/F), votre rôle sera :
Concevoir et proposer les solutions de développement répondant aux besoins fonctionnels et techniques des projets big data.
Tu participes à la conception de solutions permettant le traitement de volumes importants de pipelines données.
Réaliser ces solutions par l’écriture de code, en respectant les méthodes et procédures qualités définies au sein du département Technique.
Mise à disposition sécurisé et lisible de la data.
S’assurer de la conformité fonctionnelle et technique de ces réalisations en effectuant les tests automatisés nécessaire et la mise en place de monitoring (système et qualité).
Assurer la maintenance des applicatifs / plateforme data science
Assurer une veille technologique
Vous disposez des compétences suivantes :
Maitrise des plateformes Cloud (AWS, GCP ou Azure), de Scala et de SQL.
Un.e touche à tout : possédant des compétences en langage Python/Spark, de bonnes capacités de modélisation, une forte appétence pour le Big Data
Fin.e connaisseur.euse : Data Engineer convaincu, très peu de secrets pour les clusters et pour les calculs parallèles
Explorateur.trice : découvre de nouvelles technos grâce à une veille régulière
Débrouillard.e : relève de nouveaux défis
Notre objectif commun est de co-construire votre carrière en fonction de vos aspirations et de vos compétences.
Contactez-moi en message privé ou par mail à s.ziki@technologyandstrategy.com !
Let's make it possible #together
*Nos postes sont ouverts aux personnes bénéficiant d’une Reconnaissance de la Qualité de Travailleur Handicapé (RQTH). T&S Groupe encourage la diversité et l’égalité sur le lieu de travail. Tous les candidats qualifiés H/F/* sont pris en considération pour un emploi sur un même pied d'égalité.
Show more
Show less","{'ProgLanguage': ['Python', 'Scala', 'R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': ['Spark'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': ['AWS', 'Azure'], 'DevTools': [], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Big Data', 'Cloud'], 'FrSoftSkills': [], 'EnSoftSkils': []}","{'JobDetail': [], 'TypeContract': ['CDI'], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's', '2', '2', '2']}"
LinkedIn,Stage - Data Engineer - ML (H/F),Withings,"Issy-les-Moulineaux, Île-de-France, France",https://fr.linkedin.com/jobs/view/stage-data-engineer-ml-h-f-at-withings-3613476264?position=31&pageNum=0&refId=TDTc9UZJy78L%2BED7EV%2BMrg%3D%3D&trackingId=KmvpsR%2BWm3jN8lzOCziUBA%3D%3D&trk=public_jobs_jserp-result_search-card,"Chez Withings, nous développons des appareils de santé connectée : nos balances connectées, montres hybrides, tensiomètres, moniteurs de sommeil et tous les dispositifs de notre gamme sont aujourd'hui utilisés par des millions d'utilisateurs. Notre objectif est de permettre la prévention, le dépistage et l'accompagnement d'un certain nombre de maladies chroniques via des produits et des services innovants afin de révolutionner la manière dont on prend soin de notre santé.
Au sein de l'équipe Machine Learning, nous développons des algorithmes pour extraire des informations physiologiques et médicales pour nos utilisateurs tels que le SPO2, la fréquence cardiaque, la détection de diverses pathologies comme la fibrillation atriale, l'apnée du sommeil...
Intégré.e au sein de l'équipe Machine Learning, tu auras une ou plusieurs des responsabilités suivantes :
Développer un outil de monitoring de la dette technique, des mauvaises pratiques de code, des failles de sécurité ;
Construire des dashboards de visualisation ;
Construire un système d'alerte pour notifier les contributeurs d'éventuels problèmes ;
Développer des outils permettant de corriger les éventuels problèmes de façon automatisée ;
Requirements
À la recherche d'un stage d'une durée de 3 à 6 mois ;
Préparation d'un Master en école d'ingénieur ou équivalent / année de césure possible ;
Maîtrise de Python ;
Maîtrise de Debian ou de Ubuntu, de Shell et de l'environnement Linux ;
Première expérience sur du développement logiciel ;
Culture DevOps (omniprésence du monitoring, automatisation des tâches, ...)
Compréhension de la culture et des besoins des différents membres de l'équipe ;
Rigueur, autonomie, prise d'initiative, curiosité
Benefits
Rejoindre l'aventure Withings, c'est :
Intégrer un des pionniers et leaders mondiaux de la santé connectée, plusieurs fois primé au Consumer Electronic Show
Contribuer à des projets innovants et ambitieux pour la santé de demain dans un environnement agile et en constante évolution
Intégrer une entreprise internationale, membre de la FrenchTech 120, dont les équipes sont basées à Issy-les-Moulineaux, Boston, Hong-Kong et Shenzhen
Participer à l'amélioration continue de nos produits et services en les bêta-testant avant leur sortie, notamment lors de nos nombreuses sessions sportives entre collègues
Participer à la Withings Med Academy en assistant à des conférences de professionnels de santé afin de renforcer ses connaissances dans le domaine médical
Collaborer avec des collègues passionnés et célébrer ensemble chacune de nos réussites !
Toutes les candidatures reçues sont étudiées indépendamment de l'origine ethnique, des croyances, de la religion, du genre, de l'orientation sexuelle ou de la santé des candidats. Withings aspire à offrir et garantir l'égalité des chances aux candidats et seules les personnes habilitées (RH et Management) auront accès aux informations concernant votre candidature.
Show more
Show less","{'ProgLanguage': ['Python', 'R', 'Go'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': [], 'Os': ['Linux'], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['DevOps', 'Machine Learning'], 'FrSoftSkills': [], 'EnSoftSkils': ['Initiative']}","{'JobDetail': ['Hybride'], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's']}"
LinkedIn,Data Engineer,Thales,"Ollioules, Provence-Alpes-Côte d'Azur, France",https://fr.linkedin.com/jobs/view/data-engineer-at-thales-3902424527?position=32&pageNum=0&refId=TDTc9UZJy78L%2BED7EV%2BMrg%3D%3D&trackingId=Fv5mtAMxP79Qn3C6UTqogg%3D%3D&trk=public_jobs_jserp-result_search-card,"QUI SOMMES-NOUS ?
Thales est un leader mondial des hautes technologies comptant plus de 81 000 collaborateurs présents sur tous les continents. Le Groupe investit dans les innovations du numérique et de la « deep tech » – big data, intelligence artificielle, connectivité, cybersécurité et quantique – pour construire un avenir de confiance, essentiel au développement de nos sociétés, en plaçant l’humain au cœur des décisions.
Thales propose des solutions, services et produits qui aident ses clients – entreprises, organisations, Etats – dans cinq grands marchés vitaux pour le fonctionnement de nos sociétés : identité et sécurité numériques, défense, aéronautique, espace, et transport.
QUI ETES-VOUS ?
Diplômé d’un Bac+5 en école d’ingénieur ou équivalent universitaire avec une spécialisation en informatique, vous avez a
u moins 3 ans d'expérience
dans les technologies Big Data.
Passionné par le
secteur de la Défense et du Naval.
CE QUE NOUS POUVONS ACCOMPLIR ENSEMBLE :
En tant que
Data Engineer,
vous jouerez un rôle clé dans la conception, le développement et la maintenance de notre infrastructure de données, ainsi que dans la transformation et la gestion des flux de données.
VOS MISSIONS :
• Concevoir, développer et déployer des solutions Big Data en utilisant les technologies
Hadoop, Spark, Scala
.
• Mettre en place des pipelines de données performants pour l'ingestion, le traitement et le stockage des données massives.
• Collaborer étroitement avec les équipes métier pour comprendre leurs besoins en matière d'analyse de données et proposer des solutions adaptées.
• Optimiser les performances des clusters Hadoop pour garantir une exploitation efficace des données.
• Assurer la qualité et la fiabilité des données traitées, en mettant en place des processus de validation et de nettoyage.
• Identifier et résoudre les problèmes liés à l'infrastructure Big Data et proposer des améliorations.
Innovation, passion, ambition : rejoignez Thales et créez le monde de demain, dès aujourd’hui.
Show more
Show less","{'ProgLanguage': ['Scala', 'R'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': ['Hadoop', 'Spark'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Big Data'], 'FrSoftSkills': ['Organisation'], 'EnSoftSkils': []}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': ['Bac+5'], 'Experience': ['a', 'n', 's', '3', '3', '3']}"
LinkedIn,Data Engineer - Nantes,Capgemini,"Nantes, Pays de la Loire, France",https://fr.linkedin.com/jobs/view/data-engineer-nantes-at-capgemini-3803998213?position=33&pageNum=0&refId=TDTc9UZJy78L%2BED7EV%2BMrg%3D%3D&trackingId=AYRkKdnEYMdhl33uV621Ow%3D%3D&trk=public_jobs_jserp-result_search-card,"Capgemini
Choisir Capgemini, c'est choisir une entreprise où vous serez en mesure de façonner votre carrière selon vos aspirations, où vous serez soutenu et inspiré par une communauté d’experts dans le monde entier, où vous pourrez réécrire votre futur. Rejoignez-nous pour redéfinir les limites de ce qui est possible, contribuer à libérer la valeur de la technologie pour les plus grandes organisations et participez à la construction d’un monde plus durable et inclusif.
Vos missions :
Intégré(e) au sein d'une équipe projets intervenant pour des clients dans des secteurs d'activités variées, vous serez notamment en charge des missions suivantes :
Concevoir et mettre en oeuvre des stratégies sécurisées d'acquisition et d'intégration de données,
Configurer des référentiels de données à la pointe de la technologie dans des environnements distribués, majoritairement dans le cloud (Google Cloud Platform, Azure Databricks, AWS) et/ou en environnement Hadoop (distribution MapR, Cloudera, Hortonworks),
Construire des pipelines de données pour collecter, transformer et traiter des données en collaboration avec des scientifiques de données afin de répondre aux exigences de la modélisation de données d'analyse avancée.
Votre profil :
Diplôme d’ingénieur ou équivalent universitaire
Minimum 3 ans d'expérience
Anglais courant
Maîtrise des langages Java, Scala ou Python et expertise sur les framework Spark et/ou Hadoop.
Expertise sur les services Cloud Data Platform suivants : Azure Data Lake, Azure synapse, Azure Data Factory, Azure Data Explorer, GCP, AWS, Snowflake, Databricks…
3 raisons de nous rejoindre :
Qualité de vie au travail : accord de télétravail en France et à l’international, accord sur l’égalité
professionnelle, la parentalité, l’équilibre des temps et la mobilité durable.
Apprentissage en continu : certifications et formations en libre accès, accompagnement sur mesure avec votre carreer manager, parcours d’intégration sur 9 mois.
Avantages groupe & CSE : plan actionnariat, activités à tarifs préférentiels, remboursement partiel
vacances, remboursement de votre abonnement sportif ou culturel.
Nos engagements et priorités :
Le groupe Capgemini encourage une culture inclusive dans un cadre multiculturel et handi-accueillant. En nous rejoignant, vous intégrez un collectif qui valorise la diversité, développe le potentiel de ses talents, s’engage dans des initiatives solidaires avec ses partenaires, et se mobilise pour réduire son impact environnemental sur tous ses sites et auprès de ses clients.
Capgemini
Capgemini est un leader mondial, responsable et multiculturel, regroupant près de 350 000 personnes dans plus de 50 pays. Fort de 55 ans d’expérience, nous sommes un partenaire stratégique des entreprises pour la transformation de leurs activités en tirant profit de toute la puissance de la technologie et des innovations dans les domaines en perpétuelle évolution tels que le cloud, la data, l’Intelligence Artificielle, la connectivité, les logiciels, l’ingénierie digitale ou les plateformes.
Get The Future You Want* | www.capgemini.com/fr-fr
*Capgemini, le futur que vous voulez
Show more
Show less","{'ProgLanguage': ['Python', 'Java', 'Scala', 'R', 'Go'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': ['Hadoop', 'Spark', 'Databricks'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': ['AWS', 'Azure', 'Google Cloud Platform'], 'DevTools': ['Git'], 'Os': [], 'DBMS': ['Snowflake', 'Snowflake'], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Cloud'], 'FrSoftSkills': ['Collaboration', 'Organisation'], 'EnSoftSkils': ['Collaboration', 'Initiative']}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's', '3', '3', '3']}"
LinkedIn,Big Data engineer – Ingénieur des données massives (H/F),DGSE - Direction Générale de la Sécurité Extérieure,"Paris, Île-de-France, France",https://fr.linkedin.com/jobs/view/big-data-engineer-%E2%80%93-ing%C3%A9nieur-des-donn%C3%A9es-massives-h-f-at-dgse-direction-g%C3%A9n%C3%A9rale-de-la-s%C3%A9curit%C3%A9-ext%C3%A9rieure-3778473628?position=34&pageNum=0&refId=TDTc9UZJy78L%2BED7EV%2BMrg%3D%3D&trackingId=C68Ytx6N93azegb462EtDw%3D%3D&trk=public_jobs_jserp-result_search-card,"Introduction
La Direction Générale de la Sécurité Extérieure, DGSE, recrute Big Data engineer – Ingénieur des données massives (H/F).
Le poste est situé à Paris.
La nationalité française est obligatoire.
Domaine métier
Sciences et Technologies
Votre environnement de travail
Le flux de données traitées par la DGSE est équivalent à celui des GAFAM. Ces données sont au centre du travail des analystes de renseignement, qui doivent pouvoir compter sur des systèmes leur permettant de rechercher, croiser, traiter ces données, en temps réel ou en batch. Dans ce contexte, la DGSE cherche à renforcer ses équipes de traitement de la donnée massive.
Au sein d'un service centré sur le stockage, l'exploitation et la valorisation des données, nous vous proposons d'intégrer les équipes en charge des plateformes de stockage ou des traitements temps réel des données. Ces équipes pluridisciplinaires développent et maintiennent de bout en bout diverses plateformes reposant sur les technologies Kafka, Yarn, Hadoop, HBase ou encore Elasticsearch. Plus spécifiquement, l’équipe Stockage administre des entrepôts Big Data ainsi que des couches d’accès à leurs données. L’équipe Temps réel conçoit des algorithmes répondant à des besoins de temps de réaction très courts (levée d’alertes, enrichissement à la volée, réponse à des besoins opérationnels).
En nous rejoignant, vous découvrirez :
un environnement unique, qu'aucune autre structure ne peut vous proposer,
un métier proche du renseignement et de l'opérationnel,
une action sur l'intégralité de la chaîne, du développement au déploiement en production,
un minimum de 48 jours de congés par an,
une ambiance propice à l’épanouissement professionnel.
Vos missions
Les missions des équipes auxquelles vous serez amenés à contribuer seront déterminées en fonction de votre expérience et de vos appétences.
Vous serez en charge de plusieurs activités parmi les suivantes :
concevoir, implémenter et optimiser des algorithmes de traitement de données distribués (Scala, Spark, Java),
garantir le bon fonctionnement, la disponibilité et la performance des plateformes de traitement,
participer à l’évolution de l’architecture, en intégrant de nouveaux composants (frameworks, bibliothèques, …) permettant de mieux répondre aux besoins,
assurer une veille technologique constante pour rester au plus haut niveau et garantir une adéquation des clusters existants avec l’état de l’art du domaine,
contribuer à l'amélioration continue de l'équipe,
interagir avec l’équipe SRE/Devops pour améliorer la fiabilité des architectures, l’automatisation des déploiements et l'observabilité des systèmes mis en œuvre.
Votre profil
Vous êtes titulaire d’un diplôme en informatique, niveau master ou école d’ingénieur, ou pouvez démontrer une expérience équivalente.
Vous devez posséder les compétences et qualités suivantes :
bonnes connaissances fondamentales logicielles (structures de données, algorithmique, architecture),
maîtrise des langages Scala, Java ou python, vous n'avez pas peur de monter en compétences sur ceux que vous ne maîtrisez pas,
adepte de l'intégration continue, vous êtes familier de Gitlab CI, Github Actions ou Jenkins,
familier avec les bonnes pratiques de développement collaboratif (usage de git, pratique de relecture de code).
En bonus :
première expérience avec un framework de traitement en streaming (SparkStreaming, KStream, Storm, Flink, ...),
convaincu de l'importance de l'observabilité des systèmes qui regroupe métrologie, logging et tracing, vous avez déjà mis en place une stack de ce type (Prometheus, Telegraph, OpenTelemetry, Jaeger, ELK, …),
familier avec un outil de gestion de configuration (Ansible, Puppet, ...),
expérience sur les clusters Kafka, Hadoop, HBase ou Elasticsearch de plusieurs nœuds.
Les plus de l’offre
Contexte d’activités unique
Diversité des projets
Technologies à la pointe
Contact
Envoyez-nous votre candidature à l’adresse :
dgse-macandidature.cer.fct@intradef.gouv.fr
Plus d’information sur www.dgse.gouv.fr > Nous rejoindre.
RESTEZ DISCRET SUR VOTRE CANDIDATURE A LA DGSE
Show more
Show less","{'ProgLanguage': ['Python', 'Java', 'Scala', 'R', 'Go'], 'DataBase': ['HBase', 'Elasticsearch'], 'DataAnalytics': ['R'], 'BigData': ['Hadoop', 'Spark', 'Flink'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git', 'Jenkins'], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': ['HBase'], 'Automation': ['Ansible', 'Puppet'], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['DevOps', 'Big Data'], 'FrSoftSkills': [], 'EnSoftSkils': []}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's']}"
LinkedIn,Data Engineer (F/H),Aubay,"Île-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-f-h-at-aubay-3573871076?position=35&pageNum=0&refId=TDTc9UZJy78L%2BED7EV%2BMrg%3D%3D&trackingId=h3dJGitbn9AqvYtDTfW1hQ%3D%3D&trk=public_jobs_jserp-result_search-card,"Passionné par la Data, tu souhaites rejoindre une communauté d’experts dans le domaine afin de développer tes compétences en Data Engineering. Aubay renforce ses équipes Data et recherche des Data Engineers pour intégrer des dispositifs de projets pointus et variés.
Ton quotidien en tant que Data Engineer chez Aubay, :
Définition de la stratégie de stockage et mise en œuvre des technologie appropriées (base de données SQL, NoSQL, stockage distribué,…)
Ingestion des données (structurées, semi-structurées ou non-structurées) selon différentes fréquences : batch, micro-batch ou temps réel
Conception et mise en œuvre de pipelines de données afin de fournir des données prêtes à l’emploi aux consommateurs : uniformisation, mise en qualité, enrichissement, calcul d’indicateurs,…
Conception et développement d’API pour exposer les données auprès d’applications tierces
Appui aux Data Scientists pour industrialiser et optimiser les algorithmes de Machine Learning
Préparation et animation d’ateliers de travail avec des interlocuteurs variés : recueil/approfondissement des besoins métiers, avancement/restitution des travaux, transfert de compétences,…
Ton profil :
Tu dispose d’une formation niveau BAC+5 (Master 2 ou école d’ingénieur) spécialisée en informatique
Tu as déjà une première expérience significative (a minima 2 ans) en Data Engineering sur des technologies Big Data
Les technologies telles que Hadoop, Spark ou Kafka sont tes technologies de prédilection
La programmation n’a plus de secret pour toi et tu maitrise parfaitement un ou plusieurs langages de programmation suivants : Java, Scala et Python
Tu maîtrises les tenants et aboutissants de la philosophie DevOps et des outils orientés CI/CD
Tu es soucieux de la qualité et de la performance de tes développements et tu t'intéresse à l’innovation frugale
Tu es un expert technique dans ton domaine sans pour autant oublier l’importance d’une communication orale et écrite de qualité et adaptée à chacun de tes interlocuteurs
Tu travaille au quotidien en mode agile et tu en maitrise les fondements
Ce qui nous caractérise :
Des missions et projets dans le domaine du Data Engineering en nombre et dans des secteurs variés (Banque, Assurance, Telecom, Industrie,…) qui permettent à nos collaborateurs de monter en compétences et de devenir des experts Data reconnus
De l’apprentissage en continu avec des formations et des certifications sur les technologies Data d’aujourd’hui et de demain
Des experts Data mobilisables pour accompagner et soutenir techniquement les collaborateurs sur leurs projets
Des communautés de savoir-faire Data proposant de manière régulière aux collaborateurs d’Aubay du contenu et des évènements de partage (webinar, meetup/afterwork, BBL,…) sur les thématiques suivantes : Data Engineering, Data Viz, Data Science/IA, Data Platform & Architecture,…
Aubay encourage la diversité sous toutes ses formes et garantit l'égalité des chances à tous les candidats. Tous nos postes sont ouverts aux personnes en situation de handicap et nous proposons tous les aménagements nécessaires.
Ta carrière chez Aubay :
Tu auras la possibilité de développer et certifier tes compétences sur les dernières technologies Data avec un focus fort sur les plateformes Data Cloud telles qu’Azure Synapse Analytics, Google Cloud Platform, Snowflake et Databricks
Tu pourras rejoindre la BU d’excellence Data et évoluer au sein d’un environnement humain et professionnel de haut niveau. Tu profiteras d’un management sur-mesure pour t'accompagner dans ta trajectoire de carrière
Au sein de la BU d’excellence, de multiples perspectives s’offriront à toi :
Rôle de « Lead » : Vous pourrez gagner en responsabilité sur le plan technologique et devenir un référent auprès de nos clients et des collaborateurs de la communauté Data Engineering
Rôle de « Champion » : Vous représenterez Aubay auprès d’un ou plusieurs de nos partenaires éditeurs stratégiques et vous participerez activement à l’animation de la relation sur le plan technologique
Rôle de « Head » : Vous pourrez prendre la responsabilité du savoir-faire Data Engineering et de ses offres et en assurer le développement au sens large (développement business, recrutement, management de collaborateurs, définition de la stratégie et animation de la communauté au sein du groupe Aubay,…)
Besoin d’en savoir plus sur le processus de recrutement ?
Un échange macro au niveau RH avec Doriane
Un entretien technique avec Marius ou Peter, deux de nos référents techniques
Un échange managérial avec le Directeur de la BU Modern BI & Data
A savoir que l’ordre des étapes peut varier selon tes envies (ex : échange managérial avec l’échange technique)
Aubay encourage la diversité sous toutes ses formes et garantit l'égalité des chances à tous les candidats. Tous nos postes sont ouverts aux personnes en situation de handicap et nous proposons tous les aménagements nécessaires.
Show more
Show less","{'ProgLanguage': ['Python', 'Java', 'Scala', 'R', 'Go'], 'DataBase': ['SQL', 'NoSQL'], 'DataAnalytics': ['R'], 'BigData': ['Hadoop', 'Spark', 'Databricks'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': ['Azure', 'Google Cloud Platform'], 'DevTools': [], 'Os': [], 'DBMS': ['Snowflake', 'Snowflake'], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['DevOps', 'Big Data', 'Machine Learning', 'Cloud', 'CI/CD'], 'FrSoftSkills': ['Communication'], 'EnSoftSkils': ['Communication']}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': ['Bac+5'], 'Experience': ['a', 'n', 's', '2', '2', '2']}"
LinkedIn,Data engineer - F / H,United Robotics Group,"Paris, Île-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-f-h-at-united-robotics-group-3891680780?position=36&pageNum=0&refId=TDTc9UZJy78L%2BED7EV%2BMrg%3D%3D&trackingId=nFxE35kmFCphA0TLbxr9wg%3D%3D&trk=public_jobs_jserp-result_search-card,"Bienvenue chez
Aldebaran
, leader européen de la robotique
au sein du groupe
United Robotics Group
.
Nous concevons et industrialisons des robots innovants avec une vision sociétale ambitieuse pour façonner un monde plus humain. Depuis 2005, nous sommes à l'avant-garde de l'interaction homme-robot avec des produits emblématiques tels que NAO et Pepper.
Notre dernier-né,
Plato
,
incarne notre engagement envers la technologie de pointe et la sécurité,
fabriqué en France avec des composants européens.
Rejoignez nos équipes multiculturelles et dynamiques pour être au cœur de la révolution de la robotique.
Si vous êtes passionné.e par la robotique et l'intelligence artificielle, et que vous souhaitez contribuer à façonner l'avenir, nous vous offrons une expérience enrichissante et stimulante.
En tant que membre de notre équipe, vous bénéficierez d'une culture d'entreprise axée sur le sens de ce que nous faisons et valorisant la responsabilité sociale et environnementale.
Chez Aldebaran, nous valorisons l'innovation, la diversité et l'égalité et encourageons chacun.e à être ouvert.e, authentique, courageux.se, responsable et engagé.e.
Finalité du poste
Au sein de l'équipe Cloud-Online Services, le Data engineer intégrera l'équipe Data, responsable du développement des produits destinés à la collecte, aux process et à l'exploitation des données de nos robots.
Il aura pour rôle de définir et d'implémenter des services data, sur une infrastructure Cloud AWS, supportant des services en ligne qui gèrent les robots du groupe.
Missions principales
Le Data engineer aura pour responsabilités de :
évaluer les choix d'architecture et de solutions techniques lors de la mise en place de PoC,
concevoir et développer des services Data en respectant la spécification fonctionnelle et la méthodologie agile,
agréger et stocker de grandes quantités de données,
mettre en place des solutions de data processing,
intégrer/développer des outils de visualisation de données et analyser les KPI,
développer, tester, sélectionner et mettre en production des algorithmes qui permettent de répondre aux besoins,
réaliser des analyses de données,
mettre en place des tests de charge et fonctionnels pour les solutions Data,
investiguer et corriger les bugs remontés par les utilisateurs,
contribuer à la mise en place de l'infrastructure et outil de déploiement (CI/CD)
Rejoignez-nous pour faire partie d'une aventure passionnante où Pepper, NAO, Plato et leurs futurs successeurs attendent votre contribution pour repousser les limites de la technologie robotique !
Requirements
Pour la bonne exécution des missions confiées, vous témoignez d'au moins 6 ans d'expérience en tant que développeur sur des projets data en Cloud en Python et Spark et avec comme Cloud provider AWS.
Compétences demandées :
Bonne compréhension des technologies d'infrastructure et de déploiement,
Compétences techniques sur les services AWS : IOT core , Glue, lambda, Kinesis, S3, RDS,
Bonne compréhension technique dans la mise en place et l'automatisation de tests de charge et fonctionnels,
Bonne maitrise d'outils BI ou de dashboarding (POWER BI, TABLEAU, QUICKSIGHT)
Bonne connaissance et une expérience pratique de Scrum\Scrumban et des méthodes agiles,
Une certification AWS sera appréciée,
Un niveau de français et d'anglais courant est indispensable,
Des expériences dans des environnements fortement internationaux sont un plus
Benefits
Nos principaux avantages :
Une culture du bien-être en entreprise qui a fait ses preuves (budget célébration et moments de convivialité par équipes et directions, restauration collective de qualité, environnement de travail agréable)
Un engagement fort en matière de responsabilité sociale et environnementale (promotion de l'égalité professionnelle, performance de notre plan diversité et inclusion, référent handicap, fresque du numérique)
Une culture du télétravail encadrée de manière appropriée !
Tous nos postes sont ouverts aux personnes en situation de handicap.
Show more
Show less","{'ProgLanguage': ['Python', 'R', 'Go'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': ['Spark'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': ['Tableau', 'Power BI'], 'Statistics': [], 'CloudComputing': ['AWS'], 'DevTools': [], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Cloud', 'CI/CD'], 'FrSoftSkills': [], 'EnSoftSkils': []}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's', '6', '6', '6']}"
LinkedIn,Data Engineer H/F,Chantelle,"Cachan, Île-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-h-f-at-chantelle-3909775663?position=37&pageNum=0&refId=TDTc9UZJy78L%2BED7EV%2BMrg%3D%3D&trackingId=B7M58zT%2F%2FcerBjMK2k9%2F7g%3D%3D&trk=public_jobs_jserp-result_search-card,"La Direction des Systèmes d'Information et du Digital du groupe Chantelle recherche son/sa futur.e Data Engineer H/F, pour le lancement du grand chantier de rénovation de l'architecture Data : la bascule de l'intégralité de son Data Warehouse vers Google Big Query.
Nous souhaitons recruter un Data Engineer H/F confirmé.e, chargé.e de contribuer à la définition de la feuille de route de la Chantelle Data Plaform. En tant que Data Engineer vous travaillerez au sein de l'équipe Data Intégration en charge de la Chantelle Data Platform.
Vos Missions :
- Mettre en œuvre une infrastructure autour de Google Cloud Platform permettant de collecter (airbyte, API, ...) , transformer (dataform, Bigquery ...), exposer (dataviz, API, applications, ...) et historiser les données générées par l'entreprise.
- Travailler en étroite proximité avec les responsables des différents domaines fonctionnels (Référentiels, Supply Chain, Manufacturing, B2B, Retail & e-commerce, Finance, ...), avec notre équipe de Data Analysts ainsi qu'avec l'équipe technique en charge des infrastructures transverses
- Être force de proposition sur tous les sujets d'architecture et de modélisation (choix de mise en place de pipeline temps réels ou au contraire de flux de données en mode batch, ou bien encore stockage sur Big Query / Big Table en fonction des cas d'usage).
- Définir les éléments structurants, en justifiant vos choix, et les mettre en œuvre.
- Rationaliser et moderniser notre architecture d'intégration inter-applicative; se projeter sur la création d'un modèle de données de type Datamesh.
- Faire la refonte de la BI de nombreux use cases tels que le pilotage de nos stocks, personnalisation de nos sites e-commerce en temps réel en fonction de nos profils client, etc…
Stack technique : Google Cloud Platform, BigQuery, DataForm, DataFlow, PubSub, Airbyte, Github ...
Bonne maîtrise des langages Python et SQL
Pourquoi travailler chez Chantelle ?
Une flexibilité dans votre lieu de travail, selon la politique de télétravail de l'entreprise.
11 jours de RTT/an ainsi qu'un 13ème mois.
Une culture d'entreprise familiale basée sur des valeurs de respect, de créativité, de durabilité et de transparence
Une aventure dans laquelle vous pourrez vous épanouir, apprendre et entreprendre, avec une grande variété de missions et beaucoup d'autonomie
Des équipes ressources humaines et des managers à votre écoute pour vous accompagner dans votre parcours professionnel
Des réductions sur nos produits et des ventes au personnel
Des avantages dans votre qualité de vie au travail : une conciergerie complète proposant un large panel de services, des activités en interne, un CSE.
Vous souhaitez rejoindre un Groupe familial, innovant, engagé et leader dans son secteur en France comme à l'international et vous souhaitez apporter votre expertise et authenticité pour guider votre équipe vers le succès : postulez et rejoignez le Groupe Chantelle !
Show more
Show less","{'ProgLanguage': ['Python', 'R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': ['Google Cloud Platform'], 'DevTools': ['Git'], 'Os': [], 'DBMS': ['BigQuery', 'Big Query'], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Cloud'], 'FrSoftSkills': ['Créativité', 'Flexibilité'], 'EnSoftSkils': []}","{'JobDetail': ['Confirmé'], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's']}"
LinkedIn,Data Engineer / Developpeur Talend,Siderlog Conseil,"Niort, Nouvelle-Aquitaine, France",https://fr.linkedin.com/jobs/view/data-engineer-developpeur-talend-at-siderlog-conseil-3861714639?position=38&pageNum=0&refId=TDTc9UZJy78L%2BED7EV%2BMrg%3D%3D&trackingId=OI1YfXE1D5T6TJRZFOucYA%3D%3D&trk=public_jobs_jserp-result_search-card,"Siderlog est un cabinet de conseil spécialisé implanté à Niort depuis 2004 qui accompagne les directions métiers et SI sur des projets de:
- Business et Data Analyse
- Management de projets
- Conduite du changement
Pour soutenir notre croissance, nous prévoyons à Niort le recrutement de 20 consultants d'ici 2025.
Nos consultants bénéficient d'un modèle qui favorise l'épanouissement professionnel et le bien être:
🍃Un processus d'intégration spécifique et un suivi régulier
🍃Une écoute active des attentes, notamment en terme de formations, certifications
🍃Des déjeuners et évènements mensuels
🍃Un management et un accompagnement de proximité
🍃Un package salarial attractif
🍃La possibilité de contribuer aux projets d'entreprise ( RSE, communautés métiers, pôle conseil et expertise)
🍃Entreprise labellisée Happy At Work, charte Télétravail...
🍃De nombreux autres avantages que nous vous invitons à venir découvrir
Siderlog recherche pour renforcer son équipe, à Niort un(e) consultant(e) Data Engineer / Developpeur Talend.
Dans ce cadre vous devrez :
✔️Concevoir et développer des traitements/job de données complexes à l'aide de Talend pour l'ingestion, le nettoyage, la transformation et la distribution des données.
✔️Collaborer étroitement avec les équipes métier pour comprendre les besoins en matière de données et concevoir des solutions adaptées.
✔️Mettre en œuvre des bonnes pratiques de développement ETL, y compris la documentation, les tests unitaires et l'intégration continue.
✔️Assurer la surveillance et la maintenance des traitements/job de données en production, en résolvant les incidents et en effectuant des mises à jour si nécessaire.
📋 Qualifications et compétences :
👉Expérience avérée dans le développement de solutions de gestion et d'intégration de données, sur Talend.
👉Maîtrise des langages de requête SQL pour l'extraction et la manipulation des données.
👉Connaissance approfondie des bases de données relationnelles et des entrepôts de données.
👉Compétences en programmation avec Java, Python ou d'autres langages similaires.
👉Capacité à travailler de manière autonome tout en collaborant efficacement avec les membres de l'équipe.
👉Excellentes compétences en communication écrite et verbale.
👉Maitrise de l'outil ETL Talend.
👉Expérience avec d'autres outils d'intégration de données tels que Informatica, BODS, Altéryx.
👉Certification Talend serait un plus.
👉Expérience dans le domaine de l'assurance souhaitée
Cette offre vous intéresse ! Postulez !
🏆🙏🚀🎉 !
Show more
Show less","{'ProgLanguage': ['Python', 'Java', 'R'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': [], 'FrSoftSkills': ['Communication'], 'EnSoftSkils': ['Communication']}","{'JobDetail': [], 'TypeContract': [], 'Salary': ['Package'], 'Level': [], 'Experience': ['a', 'n', 's']}"
LinkedIn,DATA Engineer (H/F),Boulanger,"Lesquin, Hauts-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-h-f-at-boulanger-3854554057?position=39&pageNum=0&refId=TDTc9UZJy78L%2BED7EV%2BMrg%3D%3D&trackingId=rzwJ7eGfBAYHY19wsvY09w%3D%3D&trk=public_jobs_jserp-result_search-card,"Au sein de la direction informatique, le pôle DATA a pour missions de maximiser la mise en valeur des données de BOULANGER ,ELECTRO-DEPOT et KREFEL/HIFI afin d’aider nos décideurs à agir sur les leviers de leur performance par des processus décisionnels efficients.
Au sein de ce pôle, tu prendras en charge un large domaine métier qu'il te faudra maitriser de bout en bout : de la données brutes, sa transformation jusqu'à son exposition dans les reporting. Cela afin d'en assurer le bon fonctionnement, les évolutions constantes et sa pérennité
Tes tâches principales portent sur :
Le pilotage et la mise en œuvre de projets DATA.
La collecte, le stockage et l’exploitation fluides des données par le développement de solutions
Missions
Maitriser les règles fonctionnelles et les KPI de ton domaine afin de challenger les métiers dans les évolutions et les nouveaux projets
Accompagner des équipes métiers dans leurs travaux d’identification et expression des besoins sur la data
Participer aux ateliers de conception et développement des applications data
Modéliser la solution à mettre en œuvre
Concevoir et mettre (ou faire mettre) en œuvre des flux les pipelines d’intégration (en mode batch ou fil de l'eau) de données structurées/semi-structurées
Transformer les données : consolider, enrichir et optimiser les données, qui seront exploitées par le métier
Créer, faire évoluer et optimiser les restitutions
Suivre et animer les développeurs (ETL, restitution, self-BI internes ou externes)
Gérer le RUN
Maitrise le SQL et la base de données (Oracle, Snowflake)
Maîtrise d’outils de restitution (tel que Business Object (BO), PowerBI…)
Capacité relationnelle, rigueur et dynamisme
Maîtrise un ou plusieurs outils de préparation et traitement de la donnée (DataStage, Stambia, ...)
Capacité à s’adapter à tout type d’interlocuteurs (technique, métiers, Direction)
Show more
Show less","{'ProgLanguage': ['R'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': ['PowerBI'], 'Statistics': [], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'DBMS': ['Oracle', 'Snowflake', 'Snowflake'], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': [], 'FrSoftSkills': [], 'EnSoftSkils': []}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's']}"
LinkedIn,Ingénieur Data Talend (F/H),Thales,"Vélizy-Villacoublay, Île-de-France, France",https://fr.linkedin.com/jobs/view/ing%C3%A9nieur-data-talend-f-h-at-thales-3890948785?position=40&pageNum=0&refId=TDTc9UZJy78L%2BED7EV%2BMrg%3D%3D&trackingId=joJb400uS2PS7%2FhJB7d5wA%3D%3D&trk=public_jobs_jserp-result_search-card,"QUI SOMMES-NOUS ?
Thales est un leader mondial des hautes technologies comptant plus de 81 000 collaborateurs présents sur tous les continents. Le Groupe investit dans les innovations du numérique et de la « deep tech » – big data, intelligence artificielle, connectivité, cybersécurité et quantique – pour construire un avenir de confiance, essentiel au développement de nos sociétés, en plaçant l’humain au cœur des décisions.
Thales propose des solutions, services et produits qui aident ses clients – entreprises, organisations, Etats – dans cinq grands marchés vitaux pour le fonctionnement de nos sociétés : identité et sécurité numériques, défense, aéronautique, espace, et transport.
QUI ETES-VOUS ?
Diplômé d’un Bac+5 en école d’ingénieur ou équivalent universitaire avec une spécialisation en informatique, vous avez au moins 3 ans d'expérience dans les technologies Big Data.
CE QUE NOUS POUVONS ACCOMPLIR ENSEMBLE :
En tant que Data Engineer, vous jouerez un rôle clé dans la conception, le développement et la maintenance de notre infrastructure de données, ainsi que dans la transformation et la gestion des flux de données.
VOS MISSIONS :
• Concevoir, développer et déployer des solutions Big Data en utilisant les technologies Talend.
• Mettre en place des pipelines de données performants pour l'ingestion, le traitement et le stockage des données massives.
• Collaborer étroitement avec les équipes métier pour comprendre leurs besoins en matière d'analyse de données et proposer des solutions adaptées.
• Optimiser les performances des clusters Hadoop pour garantir une exploitation efficace des données.
• Assurer la qualité et la fiabilité des données traitées, en mettant en place des processus de validation et de nettoyage.
• Identifier et résoudre les problèmes liés à l'infrastructure Big Data et proposer des améliorations.
• Travailler en étroite collaboration avec les Data Scientists et les Data Analysts pour fournir des insights pertinents à partir des données.
Innovation, passion, ambition : rejoignez Thales et créez le monde de demain, dès aujourd’hui.
Show more
Show less","{'ProgLanguage': ['R'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': ['Hadoop'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Big Data'], 'FrSoftSkills': ['Collaboration', 'Organisation'], 'EnSoftSkils': ['Collaboration']}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': ['Bac+5'], 'Experience': ['a', 'n', 's', '3', '3', '3']}"
LinkedIn,Data Engineer (Snowflake),MindPal,"Toulouse, Occitanie, France",https://fr.linkedin.com/jobs/view/data-engineer-snowflake-at-mindpal-3896992742?position=41&pageNum=0&refId=TDTc9UZJy78L%2BED7EV%2BMrg%3D%3D&trackingId=tSBp1Wb79voGnfrm%2F3nyZg%3D%3D&trk=public_jobs_jserp-result_search-card,"We are looking for experienced
Data Engineers
with knowledge of
Snowflake
platform.
Responsibilities
Creating and managing data in the Snowflake environment
Designing and implementing ETL (Extract, Transform, Load) solutions for transferring data between various sources and platforms
Optimizing the performance of Snowflake databases, including designing and implementing data structures and using indexes appropriately
Automating data processing workflows using tools such as Airflow or other workflow management tools
Deploying and configuring tools to monitor and report on the performance of the Snowflake system
Requirements
Minimum 1 year of experience as a Data Engineer
Ability to use Snowflake
Very good knowledge of SQL and programming in Python
Ability to work with databases, including the Snowflake platform
Knowledge of ETL tools and data integration
Ability to work in a team and good communication skills
Fluent English in speaking and writing
We Offer
B2B contract type
Full-time job
Remote and flexible working hours
Show more
Show less","{'ProgLanguage': ['Python', 'R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'DBMS': ['Snowflake', 'Snowflake'], 'SoftBigDataProcessing': [], 'Automation': ['Airflow'], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': [], 'FrSoftSkills': ['Communication'], 'EnSoftSkils': ['Communication']}","{'JobDetail': ['Remote', 'Full'], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's']}"
LinkedIn,Data Engineer Snowflake,Key Performance Consulting (KPC),"Bordeaux, Nouvelle-Aquitaine, France",https://fr.linkedin.com/jobs/view/data-engineer-snowflake-at-key-performance-consulting-kpc-3915036342?position=42&pageNum=0&refId=TDTc9UZJy78L%2BED7EV%2BMrg%3D%3D&trackingId=87iaB3Zrtg5V1NO0NwSbCQ%3D%3D&trk=public_jobs_jserp-result_search-card,"Rejoignez la plus grosse équipe SNOWFLAKE certifiée en France !
KPC est Partner Elite Snowflake, le plus haut niveau de certification.
Vous souhaitez intégrer une ESN à taille humaine vous permettant de travailler sur des projets challengeant et de monter en compétences ? Ce poste est pour vous !
VOS MISSIONS :
Elaboration d'architectures optimisées dans un contexte Snowflake,
Conception et mise en place des ingestions de données (temps réel, Kafka, Snowpipe),
Modélisation de données (Star Schéma, DataVault, DataMesh, virtualisation) - DataOps
Mise en oeuvre des transformations et de la valorisation des données (SQL, Python, Java, Scala) - DataOps
Optimisation des performances et des coûts d utilisation Snowflake (FinOps)
VOTRE PROFIL :
Vous êtes issu d'une école d'ingénieur ou d'un Master 2
Vous avez une première expérience sur du Snowflake ou au moins 2 ans de SQL
DEVENEZ NOTRE PROCHAIN(E) Data Engineer Snowflake !
Vous recherchez une entreprise où vous pouvez télétravailler tout en gardant un lien de proximité, qui laisse de l’autonomie, et où il fait bon travailler, alors nous vous souhaitons la bienvenue chez KPC.
Vous avez une expérience d'au moins 2 ans en développement SQL ou une première expérience sur Snowflake ?
Vous souhaitez travailler au sein d’une équipe d'experts technico-fonctionnels ?
Rejoignez l’entreprise KPC ! Une entreprise à taille humaine avec un mode de management dynamique et de proximité.
Notre cœur de métier de KPC : la business intelligence. Nous sommes intégrateurs de solutions GOLD PARTENAIRE de SAP, Qlik, Microsoft BI, Tableau, Snowflake, Semarchy etc.
Notre gold partenariat nous permet d'offrir des formations certifiantes pour nos collaborateurs, d'avoir des liens de proximités avec les éditeurs et de revendre leurs solutions.
Rejoignez la plus grosse équipe SNOWFLAKE certifiée en France ! KPC est Partner Elite Snowflake, le plus haut niveau de certification.
Vous souhaitez intégrer une ESN à taille humaine vous permettant de travailler sur des projets challengeant et de monter en compétences ? Ce poste est pour vous !
VOS MISSIONS :
Elaboration d'architectures optimisées dans un contexte Snowflake,
Conception et mise en place des ingestions de données (temps réel, Kafka, Snowpipe),
Modélisation de données (Star Schéma, DataVault, DataMesh, virtualisation) - DataOps
Mise en oeuvre des transformations et de la valorisation des données (SQL, Python, Java, Scala) - DataOps
Optimisation des performances et des coûts d utilisation Snowflake (FinOps)
VOTRE PROFIL :
Vous êtes issu d'une école d'ingénieur ou d'un Master 2
Vous avez une première expérience sur du Snowflake ou deux/trois ans de SQL
PROCESSUS DE RECRUTEMENT :
Vous pensez être celui, celle qu’il nous faut et vous vous êtes reconnu dans notre organisation, alors venez vivre votre première expérience KPC en postulant à cette offre :
Vous serez appelé(e) par Ludivine (chargée de recrutement) pour une première prise de contact
Nous pourrons poursuivre les échanges avec Olivier (Directeur Sud-Ouest) pour l’approche projet et technique
Pour clore ce processus de recrutement, nous vous inviterons à rencontrer Gabriel (Directeur Sud-Ouest)
Et tout ça dans un temps record 😊 : 15 jours en moyenne pour allier réactivité et efficacité.
Nous garantissons l’égalité des chances pour toutes et tous car pour nous la diversité est une force !
KPC EN QUELQUES MOTS ?
Nous sommes une entreprise spécialisée dans la Data.
Depuis treize ans, nous accompagnons nos clients à valoriser leurs données de manière innovante et efficace pour développer leur performance, améliorer leurs processus et expériences utilisateurs. Nous intervenons en mode projet (50% régie, 50% forfait)
Nous avons développé 3 grandes activités :
ANALYTICS (BI, Data Science/Big Data, Data Gouvernance, EPM, Digital)
ERP SAP
CRM
Pour cela, nous travaillons en partenariat avec les plus grands éditeurs du marché tels que : SAP, QLIK, DATAGALAXY, SALESFORCES, SNOWFLAKE, TALEND, MICROSOFT, ONESTREAM, IMAGINO.
En forte croissance, nous cherchons de nouveaux talents pour participer à cette aventure humaine au service des entreprises de demain.
KPC EN QUELQUES CHIFFRES :
300 collaborateurs
20 % Croissance annuelle
8 agences en France (Aix-en-Provence, Nice, Montpellier, Lyon, Toulouse, Bordeaux, Paris et Nantes)
Des grands groupes en tant que clients : CMA CGM, PERNOD RICARD, AIRBUS, CDISCOUNT, CULTURA, GIFI, POLE EMPLOI, L'OREAL ...
VOS AVANTAGES :
Organisation du travail 100% flexible avec du télétravail, participation aux frais téléphonique et internet et un forfait équipement fourniture
Un parcours d'intégration
Des formations et des certifications avec les éditeurs sur les technos de pointe
IK voiture, vélo
Carte resto, mutuelle, prévoyance santé
Prime « Vacances »
POURQUOI NOUS REJOINDRE ?
Une entreprise à taille humaine
Un mode de management dynamique, agile et de proximité
Une vie d'agence animée, engagée et conviviale dans des locaux sympas
Une attention particulière à un équilibre de vie pro / perso
Une entreprise qui encourage les initiatives et l'autonomie
Une entreprise certifiée Ecovadis Silver pour des actions concrètes en termes de RSE
Un cadre de travail agréable prenant en compte les enjeux sociétaux et environnementaux
Vous êtes ou voulez être consultant(e), chef de projet, expert(e) technique, manager ? Notre promesse : vous accompagner de façon personnalisée et continue quel que soit votre projet à court, moyen et long terme.
Show more
Show less","{'ProgLanguage': ['Python', 'Java', 'Scala', 'R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': ['Tableau'], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git'], 'Os': [], 'DBMS': ['Snowflake', 'Snowflake'], 'SoftBigDataProcessing': [], 'Automation': ['Chef'], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Big Data'], 'FrSoftSkills': ['Organisation'], 'EnSoftSkils': ['Initiative']}","{'JobDetail': [], 'TypeContract': ['CDI'], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's', '2', '2', '2']}"
LinkedIn,Data Engineer (H/F),iPepperGroup,"Valbonne, Provence-Alpes-Côte d'Azur, France",https://fr.linkedin.com/jobs/view/data-engineer-h-f-at-ipeppergroup-3894091360?position=43&pageNum=0&refId=TDTc9UZJy78L%2BED7EV%2BMrg%3D%3D&trackingId=tEwLeqmjPSQfhAClCp4pfA%3D%3D&trk=public_jobs_jserp-result_search-card,"iPepper recrute pour l'un de ses clients une PME éditeur de logiciel dans le domaine du voyage, un
Data Engineer (H/F)
passionné(e) et expérimenté(e) pour rejoindre une équipe dynamique.
En tant qu'Ingénieur(e) Data, vous serez en charge d'extraire et de transformer des données, de construire et d'optimiser des pipelines de données, ainsi que de concevoir des visualisations de données intuitives et informatives.
Responsabilités :
Concevoir, construire et maintenir des pipelines de données évolutifs et efficaces pour transférer des données entre des bases de données SQL et NoSQL.
Développer et mettre en œuvre des processus ETL pour extraire, transformer et charger des données à partir de différentes sources dans notre entrepôt de données.
Collaborer avec des équipes pluridisciplinaires pour comprendre les besoins en données et garantir la fourniture réussie de solutions de données.
Optimiser et ajuster les pipelines de données existants pour la performance et la fiabilité.
Concevoir et développer des visualisations de données et des tableaux de bord pour fournir des insights exploitables aux parties prenantes.
Surveiller et résoudre les problèmes de pipelines de données, en veillant à la qualité et à l'intégrité des données.
Profil recherché :
Diplôme universitaire en informatique, en ingénierie ou dans un domaine connexe.
Expérience avérée en tant que Data Engineer ou dans un rôle similaire, avec un accent particulier sur la construction de pipelines de données et de processus ETL.
Compréhension solide des bases de données
SQL
et
NoSQL
, y compris la modélisation des données et la conception de schémas.
Maîtrise des langages de programmation tels que
Python, Java ou Scala.
Expérience avec des outils de visualisation de données tels que
Tableau, Power BI.
Solides compétences en analyse et en résolution de problèmes, avec la capacité de traduire des données complexes en insights exploitables.
Excellentes compétences en communication et en collaboration, avec la capacité de travailler efficacement dans un environnement d'équipe pluridisciplinaire.
Show more
Show less","{'ProgLanguage': ['Python', 'Java', 'Scala', 'R'], 'DataBase': ['SQL', 'NoSQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': ['Tableau', 'Power BI'], 'Statistics': [], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': [], 'FrSoftSkills': ['Communication', 'Résolution de problèmes', 'Collaboration'], 'EnSoftSkils': ['Communication', 'Collaboration']}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's']}"
LinkedIn,Ingénieur Data (H/F) | POEI,DataScientest.com,"Puteaux, Île-de-France, France",https://fr.linkedin.com/jobs/view/ing%C3%A9nieur-data-h-f-poei-at-datascientest-com-3909360157?position=44&pageNum=0&refId=TDTc9UZJy78L%2BED7EV%2BMrg%3D%3D&trackingId=FHcjn5vGWt2bAC0sneS4jg%3D%3D&trk=public_jobs_jserp-result_search-card,"Ingénieur Data (H/F) | POEI
Puteaux
CDI
Postuler
Retour
Datascientest Is Hiring!
Ingénieur Data (H/F) | POEI
À propos
DATASCIENTEST ? LA REFERENCE EN DATASCIENCE
Créée en 2017, DataScientest révolutionne la formation en Data Science et devient leader en France !
Notre école compte plus de 6 000 apprenants à son actif, et a séduit 50 entreprises dont une trentaine du CAC40 et des leaders internationaux (BCG, Allianz, Christian Dior, Axa…),
Nous formons aussi les demandeurs d'emploi en leur offrant un CDI au sein de nos entreprises partenaires
Présents en Espagne et en Allemagne, notre pédagogie repose sur une structure hybride :
Qui allie l’adaptabilité du distanciel avec une plateforme entièrement conçue par nous-même et
La motivation du présentiel avec des séances de coaching animées par nos enseignants data scientists !
Descriptif du poste
En Tant Qu'Ingénieur Data, Vous Serez Chargé(e) De Proposer Les Meilleures Solutions à L'entreprise En Leur Permettant D'optimiser Leur Activité, à Travers Quelques Missions Principales
Développer des solutions pour traiter des volumes importants de données,
Concevoir, collecter et fabriquer des données brutes,
Créer des outils et algorithmes pour le traitement des données,
Préparer des données pour le Data Analyst,
Sécuriser des Pipelines données pour les Data Analysts et Data Scientists,
Organiser l'architecture du cloud,
Contribuer à l'effort d'animation technique, de veille technologique et d'innovation
Profil recherché
Et si nous parlions de vous ?
Issu(e) d’une filière scientifique bac+5 ou d’un diplôme d’ingénieur,
Vous disposez idéalement d’une expérience significative en développement informatique, en architecture réseaux ou dans la Data,
Vous maîtrisez un langage objet type Java, Python, C++, etc.
Vous êtes demandeur d'emploi
N'attendez plus, envoyez nous votre CV, nos équipes se feront un plaisir de vous contacter et de vous accompagner pour préparer vos entretiens avec notre entreprise partenaire.
Informations complémentaires
Type de contrat : CDI
Lieu : Puteaux
Niveau d'études : Bac +5 / Master
Expérience : > 1 an
Télétravail ponctuel autorisé
Salaire : entre 38000€ et 48000€ / an
Vous êtes intéressé par cette offre ?
Postuler
Show more
Show less","{'ProgLanguage': ['Python', 'Java', 'C++', 'R', 'Go'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Cloud'], 'FrSoftSkills': ['Adaptabilité'], 'EnSoftSkils': []}","{'JobDetail': ['Hybride'], 'TypeContract': ['CDI'], 'Salary': ['38000'], 'Level': ['Bac+5'], 'Experience': ['a', 'n', 's']}"
LinkedIn,Data Engineer DevOps H/F,Inetum,"Courbevoie, Île-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-devops-h-f-at-inetum-3843956952?position=45&pageNum=0&refId=TDTc9UZJy78L%2BED7EV%2BMrg%3D%3D&trackingId=LN1KQRS61sKKEPaDT%2FUBBA%3D%3D&trk=public_jobs_jserp-result_search-card,"Détail de l'offre
Informations générales
Entité de rattachement
Nous sommes une ESN agile, un groupe international certifié Top Employer Europe 2024.
A l'ère de la post-transformation digitale, nous mettons tout en œuvre pour que chacun de nos 28 000 athlètes du digital puisse se renouveler perpétuellement, en vivant positivement son propre flow digital.
Chacun de nos talents peut ainsi façonner son parcours de carrière selon ses appétences, entreprendre de manière pragmatique avec ses clients pour un monde à impact positif, innover localement dans 27 pays et harmoniser son investissement professionnel et son bien-être personnel.
Rejoignez Inetum. Live your positive digital flow.
Tous nos postes sont ouverts aux personnes en situation de handicap.
Description du poste
Métier
Conseil et Intégration - Business Consulting
Intitulé du poste
Data Engineer DevOps H/F
Contrat
CDI
Description De La Mission
Qui sommes-nous ?
Nous sommes une ESN agile et un groupe international. A l'ère de la post-transformation digitale, nous mettons tout en œuvre pour que chacun de nos 27 000 collaborateurs puisse se renouveler perpétuellement, en vivant positivement son propre flow digital. Chacun d'entre eux peut ainsi façonner son parcours de carrière selon ses appétences, entreprendre de manière pragmatique avec ses clients pour un monde plus positif, innover localement dans 26 pays et harmoniser son investissement professionnel et son bien-être personnel.
Rejoignez
Capital Market, entité Inetum en Finance de Marché
. Nous accompagnons les acteurs majeurs du secteur de la finance en France et à l’International.
Cultivant la double compétence technique et fonctionnelle, nous intervenons sur des projets innovants à haute valeur ajoutée.
Quelles sont nos valeurs ?
🏆 Excellence Notre culture de l’excellence naît de notre audace.
🤝 Engagement S’associer et grandir ensemble !
🛰 Innovation Nos FabLab au service de la transformation digitale de nos clients.
Missions proposées
Pour accompagner notre forte croissance, nous recherchons des
Data Engineer DevOps
pour le compte d’un acteur majeur de la finance de marché en Europe et dans le monde. Dans ce contexte international et exigeant, vous travaillez sur la conception de solutions Big Data afin de répondre aux besoins des opérationnels métiers.
Pour mener à bien ce projet, vous aurez pour responsabilités de
Comprendre les enjeux des équipes Data et les accompagner. Faire le lien entre les environnements (datalake, datawarehouse et environnement de déploiement du modèle) grâce à des pipelines sophistiqués
Être référent et garant des bonnes pratiques pour le développement des langages utilisés par l'équipe. Accompagner les Data Scientists dans l'optimisation de leurs algorithmes
Assurer la viabilité des solutions de datamining et de machine learning de l'équipe Data et les mettre en production.Construire et optimiser des pipelines de données complexes (ETL et ELT)
Coordonner le développement et les opérations grâce à l’automatisation des flux de travail, la création de services Web prédictifs.
Déployez ces modèles en utilisant les dernières techniques et pratiques (API REST, Docker, Tensorflow Serving, etc.)
Analyser et résoudre les anomalies liées aux performances et à l’évolutivité des solutions Cloud BI et Big Data
Profil
Profil souhaité
De formation Ingénieur Grande Ecole ou équivalent, vous possédez une première expérience réussite de trois ans minimum sur un poste équivalent idéalement en banque d’investissement ou asset management.
Vous êtes familier avec l’environnement Big Data (data grids, compute grids, REST based architectures, SGBDR, No-SQL Databases, GPUs)
Vous avez déjà travaillé avec la méthodologie Agile
Une certaine aisance technique est également requise (Jenkins, Docker, Ansible, Git, Scala, Kubernetes, Python/Java, Maven)
Une double compétence Cloud (AWS, Google Cloud, Azure) serait un véritable plus
Evoluant dans un contexte international, la maîtrise de l'Anglais est nécessaire.
L’aisance relationnelle, de l’autonomie, la gestion des priorités, des capacités d’analyse et de synthèse, … le savoir-être est une composante importante dans notre processus de recrutement.
Tous nos postes sont ouverts aux personnes en situation de handicap.
Et pourquoi Inetum Capital Market ?
😄 Des missions intéressantes
🤩 Des perspectives d'évolutions professionnelles et financières
😎 Les avantages d'un grand groupe international
😉 Un suivi régulier
✈️ Une aide à la mobilité géographique que vous soyez localisé en France ou à l'étranger
👨‍🎓 Des formations certifiantes
🥳 Des moments de FUN !
Localisation du poste
Localisation du poste
France, Ile-de-France, 75 Paris
Ville
Courbevoie
Critères candidat
Niveau d'études min. requis
Bac+5
Niveau d'expérience min. requis
Plus de 2 ans
Show more
Show less","{'ProgLanguage': ['Python', 'Java', 'Scala', 'R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': ['TensorFlow'], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': ['AWS', 'Azure'], 'DevTools': ['Git', 'Docker', 'Jenkins'], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': ['Ansible', 'Kubernetes'], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': ['Docker', 'Kubernetes'], 'Collaboration': [], 'Other': ['DevOps', 'Big Data', 'Machine Learning', 'Cloud'], 'FrSoftSkills': [], 'EnSoftSkils': []}","{'JobDetail': [], 'TypeContract': ['CDI'], 'Salary': [], 'Level': ['Bac+5'], 'Experience': ['a', 'n', 's', '2', '2', '2']}"
LinkedIn,Développeur Big Data Junior H/F,Inetum,"St.-Ouen, Île-de-France, France",https://fr.linkedin.com/jobs/view/d%C3%A9veloppeur-big-data-junior-h-f-at-inetum-3887272015?position=46&pageNum=0&refId=TDTc9UZJy78L%2BED7EV%2BMrg%3D%3D&trackingId=GY4l3RNWLP3B0lXdrBu2dw%3D%3D&trk=public_jobs_jserp-result_search-card,"Détail de l'offre
Informations générales
Entité de rattachement
Inetum est un leader européen des services numériques. Pour les entreprises, les acteurs publics et la société dans son ensemble, les 28 000 consultants et spécialistes du groupe visent chaque jour l'impact digital des solutions qui contribuent à la performance, à l'innovation et au bien commun.
Présent dans 19 pays au plus près des territoires, et avec ses grands partenaires éditeurs de logiciels, Inetum répond aux enjeux de la transformation digitale avec proximité et flexibilité.
Porté par son ambition de croissance et d'industrialisation, Inetum a généré en 2023 un chiffre d'affaires de 2,5 milliards d'€.
Pour répondre à un marché en croissance continue depuis plus de 30ans, Inetum a fait le choix délibéré de se recentrer sur 4 métiers afin de gagner en puissance et proposer des solutions sur mesure, adaptées aux besoins spécifiques de ses clients le conseil (Inetum Consulting), la gestion des infrastructures et applications à façon (Inetum Technologies), l'implémentation de progiciels (Inetum Solutions) et sa propre activité d'éditeur de logiciels (Inetum Software). Inetum a conclu des partenariats stratégiques avec 4 grands éditeurs mondiaux - Salesforce, ServiceNow, Microsoft et SAP et poursuit une stratégie d'acquisitions dédiée afin d'entrer dans le top 5 européen sur ces technologies et proposer la meilleure expertise à ses clients.
Tous nos postes sont ouverts aux personnes en situation de handicap.
Description du poste
Métier
Conseil et Intégration - Conseil Technique
Intitulé du poste
Développeur Big Data Junior H/F
Contrat
CDI
Description De La Mission
Nous sommes une ESN agile, un groupe international certifié Top Employer Europe 2023.
A l'ère de la post-transformation digitale, nous mettons tout en œuvre pour que chacun de nos 28 000 athlètes du digital puisse se renouveler perpétuellement, en vivant positivement son propre flow digital.
Chacun de nos talents peut ainsi façonner son parcours de carrière selon ses appétences, entreprendre de manière pragmatique avec ses clients pour un monde à impact positif, innover localement dans 27 pays et harmoniser son investissement professionnel et son bien-être personnel.
Rejoignez Inetum. Live your positive digital flow.
Tous nos postes sont ouverts aux personnes en situation de handicap
A la recherche de développeurs Big Data juniors pour rejoindre notre équipe. Les candidats doivent être des ingénieurs Big Data passionnés et motivés, capables de travailler en équipe et de résoudre des problèmes complexes.
Responsabilités
Participer à la conception et au développement de solutions Big Data
Travailler en étroite collaboration avec les équipes de développement pour intégrer les solutions Big Data dans les applications existantes
Participer à la mise en place de l'architecture Big Data
Développer des scripts et des programmes pour automatiser les tâches de traitement de données
Participer à la maintenance et à l'amélioration des solutions Big Data existantes
Profil
Compétences requises
Connaissance des technologies Big Data telles que Hadoop, Hive, Iceberg, Kafka, Spark, Cloudera, Databricks, Snowflake
Maîtrise d'au moins un langage de programmation parmi Scala et Java
Connaissance des environnements Cloud tels que AWS, Azure serait un plus
Diplôme d'ingénieur ou Master 2 en informatique ou en statistiques
Une première expérience en développement Big Data serait un plus
Profil recherché
Nous recherchons des candidats passionnés par les technologies Big Data, ayant une bonne capacité d'analyse et de résolution de problèmes. Les candidats doivent être capables de travailler en équipe et de communiquer efficacement avec les autres membres de l'équipe.
Pourquoi nous rejoindre ?
Rejoindre Inetum, Certifié TOP EMPLOYER EUROPE 2024, c'est
Faire partie d'une équipe à taille humaine, soudée, encourageant la diversité des profils et des expériences et favorisant l'autonomie et l'initiative de chacun ;
Avoir un impact chez nos clients en étant responsabilisé dans le cadre de missions à forts enjeux et sur un large panel d'activités ;
S'intégrer dans une dynamique de croissance et de développement de notre marque de conseil.
Nous vous proposons
Une trajectoire de carrière personnalisée et adaptée à vos souhaits d'évolution grâce à une implantation à l’international (26 pays, 7 Fablab), des formations ciblées et des projets couvrant l’ensemble de la chaîne de valeur IT (+25 filières métiers)
Intégrer un collectif d’experts partageant des valeurs de solidarité et d’excellence
Une culture de la proximité au sein de nos 45 agences en France
Localisation du poste
Localisation du poste
France, Ile-de-France, 75 Paris
Ville
5-7 rue Touzet Gaillard - 93400 Saint-Ouen-sur-Seine
Critères candidat
Niveau d'études min. requis
Bac+5
Niveau d'expérience min. requis
Moins de 2 ans
Show more
Show less","{'ProgLanguage': ['Java', 'Scala', 'R'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': ['Hadoop', 'Spark', 'Databricks'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': ['Statistiques'], 'CloudComputing': ['AWS', 'Azure'], 'DevTools': ['Git'], 'Os': [], 'DBMS': ['Snowflake', 'Snowflake'], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Big Data', 'Statistiques', 'Cloud'], 'FrSoftSkills': ['Résolution de problèmes', 'Collaboration', 'Flexibilité'], 'EnSoftSkils': ['Collaboration', 'Initiative']}","{'JobDetail': ['Junior'], 'TypeContract': ['CDI'], 'Salary': [], 'Level': ['Bac+5'], 'Experience': ['a', 'n', 's', '30', '30', '30']}"
LinkedIn,Data engineer python,FINAXYS,"Paris, Île-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-python-at-finaxys-3887107285?position=47&pageNum=0&refId=TDTc9UZJy78L%2BED7EV%2BMrg%3D%3D&trackingId=eBg06AwxyNxRUXDsMZTakg%3D%3D&trk=public_jobs_jserp-result_search-card,"LE CONTEXTE
Leader en
IT
, dans les domaines Banque
,
Finance
et
Assurance
,
Finaxys
est un cabinet de
conseil
créé en 2008. Nous accompagnons au quotidien les plus grandes banques du pays sur leur
transformation digitale
(BNP Paribas, Société Générale, Crédit Agricole, Natixis, etc.)
Nos clients bancaires travaillent également dans des contextes Big Data sur des applications centrales rattachées aux Datalakes.
LES MISSIONS
Développement et traitements sur des applications Big Data (Python)
Être force de proposition sur les choix techniques les plus pertinents
Maintenir la qualité des solutions, mesure de cette qualité, alerte sur les non-conformités et validation des solutions définitives.
Analyser des risques liés aux solutions envisagées et proposition des actions de remédiation.
Apporter des solutions IT répondant au mieux aux besoins du business porté par la/le Product Owner (Métiers/Fonctions) en cherchant toujours la maximisation de la valeur générée
Accompagner les équipes dans les migrations Cloud
ENVIRONNEMENT TECHNIQUE
Python
Pandas
Scirpting Big Data
Culture DevOps (Jenkins, Maven, Ansible)
PROFIL
Compétences Techniques et Fonctionnelles requises
Maitrise obligatoire de l’anglais
Show more
Show less","{'ProgLanguage': ['Python', 'R'], 'DataBase': [], 'DataAnalytics': ['Pandas', 'R'], 'BigData': [], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git', 'Jenkins'], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': ['Ansible'], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['DevOps', 'Big Data', 'Cloud'], 'FrSoftSkills': [], 'EnSoftSkils': []}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's']}"
LinkedIn,Data Engineer (F/H),Renault Digital,"Boulogne-Billancourt, Île-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-f-h-at-renault-digital-3911202728?position=48&pageNum=0&refId=TDTc9UZJy78L%2BED7EV%2BMrg%3D%3D&trackingId=ZkQXgjIjA2SgSdRtYuvyYA%3D%3D&trk=public_jobs_jserp-result_search-card,"Contexte :
Dans le cadre de son programme Industrie 4.0, Renault développe depuis 2017 sa propre plateforme pour connecter et agréger les données industrielles des 22 sites du Groupe et de plus de 2500 machines.
Fort de partenariats stratégiques signés avec Google Cloud (stack data full GCP), Renault Digital est à la recherche d’un(e) Data Engineer au sein du Pôle Architecture et Data pour mettre en place des chaînes de traitement de données répondant à de nouveaux besoins métiers.
Vous collaborerez au jour le jour avec les équipes métiers ainsi qu’avec les autres fonctions du Pôle Architecture & Data (Data Analysts et Scientists, architectes, …), exploitant des téraoctets de données (événements en mode streaming, traitements en batch et temps réels et les appels aux APIs) afin entre autres d’alimenter des modèles de machine learning (segmentation clients, détection automatiquement des pannes des véhicules, …).
Responsabilités principales :
Vous participez aux phases de framing, MVP et release des produits, services et APIs orientés data ;
Vous argumentez les choix d’architecture des projets et de la plateforme datalake sur GCP ;
Vous contribuez à la valeur métier des produits orientés Data s’appuyant sur le Datalake, en mettant en place des chaînes bout en bout de traitement de la data, de l’ingestion à l’exposition d’APIs et à la visualisation des données et des solutions ML/DS ;
Vous êtes garant de la qualité des données transformées dans le Datalake, du bon fonctionnement des chaînes de traitement et de l’optimisation de l’utilisation des ressources des ressources cloud ;
Vous proposez des standards d’architecture et de développement ;
Vous êtes force de proposition, innovant(e) et bienveillant(e).
Environement technique :
Spark, Scala, Python, Java, Airflow, SQL, Google Cloud Platform (BigQuery, Cloud Storage, PubSub, Beam, Dataflow, Cloud ML, TensorFlow, Kubernetes), Git, Docker, JSON, Bash, Spotfire
Profil recherché :
Vous avez minimum 5 ans d’expérience en tant que Data Engineer ;
Vous disposez d’une expérience en développement Spark, Scala, Python et requêtage SQL sur des gros volumes de données ;
Vous avez une appétence pour la data : validation, transformation, analyse, valorisation ;
Vous possédez une expérience de développement et orchestration de chaines ETL complexes via Airflow ou équivalent ;
Vous pratiquez la méthodologie agile (Agile Scrum et/ou Kanban) ;
Vous utilisez les services cloud (préférablement GCP) ;
Vous êtes capable d’échanger en anglais technique écrit et oral.
Informations complémentaires :
Votre poste sera basé à Boulogne-Billancourt (France) en CDI (temps plein)
Vous bénéficiez de 2 à 3 jours de télétravail par semaine
Show more
Show less","{'ProgLanguage': ['Python', 'Java', 'Scala', 'R', 'Go', 'Bash'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': ['Spark'], 'MachingLearning': ['TensorFlow'], 'DataSerialization': ['Json'], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': ['Google Cloud Platform'], 'DevTools': ['Git', 'Docker'], 'Os': [], 'DBMS': ['BigQuery'], 'SoftBigDataProcessing': [], 'Automation': ['Kubernetes', 'Airflow'], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': ['Docker', 'Kubernetes'], 'Collaboration': [], 'Other': ['ML', 'Machine Learning', 'Cloud'], 'FrSoftSkills': [], 'EnSoftSkils': []}","{'JobDetail': ['Temps plein', 'Full'], 'TypeContract': ['CDI'], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's', '5', '5', '5']}"
LinkedIn,Data Engineer - Internship,Equativ,"Paris, Île-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-internship-at-equativ-3821045783?position=49&pageNum=0&refId=TDTc9UZJy78L%2BED7EV%2BMrg%3D%3D&trackingId=%2FuGqbRz65o7d93Q2HdgHZQ%3D%3D&trk=public_jobs_jserp-result_search-card,"👫 About the team
At Equativ, we’re on a mission to develop advertising technologies that empower our customers to reach their digital business goals. This means that we rely on massively scalable, widely distributed, highly available, and efficient software systems; the platform deals with over 3 millions requests per second managed by 3,000 servers.
Our innovation team based in Paris, Nantes, Limoges, Krakow and Berlin is composed of 100+ straightforward and energetic engineers working in an Agile environment and ready to tackle the most complex technical challenges.
Our data engineering team is composed of 8 skilled engineers and is based in Paris. We are part of the R&D department which is composed of 120+ engineers spread across Paris, Nantes, Limoges, Krakow and Berlin all working in an Agile environment and ready to tackle the most complex technical challenges.
The data engineers are split in two sub-teams working in close collaboration:
Pipeline team: Maintaining and enhancing the operationality of our on-premise and cloud data pipelines which feed our warehouses and APIs
Feature team: Apply best in class data modeling and orchestrating data transformations in our warehouses, leading the day-to-day management of these warehouses
Our Mission 👇
Our Data Engineering team is central to Equativ’s data centric business and is responsible to ingest, transform, model and redistribute all data coming from our ad tech platform.
We aim at building scalable and robust Big Data platforms from ingestion to business actionable consumption. Our Big Data ecosystem must handle huge volumes (15 Tb per day), short & long term data storage, complex data modeling, real-time and batch ELT as well as providing external access through dedicated APIs.
We enhance and deliver Equativ data directly to our customers and throughout the company whether it is for BI analysis, data science models feeding, customer reporting, invoicing and more.
We rely on a top tier on-premise & cloud stack (Kafka, Flink, ClickHouse, Bigquery, Dataflow, Airflow, DBT…) and work hard to increase reporting capabilities, lower maintenance time, improve performances and simplify the access to our raw data.
What you'll do ✏️
As a data engineer intern, you will be supporting one of the two sub-team (pipeline or feature) in their tasks and projects:
Take a leading part on a data engineering project such as but not limited to:
Proof of Concept of Clickhouse Cloud
Improvement of the data transformation process with DBT, BigQuery and Airflow
Development of new functionalities on our internal tools (APIs, software applications)
Setup a data lineage application (castor doc)
Support the data engineering team in their day-to-day activities:
Enhance our DevOps process with CI/CD and testing framework
Monitor performances and workflow of our applications using reporting tool (Grafana)
Take part in improving and deploying data engineering standards, documentation and operational guidelines around data usage at Equativ
💪 About you
Master degree in Computer Science or similar technical field of study
Prior experience in data or software development related environment is desired
Experience with a cloud datawarehouse (BigQuery, Snowflake, Databrick,..) is a plus
Good knowledge of SQL and one other data programming language (Java preferred, Python, Scala..).
Knowledge on the software development process (Git, CI/CD, test, scrum)
Working proficiency and communication skills in verbal and written English
Strong interest in big data and cloud computing technologies.
👋 About us
Equativ is the new single name for Smart Adserver, DynAdmic, LiquidM and Nowtilus — four proven innovators in advertising technology. The vertically integrated company provides brand and privacy-safe solutions that empower its clients to achieve maximum impact while respecting the rights of consumers. The union combines client expertise and engineering excellence to serve the interests of both the supply- side and demand-side with equal professionalism and technical sophistication.
Headquartered in Paris and New York, Equativ operates globally with a team of more than 550 people in 20 offices. Equativ offers the market its own independent ad server, SSP, buyer tools, and media services to fulfill the promise of advertising technology. Learn more at Equativ.com.
The company is ranked on the Deloitte Technology Fast 500 EMEA and in the Financial Times’ FT 1000: Europe’s Fastest-Growing Companies.
Equativ (formerly Smart AdServer) has been awarded the HappyIndex@Work label and is proud to be among the best companies in the ChooseMyCompany ranking, recognized for its flexible working environment.
Come and lead the charge with us in building a transparent ecosystem based on quality!
Equativ is an equal opportunity employer. Equal access to employment, services, and programs are available to everyone, regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity, or Veteran status. If you require reasonable accommodation throughout the application and/or interview process, please contact the recruitment team at ta-team@equativ.com
Show more
Show less","{'ProgLanguage': ['Python', 'Java', 'Scala', 'R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': ['Flink'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git'], 'Os': [], 'DBMS': ['Snowflake', 'Snowflake', 'BigQuery'], 'SoftBigDataProcessing': [], 'Automation': ['Airflow'], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': ['Teams'], 'Other': ['DevOps', 'Big Data', 'Cloud', 'CI/CD'], 'FrSoftSkills': ['Communication', 'Collaboration'], 'EnSoftSkils': ['Communication', 'Collaboration']}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's']}"
LinkedIn,Data Engineer (H/F) - Lille - CDI,METEOJOB by CleverConnect,"Lille, Hauts-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-h-f-lille-cdi-at-meteojob-by-cleverconnect-3858145866?position=50&pageNum=0&refId=TDTc9UZJy78L%2BED7EV%2BMrg%3D%3D&trackingId=Yq6xoHndecJYfbsKu%2F1jGg%3D%3D&trk=public_jobs_jserp-result_search-card,"Entreprise
Chez LJE Solutions, nous plaçons l’humain au cœur de chaque projet. Au-delà des compétences, nous valorisons les
aspirations
et les
valeurs
de chaque individu.
Nous intervenons dans tous les secteurs d'activité en France et en Suisse.
Description Du Poste
LJE Solutions recherche pour un de ses clients basé à Lille, un/une Data Engineer.
Notre client est une
ESN dynamique basée à Lille, qui se distingue dans l'intégration et la restitution de données. Partenaire privilégié de technologies de pointe comme Power BI, Tableau et Qlik, il recherche des talents désireux de participer à notre aventure entrepreneuriale.
Nous recherchons un Data Engineer curieux et motivé pour jouer un rôle clé dans l'organisation et le développement de l'agence. Ce poste offre une opportunité unique de travailler directement avec les fondateurs, experts en technologies, et de contribuer significativement à la formation interne et à l'expertise chez nos clients.
Vos Responsabilités
Travailler en étroite collaboration avec les fondateurs sur des projets d'intégration et de restitution de données,
Participer activement à la croissance de l'entreprise en apportant des idées innovantes et en prenant part à des projets variés,
Monter en compétence techniquement, avec la possibilité d'évoluer vers des rôles de Team Lead ou Tech Lead selon vos aspirations.
Cette entreprise offre un environnement convivial et ambitieux, encourageant la prise d'initiative. Leur structure à taille humaine valorise chaque collaborateur, avec une approche personnalisée et une hiérarchie plate qui favorise l'expression et la participation active de tous.
Rémunération Et Avantages
Poste basé à Lille, avec possibilité de télétravail partiel,
Rémunération compétitive basée sur l'expérience, fourchette indicative de 44k à 48k € en fixe, + variables,
Tickets restaurant,
Mutuelle d'entreprise.
Description Du Profil
Passion pour les technologies de la data, avec une expertise ou un intérêt pour XDi et Talend, sans exclure d'autres ETL du marché,
Plus de 4 ans d'expérience dans le domaine de la data engineering,
Curiosité intellectuelle, agilité, excellent savoir-être, forte capacité de travail en équipe et de partage de connaissances,
Localisation à Lille ou disposition à déménager, avec une préférence pour les candidats de la région pour faciliter la collaboration et le partage au sein de notre agence physique.
Show more
Show less","{'ProgLanguage': ['R'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': ['Tableau', 'Power BI'], 'Statistics': [], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': [], 'FrSoftSkills': ['Collaboration', 'Organisation'], 'EnSoftSkils': ['Collaboration', 'Initiative']}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's', '4', '4', '4']}"
LinkedIn,Data Engineer,Digital Waffle,"Paris, Île-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-at-digital-waffle-3913824888?position=51&pageNum=0&refId=TDTc9UZJy78L%2BED7EV%2BMrg%3D%3D&trackingId=8uQpOuoHSTAxlgIAc6XcKw%3D%3D&trk=public_jobs_jserp-result_search-card,"Digital Waffle is proud to have partnered with an innovative tech startup in Paris, who are looking for a talented Data Engineer to join their growing team!
They are made up of a powerhouse of experts, combining
data engineers, business process gurus, and Project managers
who leverage the most advanced solutions available; utilising process mining, automation tools, and smart execution systems.
Looking for an experienced Data Engineer (3-5 years)
What You'll Do:
This is a full-time,
hybrid role (Paris-based)
where you'll wear many hats: data exploration, system integration, data prep, data modeling, and implementing data solutions.
Experience:
Expertise in data engineering, data modeling, and ETL (Extract, Transform, Load) processes
Data warehousing and data analytics skills
Experience handling large, complex datasets
Proficiency in SQL and programming languages like Python or Java
Stellar problem-solving and analytical skills
Top-notch communication and collaboration abilities
Bachelor's or Master's in Computer Science, Information Systems, or a similar field (a plus for process mining or intelligent process automation experience)
If you are an experienced and driven Data Engineer, please apply here!
Show more
Show less","{'ProgLanguage': ['Python', 'Java', 'R'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git'], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': [], 'FrSoftSkills': ['Communication', 'Collaboration'], 'EnSoftSkils': ['Communication', 'Collaboration']}","{'JobDetail': ['Full'], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's']}"
LinkedIn,Data Engineer H/F,Ippon Technologies,Greater Nantes Metropolitan Area,https://fr.linkedin.com/jobs/view/data-engineer-h-f-at-ippon-technologies-3902436649?position=52&pageNum=0&refId=TDTc9UZJy78L%2BED7EV%2BMrg%3D%3D&trackingId=DqSfWwLB6EnRE5u%2BjZ6DkA%3D%3D&trk=public_jobs_jserp-result_search-card,"Envie de rejoindre la communauté DATA la plus dynamique de France ?
Notre spécialité est de construire des data platform dans le Cloud public avec les meilleurs technos du moment : Snowflake, Databricks, Matillion, DBT.
Membre de la Practice Data, le/la futur(e) Data Engineer sera intégré(e) à nos équipes de conseil et sera suivi(e) par un(e) mentor qui l’aidera à monter en compétences.
Votre champs d’expertise :
Intervenir sur les data platforms de nos clients pour développer de nouveaux pipelines de données (ingestion, traitement, exposition).
Travailler en collaboration avec les métiers et les data scientists pour leur fournir un support à l’industrialisation de leurs travaux (tests, intégration continue, scalabilité des modèles, craftsmanship etc…)
Déployer des infrastructures cloud full
infra-as-code
(Terraform, CloudFormation).
Participer aux évènements internes à la communauté data (BBL, webinar, datapéro interne, meetup, blog, dojos) et externes (Salon du Big Data, GCP Summit, Spark Summit, AWS Summit, Devoxx, workshop partenaire, meetups).
Capitaliser sur les missions et les différents évènements de la communauté au travers d’articles de blogs, REX, BBL interne.
Vos connaissances :
Un framework de calcul distribué tel que Spark, Storm, Flink.
Un ou plusieurs langages de programmation (Python, Scala, Java...)
Différents systèmes de stockage de données (SQL ou NoSQL) et bien sûr le langage SQL.
La connaissance de Snowflake est bienvenue ;-)
Un framework de streaming de données tel que Kafka ou Amazon Kinesis.
Une expérience sur les technologies Cloud : AWS, GCP, Azure
Le delivery et les projets en production faisant partie de notre ADN, vous êtes capable de livrer du code de qualité dans des environnements agiles.
De plus en plus de nos projets se font en remote avec des clients du monde entier, il devient nécessaire d’être à l’aise en Anglais.
Ippon technologies c’est aussi :
👍 Bénéficier d'un suivi de proximité réalisé par votre manager technique : points réguliers pour votre suivi en mission, votre formation et votre évolution de carrière
✌️ Rejoindre une entreprise où les valeurs du sport sont nos leitmotiv : dépassement de soi, travail en équipe, bienveillance.
🗒️ Apprendre via notre programme de formation BlackBelt : https://bit.ly/3ByqcIL
😁 Travailler en pair programming ou avec un.e mentor pour gravir les échelons !
💪 Pouvoir participer à une aventure humaine au sein de notre Fondation Ippon pour réduire la fracture numérique dans le monde !
🤝 Participer à nos apéros et divers évènements internes pour consolider la cohésion d’équipe
Et après ?
Et oui alors ? Que se passe-t-il une fois que vous êtes convaincu d’avoir lu l’offre d’emploi qui vous correspond bien ?
Nous vous proposons de prendre contact et de nous rencontrer !
Les Next Steps :
1 call RH
1 échange RH
1 échange Technique
Si le match est bon des deux côtés : Hadjimé ! Vous vous lancerez sur le tatami Ippon !
Show more
Show less","{'ProgLanguage': ['Python', 'Java', 'Scala', 'R'], 'DataBase': ['SQL', 'NoSQL'], 'DataAnalytics': ['R'], 'BigData': ['Spark', 'Databricks', 'Flink'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': ['AWS', 'Azure'], 'DevTools': [], 'Os': [], 'DBMS': ['Snowflake', 'Snowflake'], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': ['Terraform', 'CloudFormation'], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Big Data', 'Cloud'], 'FrSoftSkills': ['Collaboration'], 'EnSoftSkils': ['Collaboration']}","{'JobDetail': ['Remote', 'Full'], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's']}"
LinkedIn,"Data Engineer – Antibes, France (H/F)",Astek,"Antibes, Provence-Alpes-Côte d'Azur, France",https://fr.linkedin.com/jobs/view/data-engineer-%E2%80%93-antibes-france-h-f-at-astek-3909192086?position=53&pageNum=0&refId=TDTc9UZJy78L%2BED7EV%2BMrg%3D%3D&trackingId=ln5VxaOXXVRJsDTyWf0TrQ%3D%3D&trk=public_jobs_jserp-result_search-card,"CDI
Antibes - France
Publiée il y a 2 semaines
Le Groupe Astek
Ce Que Nous Allons Accomplir Ensemble :
Intervenir dans la conception, le développement, les tests unitaires, la qualification, l’intégration continue et la mise en production d’évolutions sur les projets du pôle produits scoring (un pôle visant à développer des solutions permettant de générer des scores ou des segments d’information pertinents dans divers domaines, notamment : profiling TV, PUB, SAB, MMDM, Voscastview) chez l’un de nos partenaires spécialisé dans le secteur des télécoms.
Votre Mission, Si Vous L’acceptez :
En collaboration avec les autres membres de l’équipe, vous devrez prendre en charge le RUN des applications du pôle produit scoring.
Conception d’une solution se basant sur les développements existants et les besoins métiers remontés par le Product Owner.
Réalisation et développement de nouvelles fonctionnalités sur les composants des applications du pôle produits scoring et environnement CGP.
Votre Future Équipe :
Au sein d’un environnement riche et complexe, vous évoluerez avec des experts passionnés à la fois techniques et fonctionnels (Ingénieurs spécialisés, chef de projet, scrum master, product owner, analystes …).
Votre stack de jeu
D ans un environnement SAFE sous cloud GCP, Big Query, OnPrime, Grafana, Python et Ansible.
Vous ?
De formation Ingénieur, vous justifiez d’une première expérience sur un poste de Data engineer. Vous possédez des compétences d’autonomie et d’adaptabilité et vous avez une capacité à communiquer efficacement au sein d’une équipe.
Le Groupe Astek
Créé en France en 1988, Astek est un acteur mondial de l’ingénierie et du conseil en technologies. Fort de son expertise dans de nombreux secteurs industriels et tertiaires, Astek accompagne ses clients internationaux dans le déploiement intelligent de leurs produits et de leurs services, et dans la mise en œuvre de leur transformation digitale.
Depuis sa création, le Groupe a fondé son développement sur une forte culture d’entrepreneuriat et d’innovation, et sur l’accompagnement et la montée en compétence de
ses 7800 collaborateurs
qui s’engagent chaque jour à promouvoir la complémentarité entre les technologies numériques et l’ingénierie des systèmes complexes.
Rejoignez un Groupe en fort développement en France et à travers le monde ayant réalisé un chiffre d’affaires de 600 M€ en 2023.
Tous les détails sur le Groupe sur le site https://astekgroup.fr. Et vous pouvez aussi nous suivre sur notre blog : https://blog.groupeastek.com.
Rencontrons-nous
Créé en France en 1988, Astek est un acteur mondial de l’ingénierie et du conseil en technologies, présent sur les 5 continents. Fort de son expertise dans de nombreux secteurs industriels et tertiaires, Astek accompagne ses clients internationaux dans le déploiement intelligent de leurs produits et de leurs services, et dans la mise en œuvre de leur transformation digitale.
Depuis sa création, le Groupe a fondé son développement sur une forte culture d’entrepreneuriat et d’innovation, et sur l’accompagnement et la montée en compétence de ses 7800 collaborateurs qui s’engagent chaque jour à promouvoir la complémentarité entre les technologies numériques et l’ingénierie des systèmes complexes.
Rejoignez un Groupe en fort développement en France et à travers le monde et ayant réalisé un chiffre d’affaires hors
acquisitions de 600M€ en 2023.
Tous les détails sur le Groupe sur le site
Nos Plus
Astek est green et fait bénéficier ses salariés d’une indemnité kilométrique vélo
Une politique CARE sur-mesure déployée par nos équipes RH pour nos collaborateurs (https://astekgroup.fr/engagements)
Notre charte de la Diversité
Mots-clés :
ingénieur – ingénieure – consultant – consultante – Data engineer – Big Data
Caractéristiques de l'emploi
Catégorie Ingénieur
Job Industry Télécom / Média
Postuler en ligne
Nom *
Prénom *
Email *
Un email valide est requis.
Téléphone *
Un numéro de téléphone valide est requis.
Joindre un CV *
Mots-clés :
ingénieur – ingénieure – consultant – consultante – Data engineer – Big Data
Show more
Show less","{'ProgLanguage': ['Python', 'R', 'Go'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git'], 'Os': [], 'DBMS': ['Big Query'], 'SoftBigDataProcessing': [], 'Automation': ['Ansible', 'Chef'], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Big Data', 'Cloud'], 'FrSoftSkills': ['Adaptabilité', 'Collaboration'], 'EnSoftSkils': ['Collaboration']}","{'JobDetail': [], 'TypeContract': ['CDI'], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's']}"
LinkedIn,Data Engineer - Profils expérimentés H/F,LCL,"Villejuif, Île-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-profils-exp%C3%A9riment%C3%A9s-h-f-at-lcl-3888403052?position=54&pageNum=0&refId=TDTc9UZJy78L%2BED7EV%2BMrg%3D%3D&trackingId=B2xAp1M9k1B%2FmH5%2FSOf%2BVg%3D%3D&trk=public_jobs_jserp-result_search-card,"🏦 LCL, c’est LA banque urbaine du Groupe Crédit Agricole - avec nous, accompagnez la transformation, le développement et le maintien technologiques de nos outils avec une vision business et de satisfaction de nos 6 millions de clients.
En tant qu’acteur majeur de la banque de détail, nous nous adaptons chaque jour aux nouveaux modes de consommation et les projets de nos de clients internes et externes tout en garantissant le besoin de sécurité et de développement technologique qu’impliquent nos activités.
💡Organisées en mode Agile, les 8 squads de la tribu DATA (6 squads Métier et 2 squads transverses) œuvrent au quotidien pour répondre à un enjeu majeur pour la banque : la collecte, le stockage, la gestion et l’usage de la donnée. En interaction permanente avec les autres tribus IT et les métiers, elles étudient et proposent les solutions et architectures à déployer pour répondre au mieux aux stratégies de développement et de pilotage de l’ensemble des métiers de la banque.
Rejoignez-nous si vous souhaitez participer aux réflexions et au développement de la trajectoire technique et DataCentric du SI LCL et plus largement du Groupe CA. Vous côtoierez et serez au cœur de l’implémentation de technologies variées telles que les plateformes Teradata, les solutions d’architecture applicative des technologies BigData ou IA, des environnements analytiques ou encore des solutions de datavisualisation. Vous assurerez le traitement de données en temps réel ou en batch et exposerez les données sous différentes formes.
Que vous souhaitiez devenir expert sur les socles technologiques ou relever le challenge de la gestion de projets Métier, nous vous aiderons à atteindre vos propres objectifs.
Vous rejoindrez une équipe pluridisciplinaire, clairement orientée vers le développement de ses collaborateurs à de nouvelles technologies !
🎯 En tant que Data Engineer :
· Vous aimez analyser les besoins avec les métiers, challenger, identifier les sources de données dans les différents univers technologiques, industrialiser des algorithmes, concevoir et développer des Datalab ou des Datamart sur les plateformes ? Vous saurez relever les challenges proposés par les squads métier !
· Vous préférez travailler à l’architecture et au déploiement de nouvelles plateformes, à la levée de la dette technologique ou encore réaliser de la veille au service de notre trajectoire ? La squad Socles Data est faite pour vous !
· Au-delà des projets que vous gérerez, garant du bon fonctionnement de votre parc applicatif, vous attacherez une grande attention à la mise en œuvre de solutions optimisées.
· La rigueur, la communication, l’esprit d’équipe mais aussi la curiosité et la créativité font partie de vos soft skills ! ils vous permettront de répondre aux enjeux de sécurité, de qualité, de transmission de la connaissance et contribueront à l’atteinte des objectifs de l’IT et plus largement de LCL, au service de ses clients.
💻 Voici les principales technologies utilisées au sein de la tribu, si certaines vous sont familières, nous vous aiderons à monter en compétence sur d’autres !
Langages utilisés : SQL, Python, Scala
SGBD : Teradata et utilitaires (TPT, BTEQ, …)
Streaming : Kafka
Search : ElasticSearch, SolR
Environnement : Unix
Solutions Big Data : Hadoop Cloudera, DataIku, HDFS, Hive, Impala,
Devops : GitLab, Jenkins, Nexus
Outils de visualisation : MS BI (SSIS, SSAS, SSRS) Qlik Sens, BO
Modélisation : MEGA
Outils collaboratifs : GIT, Jira, Confluence, Teams
⚡Si les nouveaux enjeux bancaires vous intéressent, que vous souhaitez intégrer une équipe Agile au service des métiers dans laquelle vous serez force de proposition et que vous aimez travailler dans un environnement motivant et dynamique, rejoignez-nous, cette offre est faite pour vous !
🔥 Les + de notre entreprise :
Accès au Plan d’épargne Groupe, intéressement et participation aux bénéfices de l’entreprise + abondement
Prix préférentiels bancaires et avantages CSE
Parcours évolutif dans l’entreprise et/ou dans le Groupe CA.S.A
Télétravail (jusqu'à 2 jours de télétravail par semaine)
De multiples commodités sur le campus (restaurants d'entreprise, salle de sport, crèche, centre médical, médiathèque...)
Forfait et avantages pratiques « mobilité durable » pour les velotafeurs
Des équipes aussi diversifiées que structurées dans une dynamique de transformation
LCL s’engage en faveur de la diversité et nous encourageons tout(e) candidat(e) ayant l’expérience requise à postuler à nos offres. Tous nos postes sont ouverts aux personnes en situation de handicap.
Nous avons encore de nombreuses raisons à vous présenter pour vous convaincre de nous rejoindre mais pour cela, il faudra postuler ici !
Show more
Show less","{'ProgLanguage': ['Python', 'Scala', 'R', 'Go'], 'DataBase': ['SQL', 'Elasticsearch'], 'DataAnalytics': ['R'], 'BigData': ['Hadoop'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git', 'Jenkins'], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': ['JIRA', 'Confluence', 'Teams'], 'Other': ['DevOps', 'Big Data', 'Cloud'], 'FrSoftSkills': ['Communication', 'Créativité'], 'EnSoftSkils': ['Communication']}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's']}"
LinkedIn,"Big Data Engineer Confirmé – Paris, France (H/F)",Astek,"Paris, Île-de-France, France",https://fr.linkedin.com/jobs/view/big-data-engineer-confirm%C3%A9-%E2%80%93-paris-france-h-f-at-astek-3839098103?position=55&pageNum=0&refId=TDTc9UZJy78L%2BED7EV%2BMrg%3D%3D&trackingId=Zls1eavoxiIyF27%2BQNvkaw%3D%3D&trk=public_jobs_jserp-result_search-card,"CDI
Paris - France
Publiée il y a 2 mois
Le Groupe Astek
Ce Que Nous Allons Accomplir Ensemble :
Nous rejoindre en tant que
Big Data Engineer Confirmé (H/F),
afin d’accompagner un opérateur télécoms, Leader en Europe dans l’assistance et le support applicatif de niveau 3 (résolution des problèmes utilisateurs, exploitation des environnements hors production).
Un challenge portant sur des millions d’utilisateurs dans un environnement technique innovant, stratégique et où l’entraide et la bonne humeur priment !
Votre Mission, Si Vous L’acceptez :
Supervision et détection et résolution des problèmes utilisateurs (développeurs, exploitants et data exploreurs)
Développement de solutions de self-service ou d’une solution de résolutions automatiques des problèmes
Qualifier les données et les résultats
Conception technique des solutions
Assurer l’accompagnement et le déploiement des évolutions des processus et outils
Accompagner la phase de mise en production
Votre Future Équipe :
Vous intégrerez une équipe à la fois technique et fonctionnel, qui œuvre chaque jour pour développer et maintenir en conditions opérationnelles l’ensemble des solutions IT !
L’équipe est en interaction avec des clients à la fois internes et externes.
Votre stack de jeu
Système d’exploitation : Linux
Outils des distributions : HDP, HDF, ELK
Environnement Big data : Hadoop, Spark,
Langage : Scala, Shell, Python
Cloud computing : GCP ou AWS
Base de données : No SQL (Cassandra, Mongo DB), Shell, Ansible
Dataviz : Power BI ou Kibana
Des notions en Réseau et Systèmes feront la différence !
Les Petits Plus Du Projet :
Vous évoluerez au sein d’une équipe impliquée et réactive et interviendrez sur un projet polyvalent et à forte valeur ajoutée.
Vous ?
Diplômé(e) d’une école d’ingénieur ou équivalent de niveau Bac+5.
Vous justifiez idéalement d’une expérience d’au moins 3 ans d’expériences sur un poste similaire ?
Vous faite preuve de proactivité et d’esprit d’équipe, êtes doté(e) d’un excellent sens de l’organisation et vous aimez les challenges et la résolution de problème ?
Alors ce poste est fait pour vous, n’hésitez plus et rejoignez l’aventure ASTEK !
Astek
Créé en France en 1988, Astek est un acteur mondial de l’ingénierie et du conseil en technologies. Fort de son expertise dans de nombreux secteurs industriels et tertiaires, Astek accompagne ses clients internationaux dans le déploiement intelligent de leurs produits et de leurs services, et dans la mise en œuvre de leur transformation digitale.
Depuis sa création, le Groupe a fondé son développement sur une forte culture d’entrepreneuriat et d’innovation, et sur l’accompagnement et la montée en compétence de
ses 7800 collaborateurs
qui s’engagent chaque jour à promouvoir la complémentarité entre les technologies numériques et l’ingénierie des systèmes complexes.
Rejoignez un Groupe en fort développement en France et à travers le monde ayant réalisé un chiffre d’affaires de 600 M€ en 2023.
Tous les détails sur le Groupe sur le site https://astekgroup.fr. Et vous pouvez aussi nous suivre sur notre blog : https://blog.groupeastek.com.
Rencontrons-nous
Notre projet commun vous plait ?
Postulez à cette annonce, et soyez transparent !
Maud, notre Talent Acquisition Referent, vous contactera pour un premier échange.
Puis vous rencontrerez Martin, votre futur manager, avec lequel vous échangerez autour d’Astek, de votre parcours, de vos attentes et de votre future mission .
Enfin, vous rencontrerez Jérémy, notre Directeur d’agence avec lequel vous pourrez valider votre intérêt et adéquation pour le poste et finaliser les éléments contractuels.
Nos Plus
Astek est green et fait bénéficier ses salariés d’une indemnité kilométrique vélo
Une politique CARE sur-mesure déployée par nos équipes RH pour nos collaborateurs (https://astekgroup.fr/engagements)
Notre charte de la Diversité
Mots-clés :
ingénieur – ingénieure – consultant – consultante – Hadoop – Scala – Data
Caractéristiques de l'emploi
Catégorie Ingénieur
Job Industry Télécom / Média
Postuler en ligne
Nom *
Prénom *
Email *
Un email valide est requis.
Téléphone *
Un numéro de téléphone valide est requis.
Joindre un CV *
Mots-clés :
ingénieur – ingénieure – consultant – consultante – Hadoop – Scala – Data
Show more
Show less","{'ProgLanguage': ['Python', 'Scala', 'R', 'Go'], 'DataBase': ['SQL', 'Cassandra'], 'DataAnalytics': ['R'], 'BigData': ['Hadoop', 'Spark'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': ['Power BI'], 'Statistics': [], 'CloudComputing': ['AWS'], 'DevTools': ['Git'], 'Os': ['Linux'], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': ['Ansible'], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Big Data', 'Cloud'], 'FrSoftSkills': ['Organisation'], 'EnSoftSkils': []}","{'JobDetail': ['Confirmé'], 'TypeContract': ['CDI'], 'Salary': [], 'Level': ['Bac+5'], 'Experience': ['a', 'n', 's', '3', '3', '3']}"
LinkedIn,Data Engineer (H/F) - Lille,Logic@l Conseils,"Lille, Hauts-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-h-f-lille-at-logic%40l-conseils-3811575649?position=56&pageNum=0&refId=TDTc9UZJy78L%2BED7EV%2BMrg%3D%3D&trackingId=dy9XohBb6wp2uWIn1KF0hw%3D%3D&trk=public_jobs_jserp-result_search-card,"Dans le cadre du développement de nos activités sur la métropole Lilloise, nous recherchons un
consultant data engineer
(H/F) pour intervenir chez l'un de nos grands comptes clients.
Vos missions :
Recueillir
les besoins métiers et des équipes data
Concevoir et mettre en place les
traitements de données
Réaliser les
tests de validation
Assurer
l’alimentation du dataware
Réaliser les
ordonnancements des traitements
Etre garant de la
mise en place
, du
suivi
et de l’
exploitation
des outils déployés
Assurer
une veille technologique
régulière
Environnement technique :
Développement :
Python, Scala, R, Java,
Framework :
Spark,
Hadoop,
Outils Big data :
Yarn, Pig, Hive, Kafka, Splunk
Bases de données :
MongoDB, HBase, Cassandra
ETL :
Talend, Stambia
Plateforme :
Hortonworks, Cloudera, Map Reduce
,
AWS, GCP, Azure
Votre profil :
Vous disposez d’une expérience
d’au moins 2 ans en tant que data engineer
ou dans le domaine de l’analyse et du traitement de données.
Véritable
passionné de la data
, vous êtes
force de proposition
sur les solutions techniques à mettre en œuvre. Vous maitrisez l’anglais dans un contexte professionnel.
Compétences requises :
Analyses qualitatives et quantitatives (Intermédiaire)
Anglais (Intermédiaire)
Architecture fonctionnelle SI (Débutant)
Développement d'ouvrages, produits ou événements (Débutant)
Gestion des contrôles, tests et diagnostics (Débutant)
Gestion des risques (Intermédiaire)
Maîtrise des logiciels (Intermédiaire)
Mise en exploitation / Production et maintenance (Débutant)
Nos valeurs
Nous avons décidé de renverser la pyramide du management pour placer nos collaborateurs en tête des priorités de l’entreprise.
En effet, attaché à des valeurs fortes, telles que la proximité, la sincérité, la fidélité, la confiance et le respect, nous sommes persuadés que la réussite réside dans le bien-être de nos collaborateurs.
Cela se traduit par un accompagnement de proximité, de la transparence sans langue de bois, des échanges réguliers avec les managers référents, un accompagnement dans le développement de carrière qui est construit et jalonné avec les formations et certifications nécessaires et les missions en adéquation, pour mener à bien l’évolution de carrière.
Pour vous convaincre de nous rejoindre, nos avantages salariés complémentaires :
Environnement bienveillant et stimulant au sein de 3 pôles d’expertises
Formations et Certifications à la demande
Tickets restaurants : 13€ par ticket
Remboursement à 100 % des abonnements de transports en commun
Mutuelle frais de santé avec de hautes garanties
Prise en charge à 100% de l’assurance Prévoyance
Chèque Cadeau Culture 120 €
Compte CSE avec une cagnotte de 390 €
Compte CE : billetterie, voyages, culture, sorties, à des tarifs préférentiels
Des évènements chaque mois : activités associatives, sportives, afterwork, séminaire,
Partenariat Losc (participation aux match dans la loge VIP logical conseils – (Une Vingtaine de match par an)
Possibilité de télétravail
En intégrant Logic@l Conseils, vous participez à une réelle aventure humaine, alors pour postuler, il suffit de cliquer ci-dessous !
Tous nos postes sont ouverts, à compétences égales, aux personnes en situation de handicap.
Show more
Show less","{'ProgLanguage': ['Python', 'Java', 'Scala', 'R', 'Go'], 'DataBase': ['Cassandra', 'HBase'], 'DataAnalytics': ['R'], 'BigData': ['Hadoop', 'Spark'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': ['AWS', 'Azure'], 'DevTools': [], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': ['HBase'], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Big Data', 'Cloud'], 'FrSoftSkills': [], 'EnSoftSkils': []}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's', '2', '2', '2']}"
LinkedIn,Data Engineer,CGI,"Niort, Nouvelle-Aquitaine, France",https://fr.linkedin.com/jobs/view/data-engineer-at-cgi-3902057928?position=57&pageNum=0&refId=TDTc9UZJy78L%2BED7EV%2BMrg%3D%3D&trackingId=nya1Wu5YHzOoOY6TKfTIXA%3D%3D&trk=public_jobs_jserp-result_search-card,"Description de poste
Big Data, Data Science, Data analyse, Data architecture ... Ça n’a pas de secret pour vous ?
Que vous commenciez votre carrière professionnelle ou que vous soyez spécialiste de l’une de ces disciplines, intégrer notre communauté Data, c’est l’assurance de progresser, innover, partager, vous certifier et rendre service à nos clients.
Si vous souhaitez intégrer nos équipes à Niort et accompagner les plus grands acteurs du secteur des Assurances, cette annonce est susceptible de vous intéresser.
En tant que Data Engineer, vous serez responsable de la conception, du développement, de la gestion et de l'intégration des systèmes basés sur les technologies AWS, Terraform, OpenShift, Kafka et Hadoop. Ce rôle implique la mise en place d'architectures évolutives et hautement disponibles pour répondre aux besoins de traitement et de stockage de données de l'entreprise.
Fonctions et responsabilités
Vos responsabilités seront les suivantes:
-Maintenir et développer des solutions basées sur les services AWS pour le stockage, le traitement et l'analyse de données
-Utiliser les services AWS appropriés tels que Amazon EC2, S3, RDS, Lambda, etc., pour répondre aux exigences du projet.
-Créer et maintenir les configurations Terraform pour la gestion de l'infrastructure en tant que code (IaC) sur AWS
-Participer à la maintenance et à la mise en place d'environnements OpenShift pour l'hébergement d'applications et de services
-Gérer et administrer les clusters Kafka pour garantir la disponibilité, la performance et la sécurité du système de messagerie
Participer à l’assistance utilisateurs sur les briques de la plateforme Hadoop Cloudera Data
-Travailler avec les projets et les devOps pour assurer un traitement efficace des données
En rejoignant CGI, vous bénéficiez notamment d’une offre complète de formations (techniques, métiers, développement personnel,…), de flexibilité grâce à notre accord télétravail (jusqu’à 3 jours de télétravail par semaine), d’une politique de congés avantageuse (27 jours de congés payés, RTT, congés ancienneté et enfant malade,…) et d’un package d’avantages intéressant (régime d’achats d’actions, participation, CSE,...).
Qualités requises pour réussir dans ce rôle
Ayant une première expérience en tant que Data Engineer, vous avez une première expérience relative aux points suivants:
-Développement et intégration sur les technologies AWS, Terraform, OpenShift, Kafka et Hadoop
-Connaissance avancée de l'administration Kafka, y compris la configuration, la gestion et la résolution des problèmes
-Mise en œuvre de l'infrastructure en tant que code à l'aide de Terraform
-Bonne compréhension des bonnes pratiques de sécurité pour les systèmes cloud, les clusters Kafka et les plateformes Hadoop
CGI est un employeur inclusif et attentif aux candidatures des personnes en situation de handicap, à l’évolution de carrières des hommes et des femmes et au bien-être de nos salariés LGBT+. Dans un souci d’accessibilité et de clarté, le point médian n’est pas utilisé dans cette annonce. Tous les termes employés se réfèrent aussi bien au genre féminin que masculin.
Ensemble, en tant que propriétaires, mettons notre savoir-faire à l’œuvre.
La vie chez CGI est ancrée dans l’actionnariat, le travail d’équipe, le respect et un sentiment d’appartenance. Chez nous, vous pourrez exploiter votre plein potentiel parce que…
Nous vous invitons à devenir propriétaire dès le jour 1 alors que nous travaillons ensemble à faire de notre rêve une réalité. C’est pourquoi nous nous désignons comme associés de CGI, plutôt que comme employés. Nous tirons profit des retombées de notre succès collectif et contribuons activement à l’orientation et à la stratégie de notre entreprise.
Votre travail crée de la valeur. Vous élaborerez des solutions novatrices et développerez des relations durables avec vos collègues et clients, tout en ayant accès à des capacités mondiales pour concrétiser vos idées, saisir de nouvelles opportunités, et bénéficier d’une expertise sectorielle et technologique de pointe.
Vous ferez évoluer votre carrière en vous joignant à une entreprise bâtie pour croître et durer. Vous serez soutenus par des leaders qui ont votre santé et bien-être à cœur et qui vous permettront de saisir des occasions afin de parfaire vos compétences et élargir les horizons.
Joignez-vous à nous, l’une des plus importantes entreprises de conseil en technologie de l’information (TI) et en management au monde.
Show more
Show less","{'ProgLanguage': ['R'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': ['Hadoop'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': ['AWS'], 'DevTools': [], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': ['Terraform'], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': ['OpenShift'], 'Collaboration': [], 'Other': ['DevOps', 'Big Data', 'Cloud'], 'FrSoftSkills': ['Flexibilité'], 'EnSoftSkils': []}","{'JobDetail': [], 'TypeContract': [], 'Salary': ['1'], 'Level': [], 'Experience': ['a', 'n', 's']}"
LinkedIn,Data Engineer (H/F),ternair,Greater Lille Metropolitan Area,https://fr.linkedin.com/jobs/view/data-engineer-h-f-at-ternair-3915757963?position=58&pageNum=0&refId=TDTc9UZJy78L%2BED7EV%2BMrg%3D%3D&trackingId=dWBVkZEg5jT0dB6SX9Q7Mg%3D%3D&trk=public_jobs_jserp-result_search-card,"👨‍🚀 MISSION : 👩‍🚀
En cohérence avec la stratégie d’entreprise et la roadmap data, vous aurez pour principales missions de :
En lien avec l’équipe DevOps, construire, maintenir et faire évoluer la plateforme de données;
Définir et piloter la cohérence de la collecte, la gestion et l’alimentation des données internes et externes, en différents modes : batch, streaming, API (architecture micro-services);
Préparer et mettre en qualité les données pour les rendre disponibles dans les différents environnements de travail (datalake, datawarehouse, datamart);
Vérifier la qualité des données, de leur bonne et régulière exécution ainsi que de leur utilisation adéquate (gestion des coûts);
Travailler en étroite collaboration avec les data analysts, scientists et data stewards et business de l’entreprise ;
En lien avec l’IT et la sécurité, veiller aux règles d'intégrité et de sécurité des données;
Veille technologique.
🧮 Les outils :
Plateforme data : Google Cloud Platform (Big Query, Airflow)
Développement : Github/GitLab, Docker, Terraform, Python
Analytiques : Qlik
Gestion de projet s: Jira, Confluence, Miro, Drive, Docs, Sheets, Slides
🤩 Profil recherché : 🤩
Expérience d'au moins 4-5 ans (après études) en data ingénierie (flux, modélisation, run)
A l’aise avec l’environnement Cloud et les infrastructures digitales
Communiquant, pédagogue et fortes capacités relationnelles
Anglais (à l’écrit)
Rémunération : 42-60 k€ en package selon expérience
Show more
Show less","{'ProgLanguage': ['Python', 'R', 'Go'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': ['Google Cloud Platform'], 'DevTools': ['Git', 'Docker'], 'Os': [], 'DBMS': ['Big Query'], 'SoftBigDataProcessing': [], 'Automation': ['Airflow'], 'InfrastructureAsCode': ['Terraform'], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': ['Docker'], 'Collaboration': ['JIRA', 'Confluence'], 'Other': ['DevOps', 'Cloud'], 'FrSoftSkills': ['Collaboration'], 'EnSoftSkils': ['Collaboration']}","{'JobDetail': [], 'TypeContract': [], 'Salary': ['Package'], 'Level': [], 'Experience': ['a', 'n', 's', '5', '5', '5']}"
LinkedIn,Data Solutions Engineer (Data & AI),LVMH,"Paris, Île-de-France, France",https://fr.linkedin.com/jobs/view/data-solutions-engineer-data-ai-at-lvmh-3900392289?position=59&pageNum=0&refId=TDTc9UZJy78L%2BED7EV%2BMrg%3D%3D&trackingId=Ii5OaSH%2Bx4fLih9wC%2BWMmA%3D%3D&trk=public_jobs_jserp-result_search-card,"LVMH is the #1 Luxury group and is currently accelerating rapidly on digitalisation. It is bringing technology and innovation in the core of the established 75+ Maisons by inventing unique and powerful products and services.
We are looking for talented solution engineers (Software, Cloud, Data and AI) to join our team and be part of this tech revolution of bringing the Group and its Maisons to the next level.
If you believe Data and AI can enhance the retail industry, from the day-to-day operational tasks to the long term customer experience,
If you think that the Cloud technologies (we love Google Cloud) is a revolution for Data and AI products,
If you like building tech solutions having direct impacts on billion-dollar-valued businesses,
If you have good communication skills and like sharing your knowledge,
Apply now, and join us!
The mission
The Solution Engineer is providing advices and technical assets to the Maisons having Data & AI projects.
Our team (Group Data team) is building a technical framework for all the Maisons to implement easily and quickly Data and AI use cases. Your mission will be to support the Maisons to convert their use case needs to concrete and production ready technical solutions using our framework and tools.
You will cover a portfolio of Maisons, in direct contact with their business analysts, data scientists and IT teams. You will be their dedicated referent on the Data & AI technical topics (Data platform, AI/ML softwares, data transport and transformations, data quality).
Main responsibilities
You will be responsible of providing support and advices to a portfolio of Maisons on Data & AI tech topics (Cloud, Data stacks, Data transformations, Data transfers, ML ops).
You will keep a recurrent discussion with the Maisons to accelerate their projects and immediately provide our support when it's needed.
You will follow-up the engaged productions in the Maisons and report them to the global group data strategy committees.
Applying the quality and security standards. Making them evolve if necessary.
Producing realistic, understandable and documented solutions following the group guidelines.
Sharing and learning from the team by communicating difficulties and successes, taking and bringing honest feedbacks and improving the identified pain points.
Taking responsibility as member of the team on the product performances (delivery and long term usage)
Required expertise and knowledge
Ability to build technical solutions answering concrete usage (User Stories) and communicate them to the team.
Dimension and evaluate complexity for technical solution productions.
Extensive knowledge and experience with good learning and sharing abilities.
Evaluate quickly risks and opportunities about technical choices.
Solid oral, written, presentation and interpersonal communication and relationship skills.
Problem-solving skills on Data and AI, coding and software development
Tech lover
Feedback taker and giver
Team player
Key benefits to join our team
Attractive packages
Offices in the 8th arrondissement near the Champs Elysées
Flexibility on the working hours
Remote work possible (~40%)
7 weeks of holidays (congés payés + RTT)
LVMH brands exclusive private sales
Great employee committee and health insurance (CE, mutuelle)
Last generation MacBooks
Part of a young, motivated and tech savvy team. Get prepared for the Thursday drinks and the tech meet-ups!
You’re eligible if
You have a strong experience (3+ years) in cloud data architecting or consultancy.
You graduated from an engineering (or equivalent) with a master’s degree. Computer Science knowledge is mandatory.
Experience on data stacks and/or Google Cloud (built in components) is a huge plus.
French and English both written and oral (Maisons are all over the world)
You’re thrilled to support the #1 luxury group to get even better.
Hiring Process
Call with our HR partner dedicated to the Tech Team
Technical interview with the Solution Engineering Manager
Technical test
Interview with the Head of Engineering
Still here? Apply now!!
Show more
Show less","{'ProgLanguage': ['R', 'Go'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git'], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': ['Teams'], 'Other': ['ML', 'Cloud'], 'FrSoftSkills': ['Communication'], 'EnSoftSkils': ['Communication', 'Flexibility']}","{'JobDetail': ['Remote'], 'TypeContract': [], 'Salary': ['40'], 'Level': [], 'Experience': ['a', 'n', 's']}"
LinkedIn,"Big Data Engineer – Secteur Télécom – Paris, France (H/F)",Astek,"Paris, Île-de-France, France",https://fr.linkedin.com/jobs/view/big-data-engineer-%E2%80%93-secteur-t%C3%A9l%C3%A9com-%E2%80%93-paris-france-h-f-at-astek-3832149765?position=60&pageNum=0&refId=TDTc9UZJy78L%2BED7EV%2BMrg%3D%3D&trackingId=Z8j5uhBScZ1Pfkab7NeYTg%3D%3D&trk=public_jobs_jserp-result_search-card,"CDI
Paris - France
Publiée il y a 2 semaines
Le Groupe Astek
Ce Que Nous Allons Accomplir Ensemble :
Nous rejoindre en tant que
Big Data Engineer (H/F),
afin d’accompagner un opérateur télécoms, Leader en Europe dans la gestion de ses portails clients grands publics (multimarques mobile et internet).
Un challenge portant sur des millions d’utilisateurs dans un environnement technique innovant et stratégique.
Votre Mission, Si Vous L’acceptez :
Qualifier les données et les résultats
Conception technique des solutions
Décliner les impacts de la stratégie et des innovations technologiques au sein des processus et outils de l’exploitant SI
Assurer l’accompagnement et le déploiement des évolutions des processus et outils
Contribuer aux programmes de transformation DevOps, Cloud et catalogues des offres SI
Développer des fonctions transverses et les « uses cases »
Accompagner la phase de mise en production
Votre Future Équipe :
Au sein d’un environnement riche et complexe, vous évoluerez avec des experts passionné(e)s à la fois techniques et fonctionnels (Ingénieurs spécialisées, chef de projet, scrum master, product owner, analystes…).
L’équipe est en interaction avec des clients à la fois internes et externes.
Votre stack de jeu
Système d’exploitation Linux
Big data (Hadoop, Spark, Scala)
Cloud computing (GCP…)
S QL, No SQL (Cassandra, Mongo DB)
Dataviz : Power BI ou Kibana
Des notions en développement feront la différence !
Les Petits Plus Du Projet :
Vous évoluerez au sein d’une équipe impliquée et réactive et interviendrez sur un projet polyvalent et à forte valeur ajoutée.
Vous ?
Diplômé(e) d’une
école d’ingénieur
ou équivalent de niveau Bac+5. Vous justifiez idéalement d’une expérience d’au moins 2 ans sur un poste similaire.
Ce descriptif vous interpelle ?
Alors ce poste est fait pour vous, n’hésitez plus et rejoignez l’aventure ASTEK !
Astek
Créé en France en 1988, Astek est un acteur mondial de l’ingénierie et du conseil en technologies. Fort de son expertise dans de nombreux secteurs industriels et tertiaires, Astek accompagne ses clients internationaux dans le déploiement intelligent de leurs produits et de leurs services, et dans la mise en œuvre de leur transformation digitale.
Depuis sa création, le Groupe a fondé son développement sur une forte culture d’entrepreneuriat et d’innovation, et sur l’accompagnement et la montée en compétence de
ses 7800 collaborateurs
qui s’engagent chaque jour à promouvoir la complémentarité entre les technologies numériques et l’ingénierie des systèmes complexes.
Rejoignez un Groupe en fort développement en France et à travers le monde ayant réalisé un chiffre d’affaires de 600 M€ en 2023.
Tous les détails sur le Groupe sur le site https://astekgroup.fr. Et vous pouvez aussi nous suivre sur notre blog : https://blog.groupeastek.com.
Rencontrons-nous
Vous vous êtes reconnu(e) sur l’annonce et Astek vous plaît !
Julie , Talent Acquisition Officer vous contactera pour en savoir plus sur vous.
Par La Suite, 2 Échanges Maximum :
Le premier avec Mathieu (votre futur N+1, avec lequel vous échangerez autour d’ASTEK, de votre parcours, de vos attentes et de la mission)
Le second avec Anthime (Notre Directeur d’agence pour valider votre intérêt pour le poste et vous présenter les éléments contractuels).
Nos Plus
Astek est green et fait bénéficier ses salariés d’une indemnité kilométrique vélo
Une politique CARE sur-mesure déployée par nos équipes RH pour nos collaborateurs (https://astekgroup.fr/engagements)
Notre charte de la Diversité
Bienvenue dans la team ! Allez-y, maintenant c’est à vous de jouer !
Mots-clés :
ingénieur – ingénieure – consultant – consultante – big data engineer
Caractéristiques de l'emploi
Catégorie Ingénieur
Job Industry Télécom / Média
Postuler en ligne
Nom *
Prénom *
Email *
Un email valide est requis.
Téléphone *
Un numéro de téléphone valide est requis.
Joindre un CV *
Mots-clés :
ingénieur – ingénieure – consultant – consultante – big data engineer
Show more
Show less","{'ProgLanguage': ['Scala', 'R', 'Go'], 'DataBase': ['SQL', 'Cassandra'], 'DataAnalytics': ['R'], 'BigData': ['Hadoop', 'Spark'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': ['Power BI'], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git'], 'Os': ['Linux'], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': ['Chef'], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['DevOps', 'Big Data', 'Cloud'], 'FrSoftSkills': [], 'EnSoftSkils': []}","{'JobDetail': [], 'TypeContract': ['CDI'], 'Salary': [], 'Level': ['Bac+5'], 'Experience': ['a', 'n', 's', '2', '2', '2']}"
LinkedIn,Data Engineer – Grenoble,Capgemini,"Grenoble, Auvergne-Rhône-Alpes, France",https://fr.linkedin.com/jobs/view/data-engineer-%E2%80%93-grenoble-at-capgemini-3905836212?position=1&pageNum=2&refId=EunNu8klDuKd8PhUvgvx0Q%3D%3D&trackingId=rVM%2FWT4txhii7kUBqMd4jw%3D%3D&trk=public_jobs_jserp-result_search-card,"Choisir Capgemini, c'est choisir une entreprise où vous serez en mesure de façonner votre carrière selon vos aspirations. Avec le soutien et l'inspiration d'une communauté d’experts dans le monde entier, vous pourrez réécrire votre futur. Rejoignez-nous pour redéfinir les limites de ce qui est possible, contribuer à libérer la valeur de la technologie pour les plus grandes organisations et participer à la construction d’un monde plus durable et inclusif.
Vos missions :
En tant que Data Engineer au sein d'une équipe multidisciplinaire, vos responsabilités principales seront les suivantes :
Intervenir sur les différentes phases d'un projet dans un environnement Cloud et Agile.
Contribuer à la gestion de la qualité des données et extraction et analyse de celle-ci, ainsi qu’à la présentation des données dans leur forme raffinée.
Proposer des nouvelles lectures de données via un travail de fouille sur les gisements d’information, notamment client.
Adopter une posture de consultant : proposer de nouvelles solutions et accompagner le client dans ses choix.
Votre profil :
Titulaire d'un Bac+5 en école d’ingénieur ou en université.
Connaissances approfondies des ETL (Talend, Informatica ou SSIS), du traitement de données (Spark, Python, Scala) ainsi que des bases de données (Oracle, SQL Server, Postgres).
Faculté pour se montrer curieux, autonome et proactif dans la réalisation de ses tâches.
Capacité à faire preuve de rigueur et à travailler en équipe.
Bon niveau d’anglais (B2 minimum).
3 raisons de nous rejoindre :
Qualité de vie au travail
: accord de télétravail en France et à l’international, accord sur l’égalité professionnelle, la parentalité, l’équilibre des temps et la mobilité durable.
Apprentissage en continu
: certifications et formations en libre accès, accompagnement sur mesure avec votre career manager, parcours d’intégration sur 9 mois.
Avantages groupe & CSE
: plan actionnariat, tarif préférentiels, remboursement partiel vacances, remboursement de votre abonnement sportif ou culturel.
Nos engagements et priorités
:
Le groupe Capgemini encourage une culture inclusive dans un cadre multiculturel et handi-accueillant. En nous rejoignant, vous intégrez un collectif qui valorise la diversité, développe le potentiel de ses talents, s’engage dans des initiatives solidaires avec ses partenaires, et se mobilise pour réduire son impact environnemental sur tous ses sites et auprès de ses clients.
À propos de Capgemini :
Capgemini est un leader mondial, responsable et multiculturel, regroupant près de 350 000 personnes dans plus de 50 pays. Fort de 55 ans d’expérience, nous sommes un partenaire stratégique des entreprises pour la transformation de leurs activités en tirant profit de toute la puissance de la technologie et des innovations dans les domaines en perpétuelle évolution tels que le cloud, la data, l’Intelligence Artificielle, la connectivité, les logiciels, l’ingénierie digitale ou les plateformes.
Get The Future You Want* | www.capgemini.com/fr-fr
*Capgemini, le futur que vous voulez
Show more
Show less","{'ProgLanguage': ['Python', 'Scala', 'R'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': ['Spark'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git'], 'Os': [], 'DBMS': ['Oracle', 'SQL Server'], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Cloud'], 'FrSoftSkills': ['Organisation'], 'EnSoftSkils': ['Initiative']}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': ['Bac+5'], 'Experience': ['a', 'n', 's', '55', '55', '55']}"
LinkedIn,Data Engineer,eXalt Value,"Île-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-at-exalt-value-3897767649?position=2&pageNum=2&refId=EunNu8klDuKd8PhUvgvx0Q%3D%3D&trackingId=iUyZScP6JnVgtR9o6D%2Bz8w%3D%3D&trk=public_jobs_jserp-result_search-card,"eXalt
est un cabinet de conseil IT
Pure player Data
& IA basé à Paris.
Notre offre s’articule autour de 4 piliers réunis au sein d’une même communauté pour un accompagnement à 360° alliant une expertise technique et méthodologique à une approche conseil métier:
Data Gouvernance & Project
Data Engineering & Big Data
Data Performance & Analytics
Data Science & IA
Filiale du groupe eXalt, créé en 2018,
regroupant plus de
950 collaborateurs en France
(Paris, Lyon, Bordeaux, Lille, Nantes, Marseille)
et à l’international
(Colombie, Etats-Unis, Espagne, Belgique),
eXalt Value
apporte une
expertise approfondie
dans le domaine de la Data & IA et conseille les entreprises dans le déploiement de leurs stratégies data-driven.
Bénéficiant du support du groupe eXalt
(1er dans la catégorie Conseil & Audit au classement des Champions de la Croissance 2024), eXalt Value
est en pleine croissance et regroupe aujourd’hui une communauté d’expertise de plus de 60 collaborateurs en région parisienne.
Nos consultants interviennent sur d
es projets d’envergure
dans divers secteurs d’activité,
Banque & Assurance, Médias, Transports, Retail, Tourisme, etc.
Nous recherchons un
Data Engineer Confirmé H/F (minimum 4 ans d'expérience dans la fonction)
pour rejoindre notre communauté sur le
pilier Data Engineering & Big Data.
Vos missions:
Concevoir et développer des pipelines et des flux de données.
Intégrer et transformer des données provenant de différentes sources.
Développer et mettre en œuvre des algorithmes de traitement de données avancés.
Collaborer étroitement avec les équipes clients pour comprendre leurs besoins et fournir des solutions adaptées.
Assurer la qualité et la fiabilité des solutions développées.
Conseiller les équipes clients sur les solutions à mettre en place.
Les Prérequis :
Titulaire d'un Bac+5, Ecole d'Ingénieur
Maîtrise d'un ou plusieurs langages de programmation (
Python, Scala, Spark, etc
.).
Expérience approfondie des technologies
Big Data (Hadoop, Spark, Kafka, Talend, etc.)
Expérience avérée
en
environnement Cloud (AWS, GCP, ou Azure)
.
Solides compétences en conception et en optimisation de pipelines de données.
Expérience de travail en
méthode Agile
Capacité à travailler de manière autonome et en équipe.
Excellentes compétences en communication et en résolution de problèmes.
Maîtrise de l’anglais (oral & écrit dans un contexte international professionnel).
Votre environnement eXalté:
Un environnement de travail Collaboratif
favorisant les initiatives et projets transverses à la Practice Data & IA (Lab IA, Data Hub, etc.).
Un collectif de consultants passionnés,
s’intéressant aux tendances innovantes du secteur.
Une Practice de proximité,
privilégiant la montée en compétence de ses collaborateurs (formations, coachings, mentorats, etc.)
Un suivi individualisé et de proximité
par un.e Data Sales Manager référent du compte client, un.e Chargé.e RH et un.e Practice Manager
Une équipe ouverte et dynamique,
qui privilégie les moments de partage et de convivialité (séminaires, eXaltemps, meet-up, déjeuners d’équipe, etc.)
Notre processus de recrutement :
Un entretien RH avec Estelle,
à la suite duquel vous saurez tout (ou presque) d’eXalt Value,
Un entretien technique avec un Manager assorti d’un test technique,
lors duquel vous aurez l’occasion de démontrer vos talents mais aussi d’apprendre avant même de dire oui,
Un entretien final avec la Directrice Associée ou le Directeur Opérationnel,
pour finir de vous convaincre de nous rejoindre 😊
Nous avons hâte de recevoir vos CV, et de faire votre connaissance!
Show more
Show less","{'ProgLanguage': ['Python', 'Scala', 'R', 'Go'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': ['Hadoop', 'Spark'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': ['AWS', 'Azure'], 'DevTools': [], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Big Data', 'Cloud'], 'FrSoftSkills': ['Communication', 'Résolution de problèmes'], 'EnSoftSkils': ['Communication', 'Initiative']}","{'JobDetail': ['Confirmé'], 'TypeContract': [], 'Salary': [], 'Level': ['Bac+5'], 'Experience': ['a', 'n', 's', '4', '4', '4']}"
LinkedIn,Data Engineer | Python - Spark - Hadoop | Spécialisé en Big Data | Paris ou Remote Partiel,Octopus IT - Expert du recrutement tech,"Paris, Île-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-python-spark-hadoop-sp%C3%A9cialis%C3%A9-en-big-data-paris-ou-remote-partiel-at-octopus-it-expert-du-recrutement-tech-3685740787?position=3&pageNum=2&refId=EunNu8klDuKd8PhUvgvx0Q%3D%3D&trackingId=2wRnF1bj7F62V7tFqLDvzA%3D%3D&trk=public_jobs_jserp-result_search-card,"La société
Créée il y a 7 ans, cette entreprise de conseil en hyper croissance, se compose d'environ 90 personnes. Elle est devenue experte en Data et IA (NLP, Deep Learning, Machine Learning) et accompagne leurs clients sur l’ensemble de leurs projets data à travers la valorisation de leurs données.
Leur valeur ajoutée ? Leur spécialisation en Data ce qui leur permet d'offrir 3 expertises métiers distinctes : la Data Science, la Data Engineering et le Machine Learning Engineering. Autour de ces expertises gravitent bien sûr les métiers de Lead et d'Architecte.
Une autre de leur force est leur formation interne (avec des profils de seniors ou d'architectes) et externe (avec des partenaires pour passer les certifications).
Chez eux, le collaborateur est placé au centre des préoccupations, permettant ainsi de créer une cohésion et une véritable culture au sein de l'entreprise. Par exemple la majorité des projets se font en équipe et non seul.
Connu et reconnu pour leur expertise en Big Data, ils sont devenu le partenaire principal d'un grand groupe du CAC 40 et ont pris le lead sur tous les sujets touchant à la transformation Big Data de ce groupe.
Pour poursuivre leur croissance, répondre à leurs ambitions et développer de nouveaux marchés, nous recherchons plusieurs profils pour renforcer leurs effectifs.
Le poste
En les rejoignant vous travaillerez sur les problématiques suivantes :
Mise en place et/ou scale d'architectures
Construction de Datalake
Mise en production de model de ML
Pipelining de données
Streaming de données et temps réel
La stack sur laquelle vous travaillerez :
Python, Scala, Spark, Architectures distribuées : Hadoop, HDFS, Cloud : Aws, GCP, Azure
Votre profil
A partir de 3 ans d'expérience en CDI
Vous avez une expérience significative sur des problématiques Big Data
Très bonne compétences en Python et/ou Scala et en Spark
Vous êtes familier avec Hadoop, Hive, Hbase
Une logique cloud (Aws, GCP ou Azure)
Le salaire & avantages
50-60 K€ selon expérience
RTT
Carte Swile & Mutuelle
3/4 jours de télétravail par semaine
Et plus encore…
Ce qu’on préfère
Être impliqué à fond dans une aventure avec de nombreux challenges techniques
Belles opportunités d'évolutions sur des postes d'Architecte, de Lead ou de Ml Ops
Très bonne ambiance, équipe solidaire et orientée partage d’informations
Beaucoup de workshops en interne et catalogue de formations à votre guise
Ce poste a été soigneusement choisi par votre coach. Powered by Octopus IT, cabinet d’Experts en Recrutement Tech (CDI et clients finaux uniquement) – Visitez nous pour plus d’opportunités :
www.octopusit.fr
Show more
Show less","{'ProgLanguage': ['Python', 'Scala', 'R'], 'DataBase': ['HBase'], 'DataAnalytics': ['R'], 'BigData': ['Hadoop', 'Spark'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': ['AWS', 'Azure'], 'DevTools': [], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': ['HBase'], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Big Data', 'ML', 'Machine Learning', 'Cloud'], 'FrSoftSkills': [], 'EnSoftSkils': []}","{'JobDetail': ['Senior'], 'TypeContract': ['CDI'], 'Salary': ['50'], 'Level': [], 'Experience': ['a', 'n', 's', '7', '7', '7']}"
LinkedIn,Data Engineer (H/F),MP DATA,"Toulouse, Occitanie, France",https://fr.linkedin.com/jobs/view/data-engineer-h-f-at-mp-data-3908719610?position=4&pageNum=2&refId=EunNu8klDuKd8PhUvgvx0Q%3D%3D&trackingId=B0719RxYRCpvjHVP51zIXQ%3D%3D&trk=public_jobs_jserp-result_search-card,"MP DATA est une société spécialisée dans l’acquisition, le traitement, et la valorisation des données.
Depuis sa création en 2015, MP DATA accompagne ses clients, majoritairement industriels, dans le management de leur performance et l’exploitation de leurs données.
Les collaborateurs, tous issus de grandes écoles, incarnent au quotidien les valeurs d’Excellence, de Partage et d’Engagement.
Ils associent savoir-faire technique, méthodologie et passion et mettent leurs compétences au service de missions et projets au sein de grands groupes français.
MP DATA accompagne ses clients sur toute la chaine au travers de 3 pôles d’expertise : Conseil et Stratégie, Infrastructure & CloudOPS, Data Science.
Chez MP DATA, les équipes commerciales cherchent des missions en fonction des envies des collaborateurs et non pas l’inverse. Les consultants sont accompagnés dans tous leurs projets, de la mobilité géographique, au changement de secteur d’activité en passant par le développement de nouvelles compétences.
Rejoindre MP DATA, c’est la garantie de travailler sur des sujets passionnants avec un cadre technique fort.
Descriptif du poste :
Nous recherchons un Data Engineer expérimenté pour rejoindre notre équipe.
En tant que Data Engineer, vous serez responsable de la conception, du développement et de la mise en œuvre de pipelines de traitement de données en temps réel à grande échelle.
Vous travaillerez avec des technologies telles que Kafka, Flink, Kinesis et vous utiliserez les services du cloud AWS pour stocker et traiter les données.
Vos responsabilités :
Utiliser Kafka pour le traitement de flux de données en temps réel à grande échelle, en travaillant avec les producteurs, les consommateurs et les topics.
Mettre en œuvre des pipelines de traitement de données en streaming avec Flink, en appliquant des transformations complexes et en gérant les états.
Écrire du code efficace et maintenable en Java / Python pour manipuler et analyser les données en temps réel.
Utiliser Kubernetes pour déployer et gérer des applications conteneurisées à grande échelle, en assurant la résilience et l’évolutivité des services.
Utiliser les services AWS tels que Amazon S3, AWS Lambda, Elastic Kubernetes Service (EKS), Elastic Container Service (ECS) et Elastic Compute Cloud (EC2) pour le stockage, le traitement et le calcul des données en temps réel.
Suivre les meilleures pratiques pour une utilisation efficace du cloud, en assurant la gestion des coûts, la sécurité des données et la disponibilité des services.
Collaborer avec l’équipe de développement logiciel et la gestion de projets pour assurer un flux de développement fluide et une livraison efficace des fonctionnalités.
Bon à savoir :
CDI / ASAP / Toulouse
Profil recherché:
Nous recherchons un candidat diplômé d'une grande école d'Ingénieur avec une première expérience.
Compétences nécessaires :
Expérience significative dans un environnement industriel en mode DevOps, avec des outils tels que CICD, gitlab, Jenkins, Sonar, Nexus, XLdeploy, Camunda, etc.
Maîtrise des langages de programmation tels que Python, Java et expertise dans l’écriture et l’optimisation du code SQL
Maîtrise du français et bonne maitrise de l’anglais.
Capacité à travailler en équipe et esprit d’équipe.
Le processus de recrutement se déroule en 3 entretiens :
Prise de contact
1er entretien : Présentation et projet du candidat + présentation MP DATA
2ème entretien : Entretien de qualification technique
3ème entretien : Rencontre avec les équipes dans les locaux MP DATA + Proposition de collaboration
Show more
Show less","{'ProgLanguage': ['Python', 'Java', 'R'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': ['Flink'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': ['AWS'], 'DevTools': ['Git', 'Jenkins'], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': ['Kubernetes'], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': ['Kubernetes'], 'Collaboration': [], 'Other': ['DevOps', 'Cloud'], 'FrSoftSkills': ['Collaboration'], 'EnSoftSkils': ['Collaboration']}","{'JobDetail': [], 'TypeContract': ['CDI'], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's']}"
LinkedIn,Data Engineer (H/F),Technology & Strategy,"Lyon, Auvergne-Rhône-Alpes, France",https://fr.linkedin.com/jobs/view/data-engineer-h-f-at-technology-strategy-3881556102?position=5&pageNum=2&refId=EunNu8klDuKd8PhUvgvx0Q%3D%3D&trackingId=Tp%2BxV8D3CpC1FtkRjSsGJA%3D%3D&trk=public_jobs_jserp-result_search-card,"Découvrez Novencia
:
Expert en Data et Intelligence Artificielle, nous aidons nos clients à exploiter et à valoriser leurs données sous toutes ses formes en les accompagnant sur des projets de Data Analyse, Data Gourvernance, Data Architecture, Data Science, et Data Engineering…
Vous avez une solide expérience de minimum 2 ans dans l'ingénierie des données et vous êtes à la recherche de nouveaux défis ? Bouclez votre ceinture, la suite est pour vous !
Type de contrat : CDI
Lieu : Lyon
En qualité de Data Engineer (H/F), votre rôle sera :
Concevoir et proposer les solutions de développement répondant aux besoins fonctionnels et techniques des projets big data.
Tu participes à la conception de solutions permettant le traitement de volumes importants de pipelines données.
Réaliser ces solutions par l’écriture de code, en respectant les méthodes et procédures qualités définies au sein du département Technique.
Mise à disposition sécurisé et lisible de la data.
S’assurer de la conformité fonctionnelle et technique de ces réalisations en effectuant les tests automatisés nécessaire et la mise en place de monitoring (système et qualité).
Assurer la maintenance des applicatifs / plateforme data science
Assurer une veille technologique
Vous disposez des compétences suivantes :
Maitrise des plateformes Cloud (AWS, GCP ou Azure), de Scala et de SQL.
Un.e touche à tout : possédant des compétences en langage Python/Spark, de bonnes capacités de modélisation, une forte appétence pour le Big Data
Fin.e connaisseur.euse : Data Engineer convaincu, très peu de secrets pour les clusters et pour les calculs parallèles
Explorateur.trice : découvre de nouvelles technos grâce à une veille régulière
Débrouillard.e : relève de nouveaux défis
Notre objectif commun est de co-construire votre carrière en fonction de vos aspirations et de vos compétences.
Contactez-moi en message privé ou par mail à s.ziki@technologyandstrategy.com !
Let's make it possible #together
*Nos postes sont ouverts aux personnes bénéficiant d’une Reconnaissance de la Qualité de Travailleur Handicapé (RQTH). T&S Groupe encourage la diversité et l’égalité sur le lieu de travail. Tous les candidats qualifiés H/F/* sont pris en considération pour un emploi sur un même pied d'égalité.
Show more
Show less","{'ProgLanguage': ['Python', 'Scala', 'R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': ['Spark'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': ['AWS', 'Azure'], 'DevTools': [], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Big Data', 'Cloud'], 'FrSoftSkills': [], 'EnSoftSkils': []}","{'JobDetail': [], 'TypeContract': ['CDI'], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's', '2', '2', '2']}"
LinkedIn,Stage - Data Engineer - ML (H/F),Withings,"Issy-les-Moulineaux, Île-de-France, France",https://fr.linkedin.com/jobs/view/stage-data-engineer-ml-h-f-at-withings-3613476264?position=6&pageNum=2&refId=EunNu8klDuKd8PhUvgvx0Q%3D%3D&trackingId=wgKY5I%2FqN%2BXtVHXYWR5xEw%3D%3D&trk=public_jobs_jserp-result_search-card,"Chez Withings, nous développons des appareils de santé connectée : nos balances connectées, montres hybrides, tensiomètres, moniteurs de sommeil et tous les dispositifs de notre gamme sont aujourd'hui utilisés par des millions d'utilisateurs. Notre objectif est de permettre la prévention, le dépistage et l'accompagnement d'un certain nombre de maladies chroniques via des produits et des services innovants afin de révolutionner la manière dont on prend soin de notre santé.
Au sein de l'équipe Machine Learning, nous développons des algorithmes pour extraire des informations physiologiques et médicales pour nos utilisateurs tels que le SPO2, la fréquence cardiaque, la détection de diverses pathologies comme la fibrillation atriale, l'apnée du sommeil...
Intégré.e au sein de l'équipe Machine Learning, tu auras une ou plusieurs des responsabilités suivantes :
Développer un outil de monitoring de la dette technique, des mauvaises pratiques de code, des failles de sécurité ;
Construire des dashboards de visualisation ;
Construire un système d'alerte pour notifier les contributeurs d'éventuels problèmes ;
Développer des outils permettant de corriger les éventuels problèmes de façon automatisée ;
Requirements
À la recherche d'un stage d'une durée de 3 à 6 mois ;
Préparation d'un Master en école d'ingénieur ou équivalent / année de césure possible ;
Maîtrise de Python ;
Maîtrise de Debian ou de Ubuntu, de Shell et de l'environnement Linux ;
Première expérience sur du développement logiciel ;
Culture DevOps (omniprésence du monitoring, automatisation des tâches, ...)
Compréhension de la culture et des besoins des différents membres de l'équipe ;
Rigueur, autonomie, prise d'initiative, curiosité
Benefits
Rejoindre l'aventure Withings, c'est :
Intégrer un des pionniers et leaders mondiaux de la santé connectée, plusieurs fois primé au Consumer Electronic Show
Contribuer à des projets innovants et ambitieux pour la santé de demain dans un environnement agile et en constante évolution
Intégrer une entreprise internationale, membre de la FrenchTech 120, dont les équipes sont basées à Issy-les-Moulineaux, Boston, Hong-Kong et Shenzhen
Participer à l'amélioration continue de nos produits et services en les bêta-testant avant leur sortie, notamment lors de nos nombreuses sessions sportives entre collègues
Participer à la Withings Med Academy en assistant à des conférences de professionnels de santé afin de renforcer ses connaissances dans le domaine médical
Collaborer avec des collègues passionnés et célébrer ensemble chacune de nos réussites !
Toutes les candidatures reçues sont étudiées indépendamment de l'origine ethnique, des croyances, de la religion, du genre, de l'orientation sexuelle ou de la santé des candidats. Withings aspire à offrir et garantir l'égalité des chances aux candidats et seules les personnes habilitées (RH et Management) auront accès aux informations concernant votre candidature.
Show more
Show less","{'ProgLanguage': ['Python', 'R', 'Go'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': [], 'Os': ['Linux'], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['DevOps', 'Machine Learning'], 'FrSoftSkills': [], 'EnSoftSkils': ['Initiative']}","{'JobDetail': ['Hybride'], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's']}"
LinkedIn,Data Engineer,Thales,"Ollioules, Provence-Alpes-Côte d'Azur, France",https://fr.linkedin.com/jobs/view/data-engineer-at-thales-3902424527?position=7&pageNum=2&refId=EunNu8klDuKd8PhUvgvx0Q%3D%3D&trackingId=0nf93AXX17MnZHS4OFuw%2Fw%3D%3D&trk=public_jobs_jserp-result_search-card,"QUI SOMMES-NOUS ?
Thales est un leader mondial des hautes technologies comptant plus de 81 000 collaborateurs présents sur tous les continents. Le Groupe investit dans les innovations du numérique et de la « deep tech » – big data, intelligence artificielle, connectivité, cybersécurité et quantique – pour construire un avenir de confiance, essentiel au développement de nos sociétés, en plaçant l’humain au cœur des décisions.
Thales propose des solutions, services et produits qui aident ses clients – entreprises, organisations, Etats – dans cinq grands marchés vitaux pour le fonctionnement de nos sociétés : identité et sécurité numériques, défense, aéronautique, espace, et transport.
QUI ETES-VOUS ?
Diplômé d’un Bac+5 en école d’ingénieur ou équivalent universitaire avec une spécialisation en informatique, vous avez a
u moins 3 ans d'expérience
dans les technologies Big Data.
Passionné par le
secteur de la Défense et du Naval.
CE QUE NOUS POUVONS ACCOMPLIR ENSEMBLE :
En tant que
Data Engineer,
vous jouerez un rôle clé dans la conception, le développement et la maintenance de notre infrastructure de données, ainsi que dans la transformation et la gestion des flux de données.
VOS MISSIONS :
• Concevoir, développer et déployer des solutions Big Data en utilisant les technologies
Hadoop, Spark, Scala
.
• Mettre en place des pipelines de données performants pour l'ingestion, le traitement et le stockage des données massives.
• Collaborer étroitement avec les équipes métier pour comprendre leurs besoins en matière d'analyse de données et proposer des solutions adaptées.
• Optimiser les performances des clusters Hadoop pour garantir une exploitation efficace des données.
• Assurer la qualité et la fiabilité des données traitées, en mettant en place des processus de validation et de nettoyage.
• Identifier et résoudre les problèmes liés à l'infrastructure Big Data et proposer des améliorations.
Innovation, passion, ambition : rejoignez Thales et créez le monde de demain, dès aujourd’hui.
Show more
Show less","{'ProgLanguage': ['Scala', 'R'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': ['Hadoop', 'Spark'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Big Data'], 'FrSoftSkills': ['Organisation'], 'EnSoftSkils': []}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': ['Bac+5'], 'Experience': ['a', 'n', 's', '3', '3', '3']}"
LinkedIn,Data Engineer - Nantes,Capgemini,"Nantes, Pays de la Loire, France",https://fr.linkedin.com/jobs/view/data-engineer-nantes-at-capgemini-3803998213?position=8&pageNum=2&refId=EunNu8klDuKd8PhUvgvx0Q%3D%3D&trackingId=Mef8ntH2ikGhIaILEuhGJw%3D%3D&trk=public_jobs_jserp-result_search-card,"Capgemini
Choisir Capgemini, c'est choisir une entreprise où vous serez en mesure de façonner votre carrière selon vos aspirations, où vous serez soutenu et inspiré par une communauté d’experts dans le monde entier, où vous pourrez réécrire votre futur. Rejoignez-nous pour redéfinir les limites de ce qui est possible, contribuer à libérer la valeur de la technologie pour les plus grandes organisations et participez à la construction d’un monde plus durable et inclusif.
Vos missions :
Intégré(e) au sein d'une équipe projets intervenant pour des clients dans des secteurs d'activités variées, vous serez notamment en charge des missions suivantes :
Concevoir et mettre en oeuvre des stratégies sécurisées d'acquisition et d'intégration de données,
Configurer des référentiels de données à la pointe de la technologie dans des environnements distribués, majoritairement dans le cloud (Google Cloud Platform, Azure Databricks, AWS) et/ou en environnement Hadoop (distribution MapR, Cloudera, Hortonworks),
Construire des pipelines de données pour collecter, transformer et traiter des données en collaboration avec des scientifiques de données afin de répondre aux exigences de la modélisation de données d'analyse avancée.
Votre profil :
Diplôme d’ingénieur ou équivalent universitaire
Minimum 3 ans d'expérience
Anglais courant
Maîtrise des langages Java, Scala ou Python et expertise sur les framework Spark et/ou Hadoop.
Expertise sur les services Cloud Data Platform suivants : Azure Data Lake, Azure synapse, Azure Data Factory, Azure Data Explorer, GCP, AWS, Snowflake, Databricks…
3 raisons de nous rejoindre :
Qualité de vie au travail : accord de télétravail en France et à l’international, accord sur l’égalité
professionnelle, la parentalité, l’équilibre des temps et la mobilité durable.
Apprentissage en continu : certifications et formations en libre accès, accompagnement sur mesure avec votre carreer manager, parcours d’intégration sur 9 mois.
Avantages groupe & CSE : plan actionnariat, activités à tarifs préférentiels, remboursement partiel
vacances, remboursement de votre abonnement sportif ou culturel.
Nos engagements et priorités :
Le groupe Capgemini encourage une culture inclusive dans un cadre multiculturel et handi-accueillant. En nous rejoignant, vous intégrez un collectif qui valorise la diversité, développe le potentiel de ses talents, s’engage dans des initiatives solidaires avec ses partenaires, et se mobilise pour réduire son impact environnemental sur tous ses sites et auprès de ses clients.
Capgemini
Capgemini est un leader mondial, responsable et multiculturel, regroupant près de 350 000 personnes dans plus de 50 pays. Fort de 55 ans d’expérience, nous sommes un partenaire stratégique des entreprises pour la transformation de leurs activités en tirant profit de toute la puissance de la technologie et des innovations dans les domaines en perpétuelle évolution tels que le cloud, la data, l’Intelligence Artificielle, la connectivité, les logiciels, l’ingénierie digitale ou les plateformes.
Get The Future You Want* | www.capgemini.com/fr-fr
*Capgemini, le futur que vous voulez
Show more
Show less","{'ProgLanguage': ['Python', 'Java', 'Scala', 'R', 'Go'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': ['Hadoop', 'Spark', 'Databricks'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': ['AWS', 'Azure', 'Google Cloud Platform'], 'DevTools': ['Git'], 'Os': [], 'DBMS': ['Snowflake', 'Snowflake'], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Cloud'], 'FrSoftSkills': ['Collaboration', 'Organisation'], 'EnSoftSkils': ['Collaboration', 'Initiative']}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's', '3', '3', '3']}"
LinkedIn,Big Data engineer – Ingénieur des données massives (H/F),DGSE - Direction Générale de la Sécurité Extérieure,"Paris, Île-de-France, France",https://fr.linkedin.com/jobs/view/big-data-engineer-%E2%80%93-ing%C3%A9nieur-des-donn%C3%A9es-massives-h-f-at-dgse-direction-g%C3%A9n%C3%A9rale-de-la-s%C3%A9curit%C3%A9-ext%C3%A9rieure-3778473628?position=9&pageNum=2&refId=EunNu8klDuKd8PhUvgvx0Q%3D%3D&trackingId=6VmCvsOgk1%2BOB3QFaDw2dg%3D%3D&trk=public_jobs_jserp-result_search-card,"Introduction
La Direction Générale de la Sécurité Extérieure, DGSE, recrute Big Data engineer – Ingénieur des données massives (H/F).
Le poste est situé à Paris.
La nationalité française est obligatoire.
Domaine métier
Sciences et Technologies
Votre environnement de travail
Le flux de données traitées par la DGSE est équivalent à celui des GAFAM. Ces données sont au centre du travail des analystes de renseignement, qui doivent pouvoir compter sur des systèmes leur permettant de rechercher, croiser, traiter ces données, en temps réel ou en batch. Dans ce contexte, la DGSE cherche à renforcer ses équipes de traitement de la donnée massive.
Au sein d'un service centré sur le stockage, l'exploitation et la valorisation des données, nous vous proposons d'intégrer les équipes en charge des plateformes de stockage ou des traitements temps réel des données. Ces équipes pluridisciplinaires développent et maintiennent de bout en bout diverses plateformes reposant sur les technologies Kafka, Yarn, Hadoop, HBase ou encore Elasticsearch. Plus spécifiquement, l’équipe Stockage administre des entrepôts Big Data ainsi que des couches d’accès à leurs données. L’équipe Temps réel conçoit des algorithmes répondant à des besoins de temps de réaction très courts (levée d’alertes, enrichissement à la volée, réponse à des besoins opérationnels).
En nous rejoignant, vous découvrirez :
un environnement unique, qu'aucune autre structure ne peut vous proposer,
un métier proche du renseignement et de l'opérationnel,
une action sur l'intégralité de la chaîne, du développement au déploiement en production,
un minimum de 48 jours de congés par an,
une ambiance propice à l’épanouissement professionnel.
Vos missions
Les missions des équipes auxquelles vous serez amenés à contribuer seront déterminées en fonction de votre expérience et de vos appétences.
Vous serez en charge de plusieurs activités parmi les suivantes :
concevoir, implémenter et optimiser des algorithmes de traitement de données distribués (Scala, Spark, Java),
garantir le bon fonctionnement, la disponibilité et la performance des plateformes de traitement,
participer à l’évolution de l’architecture, en intégrant de nouveaux composants (frameworks, bibliothèques, …) permettant de mieux répondre aux besoins,
assurer une veille technologique constante pour rester au plus haut niveau et garantir une adéquation des clusters existants avec l’état de l’art du domaine,
contribuer à l'amélioration continue de l'équipe,
interagir avec l’équipe SRE/Devops pour améliorer la fiabilité des architectures, l’automatisation des déploiements et l'observabilité des systèmes mis en œuvre.
Votre profil
Vous êtes titulaire d’un diplôme en informatique, niveau master ou école d’ingénieur, ou pouvez démontrer une expérience équivalente.
Vous devez posséder les compétences et qualités suivantes :
bonnes connaissances fondamentales logicielles (structures de données, algorithmique, architecture),
maîtrise des langages Scala, Java ou python, vous n'avez pas peur de monter en compétences sur ceux que vous ne maîtrisez pas,
adepte de l'intégration continue, vous êtes familier de Gitlab CI, Github Actions ou Jenkins,
familier avec les bonnes pratiques de développement collaboratif (usage de git, pratique de relecture de code).
En bonus :
première expérience avec un framework de traitement en streaming (SparkStreaming, KStream, Storm, Flink, ...),
convaincu de l'importance de l'observabilité des systèmes qui regroupe métrologie, logging et tracing, vous avez déjà mis en place une stack de ce type (Prometheus, Telegraph, OpenTelemetry, Jaeger, ELK, …),
familier avec un outil de gestion de configuration (Ansible, Puppet, ...),
expérience sur les clusters Kafka, Hadoop, HBase ou Elasticsearch de plusieurs nœuds.
Les plus de l’offre
Contexte d’activités unique
Diversité des projets
Technologies à la pointe
Contact
Envoyez-nous votre candidature à l’adresse :
dgse-macandidature.cer.fct@intradef.gouv.fr
Plus d’information sur www.dgse.gouv.fr > Nous rejoindre.
RESTEZ DISCRET SUR VOTRE CANDIDATURE A LA DGSE
Show more
Show less","{'ProgLanguage': ['Python', 'Java', 'Scala', 'R', 'Go'], 'DataBase': ['HBase', 'Elasticsearch'], 'DataAnalytics': ['R'], 'BigData': ['Hadoop', 'Spark', 'Flink'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git', 'Jenkins'], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': ['HBase'], 'Automation': ['Ansible', 'Puppet'], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['DevOps', 'Big Data'], 'FrSoftSkills': [], 'EnSoftSkils': []}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's']}"
LinkedIn,Data Engineer (F/H),Aubay,"Île-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-f-h-at-aubay-3573871076?position=10&pageNum=2&refId=EunNu8klDuKd8PhUvgvx0Q%3D%3D&trackingId=Fi2i%2BPsUT%2FrkOzoKgGwkpQ%3D%3D&trk=public_jobs_jserp-result_search-card,"Passionné par la Data, tu souhaites rejoindre une communauté d’experts dans le domaine afin de développer tes compétences en Data Engineering. Aubay renforce ses équipes Data et recherche des Data Engineers pour intégrer des dispositifs de projets pointus et variés.
Ton quotidien en tant que Data Engineer chez Aubay, :
Définition de la stratégie de stockage et mise en œuvre des technologie appropriées (base de données SQL, NoSQL, stockage distribué,…)
Ingestion des données (structurées, semi-structurées ou non-structurées) selon différentes fréquences : batch, micro-batch ou temps réel
Conception et mise en œuvre de pipelines de données afin de fournir des données prêtes à l’emploi aux consommateurs : uniformisation, mise en qualité, enrichissement, calcul d’indicateurs,…
Conception et développement d’API pour exposer les données auprès d’applications tierces
Appui aux Data Scientists pour industrialiser et optimiser les algorithmes de Machine Learning
Préparation et animation d’ateliers de travail avec des interlocuteurs variés : recueil/approfondissement des besoins métiers, avancement/restitution des travaux, transfert de compétences,…
Ton profil :
Tu dispose d’une formation niveau BAC+5 (Master 2 ou école d’ingénieur) spécialisée en informatique
Tu as déjà une première expérience significative (a minima 2 ans) en Data Engineering sur des technologies Big Data
Les technologies telles que Hadoop, Spark ou Kafka sont tes technologies de prédilection
La programmation n’a plus de secret pour toi et tu maitrise parfaitement un ou plusieurs langages de programmation suivants : Java, Scala et Python
Tu maîtrises les tenants et aboutissants de la philosophie DevOps et des outils orientés CI/CD
Tu es soucieux de la qualité et de la performance de tes développements et tu t'intéresse à l’innovation frugale
Tu es un expert technique dans ton domaine sans pour autant oublier l’importance d’une communication orale et écrite de qualité et adaptée à chacun de tes interlocuteurs
Tu travaille au quotidien en mode agile et tu en maitrise les fondements
Ce qui nous caractérise :
Des missions et projets dans le domaine du Data Engineering en nombre et dans des secteurs variés (Banque, Assurance, Telecom, Industrie,…) qui permettent à nos collaborateurs de monter en compétences et de devenir des experts Data reconnus
De l’apprentissage en continu avec des formations et des certifications sur les technologies Data d’aujourd’hui et de demain
Des experts Data mobilisables pour accompagner et soutenir techniquement les collaborateurs sur leurs projets
Des communautés de savoir-faire Data proposant de manière régulière aux collaborateurs d’Aubay du contenu et des évènements de partage (webinar, meetup/afterwork, BBL,…) sur les thématiques suivantes : Data Engineering, Data Viz, Data Science/IA, Data Platform & Architecture,…
Aubay encourage la diversité sous toutes ses formes et garantit l'égalité des chances à tous les candidats. Tous nos postes sont ouverts aux personnes en situation de handicap et nous proposons tous les aménagements nécessaires.
Ta carrière chez Aubay :
Tu auras la possibilité de développer et certifier tes compétences sur les dernières technologies Data avec un focus fort sur les plateformes Data Cloud telles qu’Azure Synapse Analytics, Google Cloud Platform, Snowflake et Databricks
Tu pourras rejoindre la BU d’excellence Data et évoluer au sein d’un environnement humain et professionnel de haut niveau. Tu profiteras d’un management sur-mesure pour t'accompagner dans ta trajectoire de carrière
Au sein de la BU d’excellence, de multiples perspectives s’offriront à toi :
Rôle de « Lead » : Vous pourrez gagner en responsabilité sur le plan technologique et devenir un référent auprès de nos clients et des collaborateurs de la communauté Data Engineering
Rôle de « Champion » : Vous représenterez Aubay auprès d’un ou plusieurs de nos partenaires éditeurs stratégiques et vous participerez activement à l’animation de la relation sur le plan technologique
Rôle de « Head » : Vous pourrez prendre la responsabilité du savoir-faire Data Engineering et de ses offres et en assurer le développement au sens large (développement business, recrutement, management de collaborateurs, définition de la stratégie et animation de la communauté au sein du groupe Aubay,…)
Besoin d’en savoir plus sur le processus de recrutement ?
Un échange macro au niveau RH avec Doriane
Un entretien technique avec Marius ou Peter, deux de nos référents techniques
Un échange managérial avec le Directeur de la BU Modern BI & Data
A savoir que l’ordre des étapes peut varier selon tes envies (ex : échange managérial avec l’échange technique)
Aubay encourage la diversité sous toutes ses formes et garantit l'égalité des chances à tous les candidats. Tous nos postes sont ouverts aux personnes en situation de handicap et nous proposons tous les aménagements nécessaires.
Show more
Show less","{'ProgLanguage': ['Python', 'Java', 'Scala', 'R', 'Go'], 'DataBase': ['SQL', 'NoSQL'], 'DataAnalytics': ['R'], 'BigData': ['Hadoop', 'Spark', 'Databricks'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': ['Azure', 'Google Cloud Platform'], 'DevTools': [], 'Os': [], 'DBMS': ['Snowflake', 'Snowflake'], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['DevOps', 'Big Data', 'Machine Learning', 'Cloud', 'CI/CD'], 'FrSoftSkills': ['Communication'], 'EnSoftSkils': ['Communication']}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': ['Bac+5'], 'Experience': ['a', 'n', 's', '2', '2', '2']}"
LinkedIn,Data Engineer,Digital Waffle,"Paris, Île-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-at-digital-waffle-3913824888?position=1&pageNum=5&refId=63c0Bj1atjsufX74pWwghg%3D%3D&trackingId=CIbs7PPg0iqB6Iyk37LUGw%3D%3D&trk=public_jobs_jserp-result_search-card,"Digital Waffle is proud to have partnered with an innovative tech startup in Paris, who are looking for a talented Data Engineer to join their growing team!
They are made up of a powerhouse of experts, combining
data engineers, business process gurus, and Project managers
who leverage the most advanced solutions available; utilising process mining, automation tools, and smart execution systems.
Looking for an experienced Data Engineer (3-5 years)
What You'll Do:
This is a full-time,
hybrid role (Paris-based)
where you'll wear many hats: data exploration, system integration, data prep, data modeling, and implementing data solutions.
Experience:
Expertise in data engineering, data modeling, and ETL (Extract, Transform, Load) processes
Data warehousing and data analytics skills
Experience handling large, complex datasets
Proficiency in SQL and programming languages like Python or Java
Stellar problem-solving and analytical skills
Top-notch communication and collaboration abilities
Bachelor's or Master's in Computer Science, Information Systems, or a similar field (a plus for process mining or intelligent process automation experience)
If you are an experienced and driven Data Engineer, please apply here!
Show more
Show less","{'ProgLanguage': ['Python', 'Java', 'R'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git'], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': [], 'FrSoftSkills': ['Communication', 'Collaboration'], 'EnSoftSkils': ['Communication', 'Collaboration']}","{'JobDetail': ['Full'], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's']}"
LinkedIn,Data Engineer H/F,Ippon Technologies,Greater Nantes Metropolitan Area,https://fr.linkedin.com/jobs/view/data-engineer-h-f-at-ippon-technologies-3902436649?position=2&pageNum=5&refId=63c0Bj1atjsufX74pWwghg%3D%3D&trackingId=GH7vg4huWWuTwG0Xe%2FwWPg%3D%3D&trk=public_jobs_jserp-result_search-card,"Envie de rejoindre la communauté DATA la plus dynamique de France ?
Notre spécialité est de construire des data platform dans le Cloud public avec les meilleurs technos du moment : Snowflake, Databricks, Matillion, DBT.
Membre de la Practice Data, le/la futur(e) Data Engineer sera intégré(e) à nos équipes de conseil et sera suivi(e) par un(e) mentor qui l’aidera à monter en compétences.
Votre champs d’expertise :
Intervenir sur les data platforms de nos clients pour développer de nouveaux pipelines de données (ingestion, traitement, exposition).
Travailler en collaboration avec les métiers et les data scientists pour leur fournir un support à l’industrialisation de leurs travaux (tests, intégration continue, scalabilité des modèles, craftsmanship etc…)
Déployer des infrastructures cloud full
infra-as-code
(Terraform, CloudFormation).
Participer aux évènements internes à la communauté data (BBL, webinar, datapéro interne, meetup, blog, dojos) et externes (Salon du Big Data, GCP Summit, Spark Summit, AWS Summit, Devoxx, workshop partenaire, meetups).
Capitaliser sur les missions et les différents évènements de la communauté au travers d’articles de blogs, REX, BBL interne.
Vos connaissances :
Un framework de calcul distribué tel que Spark, Storm, Flink.
Un ou plusieurs langages de programmation (Python, Scala, Java...)
Différents systèmes de stockage de données (SQL ou NoSQL) et bien sûr le langage SQL.
La connaissance de Snowflake est bienvenue ;-)
Un framework de streaming de données tel que Kafka ou Amazon Kinesis.
Une expérience sur les technologies Cloud : AWS, GCP, Azure
Le delivery et les projets en production faisant partie de notre ADN, vous êtes capable de livrer du code de qualité dans des environnements agiles.
De plus en plus de nos projets se font en remote avec des clients du monde entier, il devient nécessaire d’être à l’aise en Anglais.
Ippon technologies c’est aussi :
👍 Bénéficier d'un suivi de proximité réalisé par votre manager technique : points réguliers pour votre suivi en mission, votre formation et votre évolution de carrière
✌️ Rejoindre une entreprise où les valeurs du sport sont nos leitmotiv : dépassement de soi, travail en équipe, bienveillance.
🗒️ Apprendre via notre programme de formation BlackBelt : https://bit.ly/3ByqcIL
😁 Travailler en pair programming ou avec un.e mentor pour gravir les échelons !
💪 Pouvoir participer à une aventure humaine au sein de notre Fondation Ippon pour réduire la fracture numérique dans le monde !
🤝 Participer à nos apéros et divers évènements internes pour consolider la cohésion d’équipe
Et après ?
Et oui alors ? Que se passe-t-il une fois que vous êtes convaincu d’avoir lu l’offre d’emploi qui vous correspond bien ?
Nous vous proposons de prendre contact et de nous rencontrer !
Les Next Steps :
1 call RH
1 échange RH
1 échange Technique
Si le match est bon des deux côtés : Hadjimé ! Vous vous lancerez sur le tatami Ippon !
Show more
Show less","{'ProgLanguage': ['Python', 'Java', 'Scala', 'R'], 'DataBase': ['SQL', 'NoSQL'], 'DataAnalytics': ['R'], 'BigData': ['Spark', 'Databricks', 'Flink'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': ['AWS', 'Azure'], 'DevTools': [], 'Os': [], 'DBMS': ['Snowflake', 'Snowflake'], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': ['Terraform', 'CloudFormation'], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Big Data', 'Cloud'], 'FrSoftSkills': ['Collaboration'], 'EnSoftSkils': ['Collaboration']}","{'JobDetail': ['Remote', 'Full'], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's']}"
LinkedIn,"Data Engineer – Antibes, France (H/F)",Astek,"Antibes, Provence-Alpes-Côte d'Azur, France",https://fr.linkedin.com/jobs/view/data-engineer-%E2%80%93-antibes-france-h-f-at-astek-3909192086?position=3&pageNum=5&refId=63c0Bj1atjsufX74pWwghg%3D%3D&trackingId=UlDBekVCS59%2Ffa2Hrk0odA%3D%3D&trk=public_jobs_jserp-result_search-card,"CDI
Antibes - France
Publiée il y a 2 semaines
Le Groupe Astek
Ce Que Nous Allons Accomplir Ensemble :
Intervenir dans la conception, le développement, les tests unitaires, la qualification, l’intégration continue et la mise en production d’évolutions sur les projets du pôle produits scoring (un pôle visant à développer des solutions permettant de générer des scores ou des segments d’information pertinents dans divers domaines, notamment : profiling TV, PUB, SAB, MMDM, Voscastview) chez l’un de nos partenaires spécialisé dans le secteur des télécoms.
Votre Mission, Si Vous L’acceptez :
En collaboration avec les autres membres de l’équipe, vous devrez prendre en charge le RUN des applications du pôle produit scoring.
Conception d’une solution se basant sur les développements existants et les besoins métiers remontés par le Product Owner.
Réalisation et développement de nouvelles fonctionnalités sur les composants des applications du pôle produits scoring et environnement CGP.
Votre Future Équipe :
Au sein d’un environnement riche et complexe, vous évoluerez avec des experts passionnés à la fois techniques et fonctionnels (Ingénieurs spécialisés, chef de projet, scrum master, product owner, analystes …).
Votre stack de jeu
D ans un environnement SAFE sous cloud GCP, Big Query, OnPrime, Grafana, Python et Ansible.
Vous ?
De formation Ingénieur, vous justifiez d’une première expérience sur un poste de Data engineer. Vous possédez des compétences d’autonomie et d’adaptabilité et vous avez une capacité à communiquer efficacement au sein d’une équipe.
Le Groupe Astek
Créé en France en 1988, Astek est un acteur mondial de l’ingénierie et du conseil en technologies. Fort de son expertise dans de nombreux secteurs industriels et tertiaires, Astek accompagne ses clients internationaux dans le déploiement intelligent de leurs produits et de leurs services, et dans la mise en œuvre de leur transformation digitale.
Depuis sa création, le Groupe a fondé son développement sur une forte culture d’entrepreneuriat et d’innovation, et sur l’accompagnement et la montée en compétence de
ses 7800 collaborateurs
qui s’engagent chaque jour à promouvoir la complémentarité entre les technologies numériques et l’ingénierie des systèmes complexes.
Rejoignez un Groupe en fort développement en France et à travers le monde ayant réalisé un chiffre d’affaires de 600 M€ en 2023.
Tous les détails sur le Groupe sur le site https://astekgroup.fr. Et vous pouvez aussi nous suivre sur notre blog : https://blog.groupeastek.com.
Rencontrons-nous
Créé en France en 1988, Astek est un acteur mondial de l’ingénierie et du conseil en technologies, présent sur les 5 continents. Fort de son expertise dans de nombreux secteurs industriels et tertiaires, Astek accompagne ses clients internationaux dans le déploiement intelligent de leurs produits et de leurs services, et dans la mise en œuvre de leur transformation digitale.
Depuis sa création, le Groupe a fondé son développement sur une forte culture d’entrepreneuriat et d’innovation, et sur l’accompagnement et la montée en compétence de ses 7800 collaborateurs qui s’engagent chaque jour à promouvoir la complémentarité entre les technologies numériques et l’ingénierie des systèmes complexes.
Rejoignez un Groupe en fort développement en France et à travers le monde et ayant réalisé un chiffre d’affaires hors
acquisitions de 600M€ en 2023.
Tous les détails sur le Groupe sur le site
Nos Plus
Astek est green et fait bénéficier ses salariés d’une indemnité kilométrique vélo
Une politique CARE sur-mesure déployée par nos équipes RH pour nos collaborateurs (https://astekgroup.fr/engagements)
Notre charte de la Diversité
Mots-clés :
ingénieur – ingénieure – consultant – consultante – Data engineer – Big Data
Caractéristiques de l'emploi
Catégorie Ingénieur
Job Industry Télécom / Média
Postuler en ligne
Nom *
Prénom *
Email *
Un email valide est requis.
Téléphone *
Un numéro de téléphone valide est requis.
Joindre un CV *
Mots-clés :
ingénieur – ingénieure – consultant – consultante – Data engineer – Big Data
Show more
Show less","{'ProgLanguage': ['Python', 'R', 'Go'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git'], 'Os': [], 'DBMS': ['Big Query'], 'SoftBigDataProcessing': [], 'Automation': ['Ansible', 'Chef'], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Big Data', 'Cloud'], 'FrSoftSkills': ['Adaptabilité', 'Collaboration'], 'EnSoftSkils': ['Collaboration']}","{'JobDetail': [], 'TypeContract': ['CDI'], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's']}"
LinkedIn,Data Engineer - Profils expérimentés H/F,LCL,"Villejuif, Île-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-profils-exp%C3%A9riment%C3%A9s-h-f-at-lcl-3888403052?position=4&pageNum=5&refId=63c0Bj1atjsufX74pWwghg%3D%3D&trackingId=gIHYgeFCEYY8kCc8uBBh3Q%3D%3D&trk=public_jobs_jserp-result_search-card,"🏦 LCL, c’est LA banque urbaine du Groupe Crédit Agricole - avec nous, accompagnez la transformation, le développement et le maintien technologiques de nos outils avec une vision business et de satisfaction de nos 6 millions de clients.
En tant qu’acteur majeur de la banque de détail, nous nous adaptons chaque jour aux nouveaux modes de consommation et les projets de nos de clients internes et externes tout en garantissant le besoin de sécurité et de développement technologique qu’impliquent nos activités.
💡Organisées en mode Agile, les 8 squads de la tribu DATA (6 squads Métier et 2 squads transverses) œuvrent au quotidien pour répondre à un enjeu majeur pour la banque : la collecte, le stockage, la gestion et l’usage de la donnée. En interaction permanente avec les autres tribus IT et les métiers, elles étudient et proposent les solutions et architectures à déployer pour répondre au mieux aux stratégies de développement et de pilotage de l’ensemble des métiers de la banque.
Rejoignez-nous si vous souhaitez participer aux réflexions et au développement de la trajectoire technique et DataCentric du SI LCL et plus largement du Groupe CA. Vous côtoierez et serez au cœur de l’implémentation de technologies variées telles que les plateformes Teradata, les solutions d’architecture applicative des technologies BigData ou IA, des environnements analytiques ou encore des solutions de datavisualisation. Vous assurerez le traitement de données en temps réel ou en batch et exposerez les données sous différentes formes.
Que vous souhaitiez devenir expert sur les socles technologiques ou relever le challenge de la gestion de projets Métier, nous vous aiderons à atteindre vos propres objectifs.
Vous rejoindrez une équipe pluridisciplinaire, clairement orientée vers le développement de ses collaborateurs à de nouvelles technologies !
🎯 En tant que Data Engineer :
· Vous aimez analyser les besoins avec les métiers, challenger, identifier les sources de données dans les différents univers technologiques, industrialiser des algorithmes, concevoir et développer des Datalab ou des Datamart sur les plateformes ? Vous saurez relever les challenges proposés par les squads métier !
· Vous préférez travailler à l’architecture et au déploiement de nouvelles plateformes, à la levée de la dette technologique ou encore réaliser de la veille au service de notre trajectoire ? La squad Socles Data est faite pour vous !
· Au-delà des projets que vous gérerez, garant du bon fonctionnement de votre parc applicatif, vous attacherez une grande attention à la mise en œuvre de solutions optimisées.
· La rigueur, la communication, l’esprit d’équipe mais aussi la curiosité et la créativité font partie de vos soft skills ! ils vous permettront de répondre aux enjeux de sécurité, de qualité, de transmission de la connaissance et contribueront à l’atteinte des objectifs de l’IT et plus largement de LCL, au service de ses clients.
💻 Voici les principales technologies utilisées au sein de la tribu, si certaines vous sont familières, nous vous aiderons à monter en compétence sur d’autres !
Langages utilisés : SQL, Python, Scala
SGBD : Teradata et utilitaires (TPT, BTEQ, …)
Streaming : Kafka
Search : ElasticSearch, SolR
Environnement : Unix
Solutions Big Data : Hadoop Cloudera, DataIku, HDFS, Hive, Impala,
Devops : GitLab, Jenkins, Nexus
Outils de visualisation : MS BI (SSIS, SSAS, SSRS) Qlik Sens, BO
Modélisation : MEGA
Outils collaboratifs : GIT, Jira, Confluence, Teams
⚡Si les nouveaux enjeux bancaires vous intéressent, que vous souhaitez intégrer une équipe Agile au service des métiers dans laquelle vous serez force de proposition et que vous aimez travailler dans un environnement motivant et dynamique, rejoignez-nous, cette offre est faite pour vous !
🔥 Les + de notre entreprise :
Accès au Plan d’épargne Groupe, intéressement et participation aux bénéfices de l’entreprise + abondement
Prix préférentiels bancaires et avantages CSE
Parcours évolutif dans l’entreprise et/ou dans le Groupe CA.S.A
Télétravail (jusqu'à 2 jours de télétravail par semaine)
De multiples commodités sur le campus (restaurants d'entreprise, salle de sport, crèche, centre médical, médiathèque...)
Forfait et avantages pratiques « mobilité durable » pour les velotafeurs
Des équipes aussi diversifiées que structurées dans une dynamique de transformation
LCL s’engage en faveur de la diversité et nous encourageons tout(e) candidat(e) ayant l’expérience requise à postuler à nos offres. Tous nos postes sont ouverts aux personnes en situation de handicap.
Nous avons encore de nombreuses raisons à vous présenter pour vous convaincre de nous rejoindre mais pour cela, il faudra postuler ici !
Show more
Show less","{'ProgLanguage': ['Python', 'Scala', 'R', 'Go'], 'DataBase': ['SQL', 'Elasticsearch'], 'DataAnalytics': ['R'], 'BigData': ['Hadoop'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git', 'Jenkins'], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': ['JIRA', 'Confluence', 'Teams'], 'Other': ['DevOps', 'Big Data', 'Cloud'], 'FrSoftSkills': ['Communication', 'Créativité'], 'EnSoftSkils': ['Communication']}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's']}"
LinkedIn,"Big Data Engineer Confirmé – Paris, France (H/F)",Astek,"Paris, Île-de-France, France",https://fr.linkedin.com/jobs/view/big-data-engineer-confirm%C3%A9-%E2%80%93-paris-france-h-f-at-astek-3839098103?position=5&pageNum=5&refId=63c0Bj1atjsufX74pWwghg%3D%3D&trackingId=%2Fgv3ywdDRdhT0vOlps7OZw%3D%3D&trk=public_jobs_jserp-result_search-card,"CDI
Paris - France
Publiée il y a 2 mois
Le Groupe Astek
Ce Que Nous Allons Accomplir Ensemble :
Nous rejoindre en tant que
Big Data Engineer Confirmé (H/F),
afin d’accompagner un opérateur télécoms, Leader en Europe dans l’assistance et le support applicatif de niveau 3 (résolution des problèmes utilisateurs, exploitation des environnements hors production).
Un challenge portant sur des millions d’utilisateurs dans un environnement technique innovant, stratégique et où l’entraide et la bonne humeur priment !
Votre Mission, Si Vous L’acceptez :
Supervision et détection et résolution des problèmes utilisateurs (développeurs, exploitants et data exploreurs)
Développement de solutions de self-service ou d’une solution de résolutions automatiques des problèmes
Qualifier les données et les résultats
Conception technique des solutions
Assurer l’accompagnement et le déploiement des évolutions des processus et outils
Accompagner la phase de mise en production
Votre Future Équipe :
Vous intégrerez une équipe à la fois technique et fonctionnel, qui œuvre chaque jour pour développer et maintenir en conditions opérationnelles l’ensemble des solutions IT !
L’équipe est en interaction avec des clients à la fois internes et externes.
Votre stack de jeu
Système d’exploitation : Linux
Outils des distributions : HDP, HDF, ELK
Environnement Big data : Hadoop, Spark,
Langage : Scala, Shell, Python
Cloud computing : GCP ou AWS
Base de données : No SQL (Cassandra, Mongo DB), Shell, Ansible
Dataviz : Power BI ou Kibana
Des notions en Réseau et Systèmes feront la différence !
Les Petits Plus Du Projet :
Vous évoluerez au sein d’une équipe impliquée et réactive et interviendrez sur un projet polyvalent et à forte valeur ajoutée.
Vous ?
Diplômé(e) d’une école d’ingénieur ou équivalent de niveau Bac+5.
Vous justifiez idéalement d’une expérience d’au moins 3 ans d’expériences sur un poste similaire ?
Vous faite preuve de proactivité et d’esprit d’équipe, êtes doté(e) d’un excellent sens de l’organisation et vous aimez les challenges et la résolution de problème ?
Alors ce poste est fait pour vous, n’hésitez plus et rejoignez l’aventure ASTEK !
Astek
Créé en France en 1988, Astek est un acteur mondial de l’ingénierie et du conseil en technologies. Fort de son expertise dans de nombreux secteurs industriels et tertiaires, Astek accompagne ses clients internationaux dans le déploiement intelligent de leurs produits et de leurs services, et dans la mise en œuvre de leur transformation digitale.
Depuis sa création, le Groupe a fondé son développement sur une forte culture d’entrepreneuriat et d’innovation, et sur l’accompagnement et la montée en compétence de
ses 7800 collaborateurs
qui s’engagent chaque jour à promouvoir la complémentarité entre les technologies numériques et l’ingénierie des systèmes complexes.
Rejoignez un Groupe en fort développement en France et à travers le monde ayant réalisé un chiffre d’affaires de 600 M€ en 2023.
Tous les détails sur le Groupe sur le site https://astekgroup.fr. Et vous pouvez aussi nous suivre sur notre blog : https://blog.groupeastek.com.
Rencontrons-nous
Notre projet commun vous plait ?
Postulez à cette annonce, et soyez transparent !
Maud, notre Talent Acquisition Referent, vous contactera pour un premier échange.
Puis vous rencontrerez Martin, votre futur manager, avec lequel vous échangerez autour d’Astek, de votre parcours, de vos attentes et de votre future mission .
Enfin, vous rencontrerez Jérémy, notre Directeur d’agence avec lequel vous pourrez valider votre intérêt et adéquation pour le poste et finaliser les éléments contractuels.
Nos Plus
Astek est green et fait bénéficier ses salariés d’une indemnité kilométrique vélo
Une politique CARE sur-mesure déployée par nos équipes RH pour nos collaborateurs (https://astekgroup.fr/engagements)
Notre charte de la Diversité
Mots-clés :
ingénieur – ingénieure – consultant – consultante – Hadoop – Scala – Data
Caractéristiques de l'emploi
Catégorie Ingénieur
Job Industry Télécom / Média
Postuler en ligne
Nom *
Prénom *
Email *
Un email valide est requis.
Téléphone *
Un numéro de téléphone valide est requis.
Joindre un CV *
Mots-clés :
ingénieur – ingénieure – consultant – consultante – Hadoop – Scala – Data
Show more
Show less","{'ProgLanguage': ['Python', 'Scala', 'R', 'Go'], 'DataBase': ['SQL', 'Cassandra'], 'DataAnalytics': ['R'], 'BigData': ['Hadoop', 'Spark'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': ['Power BI'], 'Statistics': [], 'CloudComputing': ['AWS'], 'DevTools': ['Git'], 'Os': ['Linux'], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': ['Ansible'], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Big Data', 'Cloud'], 'FrSoftSkills': ['Organisation'], 'EnSoftSkils': []}","{'JobDetail': ['Confirmé'], 'TypeContract': ['CDI'], 'Salary': [], 'Level': ['Bac+5'], 'Experience': ['a', 'n', 's', '3', '3', '3']}"
LinkedIn,Data Engineer (H/F) - Lille,Logic@l Conseils,"Lille, Hauts-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-h-f-lille-at-logic%40l-conseils-3811575649?position=6&pageNum=5&refId=63c0Bj1atjsufX74pWwghg%3D%3D&trackingId=lsnSMaZYOtp54jPBFAW7cQ%3D%3D&trk=public_jobs_jserp-result_search-card,"Dans le cadre du développement de nos activités sur la métropole Lilloise, nous recherchons un
consultant data engineer
(H/F) pour intervenir chez l'un de nos grands comptes clients.
Vos missions :
Recueillir
les besoins métiers et des équipes data
Concevoir et mettre en place les
traitements de données
Réaliser les
tests de validation
Assurer
l’alimentation du dataware
Réaliser les
ordonnancements des traitements
Etre garant de la
mise en place
, du
suivi
et de l’
exploitation
des outils déployés
Assurer
une veille technologique
régulière
Environnement technique :
Développement :
Python, Scala, R, Java,
Framework :
Spark,
Hadoop,
Outils Big data :
Yarn, Pig, Hive, Kafka, Splunk
Bases de données :
MongoDB, HBase, Cassandra
ETL :
Talend, Stambia
Plateforme :
Hortonworks, Cloudera, Map Reduce
,
AWS, GCP, Azure
Votre profil :
Vous disposez d’une expérience
d’au moins 2 ans en tant que data engineer
ou dans le domaine de l’analyse et du traitement de données.
Véritable
passionné de la data
, vous êtes
force de proposition
sur les solutions techniques à mettre en œuvre. Vous maitrisez l’anglais dans un contexte professionnel.
Compétences requises :
Analyses qualitatives et quantitatives (Intermédiaire)
Anglais (Intermédiaire)
Architecture fonctionnelle SI (Débutant)
Développement d'ouvrages, produits ou événements (Débutant)
Gestion des contrôles, tests et diagnostics (Débutant)
Gestion des risques (Intermédiaire)
Maîtrise des logiciels (Intermédiaire)
Mise en exploitation / Production et maintenance (Débutant)
Nos valeurs
Nous avons décidé de renverser la pyramide du management pour placer nos collaborateurs en tête des priorités de l’entreprise.
En effet, attaché à des valeurs fortes, telles que la proximité, la sincérité, la fidélité, la confiance et le respect, nous sommes persuadés que la réussite réside dans le bien-être de nos collaborateurs.
Cela se traduit par un accompagnement de proximité, de la transparence sans langue de bois, des échanges réguliers avec les managers référents, un accompagnement dans le développement de carrière qui est construit et jalonné avec les formations et certifications nécessaires et les missions en adéquation, pour mener à bien l’évolution de carrière.
Pour vous convaincre de nous rejoindre, nos avantages salariés complémentaires :
Environnement bienveillant et stimulant au sein de 3 pôles d’expertises
Formations et Certifications à la demande
Tickets restaurants : 13€ par ticket
Remboursement à 100 % des abonnements de transports en commun
Mutuelle frais de santé avec de hautes garanties
Prise en charge à 100% de l’assurance Prévoyance
Chèque Cadeau Culture 120 €
Compte CSE avec une cagnotte de 390 €
Compte CE : billetterie, voyages, culture, sorties, à des tarifs préférentiels
Des évènements chaque mois : activités associatives, sportives, afterwork, séminaire,
Partenariat Losc (participation aux match dans la loge VIP logical conseils – (Une Vingtaine de match par an)
Possibilité de télétravail
En intégrant Logic@l Conseils, vous participez à une réelle aventure humaine, alors pour postuler, il suffit de cliquer ci-dessous !
Tous nos postes sont ouverts, à compétences égales, aux personnes en situation de handicap.
Show more
Show less","{'ProgLanguage': ['Python', 'Java', 'Scala', 'R', 'Go'], 'DataBase': ['Cassandra', 'HBase'], 'DataAnalytics': ['R'], 'BigData': ['Hadoop', 'Spark'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': ['AWS', 'Azure'], 'DevTools': [], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': ['HBase'], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Big Data', 'Cloud'], 'FrSoftSkills': [], 'EnSoftSkils': []}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's', '2', '2', '2']}"
LinkedIn,Data Engineer,CGI,"Niort, Nouvelle-Aquitaine, France",https://fr.linkedin.com/jobs/view/data-engineer-at-cgi-3902057928?position=7&pageNum=5&refId=63c0Bj1atjsufX74pWwghg%3D%3D&trackingId=rAZwnI6BIvOJVViuEWO5Cw%3D%3D&trk=public_jobs_jserp-result_search-card,"Description de poste
Big Data, Data Science, Data analyse, Data architecture ... Ça n’a pas de secret pour vous ?
Que vous commenciez votre carrière professionnelle ou que vous soyez spécialiste de l’une de ces disciplines, intégrer notre communauté Data, c’est l’assurance de progresser, innover, partager, vous certifier et rendre service à nos clients.
Si vous souhaitez intégrer nos équipes à Niort et accompagner les plus grands acteurs du secteur des Assurances, cette annonce est susceptible de vous intéresser.
En tant que Data Engineer, vous serez responsable de la conception, du développement, de la gestion et de l'intégration des systèmes basés sur les technologies AWS, Terraform, OpenShift, Kafka et Hadoop. Ce rôle implique la mise en place d'architectures évolutives et hautement disponibles pour répondre aux besoins de traitement et de stockage de données de l'entreprise.
Fonctions et responsabilités
Vos responsabilités seront les suivantes:
-Maintenir et développer des solutions basées sur les services AWS pour le stockage, le traitement et l'analyse de données
-Utiliser les services AWS appropriés tels que Amazon EC2, S3, RDS, Lambda, etc., pour répondre aux exigences du projet.
-Créer et maintenir les configurations Terraform pour la gestion de l'infrastructure en tant que code (IaC) sur AWS
-Participer à la maintenance et à la mise en place d'environnements OpenShift pour l'hébergement d'applications et de services
-Gérer et administrer les clusters Kafka pour garantir la disponibilité, la performance et la sécurité du système de messagerie
Participer à l’assistance utilisateurs sur les briques de la plateforme Hadoop Cloudera Data
-Travailler avec les projets et les devOps pour assurer un traitement efficace des données
En rejoignant CGI, vous bénéficiez notamment d’une offre complète de formations (techniques, métiers, développement personnel,…), de flexibilité grâce à notre accord télétravail (jusqu’à 3 jours de télétravail par semaine), d’une politique de congés avantageuse (27 jours de congés payés, RTT, congés ancienneté et enfant malade,…) et d’un package d’avantages intéressant (régime d’achats d’actions, participation, CSE,...).
Qualités requises pour réussir dans ce rôle
Ayant une première expérience en tant que Data Engineer, vous avez une première expérience relative aux points suivants:
-Développement et intégration sur les technologies AWS, Terraform, OpenShift, Kafka et Hadoop
-Connaissance avancée de l'administration Kafka, y compris la configuration, la gestion et la résolution des problèmes
-Mise en œuvre de l'infrastructure en tant que code à l'aide de Terraform
-Bonne compréhension des bonnes pratiques de sécurité pour les systèmes cloud, les clusters Kafka et les plateformes Hadoop
CGI est un employeur inclusif et attentif aux candidatures des personnes en situation de handicap, à l’évolution de carrières des hommes et des femmes et au bien-être de nos salariés LGBT+. Dans un souci d’accessibilité et de clarté, le point médian n’est pas utilisé dans cette annonce. Tous les termes employés se réfèrent aussi bien au genre féminin que masculin.
Ensemble, en tant que propriétaires, mettons notre savoir-faire à l’œuvre.
La vie chez CGI est ancrée dans l’actionnariat, le travail d’équipe, le respect et un sentiment d’appartenance. Chez nous, vous pourrez exploiter votre plein potentiel parce que…
Nous vous invitons à devenir propriétaire dès le jour 1 alors que nous travaillons ensemble à faire de notre rêve une réalité. C’est pourquoi nous nous désignons comme associés de CGI, plutôt que comme employés. Nous tirons profit des retombées de notre succès collectif et contribuons activement à l’orientation et à la stratégie de notre entreprise.
Votre travail crée de la valeur. Vous élaborerez des solutions novatrices et développerez des relations durables avec vos collègues et clients, tout en ayant accès à des capacités mondiales pour concrétiser vos idées, saisir de nouvelles opportunités, et bénéficier d’une expertise sectorielle et technologique de pointe.
Vous ferez évoluer votre carrière en vous joignant à une entreprise bâtie pour croître et durer. Vous serez soutenus par des leaders qui ont votre santé et bien-être à cœur et qui vous permettront de saisir des occasions afin de parfaire vos compétences et élargir les horizons.
Joignez-vous à nous, l’une des plus importantes entreprises de conseil en technologie de l’information (TI) et en management au monde.
Show more
Show less","{'ProgLanguage': ['R'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': ['Hadoop'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': ['AWS'], 'DevTools': [], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': ['Terraform'], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': ['OpenShift'], 'Collaboration': [], 'Other': ['DevOps', 'Big Data', 'Cloud'], 'FrSoftSkills': ['Flexibilité'], 'EnSoftSkils': []}","{'JobDetail': [], 'TypeContract': [], 'Salary': ['1'], 'Level': [], 'Experience': ['a', 'n', 's']}"
LinkedIn,Data Engineer (H/F),ternair,Greater Lille Metropolitan Area,https://fr.linkedin.com/jobs/view/data-engineer-h-f-at-ternair-3915757963?position=8&pageNum=5&refId=63c0Bj1atjsufX74pWwghg%3D%3D&trackingId=fnWL1RHsXOUn1571MFK17A%3D%3D&trk=public_jobs_jserp-result_search-card,"👨‍🚀 MISSION : 👩‍🚀
En cohérence avec la stratégie d’entreprise et la roadmap data, vous aurez pour principales missions de :
En lien avec l’équipe DevOps, construire, maintenir et faire évoluer la plateforme de données;
Définir et piloter la cohérence de la collecte, la gestion et l’alimentation des données internes et externes, en différents modes : batch, streaming, API (architecture micro-services);
Préparer et mettre en qualité les données pour les rendre disponibles dans les différents environnements de travail (datalake, datawarehouse, datamart);
Vérifier la qualité des données, de leur bonne et régulière exécution ainsi que de leur utilisation adéquate (gestion des coûts);
Travailler en étroite collaboration avec les data analysts, scientists et data stewards et business de l’entreprise ;
En lien avec l’IT et la sécurité, veiller aux règles d'intégrité et de sécurité des données;
Veille technologique.
🧮 Les outils :
Plateforme data : Google Cloud Platform (Big Query, Airflow)
Développement : Github/GitLab, Docker, Terraform, Python
Analytiques : Qlik
Gestion de projet s: Jira, Confluence, Miro, Drive, Docs, Sheets, Slides
🤩 Profil recherché : 🤩
Expérience d'au moins 4-5 ans (après études) en data ingénierie (flux, modélisation, run)
A l’aise avec l’environnement Cloud et les infrastructures digitales
Communiquant, pédagogue et fortes capacités relationnelles
Anglais (à l’écrit)
Rémunération : 42-60 k€ en package selon expérience
Show more
Show less","{'ProgLanguage': ['Python', 'R', 'Go'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': ['Google Cloud Platform'], 'DevTools': ['Git', 'Docker'], 'Os': [], 'DBMS': ['Big Query'], 'SoftBigDataProcessing': [], 'Automation': ['Airflow'], 'InfrastructureAsCode': ['Terraform'], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': ['Docker'], 'Collaboration': ['JIRA', 'Confluence'], 'Other': ['DevOps', 'Cloud'], 'FrSoftSkills': ['Collaboration'], 'EnSoftSkils': ['Collaboration']}","{'JobDetail': [], 'TypeContract': [], 'Salary': ['Package'], 'Level': [], 'Experience': ['a', 'n', 's', '5', '5', '5']}"
LinkedIn,Data Solutions Engineer (Data & AI),LVMH,"Paris, Île-de-France, France",https://fr.linkedin.com/jobs/view/data-solutions-engineer-data-ai-at-lvmh-3900392289?position=9&pageNum=5&refId=63c0Bj1atjsufX74pWwghg%3D%3D&trackingId=IQD19zGtUnDkMOS73%2BJYWQ%3D%3D&trk=public_jobs_jserp-result_search-card,"LVMH is the #1 Luxury group and is currently accelerating rapidly on digitalisation. It is bringing technology and innovation in the core of the established 75+ Maisons by inventing unique and powerful products and services.
We are looking for talented solution engineers (Software, Cloud, Data and AI) to join our team and be part of this tech revolution of bringing the Group and its Maisons to the next level.
If you believe Data and AI can enhance the retail industry, from the day-to-day operational tasks to the long term customer experience,
If you think that the Cloud technologies (we love Google Cloud) is a revolution for Data and AI products,
If you like building tech solutions having direct impacts on billion-dollar-valued businesses,
If you have good communication skills and like sharing your knowledge,
Apply now, and join us!
The mission
The Solution Engineer is providing advices and technical assets to the Maisons having Data & AI projects.
Our team (Group Data team) is building a technical framework for all the Maisons to implement easily and quickly Data and AI use cases. Your mission will be to support the Maisons to convert their use case needs to concrete and production ready technical solutions using our framework and tools.
You will cover a portfolio of Maisons, in direct contact with their business analysts, data scientists and IT teams. You will be their dedicated referent on the Data & AI technical topics (Data platform, AI/ML softwares, data transport and transformations, data quality).
Main responsibilities
You will be responsible of providing support and advices to a portfolio of Maisons on Data & AI tech topics (Cloud, Data stacks, Data transformations, Data transfers, ML ops).
You will keep a recurrent discussion with the Maisons to accelerate their projects and immediately provide our support when it's needed.
You will follow-up the engaged productions in the Maisons and report them to the global group data strategy committees.
Applying the quality and security standards. Making them evolve if necessary.
Producing realistic, understandable and documented solutions following the group guidelines.
Sharing and learning from the team by communicating difficulties and successes, taking and bringing honest feedbacks and improving the identified pain points.
Taking responsibility as member of the team on the product performances (delivery and long term usage)
Required expertise and knowledge
Ability to build technical solutions answering concrete usage (User Stories) and communicate them to the team.
Dimension and evaluate complexity for technical solution productions.
Extensive knowledge and experience with good learning and sharing abilities.
Evaluate quickly risks and opportunities about technical choices.
Solid oral, written, presentation and interpersonal communication and relationship skills.
Problem-solving skills on Data and AI, coding and software development
Tech lover
Feedback taker and giver
Team player
Key benefits to join our team
Attractive packages
Offices in the 8th arrondissement near the Champs Elysées
Flexibility on the working hours
Remote work possible (~40%)
7 weeks of holidays (congés payés + RTT)
LVMH brands exclusive private sales
Great employee committee and health insurance (CE, mutuelle)
Last generation MacBooks
Part of a young, motivated and tech savvy team. Get prepared for the Thursday drinks and the tech meet-ups!
You’re eligible if
You have a strong experience (3+ years) in cloud data architecting or consultancy.
You graduated from an engineering (or equivalent) with a master’s degree. Computer Science knowledge is mandatory.
Experience on data stacks and/or Google Cloud (built in components) is a huge plus.
French and English both written and oral (Maisons are all over the world)
You’re thrilled to support the #1 luxury group to get even better.
Hiring Process
Call with our HR partner dedicated to the Tech Team
Technical interview with the Solution Engineering Manager
Technical test
Interview with the Head of Engineering
Still here? Apply now!!
Show more
Show less","{'ProgLanguage': ['R', 'Go'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git'], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': ['Teams'], 'Other': ['ML', 'Cloud'], 'FrSoftSkills': ['Communication'], 'EnSoftSkils': ['Communication', 'Flexibility']}","{'JobDetail': ['Remote'], 'TypeContract': [], 'Salary': ['40'], 'Level': [], 'Experience': ['a', 'n', 's']}"
LinkedIn,"Big Data Engineer – Secteur Télécom – Paris, France (H/F)",Astek,"Paris, Île-de-France, France",https://fr.linkedin.com/jobs/view/big-data-engineer-%E2%80%93-secteur-t%C3%A9l%C3%A9com-%E2%80%93-paris-france-h-f-at-astek-3832149765?position=10&pageNum=5&refId=63c0Bj1atjsufX74pWwghg%3D%3D&trackingId=%2Fgwdg%2BYdGKwK5zWpSPfDOg%3D%3D&trk=public_jobs_jserp-result_search-card,"CDI
Paris - France
Publiée il y a 2 semaines
Le Groupe Astek
Ce Que Nous Allons Accomplir Ensemble :
Nous rejoindre en tant que
Big Data Engineer (H/F),
afin d’accompagner un opérateur télécoms, Leader en Europe dans la gestion de ses portails clients grands publics (multimarques mobile et internet).
Un challenge portant sur des millions d’utilisateurs dans un environnement technique innovant et stratégique.
Votre Mission, Si Vous L’acceptez :
Qualifier les données et les résultats
Conception technique des solutions
Décliner les impacts de la stratégie et des innovations technologiques au sein des processus et outils de l’exploitant SI
Assurer l’accompagnement et le déploiement des évolutions des processus et outils
Contribuer aux programmes de transformation DevOps, Cloud et catalogues des offres SI
Développer des fonctions transverses et les « uses cases »
Accompagner la phase de mise en production
Votre Future Équipe :
Au sein d’un environnement riche et complexe, vous évoluerez avec des experts passionné(e)s à la fois techniques et fonctionnels (Ingénieurs spécialisées, chef de projet, scrum master, product owner, analystes…).
L’équipe est en interaction avec des clients à la fois internes et externes.
Votre stack de jeu
Système d’exploitation Linux
Big data (Hadoop, Spark, Scala)
Cloud computing (GCP…)
S QL, No SQL (Cassandra, Mongo DB)
Dataviz : Power BI ou Kibana
Des notions en développement feront la différence !
Les Petits Plus Du Projet :
Vous évoluerez au sein d’une équipe impliquée et réactive et interviendrez sur un projet polyvalent et à forte valeur ajoutée.
Vous ?
Diplômé(e) d’une
école d’ingénieur
ou équivalent de niveau Bac+5. Vous justifiez idéalement d’une expérience d’au moins 2 ans sur un poste similaire.
Ce descriptif vous interpelle ?
Alors ce poste est fait pour vous, n’hésitez plus et rejoignez l’aventure ASTEK !
Astek
Créé en France en 1988, Astek est un acteur mondial de l’ingénierie et du conseil en technologies. Fort de son expertise dans de nombreux secteurs industriels et tertiaires, Astek accompagne ses clients internationaux dans le déploiement intelligent de leurs produits et de leurs services, et dans la mise en œuvre de leur transformation digitale.
Depuis sa création, le Groupe a fondé son développement sur une forte culture d’entrepreneuriat et d’innovation, et sur l’accompagnement et la montée en compétence de
ses 7800 collaborateurs
qui s’engagent chaque jour à promouvoir la complémentarité entre les technologies numériques et l’ingénierie des systèmes complexes.
Rejoignez un Groupe en fort développement en France et à travers le monde ayant réalisé un chiffre d’affaires de 600 M€ en 2023.
Tous les détails sur le Groupe sur le site https://astekgroup.fr. Et vous pouvez aussi nous suivre sur notre blog : https://blog.groupeastek.com.
Rencontrons-nous
Vous vous êtes reconnu(e) sur l’annonce et Astek vous plaît !
Julie , Talent Acquisition Officer vous contactera pour en savoir plus sur vous.
Par La Suite, 2 Échanges Maximum :
Le premier avec Mathieu (votre futur N+1, avec lequel vous échangerez autour d’ASTEK, de votre parcours, de vos attentes et de la mission)
Le second avec Anthime (Notre Directeur d’agence pour valider votre intérêt pour le poste et vous présenter les éléments contractuels).
Nos Plus
Astek est green et fait bénéficier ses salariés d’une indemnité kilométrique vélo
Une politique CARE sur-mesure déployée par nos équipes RH pour nos collaborateurs (https://astekgroup.fr/engagements)
Notre charte de la Diversité
Bienvenue dans la team ! Allez-y, maintenant c’est à vous de jouer !
Mots-clés :
ingénieur – ingénieure – consultant – consultante – big data engineer
Caractéristiques de l'emploi
Catégorie Ingénieur
Job Industry Télécom / Média
Postuler en ligne
Nom *
Prénom *
Email *
Un email valide est requis.
Téléphone *
Un numéro de téléphone valide est requis.
Joindre un CV *
Mots-clés :
ingénieur – ingénieure – consultant – consultante – big data engineer
Show more
Show less","{'ProgLanguage': ['Scala', 'R', 'Go'], 'DataBase': ['SQL', 'Cassandra'], 'DataAnalytics': ['R'], 'BigData': ['Hadoop', 'Spark'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': ['Power BI'], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git'], 'Os': ['Linux'], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': ['Chef'], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['DevOps', 'Big Data', 'Cloud'], 'FrSoftSkills': [], 'EnSoftSkils': []}","{'JobDetail': [], 'TypeContract': ['CDI'], 'Salary': [], 'Level': ['Bac+5'], 'Experience': ['a', 'n', 's', '2', '2', '2']}"
LinkedIn,DATA ENGINEER SÉCURITÉ H/F,Akademija Oxford,"Boulogne-Billancourt, Île-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-s%C3%A9curit%C3%A9-h-f-at-akademija-oxford-3917866657?position=1&pageNum=7&refId=c6HmMlA6dBcVTsy5H43rIw%3D%3D&trackingId=Mk9nataTJV4b3v8yeh%2BlWQ%3D%3D&trk=public_jobs_jserp-result_search-card,"Une entreprise du secteur de la protection de l’environnement et basée dans les Hauts-De-Seine recherche un.e Data Engineer Sécurité dans le cadre d’un contrat d’apprentissage.
Au sein de son Data Service, votre rôle sera d’établir la stratégie des architectures data sur les aspects sécurité en lien avec la stratégie globale métier et contribuer à la déclinaison des principes du modèle de sécurité globale.
Vous devrez également élaborer des modèles de référence pour les architectures data, mais aussi contribuer à la déclinaison des politiques de sécurité en standards de sécurité opérationnels.
Show more
Show less","{'ProgLanguage': ['R'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': [], 'FrSoftSkills': [], 'EnSoftSkils': []}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's']}"
LinkedIn,Data Engineer,MindPal,"Paris, Île-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-at-mindpal-3919800161?position=2&pageNum=7&refId=c6HmMlA6dBcVTsy5H43rIw%3D%3D&trackingId=l1UUPOQsgk8%2BcVvdL4FkwA%3D%3D&trk=public_jobs_jserp-result_search-card,"We are looking for
Data Engineer!
Responsibilities
Designing, creating, and maintaining data processing systems
Analyzing and optimizing data processing workflows
Collaborating with the team to ensure data quality and efficiency
Testing and implementing new solutions
Requirements
At least 2 years of experience in designing and creating data processing systems
Proficiency in tools and programming languages related to data engineering (e.g. Hadoop, Spark, Scala, Python)
Excellent knowledge of databases and SQL language
Ability to work in a team and communicate effectively with other departments
Communicative English skills
Experience with AWS/AWS Glue is a plus
We Offer
B2B contract
Full-time job
Remote work and flexible hours
Show more
Show less","{'ProgLanguage': ['Python', 'Scala', 'R'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': ['Hadoop', 'Spark'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': ['AWS'], 'DevTools': [], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': [], 'FrSoftSkills': [], 'EnSoftSkils': []}","{'JobDetail': ['Remote', 'Full'], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's']}"
LinkedIn,Data Engineer (H/F),Web Transition,"Lille, Hauts-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-h-f-at-web-transition-3909147172?position=3&pageNum=7&refId=c6HmMlA6dBcVTsy5H43rIw%3D%3D&trackingId=WhWEfSHP6nlUfjNFUtD%2BOw%3D%3D&trk=public_jobs_jserp-result_search-card,"Web Transition, c’est qui ?
Fondée en 2011,
Web transition
est une entreprise de services numériques opérant sur le marché de l’IT/Digital !
Constituant une part essentielle de
MoOngy Digital Lab
, Web Transition accompagne ses clients grands comptes sur leurs projets de Webmarketing, de Design, Gestion de projet et également en Data !
Notre objectif : nous implanter comme un acteur principal sur le marché de la Transformation Digitale en accompagnant et valorisant les compétences de nos collaborateurs !
Nous sommes convaincus que le succès de MoOngy Digital Lab réside dans la somme des potentiels de nos équipes 🤝
Ton équipe : La tribu Data
Parce qu’il est indispensable que tu puisses partager tes connaissances mais aussi en acquérir de nouvelles, tu feras partie de l’une de nos tribus : celle de la Data. De plus, cela te permettra d’être acteur dans le développement et la stratégie de Web Transition. Ce système de co-réflexion et co-construction est un fondement essentiel chez nous !
Dans cette aventure, tu :
T’assures
de la maîtrise de la donnée et est garant de la qualité de son utilisation (référencement, normalisation, et qualification)
Travailles
à la compréhension et l'intégration des données en provenance des différents formats
des interfaces de flux
également à la définition de la politique de la donnée et à la structuration de son cycle de vie dans le respect des réglementations en vigueur
la supervision et l'intégration des données de diverse nature qui proviennent de ces sources multiples et vérifie la qualité des données qui entrent dans le Data Lake
Garantis
l'accès qualitatif aux sources de données
Facilites
l’accès aux données pour tes collègues (data scientists, data analysts…)
Assistes
les autres équipes dans l'accès et la compréhension des données des socles.
Rejoins-nous si tu as :
Expérience d’au-moins 4 ans dans la Data
Appétence à la qualité des données.
Connaissance familière des Datawarehouses.
Maitrise de Python, Oracle SQL, GCP/Power BI
Aisance avec les indicateurs, tu as une bonne capacité d'analyse et de rédaction.
Ton savoir-être :
Ouvert d’esprit
Rigoureux
Autonome
Respectueux des différences de chacun
Curieux
Proactif
Agile
Par où on commence ?
Un premier entretien RH d’1h pour comprendre ton parcours et tes aspirations
Un second entretien de 45 minutes avec l’un de nos Business Manager afin de valider tes compétences et qu’il se projette sur l’une des missions qu’il pourrait te proposer
Un troisième entretien de quelques minutes avec notre responsable d’agence pour te proposer d’intégrer notre superbe Team Web !
3 entretiens en peu de temps, si ton profil correspond tu intègreras très vite nos équipes 😉
Prêt pour embarquer dans notre grande aventure humaine ? Deviens notre futur Weber en postulant à cette offre ! Voici les avantages qui t’attendent en tant que Weber :
🤩 Des collègues incroyables
🏆 Certifiée Great Place to Work
🎮 Des bureaux sympas (où vous serez toujours les bienvenus)
🎉 Des teambuilding et évents tous les mois
💻 Des tributs métiers pour échanger entre Weber du même métier
Des missions chez le client qui sont accompagnées et coachées par ton manager
Un accompagnement dans ton plan de carrière et tes envies de re skilling
🤓 Un catalogue de formations certifiantes ouvert à tous les salariés
🍽️ Une carte tickets restaurant MyEdenred
❤️ Une mutuelle GrasSavoye
🚎 Une prise en charge des frais de transport à 100%
Show more
Show less","{'ProgLanguage': ['Python', 'R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': ['Power BI'], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git'], 'Os': [], 'DBMS': ['Oracle'], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': [], 'FrSoftSkills': [], 'EnSoftSkils': []}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's', '4', '4', '4']}"
LinkedIn,Data Engineer / Ops H/F,Chantelle,"Cachan, Île-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-ops-h-f-at-chantelle-3909858815?position=4&pageNum=7&refId=c6HmMlA6dBcVTsy5H43rIw%3D%3D&trackingId=L4rwOAa52tSFHDVPvaDZeg%3D%3D&trk=public_jobs_jserp-result_search-card,"La Direction des Systèmes d'Information et du Digital du groupe Chantelle recherche son/sa futur.e Data Engineer / Ops H/F, pour le lancement du grand chantier de rénovation de l'architecture Data : la bascule de l'intégralité de son Data Warehouse vers Google Big Query.
Vos Missions Sont Les Suivantes
Vous concevez et mettez en œuvre une infrastructure autour de Google Cloud Platform permettant de collecter, transformer, charger et historiser les données générées par l'entreprise.
Vous travaillez en étroite proximité avec le lead data engineer de l'équipe, l'équipe
intégration en charge du développement des interfaces, avec notre équipe de Data Analysts qui sont en charge d'exposer cette donnée au reste de l'entreprise ainsi qu'avec l'équipe technique en charge des infrastructures transverses.
Vous collaborez avec l'ensemble des domaines fonctionnels de la DSI (MasterData, Supply Chain, Manufacturing, B2B, et B2C, Finance ...) dans le cadre des projets menés par le Groupe.
Vous apportez l'assertivité technique sur tous les sujets d'architecture data, et êtes force de proposition, par exemple choix de mise en place de pipeline temps réels ou au contraire de flux de données en mode batch, ou bien encore stockage sur Big Query / Big Table en fonction des cas d'usage.
Vous définissez ces éléments structurants, en justifiant vos choix, et les
mettez en œuvre.
Les enjeux sont forts et les use cases nombreux à l'échelle du groupe : amélioration du pilotage de nos stocks en dimensionnant mieux nos quantités à produire et nos assortiments, par magasin, meilleure adéquation des achats matières premières vs objectifs de stocks, produits finis, personnalisation de nos sites e-commerce en temps réel en fonction de nos profils client, refonte de nos flux / Apisation, ...
Show more
Show less","{'ProgLanguage': ['R', 'Go'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': ['Google Cloud Platform'], 'DevTools': ['Git'], 'Os': [], 'DBMS': ['Big Query'], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Cloud'], 'FrSoftSkills': [], 'EnSoftSkils': []}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's']}"
LinkedIn,Data Engineer (F/H/X),Goaheadspace,"Pantin, Île-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-f-h-x-at-goaheadspace-3915359112?position=5&pageNum=7&refId=c6HmMlA6dBcVTsy5H43rIw%3D%3D&trackingId=l%2FLvWhMpcc6a1c7uxwyTjQ%3D%3D&trk=public_jobs_jserp-result_search-card,"MFG Labs est une société de conseil et réalisation experte en data, qui aide les entreprises à améliorer leurs prises de décision, à automatiser leurs processus et à créer de nouveaux services grâce à la data science, au design et à l'utilisation des dernières technologies.
MFG Labs intervient à toutes les étapes de votre transformation data : de la création d'une feuille de route de projets data, à la découverte d'insights, à la modélisation de problématiques complexes, de la création d'un modèle prédictif à l'implémentation technique d'une solution data sur-mesure
MFG Labs accompagne ses clients de différentes manières :
Stratégie
Solutions
Fondations
MFG Labs déploie une approche holistique pluridisciplinaire, en mêlant des data scientists, des designers, des data engineers et des consultants, afin d'apporter des solutions complètes de bout en bout à des problématiques complexes.
Dans le cadre du développement de l’équipe, nous recherchons un.e Data Engineer à
Pantin (magasins généraux).
Au sein de l’équipe Data Technology, vous aurez pour mission de travailler sur des problématiques de collecte de la donnée sur tout type de support digital : web, mobile, application, voire IoT.
Votre rôle au sein de l’équipe :
Faire partie d’une équipe pluridisciplinaire avec des talents en Design de Service, Consulting et Data science.
Développer des applications de production intégrant différents outils : des Mathématiques Appliqués, Machine (Deep) Learning, Recherche Opérationnelle, Statistiques.
Développer des pipelines de traitement de données avec l’équipe de Data Science pour : ingérer, transformer et délivrer des données et mod��les à nos applications.
Déployer des applications utilisant les derniers outils mis à disposition par les différents Clouds publics.
À propos de vous :
Vous êtes titulaire d'un niveau Bac +4/Bac +5 d'une école d'ingénieur
Vous avez au minimum deux ans d'expérience hors stage ou alternance
Vous êtes rigoureux·se vis-à-vis de vous-même et des autres quant à la qualité du code.
Vous avez quelques connaissances et compétences solides en développement et en en Data Ingénierie au sens large.
En
développement
Python 3 et SQL
Framework de traitement de données (Spark ou équivalent)
Docker
GIT
En +
Framework permettant de déployer des APIs (Flask ou équivalent)
CI/CD
La pratique d'au moins un cloud (AWS, GCP ou Azure) est appréciée
En Data Ingénierie
Datawarehouse ou Datalake
Data Pipelines Batch et/ou Straming
En +
Outils de BI (Tableau, Power BI…)
Outils MLOps (Sagemaker, VertexAI, etc.)
Si vous vous reconnaissez dans cette annonce, n'hésitez pas à postuler !
Show more
Show less","{'ProgLanguage': ['Python', 'R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': ['Spark'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': ['Tableau', 'Power BI'], 'Statistics': ['Statistiques'], 'CloudComputing': ['AWS', 'Azure'], 'DevTools': ['Git', 'Docker'], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': ['Docker'], 'Collaboration': [], 'Other': ['ML', 'Statistiques', 'Cloud', 'CI/CD'], 'FrSoftSkills': [], 'EnSoftSkils': []}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's']}"
LinkedIn,Data Engineer / Big Data,ALTEN,"Antibes, Provence-Alpes-Côte d'Azur, France",https://fr.linkedin.com/jobs/view/data-engineer-big-data-at-alten-3896177673?position=6&pageNum=7&refId=c6HmMlA6dBcVTsy5H43rIw%3D%3D&trackingId=y%2FMsM8w7nqJAVlPH8FLpHg%3D%3D&trk=public_jobs_jserp-result_search-card,"Alten is one of the 3 main consulting societies in France. It is present in more than 30 countries in the word. Sophia-Antipolis is the first and largest technopole in Europe, located in the South of France between Nice and Cannes, near Antibes. It’s also called the European Silicon Valley.
Reporting to our consulting team, you will work in an IT environment as an IT Business Analyst, taking part in projects in an Agile environment.
Job Description
The mission consists in taking part toprojectsthat are collecting, processing, and converting raw data into information (Flat Data + KPIs) that can be interpreted by data/business analysts.
TheData accessibilityis the ultimate goal of this mission, by enabling the Digital data users to utilize data for their business decisions.
This role is more Pipeline-centric, for which you need in-depth knowledge of distributed systems and computer science.
The mission scope will encompass the design and delivery of some key components of the Digital Data platform(Spark environment, Scala language) including following activities:
Participate to specifications reviews, propose technical solutions and perform feasibility studies.
Acquire datasets that align with business needs.
Develop algorithms to transform data into useful, actionable information.
Develop, construct, test, and maintain optimal data pipeline architectures.
Create new data validation methods and data analysis tools.
Ensure compliance with data governance and security policies.
Identify ways to improve data reliability, efficiency, and quality.
Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.
Prepare data for predictive and prescriptive modeling.
Work with data and analytics experts to strive for greater functionality in our data systems; which requires a closed collaboration with the other trains.
Develop software according to Amadeus Standards, including documentation
Perform code reviews in line with Amadeus quality standards.
Conduct unit, package and performance tests of the software and ensure a level of quality in line with the Amadeus guidelines.
Participate in the validation / acceptance phase of the product cycle ensuring the fine-tuning necessary to finalize the product.
Produce software documentation necessary for the application and issue it to the requesting departments.
Support the end user in the Production phase by debugging existing software solutions in response to Problem Tracking Records (PTR) and Change Requests (CR) issued from Product Management or Product Definition.
As part of the team, the consultant will, as well, work as DevOps, releasing the software load to production, monitoring jobs and being involved in maintenance activities. Quality analyst activities are also handled by the Devs.
Our current data platform is a MapR architecture, and we are in the process to migrate the whole platform to the Azure cloud., which is one of the key focuses for the team in the upcoming months. This will trigger easier adoption of data and foster collaboration within Amadeus around data.
Qualifications
Technical skills:
Previous experience as a data engineer or in a similar role
Experience building or optimizing “big data” data pipelines, architectures and data sets.
Hands-on experience with Scala (>2 years or a strong experience with Java/C++ with a good knowledge level of Scala)
Experience with big data tool: Spark, Kafka, MapR , Hadoop
Understanding extract, transform, and load ETL systems
Knowledge of cloud services: MS Azure
Soft skills:
Agile Mindset: must be comfortable working with Agile values and artifacts
Fast learning: must be able to adapt quickly to the existing environment and new changes
Analytical thinking and problem-solving mindset: must be able to quickly identify, implement work-around to solve incidents and work on long term data solutions
Team spirit, knowledge sharing, Empathy: must be able to work in a team and to communicate clearly with the other team members and users
Pro-activity, Professionalism, Opennessand Innovative mindset
Various:
English: professional level
Knowledge of Scrum framework and Agile methodologies.
Knowledge of airline business is a plus
Additional Information
ALTEN places the career development of the Engineers at the heart of its model and allows you to quickly take on responsibilities and evolve in line with your professional objective. It's the promise of growing your skills on concrete subjects in a project team, with a permanent contract as an ALTEN consultant!
Do you recognize yourself in this description? Then send us your CV.
Our teams will be delighted to study your application and meet you!
Show more
Show less","{'ProgLanguage': ['Java', 'C++', 'Scala', 'R', 'Go'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': ['Hadoop', 'Spark'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': ['Azure'], 'DevTools': ['Git'], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': ['Teams'], 'Other': ['DevOps', 'Big Data', 'Cloud'], 'FrSoftSkills': ['Collaboration'], 'EnSoftSkils': ['Empathy', 'Collaboration']}","{'JobDetail': [], 'TypeContract': [], 'Salary': ['2'], 'Level': [], 'Experience': ['a', 'n', 's']}"
LinkedIn,Data Engineer (H/F),Wewyse,"Paris, Île-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-h-f-at-wewyse-3912830682?position=7&pageNum=7&refId=c6HmMlA6dBcVTsy5H43rIw%3D%3D&trackingId=NaOlOQcNmnyGl8uU35Ujaw%3D%3D&trk=public_jobs_jserp-result_search-card,"Cette offre d’emploi est fournie par Pôle emploi
Description
Wewyse est un cabinet de conseil spécialisé en Data et en Intelligence Artificielle. C'est aussi et surtout une communauté de passionnés partageant l'ambition de grandir ensemble et d'ouvrir le champ des possibles dans leurs domaines. Si vous pensez que la Data et l'Intelligence Artificielle ont beaucoup à offrir au monde de demain, et si vous souhaitez apporter votre contribution à ce monde, avec humilité et enthousiasme, alors vous êtes un Wyser en puissance. Être Data Engineer chez Wewyse c'est : Intégrer une communauté d'experts Data passionnés. Recevoir et partager de la connaissance et des savoirs-faire lors de nombreux évènements. Intervenir chez des clients pour y porter l'expertise Wewyse dans des contextes et des secteurs variés. Participer à des projets innovants au sein de notre Datalab, avec des Wysers mais aussi avec des partenaires académiques et des start up. Viser l'excellence des développement en s'appuyant sur le Software craftsmanship Concevoir des architectures logicielles modernes. Penser DevOps pour l'automatisation des déploiements et la continuité des services. Être encouragé, conseillé et accompagné dans un parcours de formation adapté à vos ambitions professionnelles. Faire partie de la famille Wemanity avec ses évènements et ses multiples opportunités de carrière. Ce que nous aimons : Les personnalités ouvertes, curieuses, ambitieuses Les langages Scala, Python et Java Le cloud : AWS, GCP, Azure Les écosystèmes : Hadoop et Spark La conteneurisation : Docker et Kubernetes Les méthodes Agiles Le SQL et le NoSQL . L'approche DevOps : Jenkins, Ansible et Terraform Le versionning : Git L'anglais Vous vous reconnaissez ? Alors n'hésitez pas à postuler !
PROFIL SOUHAITÉ
Expérience
Débutant accepté
Source: Pole emploi (https://www.pole-emploi.fr)
Show more
Show less","{'ProgLanguage': ['Python', 'Java', 'Scala', 'R'], 'DataBase': ['SQL', 'NoSQL'], 'DataAnalytics': ['R'], 'BigData': ['Hadoop', 'Spark'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': ['AWS', 'Azure'], 'DevTools': ['Git', 'Docker', 'Jenkins'], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': ['Ansible', 'Kubernetes'], 'InfrastructureAsCode': ['Terraform'], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': ['Docker', 'Kubernetes'], 'Collaboration': [], 'Other': ['DevOps', 'Cloud'], 'FrSoftSkills': [], 'EnSoftSkils': []}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's']}"
LinkedIn,Data Engineer H/F,Dalkia,"Angers, Pays de la Loire, France",https://fr.linkedin.com/jobs/view/data-engineer-h-f-at-dalkia-3907349741?position=8&pageNum=7&refId=c6HmMlA6dBcVTsy5H43rIw%3D%3D&trackingId=z4UpMnjSuKlynOh279nU7Q%3D%3D&trk=public_jobs_jserp-result_search-card,"Descriptif du poste
Et si vous faisiez équipe avec nous ? Rejoindre Dalkia, c'est plus de sens et d'implication contre le réchauffement climatique ; plus de relations humaines, avec un métier de service animé par l'esprit d'équipe ; plus de technicité, avec des projets ambitieux et innovants fondés sur nos expertises ; plus d'employabilité, avec des parcours diversifiés et individualisés. Rejoindre Dalkia, c'est rejoindre plus qu'une entreprise : un collectif de 20 000 collaborateurs engagés en faveur de la transition énergétique.
Dalkia Froid Solutions, acteur majeur de la réfrigération, spécialisé dans les services énergétiques pour les process industriels et tertiaires, recherche un(e) Data Engineer
(H/F)
. Rattaché (e) au Responsable Data au sein de la Direction des Systèmes D'Informations, vous êtes le garant du bon déroulement des développements de flux de données et de leur préparation pour leur analyse. Vous aurez l'opportunité de rejoindre une équipe en construction.
Candidater chez Dalkia Froid Solutions, c’est avoir l’envie d’intégrer un grand groupe à l’esprit familial. L’humain est au cœur de nos métiers, nous donnons la chance à tous, afin de découvrir nos talents de demain. Venez renforcer notre Direction des Systèmes d'Informations et contribuez à l'optimisation énergétique à travers la data !
Vos Principales Missions
Définir l'architecture ETL et développer les jobs d'intégration de données pour notre environnement Big Data.
Assurer le monitoring quotidien des jobs et optimiser les performances de traitement.
Garantir la qualité et l'intégrité des données en industrialisant leur nettoyage.
Adapter les DataMarts pour le reporting en collaboration avec les équipes métiers : comprendre et analyser les besoins utilisateurs, et rédiger les spécifications fonctionnelles et techniques.
Vous serez également ammené à collaborer avec l'équipe Infrastructure pour définir les besoins techniques et planifier les investissements. En lien avec votre équipe vous conduirez des projets variés et participerez à la mise en oeuvre de rapports BI et de modèles de machine learning.
Lieu :
Siège Social - Angers / Télétravail possible à raison de 2 jours par semaine après période d'essaie
Votre profil
Diplômé (e) d'un bac + 5 minimum spécialisé en Data Engineer ,vous avez de bonnes qualités relationnelles afin d'accompagner le déploiement des projets. Votre rigueur et votre logique sont incontestables. Vous aimez travailler en équipe pour accompagner l'entreprise vers l'excellence opérationnelle.
Côté Outils ? Vous maitrisez les langages SQL et Pyhton et vous avez déjà pratiqué les outils DBT et GitLab. Une première expérience avec un outil de BI/Datavisualisation est souhaitée.
La connaissance des outils Qlik Sense ou Talend serait un plus!
Prêt(e) à faire une différence avec nous ? Postulez dès maintenant !
Ensemble, nous contribuons collectivement à la transition énergétique. C'est pourquoi chez Dalkia Froid Solutions, nous sommes convaincus que chacun peut participer à relever ce défi. De ce fait, chaque candidature recevra la même attention.
Show more
Show less","{'ProgLanguage': ['R'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git'], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Big Data', 'Machine Learning'], 'FrSoftSkills': ['Collaboration'], 'EnSoftSkils': ['Collaboration']}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's']}"
LinkedIn,Data Engineer,Ramify,Greater Paris Metropolitan Region,https://fr.linkedin.com/jobs/view/data-engineer-at-ramify-3896146641?position=9&pageNum=7&refId=c6HmMlA6dBcVTsy5H43rIw%3D%3D&trackingId=yafYlDeSmYQN1tAFxdDJVA%3D%3D&trk=public_jobs_jserp-result_search-card,"ABOUT
Ramify’s mission is to help people achieve financial freedom, no matter who they are and how much they have. We are revolutionizing the private wealth management industry by making smart and affordable financial products for everyone.
No more standardized solutions, hidden fees and complicated words, Ramify enables everyone to become a smart investor. The team combines elements of its research with technology to design customized investment portfolios composed of world-class financial products.
The team comprises around 15 talented individuals. Ramify is looking for talented people in all sectors, who want to have a huge impact, move fast and deliver.
JOB DESCRIPTION
The Quantitative Investment Solutions (QIS) Team is dedicated to designing innovative investment portfolio models and developing cutting-edge investment features within our product suite. Moreover, the QIS Team is at the forefront of driving AI-based solutions for Ramify. This involves conceptualizing and implementing transformative AI solutions tailored to meet the diverse needs of various teams within Ramify.
As a Data Engineer on our QIS Team, you will play a pivotal role in shaping the future of investment strategies through data-driven insights and AI-based solutions. Collaborating closely with our talented team of quantitative researchers, and investment experts, your responsibilities will encompass architecting and implementing robust data pipelines. These pipelines will facilitate the seamless integration of diverse data sources, empowering Ramify teams to make informed decision-making.
Key Responsibilities:
Design, build and launch data pipelines at scale to move data across Ramify platform with SQL technologies.
Design and implement processes and tools for data onboarding and quality, helping to deliver an industry best-practice solution for managing the data lifecycle.
Produce stand-alone tools that can be used by other teams to automate data quality and discover faults.
Build analytical tools that provide insight into business metrics across Ramify.
Architect and lead the implementation of AI based solutions within Ramify
PREFERRED EXPERIENCE
We're looking for people who:
Want to make a difference. We are a small team effectively reshaping how people look at the industry. We need people who 'get it' and want to play an integral part in helping us accomplish this mission and are persistent in getting the job done.
Skills we're looking for:
Master’s or upper-year undergraduate-level coursework in either Computer Science, Management Information Systems, Business Information Systems, Mathematics or Finance related field.
2+ years of professional experience in data engineering.
2+ years of experience with one or more coding languages such as Python (is a must), Java.
Experience with data modeling and ETL design, implementation and maintenance.
Demonstrable mastery of industry best practices in the data lifecycle, including data quality automation and tooling.
Excellent written and verbal communication skills with ability to communicate complex designs and solutions to non-technical and highly technical audiences alike.
Good attention to detail.
Strong analytics and strategic thinking skills
Nice-to-haves :
Understanding of ML/ Generative AI technologies and their applications.
Possess a passion, curiosity, and energy for finance + investing. You understand the ins and outs of the wealth management, trading, and more importantly - know how to explain these concepts simply
Show more
Show less","{'ProgLanguage': ['Python', 'Java', 'R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': ['Teams'], 'Other': ['ML'], 'FrSoftSkills': ['Communication'], 'EnSoftSkils': ['Communication']}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's']}"
LinkedIn,Data Engineer,Beelix,"Paris, Île-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-at-beelix-3865239426?position=10&pageNum=7&refId=c6HmMlA6dBcVTsy5H43rIw%3D%3D&trackingId=pX8nmXsW8q1tbsDo0F4T0A%3D%3D&trk=public_jobs_jserp-result_search-card,"Qui sommes-nous ?
Depuis 2016, nous accompagnons nos clients sur des problématiques de Product Management, Data et Design Thinking. Beelix contribue à façonner le monde de demain en participant aux grandes avancées des secteurs suivants:
🚗Automobile
⚡Energie
📡Médias & Télécoms
👗Luxe & Retail
💶 Banque, Finance & Assurance
✈️Défense
Aujourd’hui, Beelix compte plus de 200 collaborateurs motivés et dynamiques. Labélisée Great Place To work en 2023, Beelix est aussi une entreprise engagée où il fait bon vivre.
Dans le cadre de notre développement, nous recherchons un Data Engineer en Île-de-France.
Quelles missions au quotidien ?
Vous aurez pour missions principales de développer les projets Big Data demandés par le métier, et notamment :
Passer de la donnée brute à de la donnée exploitable, exposée sous forme de tables requêtables dans le Datalake
Consolider ces données au fur et à mesure de leur alimentation récurrente dans le Datalake
Les exploiter pour atteindre la finalité business (exposition de Business View, réintégration des résultats dans le SI, service de scoring, …)
De mettre en place et de garantir le respect dans la durée d'un processus qualité sur l'ensemble du cycle de DEV (documents, tests unitaires / intégration / fonctionnels, commentaires, versionning, etc.)
Accompagner les Data Engineers sur son périmètre pour garantir la qualité des livrables
Expertise souhaitée
Expertise en SPARK et PySpark
Expertise sur Databricks
Une expérience sur un cloud provider public comme Azure (idéalement), AWS, ou GCP
Connaissances avancées d'outils de BI comme PowerBI (idéalement) ou Spotfire
Capacité à interagir avec des parties prenantes diverses : Business analyst, Architectes, Métier
Etre expert dans les pratiques du Software Craftsmanship (Test Driven Development, Behavior Driven Development, Clean Code, Code Reviews, etc.)
Des Connaissances sur Azure DevOps, Azure Pipeline, GIT
Maitrise des Traitements Big Data en mode Streaming
Maitrise des Bases de données relationnelles et NoSQL
Une expérience professionnelle avec des outils comme Azure Databricks, Azure Data Lake Storage ou encore Azure Data Factory
A propos de vous ?
Diplômé d'une école d'ingénieurs ou équivalent
Au moins 3 ans d'expérience en tant que Data Engineer
Expérience en mode de Delivery Agile (Scrum, Kanban, etc.…)
Vous avez un bon niveau d’anglais tant à l’écrit qu’à l’oral
Pourquoi nous rejoindre ?
Un suivi et un accompagnement au quotidien
Un organisme de formation certifié Qualiopi, un abonnement linkedin learning pour chaque salarié et des partenariats avec des spécialistes pour d’autres expertises
De nombreux événements : Afterworks, Communautés métiers, Happy talks…
une Expérience personnalisée basée sur vos besoins grâce au Prédictive Index
Notre package « unBeelievable » : 100% du titre de transport, Tickets restaurants, CSE, Prime de participation ...
Nombreux évènements (afterworks, sport, etc) et des communautés métiers dynamiques
Le processus de recrutement ?
Échange téléphonique (15 min)
Entretien 1 RH pour apprendre à vous connaître
Entretien 2 avec votre futur N+1 pour appréhender la relation managériale
Entretien 3 avec un Responsable commercial pour avoir la vision stratégique
Show more
Show less","{'ProgLanguage': ['R'], 'DataBase': ['SQL', 'NoSQL'], 'DataAnalytics': ['R'], 'BigData': ['Spark', 'Databricks'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': ['PowerBI'], 'Statistics': [], 'CloudComputing': ['AWS', 'Azure'], 'DevTools': ['Git'], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['DevOps', 'Big Data', 'Cloud'], 'FrSoftSkills': [], 'EnSoftSkils': []}","{'JobDetail': [], 'TypeContract': [], 'Salary': ['100'], 'Level': [], 'Experience': ['a', 'n', 's', '3', '3', '3']}"
LinkedIn,Data Engineer / Data Ops,FRG Technology Consulting,"Île-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-data-ops-at-frg-technology-consulting-3913842168?position=1&pageNum=10&refId=Wt7FrOruL4%2BCplGL9tAn0A%3D%3D&trackingId=G1%2BA824Nb12%2FuKAKVjCsiA%3D%3D&trk=public_jobs_jserp-result_search-card,"Vous êtes un expert passionné par la Data et à la recherche de défis excitants ? Mon client recherche actuellement un
Data Engineer
/ Data Ops
talentueux pour rejoindre une équipe dynamique et humaine.
Missions principales :
Participation active au déploiement de la nouvelle plateforme sur Azure & Snowflake
Forte autonomie et gestion complète des projets data
Analyse des besoins actuels et futurs
Création de spécifications fonctionnelles et techniques
Modélisation de données
Développement de packages SSIS
Intégration des données dans SnowFlake & Azure,
Création de rapports avec Power BI et Excel
Profil recherché :
3 à 4 ans d'expérience
minimum
dans la BI (SSIS, SQLServer, SSAS, SSRS) et/ou le cloud (Azure , Snowflake) ainsi qu'en SQL
Compétences en
architecture sur Snowflake
fortement appréciées
1 à 2 ans d'expérience en tant que DevOps ( CI/CD ; GitLab)
Autonome, rigoureux et anglais courant
Show more
Show less","{'ProgLanguage': ['R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': ['Power BI'], 'Statistics': [], 'CloudComputing': ['Azure'], 'DevTools': ['Git'], 'Os': [], 'DBMS': ['Snowflake', 'Snowflake'], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['DevOps', 'Cloud', 'CI/CD'], 'FrSoftSkills': [], 'EnSoftSkils': []}","{'JobDetail': [], 'TypeContract': [], 'Salary': ['3'], 'Level': [], 'Experience': ['a', 'n', 's', '4', '4', '4']}"
LinkedIn,Data Engineer,ADVANCED Schema,Greater Lille Metropolitan Area,https://fr.linkedin.com/jobs/view/data-engineer-at-advanced-schema-3539059697?position=2&pageNum=10&refId=Wt7FrOruL4%2BCplGL9tAn0A%3D%3D&trackingId=xYdxyEx6HBpgfQXeuvfj1g%3D%3D&trk=public_jobs_jserp-result_search-card,"ADVANCED SCHEMA
est une société de services informatiques
spécialisée dans la donnée.
Depuis 20 ans, nous créons des plateformes data sur mesure pour nos clients, orientées usages et alliant qualité, performance, sécurité et gouvernance.
ADVANCED SCHEMA
a développé de nouvelles activités pour réaliser l'ambition du groupe : devenir
une entreprise end-to-end,
en proposant une offre à 360° à nos clients pour les
accompagner à chaque étape de leurs projets.
À ce jour, nous sommes près de 220 passionnés répartis entre Paris, Lille, Nantes, Lyon mettant à profit leur expertises aussi bien dans le domaine du retail, de la finance/assurance, du luxe, des médias, de la santé et de l'industrie.
Aujourd’hui, nous souhaitons intégrer de nouveaux renforts dans nos équipes Lilloises.
En tant que Data Engineer, vous aurez les missions suivantes :
Concevoir des modélisations physiques
Construire des mappings techniques et rédaction de spécifications d’alimentation.
Développer des flux des données
Contribuer au pilotage de projets, de proof of concepts
Participer à des missions d’expertise
Compétences professionnelles & niveau d'études requis :
Vous êtes titulaire d'un diplôme Bac +3 minimum dans le domaine de la data
Vous possédez minimum 2 ans d'expérience dans le métier
Positif(ve), curieux(se), rigoureux(se) et doté(e) d'une bonne aisance relationnelle
Être enthousiaste à l'idée d'apprendre de nouvelles technologies
Expérience de la méthodologie Agile / Scrum
Capacité à planifier et à prioriser les tâches et les activités confiées en autonomie
Maîtrise de l’anglais oral et technique obligatoire
Expérience avérée dans l'écriture de code propre avec 2 ou plusieurs des technologies suivantes : BASH, SQL, Java, Python, NoSQL
Notre proposition :
Temps plein en
CDI
avec un
salaire attractif
+ participation aux bénéfices + prime(s) sur investissement personnel
Mode de
travail hybride
(agence, site, télétravail selon projets/clients)
Ticket restaurant (Sodexo)
Mutuelle financée à 50%
Prévoyance
Comité entreprise
5 jours d’onboarding plein temps via la
ADVANCED SCHEMA Academy
Notre investissement :
Chez
ADVANCED SCHEMA
, nous t’offrons un environnement de travail stimulant et collaboratif ainsi que des possibilités de croissance et de développement professionnel. Également un
accompagnement/support au quotidien
pour te faire grandir et monter en compétences, sur des projets qui répondent à de
vrais enjeux pour nos clients
. Si tu es passionné(e) par les données et prêt(e) à relever de nouveaux défis, alors nous aussi nous aimerions te rencontrer
Process de recrutement :
Si ta candidature retient notre attention, nous te proposons :
Un premier échange téléphonique/visio
Un entretien physique (+questionnaire d’évaluation) avec un senior manager
Un entretien final à notre siège Parisien afin de rencontrer le DG
Show more
Show less","{'ProgLanguage': ['Python', 'Java', 'R', 'Go', 'Bash'], 'DataBase': ['SQL', 'NoSQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': [], 'FrSoftSkills': [], 'EnSoftSkils': []}","{'JobDetail': ['Hybride', 'Temps plein', 'Senior'], 'TypeContract': ['CDI'], 'Salary': ['50'], 'Level': [], 'Experience': ['a', 'n', 's', '20', '20', '20']}"
LinkedIn,(Senior) Data Engineer,Mirakl,"Paris, Île-de-France, France",https://fr.linkedin.com/jobs/view/senior-data-engineer-at-mirakl-3904071960?position=3&pageNum=10&refId=Wt7FrOruL4%2BCplGL9tAn0A%3D%3D&trackingId=Q7xsnmeByL9zBjTSiMtetQ%3D%3D&trk=public_jobs_jserp-result_search-card,"Mirakl, leader et pionnier de l’économie de plateforme, propose aux entreprises une suite unique de solutions leur permettant de transformer significativement leur e-commerce afin d'accélérer de façon durable et rentable leur croissance. Depuis 2012, Mirakl accompagne les entreprises B2C et B2B avec la technologie la plus avancée, sécurisée et évolutive leur permettant de digitaliser leur activité et d'élargir leur offre via la marketplace ou le dropship, faciliter la gestion des catalogues et des paiements de leurs fournisseurs pour plus d'efficacité, offrir une expérience d'achat personnalisée à leurs clients, et augmenter leurs profits grâce au retail media. Basée à Paris et Boston, Mirakl est certifiée Great Place to Work.
A propos de Mirakl Labs
Nos équipes techniques et produits, nommées Mirakl Labs, sont principalement réparties entre nos 2 hubs situés à Paris et à Bordeaux. Elles collaborent au quotidien afin d'adresser les problématiques de nos clients et utilisateurs en répondant à différents challenges liés aux nouvelles fonctionnalités, à la scalabilité, la sécurité et l’ergonomie…
Elles opèrent en mode agile et s'organisent en Squads composées d'un Squad Lead, de 5 développeurs, d'un Product Manager et d'un QA. Chaque Squad est spécialisée sur un scope fonctionnel afin de concevoir et réaliser de nouvelles features, leurs évolutions et des APIs (avec un découpage en micro-services). Nos équipes Infrastructure, Architecture, Sécurité, Documentation, Product Design, Data et Support opèrent en transverse en apportant leur expertise et de la cohérence sur l’ensemble des produits.
Toutes les équipes sont responsables de leur périmètre et chacun des collaborateurs apporte son expérience et ses idées. Innovation, feedback et implication dans les prises de décision sont au cœur de notre philosophie.
Et pour favoriser ce partage avec d’autres passionnés, nous sommes sponsors, speakers, et hôtes de différents événements, meetups, et associations de la scène Tech en France. Au cours des dernières années, nous avons participé à des événements tels que Devoxx, ReactEurope, ProductConf et Flupa UX Days.
A propos du job
La solution SaaS Mirakl est le moteur des marketplaces des plus importants e-commerçants à travers le monde. Cette solution gère et produit de gros volumes de données qui présentent des challenges extrêmement intéressants pour les spécialistes de la donnée (produits, commandes, clients, niveaux de stock, prix, messages, appels API, données de navigation, séries temporelles, données géolocalisées etc.).
En tant que (Senior) Data Engineer au sein de l’équipe Data Mirakl, vos principales missions seront de :
contribuer à l'enrichissement de la Data Platform (ETL)
améliorer la robustesse de nos pipelines de production pour nos applications Machine Learning (inférence real time etc.)
Intégré(e) dans une équipe de spécialistes de la donnée (data engineers, machine learning engineers, data scientists, data analysts), vous êtes un des acteurs clés pour garantir la place de Mirakl comme solution dominante sur son marché.
Notre stack et nos outils
Apache Spark, Kafka, AWS, Databricks, Python, Airflow, Mlflow, Tensorflow, Delta lake, Superset, Kubernetes, Redshift, SQL, Terraform, Ansible
Au quotidien, vous allez :
Participer à la définition et à l’implémentation d’une architecture performante, robuste, scalable et aux coûts maîtrisés pour nos applications Spark ainsi que pour nos pipelines de production de Machine Learning (évaluation des feature stores, refactoring de DAG Airflow)
Accompagner les Data Scientists lors de leur mise en production (relecture de code, pair programming) et mettre en place les best practices
Optimiser et améliorer la CI/CD de l’équipe en collaboration avec l’équipe SRE
Assurer la montée en compétence des membres de l’équipe sur les sujets de MLOps et Data Engineering
Réfléchir à la meilleure façon d'intégrer les données Google Analytics dans la data platform
Partager ses connaissances et présenter les travaux devant toutes les équipes Labs
Ce qu’on peut vous apporter :
Des projets data driven, divers et variés (traitements massifs d’images, de textes, time series etc.) pour des produits différents de Mirakl
Une culture orientée sur la veille technologique
Des projets qui ont un vrai impact business devant être déployés sur des centaines de clients dans un contexte multilingue
Quelques exemples de sujets en cours :
Enrichissement des données produit à partir des images et des descriptions
Modération automatique des produits
Mapping automatique des données produit
Identification des produits à fort potentiels
Détection de comportements frauduleux
Sentiment analysis sur les messages échangés entre clients et vendeurs et dans les évaluations
Détermination de prix optimaux
Monitoring de la qualité de service des vendeurs
Des applications d’inférence en synchrone de nos modèles de ML
Vous aimerez ce job si :
Vous êtes passionné(e) par la data et les technologies modernes permettant d'en tirer partie
Vous vous intéressez à la data science et avez des connaissances générales sur les algorithmes de Machine Learning
Vous avez un background en développement et avez évolué dans un environnement Data
Vous avez a minima 4 ans d’expérience en environnement Machine Learning et/ou Data
Vous avez mis en production avec succès des applications Big Data faisant appel à du Machine Learning, du NLP, du traitement d’images dans des projets d'envergure, à fort volume de données
Votre maîtrisez Python, êtes un pro des frameworks data de la fondation Apache et êtes à l'aise dans un environnement AWS
Vous maîtrisez au moins un outil d’orchestration (Airflow, Data Pipeline ou tout autre outil similaire)
Vous présentez vos travaux de manière simple et accessible
Vous faîtes preuve d'un bon relationnel et vous aimez mentorer des collaborateurs
Vous parlez couramment anglais et français
Les plus pour le poste :
Vous avez une expérience significative dans le domaine du e-commerce
Vous avez déjà mis en place un Data Lake, Data Warehouse ou une Data Platform
Vous avez déployé des applicatifs en environnement Kubernetes
Vous avez mis en place des pipelines d'ingestion de données avec une approche CDC à l'aide de Debezium ou autre
Vous maîtrisez Java/Scala
Mirakl est engagée en faveur de la diversité, de l’égalité des chances et de l’inclusion. Nous célébrons nos différences car nous sommes convaincus que les qualités visibles et invisibles de chaque Mirakl Worker sont une source de force et d’innovation. Dans le cadre de cet engagement, nous étudions toutes les candidatures sans distinction de : genre, ethnicité, religion, orientation sexuelle, handicap, âge ou toute autre caractéristique protégée par la loi.
Show more
Show less","{'ProgLanguage': ['Python', 'Java', 'Scala', 'R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': ['Spark', 'Databricks'], 'MachingLearning': ['TensorFlow'], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': ['AWS'], 'DevTools': ['Git'], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': ['Ansible', 'Kubernetes', 'Airflow'], 'InfrastructureAsCode': ['Terraform'], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': ['Kubernetes'], 'Collaboration': [], 'Other': ['Big Data', 'ML', 'Machine Learning', 'CI/CD'], 'FrSoftSkills': ['Collaboration'], 'EnSoftSkils': ['Collaboration']}","{'JobDetail': ['Senior'], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's', '4', '4', '4']}"
LinkedIn,Data Engineer (H/F),Scalian,"Valbonne, Provence-Alpes-Côte d'Azur, France",https://fr.linkedin.com/jobs/view/data-engineer-h-f-at-scalian-3819563847?position=4&pageNum=10&refId=Wt7FrOruL4%2BCplGL9tAn0A%3D%3D&trackingId=inh7goY5tExGCo%2B1yjcFcg%3D%3D&trk=public_jobs_jserp-result_search-card,"Ingénieur DATA / Data engineer (H/F)
Valbonne/Sophia-Antipolis
Type : CDI
Lieu : Locaux Scalian Sophia-Antipolis
Télétravail : En fonction des possibilités
Date de prise de poste : immédiatement ou en fonction de votre préavis
Salaire : en fonction du profil - entre 40 et 48K Brut annuels (hors avantages Scalian)
Avantages Scalian : Accord d'entreprise télétravail, Tickets restaurants, Mutuelle groupe, accord aménagement temps de travail, compte épargne temps, accord de participation et intéressement groupe, programme cooptation et apports d'affaires, accompagnement parentalité, avantages CSE
Vous êtes data engineer ou vous souhaitez le devenir !
Quel sera votre rôle ?
La portée de la mission comprend (sans toutefois s'y limiter) :
Science des données
Ingénierie des données
Analyse des données
Génie logiciel
Ce que cette expérience va vous apporter
Vous êtes autonome, vous avez le sens du service et de l’analyse, vous êtes impliqué, nous vous offrons une ouverture sur des projets complexes et une rapide évolution de carrière. Vous rejoignez notre business unit à Sophia Antipolis composée d'environ 50 consultants, avec possibilité de télétravail en fonction des sujets.
Nous co-construisons votre trajectoire professionnelle et assurons votre montée en compétences.
Nous nous inscrivons ensemble dans la durée, nous assurons votre montée en compétences et disposons d'une variété de sujets passionnants.
Ce que nous recherchons chez vous
De formation supérieure (Bac+5, école ou université), vous possédez idéalement une première expérience réussie dans ce domaine (débutants acceptés), vous aimez le travail en équipe.
Compétences requises
:
Etape d’analyse : Comprendre l’architecture technique, les sources de données, les objectifs fonctionnels.
Etape de conception : Solution de conception avec un fort centrage sur les pipelines de données et les modèles ML et l’exposition des KPI via API
Mise en œuvre : Après les phases d’analyse et de conception, procéder à a mise en œuvre dans des technologies sélectionnées (Java,Scala,Python,Spark)
Créer un code testé et documenté
Techno : Linux, Shell, Hadoop, Scrum, Python, Spark, Scala
Pourquoi feriez-vous le grand saut ?
Parce que Scalian vous accompagne dans le développement de votre carrière :
Programme d'onboarding complet sur 1 an avec votre manager et votre RH
Programme de formation (Scalian Academy, e-learning, webinaires et formations externes)
Communautés techniques (Squads, Practices) afin de valoriser et développer votre expertise
Événements internes (Afterworks, Awards Dinner, Kick Off, Live Event du COMEX, Stand Up) et externes (participation à des salons et forums spécialisés dans nos domaines d’activités…)
Dispositif d’accélération d’accès à la mobilité interne et à des échanges internationaux type Erasmus
Parce que Scalian favorise la Qualité de Vie au Travail :
Certifications Great Place to Work® et Best Workplaces for Women®
Prime de cooptation, prime vacances, prise en charge par l’employeur de 60% des titres-restaurant, Accord télétravail (jusqu’à 2,5 jours par semaine indemnisés), RTT (dont une partie monétisable), CSE (activités ludiques, chèques-cadeaux, chèques vacances)
Berceaux en crèches inter-entreprises
Don ou réception de jours de congés en cas de difficultés personnelles
Parce que Scalian développe une politique RSE concrète et ambitieuse :
Mobilité durable (indemnité kilométrique vélo, leasing de vélos à assistance électrique)
Actions environnementales (Fresque du Climat, Reforest'Action, Clean Up Day, mécénat ONF)
Postes ouverts aux personnes en situation de Handicap
Diverses politiques de diversité, d’inclusion et d’intégration mises en place
Scalian c’est aussi :
Une entreprise en très forte croissance qui, créée en 1989, compte aujourd’hui plus de 5500 personnes
Des références clients à forte valeur ajoutée auprès de grands industriels français (du CAC40) et internationaux
Un terrain de jeu où l’expertise se conjugue avec audace, liberté d’entreprendre et convivialité
Si vous aspirez à un environnement de travail qui valorise autant votre bien-être que votre développement professionnel,
rejoignez-nous et exprimez pleinement votre talent !
Envie d'élargir le cadre ?
Je suis Liza Djehel, Talent Acquisition Officer.
Si votre CV est retenu, je vous contacte pour un premier échange téléphonique de 15 à 20 minutes.
Nous déterminons ensemble si ce poste est en adéquation avec vos compétences et surtout, avec vos attentes.
L'échange est positif ? Nous convenons d'un entretien de 1h (en présentiel ou en visio) avec Lucas Daunar, Business Manager à Sophia-Antipolis. Cet échange permet de revenir en détail sur vos compétences, vos attentes, de vous présenter le poste plus en détail, et d'évoquer d'autres opportunités.
Nous prévoyons ensuite un rendez-vous technique de 1h (en présentiel ou en visio) avec un de nos responsable technique.
Enfin, nous vous présentons notre proposition d'embauche.
Notre processus de recrutement dure entre 15 et 30 jours
Show more
Show less","{'ProgLanguage': ['Python', 'Java', 'Scala', 'R'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': ['Hadoop', 'Spark'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': [], 'Os': ['Linux'], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['ML'], 'FrSoftSkills': [], 'EnSoftSkils': []}","{'JobDetail': [], 'TypeContract': ['CDI'], 'Salary': ['40'], 'Level': ['Bac+5'], 'Experience': ['a', 'n', 's']}"
LinkedIn,Data Engineer confirmé (H/F),BforBank,Greater Paris Metropolitan Region,https://fr.linkedin.com/jobs/view/data-engineer-confirm%C3%A9-h-f-at-bforbank-3918327555?position=5&pageNum=10&refId=Wt7FrOruL4%2BCplGL9tAn0A%3D%3D&trackingId=YLN7BIC2OVrtG%2B8DPUdn2Q%3D%3D&trk=public_jobs_jserp-result_search-card,"Sur le modèle d'une
""Tech company"",
BforBank place
l'humain et le digital
au cœur de sa transformation. Notre mission,
offrir à nos clients une expérience bancaire incomparable
pour répondre à leurs besoins et usages mobile. 🌟 📱
Rejoindre BforBank c’est
rejoindre une équipe engagée
dans un
grand projet de développement stratégique en France et en Europe.
Nous sommes aujourd’hui 350 passionné(e)s et
recherchons nos talents pour construire la banque de demain
. 🚀
Nous croyons en la force du collectif, chaque jour rassemblés autour de nos valeurs, de simplicité, d'optimisme et d’engagement, encourageant chacun à oser, essayer et accepter d’échouer.
🎯 Au sein de la Direction Technologie, la Data Factory a pour objectifs de piloter, définir, déployer et opérer les meilleures solutions technologiques répondant aux cas d’usage data et d’automatisations de processus de la banque au travers de plateformes. Également, la Data Factory contribue au développement des produits, à la cristallisation et à la diffusion des pratiques au sein des Squads BforBank sur les usages data dans la banque.
Tu rejoindras une squad en charge de résoudre des problématiques métiers en créant des solutions applicatives utilisant les données, des data products, avec pour finalités la prise de décision via des moteurs de calcul ou des dashboards, la création de flux réglementaires, la création de data layer ou de reportings.
🚀 Tes missions principales sont les suivantes :
· Participer aux analyses, études d’impacts et cadrage techniques
· Concevoir des solutions en respectant les bonnes pratiques d’architecture data et développement
· Réaliser le développement de nouveaux data products et assurer la maintenance évolutive et corrective des data products existants
· Rédiger la documentation technique des data products
· Assurer un support aux testeurs
· Reporter de ton activité à ta Squad et travailler dans une démarche d’efficacité collective
Concrètement tu seras amené(e) à produire les livrables suivants :
· Réaliser du code applicatif à l’état de l’art sur notre nouvelle Data Platform
· Créer des data layer et des rapports sur notre outil de Data Visualisation
· Rédiger les documentations techniques liées à ta solution, incluant le modèle de données, les procédures, l’ordonnancement
Ce que tu maîtrises :
· Maitrise des services managés de GCP (BigQuery, dataproc, dataflow, CloudSQL …)
· Maitrise du langage Python, Pandas, Spark
· Maitrise de la modélisation de base de données et du langage SQL
· Maitrise d’une chaine CI/CD (GitLab…)
· Bonne connaissance de Kafka
· Bonne connaissance d’un outil d’intégration de données type ETL (Informatica…)
· Connaissance de l’infra as code (Terraform)
· Connaissance d’un outil de reporting (Looker, BO…)
🤝 Ce poste est fait pour toi si :
· Tu es passionné(e) par la Data et leurs usages
· Tu es orienté résolution de problème, est curieux(se) et force de proposition
· Tu apprécies le travail en équipe
· Tu as un bon relationnel et est rigoureux(se)
· Tu as une bonne capacité d’analyse et rédactionnelle
· Tu t’adaptes rapidement aux changements
🎓
Formation :
Tu es diplômé(e) d’un master en école de commerce, école d’ingénieur ou équivalent.
Chez BforBank nous recherchons avant tout des compétences. Tu ne disposes pas du diplôme requis mais as des expériences équivalentes ? N'hésite pas à postuler !
💼
Expérience :
Expérience confirmée de 3 ans en tant que Data Engineer.
En rejoignant BforBank tu trouveras…
· Un projet ambitieux de transformation digitale et culturelle à l’échelon européen, terrain d’innovation et d’ouverture d’esprit
· Une organisation apprenante, proposant un large choix de formations toute l’année, et qui favorise l’échange avec les autres marques du Groupe
· Une promo RSE multi-métiers qui fait évoluer en continu les actions de BforBank vers une banque plus responsable
· Une organisation du travail en mode Agile, impliquant un degré élevé de collaboration et d'autonomie tout en travaillant avec un groupe de pairs diversifiés.
· Une Direction Technologie en pleine expansion, porteuse de nombreux défis stratégiques
Mais aussi…
De 2 jours à 5 jours de télétravail modulables par semaine, dans la limite de 84 jours par an (frais de fonctionnement pris en charge)
25 jours de congés + 16 jours de RTT
80% du coût de la mutuelle d’entreprise pris en charge / couvert
Avantages collaborateurs Crédit Agricole : taux et tarifs préférentiels
Des frais de transports remboursés à 75%
Un restaurant d’entreprise
Des douches pour les sportifs et un tarif avantageux auprès d’une salle de sport toute proche
📍 Le poste est basé à La Défense, dans des locaux flambant neufs !
BforBank s'engage à garantir l'égalité des chances aux candidats car nous sommes convaincus de la richesse apportée par la diversité et l'inclusion dans nos équipes.
Rencontrons-nous !
Le processus de recrutement se déroule en 4 étapes :
🧑🏼‍💻
Call de 30 minutes avec notre équipe Talent Acquisition
Echange avec le Data Factory Manager et notre équipe Talent Acquisition (présentiel)
Echange avec une personne de l’équipe avec qui tu seras amené à travailler (visio)
Echange avec le CTO (visio ou présentiel)
Notre processus de recrutement dure en moyenne 3 semaines et l’équipe Talent Acquisition se tiendra à ta disposition pour te donner un maximum de visibilité sur l’avancée du process.
Show more
Show less","{'ProgLanguage': ['Python', 'R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['Pandas', 'R'], 'BigData': ['Spark'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git'], 'Os': [], 'DBMS': ['BigQuery'], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': ['Terraform'], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Cloud', 'CI/CD'], 'FrSoftSkills': ['Collaboration', 'Organisation'], 'EnSoftSkils': ['Collaboration']}","{'JobDetail': ['Confirmé'], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's', '3', '3', '3']}"
LinkedIn,DATA ENGINEER,Action for Market Transformation - A4MT,"Paris, Île-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-at-action-for-market-transformation-a4mt-3910049004?position=6&pageNum=10&refId=Wt7FrOruL4%2BCplGL9tAn0A%3D%3D&trackingId=a5VzP6Z29J%2BQGi4BQ1%2F3Dg%3D%3D&trk=public_jobs_jserp-result_search-card,"A4MT – Action pour la Transformation des Marchés
A4MT conçoit et implémente des programmes d’engagement et de « Market Transformation » qui visent à généraliser des pratiques vertueuses – au sens environnemental et sociétal – en modifiant la donne du marché, en reconfigurant le jeu d’acteurs, généralement via des actions collectives.
Ces programmes agissent sur la demande en suscitant de nouvelles pratiques individuelles et collectives. A4MT assure le rôle de pilote, orchestrant les plans d’action des parties prenantes grâce à une équipe de qualité à caractère international, un savoir-faire sur la mise en œuvre des programmes, une connaissance technico-économique experte des sujets traités, et une capacité à interpeller les décideurs à bon niveau.
Championnat de France des économies d’énergie
A4MT avec ses partenaires opère l’ensemble des concours CUBE en France (Championnat de France des Economies d’Energies) et assure son développement international (Europe, Asie, etc.). CUBE est un concours original d’économies d’énergie et de CO2 pour les bâtiments tertiaires et résidentiels qui accélère fortement l’action de terrain grâce à une intelligence collective sur le terrain.
Le concours est aujourd’hui présent dans 8 pays et se développe encore. Au-delà des économies les plus faciles, il s’agit de mettre en œuvre la trajectoire de gestion immobilière et d’investissement qui permettra, au-delà des avancées dans ce programme à faible investissement, de progresser sur la trajectoire de la neutralité carbone.
https://championnatdefrancedeseconomiesdenergie.org/
MISSION
Rendant compte au directeur d’A4MT et en étroite collaboration avec le directeur technique A4MT, vous êtes Data Engineer, vous serez responsable de la conception, du développement et de la maintenance des bases de données, et des outils de reporting. Vous travaillerez en étroite collaboration avec l'équipe de développement (prestataire externe) et vous participez à la structuration d’une équipe IT interne pour créer des solutions innovantes répondant aux besoins de l'entreprise.
Votre mission s'articule autours des 3 axes ci-dessous:
1/ Pilotage et et développement
développer et déployer des reporting robustes et évolutifs.
le planning de développement et le budget alloué.
avec les équipes d’animation et le back office technique du programme et avec les prestataires externes pour comprendre les exigences et les spécifications du projet.
à la conception de l'architecture des bases de données et à la prise de décisions techniques.
la qualité des données en effectuant des contrôles qualité.
les performances des applications pour garantir une expérience utilisateur fluide.
la maintenance et les mises à jour régulières des applications existantes.
à l'affût des tendances et des technologies émergentes.
Vous serez responsable du process, de la maîtrise d’ouvrage liée à la Data et garant(e) de la qualité de service.
2/ Implication des équipes et de la sous-traitance
Vous serez impliqué dans une équipe informatique naissante et dans une équipe projet avec les différentes fonctions métiers. Vous devrez faire le suivi de votre implication avec le responsable de programme et le directeur technique d’ A4MT :
3/ Gestion de projet
Vous tiendrez le tableau de bord des outils : budgets, engagements, planning, résultats, développements.
PROFIL
Vous avez une expérience significative d’au moins 3 années dans l’écosystème de big data, des serveurs et bases de données dans des contextes de projets, d’exploitation de migration.
COMPETENCES
Bac +5 diplômé(e) d’une grande école d’ingénieur ou équivalent, vous êtes :
+5 diplômé (e) d’une école d’ingénieurs ou équivalent, en Data science, Informatique, génie logiciel ou domaine connexe.
professionnelle démontrée de 3 ans ou plus en tant que Data Engineer
des langages structurés (JavaScript, Scala, Python…),
avec les bases de données relationnelles (MySQL, PostgreSQL) et non relationnelles (MongoDB, Firebase).
au moins un outil de reporting (Power BI, Tableau …)
des services de déploiement et d'hébergement cloud comme AWS, Azure ou Google Cloud Platform.
compétences en développement back-end avec des technologies comme Node.js, Python, Ruby on Rails, ou Java. et notamment en PHP sont recommandées
des langages de programmation front-end tels que HTML5, CSS3 et JavaScript (notamment frameworks: comme React, Angular ou Vue.js).
à travailler en équipe, à communiquer efficacement et à résoudre les problèmes de manière autonome.
des principes de sécurité des applications web et des meilleures pratiques en matière de développement sécurisé ainsi que le respect du RGPD.
Date d’entrée et conditions
Le poste est à pourvoir immédiatement; il est basé au 54, rue de Clichy, Paris (IXème). Niveau de rémunération selon expérience.
Contact
Merci d’adresser votre candidature complète (CV, lettre de motivation, présentation du cursus en cours de conclusions et références éventuelles) à l’attention de M. Adrien Brunella sur le mail elisabeth.clement@a4mt.com
Show more
Show less","{'ProgLanguage': ['Python', 'Java', 'Scala', 'R', 'Go', 'JavaScript', 'HTML'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': ['Tableau', 'Power BI'], 'Statistics': [], 'CloudComputing': ['AWS', 'Azure', 'Google Cloud Platform'], 'DevTools': ['Git'], 'Os': [], 'DBMS': ['MySQL', 'PostgreSQL'], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Big Data', 'ML', 'Cloud'], 'FrSoftSkills': ['Collaboration'], 'EnSoftSkils': ['Collaboration']}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's', '3', '3', '3']}"
LinkedIn,(Senior) Data Engineer,Mirakl,France,https://fr.linkedin.com/jobs/view/senior-data-engineer-at-mirakl-3904076524?position=7&pageNum=10&refId=Wt7FrOruL4%2BCplGL9tAn0A%3D%3D&trackingId=nk2bB5vqPzMQmCDY62Tvyg%3D%3D&trk=public_jobs_jserp-result_search-card,"Mirakl, leader et pionnier de l’économie de plateforme, propose aux entreprises une suite unique de solutions leur permettant de transformer significativement leur e-commerce afin d'accélérer de façon durable et rentable leur croissance. Depuis 2012, Mirakl accompagne les entreprises B2C et B2B avec la technologie la plus avancée, sécurisée et évolutive leur permettant de digitaliser leur activité et d'élargir leur offre via la marketplace ou le dropship, faciliter la gestion des catalogues et des paiements de leurs fournisseurs pour plus d'efficacité, offrir une expérience d'achat personnalisée à leurs clients, et augmenter leurs profits grâce au retail media. Basée à Paris et Boston, Mirakl est certifiée Great Place to Work.
A propos de Mirakl Labs
Nos équipes techniques et produits, nommées Mirakl Labs, sont principalement réparties entre nos 2 hubs situés à Paris et à Bordeaux. Elles collaborent au quotidien afin d'adresser les problématiques de nos clients et utilisateurs en répondant à différents challenges liés aux nouvelles fonctionnalités, à la scalabilité, la sécurité et l’ergonomie…
Elles opèrent en mode agile et s'organisent en Squads composées d'un Squad Lead, de 5 développeurs, d'un Product Manager et d'un QA. Chaque Squad est spécialisée sur un scope fonctionnel afin de concevoir et réaliser de nouvelles features, leurs évolutions et des APIs (avec un découpage en micro-services). Nos équipes Infrastructure, Architecture, Sécurité, Documentation, Product Design, Data et Support opèrent en transverse en apportant leur expertise et de la cohérence sur l’ensemble des produits.
Toutes les équipes sont responsables de leur périmètre et chacun des collaborateurs apporte son expérience et ses idées. Innovation, feedback et implication dans les prises de décision sont au cœur de notre philosophie.
Et pour favoriser ce partage avec d’autres passionnés, nous sommes sponsors, speakers, et hôtes de différents événements, meetups, et associations de la scène Tech en France. Au cours des dernières années, nous avons participé à des événements tels que Devoxx, ReactEurope, ProductConf et Flupa UX Days.
A propos du job
La solution SaaS Mirakl est le moteur des marketplaces des plus importants e-commerçants à travers le monde. Cette solution gère et produit de gros volumes de données qui présentent des challenges extrêmement intéressants pour les spécialistes de la donnée (produits, commandes, clients, niveaux de stock, prix, messages, appels API, données de navigation, séries temporelles, données géolocalisées etc.).
En tant que (Senior) Data Engineer au sein de l’équipe Data Mirakl, vos principales missions seront de :
contribuer à l'enrichissement de la Data Platform (ETL)
améliorer la robustesse de nos pipelines de production pour nos applications Machine Learning (inférence real time etc.)
Intégré(e) dans une équipe de spécialistes de la donnée (data engineers, machine learning engineers, data scientists, data analysts), vous êtes un des acteurs clés pour garantir la place de Mirakl comme solution dominante sur son marché.
Notre stack et nos outils
Apache Spark, Kafka, AWS, Databricks, Python, Airflow, Mlflow, Tensorflow, Delta lake, Superset, Kubernetes, Redshift, SQL, Terraform, Ansible
Au quotidien, vous allez :
Participer à la définition et à l’implémentation d’une architecture performante, robuste, scalable et aux coûts maîtrisés pour nos applications Spark ainsi que pour nos pipelines de production de Machine Learning (évaluation des feature stores, refactoring de DAG Airflow)
Accompagner les Data Scientists lors de leur mise en production (relecture de code, pair programming) et mettre en place les best practices
Optimiser et améliorer la CI/CD de l’équipe en collaboration avec l’équipe SRE
Assurer la montée en compétence des membres de l’équipe sur les sujets de MLOps et Data Engineering
Réfléchir à la meilleure façon d'intégrer les données Google Analytics dans la data platform
Partager ses connaissances et présenter les travaux devant toutes les équipes Labs
Ce qu’on peut vous apporter :
Des projets data driven, divers et variés (traitements massifs d’images, de textes, time series etc.) pour des produits différents de Mirakl
Une culture orientée sur la veille technologique
Des projets qui ont un vrai impact business devant être déployés sur des centaines de clients dans un contexte multilingue
Quelques exemples de sujets en cours :
Enrichissement des données produit à partir des images et des descriptions
Modération automatique des produits
Mapping automatique des données produit
Identification des produits à fort potentiels
Détection de comportements frauduleux
Sentiment analysis sur les messages échangés entre clients et vendeurs et dans les évaluations
Détermination de prix optimaux
Monitoring de la qualité de service des vendeurs
Des applications d’inférence en synchrone de nos modèles de ML
Vous aimerez ce job si :
Vous êtes passionné(e) par la data et les technologies modernes permettant d'en tirer partie
Vous vous intéressez à la data science et avez des connaissances générales sur les algorithmes de Machine Learning
Vous avez un background en développement et avez évolué dans un environnement Data
Vous avez a minima 4 ans d’expérience en environnement Machine Learning et/ou Data
Vous avez mis en production avec succès des applications Big Data faisant appel à du Machine Learning, du NLP, du traitement d’images dans des projets d'envergure, à fort volume de données
Votre maîtrisez Python, êtes un pro des frameworks data de la fondation Apache et êtes à l'aise dans un environnement AWS
Vous maîtrisez au moins un outil d’orchestration (Airflow, Data Pipeline ou tout autre outil similaire)
Vous présentez vos travaux de manière simple et accessible
Vous faîtes preuve d'un bon relationnel et vous aimez mentorer des collaborateurs
Vous parlez couramment anglais et français
Les plus pour le poste :
Vous avez une expérience significative dans le domaine du e-commerce
Vous avez déjà mis en place un Data Lake, Data Warehouse ou une Data Platform
Vous avez déployé des applicatifs en environnement Kubernetes
Vous avez mis en place des pipelines d'ingestion de données avec une approche CDC à l'aide de Debezium ou autre
Vous maîtrisez Java/Scala
Mirakl est engagée en faveur de la diversité, de l’égalité des chances et de l’inclusion. Nous célébrons nos différences car nous sommes convaincus que les qualités visibles et invisibles de chaque Mirakl Worker sont une source de force et d’innovation. Dans le cadre de cet engagement, nous étudions toutes les candidatures sans distinction de : genre, ethnicité, religion, orientation sexuelle, handicap, âge ou toute autre caractéristique protégée par la loi.
Show more
Show less","{'ProgLanguage': ['Python', 'Java', 'Scala', 'R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': ['Spark', 'Databricks'], 'MachingLearning': ['TensorFlow'], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': ['AWS'], 'DevTools': ['Git'], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': ['Ansible', 'Kubernetes', 'Airflow'], 'InfrastructureAsCode': ['Terraform'], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': ['Kubernetes'], 'Collaboration': [], 'Other': ['Big Data', 'ML', 'Machine Learning', 'CI/CD'], 'FrSoftSkills': ['Collaboration'], 'EnSoftSkils': ['Collaboration']}","{'JobDetail': ['Senior'], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's', '4', '4', '4']}"
LinkedIn,Data Engineer Senior,AXA en France,"Hauts-de-Seine, Île-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-senior-at-axa-en-france-3884386043?position=8&pageNum=10&refId=Wt7FrOruL4%2BCplGL9tAn0A%3D%3D&trackingId=3U%2F2pMNXXaCLmgpNUaVdcg%3D%3D&trk=public_jobs_jserp-result_search-card,"Environnement
En tant que
Senior Data Engineer F/H
, vous allez contribuer directement aux projets des directions métier (ex : fraude santé, multiéquipements, pricing IARD, optimisation du lead management, fragilité auto, …) d’AXA France et à la construction du socle technique Big Data.
Vous allez intégrer une équipe d'une dizaine de personne composée de Data Engineer et des Tech Lead travaillant en mode Feature Team au sein des tribus métier de la Direction Transformation Digital Tech et DATA (DT2).
La Direction Transformation Digital Tech et DATA d'AXA France en quelques mots :
- Une organisation agile en feature teams : tribus, guildes, squads
- Des projets sur des applications innovantes à fort trafic (web, mobile…)
- Des méthodologies craft (TDD, BDD, clean code, code review…) et DevOps
- Une communauté de partage de bonnes pratiques (BBL, dojo, meetup, conf…)
Votre rôle et vos missions
Vous aurez pour missions principales de développer les projets Big Data demandés par le métier, et notamment :
Passer de la donnée brute à de la donnée exploitable, exposée sous forme de tables requêtables dans le datalake
Consolider ces données au fur et à mesure de leur alimentation récurrente dans le data lake
Les exploiter pour atteindre la finalité business (exposition de business view, réintégration des résultats dans le SI, service de scoring, …)
De travailler à la création du socle technique Big Data et industrialiser le cycle de développement de l'équipe
De mettre en place et de garantir le respect dans la durée d'un processus qualité sur l'ensemble du cycle de DEV (documents, tests unitaires / intégration / fonctionnels, commentaires, versionning, etc.)
Votre profil
Vous justifiez de plusieurs expériences significatives (+ de 5 ans) sur du
développement big data, en particulier sur du PySpark.
Compétences techniques :
Connaissances avancées en développement en
PySpark
(Spark avec le langage Python)
Maitrise de l'environnement
Microsoft Azure
Connaissances avancées d'outils de BI comme
PowerBI
Compétences transverses :
Capacité à interagir avec des parties prenantes diverses : Business analyst, Architectes, Métier
Expérience en mode de delivery Agile (Scrum, Kanban, etc...)
Driver et accompagner des Data Engineer junior sur les aspects technique
Et Idéalement :
Des Connaissances sur Azure DevOps, Azure Pipeline, GIT, JIRA
Maitrise des Traitements Big Data en mode Streaming
Maitrise des Bases de données relationnelles et NoSQL
Une expérience professionnelle avec des outils comme Azure Databricks, Azure Data Lake Storage ou encore Azure Data Factory
Qui sommes nous ?
AXA est un des leaders de l’assurance et de la gestion d’actifs dans le monde.
Nous aidons nos 108 millions de clients à traverser les petites et grandes difficultés de la vie.
Chaque jour, nous agissons ensemble pour inventer la meilleure manière de les protéger et voulons donner à chacun les moyens de vivre une vie meilleure.
Un challenge qui donne le sourire et envie de se lever le matin !
Chez AXA, nous sommes persuadés que pour bien prendre soin de nos clients, nous devons commencer par bien prendre soin de nos collaborateurs. C’est pour cette raison que nous menons une politique RH engagée qui favorise la diversité, qui préserve l’équilibre vie privée-vie professionnelle et accélère le développement des compétences et des carrières.
Ainsi, en rejoignant AXA France vous travaillerez dans une entreprise responsable, offrant une véritable culture d’expertise, accélérant le développement des compétences de chacun et proposant une rémunération attractive.
Pourquoi nous rejoindre ?
Vous êtes porteur d’idées et d’initiatives innovantes ? Vous proposez des solutions et êtes au service du client ? Faites partie de notre grande famille en rejoignant
Un leader mondial offrant des opportunités de carrières intéressantes
Une entreprise qui donne une place de choix à l’innovation, à l’initiative et aux actions solidaires (notamment via l’association AXA Atout Cœur)
Un environnement inclusif à tous les niveaux (mixité, handicap, initiatives pour favoriser l’insertion des jeunes, orientation sexuelle, etc.)
Un accès à de multiples avantages (congés, temps partiel, télétravail, etc.)
Un cadre stimulant, qui permet de rencontrer des collaborateurs performants et d’enrichir ses compétences
Victime ou témoin, en cas de discrimination, vous pouvez adresser vos signalements et/ou alertes discrimination à alerte.discrimination.harcelement@axa.fr
Show more
Show less","{'ProgLanguage': ['Python', 'R'], 'DataBase': ['SQL', 'NoSQL'], 'DataAnalytics': ['R'], 'BigData': ['Spark', 'Databricks'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': ['PowerBI'], 'Statistics': [], 'CloudComputing': ['Azure'], 'DevTools': ['Git'], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': ['JIRA', 'Teams'], 'Other': ['DevOps', 'Big Data'], 'FrSoftSkills': ['Organisation'], 'EnSoftSkils': ['Initiative']}","{'JobDetail': ['Junior', 'Senior'], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's', '5', '5', '5']}"
LinkedIn,Data Engineer (Snowflake),MindPal,"Lyon, Auvergne-Rhône-Alpes, France",https://fr.linkedin.com/jobs/view/data-engineer-snowflake-at-mindpal-3910994899?position=9&pageNum=10&refId=Wt7FrOruL4%2BCplGL9tAn0A%3D%3D&trackingId=9jrBl%2BUf0qJsGQTz6OU5UQ%3D%3D&trk=public_jobs_jserp-result_search-card,"We are looking for experienced
Data Engineers
with knowledge of
Snowflake
platform.
Responsibilities
Creating and managing data in the Snowflake environment
Designing and implementing ETL (Extract, Transform, Load) solutions for transferring data between various sources and platforms
Optimizing the performance of Snowflake databases, including designing and implementing data structures and using indexes appropriately
Automating data processing workflows using tools such as Airflow or other workflow management tools
Deploying and configuring tools to monitor and report on the performance of the Snowflake system
Requirements
Minimum 1 year of experience as a Data Engineer
Ability to use Snowflake
Very good knowledge of SQL and programming in Python
Ability to work with databases, including the Snowflake platform
Knowledge of ETL tools and data integration
Ability to work in a team and good communication skills
Fluent English in speaking and writing
We Offer
B2B contract type
Full-time job
Remote and flexible working hours
Show more
Show less","{'ProgLanguage': ['Python', 'R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'DBMS': ['Snowflake', 'Snowflake'], 'SoftBigDataProcessing': [], 'Automation': ['Airflow'], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': [], 'FrSoftSkills': ['Communication'], 'EnSoftSkils': ['Communication']}","{'JobDetail': ['Remote', 'Full'], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's']}"
LinkedIn,Data Engineer,ASTRELYA,Greater Paris Metropolitan Region,https://fr.linkedin.com/jobs/view/data-engineer-at-astrelya-3910760230?position=10&pageNum=10&refId=Wt7FrOruL4%2BCplGL9tAn0A%3D%3D&trackingId=yV6o8FO4VtUJdgoHfgWavQ%3D%3D&trk=public_jobs_jserp-result_search-card,"ASTRELYA est un groupe de conseil et d’expertise IT fondé en 2017, présent en France (Paris et régions) et en Suisse (Genève). Aujourd'hui plus de 280 collaborateurs accompagnent nos clients dans l’accélération et la transformation de leurs organisations.
Dans le cadre de notre développement, nous recherchons un
Data Engineeer F/H
.
Vos rôles et responsabilités :
Développements Java Spark
Optimisation et gestion des évolutions de l&#39;architecture pour intégrer des calculs sur des volumétries de plus en plus importantes
Support technique auprès des équipes de développement et du responsable applicatif
Conception des solutions applicatives cohérentes avec l&#39;ensemble du SI et avec les normes et standards
Développer et garantir les pratiques de développement et de documentation associés (DevOps
L’environnement technique dans lequel vous évoluerez :
Java, Scala, Spark, écosystème Hadoop, environnement DevOps
Les compétences recherchées :
Formation : École d’ingénieur ou équivalent Bac+5
Expériences : Minimum 5 ans d’expérience
Langues : Anglais technique
Excellent relationnel, force de proposition, autonome
Pourquoi rejoindre ASTRELYA ?
Une gestion de carrière personnalisée et un management de proximité
Une politique active de formations / certifications (technique, métier, leadership)
Une offre variée de missions d’expertise
Un engagement RSE fort : Ecovadis Gold, Signataire de la charte pour la diversité, du Pacte des Nations Unies et mise en place du Mécénat de compétences
Un programme de cooptation attractif
Afterworks, conférences techniques et activités sportives réguliers
Cette annonce vous correspond ? Postulez !
🚀
Tous nos postes sont ouverts aux personnes en situation de handicap.
Show more
Show less","{'ProgLanguage': ['Java', 'Scala', 'R', 'Go'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': ['Hadoop', 'Spark'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['DevOps'], 'FrSoftSkills': ['Leadership', 'Organisation'], 'EnSoftSkils': ['Leadership']}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': ['Bac+5'], 'Experience': ['a', 'n', 's', '5', '5', '5']}"
LinkedIn,Data Engineer  H/F,Groupe INGENA,Greater Paris Metropolitan Region,https://fr.linkedin.com/jobs/view/data-engineer-h-f-at-groupe-ingena-3883689479?position=1&pageNum=12&refId=a575NEEXj%2F5ZYoAYMJyABw%3D%3D&trackingId=PTJFmVLol0NZPIc8rRt%2BRw%3D%3D&trk=public_jobs_jserp-result_search-card,"Le groupe INGENA promeut la transition numérique en étant acteur d’un monde souhaitable.
Votre mission :
Concevoir, développer et tester des algorithmes de collecte et de traitement de gros volumes de données sous Scala, Python ou Java
Automatiser et optimiser les flux de données et leurs visualisations en dashboards
Industrialiser les traitements, la qualité et l’intégrité des données
Participer à la Modélisation et à la Gouvernance des données (process, normalisation, référentiel,…)
Contribuer à la scalabilité, la sécurité, la stabilité et la disponibilité des données de la plateforme
Analyser les données pour répondre aux questions métiers et participer à l’évolution de l’architecture Big Data
Concevoir, Développer et Industrialiser des modèles de Machine Learning, Deep Learning, en collaboration avec les Data Scientists
Appliquer une démarche CI/CD (Git, Jira, Jenkins)
Les compétences techniques nécessaires sont :
Expérience de 5 ans minimum en développements Scala, Python ou Java
Expérience de 2 ans minimum sur SPARK et sur le traitement des flux en streaming
Expertise sur Hadoop (Hive, HBase, HDFS) sous distributions MapR ou Hortonworks
Expérience souhaitée sur ELK, Terraform, NoSQL,…
Fort background en Modélisation de données ou ETL
Maîtrise des briques analytiques des clouds AWS, GCP ou Azure
Sensibilisation à la démarche CI/CD tools (Git, Jenkins)
La connaissance de Docker, Kubernetes et Ansible est un plus
Mise en œuvre des méthodes Agile (Scrum, Kanban,…)
Anglais souhaité
Groupe INGENA
:
Le Groupe INGENA est spécialisé en Conseil Métier et en Intégration pour les marchés de l’assurance, de la banque et de la Finance. INGENA intervient notamment sur les projets associés à la Data, aux Risques et à la Distribution.
Le groupe comprend également la société DRiMS spécialisée en Finance de Marché.
Nos valeurs : Engagement, Intégrité et Bienveillance.
La mise en pratique du monde souhaitable, c’est pour nous une entreprise éco-responsable, éthique, inclusive, sociale, soucieuse du bien-être, de l’évolution et de l’épanouissement de ses équipes. Ce sont aussi des offres pour un monde durable comme la maîtrise des risques ou l’ESG.
Dans un esprit convivial et engagé, nous faisons en sorte que chacun puisse être acteur de l’INGENA souhaitable.
Bureau à Paris 9ème (Métro Le Peletier). Clients à Paris ou très proche banlieue.
Show more
Show less","{'ProgLanguage': ['Python', 'Java', 'Scala', 'R', 'Go'], 'DataBase': ['SQL', 'NoSQL', 'HBase'], 'DataAnalytics': ['R'], 'BigData': ['Hadoop', 'Spark'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': ['AWS', 'Azure'], 'DevTools': ['Git', 'Docker', 'Jenkins'], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': ['HBase'], 'Automation': ['Ansible', 'Kubernetes'], 'InfrastructureAsCode': ['Terraform'], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': ['Docker', 'Kubernetes'], 'Collaboration': ['JIRA'], 'Other': ['Big Data', 'Machine Learning', 'Cloud', 'CI/CD'], 'FrSoftSkills': ['Collaboration'], 'EnSoftSkils': ['Collaboration']}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's', '5', '5', '5']}"
LinkedIn,DATA ENGINEER-LYON H/F,Lincoln France,"Auvergne-Rhône-Alpes, France",https://fr.linkedin.com/jobs/view/data-engineer-lyon-h-f-at-lincoln-france-3851734549?position=2&pageNum=12&refId=a575NEEXj%2F5ZYoAYMJyABw%3D%3D&trackingId=VeypythEIv8Md9nnB3RwPA%3D%3D&trk=public_jobs_jserp-result_search-card,"Poste CDI : Data Engineer (Scala, Spark, GCP, etc.) -H/F - Lyon
Lincoln Pure Player Data
💡: Réinventant l'analyse
depuis 30 ans
. Experts en Modern BI, Big Data et Science des données 📊. Nous transformons vos données en solutions pour les grands comptes, des secteurs bancaire, retail, télécoms, industriel, santé, et plus encore 💼.
Description de poste
🎯
Missions
:
Concevoir et développer des pipelines de données robustes et évolutifs.
Intégrer et transformer des données provenant de différentes sources.
Développer et mettre en œuvre des algorithmes de traitement de données avancés.
Collaborer étroitement avec les équipes clients pour comprendre leurs besoins et fournir des solutions adaptées.
Assurer la qualité et la fiabilité des solutions développées.
🔍
Prérequis
:
Maîtrise des langages de programmation (
Python, Scala, Spark, etc
.).
Connaissance approfondie des bases de données et des technologies
Big Data (Hadoop, Spark, Kafka, Talend,...) et Cloud (AWS, GCP, Azure,...)
.
Expérience avec
MySQL, PostgreSQL, MongoDB.
Solides compétences en conception et en optimisation de pipelines de données.
Expérience de travail en
méthode Agile
pour la gestion de projet et le développement de solutions.
Capacité à travailler de manière autonome et en équipe.
Excellentes compétences en communication et en résolution de problèmes.
🌟
Avantages :
Environnement collaboratif et innovant
Formations certifiantes et accompagnement individualisé
Télétravail et horaires flexibles
Rémunération compétitive avec avantages sociaux attrayants
Possibilité de mobilité à Lille, Paris ou Aix-en-Provence
✨
Processus de recrutement
: 2 entretiens (RH et technique)
Si vous êtes passionné par les défis de la Data et que vous souhaitez rejoindre une équipe dynamique et innovante,
postulez dès maintenant et contribuez à redéfinir l'avenir de l'analyse de données chez Lincoln! 😉
Show more
Show less","{'ProgLanguage': ['Python', 'Scala', 'R', 'Go'], 'DataBase': ['SQL', ' MongoDB'], 'DataAnalytics': ['R'], 'BigData': ['Hadoop', 'Spark'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': ['AWS', 'Azure'], 'DevTools': [], 'Os': [], 'DBMS': ['MySQL', 'PostgreSQL'], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Big Data', 'Cloud'], 'FrSoftSkills': ['Communication', 'Résolution de problèmes'], 'EnSoftSkils': ['Communication']}","{'JobDetail': [], 'TypeContract': ['CDI'], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's', '30', '30', '30']}"
LinkedIn,Développeur Big Data H/F,Inetum,"St.-Ouen, Île-de-France, France",https://fr.linkedin.com/jobs/view/d%C3%A9veloppeur-big-data-h-f-at-inetum-3843965989?position=3&pageNum=12&refId=a575NEEXj%2F5ZYoAYMJyABw%3D%3D&trackingId=cF9s3MXmDqgW8F6HUp9rFw%3D%3D&trk=public_jobs_jserp-result_search-card,"Détail de l'offre
Informations générales
Entité de rattachement
Inetum est un leader européen des services numériques. Pour les entreprises, les acteurs publics et la société dans son ensemble, les 28 000 consultants et spécialistes du groupe visent chaque jour l'impact digital des solutions qui contribuent à la performance, à l'innovation et au bien commun.
Présent dans 19 pays au plus près des territoires, et avec ses grands partenaires éditeurs de logiciels, Inetum répond aux enjeux de la transformation digitale avec proximité et flexibilité.
Porté par son ambition de croissance et d'industrialisation, Inetum a généré en 2023 un chiffre d'affaires de 2,5 milliards d'€.
Pour répondre à un marché en croissance continue depuis plus de 30ans, Inetum a fait le choix délibéré de se recentrer sur 4 métiers afin de gagner en puissance et proposer des solutions sur mesure, adaptées aux besoins spécifiques de ses clients le conseil (Inetum Consulting), la gestion des infrastructures et applications à façon (Inetum Technologies), l'implémentation de progiciels (Inetum Solutions) et sa propre activité d'éditeur de logiciels (Inetum Software). Inetum a conclu des partenariats stratégiques avec 4 grands éditeurs mondiaux - Salesforce, ServiceNow, Microsoft et SAP et poursuit une stratégie d'acquisitions dédiée afin d'entrer dans le top 5 européen sur ces technologies et proposer la meilleure expertise à ses clients.
Tous nos postes sont ouverts aux personnes en situation de handicap.
Description du poste
Métier
Applications Delivery - Software Development
Intitulé du poste
Développeur Big Data H/F
Contrat
CDI
Description De La Mission
Le pôle
BFA
de la branche Application Services du groupe
INETUM
, recherche plusieurs développeurs
Big Data
afin d'intervenir auprès de clients grands comptes au sein
des marchés bancaires et de l'assurance.
Directement intégré(e) chez l'un de nos clients sur des sujets stratégiques et aux enjeux forts, vous serez amené(e) à
Participer à l'analyse détaillée à partir des besoins des utilisateurs et de l'analyse fonctionnelle
Concevoir l'application et les tests à partir de l'analyse détaillée
Dérouler les tests et corriger les anomalies
Travailler sur la mise en place d’infrastructures Big Data
Réaliser les flux de données
Valider leur fonctionnement en sécurité et performance
Assurer la pérennité de leurs évolutions
Participer quotidiennement aux réunions d’équipe (daily meeting) afin de contribuer à l’évaluation de l’effort de travail nécessaire
Profil
Issue d'une formation d'ingénieur / Bac+5 en Informatique
Doté d'une expérience d’au moins 2 ans sur ce type poste
Maîtrise des technologies Hadoop, Spark, Hive, Impala, ETL (Talend, Informatica, …), Java, Scala, Python, SQL, les bases de données SQL (oracle, …) et NoSQL (Cassandra, …)
Des notions de Machine Learning et d’IA sont recommandées pour bien appréhender les besoins de nos Data Scientists.
Expérience au sein d'un environnement agile (Scrum) indispensable
Anglais obligatoire
Localisation du poste
Localisation du poste
France, Ile-de-France
Ville
145, Boulevard Victor Hugo 93400 Saint-Ouen
Critères candidat
Niveau d'expérience min. requis
Plus de 2 ans
Show more
Show less","{'ProgLanguage': ['Python', 'Java', 'Scala', 'R', 'Go'], 'DataBase': ['SQL', 'NoSQL', 'Cassandra'], 'DataAnalytics': ['R'], 'BigData': ['Hadoop', 'Spark'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git'], 'Os': [], 'DBMS': ['Oracle'], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Big Data', 'Machine Learning'], 'FrSoftSkills': ['Flexibilité'], 'EnSoftSkils': []}","{'JobDetail': [], 'TypeContract': ['CDI'], 'Salary': [], 'Level': ['Bac+5'], 'Experience': ['a', 'n', 's', '30', '30', '30']}"
LinkedIn,Data Engineer - Développeur - 38 - 42K€ Nantes H/F,L2C / Spécialiste du recrutement IT,"Nantes, Pays de la Loire, France",https://fr.linkedin.com/jobs/view/data-engineer-d%C3%A9veloppeur-38-42k%E2%82%AC-nantes-h-f-at-l2c-sp%C3%A9cialiste-du-recrutement-it-3913996457?position=4&pageNum=12&refId=a575NEEXj%2F5ZYoAYMJyABw%3D%3D&trackingId=qmrHjOejaWqg6MEzmYhDuQ%3D%3D&trk=public_jobs_jserp-result_search-card,"L2C est un cabinet spécialisé dans le recrutement de profils informatiques, tech' et data en CDI pour des clients finaux.
CLIENT
Précurseur, innovant et visionnaire, notre client a développé une plateforme basée sur l'IA prédictive, qui permet aux entreprises de prendre les meilleures décisions.
Référence reconnue et leader dans le domaine de la Business Intelligence, notre client développe des solutions d'intelligence artificielle commerciale BtoB pointues, complètes, avec un haut niveau de qualité : aide à la prospection, gestion des appels d'offres, prédiction financière
Solidement établi, en croissance continue, notre client se réinvente constamment afin de rester à la pointe et de prendre soin de ses collaborateurs.
Depuis plus de 20 ans, notre client a conquis près de 15 000 clients. (Paypal, Dassault, KPMG)
C'est une société saine, bijou de la tech, précurseur en termes de stack technique et façon de fonctionner, avec un bon état d'esprit, offrant des conditions de travail agréables.
Nous recherchons un candidat polyvalent, à la croisée entre le traitement de données et le développement. (Proche Nantes)
Poste à pourvoir en interne en CDI. (télétravail 3 jours/semaine)
Missions
Vous participerez à l'amélioration des outils référentiels Big Data, en étroite collaboration avec les équipes de développeurs (10 personnes) et les data scientists (6 personnes)
Vous développerez des solutions de captation et d'intégration des données issues de l'Open Data et des partenaires, crawls, scraping, imports de fichiers
Vous modéliserez des bases de données
Vous orchestrerez des flux de données entre les applicatifs, référentiels, bases de données (SQL/NoSQL) avec des outils ETL.
Vous valoriserez les données avec des traitements complémentaires (géocodage, océrisation)
Vous développerez des APIs pour des usages internes et pour les clients
Vous assurerez la supervision et l'exploitation des outils (surveillance des performances et garantie de la disponibilité.
Vous assurerez la qualité des données (nettoyage, standardisation, valorisation pour garantir la fiabilité)
Vous rédigerez la documentation technique et accompagnerez les utilisateurs
Les plus
Société précurseur, innovante et visionnaire, qui prend soin de ses collaborateurs
Référence reconnue et leader dans le domaine de la Business Intelligence (IA prédictive, sujets tech modernes et riches)
Groupe solide en forte croissance
Société solidement implantée en France et à l'international depuis une vingtaine d'années
Télétravail partiel
Environnement de travail sain et agréable
Complémentaire santé/Prévoyance, comité d'entreprise, prime vacances, tickets restaurant
Vous disposez d'un bon bagage technique sur Python.
Vous avez l'habitude de vous auto-former sur les outils et langages et vous savez maintenir une veille active sur les outils de traitement des données.
Compétences / Connaissances
Data-Management, Audit de qualité des données et usage des ETL
Systèmes Linux, gestion et administration des containers (Docker, Kubernetes)
Développement / Scripts : Python ++ (Avec Spark), JavaScript, C#
Bases De Données
SQL Server ou autres SGBD Relationnels
MongoDB
Elasticsearch
Bases de données orientées Graph (Neo4J)
Connaissances CI/CD, Git
Connaissance générale des technologies et framework big data usuels.
Show more
Show less","{'ProgLanguage': ['Python', 'Java', 'C#', 'R', 'Go', 'JavaScript'], 'DataBase': ['SQL', 'NoSQL', 'Neo4j', 'Elasticsearch'], 'DataAnalytics': ['R'], 'BigData': ['Spark'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git', 'Docker'], 'Os': ['Linux'], 'DBMS': ['SQL Server'], 'SoftBigDataProcessing': [], 'Automation': ['Kubernetes'], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': ['Docker', 'Kubernetes'], 'Collaboration': [], 'Other': ['Big Data', 'CI/CD'], 'FrSoftSkills': ['Collaboration'], 'EnSoftSkils': ['Collaboration']}","{'JobDetail': [], 'TypeContract': ['CDI'], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's', '20', '20', '20']}"
LinkedIn,Data Engineer (H/F),Harry Hope.,"Paris, Île-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-h-f-at-harry-hope-3920545043?position=5&pageNum=12&refId=a575NEEXj%2F5ZYoAYMJyABw%3D%3D&trackingId=kGbVGmURBYVn0rXlEKV%2BSg%3D%3D&trk=public_jobs_jserp-result_search-card,"Harry Hope, cabinet de recrutement accompagne candidats et entreprises dans leurs recherches des meilleures opportunités en France et à l'international. Afin de mieux répondre à vos enjeux, tous nos consultants sont spécialisés par secteur d'activité et zone géographique.
Notre client, société en pleine croissance, spécialisé dans le domaine de la Big Data, recherche des Consultants Data Engineer ! Participez à cette aventure et rejoignez une formidable équipe.
Vos missions principales seront diversifiées, comprenant notamment :
Participation aux processus d'avant-vente : Vous contribuerez à l'élaboration des propositions techniques, mettant en avant votre expertise pour répondre aux besoins des clients.
Qualification technique des prestataires : Vous participerez activement à l'évaluation et à la sélection des prestataires, garantissant un partenariat de qualité.
Direction et coordination des projets : Vous dirigerez et coordonnerez la conception et la mise en oeuvre des projets, assurant leur réussite technique.
Documentation technique : Vous élaborerez, au besoin, des dossiers d'architecture, d'installation et d'exploitation, assurant une traçabilité et une compréhension optimale des solutions mises en place.
Participation active aux développements : Vous apporterez votre expertise en contribuant directement aux développements dans le cadre des projets.
De manière plus étendue, vous aurez l'opportunité de :
Enrichir les bonnes pratiques : Vous contribuerez à l'évolution et à l'amélioration des bonnes pratiques d'architecture et de développement dans le domaine du Big Data.
Veille technologique : Vous réaliserez une veille constante sur les avancées technologiques du secteur, assurant ainsi la pertinence des solutions proposées.
Formation technique : Vous élaborerez des supports de formation technique pour nos clients et/ou nos consultants juniors, partageant ainsi votre savoir-faire.
Animation du pôle technique : Vous participerez activement à l'animation du pôle technique favorisant un environnement collaboratif et innovant.
Vous êtes détenteur d'un diplôme d'ingénieur (école ou université), et vous avez 5 ans d'expérience en tant que Data Engineer.
En tant que Consultant Data Engineer, nous recherchons des professionnels possédant des compétences solides et des convictions dans les domaines suivants :
Architectures Big Data : Kappa, Lambda, Réactive, SMACK, etc.
Solutions technologiques : Hadoop, SGBD NoSQL, Kafka, Spark, etc.
Outils de développement : Vous êtes à l'aise avec des outils tels que Hive, Pig, Python, Scala, etc.
Environnements d'exploitation et de supervision : Vous avez une expérience pratique avec des outils tels qu'Ambari, Oozie, Zookeeper, etc. 20681288-55584
Show more
Show less","{'ProgLanguage': ['Python', 'Scala', 'R'], 'DataBase': ['SQL', 'NoSQL'], 'DataAnalytics': ['R'], 'BigData': ['Hadoop', 'Spark'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Big Data'], 'FrSoftSkills': [], 'EnSoftSkils': []}","{'JobDetail': ['Junior'], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's', '5', '5', '5']}"
LinkedIn,Data Engineer,Mobiskill | WEFY Group,"Paris, Île-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-at-mobiskill-wefy-group-3907391938?position=6&pageNum=12&refId=a575NEEXj%2F5ZYoAYMJyABw%3D%3D&trackingId=d9sK3EdR8JW0CN1NTR9hag%3D%3D&trk=public_jobs_jserp-result_search-card,"La société ?
Cette startup a été créée en 2018 et vise à aider la prise de décision de ses clients qui sont principalement dans le secteur du retail ou de l'alimentaire.
Ils permettent d'enrichir la donnée afin d'améliorer la stratégie de vente et marketing d'une entreprise grâce à leur plateforme Saas basée sur des algorithmes d'IA.
Ils ont besoin de renforcer leur équipe en Data Engineering pour gérer au mieux leur volumétrie.
Les missions ?
- Editer le cahier des charges des données à collecter auprès de nos partenaires distributeurs
- Prendre en main la gestion de la donnée dans le cloud de la société pour optimiser les coûts et l’efficacité des analyses effectuées par l’équipe Analytics
- Anticiper les évolutions et participer aux choix structurants de la société liés à la gestion de la data
Le profil recherché ?
- Avoir 2/3 ans d'expérience en Data Engineering (hors stage et alternance)
- Avoir pu travaillé en Python comme langage de programmation
Avoir travaillé au moins deux ans et si possible sur des sujets d'optimisation avec Spark !
- La maîtrise des outils tels Airflow, Kafka et Snowflake seraient un plus apprécié
- Maîtriser un des cloud providers et si possible avoir une expérience sur Azure
Pourquoi les rejoindre ?
- Une société stable financièrement (fonds propres uniquement)
- Une startup en pleine croissance
- Une rémunération en fonction de votre séniorité
- Volumétrie de données incroyable, il y a de quoi s'amuser !
- Faire parti de l'unique retail-tech qui a un impact écologique positif (fin des prospectus, éviter le gâchis alimentaire)
Hâte de vous en dire plus rapidement !
Show more
Show less","{'ProgLanguage': ['Python', 'R', 'Go'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': ['Spark'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': ['Azure'], 'DevTools': [], 'Os': [], 'DBMS': ['Snowflake', 'Snowflake'], 'SoftBigDataProcessing': [], 'Automation': ['Airflow'], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Cloud'], 'FrSoftSkills': [], 'EnSoftSkils': []}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's', '3', '3', '3']}"
LinkedIn,Data Engineer,MindPal,"Lyon, Auvergne-Rhône-Alpes, France",https://fr.linkedin.com/jobs/view/data-engineer-at-mindpal-3896997013?position=7&pageNum=12&refId=a575NEEXj%2F5ZYoAYMJyABw%3D%3D&trackingId=GrAS148%2BSqUlVtQ2ePplOg%3D%3D&trk=public_jobs_jserp-result_search-card,"We are looking for
Data Engineer!
Responsibilities
Designing, creating, and maintaining data processing systems
Analyzing and optimizing data processing workflows
Collaborating with the team to ensure data quality and efficiency
Testing and implementing new solutions
Requirements
At least 2 years of experience in designing and creating data processing systems
Proficiency in tools and programming languages related to data engineering (e.g. Hadoop, Spark, Scala, Python)
Excellent knowledge of databases and SQL language
Ability to work in a team and communicate effectively with other departments
Communicative English skills
Experience with AWS/AWS Glue is a plus
We Offer
B2B contract
Full-time job
Remote work and flexible hours
Show more
Show less","{'ProgLanguage': ['Python', 'Scala', 'R'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': ['Hadoop', 'Spark'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': ['AWS'], 'DevTools': [], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': [], 'FrSoftSkills': [], 'EnSoftSkils': []}","{'JobDetail': ['Remote', 'Full'], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's']}"
LinkedIn,Data Engineer Alternant(e),Wakam,"Paris, Île-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-alternant-e-at-wakam-3918901392?position=8&pageNum=12&refId=a575NEEXj%2F5ZYoAYMJyABw%3D%3D&trackingId=xnrf2vRnerqq3Y11vT3uZQ%3D%3D&trk=public_jobs_jserp-result_search-card,"Who are we?
Wakam is a B2B2C insurance company that creates white-label insurance solutions via its Play&Plug® technology platform for more than 150 distribution partners. We provide most of our insurance products through API, and hosts white label insurance solutions via our Play&Plug technology platform.
With a footprint spanning 32 countries and revenue of more than €900 million in 2023, mostly generated outside France, Wakam is the European leader in digital and embedded insurance.
Strongly committed to social responsibility,
Wakam is a mission-driven company
dedicated to ""enabling transparent and impactful insurance"".
✎
Missions
Wakam assure la conception de produits d'assurances sur-mesure qui sont ensuite commercialisés par des partenaires distributeurs (courtiers, insurtech, retailers) sur un modèle B2B2C en marque blanche. Pour accompagner la forte croissance de l'entreprise, Wakam est à la recherche d'un(e) alternant(e) pour rejoindre notre Office Data.
Rattaché(e) à l'équipe Data Platform (DPF), vous contribuerez activement à l'élaboration de la nouvelle plateforme en y développant de nouveaux cas d'usages techniques et business.
Vos principales missions sont les suivantes :
Construire des pipelines ETL/ELT et reverse ETL sur les données des partenaires Wakam;
Comprendre l'architecture existante, incluant le portail d'ingestion des données, le framework de self-service et l'infrastructure technique;
Réaliser des transformations de données à l'aide du framework DBT en SQL;
Contribuer au développement des produits de la Data Platform en utilisant Python et partager les connaissances acquises avec la communauté techniques de Wakam;
Collecter des données aux formats variés provenant des différentes sources;
Participer activement au développement de la data platform sur Snowflake;
Aider et assister les utilisateurs métier dans l'utilisation des outils fournis par l'équipe DPF;
Documenter les différentes étapes de transformation et d'historisation des données;
✯
Profil recherché
Vous suivez actuellement des études dans l'un de ces domaines : école d'ingénieurs, master en informatique, data science, data engineering;
Vous avez de fortes capacités d'analyse et de réflexion et savez également être dans l'action et orienté.e résultats ;
Vous êtes curieux, autonome et agile;
Vous devez avoir de fortes capacités d'analyse et de réflexion, mais également être dans l'action et orienté.e résultats;
Excellente maîtrise du français et de l'anglais, à l'oral comme à l'écrit;
Bonne connaissance de Python, SQL, entrepôts de données, systèmes distribués, Cloud;
Process de recrutement
To help you get a complete picture of our hiring process and Wakam's work culture, please visit our dedicated page: Interviews at Wakam
Échange avec Jade, Talent Acquisition
Échange avec Mariana Gherghina (Senior Data Engineer) et Simon Pichon (Engineering Manager)
=> Welcome @Wakam
Positive energy, agility, and team spirit are essential to support Wakam in its hyper-growth!
You have the Wakam mindset? Join us!
More about us
Our culture?
Free to impact
. A culture where everything is possible, where all ideas are taken into consideration, where everyone has an impact on the transformation of insurance! Hungry for freedom? Thirsty for autonomy? If you are adventurous and like challenges, then the Wakam adventure might be made for you!
Discover on our website who we really are with the 11 cultural markers that so well describe us!
What we are looking for ?
Mindset compatibility with our 'Free to Impact' culture:
Think big
Biased for action
Curious and eager to learn
Can say no and find solutions
Aims for the moon (but please don't stick on the moon)
And above all: have fun working together 🤜🤛 !
Good to know !
Wakam is not based on a hierarchy but on a methodology where everyone finds their role and knows their objectives.
With a flat hierarchical system and a highly collaborative operating model, Wakam is an extremely agile and transparent company.
Every last Friday of the month, it's Free.day @Wakam, a day without meetings to take a step aside and dedicate ourselves to skills sponsorship or other activities (because we are curious, I remind you).
Full-remote is a reality at Wakam (there is even one Wakamee who works from his sailing boat ⛵) with our Wakam From Anywhere (WFA) program.
Last but not least : we are nice and we have fun! (you'll find out by yourself 😉)
At Wakam, we are committed to fostering an inclusive environment where diversity is celebrated. If you require any reasonable adjustments during the recruitment process, please feel free to reach out to your recruiter.
Show more
Show less","{'ProgLanguage': ['Python', 'R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git'], 'Os': [], 'DBMS': ['Snowflake', 'Snowflake'], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Cloud'], 'FrSoftSkills': [], 'EnSoftSkils': []}","{'JobDetail': ['Remote', 'Full', 'Senior'], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's']}"
LinkedIn,Data Engineer Cloud (H/F),Beelix,"Mougins, Provence-Alpes-Côte d'Azur, France",https://fr.linkedin.com/jobs/view/data-engineer-cloud-h-f-at-beelix-3909193730?position=9&pageNum=12&refId=a575NEEXj%2F5ZYoAYMJyABw%3D%3D&trackingId=%2Bx0Epim5PeLAZ9pvSZREUQ%3D%3D&trk=public_jobs_jserp-result_search-card,"Qui sommes-nous ?
Depuis 2016, nous accompagnons nos clients sur des problématiques de Product Management, Data et Design Thinking. Beelix contribue à façonner le monde de demain en participant aux grandes avancées des secteurs suivants:
🚗Automobile
⚡Energie
📡Médias & Télécoms
👗Luxe & Retail
💶 Banque, Finance & Assurance
✈️Défense
Aujourd’hui, Beelix compte plus de 200 collaborateurs motivés et dynamiques. Labélisée Great Place To work en 2023, Beelix est aussi une entreprise engagée où il fait bon vivre.
Dans le cadre de notre développement, nous recherchons un Data Engineer Cloud (H/F) en région PACA.
Quelles missions au quotidien ?
Concevoir, développer et déployer des pipelines de données fiables et évolutifs sur GCP.
Collaborer avec les équipes métier pour comprendre les besoins en données et fournir des solutions adaptées.
Optimiser les performances et la disponibilité des solutions de données sur GCP.
Mettre en œuvre des pratiques de sécurité des données et assurer la conformité aux réglementations.
Travailler en étroite collaboration avec les équipes de développement dans un environnement agile pour fournir des solutions dans des délais serrés.
Expertise souhaitée
Expérience significative dans le développement et la gestion de pipelines de données sur GCP ou autre plateforme cloud.
Maîtrise des outils GCP tels que BigQuery, Dataflow, Pub/Sub, et Cloud Storage.
Solide expérience en Python, Java ou Scala.
Compréhension des principes de l'ingénierie des données, du traitement des données en continu et des entrepôts de données.
Capacité à travailler de manière autonome et en équipe, avec d'excellentes compétences en communication.
A propos de vous ?
Diplômé d'une école d'ingénieurs ou équivalent
Au moins 3 ans d'expérience en tant que Data Engineer
Expérience en mode de Delivery Agile (Scrum, Kanban, etc.…)
Vous avez un bon niveau d’anglais tant à l’écrit qu’à l’oral
Pourquoi nous rejoindre ?
Un suivi et un accompagnement au quotidien
Un organisme de formation certifié Qualiopi, un abonnement linkedin learning pour chaque salarié et des partenariats avec des spécialistes pour d’autres expertises
De nombreux événements : Afterworks, Communautés métiers, Happy talks…
une Expérience personnalisée basée sur vos besoins grâce au Prédictive Index
Notre package « unBeelievable » : 100% du titre de transport, Tickets restaurants, CSE, Prime de participation...
Nombreux évènements (afterworks, sport, etc) et des communautés métiers dynamiques
Le processus de recrutement ?
Échange téléphonique (15 min)
Entretien 1 RH pour apprendre à vous connaître
Entretien 2 avec votre futur N+1 pour appréhender la relation managériale
Entretien 3 avec un Responsable commercial pour avoir la vision stratégique
Localisation : Mougins, format hybride
Show more
Show less","{'ProgLanguage': ['Python', 'Java', 'Scala', 'R'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'DBMS': ['BigQuery'], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Cloud'], 'FrSoftSkills': ['Communication', 'Collaboration'], 'EnSoftSkils': ['Communication', 'Collaboration']}","{'JobDetail': ['Hybride'], 'TypeContract': [], 'Salary': ['100'], 'Level': [], 'Experience': ['a', 'n', 's', '3', '3', '3']}"
LinkedIn,Data Engineer & Analyst - Paris - F/H/X - CDI,Partoo,"Paris, Île-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-analyst-paris-f-h-x-cdi-at-partoo-3892387658?position=10&pageNum=12&refId=a575NEEXj%2F5ZYoAYMJyABw%3D%3D&trackingId=1AWLZFifjjDn5cL6tE%2Bgvw%3D%3D&trk=public_jobs_jserp-result_search-card,"Partoo, who are we? 👀
Partoo est une scale-up saas B2B qui a à cœur d’aider les commerces locaux, grandes entreprises ou PME à se rapprocher de leurs clients. Pour cela, ils ont développé une plateforme tout-en-un et différentes solutions qui s’articulent autour de 3 propositions de valeur : Get found, Get chosen & Get clients.
À travers ces 3 propositions, ils ont développé plusieurs produits qui s’adaptent aux évolutions du parcours d’achat des clients :
🔎 Get found
Presence: Synchroniser les informations des magasins sur les principales plateformes (Google, Facebook, Waze, etc.), annuaires et GPS
Store Locator: Aider les clients à trouver le magasin qui leur convient grâce à des données locales actualisées et des filtres dédiés sur les sites web des enseignes
Réseaux sociaux: Gérer les publications sur Facebook, Google, Instagram, etc
🎯 Get chosen
Review: Centraliser, répondre et analyser les avis clients reçus sur Google et Facebook
Booster: Obtenir des avis positifs supplémentaires sur Google par le biais de SMS et de QR codes
🤗 Get clients
Messages: Centraliser et répondre à tous les messages de chat reçus via Google Business Messages, Messenger et bientôt aussi via Instagram, whatsapp, etc. (templates messages, conversations starter, appels manqués...)
Quelques chiffres 🗝️
> Un label Happy at Work et l'une des meilleures notes Glassdoor de l'écosystème avec 4.6/5 pour plus de 260 avis⭐️⭐️⭐️⭐️⭐️ ️️️️️️
> 450+ employés heureux, 37 nationalités différentes, des bureaux à Paris et Barcelone 🚀
> Ils gèrent 300 000 points de vente et travaillent de manière transversale avec +1000 chaînes (Carrefour, Generali, Toyota, Décathlon, Leroy Merlin etc.) et +6000 pme dans environ 150 pays
Notre mémo 2024: le mot du CEO (https://www.partoo.co/fr/blog/memo-2024/)
IMPACT 💥
Partoo compte aujourd’hui pas moins de 400 collaborateurs, qui œuvrent au quotidien à maintenir une croissance saine, en phase avec les enjeux et challenges économiques du moment.
Une des composantes clefs pour y parvenir réside en notre capacité à développer et maintenir un haut niveau d’efficacité opérationnelle. Dans cette logique, améliorer notre capacité à exploiter et utiliser la donnée présente dans nos systèmes est indispensable. Si nous avons déjà une équipe Data en place, celle-ci est aujourd’hui mobilisée presque exclusivement sur les thématiques data relatives au fonctionnement de notre application ainsi qu’à la construction d’éléments de visibilité pour nos clients.
Nous souhaitons donc recruter un Data Engineer & Analyst dont l’objectif principal sera de permettre aux équipes Opérations et client-facing de visibiliser et tirer le meilleur parti d’une donnée aujourd’hui difficile d’accès.
Manager : Adel Adman (cc. Clément Bouillaud, en charge de la team Operations)
TEAM 💙
Meetings récurrent avec les membres de Partoo :
Membre à part entière de l’équipe Data (elle-même intégrée dans l’équipe Produit), tu seras néanmoins en contact régulier avec les équipes Opérations, qui seront tes principales interlocutrices.
En d’autres termes, tu seras le pilier central entre les équipes Ops et Data.
Dans un premier temps, tu auras un meeting hebdomadaire avec Adel (Lead Data) et avec Clément (COO), le temps de cadrer tes premières priorités et de trouver la bonne récurrence de rencontre avec les équipes Opérations.
MISSIONS 🔥
Ton principal objectif consiste à faire en sorte que chaque personne, des équipes Opérations comme des équipes client-facing, ait accès à la donnée dont elle a besoin, au moment où elle en a besoin, sur le support le plus adéquat. Pour y parvenir, plusieurs missions seront tiennes :
Architecture
:
Créer des architectures de données robustes et évolutives pour collecter, stocker et analyser de grandes quantités de données provenant de diverses sources (Salesforce, Intercom, Chargebee, back office de Partoo, etc.)
Analyser et améliorer continuellement le modèle de données Salesforce (SF), en accompagnant l'équipe Ops dans le monitoring des anomalies et l'optimisation des performances
Intégrations et flux
:
Développer et optimiser des pipelines de données, assurant l'intégration fluide des données dans notre Data Warehouse depuis différentes sources, et inversement
Transformation & analyse
:
Concevoir et exécuter des requêtes SQL complexes pour l'analyse de données, permettant de soutenir les décisions business
Identifier et construire des KPI cruciaux, fournissant des insights précieux aux équipes business
Visualisation
:
Fournir aux équipes Ops et client-facing des outils de visualisation de données (Looker Studio, embedding, etc.), clés dans l'optimisation de notre gestion de clientèle.
Formation
:
Former les équipes Opérations sur l’exploitation des tables de notre Datawarehouse ainsi que sur l’usage de Looker Studio et propager les principales best practices associées. Tout ça, en collaboration au quotidien avec les équipes Ops !
DESIRED PROFILE 🎯
Compétences recherchées :
Une très bonne connaissance du langage SQL, notamment PostgreSQL et BigQuery.
Maîtrise du scripting Python et des notebooks pour l'analyse de données
D’excellentes capacités d'analyse pour comprendre les besoins business, identifier les anomalies dans les données et proposer des améliorations pertinentes
Une bonne aptitude à manipuler et analyser de grands ensembles de données et en extraire des insights actionnables
Une très bonne maîtrise d'au moins un outil de business intelligence tel que Looker Studio, PowerBI ou Tableau
Profils recherché :
Tu as plus de 3 ans d'expérience en Data Engineering /Advanced Data Analysis
Tu maîtrises les stacks de data les plus récentes (dbt, Airflow, Airbyte, etc.) et les meilleures pratiques en matière de données (ETL, reverse-ETL, etc.)
Tu es orienté(e) utilisateur et sais convertir les besoins commerciaux en solutions techniques
Tu sais communiquer avec les équipes et t'assurer que les meilleures pratiques sont adoptées
Tu es un team player !
Tu souhaites apprendre et grandir avec nous
RECRUITMENT PROCESS 🛠️
A first video call with Marine, Talent Acquisition Specialist, 45 min
Interview with Adel, Lead Data Engineer, 1h
Case Study
Interview with Clément, Chief Operations Officer, 1h
À compétences égales, ce poste est ouvert aux travailleurs et travailleuses en situation de handicap ou assimilés au sens de l’article L5212-13 du Code du travail. Partoo s’engage en faveur de la diversité, l’égalité professionnelle, l’emploi des travailleurs handicapés.
With equal skills, this position is open to disabled workers or those considered to be disabled within the meaning of Article L5212-13 of the French Labour Code. Partoo is committed to diversity, professional equality and the employment of disabled workers.
Show more
Show less","{'ProgLanguage': ['Python', 'R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': ['Tableau', 'PowerBI'], 'Statistics': [], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'DBMS': ['PostgreSQL', 'BigQuery'], 'SoftBigDataProcessing': [], 'Automation': ['Airflow'], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': [], 'FrSoftSkills': ['Collaboration'], 'EnSoftSkils': ['Collaboration']}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's', '3', '3', '3']}"
LinkedIn,Senior Data & Cloud Engineer (H/F),fifty-five,"Paris, Île-de-France, France",https://fr.linkedin.com/jobs/view/senior-data-cloud-engineer-h-f-at-fifty-five-3915044673?position=1&pageNum=15&refId=3Lir5Tz0viOiyHjhQOdm%2FQ%3D%3D&trackingId=19LhPvryuXNgBpkjdc5ogw%3D%3D&trk=public_jobs_jserp-result_search-card,"Senior Data & Cloud Engineer
fifty-five est une data-company d'un genre nouveau qui aide les marques à exploiter les données pour améliorer le marketing, les médias et l'expérience client grâce à une combinaison de services de conseil et de technologie spécialisés.
En tant que pilier data et marketing du Brandtech Group, nous offrons des services qui combinent le conseil en stratégie, les services de cloud, le conseil en média et l'expérience client.
fifty-five, c'est plus de 400 experts du numérique. Des digital consultants, des spécialistes du tracking et du média, des ingénieurs et des data scientists, travaillent tous en étroite collaboration pour fournir des conseils marketing de haut niveau et une assistance technique aux marques, dans tout type d'industrie, partout dans le monde.
Partenaire des annonceurs de la collecte à l'activation et l'exploitation des données, nous aidons les organisations à devenir de véritables entités omnicanales maîtrisant l'efficacité de leur écosystème digital et ses synergies avec le monde physique.
Basé à Paris, nous opérons sur 3 fuseaux horaires depuis nos 10 bureaux, situés à Paris, Londres, Genève, Milan, Shanghai, Hong Kong, Shenzhen, Taipei, Singapour et New York. fifty-five attache une importance particulière au bien-être de ses collaborateurs, ce qui lui a permis de figurer dans le classement Best Workplaces France en 2018.
Contexte :
L'équipe d'ingénierie développe et met en œuvre les solutions techniques permettant la réalisation de pipelines de données et l'implémentation de data platform pour nos clients : récupération de datas sur de multiples sources de données (APIs, files, etc.), data cleaning, data processing, automation et monitoring de l'ensemble. L'équipe s'appuie sur des technologies récentes (docker, kubernetes, terraform, notebooks, etc.) et met en place ses projets dans les différents clouds du marché (GCP, Azure, AWS...).
Mission :
Nous sommes à la recherche d'une personne capable de réaliser des projets techniques pour répondre aux besoins de nos clients (par exemple: système de recommandations de produits, détection d'anomalies, ranking). Les activités vont du chiffrage et du sizing technique à la mise en œuvre des architectures, en passant par la revue des spécifications fonctionnelles et la production de code. Le Data & Cloud Engineer sera épaulé par un Lead dans ses missions. Il sera également amené à participer à la R&D et à accompagner les équipes transverses dans la mise en place d'outils de travail internes (librairies pour les data scientists, environnement Notebooks pour les data analysts et data scientists, développement de frameworks sur différents cloud providers, etc.).
Nous souhaitons trouver la bonne personne pour faire évoluer ou créer de nouvelles solutions dans ce cadre. Les missions comprennent aussi bien du prototypage rapide pour des démonstrateurs, que de la production de code robuste qui tourne en production tous les jours.
Compétences et expériences :
4-5 ans d'expérience en tant que Data Engineer
Maîtrise de Python, SQL
Maîtrise des environnements Cloud. Idéalement certifié GCP, Azure ou AWS
Bonne connaissance de Docker/Kubernetes
Bonne connaissance d'au moins un data warehouse (BigQuery, Snowflake, etc)
Connaissance autour des Notebooks (Jupyter)
A l'aise avec des concepts liés aux APIs (OAuth, REST, etc.)
A l'aise avec les notions d'Infrastructure as Code (Terraform)
Au courant des pratiques GitOps et connaissances des concepts autour du CI/CD
La maîtrise d'un orchestrateur, comme Apache Airflow, est un plus
Esprit d'équipe (collaborer aux tests unitaires, revue de code, partage de code, sprints)
Bon niveau en français et en anglais
A déjà travaillé en mode projet avec des interlocuteurs variés (consultant, data analyst, data scientist)
Une expérience en marketing digital est un plus
Nous proposons :
un bureau au centre de Paris avec terrasse et jardin
un environnement multiculturel avec des collaborateurs aux nationalités multiples (France, Royaume-Uni, Etats-Unis, Chine, Tunisie, Italie et plus)
des projets avec nos bureaux à Londres, Hong Kong, New York, Shanghai, Genève, Shenzhen et Taipei
des TGIF et supers soirées
Show more
Show less","{'ProgLanguage': ['Python', 'R'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': ['Apache Airflow'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': ['AWS', 'Azure'], 'DevTools': ['Git', 'Docker'], 'Os': [], 'DBMS': ['Snowflake', 'Snowflake', 'BigQuery'], 'SoftBigDataProcessing': [], 'Automation': ['Kubernetes', 'Airflow'], 'InfrastructureAsCode': ['Terraform'], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': ['Docker', 'Kubernetes'], 'Collaboration': [], 'Other': ['Cloud', 'CI/CD'], 'FrSoftSkills': ['Collaboration', 'Organisation'], 'EnSoftSkils': ['Collaboration']}","{'JobDetail': ['Senior'], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's', '5', '5', '5']}"
LinkedIn,Data Engineer,NW,"Paris, Île-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-at-nw-3904072453?position=2&pageNum=15&refId=3Lir5Tz0viOiyHjhQOdm%2FQ%3D%3D&trackingId=FFg227%2BWLr13f6Zrujr8iA%3D%3D&trk=public_jobs_jserp-result_search-card,"Type de contrat :
CDI
Localisation :
Paris, 7ème (présentiel)
Date de début :
dès que possible
Expérience requise :
1 ou 2 ans d’expérience
A propos de NW
NW vise à rendre la transition énergétique accessible à tous. Depuis 2007, le groupe déploie des solutions innovantes pour augmenter la part des énergies décarbonées dans le mix électrique français, soutenir la stabilité du réseau électrique et contribuer au développement de la mobilité électrique.
Première licorne française de la transition énergétique, NW est le leader en France du stockage d'électricité avec sa solution JBox® et le précurseur de la recharge haute puissance grâce à ses bornes IECharge®. L'entreprise se développe également à l'international, en particulier en Europe et aux Etats-Unis. En février 2023, NW a rejoint la FrenchTech Next40.
Dans le cadre de notre forte croissance, nous recherchons un(e) Data Engineer pour rejoindre notre équipe tech. De formation Bac+5 Ingénieur ou similaire, vous souhaitez contribuer dans le domaine des énergies renouvelables, sur un poste à fort impact et au sein d’une jeune équipe et engagée.
Vos principales missions
Mettre en place des outils de traitement et stockage de données
Benchmarking des solutions les plus adaptées aux besoins des équipes
Assurer la sécurité de l’architecture de données
Participer à la sélection de la stack technique
Actualisation et adaptation des solutions utilisées selon l’évolution des technologies
Assurer la gestion des coûts liés aux besoins data avec les équipes internes
Support technique aux utilisateurs internes
Implémenter les processus de stockage et préparation des données
Configurer la connexion aux APIs internes et externes
Formation des équipes internes sur les sujets data
Vos compétences
Vous êtes intéressé(e) par les énergies renouvelables
Vous avez une réelle aisance relationnelle et une bonne capacité rédactionnelle
Vous avez la volonté de rejoindre une entreprise en pleine croissance avec un projet de développement ambitieux
Vous assurez la conversion des données
Vous maîtrisez de l’automatisation de la CI/CD
Vous parlez l’anglais couramment
Votre profil
Idéalement, vous avez 1 ou 2 ans d’expérience dans un poste similaire
Vous avez un Bac +5 Ingénieur ou similaire
Vous êtes curieux(se), rigoureux(se), proactif(ve) et autonome
Tech stack
Python
Docker
Kubernetes
Apache Kafka
Apache Flink
Github Actions
Apache Iceberg
Pourquoi NW ?
Découvrir le secteur de la mobilité électrique, du stockage d'énergie et du développement de projet dans une entreprise
Rejoindre une équipe dynamique, positive, engagée
Participez activement aux défis majeurs de la transition énergétique et de la décarbonisation des énergies
Entreprise en pleine croissance, possibilité d’avoir un impact important dans la valorisation de l’entreprise
Processus de recrutement :
Entretien RH
Entretien manager
Test technique
Entretien fit équipe
NW Groupe est un employeur garantissant l'égalité des chances. NW Groupe célèbre la diversité et s'engage à fournir un environnement de respect mutuel où toutes les décisions de recrutement sont basées sur les qualifications, le mérite et les besoins de l'entreprise.
Organisation et méthodologies ✅
Nous travaillons en Squad sur le principe du roulement de projet avec pour but de participer activement à la réflexion et au développement de chacune des applications de l'entreprise.
Projets et défis techniques 💻
Nos outils sont développés en interne et permettent de développer, installer et superviser plusieurs centaines de sites de stockage d'énergie. Chaque jour, ces outils permettent d'optimiser la gestion de notre activité et d'accélérer la transition énergétique visant la décarbonisation des énergies.
Recherche et Développement 🔍
Nous travaillons activement sur l’amélioration continue des concepts et des solutions existantes autour de la transition énergétique. Nos équipes s'occupent non seulement de la conception et de la l'amélioration de ces systèmes mais aussi de l'exploration de futures opportunités dans le secteur.
Show more
Show less","{'ProgLanguage': ['Python', 'R', 'Go'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': ['Flink'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git', 'Docker'], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': ['Apache Kafka', 'Apache Flink'], 'Automation': ['Kubernetes'], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': ['Docker', 'Kubernetes'], 'Collaboration': [], 'Other': ['CI/CD'], 'FrSoftSkills': ['Organisation'], 'EnSoftSkils': []}","{'JobDetail': [], 'TypeContract': ['CDI'], 'Salary': [], 'Level': ['Bac+5'], 'Experience': ['a', 'n', 's', '2', '2', '2']}"
LinkedIn,"Data Engineer F/H - Système, réseaux, données (H/F)",UpMan Consulting,"Lille, Hauts-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-f-h-syst%C3%A8me-r%C3%A9seaux-donn%C3%A9es-h-f-at-upman-consulting-3901572843?position=3&pageNum=15&refId=3Lir5Tz0viOiyHjhQOdm%2FQ%3D%3D&trackingId=5F%2FT5Lsts3uu%2FuZVqqv4gQ%3D%3D&trk=public_jobs_jserp-result_search-card,"Cette offre d’emploi est fournie par Pôle emploi
Description
Descriptif du poste: C est maintenant l occasion pour toi de rejoindre UpMan Consulting Notre ambition est de trouver les meilleurs profils Data Engineer pour intervenir chez nos clients grands comptes de la métropole lilloise. On te propose une expérience professionnelle en adéquation avec ce que tu souhaites réellement. Tu découvriras une ambiance de travail saine & bienveillante, tu participeras activement au développement d une Happy StartUp, actuellement en forte croissance. Où convivialité rime avec efficacité & où ta performance individuelle contribue à notre réussite globale. Tes missions / compétences techniques Si tu l acceptes, ton rôle & tes missions seront les suivantes : * Réaliser le processus d intégration de nouvelles données (réflexion sur la solution, mise en place d ETL, règles de nettoyage, anonymisation ) * Être garant de l'accès aux sources de données. * Maîtrise de la donnée et être le garant de sa qualité (référencement, normalisation et qualification) afin d'en faciliter l'exploitation par les équipes (Data Analysts et Data Scientists). * Maîtrise de technologies Big Data et Cloud : Hadoop, Spark * Assurer la supervision et l'intégration de données structurées et non structurées venant de sources multiples, tout en veillant à garder des données de qualité. * Assurer le suivi, la cartographie et la documentation des données intégrées * Afin de garantir une bonne exécution de ta mission, nous recherchons les compétences techniques suivantes : Langages de programmation : * SQL * Python / Pyspark * Java/Scala (plus rare, mais important) Différents types d ETL & orchestrateurs : * Airflow * Dagster * Prefect * SSIS/informatica * Talend Plateformes cloud : * GCP * Microsoft Azure * AWS Base de données relationnelles & NoSQL : * postgreSQL, MySQL,... * Redis, graphDB * Data warehouse/data transform : * Snowflake, Bigquery (très important) * DBT Qualité & compétences nécessaires * Communiquant.e dans l âme * Avoir une bonne capacité de synthèse & l esprit critique * Travail d équipe * Curiosité aiguë * Comprendre les objectifs & les besoins Nice to have * Anglais courant * Connaissance de la méthodologie DevOps * Notions en Data-science The office Pas de full remote (pour l instant) mais de l hybride dans la plupart des missions. En moyenne, 2 jours de télétravail par semaine. Cependant, les portes de nos bureaux à Wambrechies sont toujours ouvertes pour accueillir nos collaborateurs pendant leurs journées de télétravail & passer une bonne journée tous ensemble ! Le salaire Junior : 30K à 36K Maîtrisant : 37K à 43K Expert : 44K à 50K & plus + notre package avantage Profil recherché: Ton Profil Tu es une personne passionnée & passionnante. Tu as envie d'évoluer, de partager, de participer à une mission collective & découvrir LA nouvelle façon de collaborer avec une ESN made in Lille. Tu peux justifier d'une expérience forte & significative en tant que Tech Lead Java, dans le développement Java ! Pas besoin d'avoir trop ou pas assez de diplômes, chez nous, ce sont les compétences qui priment  ! On se rencontre, on discute, on échange sur tes envies professionnelles & on laisse la magie opérer. L'envie de grandir & de monter en compétences est ton moteur au quotidien. Tu aimes les problématiques complexes et les défis technologiques. On dit de toi que tu es un.e agiliste dans l'âme, qui effectue une veille constante, à l'affût de tout ce qui évolue autour de toi... Ne réfléchis plus, saute le pas & découvre UpMan Consulting, tu ne seras pas déçu. Tu balances ta démission ?
PROFIL SOUHAITÉ
Expérience
Expérience exigée de 1 An(s)
Source: Pole emploi (https://www.pole-emploi.fr)
Show more
Show less","{'ProgLanguage': ['Python', 'Java', 'Scala', 'R'], 'DataBase': ['SQL', 'NoSQL'], 'DataAnalytics': ['R'], 'BigData': ['Hadoop', 'Spark'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': ['AWS', 'Azure'], 'DevTools': [], 'Os': [], 'DBMS': ['MySQL', 'PostgreSQL', 'Snowflake', 'Snowflake', 'BigQuery'], 'SoftBigDataProcessing': [], 'Automation': ['Airflow'], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['DevOps', 'Big Data', 'Cloud'], 'FrSoftSkills': [], 'EnSoftSkils': []}","{'JobDetail': ['Hybride', 'Remote', 'Full', 'Junior'], 'TypeContract': [], 'Salary': ['30K', '1'], 'Level': [], 'Experience': ['a', 'n', 's']}"
LinkedIn,Data Engineer GCP (F/H),Apside,"Paris, Île-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-gcp-f-h-at-apside-2859485219?position=4&pageNum=15&refId=3Lir5Tz0viOiyHjhQOdm%2FQ%3D%3D&trackingId=wv7OLTbzzRJCbMwFBnb29w%3D%3D&trk=public_jobs_jserp-result_search-card,"Envie de rejoindre une entreprise apprenante ? Engagée pour t’accompagner dans ton évolution professionnelle et dans tes projets personnels ?
Rejoins Apside Paris pour travailler sur nos projets de demain !
Le poste :
Tu seras amené à participer à la migration des données et le traitements Big Data depuis un cluster Hadoop interne vers l'infrastructure Google Cloud Platform.
Dans ce sens, tes missions seront les suivantes :
Participation aux chantiers de cadrage de la migration
Contribution à la mise en place des environnements et outils de déploiement automatisés
Accompagnement et formation des équipes à l’outil GCP
...
Environnement technique :
Jira Big data
Cloud GCP
Hadoop
Kubernetes
Spark, Kafka, Python
Toi ?
Tu as déjà participé à un projet de
migration Google Cloud Platform (GCP)
?
Tu es
rigoureux
,
bon communiquant
?
Tu souhaites participer à un
projet d’envergure associant cloud et Big Data
?
Alors ce poste de
Data Engineer GCP
est fait pour toi !
Et la suite ?
Tu rencontres d’abord l’équipe RH pour parler de tes attentes, ton projet, ton futur !
Puis les managers pour parler concret : missions, projets, parcours de carrière, et bien sûr salaire et avantages :)
Et tu discutes avec un de nos Tech Leads, pour évaluer tes compétences et te challenger.
Tu souhaites donner un nouvel élan à ta carrière ? Rejoins la vie Apsidienne !
Pour en savoir plus à www.apside.com
Show more
Show less","{'ProgLanguage': ['Python', 'R', 'Go'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': ['Hadoop', 'Spark'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': ['Google Cloud Platform'], 'DevTools': [], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': ['Kubernetes'], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': ['Kubernetes'], 'Collaboration': ['JIRA'], 'Other': ['Big Data', 'Cloud'], 'FrSoftSkills': [], 'EnSoftSkils': []}","{'JobDetail': [], 'TypeContract': [], 'Salary': ['Salaire'], 'Level': [], 'Experience': ['a', 'n', 's']}"
LinkedIn,Data Engineer Spark Scala - Services Financiers - Ile de France,Sopra Steria,"Paris, Île-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-spark-scala-services-financiers-ile-de-france-at-sopra-steria-3913390665?position=5&pageNum=15&refId=3Lir5Tz0viOiyHjhQOdm%2FQ%3D%3D&trackingId=jSrg1Q0BPIqKrW7h8N2KDQ%3D%3D&trk=public_jobs_jserp-result_search-card,"Company Description
Sopra Steria
, acteur majeur de la Tech en Europe, reconnu pour ses activités de conseil, de services numériques et d’édition de logiciels, aide ses clients à mener leur transformation digitale et à obtenir des bénéfices concrets et durables. Il apporte une réponse globale aux enjeux de compétitivité des grandes entreprises et organisations, combinant une connaissance approfondie des secteurs d’activité et des technologies innovantes à une approche résolument collaborative.
Sopra Steria place l’humain au centre de son action et s’engage auprès de ses clients à tirer le meilleur parti du digital pour construire un avenir positif.
Fort de 56 000 collaborateurs dans près de 30 pays, le Groupe a réalisé un chiffre d’affaires de 5,8 milliards d’euros en 2023.
The world is how we shape it
Job Description
Votre futur environnement de travail :
Chez notre client, grande banque commerciale française, vous intégrez nos squads pour intervenir sur des projets de grande envergure, des projets transformants et structurants de la banque de demain. Vous interviendrez sur la gestion d’applications sur des domaines tels que : la conformité, la fraude, la lutte anti-blanchiment, les risques de crédit, la trésorerie, les paiements, les financements structurés ou encore le réglementaire bancaire.
Au sein de notre Data Factory, vous êtes pleinement impliqué(e) dans toutes les phases de nos projets pour le compte de grands clients, contribuant ainsi à leur succès. Vous avez l'occasion de développer vos compétences techniques et fonctionnelles de manière approfondie, tout en travaillant sur des projets exigeants et passionnants pour le compte de grands clients du secteur bancaire.
Votre rôle et vos missions :
Vous avez pour rôle la mise en place de pipelines de données fiables, sécurisés et à l’échelle pour soutenir la mise à disposition des données aux cas d’usage métier qui en ont besoin.
Vos activités principales sont les suivantes :
Vous travaillez avec le client pour évaluer, concevoir, déployer, améliorer et maintenir les pipelines de données;
Vous vous assurez que les pipelines de données créés sont résilients, sécurisés et accessibles;
Vous définissez le modèle opérationnel pour monitorer et supporter les pipelines de données
Vous fournissez une expertise à nos clients sur leurs données pour assurer leur optimisation et leur sécurité par rapport à leurs besoins;
Vous apportez un savoir en gestion de la qualité et la gouvernance de la donnée pour assurer le suivi de la conformité à la gouvernance de la donnée
Vous faites de la veille technologique dans le domaine afin d’enrichir les roadmaps technologiques et fournir des solutions modernes à nos clients.
Qualifications
Votre profil :
De formation Master 2 Ecole d'Ingénieurs ou Informatique, ou équivalent, vous justifiez d'une expérience technique de 3 ans minimum et souhaitez évoluer rapidement dans un contexte motivant. Vous avez ces compétences requises :
Maîtrise des technologies de bases de données Relationnelles et NoSQL
Maîtrise d’au moins un outil d’ETL/ELT (Informatica, datastage, etc.)
Maîtrise des technologies de traitement distribué de données (spark, scala, Hadoop)
Maîtrise d’au moins un framework de streaming de données (Kafka, RabbitMQ, etc.)
Maîtrise de chaines CI/CD et de des bonnes pratiques de DataOps
Maîtrise de solution de Vitrtualisation de données (Denodo, Dremio, etc.)
Méthodologie Agile Scrum
Anglais professionnel
Vous êtes attiré(e) par le monde du numérique, le Cloud (maitrise d'un environnement public ou privé est un plus) et des technologies innovantes.
Vous avez un bon esprit d'analyse, êtes curieux(se) et passionné(e) et vous avez le sens du travail en équipe.
Additional Information
Ce que nous vous proposons :
Un accord télétravail pour télétravailler jusqu'à 2 jours par semaine selon vos missions.
Un package avantages intéressants : une mutuelle, un CSE, des titres restaurants, un accord d'intéressement, des primes vacances et cooptation.
Un accompagnement individualisé avec un mentor.
Des opportunités de carrières multiples : plus de 50 métiers, autant de passerelles à imaginer ensemble.
Plusieurs centaines de formations accessibles en toute autonomie depuis l'app mobile avec Sopra Steria Academy.
.La possibilité de s'engager auprès de notre fondation ou de notre partenaire « Vendredi ».
L'opportunité de rejoindre le collectif Tech'Me UP (formations, conférences, veille, et bien plus encore).
Employeur inclusif et engagé, notre société œuvre chaque jour pour lutter contre toute forme de discrimination et favoriser un environnement de travail respectueux. C’est pourquoi, attachés à la mixité et à la diversité, nous encourageons toutes les candidatures et tous les profils.
https://www.soprasteria.fr/nous-connaitre/nos-engagements
Show more
Show less","{'ProgLanguage': ['Scala', 'R', 'Go'], 'DataBase': ['SQL', 'NoSQL'], 'DataAnalytics': ['R'], 'BigData': ['Hadoop', 'Spark'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git'], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Cloud', 'CI/CD'], 'FrSoftSkills': ['Organisation'], 'EnSoftSkils': []}","{'JobDetail': [], 'TypeContract': [], 'Salary': ['50'], 'Level': [], 'Experience': ['a', 'n', 's', '3', '3', '3']}"
LinkedIn,"Data Engineer (Python/Spark/Hadoop)-Aix-en-Provence F/H - Système, réseaux, données (H/F)",scient,"Aix-en-Provence, Provence-Alpes-Côte d'Azur, France",https://fr.linkedin.com/jobs/view/data-engineer-python-spark-hadoop-aix-en-provence-f-h-syst%C3%A8me-r%C3%A9seaux-donn%C3%A9es-h-f-at-scient-3904578388?position=6&pageNum=15&refId=3Lir5Tz0viOiyHjhQOdm%2FQ%3D%3D&trackingId=J%2B0%2BLvS4df0oncADPyQXRg%3D%3D&trk=public_jobs_jserp-result_search-card,"Cette offre d’emploi est fournie par Pôle emploi
Description
Descriptif du poste: Votre travail quotidien consistera à : * Concevoir des modèles efficaces pour stocker et analyser des téraoctets de données. * Mettre en œuvre des flux d'acquisition et de transformation complexes * Construire des modèles de données intelligents pour servir nos équipes produits et nos équipes BI, Insights et data science tout en minimisant les coûts. * Développer des outils pour aider nos data scientists à industrialiser les projets d'apprentissage automatique. * Travailler sur la qualité et la fiabilité des données pour garantir que nous fournissons des mesures fiables à l'ensemble de l'entreprise. * Développer des outils pour aider nos scientifiques à industrialiser les projets d'apprentissage automatique. * Développer notre plateforme de science des données * Industrialiser les projets d'apprentissage automatique avec les scientifiques spécialisés dans les données. Les enjeux * Data powerBI sur un data center -> doit être migré dans 1 autre serveur * Travailler sur une infra hadoop / migration de MariaDB à techno GPAS. * Aujourd'hui reçoit des flux de fichiers avec un ETL et met dans sa base MariaDB. L'environnement va être remplacé en plus du changement de serveur. L'ETL fait dans MariaDB va devoir être recréé dans GPAS Profil recherché: Votre profil : * Avec un minimum de 3 ans d'expérience, vous avez une parfaite connaissance des Data Engineering, des technologies et vous maîtrisez python (idéalement avec plusieurs autres langages backend et vous connaissez bien les meilleures pratiques de développement logiciel, telles que CI/CD, tests unitaires, QA et création de mocks...). * Excellent esprit d'équipe et à l'aise pour interagir avec les parties prenantes techniques et commerciales. * Habitué à travailler dans un environnement agile et à accepter les changements de priorités. * Curieux, humble et faisant preuve d'un équilibre entre créativité et pragmatisme. * Grande volonté d'apprendre et d'enseigner aux autres * Maîtrise de l'anglais (écrit et parlé) Compétences techniques : * Maîtrise de Python, Scala, Spark et PostgreSQL * Maitrise Pyspark, Hive et Hadoop * Vous êtes curieux, autonome, rigoureux et proactif, vous souhaitez rejoindre une équipe passionnée d'informatique, d'IA et d'innovations et que vous maîtrisez les compétences nécessaires.
PROFIL SOUHAITÉ
Expérience
Expérience exigée de 1 An(s)
Source: Pole emploi (https://www.pole-emploi.fr)
Show more
Show less","{'ProgLanguage': ['Python', 'Scala', 'R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': ['Hadoop', 'Spark'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': ['PowerBI'], 'Statistics': [], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'DBMS': ['PostgreSQL'], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['CI/CD'], 'FrSoftSkills': ['Créativité'], 'EnSoftSkils': []}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's', '3', '3', '3']}"
LinkedIn,Data Engineer,Pictarine,"Toulouse, Occitanie, France",https://fr.linkedin.com/jobs/view/data-engineer-at-pictarine-3911913926?position=7&pageNum=15&refId=3Lir5Tz0viOiyHjhQOdm%2FQ%3D%3D&trackingId=U7AF5ggHYB4XAUH2FvxmZQ%3D%3D&trk=public_jobs_jserp-result_search-card,"Mission and challenges 🎯
Si tu es enthousiaste à embarquer dans la nouvelle équipe data de Pictarine pour la faire rayonner avec tout ton savoir-faire, alors c’est l’aventure qu’il te faut! 🏔️
Avec plus de 1K tables, 2M de clients et 4M de commandes en 2022, les équipes de Pictarine ne sont jamais à court d’idées pour explorer de nouveaux horizons. 🚀
En tant que Data Engineer chez Pictarine tu vas pouvoir utiliser toutes tes compétences SQL pour garantir la qualité de la data sur GCP, accompagner et challenger les besoins data.
Tu évolueras au sein de l’équipe Engineering, composée des pôles dev & data.
Ton rôle comprendra les aspects suivants 👇🏻
Tu es garant de la qualité de la data !
En simplifiant la structure de la data et réduisant le nombre de tables
En transformant les données pour les rendre facilement utilisables
En orchestrant le flux des données de manière continue et automatique
Tu accompagnes et challenges les équipes de Pictarine !
En co-construisant des solutions data appropriées
En élevant le niveau de jeu des méthodes data existantes
En faisant rayonner la data autour de bonnes pratiques et d’outillages adéquates
Profil Recherché
About you 💎
Tu as au moins 5 ans d’expérience sur un poste similaire
Tu maîtrises le data warehouse BigQuery et son langage SQL
Tu es à l'aise avec les services GCP
Tu as de bonnes connaissances dans la conception de modèles de données et les stratégies d'optimisation des requêtes SQL
Tu as des compétences en DevOps pour le déploiement et la gestion efficace des pipelines de données
Tu as une bonne maîtrise de Python & Github
Tu es organisé, rigoureux et portes une grande attention aux détails
Tu es doté d’excellentes qualités relationnelles, de communication et de vulgarisation
Tu as une passion pour résoudre des problèmes business avec la programmation
Tu es curieux de tester des nouvelles technologies
Tu es un team player et toujours à l'affût de nouvelles idées
Work @ Pictarine✨
Un environnement de travail agile, collaboratif, international et multiculturel
Des perspectives d’évolution rapides
Des locaux tout beaux à Labège avec du matériel dernier cri (mais aussi des snacks à profusion et un frigo à boissons toujours bien rempli)
Un apprentissage permanent : conférence, meet-up, Pictarine Academy, cours d’anglais.
Des events tous les mois : massage, pilates, TGIF, team building .
Un environnement de travail flexible : horaires, politique de remote hybride.
Un package de rémunération attractif : salaire compétitif, RTT, mutuelle & prévoyance 100% prise en charge, intéressement.
Des petits + : Développement de photos gratuit, subvention sport, 3 jours “entraide familiale”, jours de congés en plus avec l'ancienneté... 🤫 on ne te dévoile pas tout !
Recruitment process ⚙️
Tu souhaites nous rejoindre ? Viens rencontrer les gens avec qui tu vas bosser :
1er échange pour apprendre à se connaître avec Marie - Engineering Manager Data (15’)
Entretien Manager avec Marie (60-90’)
Test pratique afin de nous montrer tes talents 🙂 (3 heures)
Entretien final avec 2 membres du Codir (90’)
Welcome aboard !
Show more
Show less","{'ProgLanguage': ['Python', 'R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git'], 'Os': [], 'DBMS': ['BigQuery'], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['DevOps'], 'FrSoftSkills': ['Communication'], 'EnSoftSkils': ['Communication']}","{'JobDetail': ['Hybride', 'Remote'], 'TypeContract': [], 'Salary': ['100', '100'], 'Level': [], 'Experience': ['a', 'n', 's', '5', '5', '5']}"
LinkedIn,Développeur Big Data - Spark,NEXTON,"Lyon, Auvergne-Rhône-Alpes, France",https://fr.linkedin.com/jobs/view/d%C3%A9veloppeur-big-data-spark-at-nexton-3911787310?position=8&pageNum=15&refId=3Lir5Tz0viOiyHjhQOdm%2FQ%3D%3D&trackingId=gspnV%2B2uQbImXFxdlEEzMQ%3D%3D&trk=public_jobs_jserp-result_search-card,"Mission (fiche métier)
NEXTON recrute un
Développeur Big Data - Spark
, en CDI, à
Lyon
!
Qui sommes-nous ?
NEXTON c’est avant tout une entreprise qui accompagne ses clients dans leur transformation digitale. Tous les jours, nous travaillons avec des grands comptes et des pures players (SNCF, Orange, BNP PARIBAS…).
Nous sommes experts du digital aussi bien sur de l’accompagnement stratégique qu’opérationnel.
Fort du succès, Nexton connaît aujourd’hui un développement significatif, autour de ses valeurs piliers : cohésion, confiance et performance.
Et pour toi ? Notre politique de développement des compétences dynamique saura te séduire avec un programme de suivi de carrière sur-mesure.
Le contexte :
Pour l'un de nos clients, dans le secteur de l'énergie, nous sommes à la recherche d'un développeur Big Data.
Les missions :
Apporter une expertise
Big Data
pour faciliter la manipulation des données.
Définir les solutions techniques permettant le traitement massif des données.
Mettre en place des
solutions de stockage de données
(SQL, NoSQL etc.)
Veiller la sécurisation et la clarté des pipelines de données pour faciliter
l'analyse
et la
transformation
.
Assurer la création, la maintenance, l'optimisation et la sécurité des bases de données.
Assurer le support aux équipes de
développement
afin d'identifier et proposer des solutions performantes.
Profil (fiche métier)
De formation supérieure, tu justifies d'une expérience d'au moins
4 ans
dans le domaine.
Tu maitrises
Spark
,
Python
et
SQL
.
Tu es
autonome
,
rigoureux
et
force de proposition
.
De plus, tu as acquis une
capacité d'analyse
et de
synthèse
grâce à tes différentes expérience.
Tu maitrises également les fondamentaux de
l'agilité
.
Enfin, ton
esprit d'équipe
te permet de communiquer et de travailler dans les meilleures conditions.
NEXTON c’est aussi et surtout de nombreux moments de rencontres tout au long de l’année :
- Des communautés : 2 Meet Up par mois pour partager et échanger avec des experts
- De nombreux moments de rencontres professionnels et extra professionnels tout au long de l’année
- Des moments privilégiés avec ton manager
Prêts à nous rejoindre ? Rencontrons-nous !
Show more
Show less","{'ProgLanguage': ['Python', 'R', 'Go'], 'DataBase': ['SQL', 'NoSQL'], 'DataAnalytics': ['R'], 'BigData': ['Spark'], 'MachingLearning': ['Orange'], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git'], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Big Data'], 'FrSoftSkills': [], 'EnSoftSkils': []}","{'JobDetail': [], 'TypeContract': ['CDI'], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's', '4', '4', '4']}"
LinkedIn,Data Engineer Talend / Spark / Scala / MSBI,Sibylone,"Paris, Île-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-talend-spark-scala-msbi-at-sibylone-3918822674?position=9&pageNum=15&refId=3Lir5Tz0viOiyHjhQOdm%2FQ%3D%3D&trackingId=GQ2byteWKyn3cPr%2FE6GnrA%3D%3D&trk=public_jobs_jserp-result_search-card,"SIBYLONE
, société de conseil spécialisée dans les systèmes d’information de synthèse et de pilotage, aide ses clients à tirer toute la valeur de leur patrimoine de données, levier stratégique majeur de développement et de rentabilité.
Notre ambition : rendre les différents acteurs de l’entreprise autonomes dans l’exploitation des données, libérer les usages Métier, pour qu’ils soient en mesure de relever les défis de performance, de couverture de risque, de financement, de conquête client, de RSE… qui s’imposent à eux.
Spécialistes reconnus, nos consultants s’appuient pour cela sur une connaissance approfondie de l’activité business de nos clients, en lien avec nos trois piliers que sont le Métier, la Data et le Projet.
SIBYLONE emploie 250 salariés et réalise un CA de 30m€ dans la prestation de services auprès de grandes entreprises (8 grands comptes représentant 80% du CA). SIBYLONE est une filiale du Groupe Smart 4 Engineering créé en 2020. Le groupe s’est constitué en procédant à l’acquisition de 12 sociétés en France, en Italie, en Espagne et au Portugal dans le domaine de l’ingénierie. Avec nos 3,000 ingénieurs / consultants hautement qualifiés, le Groupe offre ses services dans les domaines très porteurs du Digital, de la Data, de l’Intelligence Artificielle, de la Cybersécurité, du Cloud.
Nous recherchons pour l’un de nos clients du domaine bancaire :
Un.e Data Engineer
Le Data Engineer intégrera une équipe projet Big Data dont l’objectif premier est de conduire des projets ayant traits à des problématiques d’architecture et de conception.
Le Data Engineer sera en charge de la maintenance, du support et de l’évolution d’un outil de pilotage financier déployé au sein des directions centrales du groupe et de la facturation interne. Il participera notamment à la conception, la construction, le déploiement et le maintien en production d’architectures Big Data, ces dernières ayant pour objectif de permettre tant l’évolution que l’optimisation du système d’information décisionnel existant.
Missions
Analyser, comprendre et cadrer une architecture permettant de répondre aux besoins métiers des clients
Concevoir et mettre en place des plateformes Data en tenant compte des contraintes tant techniques que fonctionnelles
Intervenir sur la conception et le déploiement d’environnements
Développement de pipelines d’ingestion et de préparation
Gestion du stockage de données (systèmes de fichiers comme HDFS, bases SQL ou NoSQL)
Alimentation d’entrepôts de données (Hive, Impala, Hbase, Snowflake, BigQuery, …)
Développer des applications d’exploration et de manipulation de données (SPARK / pySpark, Scala) afin d’alimenter les flux sortants, les reporting et d’exposer les données
Evoluer sur l’ordonnancement des traitements de données (Oozie, Bash / Shell)
Assurer le maintien en conditions opérationnelles des plateformes produites
Etablir, formaliser, et promouvoir les best practices
Pourquoi pas vous ?
Profil recherché :
De formation supérieure ingénieur en Informatique, vous justifiez d’une première expérience réussie en data engineering acquise dans un contexte projet au sein d’une start-up, d’un pure player, ou d’une ESN.
Vous disposez d’une bonne maitrise des langages propres aux environnements Big Data tels que :
Hadoop
Talend (Data Integration, Big Data)
Les solutions Cloud (Azure, AWS, GPC)
Spark, Scala, Python, Unix, SQL
Microsoft Power BI
Une connaissance de : Docker, ELK, Kubernetes, Cassandra, Kafka, … serait un plus, de même que des fondamentaux DevOps (CI / CD).
Vous avez déjà évolué dans un contexte projet agile ou scrum et faites preuve de flexibilité, d’adaptabilité et savez être force de proposition.
Au-delà de vos compétences techniques, vous êtes curieux, autonome, organisé, doté d’un bon sens relationnel et d’un esprit de synthèse.
Vous vous reconnaissez dans la description du poste ?
Vous souhaitez travailler dans un environnement stimulant et dynamique ?
Vous souhaitez rejoindre une société ambitieuse ?
Vous souhaitez comprendre l’origine de Sibylone ?
Venez-nous rencontrer :
La Team Talent Acquisition sera ravie d'échanger avec vous !
Ce poste est ouvert aux personnes en situation de handicap.
Show more
Show less","{'ProgLanguage': ['Python', 'Scala', 'R', 'Bash'], 'DataBase': ['SQL', 'NoSQL', 'Cassandra', 'HBase'], 'DataAnalytics': ['R'], 'BigData': ['Hadoop', 'Spark'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': ['Power BI'], 'Statistics': [], 'CloudComputing': ['AWS', 'Azure'], 'DevTools': ['Git', 'Docker'], 'Os': [], 'DBMS': ['Snowflake', 'Snowflake', 'BigQuery'], 'SoftBigDataProcessing': ['HBase'], 'Automation': ['Kubernetes'], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': ['Docker', 'Kubernetes'], 'Collaboration': [], 'Other': ['DevOps', 'Big Data', 'Cloud', 'CI / CD'], 'FrSoftSkills': ['Adaptabilité', 'Flexibilité'], 'EnSoftSkils': []}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's']}"
LinkedIn,Data Engineer H/F,Amiltone,"Lille, Hauts-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-h-f-at-amiltone-3846492584?position=10&pageNum=15&refId=3Lir5Tz0viOiyHjhQOdm%2FQ%3D%3D&trackingId=nJmMAJWbmBew3htigNQ6mA%3D%3D&trk=public_jobs_jserp-result_search-card,"Qui sommes-nous ?
Nous sommes passionnés par les nouvelles technologies, et vous ?
Rejoindre Amiltone, c’est intégrer des équipes dynamiques et soudées dans le cadre de projets novateurs et ambitieux. Nous relevons les challenges techniques de nos clients et les accompagnons dans leur transformation digitale.
Pourquoi choisir Amiltone ?
Amiltone, plus qu’une entreprise, un état d’esprit !
Notre objectif ? Votre épanouissement professionnel !
Nous Avons à Cœur De
Vous accompagner au mieux au travers d’un suivi personnalisé
Vous faire monter en compétences en vous proposant des formations tout au long de votre carrière
Comprendre vos besoins et respecter nos engagements
Vous proposer des missions de qualité avec des technologies innovantes
Cultiver votre potentiel grâce à notre programme de développement personnel Addvise
Votre bien-être passe aussi par des activités extraprofessionnelles, c’est pourquoi nous vous proposons des séances sportives animées par nos coachs, soirées pour se retrouver et animations (à l'agence ou en visio), Gaming nights…
Les Missions D'un Amiltonien
En tant que Data Engineer
(H/F)
, vous serez en charge des missions suivantes :
– Concevoir et développer les futures fonctionnalités de la plateforme Big Data sous Google Cloud Platform.
– Concevoir les flux d'alimentation et les tables (structure de donnée).
– Automatiser et industrialiser les flux.
– Assurer le run applicatif, le cas échéant.
La Stack Technique
Maîtrise des langages suivants : SQL, Talend, BigQuery
Connaissances de Google (GCP)
Notion de programmation fonctionnelle
Le Profil D’un Amiltonien
Diplômé Bac+4/5 (Ecole d'ingénieur/Master), vous disposez de 2 années d'expérience dans le développement de data.
Toujours sur le qui-vive des nouveautés technologiques, vous êtes force de proposition sur des technos, des outils ou des process qui permettent d'améliorer la qualité du code et la stabilité de nos applications.
Outre vos compétences techniques, nous nous intéressons également à votre potentiel et votre motivation.
Nos postes sont ouverts aux personnes en situation de handicap.
Postuler
Show more
Show less","{'ProgLanguage': ['R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': ['Google Cloud Platform'], 'DevTools': ['Git'], 'Os': [], 'DBMS': ['BigQuery'], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Big Data', 'Cloud'], 'FrSoftSkills': [], 'EnSoftSkils': []}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's']}"
