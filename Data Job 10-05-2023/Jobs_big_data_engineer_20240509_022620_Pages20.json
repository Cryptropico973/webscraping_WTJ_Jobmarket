[
    {
        "source": "LinkedIn",
        "title": "ING\u00c9NIEUR DATA",
        "company": "Akademija Oxford",
        "location": "Ille-et-Vilaine, Brittany, France",
        "link": "https://fr.linkedin.com/jobs/view/ing%C3%A9nieur-data-at-akademija-oxford-3912800588?position=2&pageNum=0&refId=TDTc9UZJy78L%2BED7EV%2BMrg%3D%3D&trackingId=qxkAxO3kCKPFsjtGrF%2F6AA%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Vous souhaitez int\u00e9grer une \u00e9cole \u00e0 taille humaine ? Vous \u00eates int\u00e9ress\u00e9.es par la donn\u00e9e ? Sup de Vinci propose une formation compl\u00e8te, en Mast\u00e8re Big Data & Intelligence Artificielle (2 ann\u00e9es en alternance).\nL\u2019\u00e9cole Sup de Vinci, Rennes, accompagne l\u2019une de ses entreprises partenaires dans son projet de recrutement d\u2019un profil ing\u00e9nieur data, en alternance pour la rentr\u00e9e 2022.\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "R"
            ],
            "DataBase": [],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [],
            "DevTools": [],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [
                "Big Data"
            ],
            "FrSoftSkills": [],
            "EnSoftSkils": []
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "title": "Hadoop Data Engineer (F/H)",
        "company": "Thales",
        "location": "V\u00e9lizy-Villacoublay, \u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/hadoop-data-engineer-f-h-at-thales-3890949542?position=3&pageNum=0&refId=TDTc9UZJy78L%2BED7EV%2BMrg%3D%3D&trackingId=NUzkjoDiCgv%2B68vSb9TBHw%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "QUI SOMMES-NOUS ?\nThales est un leader mondial des hautes technologies comptant plus de 81 000 collaborateurs pr\u00e9sents sur tous les continents. Le Groupe investit dans les innovations du num\u00e9rique et de la \u00ab deep tech \u00bb \u2013 big data, intelligence artificielle, connectivit\u00e9, cybers\u00e9curit\u00e9 et quantique \u2013 pour construire un avenir de confiance, essentiel au d\u00e9veloppement de nos soci\u00e9t\u00e9s, en pla\u00e7ant l\u2019humain au c\u0153ur des d\u00e9cisions.\nThales propose des solutions, services et produits qui aident ses clients \u2013 entreprises, organisations, Etats \u2013 dans cinq grands march\u00e9s vitaux pour le fonctionnement de nos soci\u00e9t\u00e9s : identit\u00e9 et s\u00e9curit\u00e9 num\u00e9riques, d\u00e9fense, a\u00e9ronautique, espace, et transport.\nQUI ETES-VOUS ?\nDipl\u00f4m\u00e9 d\u2019un Bac+5 en \u00e9cole d\u2019ing\u00e9nieur ou \u00e9quivalent universitaire avec une sp\u00e9cialisation en informatique, vous avez au moins 3 ans d'exp\u00e9rience dans les technologies Big Data.\nCE QUE NOUS POUVONS ACCOMPLIR ENSEMBLE :\nEn tant que Data Engineer, vous jouerez un r\u00f4le cl\u00e9 dans la conception, le d\u00e9veloppement et la maintenance de notre infrastructure de donn\u00e9es, ainsi que dans la transformation et la gestion des flux de donn\u00e9es.\nVOS MISSIONS :\n\u2022 Concevoir, d\u00e9velopper et d\u00e9ployer des solutions Big Data en utilisant les technologies Hadoop.\n\u2022 Mettre en place des pipelines de donn\u00e9es performants pour l'ingestion, le traitement et le stockage des donn\u00e9es massives.\n\u2022 Collaborer \u00e9troitement avec les \u00e9quipes m\u00e9tier pour comprendre leurs besoins en mati\u00e8re d'analyse de donn\u00e9es et proposer des solutions adapt\u00e9es.\n\u2022 Optimiser les performances des clusters Hadoop pour garantir une exploitation efficace des donn\u00e9es.\n\u2022 Assurer la qualit\u00e9 et la fiabilit\u00e9 des donn\u00e9es trait\u00e9es, en mettant en place des processus de validation et de nettoyage.\n\u2022 Identifier et r\u00e9soudre les probl\u00e8mes li\u00e9s \u00e0 l'infrastructure Big Data et proposer des am\u00e9liorations.\n\u2022 Travailler en \u00e9troite collaboration avec les Data Scientists et les Data Analysts pour fournir des insights pertinents \u00e0 partir des donn\u00e9es.\nInnovation, passion, ambition : rejoignez Thales et cr\u00e9ez le monde de demain, d\u00e8s aujourd\u2019hui.\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "R"
            ],
            "DataBase": [],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [
                "Hadoop"
            ],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [],
            "DevTools": [],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [
                "Big Data"
            ],
            "FrSoftSkills": [
                "Collaboration",
                "Organisation"
            ],
            "EnSoftSkils": [
                "Collaboration"
            ]
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [],
            "Salary": [],
            "Level": [
                "Bac+5"
            ],
            "Experience": [
                "a",
                "n",
                "s",
                "3",
                "3",
                "3"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "title": "Data Engineer / D\u00e9veloppeur Big Data # H/F",
        "company": "Air France",
        "location": "Provence-Alpes-C\u00f4te d'Azur, France",
        "link": "https://fr.linkedin.com/jobs/view/data-engineer-d%C3%A9veloppeur-big-data-%23-h-f-at-air-france-3900080172?position=4&pageNum=0&refId=TDTc9UZJy78L%2BED7EV%2BMrg%3D%3D&trackingId=r6G3xtDtwyoSIYOezOARsw%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Description du poste\nIntitul\u00e9 du poste\nData Engineer / D\u00e9veloppeur Big Data # H/F\nM\u00e9tier\nSyst\u00e8mes d'informations - D\u00e9veloppement\nCat\u00e9gorie socio-professionnelle\nCadre\nPr\u00e9sentation du contexte\nVous avez peut-\u00eatre d\u00e9j\u00e0 voyag\u00e9 avec nous, mais que connaissez-vous de nos m\u00e9tiers et de la richesse des donn\u00e9es qu\u2019ils g\u00e9n\u00e8rent au quotidien ? Comment le traitement et l\u2019exploitation de ces donn\u00e9es peut contribuer \u00e0 notre strat\u00e9gie de Revenue Management, ou encore aux multiples op\u00e9rations \u00e0 r\u00e9aliser pour permettre \u00e0 un vol de partir \u00e0 l\u2019heure ?\nAir France-KLM fait r\u00eaver 104 millions de passagers par an, en les emmenant vers plus de 250 destinations, gr\u00e2ce \u00e0 une flotte de plus de 500 appareils. Le Groupe emploie 80 000 collaborateurs partout dans le monde :les opportunit\u00e9s sont vastes pour mettre \u00e0 profit ses comp\u00e9tences, apprendre et se d\u00e9velopper !\nLe d\u00e9partement de d\u00e9veloppement DATA, OR & AI d\u2019Air France, au sein de la direction des Syst\u00e8mes d\u2019Information, intervient dans toute la cha\u00eene de captation et de traitement des donn\u00e9es du groupe pour d\u00e9livrer \u00e0 nos m\u00e9tiers des solutions applicatives cl\u00e9s en main.\nLe d\u00e9partement est \u00e9galement en charge de l\u2019ensemble des outils techniques (ETL, DataLakes, DataWarehouses, Data visualisation) et du d\u00e9veloppement des talents et comp\u00e9tences de Data Engineering.\nNotre mission ? Transformer la donn\u00e9e brute en d\u00e9cision intelligente, pour mieux optimiser les m\u00e9tiers d\u2019Air France \u2013 KLM !\nPour cela, nous avons chacun un r\u00f4le essentiel \u00e0 jouer, pourquoi le v\u00f4tre ne serait pas celui de Data Engineer et de d\u00e9veloppeur Big Data ?\nDescription de la mission\nAu sein de notre d\u00e9partement, vous travaillerez main dans la main avec d\u2019autres Data Engineers et d\u00e9veloppeurs Big Data ainsi qu\u2019avec des sp\u00e9cialistes des m\u00e9tiers.\nInt\u00e9gr\u00e9 au sein d\u2019une product team agile passionn\u00e9e et dynamique :\nVous participez \u00e0 l\u2019analyse des besoins m\u00e9tiers du commercial, des op\u00e9rations a\u00e9riennes, de l\u2019exploitation sol en a\u00e9roport, de la maintenance a\u00e9ronautique ou encore du Cargo.\nVous contribuez \u00e0 la d\u00e9finition, au d\u00e9veloppement, \u00e0 l\u2019industrialisation et \u00e0 la maintenance d\u2019applications Big Data ou en Business Intelligence\nVous pr\u00e9sentez la restitution de vos travaux et accompagnez les utilisateurs d\u2019un point de vue fonctionnel ou m\u00e9thodologique\nVous serez en contact avec les directions m\u00e9tier du groupe Air France KLM.\nNous attachons beaucoup d'importance au d\u00e9veloppement des comp\u00e9tences de nos collaborateurs ainsi qu\u2019\u00e0 leur offrir des conditions de travail favorables \u00e0 l\u2019autonomie et aux missions \u00e0 forte valeur ajout\u00e9e. L'ouverture, le respect, la bienveillance et le partage sont des valeurs humaines port\u00e9es par l'entreprise.\nProfil recherch\u00e9\nVous \u00eates dipl\u00f4m\u00e9 de niveau Master ou Ing\u00e9nieur dans les domaines informatiques, vous avez acquis une exp\u00e9rience professionnelle dans le d\u00e9veloppement d\u2019applications.\nVous disposez d\u2019une exp\u00e9rience du d\u00e9veloppement indispensable en Backend / Java\nVous ma\u00eetrisez les bases de donn\u00e9es relationnelles et le langage SQL\nEn Compl\u00e9ment, Vous Avez Une Connaissance Ou Une Exp\u00e9rience Dans Tout Ou Partie Des Concepts Ou Outils Suivants\nEnvironnement Big Data (Spark, Hadoop, Elasticsearch, Kafka, ...)\nBase de donn\u00e9es noSQL (MongoDB, HBase, REDIS) ou Data Warehouse Teradata\nOutil de Datavisualisation (Spotfire, PowerBI, Qlik ou Kibana)\nSolutions de Cloud (GCP) et hybride (GCP / AZURE)\n(Ces comp\u00e9tences compl\u00e9mentaires ou manquantes pouvant aussi s'acqu\u00e9rir \u00e0 travers un parcours de reskilling et de formations aux outils du data engineering dispens\u00e9 en interne).\nVous avez particip\u00e9 \u00e0 des projets organis\u00e9s en Scrum ou Kanban, et avez peut-\u00eatre m\u00eame \u0153uvr\u00e9 comme Scrum-Master, ce qui vous permettra de vous int\u00e9grer ais\u00e9ment au sein d\u2019une Product Team. Votre esprit de synth\u00e8se, votre force de conviction et votre ma\u00eetrise de la communication facilitent les d\u00e9cisions avec l\u2019ensemble des collaborateurs de l\u2019\u00e9quipe, \u00e9ventuellement en langue anglaise, \u00e0 l\u2019\u00e9crit comme \u00e0 l\u2019oral.\nVous \u00eates autonome, rigoureux(se), responsable et curieux(se), vous aimez travailler en \u00e9quipe. Vous poss\u00e9dez de bonnes capacit\u00e9s d'\u00e9coute, d'analyse, de synth\u00e8se et de communication.\nEt bien s\u00fbr, vous \u00eates passionn\u00e9(e), enthousiaste et ing\u00e9nieux(se)\nCe que nous vous offrons\nDe la cr\u00e9ation de valeur pour l\u2019ensemble des m\u00e9tiers d\u2019Air France KLM\nDes challenges et probl\u00e9matiques complexes \u00e0 r\u00e9soudre\nL\u2019opportunit\u00e9 de d\u00e9ployer des solutions Data industrielles \u00e0 l\u2019\u00e9chelle !\nUne grande part de responsabilit\u00e9 dans une structure hi\u00e9rarchique horizontale\nUn important degr\u00e9 de libert\u00e9 pour apprendre et d\u00e9velopper son expertise au sein de l\u2019\u00e9quipe\nOn vous attend le plus rapidement possible ! Et pour une dur\u00e9e ind\u00e9termin\u00e9e ;)\nType de contrat\nCDI\nTemps partiel possible\nNon\nType d'horaires\nAdministratif\nProfil candidat\nNiveau d'\u00e9tudes min. requis\nBac + 5 et plus\nLangue\nAnglais (4 - Confirm\u00e9 / C1)\nLocalisation du poste\nLocalisation du poste\nFrance, Provence-Alpes-C\u00f4te d'Azur, Alpes Maritimes (06)\nSite\nValbonne\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Java",
                "R",
                "Go"
            ],
            "DataBase": [
                "SQL",
                "NoSQL",
                "HBase",
                "Elasticsearch"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [
                "Hadoop",
                "Spark"
            ],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [
                "PowerBI"
            ],
            "Statistics": [],
            "CloudComputing": [
                "Azure"
            ],
            "DevTools": [],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [
                "HBase"
            ],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [
                "Big Data",
                "Cloud"
            ],
            "FrSoftSkills": [
                "Communication"
            ],
            "EnSoftSkils": [
                "Communication"
            ]
        },
        "details": {
            "JobDetail": [
                "Hybride",
                "Confirm\u00e9"
            ],
            "TypeContract": [
                "CDI"
            ],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "title": "APPRENTI DATA ENGINEER (H/F)",
        "company": "Akademija Oxford",
        "location": "Paris, \u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/apprenti-data-engineer-h-f-at-akademija-oxford-3917872047?position=5&pageNum=0&refId=TDTc9UZJy78L%2BED7EV%2BMrg%3D%3D&trackingId=rmaFYM2oHNOKTV4fxpDKVg%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Une de nos entreprises partenaires, ESN situ\u00e9e \u00e0 Paris, recherche un Apprenti Data Engineer (H/F) pr\u00e9parant un bac +4/+5 sp\u00e9cialit\u00e9 Big Data pour la rentr\u00e9e de Septembre 2021.\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "R"
            ],
            "DataBase": [],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [],
            "DevTools": [],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [
                "Big Data"
            ],
            "FrSoftSkills": [],
            "EnSoftSkils": []
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "title": "APPRENTI.E ING\u00c9NIEUR DATA",
        "company": "Akademija Oxford",
        "location": "Bordeaux, Nouvelle-Aquitaine, France",
        "link": "https://fr.linkedin.com/jobs/view/apprenti-e-ing%C3%A9nieur-data-at-akademija-oxford-3912806043?position=6&pageNum=0&refId=TDTc9UZJy78L%2BED7EV%2BMrg%3D%3D&trackingId=UHqnpuGea9Itifl0Aoj1Lg%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Vous souhaitez int\u00e9grer une \u00e9cole \u00e0 taille humaine ? Vous \u00eates int\u00e9ress\u00e9 par le secteur du d\u00e9veloppement informatique ? Sup de Vinci propose une formation compl\u00e8te en Mast\u00e8re Big Data.\nL\u2019\u00e9cole Sup de Vinci \u00e0 Bordeaux, accompagne l\u2019une de ses entreprises partenaires dans son projet de recrutement d\u2019un profil Ing\u00e9nieur Data, en alternance pour la rentr\u00e9e 2022.\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "R"
            ],
            "DataBase": [],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [],
            "DevTools": [],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [
                "Big Data"
            ],
            "FrSoftSkills": [],
            "EnSoftSkils": []
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "title": "Data Engineer (H/F) | POEI",
        "company": "DataScientest.com",
        "location": "Puteaux, \u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/data-engineer-h-f-poei-at-datascientest-com-3909358387?position=7&pageNum=0&refId=TDTc9UZJy78L%2BED7EV%2BMrg%3D%3D&trackingId=dzcO8ZpLWKV7kVqbDMyaZA%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Data Engineer (H/F) | POEI\nPuteaux\nCDI\nPostuler\nRetour\nDatascientest Is Hiring!\nData Engineer (H/F) | POEI\n\u00c0 propos\nVous \u00eates demandeur d'emploi et vivement int\u00e9ress\u00e9(e) par les m\u00e9tiers de la Data ?\nRejoignez DataScientest en int\u00e9grant une formation 100% financ\u00e9e par P\u00f4le Emploi afin d\u2019acqu\u00e9rir les comp\u00e9tences cl\u00e9s qui vous permettront de booster votre carri\u00e8re en tant que Data Engineer Cloud, un m\u00e9tier en tension et en plein essor.\nCette formation est certifi\u00e9e par l'Ecole des Mines ParisTech, et inclut le passage de certifications \u00e9diteurs (AWS, Microsoft Azure ou encore GCP) qui garantissent votre employabilit\u00e9.\nApr\u00e8s avoir suivi notre formation de Cloud Data Engineer, vous rejoindrez, en CDI , notre entreprise partenaire.\nLes candidats retenus b\u00e9n\u00e9ficieront d\u2019une formation intensive, enti\u00e8rement prise en charge par le dispositif POEI (Pr\u00e9paration Op\u00e9rationnelle \u00e0 l\u2019Emploi Individuel) avec P\u00f4le-Emploi.\nDescriptif du poste\nEn Tant Que Cloud Data Engineer, Vous Aurez Pour Missions De Proposer Les Meilleures Solutions Aux Entreprises Afin D'optimiser Leur Activit\u00e9, \u00e0 Travers Les Missions Suivantes\nD\u00e9veloppement de solutions permettant de traiter des volumes importants de donn\u00e9es,\nConception, collection et fabrication des donn\u00e9es brutes,\nCr\u00e9ation d'outils et algorithmes pour le traitement des donn\u00e9es,\nPr\u00e9paration des donn\u00e9es pour le Data Analyst,\nS\u00e9curisation des Pipelines donn\u00e9es pour les Data Analysts et Data Scientists,\nOrganisation de l'architecture du cloud\nProfil recherch\u00e9\nCe Que Nous Vous Offrons\nUne certification de l'Ecole des Mines ParisTech\nUn CDI aupr\u00e8s d'un de nos partenaires, expert europ\u00e9en dans le traitement et l'exploitation des donn\u00e9es\nUn salaire attractif \u00e0 la cl\u00e9 : 35 000\u20ac \u00e0 48 000\u20ac selon le profil\n**Votre profil : **\nIssu(e) d\u2019une fili\u00e8re scientifique ou informatique vous disposez d'un bac+5 ou d\u2019un dipl\u00f4me d\u2019ing\u00e9nieur,\nVous disposez id\u00e9alement d\u2019une exp\u00e9rience significative en d\u00e9veloppement informatique, en architecture r\u00e9seaux ou dans la Data,\nVous ma\u00eetrisez un langage objet type Java, Python, C++, etc.\nVous \u00eates inscrit(e) \u00e0 P\u00f4le Emploi\nInformations compl\u00e9mentaires\nType de contrat : CDI\nDate de d\u00e9but : 01 septembre 2023\nLieu : Puteaux\nNiveau d'\u00e9tudes : Bac +5 / Master\nExp\u00e9rience : > 1 an\nT\u00e9l\u00e9travail ponctuel autoris\u00e9\nSalaire : entre 35000\u20ac et 48000\u20ac / an\nVous \u00eates int\u00e9ress\u00e9 par cette offre ?\nPostuler\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "Java",
                "C++",
                "R",
                "Go"
            ],
            "DataBase": [],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [
                "AWS",
                "Azure"
            ],
            "DevTools": [],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [
                "Cloud"
            ],
            "FrSoftSkills": [
                "Organisation"
            ],
            "EnSoftSkils": []
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [
                "CDI"
            ],
            "Salary": [
                "35"
            ],
            "Level": [
                "Bac+5"
            ],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "title": "Big Data Engineer \u2013 Paris, France (H/F)",
        "company": "Astek",
        "location": "Paris, \u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/big-data-engineer-%E2%80%93-paris-france-h-f-at-astek-3470775874?position=8&pageNum=0&refId=TDTc9UZJy78L%2BED7EV%2BMrg%3D%3D&trackingId=q4j7hA8VWh11yPRBq9Ju3Q%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "CDI\nParis - France\nPubli\u00e9e il y a 2 mois\nLe Groupe Astek\nCe Que Nous Allons Accomplir Ensemble :\nNous rejoindre en tant que\nBig Data Engineer (H/F),\nafin d\u2019accompagner un op\u00e9rateur t\u00e9l\u00e9coms, Leader en Europe dans la cr\u00e9ation d\u2019une infrastructure cloud (IAAS) performante, robuste et s\u00e9curis\u00e9e.\nUn challenge portant sur des millions d\u2019utilisateurs dans un environnement technique innovant, strat\u00e9gique et o\u00f9 l\u2019entraide et la bonne humeur priment !\nVotre Mission, Si Vous L\u2019acceptez :\nQualifier les donn\u00e9es et les r\u00e9sultats\nConception technique des solutions\nD\u00e9cliner les impacts de la strat\u00e9gie et des innovations technologiques au sein des processus et outils de l\u2019exploitant SI\nAssurer l\u2019accompagnement et le d\u00e9ploiement des \u00e9volutions des processus et outils\nContribuer aux programmes de transformation DevOps, Cloud et catalogues des offres SI\nD\u00e9velopper des fonctions transverses et les \u00ab uses cases \u00bb\nAccompagner la phase de mise en production\nVotre Future \u00c9quipe :\nVous int\u00e9grerez une \u00e9quipe \u00e0 la fois technique et fonctionnel, qui \u0153uvre chaque jour pour d\u00e9velopper et maintenir en conditions op\u00e9rationnelles l\u2019ensemble des solutions IT !\nL\u2019\u00e9quipe est en interaction avec des clients \u00e0 la fois internes et externes.\nVotre stack de jeu\nSyst\u00e8me d\u2019exploitation : Linux\nEnvironnement Big data : Hadoop, Spark, Scala\nCloud computing : GCP ou AWS\nBase de donn\u00e9es : No SQL (Cassandra, Mongo DB)\nDataviz : Power BI ou Kibana\nDes notions en d\u00e9veloppement feront la diff\u00e9rence !\nLes Petits Plus Du Projet :\nVous \u00e9voluerez au sein d\u2019une \u00e9quipe impliqu\u00e9e et r\u00e9active et interviendrez sur un projet polyvalent et \u00e0 forte valeur ajout\u00e9e.\nVous ?\nDipl\u00f4m\u00e9(e) d\u2019une \u00e9cole d\u2019ing\u00e9nieur ou \u00e9quivalent de niveau Bac+5.\nVous justifiez id\u00e9alement d\u2019une exp\u00e9rience d\u2019au moins 3 ans d\u2019exp\u00e9riences sur un poste similaire ?\nVous faite preuve de proactivit\u00e9 et d\u2019esprit d\u2019\u00e9quipe, \u00eates dot\u00e9(e) d\u2019un excellent sens de l\u2019organisation et vous aimez les challenges et la r\u00e9solution de probl\u00e8me ?\nAlors ce poste est fait pour vous, n\u2019h\u00e9sitez plus et rejoignez l\u2019aventure ASTEK !\nAstek\nCr\u00e9\u00e9 en France en 1988, Astek est un acteur mondial de l\u2019ing\u00e9nierie et du conseil en technologies. Fort de son expertise dans de nombreux secteurs industriels et tertiaires, Astek accompagne ses clients internationaux dans le d\u00e9ploiement intelligent de leurs produits et de leurs services, et dans la mise en \u0153uvre de leur transformation digitale.\nDepuis sa cr\u00e9ation, le Groupe a fond\u00e9 son d\u00e9veloppement sur une forte culture d\u2019entrepreneuriat et d\u2019innovation, et sur l\u2019accompagnement et la mont\u00e9e en comp\u00e9tence de\nses 7800 collaborateurs\nqui s\u2019engagent chaque jour \u00e0 promouvoir la compl\u00e9mentarit\u00e9 entre les technologies num\u00e9riques et l\u2019ing\u00e9nierie des syst\u00e8mes complexes.\nRejoignez un Groupe en fort d\u00e9veloppement en France et \u00e0 travers le monde ayant r\u00e9alis\u00e9 un chiffre d\u2019affaires de 600 M\u20ac en 2023.\nTous les d\u00e9tails sur le Groupe sur le site https://astekgroup.fr. Et vous pouvez aussi nous suivre sur notre blog : https://blog.groupeastek.com.\nRencontrons-nous\nNotre projet commun vous plait ?\nPostulez \u00e0 cette annonce, et soyez transparent !\nMaud, notre Talent Acquisition Referent, vous contactera pour un premier \u00e9change.\nPuis vous rencontrerez Yoram, votre futur manager, avec lequel vous \u00e9changerez autour d\u2019Astek, de votre parcours, de vos attentes et de votre future mission .\nEnfin, vous rencontrerez Anthime, notre Directeur d\u2019agence avec lequel vous pourrez valider votre int\u00e9r\u00eat et ad\u00e9quation pour le poste et finaliser les \u00e9l\u00e9ments contractuels.\nNos Plus\nAstek est green et fait b\u00e9n\u00e9ficier ses salari\u00e9s d\u2019une indemnit\u00e9 kilom\u00e9trique v\u00e9lo\nUne politique CARE sur-mesure d\u00e9ploy\u00e9e par nos \u00e9quipes RH pour nos collaborateurs (https://astekgroup.fr/engagements)\nNotre charte de la Diversit\u00e9\nMots-cl\u00e9s :\ning\u00e9nieur \u2013 ing\u00e9nieure \u2013 consultant \u2013 consultante \u2013 developpement \u2013 Scala \u2013 Data\nCaract\u00e9ristiques de l'emploi\nCat\u00e9gorie Ing\u00e9nieur\nJob Industry T\u00e9l\u00e9com / M\u00e9dia\nPostuler en ligne\nNom *\nPr\u00e9nom *\nEmail *\nUn email valide est requis.\nT\u00e9l\u00e9phone *\nUn num\u00e9ro de t\u00e9l\u00e9phone valide est requis.\nJoindre un CV *\nMots-cl\u00e9s :\ning\u00e9nieur \u2013 ing\u00e9nieure \u2013 consultant \u2013 consultante \u2013 developpement \u2013 Scala \u2013 Data\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Scala",
                "R",
                "Go"
            ],
            "DataBase": [
                "SQL",
                "Cassandra"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [
                "Hadoop",
                "Spark"
            ],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [
                "Power BI"
            ],
            "Statistics": [],
            "CloudComputing": [
                "AWS"
            ],
            "DevTools": [
                "Git"
            ],
            "Os": [
                "Linux"
            ],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [
                "DevOps",
                "Big Data",
                "Cloud"
            ],
            "FrSoftSkills": [
                "Organisation"
            ],
            "EnSoftSkils": []
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [
                "CDI"
            ],
            "Salary": [],
            "Level": [
                "Bac+5"
            ],
            "Experience": [
                "a",
                "n",
                "s",
                "3",
                "3",
                "3"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "title": "Data Engineer - Bordeaux",
        "company": "Capgemini",
        "location": "Bordeaux, Nouvelle-Aquitaine, France",
        "link": "https://fr.linkedin.com/jobs/view/data-engineer-bordeaux-at-capgemini-3889788624?position=9&pageNum=0&refId=TDTc9UZJy78L%2BED7EV%2BMrg%3D%3D&trackingId=qJ4q4DZbIEQJgFfJAS3paA%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Choisir Capgemini, c'est choisir une entreprise o\u00f9 vous serez en mesure de fa\u00e7onner votre carri\u00e8re selon vos aspirations. Avec le soutien et l'inspiration d'une\ncommunaut\u00e9 d\u2019experts dans le monde entier, vous pourrez r\u00e9\u00e9crire votre futur. Rejoignez-nous pour red\u00e9finir les limites de ce qui est possible, contribuer \u00e0 lib\u00e9rer la\nvaleur de la technologie pour les plus grandes organisations et participer \u00e0 la construction d\u2019un monde plus durable et inclusif.\nVos missions :\nVous \u00eates passionn\u00e9 par le domaine de la Data, vous souhaitez prendre part \u00e0 des projets d'envergure, concevoir des solutions, les impl\u00e9menter et les faire \u00e9voluer?\nAlors rejoignez notre \u00e9quipe Data Engineering Services au sein de Capgemini Cloud Infrastructure Services en tant que Data Engineer.\nVous avez acquis une exp\u00e9rience solide dans le d\u00e9veloppement, la mise en \u0153uvre et l\u2019optimisation de solutions pour le traitement d'un grand volume de donn\u00e9es, vous \u00eates capable de cr\u00e9er des solutions qui r\u00e9pondent aux besoins m\u00e9tiers et IT, alors rejoignez notre \u00e9quipe d\u2019experts.\nEn qualit\u00e9 de Data engineer, vos missions sont les suivantes :\n\u25aa Concevoir et d\u00e9velopper des solutions Data/IA.\n\u25aa Accompagner les M\u00e9tier dans la compr\u00e9hension et la mise en \u0153uvre de solution orient\u00e9es donn\u00e9es.\n\u25aa Collaborer avec les Dev, les Ops, les experts infrastructures dans la construction de solutions et d\u2019infrastructures ax\u00e9es sur les donn\u00e9es.\n\u25aa G\u00e9rer un \u00e9cosyst\u00e8me de partenaires data et assurer un haut niveau d'expertise\n\u25aa Assurer un r\u00f4le de veille technologique sur tous les outils autours de la data, de l\u2019IA et de la BI.\nVotre profil :\nVous \u00eates issu d\u2019une formation ing\u00e9nieur ou \u00e9quivalent bac+5 informatique sp\u00e9cialis\u00e9e en DATA et vous justifiez d\u2019une exp\u00e9rience de 3 \u00e0 5 ans dans un r\u00f4le similaire. Expert dans une technologie de base de donn\u00e9es relationnelle (PostgreSQL, Oracle...)\nExpert dans une technologie de base NoSQL (MongoDB, Cassandra...)\nVous maitrisez un framework de manipulation de donn\u00e9es (Hadoop, Spark, Kafka...)\nVous maitrisez les concepts DevOps et avez de bonnes notions en scripting et d\u00e9veloppement\nVous avez une exp\u00e9rience des outils BI et de data visualisation (Kibana, PowerBI...)\nLa maitrise de l'anglais est n\u00e9cessaire.\n3 raisons de nous rejoindre :\nQualit\u00e9 de vie au travail :\naccord de t\u00e9l\u00e9travail en France et \u00e0 l\u2019international, accord sur l\u2019\u00e9galit\u00e9 professionnelle, la parentalit\u00e9, l\u2019\u00e9quilibre des temps et la mobilit\u00e9 durable.\nApprentissage en continu :\ncertifications et formations en libre acc\u00e8s, accompagnement sur mesure avec votre career manager, parcours d\u2019int\u00e9gration sur 9 mois.\nAvantages groupe & CSE :\nplan actionnariat, tarif pr\u00e9f\u00e9rentiels, remboursement partiel vacances, remboursement de votre abonnement sportif ou culture\nNos engagements et priorit\u00e9s :\nLe groupe Capgemini encourage une culture inclusive dans un cadre multiculturel et handi-accueillant. En nous rejoignant, vous int\u00e9grez un collectif qui valorise la diversit\u00e9, d\u00e9veloppe le potentiel de ses talents, s\u2019engage dans des initiatives solidaires avec ses partenaires, et se mobilise pour r\u00e9duire son impact environnemental sur tous ses sites et aupr\u00e8s de ses clients.\n\u00c0 propos de Capgemini :\nCapgemini est un leader mondial, responsable et multiculturel, regroupant pr\u00e8s de 350 000 personnes dans plus de 50 pays. Fort de 55 ans d\u2019exp\u00e9rience, nous sommes un partenaire strat\u00e9gique des entreprises pour la transformation de leurs activit\u00e9s en tirant profit de toute la puissance de la technologie et des innovations dans les domaines en perp\u00e9tuelle \u00e9volution tels que le cloud, la data, l\u2019Intelligence Artificielle, la connectivit\u00e9, les logiciels, l\u2019ing\u00e9nierie digitale ou les plateformes.\nGet The Future You Want* | www.capgemini.com/fr-fr\n*Capgemini, le futur que vous voulez\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "R",
                "Go"
            ],
            "DataBase": [
                "SQL",
                "NoSQL",
                "Cassandra"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [
                "Hadoop",
                "Spark"
            ],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [
                "PowerBI"
            ],
            "Statistics": [],
            "CloudComputing": [],
            "DevTools": [
                "Git"
            ],
            "Os": [],
            "DBMS": [
                "PostgreSQL",
                "Oracle"
            ],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [
                "DevOps",
                "Cloud"
            ],
            "FrSoftSkills": [
                "Organisation"
            ],
            "EnSoftSkils": [
                "Initiative"
            ]
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [],
            "Salary": [],
            "Level": [
                "Bac+5"
            ],
            "Experience": [
                "a",
                "n",
                "s",
                "5",
                "5",
                "5"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "title": "Big Data Engineer - H/F",
        "company": "Lincoln France",
        "location": "\u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/big-data-engineer-h-f-at-lincoln-france-3834466740?position=10&pageNum=0&refId=TDTc9UZJy78L%2BED7EV%2BMrg%3D%3D&trackingId=2dHhajJA1zlXIU1bYbcHBA%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Poste CDI : Consultant Big Data Engineer - H/F (Hadoop, Spark, PySpark, Databricks, Kafka, Python, Scala, Java, Hive, MongoDB, etc.)\nLincoln Pure Player Data\n\ud83d\udca1: R\u00e9inventant l'analyse\ndepuis 30 ans\n. Experts en Modern BI, Big Data et Science des donn\u00e9es \ud83d\udcca. Nous transformons les donn\u00e9es en solutions pour les grands comptes, des secteurs bancaire, retail, t\u00e9l\u00e9coms, industriel, sant\u00e9, et plus encore \ud83d\udcbc.\nDescription du poste\n\ud83c\udfaf\nMissions\n:\nAnalyser les besoins clients en mati\u00e8re d'analyse de donn\u00e9es\nD\u00e9velopper et optimiser des pipelines de donn\u00e9es distribu\u00e9s\nConcevoir et mettre en \u0153uvre des solutions Big Data adapt\u00e9es\nInt\u00e9grer les solutions dans les environnements existants\nFournir un support technique et une expertise tout au long des projets\n\ud83d\udd0d\nPr\u00e9requis\n:\nExpertise av\u00e9r\u00e9e en Hadoop, Spark, PySpark, Databricks, Kafka, Hive\nMa\u00eetrise de Python, Scala, Java\nConnaissance des bases de donn\u00e9es NoSQL (MongoDB, etc.)\nCapacit\u00e9 \u00e0 travailler en \u00e9quipe et \u00e0 communiquer efficacement avec les clients\n\ud83c\udf1f\nAvantages :\nEnvironnement collaboratif et innovant\nFormations certifiantes et accompagnement individualis\u00e9\nT\u00e9l\u00e9travail et horaires flexibles\nR\u00e9mun\u00e9ration comp\u00e9titive avec avantages sociaux attrayants\nPossibilit\u00e9 de mobilit\u00e9 \u00e0 Lille, Lyon ou Aix-en-Provence\n\u2728\nProcessus de recrutement\n: 2 entretiens (RH et technique)\nSi vous \u00eates passionn\u00e9 par les d\u00e9fis de la Data et que vous souhaitez rejoindre une \u00e9quipe dynamique et innovante,\npostulez d\u00e8s maintenant et contribuez \u00e0 red\u00e9finir l'avenir de l'analyse de donn\u00e9es chez Lincoln! \ud83d\ude09\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "Java",
                "Scala",
                "R",
                "Go"
            ],
            "DataBase": [
                "SQL",
                "NoSQL",
                " MongoDB"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [
                "Hadoop",
                "Spark",
                "Databricks"
            ],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [],
            "DevTools": [],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [
                "Big Data"
            ],
            "FrSoftSkills": [],
            "EnSoftSkils": []
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [
                "CDI"
            ],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s",
                "30",
                "30",
                "30"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "title": "Big Data Engineer Databricks Senior - H/F - CDI",
        "company": "Talan",
        "location": "Paris, \u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/big-data-engineer-databricks-senior-h-f-cdi-at-talan-3909664424?position=11&pageNum=0&refId=TDTc9UZJy78L%2BED7EV%2BMrg%3D%3D&trackingId=JOUu%2BSuh85U2DmX%2B5oozDw%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Talan est un groupe international de conseil en transformation et en innovation par la technologie, cr\u00e9\u00e9 en 2002.\nNos 5000 consultantes et consultants partagent \u00e0 travers le monde l\u2019audace d\u2019innover, le go\u00fbt de l\u2019excellence, et l\u2019envie de relever les d\u00e9fis les plus complexes.\nNous accompagnons les entreprises dans des secteurs vari\u00e9s\u202f: \u00e9nergie, industrie, transport, finance, luxe\u2026 \u00e0 travers 3 grandes expertises\u202f:\nLe Conseil en Management et Innovation (320 Consultants en France)\nLa valorisation des donn\u00e9es, leurs structurations, et leurs usages (Data et Technologies)\nL\u2019int\u00e9gration de solutions logicielles (Cloud et Applications Services)\nNos valeurs\u202f: engagement, respect, partage, esprit d\u2019\u00e9quipe et optimisme.\nTalan est une entreprise responsable, reconnue par ses collaborateurs et attach\u00e9e \u00e0 la diversit\u00e9. Des am\u00e9nagements peuvent \u00eatre propos\u00e9s si vous \u00eates en situation de handicap.\nRetrouvez nos engagements RSEiciet nos actions en faveur de la diversit\u00e9ici\nJob Description\nNous sommes \u00e0 la recherche d\u2019un Big Data Engineer Databricks S\u00e9nior qui sera en charge de l\u2019int\u00e9gration des donn\u00e9es: acquisition, pr\u00e9paration, mod\u00e9lisation et stockage, exposition, . Vous devrez faire preuve d\u2019un \u00e9tat d\u2019esprit \u00e0 la fois innovant, m\u00e9thodique, orient\u00e9 solution (et non probl\u00e8me!), et communiquant.\nResponsabilit\u00e9s\nManager des Big Data Engineer et Cloud Engineer\nCoacher techniquement les membres de l\u2019\u00e9quipe: solution et code review sur site, recommandation sur les formations \u00e0 suivre, certifications \u00e0 r\u00e9aliser, \u2026\nAnalyse des besoins techniques m\u00e9tiers, d\u00e9finition de l\u2019architecture solution et logiciel, r\u00e9f\u00e9rent technique, d\u00e9veloppement et optimisation, code review, maintenir les pratiques Devops \u201cYou build IT, You run IT\u201d, support \u00e0 recette et mise en production, documentation, et parfois assumer le r\u00f4le de Scrum Master,\u2026\nBenchmark de solutions et conseil aupr\u00e8s de notre client sur les solutions technologiques \u00e0 adopter, en lien avec leurs besoins\nPartage de connaissances et formations interne\nQualifications\nIssu(e) d\u2019une formation sup\u00e9rieure (\u00e9cole d\u2019ing\u00e9nieur, master,\u2026)\nVous disposez d\u2019au moins 4 ann\u00e9es d\u2019exp\u00e9rience dans le domaine du Big Data (et particuli\u00e8rement sur le framework Spark), et au moins 6 ann\u00e9es d\u2019exp\u00e9rience dans le d\u00e9veloppement logiciel\nVous ma\u00eetrisez led\u00e9veloppement logiciel (Scala, Python \u2026), et vous disposez de solides exp\u00e9riences dans la mise en place de pipelines de donn\u00e9es\nVous ma\u00eetrisez leFramework Spark (id\u00e9alement sur Databricks) etson optimisation\nExp\u00e9rience sur une plateforme Cloud serait un plus et id\u00e9alement AWS\nExp\u00e9rience sur des flux temps r\u00e9elserait un plus : Kafka + Spark Streaming\nVous ma\u00eetrisez les bases de donn\u00e9es SQL et le langage SQL\nVous avez de l'exp\u00e9rience sur les m\u00e9thodes de stockage: HDFS, S3,,\u2026\nVous avez de bonnes connaissances en devOps : Jenkins, Gitlab, Maven, \u2026\nLa connaissance des concepts suivants serait un +: DataOps, DataVault, DataMesh..\nConnaissance de l\u2019Agilit\u00e9\nAutonome\nOrganis\u00e9(e)\nSens du partage\nBonne communication\nOrientation produit et solution\nAdditional Information\nAVANTAGES\n:\nPlan de formation pour accompagner votre carri\u00e8re (formations \u00e9diteurs, certifications) gr\u00e2ce \u00e0 nos partenariats nous accordant une position de partenaire privil\u00e9gi\u00e9, et management de proximit\u00e9 par des experts\nLocaux modernes en centre-ville\nTop 5 du Palmar\u00e8s Great Place to Work\nT\u00e9l\u00e9travail jusqu\u2019\u00e0 5 jours selon les missions, prime d\u2019\u00e9quipement de 100\u20ac\nMobilit\u00e9 en France et \u00e0 l\u2019\u00e9tranger\nTop 1% des entreprises \u00e9valu\u00e9es par Ecovadis dans le domaine social, environnemental et \u00e9thique\nTickets restaurant, prime vacances, 50% transport (abonnement transport public), mutuelle\nPermanence handicap (consultant d\u00e9di\u00e9 aux collaborateurs en situation de handicap et aux proches aidants)\nActionnariat salari\u00e9\nPrime de cooptations\nRTT\nPROCESS RECRUTEMENT\n:\nL\u2019\u00e9quipe recrutement s\u2019engage \u00e0 vous proposer un processus de recrutement rapide et fluide\n1 entretien RHpar Teams (45min)\n1 test technique\n1 entretien technique par Teams (1heure)\n1 entretien op\u00e9rationnel avec le responsable de domaine, au si\u00e8ge (1heure)\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "Scala",
                "R",
                "Go"
            ],
            "DataBase": [
                "SQL"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [
                "Spark",
                "Databricks"
            ],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [
                "AWS"
            ],
            "DevTools": [
                "Git",
                "Jenkins"
            ],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [
                "Teams"
            ],
            "Other": [
                "DevOps",
                "Big Data",
                "Cloud"
            ],
            "FrSoftSkills": [
                "Communication"
            ],
            "EnSoftSkils": [
                "Communication"
            ]
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "title": "Data Engineer",
        "company": "digiRocks recrute \u2705",
        "location": "Paris, \u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/data-engineer-at-digirocks-recrute-%E2%9C%85-3903481080?position=12&pageNum=0&refId=TDTc9UZJy78L%2BED7EV%2BMrg%3D%3D&trackingId=DIzHfjsZbaLVQRKIaO5kzQ%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "\ud83d\ude0e Envie d'accompagner des organisations dans leurs strat\u00e9gies, Fan de data?\nRejoins un jeune cabinet de conseil en strat\u00e9gie sp\u00e9cialis\u00e9 en data. Le cabinet a \u00e9t\u00e9 cr\u00e9\u00e9 il y a 4 ans pas des anciens de grands cabinets de conseil en strat\u00e9gie qui ne se reconnaissaient plus dans ce qu'est devenu le \"consulting\". Cependant ils n'ont pas perdu espoir de pouvoir apporter du conseil \u00e0 haute valeur ajout\u00e9e dans une ambiance friendly, fa\u00e7on start-up, sans sacrifier l'excellence.\nJean-Patrick recrute un(e) Consultant Data Engineer \u00e0 Paris en CDI\n\u2705 MISSION :\nVous serez responsable de la mise en \u0153uvre de bout en bout de la pile de donn\u00e9es, de la collecte au reporting, avec un accent sur l'infrastructure et les processus techniques. Vous travaillerez avec des Consultants en Strat\u00e9gie & Data et les soutiendrez dans la r\u00e9solution des d\u00e9fis li\u00e9s aux donn\u00e9es de leurs clients. Vous contribuerez \u00e0 la d\u00e9finition des strat\u00e9gies de donn\u00e9es, \u00e0 la mise en \u0153uvre des syst\u00e8mes de donn\u00e9es et vous soutiendrez l'exploitation des donn\u00e9es dans des projets transformationnels. En g\u00e9n\u00e9ral, vous serez responsable de comprendre intimement les probl\u00e8mes, de concevoir une strat\u00e9gie technique pour les adresser et de faciliter une ex\u00e9cution technique de haute qualit\u00e9.\n\u2705 R\u00c9SULTATS ATTENDUS :\n\ud83d\ude80 R\u00e9sultat 1: Unificateur de Donn\u00e9es : Architecturer, assembler, assimiler, nettoyer et conformer de grands ensembles de donn\u00e9es complexes pour livrer des insights commerciaux et alimenter les exp\u00e9riences de produits de donn\u00e9es.\n\ud83d\ude80 R\u00e9sultat 2: Agent de S\u00e9curit\u00e9 des Donn\u00e9es : Concevoir et construire une infrastructure de donn\u00e9es fiable et \u00e9volutive avec les techniques de confidentialit\u00e9 et de s\u00e9curit\u00e9 de pointe pour prot\u00e9ger les donn\u00e9es.\n\ud83d\ude80 R\u00e9sultat 3: DataOps : Poss\u00e9der la pile de donn\u00e9es de bout en bout, y compris la collecte d'\u00e9v\u00e9nements, la gouvernance des donn\u00e9es, les int\u00e9grations de donn\u00e9es et la mod\u00e9lisation.\n\ud83d\ude80 R\u00e9sultat 4: Gardien des Donn\u00e9es : Assurer la coh\u00e9rence et la qualit\u00e9 de l'environnement technique et de la structure des donn\u00e9es \u00e0 travers des m\u00e9triques, de la documentation, des processus, des tests de donn\u00e9es et de la formation.\nRequirements\n\u2705 PROFIL RECHERCH\u00c9 :\nDipl\u00f4m\u00e9 d'une Grande Ecole de Commerce ou d'ing\u00e9nieur, avec une premi\u00e8re exp\u00e9rience r\u00e9ussie comme Data Engineer, id\u00e9alement dans un contexte similaire au Conseil,\nConnaissance des services de Data Warehouses Cloud. Exp\u00e9rience avec Google BigQuery, Snowflake, AWS Redshift/Athena, Looker, Azure SQL DWH, ou Azure Databricks est tr\u00e8s souhaitable.\nConnaissance des architectures de donn\u00e9es relationnelles et de grandes donn\u00e9es, de l'entreposage de donn\u00e9es, de l'int\u00e9gration de donn\u00e9es, de la mod\u00e9lisation de donn\u00e9es, de l'optimisation de donn\u00e9es et des techniques d'analyse de donn\u00e9es.\nExp\u00e9rience dans la construction de pipelines de donn\u00e9es de bout en bout en utilisant des plateformes de donn\u00e9es sur site ou bas\u00e9es sur le cloud.\nExp\u00e9rience pratique dans la livraison de solutions comprenant des bases de donn\u00e9es, SQL avanc\u00e9 et d\u00e9veloppement logiciel dans des langues telles que Python.\nInt\u00e9ress\u00e9 et connaissant les technologies Big Data et les technologies de l'\u00e9cosyst\u00e8me Apache telles que Beam, Spark, Kafka, Airflow, bases de donn\u00e9es, int\u00e9gration, gestion des donn\u00e9es de r\u00e9f\u00e9rence, assurance qualit\u00e9, manipulation de donn\u00e9es et technologies de gouvernance des donn\u00e9es.\nExp\u00e9rience avec les plateformes cloud publiques et l'infrastructure cloud qui est essentielle.\nExpos\u00e9 aux outils ETL/ELT et de gouvernance.\nInt\u00e9ress\u00e9 par les technologies et principes IA et ML.\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "R",
                "Go"
            ],
            "DataBase": [
                "SQL"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [
                "Spark",
                "Databricks"
            ],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [
                "AWS",
                "Azure"
            ],
            "DevTools": [],
            "Os": [],
            "DBMS": [
                "Snowflake",
                "Snowflake",
                "BigQuery"
            ],
            "SoftBigDataProcessing": [],
            "Automation": [
                "Airflow"
            ],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [
                "Big Data",
                "ML",
                "Cloud"
            ],
            "FrSoftSkills": [
                "Organisation"
            ],
            "EnSoftSkils": []
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [
                "CDI"
            ],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s",
                "4",
                "4",
                "4"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "title": "Big Data Engineer \u2013 Lille, France (H/F)",
        "company": "Astek",
        "location": "Lille, Hauts-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/big-data-engineer-%E2%80%93-lille-france-h-f-at-astek-3839097187?position=13&pageNum=0&refId=TDTc9UZJy78L%2BED7EV%2BMrg%3D%3D&trackingId=g6Iw%2FVj01V51GKbNbzngpQ%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "CDI\nLille - France\nPubli\u00e9e il y a 2 mois\nLe Groupe Astek\nCe Que Nous Allons Accomplir Ensemble :\nNous rejoindre en tant que\nBig Data Engineer (H/F),\nafin d\u2019accompagner un op\u00e9rateur t\u00e9l\u00e9coms, Leader en Europe dans la cr\u00e9ation d\u2019une infrastructure cloud (IAAS) performante, robuste et s\u00e9curis\u00e9e.\nUn challenge portant sur des millions d\u2019utilisateurs dans un environnement technique innovant, strat\u00e9gique et o\u00f9 l\u2019entraide et la bonne humeur priment !\nVotre Mission, Si Vous L\u2019acceptez :\nQualifier les donn\u00e9es et les r\u00e9sultats\nConception technique des solutions\nD\u00e9cliner les impacts de la strat\u00e9gie et des innovations technologiques au sein des processus et outils de l\u2019exploitant SI\nAssurer l\u2019accompagnement et le d\u00e9ploiement des \u00e9volutions des processus et outils\nContribuer aux programmes de transformation DevOps, Cloud et catalogues des offres SI\nD\u00e9velopper des fonctions transverses et les \u00ab uses cases \u00bb\nAccompagner la phase de mise en production\nVotre Future \u00c9quipe :\nVous int\u00e9grerez une \u00e9quipe \u00e0 la fois technique et fonctionnel, qui \u0153uvre chaque jour pour d\u00e9velopper et maintenir en conditions op\u00e9rationnelles l\u2019ensemble des solutions IT !\nL\u2019\u00e9quipe est en interaction avec des clients \u00e0 la fois internes et externes.\nVotre stack de jeu\nSyst\u00e8me d\u2019exploitation : Linux\nEnvironnement Big data : Hadoop, Spark, Scala\nCloud computing : GCP ou AWS\nBase de donn\u00e9es : No SQL (Cassandra, Mongo DB)\nDataviz : Power BI ou Kibana\nDes notions en d\u00e9veloppement feront la diff\u00e9rence !\nLes Petits Plus Du Projet :\nVous \u00e9voluerez au sein d\u2019une \u00e9quipe impliqu\u00e9e et r\u00e9active et interviendrez sur un projet polyvalent et \u00e0 forte valeur ajout\u00e9e.\nVous ?\nDipl\u00f4m\u00e9(e) d\u2019une \u00e9cole d\u2019ing\u00e9nieur ou \u00e9quivalent de niveau Bac+5.\nVous justifiez id\u00e9alement d\u2019une exp\u00e9rience d\u2019au moins 3 ans d\u2019exp\u00e9riences sur un poste similaire ?\nVous faite preuve de proactivit\u00e9 et d\u2019esprit d\u2019\u00e9quipe, \u00eates dot\u00e9(e) d\u2019un excellent sens de l\u2019organisation et vous aimez les challenges et la r\u00e9solution de probl\u00e8me ?\nAlors ce poste est fait pour vous, n\u2019h\u00e9sitez plus et rejoignez l\u2019aventure ASTEK !\nAstek\nCr\u00e9\u00e9 en France en 1988, Astek est un acteur mondial de l\u2019ing\u00e9nierie et du conseil en technologies. Fort de son expertise dans de nombreux secteurs industriels et tertiaires, Astek accompagne ses clients internationaux dans le d\u00e9ploiement intelligent de leurs produits et de leurs services, et dans la mise en \u0153uvre de leur transformation digitale.\nDepuis sa cr\u00e9ation, le Groupe a fond\u00e9 son d\u00e9veloppement sur une forte culture d\u2019entrepreneuriat et d\u2019innovation, et sur l\u2019accompagnement et la mont\u00e9e en comp\u00e9tence de\nses 7800 collaborateurs\nqui s\u2019engagent chaque jour \u00e0 promouvoir la compl\u00e9mentarit\u00e9 entre les technologies num\u00e9riques et l\u2019ing\u00e9nierie des syst\u00e8mes complexes.\nRejoignez un Groupe en fort d\u00e9veloppement en France et \u00e0 travers le monde ayant r\u00e9alis\u00e9 un chiffre d\u2019affaires de 600 M\u20ac en 2023.\nTous les d\u00e9tails sur le Groupe sur le site https://astekgroup.fr. Et vous pouvez aussi nous suivre sur notre blog : https://blog.groupeastek.com.\nRencontrons-nous\nNotre projet commun vous plait ?\nPostulez \u00e0 cette annonce, et soyez transparent !\nMaud, notre Talent Acquisition Referent, vous contactera pour un premier \u00e9change.\nPuis vous rencontrerez Yoram, votre futur manager, avec lequel vous \u00e9changerez autour d\u2019Astek, de votre parcours, de vos attentes et de votre future mission .\nEnfin, vous rencontrerez Anthime, notre Directeur d\u2019agence avec lequel vous pourrez valider votre int\u00e9r\u00eat et ad\u00e9quation pour le poste et finaliser les \u00e9l\u00e9ments contractuels.\nNos Plus\nAstek est green et fait b\u00e9n\u00e9ficier ses salari\u00e9s d\u2019une indemnit\u00e9 kilom\u00e9trique v\u00e9lo\nUne politique CARE sur-mesure d\u00e9ploy\u00e9e par nos \u00e9quipes RH pour nos collaborateurs (https://astekgroup.fr/engagements)\nNotre charte de la Diversit\u00e9\nMots-cl\u00e9s :\ning\u00e9nieur \u2013 ing\u00e9nieure \u2013 consultant \u2013 consultante \u2013 developpement \u2013 Scala \u2013 Data\nCaract\u00e9ristiques de l'emploi\nCat\u00e9gorie Ing\u00e9nieur\nJob Industry T\u00e9l\u00e9com / M\u00e9dia\nPostuler en ligne\nNom *\nPr\u00e9nom *\nEmail *\nUn email valide est requis.\nT\u00e9l\u00e9phone *\nUn num\u00e9ro de t\u00e9l\u00e9phone valide est requis.\nJoindre un CV *\nMots-cl\u00e9s :\ning\u00e9nieur \u2013 ing\u00e9nieure \u2013 consultant \u2013 consultante \u2013 developpement \u2013 Scala \u2013 Data\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Scala",
                "R",
                "Go"
            ],
            "DataBase": [
                "SQL",
                "Cassandra"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [
                "Hadoop",
                "Spark"
            ],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [
                "Power BI"
            ],
            "Statistics": [],
            "CloudComputing": [
                "AWS"
            ],
            "DevTools": [
                "Git"
            ],
            "Os": [
                "Linux"
            ],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [
                "DevOps",
                "Big Data",
                "Cloud"
            ],
            "FrSoftSkills": [
                "Organisation"
            ],
            "EnSoftSkils": []
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [
                "CDI"
            ],
            "Salary": [],
            "Level": [
                "Bac+5"
            ],
            "Experience": [
                "a",
                "n",
                "s",
                "3",
                "3",
                "3"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "title": "Big Data Engineer Databricks confirm\u00e9 - H/F - CDI",
        "company": "Talan",
        "location": "Paris, \u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/big-data-engineer-databricks-confirm%C3%A9-h-f-cdi-at-talan-3902693062?position=14&pageNum=0&refId=TDTc9UZJy78L%2BED7EV%2BMrg%3D%3D&trackingId=YqfrGktg2oFxsRwyJ9Dmfg%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Talan est un cabinet de conseil en innovation et transformation par la technologie.\nDepuis 20 ans, Talan conseille les entreprises et les administrations, les accompagne et met en \u0153uvre leurs projets de transformation et d\u2019innovation en France et \u00e0 l'international. Pr\u00e9sent sur cinq continents, le groupe pr\u00e9voit de r\u00e9aliser un chiffre d'affaires de 600 millions d'euros en 2022 pour plus de 6000 consultant\u00b7e\u00b7s et vise \u00e0 d\u00e9passer la barre du milliard d\u2019\u20ac de CA \u00e0 horizon 2024.\nLe Groupe met l'innovation au c\u0153ur de son d\u00e9veloppement et intervient dans les domaines li\u00e9s aux mutations technologiques des grands groupes, comme le Big Data, l'IoT, la Blockchain et l'Intelligence Artificielle.\nPr\u00e9sent dans les \u00e9v\u00e9nements incontournables du secteur, comme Viva Technology, Talan prend r\u00e9guli\u00e8rement la parole sur les enjeux de ces technologies r\u00e9volutionnaires aux c\u00f4t\u00e9s d'acteurs majeurs du secteur et de parlementaires (Syntec Num\u00e9rique, Forum de l'intelligence artificielle, French Fab Tour, Forum de Giverny\u2026).\nTalan est une entreprise responsable, attach\u00e9e \u00e0 la diversit\u00e9. Des am\u00e9nagements de poste peuvent \u00eatre organis\u00e9s pour tenir compte des personnes en situation de handicap.\nRetrouvez nos engagementsRSEiciet nos actions en faveur de la diversit\u00e9ici\nJob Description\nNous sommes \u00e0 la recherche d\u2019un Big Data Engineer Databricks confirm\u00e9 qui sera en charge de l\u2019int\u00e9gration des donn\u00e9es: acquisition, pr\u00e9paration, mod\u00e9lisation et stockage, exposition, . Vous devrez faire preuve d\u2019un \u00e9tat d\u2019esprit \u00e0 la fois innovant, m\u00e9thodique, orient\u00e9 solution (et non probl\u00e8me!), et communiquant.\nResponsabilit\u00e9s\nAnalyse des besoins techniques m\u00e9tiers, d\u00e9finition de l\u2019architecture solution et logiciel, r\u00e9f\u00e9rent technique, d\u00e9veloppement et optimisation, code review, maintenir les pratiques Devops \u201cYou build IT, You run IT\u201d, support \u00e0 recette et mise en production, documentation, et parfois assumer le r\u00f4le de Scrum Master,\u2026\nPartager techniquement les membres de l\u2019\u00e9quipe: solutions et code reviews, recommandations, certifications \u00e0 r\u00e9aliser, \u2026\nParticipation \u00e0 des meet-up, coding dogo,\u2026\nCommunication: \u00e9criture d\u2019articles, retours d\u2019exp\u00e9rience\u2026\nQualifications\nIssu d\u2019une formation sup\u00e9rieure (\u00e9cole d\u2019ing\u00e9nieur, master,\u2026)\nVous disposez d\u2019au moins 3 ann\u00e9es d\u2019exp\u00e9rience dans le domaine du Big Data et particuli\u00e8rement sur le framework Spark (id\u00e9alement Databricks)\nMa\u00eetrise du d\u00e9veloppement logiciel (Scala, Python,\u2026) et vous disposez de solides exp\u00e9riences dans la mise en place de pipeline de donn\u00e9es\nExp\u00e9rience sur une plateforme Cloud serait un plus et id\u00e9alement AWS\nExp\u00e9rience sur des flux temps r\u00e9elserait un plus : Kafka + Spark Streaming\nMaitrise du langage SQL\nExp\u00e9rience sur des m\u00e9thodes de stockage: HDFS, S3, ,\u2026\nBonnes connaissances en devOps : Jenkins, Gitlab, Maven, \u2026\nConnaissance de l\u2019Agilit\u00e9\nAutonomie, organisation, sens du partage\nBonne communication\nOrientation produit et solution\nAdditional Information\nAVANTAGES\n:\nPlan de formation pour accompagner votre carri\u00e8re (formations \u00e9diteurs, certifications) gr\u00e2ce \u00e0 nos partenariats nous accordant une position de partenaire privil\u00e9gi\u00e9, et management de proximit\u00e9 par des experts\nLocaux modernes en centre-ville\nTop 5 du Palmar\u00e8s Great Place to Work\nT\u00e9l\u00e9travail jusqu\u2019\u00e0 5 jours selon les missions, prime d\u2019\u00e9quipement de 100\u20ac\nMobilit\u00e9 en France et \u00e0 l\u2019\u00e9tranger\nTop 1% des entreprises \u00e9valu\u00e9es par Ecovadis dans le domaine social, environnemental et \u00e9thique\nTickets restaurant, prime vacances, 50% transport (abonnement transport public), mutuelle\nPermanence handicap (consultant d\u00e9di\u00e9 aux collaborateurs en situation de handicap et aux proches aidants)\nActionnariat salari\u00e9\nPrime de cooptations\nRTT\nPROCESS RECRUTEMENT\n:\nL\u2019\u00e9quipe recrutement s\u2019engage \u00e0 vous proposer un processus de recrutement rapide et fluide\n1 entretien RHpar Teams (45min)\n1 entretien op\u00e9rationnel avec le responsable de domaine, au si\u00e8ge (1heure)\n1 entretien avec le directeur de p\u00f4le, au si\u00e8ge(1heure)\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "Scala",
                "R",
                "Go"
            ],
            "DataBase": [
                "SQL"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [
                "Spark",
                "Databricks"
            ],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [
                "AWS"
            ],
            "DevTools": [
                "Git",
                "Jenkins"
            ],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [
                "Teams"
            ],
            "Other": [
                "DevOps",
                "Big Data",
                "Cloud"
            ],
            "FrSoftSkills": [
                "Communication",
                "Organisation"
            ],
            "EnSoftSkils": [
                "Communication"
            ]
        },
        "details": {
            "JobDetail": [
                "Confirm\u00e9"
            ],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s",
                "20",
                "20",
                "20"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "title": "Data Engineer \u2013 SQL & GCP - F/H",
        "company": "Orange Business",
        "location": "Greater Lille Metropolitan Area",
        "link": "https://fr.linkedin.com/jobs/view/data-engineer-%E2%80%93-sql-gcp-f-h-at-orange-business-3916557264?position=15&pageNum=0&refId=TDTc9UZJy78L%2BED7EV%2BMrg%3D%3D&trackingId=0rGuS34ssXebpVfpSRYJ7w%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Et si Business & Decision et Orange Business conjuguaient leurs forces pour devenir l\u2019un des leaders europ\u00e9ens de la Data transformation ?\nNous l\u2019avons fait ! Notre alchimie nous positionne comme un acteur unique intervenant sur toutes les \u00e9tapes du voyage de la donn\u00e9e.\nDepuis 30 ans, Business & Decision, entit\u00e9 de Digital Services s'est impos\u00e9e comme un partenaire strat\u00e9gique pour la transformation Data de nombreux clients, dans des secteurs tr\u00e8s vari\u00e9s. Digital Services est aujourd\u2019hui l\u2019ESN d\u2019Orange Business alliant les expertises historiques Cloud et Digital d\u2019Orange ainsi que le c\u0153ur de m\u00e9tier Data/IA de Business & Decision. Son but est d\u2019accompagner les entreprises et les acteurs publics dans leur transformation gr\u00e2ce aux 4000 experts pr\u00e9sents dans plusieurs grandes villes fran\u00e7aises comme Montpellier, Niort, Lyon, Bordeaux, Lille et Toulouse \u2026\nDescription du poste\nOrange Business, recherche pour son site de Lille, son futur Data Engineer pour rejoindre sa team Data.\nVotre quotidien ?\nEn int\u00e9grant Orange Business, vous pouvez participer \u00e0 une grande diversit\u00e9 d\u2019activit\u00e9s dans la Data. En voici un aper\u00e7u :\nAu d\u00e9marrage du projet :\nRecueillir et analyser les besoins du client\nR\u00e9diger les sp\u00e9cifications fonctionnelles et techniques\nEstimre les charges\nPendant la phase de r\u00e9alisation :\nMod\u00e9liser des datawarehouses et datamart (int\u00e9gration de flux et consolidation des donn\u00e9es)\nD\u00e9velopper les proc\u00e9dures d\u2019alimentation (ETL)\nD\u00e9velopper en SQL\n/ PLSQL / Shell\nGarantir la qualit\u00e9 des donn\u00e9es et leur disponibilit\u00e9\nConcevoir et d\u00e9velopper des solutions frontend BI \u00e0 des fins analytics & dashboarding\nR\u00e9aliser la recette et les tests\nSuivre et mettre en production\nEn fonction de votre \u00e9volution et de nos enjeux, vous pouvez aussi \u00e9voluer sur des missions transverses (conseil, coaching, avant-vente, formation, audit, etc.). La prise d\u2019initiative est toujours la bienvenue !\nQualifications\nVous poss\u00e9dez 3 ans d'exp\u00e9rience ou plus dans la mise en \u0153uvre de projets d\u00e9cisionnels et ing\u00e9nierie ou analyse data.\nVous avez de\nsolides comp\u00e9tences en d\u00e9veloppement SQL\n(job, scripting, d\u00e9ploiement), vous avez l\u2019habitude de travailler dans un\nenvironnement Google Cloud Plateform\nainsi qu\u2019avec\nPower BI\n.\nEnvie d\u2019apprendre de nouvelles technos ? Vous souhaitez partager vos comp\u00e9tences et b\u00e9n\u00e9ficier des expertises de la Team Orange Business ?\nOutre l\u2019aspect technique, c\u2019est une personnalit\u00e9 qui est recherch\u00e9e !\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "R",
                "Go"
            ],
            "DataBase": [
                "SQL"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [],
            "MachingLearning": [
                "Orange"
            ],
            "DataSerialization": [],
            "DataVisualization": [
                "Power BI"
            ],
            "Statistics": [],
            "CloudComputing": [],
            "DevTools": [
                "Git"
            ],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [
                "Cloud"
            ],
            "FrSoftSkills": [],
            "EnSoftSkils": [
                "Initiative"
            ]
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s",
                "30",
                "30",
                "30"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "title": "Data Engineer (F/H)",
        "company": "Thales",
        "location": "V\u00e9lizy-Villacoublay, \u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/data-engineer-f-h-at-thales-3908228180?position=16&pageNum=0&refId=TDTc9UZJy78L%2BED7EV%2BMrg%3D%3D&trackingId=SR3wNiEahgqu4gp2aczA2g%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "QUI SOMMES-NOUS ?\nThales est un leader mondial des hautes technologies comptant plus de 81 000 collaborateurs pr\u00e9sents sur tous les continents. Le Groupe investit dans les innovations du num\u00e9rique et de la \u00ab deep tech \u00bb \u2013 big data, intelligence artificielle, connectivit\u00e9, cybers\u00e9curit\u00e9 et quantique \u2013 pour construire un avenir de confiance, essentiel au d\u00e9veloppement de nos soci\u00e9t\u00e9s, en pla\u00e7ant l\u2019humain au c\u0153ur des d\u00e9cisions.\nThales propose des solutions, services et produits qui aident ses clients \u2013 entreprises, organisations, Etats \u2013 dans cinq grands march\u00e9s vitaux pour le fonctionnement de nos soci\u00e9t\u00e9s : identit\u00e9 et s\u00e9curit\u00e9 num\u00e9riques, d\u00e9fense, a\u00e9ronautique, espace, et transport.\nQUI ETES-VOUS ?\nDipl\u00f4m\u00e9 d\u2019un Bac+5 en \u00e9cole d\u2019ing\u00e9nieur ou \u00e9quivalent universitaire avec une sp\u00e9cialisation en informatique, vous avez au moins 3 ans d'exp\u00e9rience dans les technologies Big Data.\nCE QUE NOUS POUVONS ACCOMPLIR ENSEMBLE :\nEn tant que Data Engineer, vous jouerez un r\u00f4le cl\u00e9 dans la conception, le d\u00e9veloppement et la maintenance de notre infrastructure de donn\u00e9es, ainsi que dans la transformation et la gestion des flux de donn\u00e9es.\nVOS MISSIONS :\n\u2022 Concevoir, d\u00e9velopper et d\u00e9ployer des solutions Big Data en utilisant les technologies Hadoop.\n\u2022 Mettre en place des pipelines de donn\u00e9es performants pour l'ingestion, le traitement et le stockage des donn\u00e9es massives.\n\u2022 Collaborer \u00e9troitement avec les \u00e9quipes m\u00e9tier pour comprendre leurs besoins en mati\u00e8re d'analyse de donn\u00e9es et proposer des solutions adapt\u00e9es.\n\u2022 Optimiser les performances des clusters Hadoop pour garantir une exploitation efficace des donn\u00e9es.\n\u2022 Assurer la qualit\u00e9 et la fiabilit\u00e9 des donn\u00e9es trait\u00e9es, en mettant en place des processus de validation et de nettoyage.\n\u2022 Identifier et r\u00e9soudre les probl\u00e8mes li\u00e9s \u00e0 l'infrastructure Big Data et proposer des am\u00e9liorations.\n\u2022 Travailler en \u00e9troite collaboration avec les Data Scientists et les Data Analysts pour fournir des insights pertinents \u00e0 partir des donn\u00e9es.\nInnovation, passion, ambition : rejoignez Thales et cr\u00e9ez le monde de demain, d\u00e8s aujourd\u2019hui.\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "R"
            ],
            "DataBase": [],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [
                "Hadoop"
            ],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [],
            "DevTools": [],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [
                "Big Data"
            ],
            "FrSoftSkills": [
                "Collaboration",
                "Organisation"
            ],
            "EnSoftSkils": [
                "Collaboration"
            ]
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [],
            "Salary": [],
            "Level": [
                "Bac+5"
            ],
            "Experience": [
                "a",
                "n",
                "s",
                "3",
                "3",
                "3"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "title": "Data Engineer - Lille",
        "company": "Capgemini",
        "location": "Greater Lille Metropolitan Area",
        "link": "https://fr.linkedin.com/jobs/view/data-engineer-lille-at-capgemini-3914228495?position=17&pageNum=0&refId=TDTc9UZJy78L%2BED7EV%2BMrg%3D%3D&trackingId=tWBPN1TDM2mx5aVvM0uDjQ%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Capgemini en quelques mots\nChoisir Capgemini, c'est choisir une entreprise o\u00f9 vous serez en mesure de fa\u00e7onner votre carri\u00e8re selon vos aspirations, o\u00f9 vous serez soutenu et inspir\u00e9 par une communaut\u00e9 d\u2019experts dans le monde entier, o\u00f9 vous pourrez r\u00e9\u00e9crire votre futur. Rejoignez-nous pour red\u00e9finir les limites de ce qui est possible, contribuer \u00e0 lib\u00e9rer la valeur de la technologie pour les plus grandes organisations et participez \u00e0 la construction d\u2019un monde plus durable et inclusif.\nVos missions\nVous maitrisez au minimum un langage de programmation appliqu\u00e9 \u00e0 l\u2019analyse de donn\u00e9es\n(Java, Python, Scala et les environnements Spark et / ou Hadoop).\nVous \u00eates passionn\u00e9 par le Big Data et le Machine Learning et l\u2019analyse de donn\u00e9es\nVous concevez et mettez en \u0153uvre des strat\u00e9gies s\u00e9curis\u00e9es d'acquisition et d'int\u00e9gration de donn\u00e9es\nVous configurez des r\u00e9f\u00e9rentiels de donn\u00e9es \u00e0 la pointe de la technologie dans des environnements distribu\u00e9s\nVous construisez des pipelines de donn\u00e9es pour collecter, transformer et traiter des donn\u00e9es en collaboration avec des scientifiques de donn\u00e9es afin de r\u00e9pondre aux exigences de la mod\u00e9lisation de donn\u00e9es d'analyse avanc\u00e9e\nVotre profil\nDipl\u00f4m\u00e9(e) de Bac+5 en informatique\n4 ans d\u2019exp\u00e9rience\n(au sein d\u2019une ESN ou chez un int\u00e9grateur) en conseil client\u00e8le\nUne solide culture technologique\nUn bon niveau d\u2019anglais\n3 raisons de nous rejoindre\nQualit\u00e9 de vie au travail :\naccord de t\u00e9l\u00e9travail en France et \u00e0 l\u2019international, accord sur l\u2019\u00e9galit\u00e9\nprofessionnelle, la parentalit\u00e9, l\u2019\u00e9quilibre des temps et la mobilit\u00e9 durable.\nApprentissage en continu :\ncertifications et formations en libre acc\u00e8s, accompagnement sur mesure avec\nvotre carreer manager, parcours d\u2019int\u00e9gration sur 9 mois.\nAvantages groupe & CSE :\nplan actionnariat, activit\u00e9s \u00e0 tarifs pr\u00e9f\u00e9rentiels, remboursement partiel\nvacances, remboursement de votre abonnement sportif ou culturel\nNos engagements et priorit\u00e9s\nLe groupe Capgemini encourage une\nculture inclusive dans un cadre multiculturel et handi-accueillant.\nEn nous rejoignant, vous int\u00e9grez un collectif qui valorise la diversit\u00e9, d\u00e9veloppe le potentiel de ses talents, s\u2019engage dans des\ninitiatives solidaires avec ses partenaires, et se mobilise pour r\u00e9duire son impact environnemental sur tous ses sites et aupr\u00e8s de ses clients.\nCapgemini\nest un\nleader mondial\n, responsable et multiculturel, regroupant pr\u00e8s de 350 000 personnes dans plus de 50 pays. Fort de\n55 ans d\u2019exp\u00e9rience,\nnous sommes un partenaire strat\u00e9gique des entreprises pour la transformation de leurs activit\u00e9s en tirant profit de toute la puissance de la technologie et des innovations dans les domaines en perp\u00e9tuelle \u00e9volution tels que le\ncloud, la data, l\u2019Intelligence Artificielle, la connectivit\u00e9, les logiciels, l\u2019ing\u00e9nierie digitale ou les plateformes.\nGet The Future You Want* | www.capgemini.com/fr-fr\n*Capgemini, le futur que vous voulez\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "Java",
                "Scala",
                "R"
            ],
            "DataBase": [],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [
                "Hadoop",
                "Spark"
            ],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [],
            "DevTools": [
                "Git"
            ],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [
                "Big Data",
                "Machine Learning",
                "Cloud"
            ],
            "FrSoftSkills": [
                "Collaboration",
                "Organisation"
            ],
            "EnSoftSkils": [
                "Collaboration",
                "Initiative"
            ]
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [],
            "Salary": [],
            "Level": [
                "Bac+5"
            ],
            "Experience": [
                "a",
                "n",
                "s",
                "4",
                "4",
                "4"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "title": "Data Engineer",
        "company": "EarthDaily Agro",
        "location": "Balma, Occitanie, France",
        "link": "https://fr.linkedin.com/jobs/view/data-engineer-at-earthdaily-agro-3883708013?position=18&pageNum=0&refId=TDTc9UZJy78L%2BED7EV%2BMrg%3D%3D&trackingId=OstO0NnkVGTi6x0rYb4beg%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "About Us\nEarthDaily Agro provides space age data and analytics to the organizations and people who feed the planet!\nWith 35 years of industry experience, EarthDaily Agro provides customers with the data, analysis and knowledge they need to make more efficient and effective decisions. B2B services range from global risk management and monitoring of agricultural commodities to the marketing of inputs and precision agriculture consulting, using the latest research in agronomy, information technologies and remote sensing.\nEarthDaily Agro also develops highly customized business solutions for agricultural lenders, insurers, input suppliers and food companies, with easy-to-use analytics, that help reduce the daily risks of agriculture.\nEarthDaily Agro is headquartered in Minneapolis, MN, USA, with offices in France, Brazil, Australia and Switzerland and is a division of EarthDaily Analytics Corp.\nEarthDaily Analytics Corp., a vertically-integrated data processing and analytics company, is launching a new constellation of earth observation satellites. The EarthDaily satellite constellation will significantly enhance geospatial analytics capabilities in agriculture, forestry, environment, financial services, and intelligence, among many other verticals.\nMain Job Tasks And Responsibilities\nAs a EarthDailyAgro Data Engineer, your primary responsibility will be to design, develop, and manage data pipelines and infrastructure specialized for geospatial and remote sensing applications. You will work closely with data scientists, geospatial analysts, remote sensing experts, software engineers, and DevOps teams to ensure the successful deployment and scaling of data pipeline to feed geospatial data machine learning models. Your role will be crucial in optimizing the geospatial machine learning ecosystem and ensuring the seamless integration of AI-driven geospatial solutions into real-world applications.\nYour Responsibilities Include\nCloud-based data pipeline Conceptualization, Development and Scaling: Build up pipeline to ingest large volumes of geospatial data, pre-process them and meet data scientists\u2019 requirements, in terms of accessibility, speed, format, quality.\nAutomation and CI/CD: Industrialization of pipeline deployment, orchestration, workflows, and versioning.\nCost & Speed Optimization: Collaborate with infrastructure team to develop, optimize, and fine-tune pipeline.\nCloud and Containerization: Experience with cloud platforms (e.g., AWS, Azure, GCP) and containerization tools.\nInfrastructure Management: Utilize containerization technologies and cloud-based services to set up and manage infrastructure, enabling seamless deployment and scalability.\nMonitoring and Anomaly Detection: Implement monitoring systems to track pipeline performance and identify anomalies.\nVersion Control and Data Version Control: Proficient with version control systems like Git and DVC.\nSecurity and Compliance: Ensure the security and privacy of geospatial data, adhering to relevant data protection regulations and industry best practices.\nCollaboration and Communication: Collaborate with interdisciplinary teams to integrate data pipeline into existing applications or develop new geospatial products.\nIssue Resolution and Troubleshooting: Identify and resolve promptly technical issues related to geospatial data processing, performance, or infrastructure.\nEducation, Knowledge And Abilities\nRequirements\nEducation: Master's degree in Computer Science, specialisation in Geomatics and/or Remote sensing would be a plus.\nExperience: 3+ years experiences with data pipeline processes and deployment is a must-have. Proven hands-on experience in setting up pipelines and data processes with opensource tools (e.g., MLFlow, Argo, Kubeflow) is desirable.\nProgramming Skills: Proficiency in Python and with data manipulation frameworks (e.g., dataframe, numpy, pandas, xarray, rasterio) and librairies (e.g., Dask).\nProblem-Solving Skills: Autonomous, and strong analytical and problem-solving abilities to address complex geospatial data and analysis challenges.\nCommunication Skills: Excellent communication and interpersonal skills to collaborate effectively with cross-functional teams and stakeholders.\nFrench mandatory (job based in France). Fluent in English (oral and written):\u202fmeetings with internal are mostly in\u202fEnglish.\nPreferred Additional Skills\nExperience with Earth Observation (EO) data analysis and processing.\nExperience with geospatial data formats (e.g., GeoTIFF, Shapefile, NetCDF).\nSpatial Analysis Techniques: Understanding of spatial analysis techniques and algorithms commonly used in geospatial data manipulation.\nRemote Sensing Integration: Knowledge of remote sensing data sources (e.g., STAC catalog, satellite imagery, LiDAR, SAR) integration into data pipelines for accurate and up-to-date geospatial analysis.\nCONDITIONS\nFull time job based in Balma, near Toulouse, France.\nFixed + Bonuses\nTR / \"Family\" insurance / CSE\nPowered by JazzHR\nWrfSXQ5YJg\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "Scala",
                "R",
                "Go"
            ],
            "DataBase": [],
            "DataAnalytics": [
                "Pandas",
                "NumPy",
                "R"
            ],
            "BigData": [],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [
                "AWS",
                "Azure"
            ],
            "DevTools": [
                "Git"
            ],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [
                "Teams"
            ],
            "Other": [
                "DevOps",
                "ML",
                "Machine Learning",
                "Cloud",
                "CI/CD"
            ],
            "FrSoftSkills": [
                "Communication",
                "Collaboration"
            ],
            "EnSoftSkils": [
                "Communication",
                "Collaboration",
                "Organization",
                "Interpersonal Skills"
            ]
        },
        "details": {
            "JobDetail": [
                "Remote",
                "Full"
            ],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "title": "Data Engineer H/F",
        "company": "Thales",
        "location": "Lyon, Auvergne-Rh\u00f4ne-Alpes, France",
        "link": "https://fr.linkedin.com/jobs/view/data-engineer-h-f-at-thales-3903089036?position=19&pageNum=0&refId=TDTc9UZJy78L%2BED7EV%2BMrg%3D%3D&trackingId=l0OHDSxc4s3SzSTrRXtmfg%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "\ud83d\udce2 Nous recherchons un(e) Data Engineer, bas\u00e9(e) \u00e0 Lyon\n\ud83d\udc49Quelques mots sur les activit\u00e9s num\u00e9riques de Thales Lyon :\nLes activit\u00e9s num\u00e9riques repr\u00e9sentent une entit\u00e9 rattach\u00e9e au groupe Thales, sp\u00e9cialis\u00e9e dans l\u2019IT et pr\u00e9sente au national.\nL\u2019agence de Lyon adresse divers sujets d\u2019expertise : ing\u00e9nierie logiciels, cybers\u00e9curit\u00e9, infog\u00e9rance des infrastructures et transformation digitale.\n\ud83c\udfaf\nVotre r\u00f4le et missions\nEn nous rejoignant, vous int\u00e9grerez le centre de comp\u00e9tences\nAugmented data\n,\nsp\u00e9cialis\u00e9 dans la conception, le d\u00e9veloppement et l\u2019\u00e9volution d\u2019applications data centr\u00e9es. Vous y boosterez votre carri\u00e8re en travaillant sur des technologies telles que\nSpark, Elasticsearch, Kube ...\nle plus souvent dans un environnement\nAgile\n.\nDans le cadre des projets que nous op\u00e9rons aujourd\u2019hui :\n- Vous contribuerez \u00e0 la conception, au maintien, \u00e0 la scalabilit\u00e9 des plateformes d\u2019analyse de donn\u00e9es au travers de votre expertise sur les sujets data (base de donn\u00e9es, gestion de flux, ETL \u2026)\n- Vous contribuerez \u00e0 la conception et \u00e0 la mise en production des pipelines d\u2019analyses et de transformations de donn\u00e9es en veillant \u00e0 leur bonne adaptation aux besoins m\u00e9tiers et aux contraintes techniques du client\n- Vous pourrez intervenir sur des sujets de visualisations, dans le but de notamment accompagn\u00e9es nos clients sur la conception de Dashboard m\u00e9tier intelligent \u2026\n- Vous serez \u00e9galement amen\u00e9es \u00e0 \u00e9changer directement avec des DevOps/Datascientist pour la mise en place, l\u2019int\u00e9gration des pipelines et l\u2019\u00e9laboration des algorithmes de traitements de donn\u00e9es.\n- A l\u2019\u00e9chelle du d\u00e9partement, Vous serez un acteur majeur du d\u00e9veloppement de notre activit\u00e9 et du lancement de nouveaux projets de valorisation de donn\u00e9es.\n\ud83d\ude4b\u200d\u2640\ufe0f \ud83d\ude4b\u200d\u2642\ufe0f\nVotre profil\nDe formation Bac +5 en informatique (\u00e9cole d\u2019ing\u00e9nieur, Master ou \u00e9quivalent), vous justifiez d\u2019une premi\u00e8re exp\u00e9rience r\u00e9ussie sur un projet data ? Vous souhaitez participer \u00e0 la conception et intervenir sur des solutions de r\u00e9cup\u00e9ration et d\u2019exploitation de donn\u00e9es m\u00e9tiers dans des contextes critiques et hautement s\u00e9curis\u00e9s ?\nAutonome, dynamique, organis\u00e9(e) et proactif(ve), vous souhaitez \u00e9voluer au sein d\u2019\u00e9quipes passionn\u00e9es par l\u2019exploration et l\u2019int\u00e9gration des technologies nouvelles au service des m\u00e9tiers de nos clients ?\nVous avez des comp\u00e9tences qui couvrent les domaines suivants :\nMise en place et gestion de base de donn\u00e9es (SQL, Elasticsearch, Clickhouse ...)\nLangages de programmations (Java, Python)\nGestion de flux (Kafka, flink, logstash \u2026)\nEnvironnements big Data (Spark/hadoop )\nPrincipes et outils de type ETL\nVous \u00eates de plus int\u00e9ress\u00e9(e):\nPar les environnements containeris\u00e9s (docker, kubernetes, helm ...)\nLes concepts DevOps (Ansible, CI/CD...)\nLes sujets de Datavisualisation (Vega, Kibana, python librairies...)\nVous aimez travailler en \u00e9quipe ? Vous \u00eates reconnu(e) pour vos qualit\u00e9s relationnelles et vos capacit\u00e9s de vulgarisation ?\nAlors notre poste d\u2019Ing\u00e9nieur(e) Data(H/F) est fait pour vous !\n\ud83d\ude4c\nVotre carri\u00e8re chez Thales\nDiff\u00e9rentes opportunit\u00e9s vous permettront de d\u00e9couvrir d'autres domaines ou sites. Vous pourrez \u00e9voluer et d\u00e9velopper vos comp\u00e9tences dans diff\u00e9rents domaines.\nExplorez un espace attentif au d\u00e9veloppement personnel.\nD\u00e9veloppez vos talents dans un autre domaine du groupe Thales, en d\u00e9couvrant de nouveaux produits, de nouveaux clients, un nouveau pays ou en vous orientant vers une solution plus complexe.\nChoisissez entre une expertise technique ou un parcours de leadership.\nVous travaillerez dans une entreprise r\u00e9solument humaine avec des valeurs fortes comme la s\u00e9curit\u00e9 au travail, l\u2019\u00e9galit\u00e9 Homme/Femme et l\u2019\u00e9quilibre vie personnelle/professionnelle (Accord T\u00e9l\u00e9travail).\nRattach\u00e9(e) \u00e0 la Convention m\u00e9tallurgie, vous b\u00e9n\u00e9ficierez aussi de ses multiples avantages (\u2026)\nVous souhaitez en savoir plus ?\nN\u2019h\u00e9sitez pas \u00e0 contacter notre \u00e9quipe de recrutement ou nos \u00e9quipes directement.\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "Java",
                "Scala",
                "R",
                "Go"
            ],
            "DataBase": [
                "SQL",
                "Elasticsearch"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [
                "Hadoop",
                "Spark",
                "Flink"
            ],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [],
            "DevTools": [
                "Git",
                "Docker"
            ],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [
                "Ansible",
                "Kubernetes"
            ],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [
                "Docker",
                "Kubernetes"
            ],
            "Collaboration": [],
            "Other": [
                "DevOps",
                "Big Data",
                "CI/CD"
            ],
            "FrSoftSkills": [
                "Leadership"
            ],
            "EnSoftSkils": [
                "Leadership"
            ]
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "title": "Data Engineer | Python - Spark - Hadoop | Sp\u00e9cialis\u00e9 en Big Data | Paris ou Remote Partiel",
        "company": "Octopus IT - Expert du recrutement tech",
        "location": "Paris, \u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/data-engineer-python-spark-hadoop-sp%C3%A9cialis%C3%A9-en-big-data-paris-ou-remote-partiel-at-octopus-it-expert-du-recrutement-tech-3837194913?position=20&pageNum=0&refId=TDTc9UZJy78L%2BED7EV%2BMrg%3D%3D&trackingId=pVu5TEtTTwGCsZughQT0Dw%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "La soci\u00e9t\u00e9\nCr\u00e9\u00e9e il y a 7 ans, cette entreprise de conseil en hyper croissance, se compose d'environ 90 personnes. Elle est devenue experte en Data et IA (NLP, Deep Learning, Machine Learning) et accompagne leurs clients sur l\u2019ensemble de leurs projets data \u00e0 travers la valorisation de leurs donn\u00e9es.\nLeur valeur ajout\u00e9e ? Leur sp\u00e9cialisation en Data ce qui leur permet d'offrir 3 expertises m\u00e9tiers distinctes : la Data Science, la Data Engineering et le Machine Learning Engineering. Autour de ces expertises gravitent bien s\u00fbr les m\u00e9tiers de Lead et d'Architecte.\nUne autre de leur force est leur formation interne (avec des profils de seniors ou d'architectes) et externe (avec des partenaires pour passer les certifications).\nChez eux, le collaborateur est plac\u00e9 au centre des pr\u00e9occupations, permettant ainsi de cr\u00e9er une coh\u00e9sion et une v\u00e9ritable culture au sein de l'entreprise. Par exemple la majorit\u00e9 des projets se font en \u00e9quipe et non seul.\nConnu et reconnu pour leur expertise en Big Data, ils sont devenu le partenaire principal d'un grand groupe du CAC 40 et ont pris le lead sur tous les sujets touchant \u00e0 la transformation Big Data de ce groupe.\nPour poursuivre leur croissance, r\u00e9pondre \u00e0 leurs ambitions et d\u00e9velopper de nouveaux march\u00e9s, nous recherchons plusieurs profils pour renforcer leurs effectifs.\nLe poste\nEn les rejoignant vous travaillerez sur les probl\u00e9matiques suivantes :\nMise en place et/ou scale d'architectures\nConstruction de Datalake\nMise en production de model de ML\nPipelining de donn\u00e9es\nStreaming de donn\u00e9es et temps r\u00e9el\nLa stack sur laquelle vous travaillerez :\nPython, Scala, Spark, Architectures distribu\u00e9es : Hadoop, HDFS, Cloud : Aws, GCP, Azure\nVotre profil\nA partir de 3 ans d'exp\u00e9rience en CDI\nVous avez une exp\u00e9rience significative sur des probl\u00e9matiques Big Data\nTr\u00e8s bonne comp\u00e9tences en Python et/ou Scala et en Spark\nVous \u00eates familier avec Hadoop, Hive, Hbase\nUne logique cloud (Aws, GCP ou Azure)\nLe salaire & avantages\n50-60 K\u20ac selon exp\u00e9rience\nRTT\nCarte Swile & Mutuelle\n3/4 jours de t\u00e9l\u00e9travail par semaine\nEt plus encore\u2026\nCe qu\u2019on pr\u00e9f\u00e8re\n\u00catre impliqu\u00e9 \u00e0 fond dans une aventure avec de nombreux challenges techniques\nBelles opportunit\u00e9s d'\u00e9volutions sur des postes d'Architecte, de Lead ou de Ml Ops\nTr\u00e8s bonne ambiance, \u00e9quipe solidaire et orient\u00e9e partage d\u2019informations\nBeaucoup de workshops en interne et catalogue de formations \u00e0 votre guise\nCe poste a \u00e9t\u00e9 soigneusement choisi par votre coach. Powered by Octopus IT, cabinet d\u2019Experts en Recrutement Tech (CDI et clients finaux uniquement) \u2013 Visitez nous pour plus d\u2019opportunit\u00e9s :\nwww.octopusit.fr\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "Scala",
                "R"
            ],
            "DataBase": [
                "HBase"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [
                "Hadoop",
                "Spark"
            ],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [
                "AWS",
                "Azure"
            ],
            "DevTools": [],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [
                "HBase"
            ],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [
                "Big Data",
                "ML",
                "Machine Learning",
                "Cloud"
            ],
            "FrSoftSkills": [],
            "EnSoftSkils": []
        },
        "details": {
            "JobDetail": [
                "Senior"
            ],
            "TypeContract": [
                "CDI"
            ],
            "Salary": [
                "50"
            ],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s",
                "7",
                "7",
                "7"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "title": "Data Engineer Talend F/H",
        "company": "Orange Business",
        "location": "Greater Lille Metropolitan Area",
        "link": "https://fr.linkedin.com/jobs/view/data-engineer-talend-f-h-at-orange-business-3916552363?position=21&pageNum=0&refId=TDTc9UZJy78L%2BED7EV%2BMrg%3D%3D&trackingId=nWMEAJ97Rkf7axHPJgu4ww%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "L\u2019ambition d\u2019Orange Business est de devenir l\u2019int\u00e9grateur r\u00e9seau et num\u00e9rique de r\u00e9f\u00e9rence en Europe, en nous appuyant sur nos forces autour des solutions de connectivit\u00e9 nouvelle g\u00e9n\u00e9ration, du cloud et de la cybers\u00e9curit\u00e9.\nNos 30 000 femmes et hommes pr\u00e9sents dans 65 pays, dont chaque voix compte, sont tous anim\u00e9s par la m\u00eame d\u00e9termination et le m\u00eame esprit d\u2019\u00e9quipe, pour construire les solutions digitales d\u2019aujourd\u2019hui et de demain et cr\u00e9er un impact positif pour nos clients, pour leurs salari\u00e9s et pour la plan\u00e8te.\nNous offrons des opportunit\u00e9s passionnantes gr\u00e2ce \u00e0 des projets innovants dans la data et le digital, le cloud, l\u2019IA, la cybers\u00e9curit\u00e9, l\u2019IoT, ou encore le digital workspace et le big data.\nVenez vivre cette aventure avec nous !\nAfin de d\u00e9velopper notre \u00e9quipe lilloise, nous recherchons aujourd'hui, un Ing\u00e9nieur DATA \u00e0 m\u00eame d\u2019accompagner nos clients dans la structuration de leurs SI autour de la donn\u00e9e.\nVos principales missions seront les suivantes\n:\n- Concevoir des solutions de traitement et collecter des volumes importants de donn\u00e9es.\n- Participer \u00e0 des \u00e9tudes de cadrage pour collecter le besoin m\u00e9tier et concevoir les solutions qui r\u00e9pondent au besoin du client.\n- Apporter son expertise sur des probl\u00e9matiques pr\u00e9cises rencontr\u00e9es chez les clients.\n- Participer \u00e0 la veille technologique\n- R\u00e9aliser les\nd\u00e9veloppements TALEND\n- Rester inform\u00e9 et former sur les nouvelles solutions DATA\n- Contribuer aux phases d'avant-vente et au d\u00e9veloppement business.\n- Participer \u00e0 la conception, l'\u00e9volution et la pr\u00e9sentation de nos offres DATA.\nVous\n:\n- \u00cates issu(e) de formation bac+5 ?\n- Vous justifiez d'au moins 3 ans d'exp\u00e9riences en qualit\u00e9 d'Ing\u00e9nieur DATA sur la solution TALEND Enterprise (Data Integration) et avez id\u00e9alement une connaissance des solutions Cloud d'AWS et d'AZURE ?\n- Vous \u00eates intervenu sur des projets int\u00e9grant des pratiques DevOps et AGILE ?\nAlors postulez, ce poste est fait pour vous !\nVos comp\u00e9tences cl\u00e9s\n:\n- Expertise sur l'outil\nETL TALEND\nEnterprise (administration et d\u00e9veloppement)\n- Fortes connaissances des solutions de bases de donn\u00e9es (SQL, NoSQL\u2026)\n- Connaissances en langages objets ou scripts (notamment Java mais aussi Javascript, Scala, Python\u2026)\n- Divers syst\u00e8mes d'exploitation : UNIX, Windows\nAutonomie, rigueur, curiosit\u00e9, dynamisme et sens du service sont des qualit\u00e9s n\u00e9cessaires pour ce poste.\nLes comp\u00e9tences compl\u00e9mentaires qui seraient appr\u00e9ci\u00e9es :\n- Connaissances d'autres modules Talend (MDM, ESB, Data Quality, Cloud\u2026)\n- Ma\u00eetrise des technologies du Big Data (Hadoop, Spark, Kafka\u2026)\n- Expertise sur d'autres outils ETL (Informatica, SSIS, DataStage...)\n- Notions en architecture des Syst\u00e8mes d'Information\n- Ma\u00eetrise de l'anglais (oral et \u00e9crit)\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "Java",
                "Scala",
                "R",
                "JavaScript"
            ],
            "DataBase": [
                "SQL",
                "NoSQL"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [
                "Hadoop",
                "Spark"
            ],
            "MachingLearning": [
                "Orange"
            ],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [
                "AWS",
                "Azure"
            ],
            "DevTools": [
                "Git"
            ],
            "Os": [
                "Windows"
            ],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [
                "DevOps",
                "Big Data",
                "Cloud"
            ],
            "FrSoftSkills": [],
            "EnSoftSkils": []
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [],
            "Salary": [],
            "Level": [
                "Bac+5"
            ],
            "Experience": [
                "a",
                "n",
                "s",
                "3",
                "3",
                "3"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "title": "Data Engineer | Python - Azure | IA & Machine Learning  | Paris ou Remote Partiel",
        "company": "Octopus IT - Expert du recrutement tech",
        "location": "Paris, \u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/data-engineer-python-azure-ia-machine-learning-paris-ou-remote-partiel-at-octopus-it-expert-du-recrutement-tech-3664568765?position=22&pageNum=0&refId=TDTc9UZJy78L%2BED7EV%2BMrg%3D%3D&trackingId=moygXwPkYJVD30cyjrlNXw%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "La soci\u00e9t\ufffd\ufffd\nCr\u00e9\u00e9e il y a plus de 2 ans, cette startup est la premi\u00e8re base de connaissance intelligente d\u00e9di\u00e9e aux services clients. Leur mission ? En finir avec la frustration lorsque l'on contact un Help Desk.\nPour cela, elle propose aux entreprises la possibilit\u00e9 de d\u00e9livrer une exp\u00e9rience client d'exception : rapide et de qualit\u00e9. Gr\u00e2ce \u00e0 leur moteur de recherche intelligent, cette entreprise est capable de centraliser toute la connaissance interne de l'entreprise (proc\u00e9dures, produits, modes op\u00e9ratoires, etc.) et la diffuse intelligemment dans les outils de production des conseillers de service client.\nR\u00e9sultat :\nPlus besoin de chercher l'information\nDes r\u00e9ponses instantan\u00e9es et de meilleures qualit\u00e9es\nUne autonomie totale des collaborateurs\nApr\u00e8s une croissance fulgurante, elle a su s\u00e9duire \u00e0 la fois de nombreuses scale up (Luko, OpenClassrooms, Japhy...) et grands groupes (BNP Paribas, La Poste, Fnac Darty...).\nApr\u00e8s le recrutement de leur Lead Data (r\u00e9aliser ensemble) et suite \u00e0 l'annonce de leur lev\u00e9e de 2,5M\u20ac pour tripler la taille de ses \u00e9quipes, le but est maintenant de s'imposer tr\u00e8s vite comme la base de connaissance de r\u00e9f\u00e9rence en France et en Europe. Pour ce faire, nous recherchons un Data Engineer.\nLe poste\nEn travaillant main dans la main avec le Lead Data, ta mission sera de d\u00e9velopper et de maintenir des flux de donn\u00e9es complexes et robustes. La donn\u00e9e \u00e9tant au coeur de l' entreprise, dans le produit comme dans la strat\u00e9gie, tu seras amen\u00e9 \u00e0 travailler avec un panel d\u2019interlocuteurs tr\u00e8s vari\u00e9s :\nData Scientists sur des sujets comme le monitoring des mod\u00e8les de production et l\u2019enrichissement des donn\u00e9es d\u2019entrainement.\nProduct Team sur des sujets de performance et d\u2019acheminement de donn\u00e9es au service de fonctionnalit\u00e9s produit telles que le dashboard d\u2019analytics \u00e0 destination de nos clients.\nCustomer Success / Strategy sur des sujets de pilotage comme le suivi de l\u2019utilisation de notre plateforme ou la mise en place de KPIs de performance.\nTu travailleras sur les probl\u00e9matiques suivantes :\nTu seras responsable de notre architecture de donn\u00e9es et de son outillage, mais aussi de la mise en place de pipelines de donn\u00e9es complexes et robustes.\nTu seras amen\u00e9 \u00e0 mettre en place des outils de monitoring et d\u2019alerting pour suivre de pr\u00e8s nos nombreuses pipelines de donn\u00e9e.\nTu seras garant de la qualit\u00e9 de nos donn\u00e9es en assurant l\u2019application des guidelines de code et des tests automatis\u00e9s pour chacune de nos pipelines.\nTu seras amen\u00e9 \u00e0 mettre en place des outils de reporting / insights \u00e0 destination d\u2019interlocuteurs vari\u00e9s (Data Science, Product, Customer Success, Clients, etc.).\nTu cr\u00e9eras et d\u00e9velopperas des pipelines de donn\u00e9es avec des outils de scheduling et d\u2019orchestration.\nLa stack sur laquelle vous travaillerez :\nLangage : Python, Javascript\nFramework data : PyTorch, Transformers (Hugging Face), FastAPI\nDatabase : PostgreSQL, MongoDB, ElasticSearch, Redis\nInfrastructure : Azure, Docker, Kubernetes, Spark, RabbitMQ, Serverless, Terraform\nEnvironnement / Test : PyTest, Gitlab (git + ci/cd)\nBI : Metabase, Superset\nVotre profil\nEntre 1 et 3 ans d'exp\u00e9rience en CDI\nTu as une exp\u00e9rience significative sur des probl\u00e9matiques de Data engineering\nTu es quelqu'un de pragmatique\nUn tr\u00e8s bon niveau en Python et une tr\u00e8s bonne rigueur dans le code\nBonne pratique de dev : clean code, TDD, BDD\nUne bonne culture Ops\nUne logique cloud (Aws, GCP ou Azure)\nLe salaire & avantages\n50-7O K\u20ac selon exp\u00e9rience\nRTT\nCarte Swile & Mutuelle\n2/3 jours de t\u00e9l\u00e9travail par semaine\nEt plus encore\u2026\nCe qu\u2019on pr\u00e9f\u00e8re\n\u00catre impliqu\u00e9 \u00e0 fond dans une aventure avec de nombreux challenges techniques\nBelles opportunit\u00e9s d'\u00e9volutions sur des postes d'Architecte, de Lead ou de Ml Ops\nBeaucoup de workshops en interne et catalogue de formations \u00e0 votre guise\nUne opportunit\u00e9 de travailler sur un produit unique qui a d\u00e9j\u00e0 s\u00e9duit de tr\u00e8s beaux clients (BNP Paribas, Fnac Darty, Luko, OpenClassrooms)\nLa possibilit\u00e9 de travailler sur une stack tr\u00e8s moderne, des probl\u00e9matiques complexes aussi bien en traitement de donn\u00e9es, qu'en DevOps\nUn plan de BSPCE (actions de l'entreprise) tr\u00e8s int\u00e9ressant et motivant !\nUne culture d'entreprise fond\u00e9e sur l'apprentissage, l'autonomie, la bienveillance et l'exigence\nLe fait de travailler au quotidien avec des fondateurs passionn\u00e9s par leur domaine d'expertise\nCe poste a \u00e9t\u00e9 soigneusement choisi par votre coach. Powered by Octopus IT, cabinet d\u2019Experts en Recrutement Tech (CDI et clients finaux uniquement) \u2013 Visitez nous pour plus d\u2019opportunit\u00e9s :\nwww.octopusit.fr\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "Java",
                "R",
                "Go",
                "JavaScript"
            ],
            "DataBase": [
                "SQL",
                " MongoDB",
                "Elasticsearch"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [
                "Spark"
            ],
            "MachingLearning": [
                "PyTorch"
            ],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [
                "AWS",
                "Azure"
            ],
            "DevTools": [
                "Git",
                "Docker"
            ],
            "Os": [],
            "DBMS": [
                "PostgreSQL"
            ],
            "SoftBigDataProcessing": [],
            "Automation": [
                "Kubernetes"
            ],
            "InfrastructureAsCode": [
                "Terraform"
            ],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [
                "Docker",
                "Kubernetes"
            ],
            "Collaboration": [],
            "Other": [
                "DevOps",
                "ML",
                "Cloud",
                "CI/CD"
            ],
            "FrSoftSkills": [],
            "EnSoftSkils": []
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [
                "CDI"
            ],
            "Salary": [
                "50"
            ],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s",
                "2",
                "2",
                "2"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "title": "Data Engineer - Mod\u00e9lisation SQL - F/H",
        "company": "Orange Business",
        "location": "Greater Lille Metropolitan Area",
        "link": "https://fr.linkedin.com/jobs/view/data-engineer-mod%C3%A9lisation-sql-f-h-at-orange-business-3916551577?position=23&pageNum=0&refId=TDTc9UZJy78L%2BED7EV%2BMrg%3D%3D&trackingId=mXyowhaRMxCj2BN%2Bzc7rrw%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Et si Business & Decision et Orange Business conjuguaient leurs forces pour devenir l\u2019un des leaders europ\u00e9ens de la Data transformation ?\nNous l\u2019avons fait ! Notre alchimie nous positionne comme un acteur unique intervenant sur toutes les \u00e9tapes du voyage de la donn\u00e9e.\nDepuis 30 ans, Business & Decision, entit\u00e9 de Digital Services s'est impos\u00e9e comme un partenaire strat\u00e9gique pour la transformation Data de nombreux clients, dans des secteurs tr\u00e8s vari\u00e9s. Digital Services est aujourd\u2019hui l\u2019ESN d\u2019Orange Business alliant les expertises historiques Cloud et Digital d\u2019Orange ainsi que le c\u0153ur de m\u00e9tier Data/IA de Business & Decision. Son but est d\u2019accompagner les entreprises et les acteurs publics dans leur transformation gr\u00e2ce aux 4000 experts pr\u00e9sents dans plusieurs grandes villes fran\u00e7aises comme Montpellier, Niort, Lyon, Bordeaux, Lille et Toulouse \u2026\nDescription du poste\nOrange Business, recherche pour son site de Lille, son futur Data Engineer pour rejoindre sa team Data.\nVotre quotidien ?\nEn int\u00e9grant Orange Business, vous pouvez participer \u00e0 une grande diversit\u00e9 d\u2019activit\u00e9s dans la Data. En voici un aper\u00e7u :\nAu d\u00e9marrage du projet :\nRecueillir et analyser les besoins du client\nR\u00e9diger les sp\u00e9cifications fonctionnelles et techniques\nEstimer les charges\nPendant la phase de r\u00e9alisation :\nMod\u00e9liser des datawarehouses et datamart (int\u00e9gration de flux et consolidation des donn\u00e9es)\nD\u00e9velopper les proc\u00e9dures d\u2019alimentation (ETL)\nD\u00e9velopper en SQL / PLSQL / Shell\nGarantir la qualit\u00e9 des donn\u00e9es et leur disponibilit\u00e9\nR\u00e9aliser la recette et les tests\nSuivre et mettre en production\nEn fonction de votre \u00e9volution et de nos enjeux, vous pouvez aussi \u00e9voluer sur des missions transverses (conseil, coaching, avant-vente, formation, audit, etc.). La prise d\u2019initiative est toujours la bienvenue !\nQualifications\nVous poss\u00e9dez 5 ans d'exp\u00e9rience ou plus dans la mise en \u0153uvre de projets d\u00e9cisionnels et en mod\u00e9lisation.\nVous avez de s\nolides comp\u00e9tences en d\u00e9veloppement SQL\n(job, scripting, d\u00e9ploiement) ainsi que sur Python.\nEnvie d\u2019apprendre de nouvelles technos ? Vous souhaitez partager vos comp\u00e9tences et b\u00e9n\u00e9ficier des expertises de la Team Orange Business ?\nOutre l\u2019aspect technique, c\u2019est une personnalit\u00e9 qui est recherch\u00e9e !\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "R"
            ],
            "DataBase": [
                "SQL"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [],
            "MachingLearning": [
                "Orange"
            ],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [],
            "DevTools": [
                "Git"
            ],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [
                "Cloud"
            ],
            "FrSoftSkills": [],
            "EnSoftSkils": [
                "Initiative"
            ]
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s",
                "30",
                "30",
                "30"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "title": "DATA ENGINEER (H/F)",
        "company": "SFR",
        "location": "Paris, \u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/data-engineer-h-f-at-sfr-3879318123?position=24&pageNum=0&refId=TDTc9UZJy78L%2BED7EV%2BMrg%3D%3D&trackingId=FMZDHlMn1O%2FB9TWDKjU5bw%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "En tant que Data Ing\u00e9nieur exp\u00e9riment\u00e9, vous occuperez un r\u00f4le essentiel dans notre \u00e9quipe Data Science.\nVous serez responsable de la conception, du d\u00e9veloppement et de la maintenance des pipelines de donn\u00e9es ainsi que de l'int\u00e9gration de sources de donn\u00e9es multiples.\nVotre expertise sera cruciale pour garantir une gestion efficace des flux de donn\u00e9es, ainsi que pour faciliter l'analyse et la visualisation des donn\u00e9es en plus du support aux data scientists vos missions seront les suivantes :\nArchitecture projet des donn\u00e9es\n: Concevoir et d\u00e9velopper des architectures projet de donn\u00e9es robustes, \u00e9volutives et performantes pour int\u00e9grer et g\u00e9rer de grandes quantit\u00e9s de donn\u00e9es provenant de sources multiples. Assurer la fiabilit\u00e9, l'\u00e9volutivit\u00e9 et la s\u00e9curit\u00e9 des flux de donn\u00e9es entrant d\u2019un projet Data Science.\nInt\u00e9gration des donn\u00e9es\n: \u00c9laborer des pipelines de donn\u00e9es efficaces pour l'extraction, la transformation et le chargement des donn\u00e9es (via notre Framework ELT/ETL interne) provenant de diff\u00e9rentes sources. Mettre en place des processus d'int\u00e9gration automatis\u00e9s et veiller \u00e0 la qualit\u00e9 des donn\u00e9es.\nGestion des bases de donn\u00e9es\n: Concevoir et optimiser des bases de donn\u00e9es pour r\u00e9pondre aux besoins analytiques et de reporting. Assurer la performance, la disponibilit\u00e9 et la s\u00e9curit\u00e9 des bases de donn\u00e9es, ainsi que la gestion efficace des requ\u00eates.\nCollaboration interfonctionnelle\n: Support des Data Scientists, vous travaillerez avec les \u00e9quipes business pour comprendre leurs besoins et fournir des conseils et des recommandations bas\u00e9s sur les donn\u00e9es.\nOptimisation des performances\n: Surveiller et optimiser les performances des pipelines de donn\u00e9es, des bases de donn\u00e9es et des requ\u00eates. Identifier les goulots d'\u00e9tranglement et les points d'optimisation, et proposer des am\u00e9liorations pour garantir des performances optimales.\nS\u00e9curit\u00e9 et conformit\u00e9\n: Veiller \u00e0 ce que les donn\u00e9es soient trait\u00e9es et stock\u00e9es conform\u00e9ment aux normes de s\u00e9curit\u00e9 et de confidentialit\u00e9. Mettre en place des m\u00e9canismes de s\u00e9curit\u00e9 pour prot\u00e9ger les donn\u00e9es sensibles et garantir la conformit\u00e9 aux r\u00e9glementations en vigueur.\nVotre profil :\nVous avez un\nDipl\u00f4me universitaire en informatique, en g\u00e9nie logiciel, en science des donn\u00e9es ou dans un domaine connexe et vous avez \u00e0 minima 5 ans d'exp\u00e9rience en tant que Data Ing\u00e9nieur.\nVous poss\u00e9dez \u00e9galement une solide ma\u00eetrise des technologies et des outils suivants :\nHadoop, Spark, SQL, Kafka, GCP BigQuery,\nDe plus vous avez une bonne compr\u00e9hension des architectures, des mod\u00e8les et des concepts de base de donn\u00e9s avec une exp\u00e9rience avanc\u00e9e dans la mise en \u0153uvre de pipelines ETL et dans la gestion de bases de donn\u00e9es.\nVos connaissances en mati\u00e8re de s\u00e9curit\u00e9 des donn\u00e9es, de conformit\u00e9 aux r\u00e9glementations ainsi que vos comp\u00e9tences en programmation scripting et en d\u00e9veloppement logiciel seront un plus.\nVos excellentes comp\u00e9tences en communication seront des qualit\u00e9s appr\u00e9ci\u00e9es et\nun niveau d'anglais (appliqu\u00e9e au domaine technique) est un plus.\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "R",
                "Go"
            ],
            "DataBase": [
                "SQL"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [
                "Hadoop",
                "Spark"
            ],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [],
            "DevTools": [],
            "Os": [],
            "DBMS": [
                "BigQuery"
            ],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [],
            "FrSoftSkills": [
                "Communication",
                "Collaboration"
            ],
            "EnSoftSkils": [
                "Communication",
                "Collaboration"
            ]
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s",
                "5",
                "5",
                "5"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "title": "Data & Cloud Engineer (H/F)",
        "company": "fifty-five",
        "location": "Paris, \u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/data-cloud-engineer-h-f-at-fifty-five-3910028674?position=25&pageNum=0&refId=TDTc9UZJy78L%2BED7EV%2BMrg%3D%3D&trackingId=VCniSLmV9FdFUbTN8DKrDw%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Data & Cloud Engineer\nfifty-five est une data-company d'un genre nouveau qui aide les marques \u00e0 exploiter les donn\u00e9es pour am\u00e9liorer le marketing, les m\u00e9dias et l'exp\u00e9rience client gr\u00e2ce \u00e0 une combinaison de services de conseil et de technologie sp\u00e9cialis\u00e9s.\nEn tant que pilier data et marketing du Brandtech Group, nous offrons des services qui combinent le conseil en strat\u00e9gie, les services de cloud, le conseil en m\u00e9dia et l'exp\u00e9rience client.\nfifty-five, c'est plus de 400 experts du num\u00e9rique. Des digital consultants, des sp\u00e9cialistes du tracking et du m\u00e9dia, des ing\u00e9nieurs et des data scientists, travaillent tous en \u00e9troite collaboration pour fournir des conseils marketing de haut niveau et une assistance technique aux marques, dans tout type d'industrie, partout dans le monde.\nPartenaire des annonceurs de la collecte \u00e0 l'activation et l'exploitation des donn\u00e9es, nous aidons les organisations \u00e0 devenir de v\u00e9ritables entit\u00e9s omnicanales ma\u00eetrisant l'efficacit\u00e9 de leur \u00e9cosyst\u00e8me digital et ses synergies avec le monde physique.\nBas\u00e9 \u00e0 Paris, nous op\u00e9rons sur 3 fuseaux horaires depuis nos 10 bureaux, situ\u00e9s \u00e0 Paris, Londres, Gen\u00e8ve, Milan, Shanghai, Hong Kong, Shenzhen, Taipei, Singapour et New York. fifty-five attache une importance particuli\u00e8re au bien-\u00eatre de ses collaborateurs, ce qui lui a permis de figurer dans le classement Best Workplaces France en 2018.\nContexte :\nL'\u00e9quipe d'ing\u00e9nierie d\u00e9veloppe et met en \u0153uvre les solutions techniques permettant la r\u00e9alisation de pipelines de donn\u00e9es et l'impl\u00e9mentation de data platform pour nos clients : r\u00e9cup\u00e9ration de datas sur de multiples sources de donn\u00e9es (APIs, files, etc.), data cleaning, data processing, automation et monitoring de l'ensemble. L'\u00e9quipe s'appuie sur des technologies r\u00e9centes (docker, kubernetes, terraform, notebooks, etc.) et met en place ses projets dans les diff\u00e9rents clouds du march\u00e9 (GCP, Azure, AWS...).\nMission :\nNous sommes \u00e0 la recherche d'une personne capable de r\u00e9aliser des projets techniques pour r\u00e9pondre aux besoins de nos clients (par exemple: syst\u00e8me de recommandations de produits, d\u00e9tection d'anomalies, ranking). Les activit\u00e9s vont du chiffrage et du sizing technique \u00e0 la mise en \u0153uvre des architectures, en passant par la revue des sp\u00e9cifications fonctionnelles et la production de code. Le Data & Cloud Engineer sera \u00e9paul\u00e9 par un Lead dans ses missions. Il sera \u00e9galement amen\u00e9 \u00e0 participer \u00e0 la R&D et \u00e0 accompagner les \u00e9quipes transverses dans la mise en place d'outils de travail internes (librairies pour les data scientists, environnement Notebooks pour les data analysts et data scientists, d\u00e9veloppement de frameworks sur diff\u00e9rents cloud providers, etc.).\nNous souhaitons trouver la bonne personne pour faire \u00e9voluer ou cr\u00e9er de nouvelles solutions dans ce cadre. Les missions comprennent aussi bien du prototypage rapide pour des d\u00e9monstrateurs, que de la production de code robuste qui tourne en production tous les jours.\nComp\u00e9tences et exp\u00e9riences :\n2 ans d'exp\u00e9rience en tant que Data Engineer\nMa\u00eetrise de Python, SQL\nMa\u00eetrise des environnements Cloud. Id\u00e9alement certifi\u00e9 GCP, Azure ou AWS\nBonne connaissance de Docker/Kubernetes\nBonne connaissance d'au moins un data warehouse (BigQuery, Snowflake, etc)\nConnaissance autour des Notebooks (Jupyter)\nA l'aise avec des concepts li\u00e9s aux APIs (OAuth, REST, etc.)\nA l'aise avec les notions d'Infrastructure as Code (Terraform)\nAu courant des pratiques GitOps et connaissances des concepts autour du CI/CD\nLa ma\u00eetrise d'un orchestrateur, comme Apache Airflow, est un plus\nEsprit d'\u00e9quipe (collaborer aux tests unitaires, revue de code, partage de code, sprints)\nBon niveau en fran\u00e7ais et en anglais\nA d\u00e9j\u00e0 travaill\u00e9 en mode projet avec des interlocuteurs vari\u00e9s (consultant, data analyst, data scientist)\nUne exp\u00e9rience en marketing digital est un plus\nNous proposons :\nun bureau au centre de Paris avec terrasse et jardin\nun environnement multiculturel avec des collaborateurs aux nationalit\u00e9s multiples (France, Royaume-Uni, Etats-Unis, Chine, Tunisie, Italie et plus)\ndes projets avec nos bureaux \u00e0 Londres, Hong Kong, New York, Shanghai, Gen\u00e8ve, Shenzhen et Taipei\ndes TGIF et supers soir\u00e9es\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "R"
            ],
            "DataBase": [
                "SQL"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [
                "Apache Airflow"
            ],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [
                "AWS",
                "Azure"
            ],
            "DevTools": [
                "Git",
                "Docker"
            ],
            "Os": [],
            "DBMS": [
                "Snowflake",
                "Snowflake",
                "BigQuery"
            ],
            "SoftBigDataProcessing": [],
            "Automation": [
                "Kubernetes",
                "Airflow"
            ],
            "InfrastructureAsCode": [
                "Terraform"
            ],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [
                "Docker",
                "Kubernetes"
            ],
            "Collaboration": [],
            "Other": [
                "Cloud",
                "CI/CD"
            ],
            "FrSoftSkills": [
                "Collaboration",
                "Organisation"
            ],
            "EnSoftSkils": [
                "Collaboration"
            ]
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s",
                "2",
                "2",
                "2"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "title": "Data Engineer \u2013 Grenoble",
        "company": "Capgemini",
        "location": "Grenoble, Auvergne-Rh\u00f4ne-Alpes, France",
        "link": "https://fr.linkedin.com/jobs/view/data-engineer-%E2%80%93-grenoble-at-capgemini-3905836212?position=26&pageNum=0&refId=TDTc9UZJy78L%2BED7EV%2BMrg%3D%3D&trackingId=phBx1%2BYFP%2BE7q4Dxg28eJw%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Choisir Capgemini, c'est choisir une entreprise o\u00f9 vous serez en mesure de fa\u00e7onner votre carri\u00e8re selon vos aspirations. Avec le soutien et l'inspiration d'une communaut\u00e9 d\u2019experts dans le monde entier, vous pourrez r\u00e9\u00e9crire votre futur. Rejoignez-nous pour red\u00e9finir les limites de ce qui est possible, contribuer \u00e0 lib\u00e9rer la valeur de la technologie pour les plus grandes organisations et participer \u00e0 la construction d\u2019un monde plus durable et inclusif.\nVos missions :\nEn tant que Data Engineer au sein d'une \u00e9quipe multidisciplinaire, vos responsabilit\u00e9s principales seront les suivantes :\nIntervenir sur les diff\u00e9rentes phases d'un projet dans un environnement Cloud et Agile.\nContribuer \u00e0 la gestion de la qualit\u00e9 des donn\u00e9es et extraction et analyse de celle-ci, ainsi qu\u2019\u00e0 la pr\u00e9sentation des donn\u00e9es dans leur forme raffin\u00e9e.\nProposer des nouvelles lectures de donn\u00e9es via un travail de fouille sur les gisements d\u2019information, notamment client.\nAdopter une posture de consultant : proposer de nouvelles solutions et accompagner le client dans ses choix.\nVotre profil :\nTitulaire d'un Bac+5 en \u00e9cole d\u2019ing\u00e9nieur ou en universit\u00e9.\nConnaissances approfondies des ETL (Talend, Informatica ou SSIS), du traitement de donn\u00e9es (Spark, Python, Scala) ainsi que des bases de donn\u00e9es (Oracle, SQL Server, Postgres).\nFacult\u00e9 pour se montrer curieux, autonome et proactif dans la r\u00e9alisation de ses t\u00e2ches.\nCapacit\u00e9 \u00e0 faire preuve de rigueur et \u00e0 travailler en \u00e9quipe.\nBon niveau d\u2019anglais (B2 minimum).\n3 raisons de nous rejoindre :\nQualit\u00e9 de vie au travail\n: accord de t\u00e9l\u00e9travail en France et \u00e0 l\u2019international, accord sur l\u2019\u00e9galit\u00e9 professionnelle, la parentalit\u00e9, l\u2019\u00e9quilibre des temps et la mobilit\u00e9 durable.\nApprentissage en continu\n: certifications et formations en libre acc\u00e8s, accompagnement sur mesure avec votre career manager, parcours d\u2019int\u00e9gration sur 9 mois.\nAvantages groupe & CSE\n: plan actionnariat, tarif pr\u00e9f\u00e9rentiels, remboursement partiel vacances, remboursement de votre abonnement sportif ou culturel.\nNos engagements et priorit\u00e9s\n:\nLe groupe Capgemini encourage une culture inclusive dans un cadre multiculturel et handi-accueillant. En nous rejoignant, vous int\u00e9grez un collectif qui valorise la diversit\u00e9, d\u00e9veloppe le potentiel de ses talents, s\u2019engage dans des initiatives solidaires avec ses partenaires, et se mobilise pour r\u00e9duire son impact environnemental sur tous ses sites et aupr\u00e8s de ses clients.\n\u00c0 propos de Capgemini :\nCapgemini est un leader mondial, responsable et multiculturel, regroupant pr\u00e8s de 350 000 personnes dans plus de 50 pays. Fort de 55 ans d\u2019exp\u00e9rience, nous sommes un partenaire strat\u00e9gique des entreprises pour la transformation de leurs activit\u00e9s en tirant profit de toute la puissance de la technologie et des innovations dans les domaines en perp\u00e9tuelle \u00e9volution tels que le cloud, la data, l\u2019Intelligence Artificielle, la connectivit\u00e9, les logiciels, l\u2019ing\u00e9nierie digitale ou les plateformes.\nGet The Future You Want* | www.capgemini.com/fr-fr\n*Capgemini, le futur que vous voulez\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "Scala",
                "R"
            ],
            "DataBase": [
                "SQL"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [
                "Spark"
            ],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [],
            "DevTools": [
                "Git"
            ],
            "Os": [],
            "DBMS": [
                "Oracle",
                "SQL Server"
            ],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [
                "Cloud"
            ],
            "FrSoftSkills": [
                "Organisation"
            ],
            "EnSoftSkils": [
                "Initiative"
            ]
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [],
            "Salary": [],
            "Level": [
                "Bac+5"
            ],
            "Experience": [
                "a",
                "n",
                "s",
                "55",
                "55",
                "55"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "title": "Data Engineer",
        "company": "eXalt Value",
        "location": "\u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/data-engineer-at-exalt-value-3897767649?position=27&pageNum=0&refId=TDTc9UZJy78L%2BED7EV%2BMrg%3D%3D&trackingId=NbB%2F19lo6taC1wWs893b8w%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "eXalt\nest un cabinet de conseil IT\nPure player Data\n& IA bas\u00e9 \u00e0 Paris.\nNotre offre s\u2019articule autour de 4 piliers r\u00e9unis au sein d\u2019une m\u00eame communaut\u00e9 pour un accompagnement \u00e0 360\u00b0 alliant une expertise technique et m\u00e9thodologique \u00e0 une approche conseil m\u00e9tier:\nData Gouvernance & Project\nData Engineering & Big Data\nData Performance & Analytics\nData Science & IA\nFiliale du groupe eXalt, cr\u00e9\u00e9 en 2018,\nregroupant plus de\n950 collaborateurs en France\n(Paris, Lyon, Bordeaux, Lille, Nantes, Marseille)\net \u00e0 l\u2019international\n(Colombie, Etats-Unis, Espagne, Belgique),\neXalt Value\napporte une\nexpertise approfondie\ndans le domaine de la Data & IA et conseille les entreprises dans le d\u00e9ploiement de leurs strat\u00e9gies data-driven.\nB\u00e9n\u00e9ficiant du support du groupe eXalt\n(1er dans la cat\u00e9gorie Conseil & Audit au classement des Champions de la Croissance 2024), eXalt Value\nest en pleine croissance et regroupe aujourd\u2019hui une communaut\u00e9 d\u2019expertise de plus de 60 collaborateurs en r\u00e9gion parisienne.\nNos consultants interviennent sur d\nes projets d\u2019envergure\ndans divers secteurs d\u2019activit\u00e9,\nBanque & Assurance, M\u00e9dias, Transports, Retail, Tourisme, etc.\nNous recherchons un\nData Engineer Confirm\u00e9 H/F (minimum 4 ans d'exp\u00e9rience dans la fonction)\npour rejoindre notre communaut\u00e9 sur le\npilier Data Engineering & Big Data.\nVos missions:\nConcevoir et d\u00e9velopper des pipelines et des flux de donn\u00e9es.\nInt\u00e9grer et transformer des donn\u00e9es provenant de diff\u00e9rentes sources.\nD\u00e9velopper et mettre en \u0153uvre des algorithmes de traitement de donn\u00e9es avanc\u00e9s.\nCollaborer \u00e9troitement avec les \u00e9quipes clients pour comprendre leurs besoins et fournir des solutions adapt\u00e9es.\nAssurer la qualit\u00e9 et la fiabilit\u00e9 des solutions d\u00e9velopp\u00e9es.\nConseiller les \u00e9quipes clients sur les solutions \u00e0 mettre en place.\nLes Pr\u00e9requis :\nTitulaire d'un Bac+5, Ecole d'Ing\u00e9nieur\nMa\u00eetrise d'un ou plusieurs langages de programmation (\nPython, Scala, Spark, etc\n.).\nExp\u00e9rience approfondie des technologies\nBig Data (Hadoop, Spark, Kafka, Talend, etc.)\nExp\u00e9rience av\u00e9r\u00e9e\nen\nenvironnement Cloud (AWS, GCP, ou Azure)\n.\nSolides comp\u00e9tences en conception et en optimisation de pipelines de donn\u00e9es.\nExp\u00e9rience de travail en\nm\u00e9thode Agile\nCapacit\u00e9 \u00e0 travailler de mani\u00e8re autonome et en \u00e9quipe.\nExcellentes comp\u00e9tences en communication et en r\u00e9solution de probl\u00e8mes.\nMa\u00eetrise de l\u2019anglais (oral & \u00e9crit dans un contexte international professionnel).\nVotre environnement eXalt\u00e9:\nUn environnement de travail Collaboratif\nfavorisant les initiatives et projets transverses \u00e0 la Practice Data & IA (Lab IA, Data Hub, etc.).\nUn collectif de consultants passionn\u00e9s,\ns\u2019int\u00e9ressant aux tendances innovantes du secteur.\nUne Practice de proximit\u00e9,\nprivil\u00e9giant la mont\u00e9e en comp\u00e9tence de ses collaborateurs (formations, coachings, mentorats, etc.)\nUn suivi individualis\u00e9 et de proximit\u00e9\npar un.e Data Sales Manager r\u00e9f\u00e9rent du compte client, un.e Charg\u00e9.e RH et un.e Practice Manager\nUne \u00e9quipe ouverte et dynamique,\nqui privil\u00e9gie les moments de partage et de convivialit\u00e9 (s\u00e9minaires, eXaltemps, meet-up, d\u00e9jeuners d\u2019\u00e9quipe, etc.)\nNotre processus de recrutement :\nUn entretien RH avec Estelle,\n\u00e0 la suite duquel vous saurez tout (ou presque) d\u2019eXalt Value,\nUn entretien technique avec un Manager assorti d\u2019un test technique,\nlors duquel vous aurez l\u2019occasion de d\u00e9montrer vos talents mais aussi d\u2019apprendre avant m\u00eame de dire oui,\nUn entretien final avec la Directrice Associ\u00e9e ou le Directeur Op\u00e9rationnel,\npour finir de vous convaincre de nous rejoindre \ud83d\ude0a\nNous avons h\u00e2te de recevoir vos CV, et de faire votre connaissance!\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "Scala",
                "R",
                "Go"
            ],
            "DataBase": [],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [
                "Hadoop",
                "Spark"
            ],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [
                "AWS",
                "Azure"
            ],
            "DevTools": [],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [
                "Big Data",
                "Cloud"
            ],
            "FrSoftSkills": [
                "Communication",
                "R\u00e9solution de probl\u00e8mes"
            ],
            "EnSoftSkils": [
                "Communication",
                "Initiative"
            ]
        },
        "details": {
            "JobDetail": [
                "Confirm\u00e9"
            ],
            "TypeContract": [],
            "Salary": [],
            "Level": [
                "Bac+5"
            ],
            "Experience": [
                "a",
                "n",
                "s",
                "4",
                "4",
                "4"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "title": "Data Engineer | Python - Spark - Hadoop | Sp\u00e9cialis\u00e9 en Big Data | Paris ou Remote Partiel",
        "company": "Octopus IT - Expert du recrutement tech",
        "location": "Paris, \u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/data-engineer-python-spark-hadoop-sp%C3%A9cialis%C3%A9-en-big-data-paris-ou-remote-partiel-at-octopus-it-expert-du-recrutement-tech-3685740787?position=28&pageNum=0&refId=TDTc9UZJy78L%2BED7EV%2BMrg%3D%3D&trackingId=95UUn0EtXS4JBMe178TvPw%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "La soci\u00e9t\u00e9\nCr\u00e9\u00e9e il y a 7 ans, cette entreprise de conseil en hyper croissance, se compose d'environ 90 personnes. Elle est devenue experte en Data et IA (NLP, Deep Learning, Machine Learning) et accompagne leurs clients sur l\u2019ensemble de leurs projets data \u00e0 travers la valorisation de leurs donn\u00e9es.\nLeur valeur ajout\u00e9e ? Leur sp\u00e9cialisation en Data ce qui leur permet d'offrir 3 expertises m\u00e9tiers distinctes : la Data Science, la Data Engineering et le Machine Learning Engineering. Autour de ces expertises gravitent bien s\u00fbr les m\u00e9tiers de Lead et d'Architecte.\nUne autre de leur force est leur formation interne (avec des profils de seniors ou d'architectes) et externe (avec des partenaires pour passer les certifications).\nChez eux, le collaborateur est plac\u00e9 au centre des pr\u00e9occupations, permettant ainsi de cr\u00e9er une coh\u00e9sion et une v\u00e9ritable culture au sein de l'entreprise. Par exemple la majorit\u00e9 des projets se font en \u00e9quipe et non seul.\nConnu et reconnu pour leur expertise en Big Data, ils sont devenu le partenaire principal d'un grand groupe du CAC 40 et ont pris le lead sur tous les sujets touchant \u00e0 la transformation Big Data de ce groupe.\nPour poursuivre leur croissance, r\u00e9pondre \u00e0 leurs ambitions et d\u00e9velopper de nouveaux march\u00e9s, nous recherchons plusieurs profils pour renforcer leurs effectifs.\nLe poste\nEn les rejoignant vous travaillerez sur les probl\u00e9matiques suivantes :\nMise en place et/ou scale d'architectures\nConstruction de Datalake\nMise en production de model de ML\nPipelining de donn\u00e9es\nStreaming de donn\u00e9es et temps r\u00e9el\nLa stack sur laquelle vous travaillerez :\nPython, Scala, Spark, Architectures distribu\u00e9es : Hadoop, HDFS, Cloud : Aws, GCP, Azure\nVotre profil\nA partir de 3 ans d'exp\u00e9rience en CDI\nVous avez une exp\u00e9rience significative sur des probl\u00e9matiques Big Data\nTr\u00e8s bonne comp\u00e9tences en Python et/ou Scala et en Spark\nVous \u00eates familier avec Hadoop, Hive, Hbase\nUne logique cloud (Aws, GCP ou Azure)\nLe salaire & avantages\n50-60 K\u20ac selon exp\u00e9rience\nRTT\nCarte Swile & Mutuelle\n3/4 jours de t\u00e9l\u00e9travail par semaine\nEt plus encore\u2026\nCe qu\u2019on pr\u00e9f\u00e8re\n\u00catre impliqu\u00e9 \u00e0 fond dans une aventure avec de nombreux challenges techniques\nBelles opportunit\u00e9s d'\u00e9volutions sur des postes d'Architecte, de Lead ou de Ml Ops\nTr\u00e8s bonne ambiance, \u00e9quipe solidaire et orient\u00e9e partage d\u2019informations\nBeaucoup de workshops en interne et catalogue de formations \u00e0 votre guise\nCe poste a \u00e9t\u00e9 soigneusement choisi par votre coach. Powered by Octopus IT, cabinet d\u2019Experts en Recrutement Tech (CDI et clients finaux uniquement) \u2013 Visitez nous pour plus d\u2019opportunit\u00e9s :\nwww.octopusit.fr\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "Scala",
                "R"
            ],
            "DataBase": [
                "HBase"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [
                "Hadoop",
                "Spark"
            ],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [
                "AWS",
                "Azure"
            ],
            "DevTools": [],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [
                "HBase"
            ],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [
                "Big Data",
                "ML",
                "Machine Learning",
                "Cloud"
            ],
            "FrSoftSkills": [],
            "EnSoftSkils": []
        },
        "details": {
            "JobDetail": [
                "Senior"
            ],
            "TypeContract": [
                "CDI"
            ],
            "Salary": [
                "50"
            ],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s",
                "7",
                "7",
                "7"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "title": "Data Engineer (H/F)",
        "company": "MP DATA",
        "location": "Toulouse, Occitanie, France",
        "link": "https://fr.linkedin.com/jobs/view/data-engineer-h-f-at-mp-data-3908719610?position=29&pageNum=0&refId=TDTc9UZJy78L%2BED7EV%2BMrg%3D%3D&trackingId=wOEylaAHBy4c%2BGNI5PQ6tg%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "MP DATA est une soci\u00e9t\u00e9 sp\u00e9cialis\u00e9e dans l\u2019acquisition, le traitement, et la valorisation des donn\u00e9es.\nDepuis sa cr\u00e9ation en 2015, MP DATA accompagne ses clients, majoritairement industriels, dans le management de leur performance et l\u2019exploitation de leurs donn\u00e9es.\nLes collaborateurs, tous issus de grandes \u00e9coles, incarnent au quotidien les valeurs d\u2019Excellence, de Partage et d\u2019Engagement.\nIls associent savoir-faire technique, m\u00e9thodologie et passion et mettent leurs comp\u00e9tences au service de missions et projets au sein de grands groupes fran\u00e7ais.\nMP DATA accompagne ses clients sur toute la chaine au travers de 3 p\u00f4les d\u2019expertise : Conseil et Strat\u00e9gie, Infrastructure & CloudOPS, Data Science.\nChez MP DATA, les \u00e9quipes commerciales cherchent des missions en fonction des envies des collaborateurs et non pas l\u2019inverse. Les consultants sont accompagn\u00e9s dans tous leurs projets, de la mobilit\u00e9 g\u00e9ographique, au changement de secteur d\u2019activit\u00e9 en passant par le d\u00e9veloppement de nouvelles comp\u00e9tences.\nRejoindre MP DATA, c\u2019est la garantie de travailler sur des sujets passionnants avec un cadre technique fort.\nDescriptif du poste :\nNous recherchons un Data Engineer exp\u00e9riment\u00e9 pour rejoindre notre \u00e9quipe.\nEn tant que Data Engineer, vous serez responsable de la conception, du d\u00e9veloppement et de la mise en \u0153uvre de pipelines de traitement de donn\u00e9es en temps r\u00e9el \u00e0 grande \u00e9chelle.\nVous travaillerez avec des technologies telles que Kafka, Flink, Kinesis et vous utiliserez les services du cloud AWS pour stocker et traiter les donn\u00e9es.\nVos responsabilit\u00e9s :\nUtiliser Kafka pour le traitement de flux de donn\u00e9es en temps r\u00e9el \u00e0 grande \u00e9chelle, en travaillant avec les producteurs, les consommateurs et les topics.\nMettre en \u0153uvre des pipelines de traitement de donn\u00e9es en streaming avec Flink, en appliquant des transformations complexes et en g\u00e9rant les \u00e9tats.\n\u00c9crire du code efficace et maintenable en Java / Python pour manipuler et analyser les donn\u00e9es en temps r\u00e9el.\nUtiliser Kubernetes pour d\u00e9ployer et g\u00e9rer des applications conteneuris\u00e9es \u00e0 grande \u00e9chelle, en assurant la r\u00e9silience et l\u2019\u00e9volutivit\u00e9 des services.\nUtiliser les services AWS tels que Amazon S3, AWS Lambda, Elastic Kubernetes Service (EKS), Elastic Container Service (ECS) et Elastic Compute Cloud (EC2) pour le stockage, le traitement et le calcul des donn\u00e9es en temps r\u00e9el.\nSuivre les meilleures pratiques pour une utilisation efficace du cloud, en assurant la gestion des co\u00fbts, la s\u00e9curit\u00e9 des donn\u00e9es et la disponibilit\u00e9 des services.\nCollaborer avec l\u2019\u00e9quipe de d\u00e9veloppement logiciel et la gestion de projets pour assurer un flux de d\u00e9veloppement fluide et une livraison efficace des fonctionnalit\u00e9s.\nBon \u00e0 savoir :\nCDI / ASAP / Toulouse\nProfil recherch\u00e9:\nNous recherchons un candidat dipl\u00f4m\u00e9 d'une grande \u00e9cole d'Ing\u00e9nieur avec une premi\u00e8re exp\u00e9rience.\nComp\u00e9tences n\u00e9cessaires :\nExp\u00e9rience significative dans un environnement industriel en mode DevOps, avec des outils tels que CICD, gitlab, Jenkins, Sonar, Nexus, XLdeploy, Camunda, etc.\nMa\u00eetrise des langages de programmation tels que Python, Java et expertise dans l\u2019\u00e9criture et l\u2019optimisation du code SQL\nMa\u00eetrise du fran\u00e7ais et bonne maitrise de l\u2019anglais.\nCapacit\u00e9 \u00e0 travailler en \u00e9quipe et esprit d\u2019\u00e9quipe.\nLe processus de recrutement se d\u00e9roule en 3 entretiens :\nPrise de contact\n1er entretien : Pr\u00e9sentation et projet du candidat + pr\u00e9sentation MP DATA\n2\u00e8me entretien : Entretien de qualification technique\n3\u00e8me entretien : Rencontre avec les \u00e9quipes dans les locaux MP DATA + Proposition de collaboration\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "Java",
                "R"
            ],
            "DataBase": [
                "SQL"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [
                "Flink"
            ],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [
                "AWS"
            ],
            "DevTools": [
                "Git",
                "Jenkins"
            ],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [
                "Kubernetes"
            ],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [
                "Kubernetes"
            ],
            "Collaboration": [],
            "Other": [
                "DevOps",
                "Cloud"
            ],
            "FrSoftSkills": [
                "Collaboration"
            ],
            "EnSoftSkils": [
                "Collaboration"
            ]
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [
                "CDI"
            ],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "title": "Data Engineer (H/F)",
        "company": "Technology & Strategy",
        "location": "Lyon, Auvergne-Rh\u00f4ne-Alpes, France",
        "link": "https://fr.linkedin.com/jobs/view/data-engineer-h-f-at-technology-strategy-3881556102?position=30&pageNum=0&refId=TDTc9UZJy78L%2BED7EV%2BMrg%3D%3D&trackingId=6Bqksdqvzmsz9cNBZny65A%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "D\u00e9couvrez Novencia\n:\nExpert en Data et Intelligence Artificielle, nous aidons nos clients \u00e0 exploiter et \u00e0 valoriser leurs donn\u00e9es sous toutes ses formes en les accompagnant sur des projets de Data Analyse, Data Gourvernance, Data Architecture, Data Science, et Data Engineering\u2026\nVous avez une solide exp\u00e9rience de minimum 2 ans dans l'ing\u00e9nierie des donn\u00e9es et vous \u00eates \u00e0 la recherche de nouveaux d\u00e9fis ? Bouclez votre ceinture, la suite est pour vous !\nType de contrat : CDI\nLieu : Lyon\nEn qualit\u00e9 de Data Engineer (H/F), votre r\u00f4le sera :\nConcevoir et proposer les solutions de d\u00e9veloppement r\u00e9pondant aux besoins fonctionnels et techniques des projets big data.\nTu participes \u00e0 la conception de solutions permettant le traitement de volumes importants de pipelines donn\u00e9es.\nR\u00e9aliser ces solutions par l\u2019\u00e9criture de code, en respectant les m\u00e9thodes et proc\u00e9dures qualit\u00e9s d\u00e9finies au sein du d\u00e9partement Technique.\nMise \u00e0 disposition s\u00e9curis\u00e9 et lisible de la data.\nS\u2019assurer de la conformit\u00e9 fonctionnelle et technique de ces r\u00e9alisations en effectuant les tests automatis\u00e9s n\u00e9cessaire et la mise en place de monitoring (syst\u00e8me et qualit\u00e9).\nAssurer la maintenance des applicatifs / plateforme data science\nAssurer une veille technologique\nVous disposez des comp\u00e9tences suivantes :\nMaitrise des plateformes Cloud (AWS, GCP ou Azure), de Scala et de SQL.\nUn.e touche \u00e0 tout : poss\u00e9dant des comp\u00e9tences en langage Python/Spark, de bonnes capacit\u00e9s de mod\u00e9lisation, une forte app\u00e9tence pour le Big Data\nFin.e connaisseur.euse : Data Engineer convaincu, tr\u00e8s peu de secrets pour les clusters et pour les calculs parall\u00e8les\nExplorateur.trice : d\u00e9couvre de nouvelles technos gr\u00e2ce \u00e0 une veille r\u00e9guli\u00e8re\nD\u00e9brouillard.e : rel\u00e8ve de nouveaux d\u00e9fis\nNotre objectif commun est de co-construire votre carri\u00e8re en fonction de vos aspirations et de vos comp\u00e9tences.\nContactez-moi en message priv\u00e9 ou par mail \u00e0 s.ziki@technologyandstrategy.com !\nLet's make it possible #together\n*Nos postes sont ouverts aux personnes b\u00e9n\u00e9ficiant d\u2019une Reconnaissance de la Qualit\u00e9 de Travailleur Handicap\u00e9 (RQTH). T&S Groupe encourage la diversit\u00e9 et l\u2019\u00e9galit\u00e9 sur le lieu de travail. Tous les candidats qualifi\u00e9s H/F/* sont pris en consid\u00e9ration pour un emploi sur un m\u00eame pied d'\u00e9galit\u00e9.\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "Scala",
                "R",
                "Go"
            ],
            "DataBase": [
                "SQL"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [
                "Spark"
            ],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [
                "AWS",
                "Azure"
            ],
            "DevTools": [],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [
                "Big Data",
                "Cloud"
            ],
            "FrSoftSkills": [],
            "EnSoftSkils": []
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [
                "CDI"
            ],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s",
                "2",
                "2",
                "2"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "title": "Stage - Data Engineer - ML (H/F)",
        "company": "Withings",
        "location": "Issy-les-Moulineaux, \u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/stage-data-engineer-ml-h-f-at-withings-3613476264?position=31&pageNum=0&refId=TDTc9UZJy78L%2BED7EV%2BMrg%3D%3D&trackingId=KmvpsR%2BWm3jN8lzOCziUBA%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Chez Withings, nous d\u00e9veloppons des appareils de sant\u00e9 connect\u00e9e : nos balances connect\u00e9es, montres hybrides, tensiom\u00e8tres, moniteurs de sommeil et tous les dispositifs de notre gamme sont aujourd'hui utilis\u00e9s par des millions d'utilisateurs. Notre objectif est de permettre la pr\u00e9vention, le d\u00e9pistage et l'accompagnement d'un certain nombre de maladies chroniques via des produits et des services innovants afin de r\u00e9volutionner la mani\u00e8re dont on prend soin de notre sant\u00e9.\nAu sein de l'\u00e9quipe Machine Learning, nous d\u00e9veloppons des algorithmes pour extraire des informations physiologiques et m\u00e9dicales pour nos utilisateurs tels que le SPO2, la fr\u00e9quence cardiaque, la d\u00e9tection de diverses pathologies comme la fibrillation atriale, l'apn\u00e9e du sommeil...\nInt\u00e9gr\u00e9.e au sein de l'\u00e9quipe Machine Learning, tu auras une ou plusieurs des responsabilit\u00e9s suivantes :\nD\u00e9velopper un outil de monitoring de la dette technique, des mauvaises pratiques de code, des failles de s\u00e9curit\u00e9 ;\nConstruire des dashboards de visualisation ;\nConstruire un syst\u00e8me d'alerte pour notifier les contributeurs d'\u00e9ventuels probl\u00e8mes ;\nD\u00e9velopper des outils permettant de corriger les \u00e9ventuels probl\u00e8mes de fa\u00e7on automatis\u00e9e ;\nRequirements\n\u00c0 la recherche d'un stage d'une dur\u00e9e de 3 \u00e0 6 mois ;\nPr\u00e9paration d'un Master en \u00e9cole d'ing\u00e9nieur ou \u00e9quivalent / ann\u00e9e de c\u00e9sure possible ;\nMa\u00eetrise de Python ;\nMa\u00eetrise de Debian ou de Ubuntu, de Shell et de l'environnement Linux ;\nPremi\u00e8re exp\u00e9rience sur du d\u00e9veloppement logiciel ;\nCulture DevOps (omnipr\u00e9sence du monitoring, automatisation des t\u00e2ches, ...)\nCompr\u00e9hension de la culture et des besoins des diff\u00e9rents membres de l'\u00e9quipe ;\nRigueur, autonomie, prise d'initiative, curiosit\u00e9\nBenefits\nRejoindre l'aventure Withings, c'est :\nInt\u00e9grer un des pionniers et leaders mondiaux de la sant\u00e9 connect\u00e9e, plusieurs fois prim\u00e9 au Consumer Electronic Show\nContribuer \u00e0 des projets innovants et ambitieux pour la sant\u00e9 de demain dans un environnement agile et en constante \u00e9volution\nInt\u00e9grer une entreprise internationale, membre de la FrenchTech 120, dont les \u00e9quipes sont bas\u00e9es \u00e0 Issy-les-Moulineaux, Boston, Hong-Kong et Shenzhen\nParticiper \u00e0 l'am\u00e9lioration continue de nos produits et services en les b\u00eata-testant avant leur sortie, notamment lors de nos nombreuses sessions sportives entre coll\u00e8gues\nParticiper \u00e0 la Withings Med Academy en assistant \u00e0 des conf\u00e9rences de professionnels de sant\u00e9 afin de renforcer ses connaissances dans le domaine m\u00e9dical\nCollaborer avec des coll\u00e8gues passionn\u00e9s et c\u00e9l\u00e9brer ensemble chacune de nos r\u00e9ussites !\nToutes les candidatures re\u00e7ues sont \u00e9tudi\u00e9es ind\u00e9pendamment de l'origine ethnique, des croyances, de la religion, du genre, de l'orientation sexuelle ou de la sant\u00e9 des candidats. Withings aspire \u00e0 offrir et garantir l'\u00e9galit\u00e9 des chances aux candidats et seules les personnes habilit\u00e9es (RH et Management) auront acc\u00e8s aux informations concernant votre candidature.\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "R",
                "Go"
            ],
            "DataBase": [],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [],
            "DevTools": [],
            "Os": [
                "Linux"
            ],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [
                "DevOps",
                "Machine Learning"
            ],
            "FrSoftSkills": [],
            "EnSoftSkils": [
                "Initiative"
            ]
        },
        "details": {
            "JobDetail": [
                "Hybride"
            ],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "title": "Data Engineer",
        "company": "Thales",
        "location": "Ollioules, Provence-Alpes-C\u00f4te d'Azur, France",
        "link": "https://fr.linkedin.com/jobs/view/data-engineer-at-thales-3902424527?position=32&pageNum=0&refId=TDTc9UZJy78L%2BED7EV%2BMrg%3D%3D&trackingId=Fv5mtAMxP79Qn3C6UTqogg%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "QUI SOMMES-NOUS ?\nThales est un leader mondial des hautes technologies comptant plus de 81 000 collaborateurs pr\u00e9sents sur tous les continents. Le Groupe investit dans les innovations du num\u00e9rique et de la \u00ab deep tech \u00bb \u2013 big data, intelligence artificielle, connectivit\u00e9, cybers\u00e9curit\u00e9 et quantique \u2013 pour construire un avenir de confiance, essentiel au d\u00e9veloppement de nos soci\u00e9t\u00e9s, en pla\u00e7ant l\u2019humain au c\u0153ur des d\u00e9cisions.\nThales propose des solutions, services et produits qui aident ses clients \u2013 entreprises, organisations, Etats \u2013 dans cinq grands march\u00e9s vitaux pour le fonctionnement de nos soci\u00e9t\u00e9s : identit\u00e9 et s\u00e9curit\u00e9 num\u00e9riques, d\u00e9fense, a\u00e9ronautique, espace, et transport.\nQUI ETES-VOUS ?\nDipl\u00f4m\u00e9 d\u2019un Bac+5 en \u00e9cole d\u2019ing\u00e9nieur ou \u00e9quivalent universitaire avec une sp\u00e9cialisation en informatique, vous avez a\nu moins 3 ans d'exp\u00e9rience\ndans les technologies Big Data.\nPassionn\u00e9 par le\nsecteur de la D\u00e9fense et du Naval.\nCE QUE NOUS POUVONS ACCOMPLIR ENSEMBLE :\nEn tant que\nData Engineer,\nvous jouerez un r\u00f4le cl\u00e9 dans la conception, le d\u00e9veloppement et la maintenance de notre infrastructure de donn\u00e9es, ainsi que dans la transformation et la gestion des flux de donn\u00e9es.\nVOS MISSIONS :\n\u2022 Concevoir, d\u00e9velopper et d\u00e9ployer des solutions Big Data en utilisant les technologies\nHadoop, Spark, Scala\n.\n\u2022 Mettre en place des pipelines de donn\u00e9es performants pour l'ingestion, le traitement et le stockage des donn\u00e9es massives.\n\u2022 Collaborer \u00e9troitement avec les \u00e9quipes m\u00e9tier pour comprendre leurs besoins en mati\u00e8re d'analyse de donn\u00e9es et proposer des solutions adapt\u00e9es.\n\u2022 Optimiser les performances des clusters Hadoop pour garantir une exploitation efficace des donn\u00e9es.\n\u2022 Assurer la qualit\u00e9 et la fiabilit\u00e9 des donn\u00e9es trait\u00e9es, en mettant en place des processus de validation et de nettoyage.\n\u2022 Identifier et r\u00e9soudre les probl\u00e8mes li\u00e9s \u00e0 l'infrastructure Big Data et proposer des am\u00e9liorations.\nInnovation, passion, ambition : rejoignez Thales et cr\u00e9ez le monde de demain, d\u00e8s aujourd\u2019hui.\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Scala",
                "R"
            ],
            "DataBase": [],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [
                "Hadoop",
                "Spark"
            ],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [],
            "DevTools": [],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [
                "Big Data"
            ],
            "FrSoftSkills": [
                "Organisation"
            ],
            "EnSoftSkils": []
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [],
            "Salary": [],
            "Level": [
                "Bac+5"
            ],
            "Experience": [
                "a",
                "n",
                "s",
                "3",
                "3",
                "3"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "title": "Data Engineer - Nantes",
        "company": "Capgemini",
        "location": "Nantes, Pays de la Loire, France",
        "link": "https://fr.linkedin.com/jobs/view/data-engineer-nantes-at-capgemini-3803998213?position=33&pageNum=0&refId=TDTc9UZJy78L%2BED7EV%2BMrg%3D%3D&trackingId=AYRkKdnEYMdhl33uV621Ow%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Capgemini\nChoisir Capgemini, c'est choisir une entreprise o\u00f9 vous serez en mesure de fa\u00e7onner votre carri\u00e8re selon vos aspirations, o\u00f9 vous serez soutenu et inspir\u00e9 par une communaut\u00e9 d\u2019experts dans le monde entier, o\u00f9 vous pourrez r\u00e9\u00e9crire votre futur. Rejoignez-nous pour red\u00e9finir les limites de ce qui est possible, contribuer \u00e0 lib\u00e9rer la valeur de la technologie pour les plus grandes organisations et participez \u00e0 la construction d\u2019un monde plus durable et inclusif.\nVos missions :\nInt\u00e9gr\u00e9(e) au sein d'une \u00e9quipe projets intervenant pour des clients dans des secteurs d'activit\u00e9s vari\u00e9es, vous serez notamment en charge des missions suivantes :\nConcevoir et mettre en oeuvre des strat\u00e9gies s\u00e9curis\u00e9es d'acquisition et d'int\u00e9gration de donn\u00e9es,\nConfigurer des r\u00e9f\u00e9rentiels de donn\u00e9es \u00e0 la pointe de la technologie dans des environnements distribu\u00e9s, majoritairement dans le cloud (Google Cloud Platform, Azure Databricks, AWS) et/ou en environnement Hadoop (distribution MapR, Cloudera, Hortonworks),\nConstruire des pipelines de donn\u00e9es pour collecter, transformer et traiter des donn\u00e9es en collaboration avec des scientifiques de donn\u00e9es afin de r\u00e9pondre aux exigences de la mod\u00e9lisation de donn\u00e9es d'analyse avanc\u00e9e.\nVotre profil :\nDipl\u00f4me d\u2019ing\u00e9nieur ou \u00e9quivalent universitaire\nMinimum 3 ans d'exp\u00e9rience\nAnglais courant\nMa\u00eetrise des langages Java, Scala ou Python et expertise sur les framework Spark et/ou Hadoop.\nExpertise sur les services Cloud Data Platform suivants : Azure Data Lake, Azure synapse, Azure Data Factory, Azure Data Explorer, GCP, AWS, Snowflake, Databricks\u2026\n3 raisons de nous rejoindre :\nQualit\u00e9 de vie au travail : accord de t\u00e9l\u00e9travail en France et \u00e0 l\u2019international, accord sur l\u2019\u00e9galit\u00e9\nprofessionnelle, la parentalit\u00e9, l\u2019\u00e9quilibre des temps et la mobilit\u00e9 durable.\nApprentissage en continu : certifications et formations en libre acc\u00e8s, accompagnement sur mesure avec votre carreer manager, parcours d\u2019int\u00e9gration sur 9 mois.\nAvantages groupe & CSE : plan actionnariat, activit\u00e9s \u00e0 tarifs pr\u00e9f\u00e9rentiels, remboursement partiel\nvacances, remboursement de votre abonnement sportif ou culturel.\nNos engagements et priorit\u00e9s :\nLe groupe Capgemini encourage une culture inclusive dans un cadre multiculturel et handi-accueillant. En nous rejoignant, vous int\u00e9grez un collectif qui valorise la diversit\u00e9, d\u00e9veloppe le potentiel de ses talents, s\u2019engage dans des initiatives solidaires avec ses partenaires, et se mobilise pour r\u00e9duire son impact environnemental sur tous ses sites et aupr\u00e8s de ses clients.\nCapgemini\nCapgemini est un leader mondial, responsable et multiculturel, regroupant pr\u00e8s de 350 000 personnes dans plus de 50 pays. Fort de 55 ans d\u2019exp\u00e9rience, nous sommes un partenaire strat\u00e9gique des entreprises pour la transformation de leurs activit\u00e9s en tirant profit de toute la puissance de la technologie et des innovations dans les domaines en perp\u00e9tuelle \u00e9volution tels que le cloud, la data, l\u2019Intelligence Artificielle, la connectivit\u00e9, les logiciels, l\u2019ing\u00e9nierie digitale ou les plateformes.\nGet The Future You Want* | www.capgemini.com/fr-fr\n*Capgemini, le futur que vous voulez\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "Java",
                "Scala",
                "R",
                "Go"
            ],
            "DataBase": [],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [
                "Hadoop",
                "Spark",
                "Databricks"
            ],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [
                "AWS",
                "Azure",
                "Google Cloud Platform"
            ],
            "DevTools": [
                "Git"
            ],
            "Os": [],
            "DBMS": [
                "Snowflake",
                "Snowflake"
            ],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [
                "Cloud"
            ],
            "FrSoftSkills": [
                "Collaboration",
                "Organisation"
            ],
            "EnSoftSkils": [
                "Collaboration",
                "Initiative"
            ]
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s",
                "3",
                "3",
                "3"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "title": "Big Data engineer \u2013 Ing\u00e9nieur des donn\u00e9es massives (H/F)",
        "company": "DGSE - Direction G\u00e9n\u00e9rale de la S\u00e9curit\u00e9 Ext\u00e9rieure",
        "location": "Paris, \u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/big-data-engineer-%E2%80%93-ing%C3%A9nieur-des-donn%C3%A9es-massives-h-f-at-dgse-direction-g%C3%A9n%C3%A9rale-de-la-s%C3%A9curit%C3%A9-ext%C3%A9rieure-3778473628?position=34&pageNum=0&refId=TDTc9UZJy78L%2BED7EV%2BMrg%3D%3D&trackingId=C68Ytx6N93azegb462EtDw%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Introduction\nLa Direction G\u00e9n\u00e9rale de la S\u00e9curit\u00e9 Ext\u00e9rieure, DGSE, recrute Big Data engineer \u2013 Ing\u00e9nieur des donn\u00e9es massives (H/F).\nLe poste est situ\u00e9 \u00e0 Paris.\nLa nationalit\u00e9 fran\u00e7aise est obligatoire.\nDomaine m\u00e9tier\nSciences et Technologies\nVotre environnement de travail\nLe flux de donn\u00e9es trait\u00e9es par la DGSE est \u00e9quivalent \u00e0 celui des GAFAM. Ces donn\u00e9es sont au centre du travail des analystes de renseignement, qui doivent pouvoir compter sur des syst\u00e8mes leur permettant de rechercher, croiser, traiter ces donn\u00e9es, en temps r\u00e9el ou en batch. Dans ce contexte, la DGSE cherche \u00e0 renforcer ses \u00e9quipes de traitement de la donn\u00e9e massive.\nAu sein d'un service centr\u00e9 sur le stockage, l'exploitation et la valorisation des donn\u00e9es, nous vous proposons d'int\u00e9grer les \u00e9quipes en charge des plateformes de stockage ou des traitements temps r\u00e9el des donn\u00e9es. Ces \u00e9quipes pluridisciplinaires d\u00e9veloppent et maintiennent de bout en bout diverses plateformes reposant sur les technologies Kafka, Yarn, Hadoop, HBase ou encore Elasticsearch. Plus sp\u00e9cifiquement, l\u2019\u00e9quipe Stockage administre des entrep\u00f4ts Big Data ainsi que des couches d\u2019acc\u00e8s \u00e0 leurs donn\u00e9es. L\u2019\u00e9quipe Temps r\u00e9el con\u00e7oit des algorithmes r\u00e9pondant \u00e0 des besoins de temps de r\u00e9action tr\u00e8s courts (lev\u00e9e d\u2019alertes, enrichissement \u00e0 la vol\u00e9e, r\u00e9ponse \u00e0 des besoins op\u00e9rationnels).\nEn nous rejoignant, vous d\u00e9couvrirez :\nun environnement unique, qu'aucune autre structure ne peut vous proposer,\nun m\u00e9tier proche du renseignement et de l'op\u00e9rationnel,\nune action sur l'int\u00e9gralit\u00e9 de la cha\u00eene, du d\u00e9veloppement au d\u00e9ploiement en production,\nun minimum de 48 jours de cong\u00e9s par an,\nune ambiance propice \u00e0 l\u2019\u00e9panouissement professionnel.\nVos missions\nLes missions des \u00e9quipes auxquelles vous serez amen\u00e9s \u00e0 contribuer seront d\u00e9termin\u00e9es en fonction de votre exp\u00e9rience et de vos app\u00e9tences.\nVous serez en charge de plusieurs activit\u00e9s parmi les suivantes :\nconcevoir, impl\u00e9menter et optimiser des algorithmes de traitement de donn\u00e9es distribu\u00e9s (Scala, Spark, Java),\ngarantir le bon fonctionnement, la disponibilit\u00e9 et la performance des plateformes de traitement,\nparticiper \u00e0 l\u2019\u00e9volution de l\u2019architecture, en int\u00e9grant de nouveaux composants (frameworks, biblioth\u00e8ques, \u2026) permettant de mieux r\u00e9pondre aux besoins,\nassurer une veille technologique constante pour rester au plus haut niveau et garantir une ad\u00e9quation des clusters existants avec l\u2019\u00e9tat de l\u2019art du domaine,\ncontribuer \u00e0 l'am\u00e9lioration continue de l'\u00e9quipe,\ninteragir avec l\u2019\u00e9quipe SRE/Devops pour am\u00e9liorer la fiabilit\u00e9 des architectures, l\u2019automatisation des d\u00e9ploiements et l'observabilit\u00e9 des syst\u00e8mes mis en \u0153uvre.\nVotre profil\nVous \u00eates titulaire d\u2019un dipl\u00f4me en informatique, niveau master ou \u00e9cole d\u2019ing\u00e9nieur, ou pouvez d\u00e9montrer une exp\u00e9rience \u00e9quivalente.\nVous devez poss\u00e9der les comp\u00e9tences et qualit\u00e9s suivantes :\nbonnes connaissances fondamentales logicielles (structures de donn\u00e9es, algorithmique, architecture),\nma\u00eetrise des langages Scala, Java ou python, vous n'avez pas peur de monter en comp\u00e9tences sur ceux que vous ne ma\u00eetrisez pas,\nadepte de l'int\u00e9gration continue, vous \u00eates familier de Gitlab CI, Github Actions ou Jenkins,\nfamilier avec les bonnes pratiques de d\u00e9veloppement collaboratif (usage de git, pratique de relecture de code).\nEn bonus :\npremi\u00e8re exp\u00e9rience avec un framework de traitement en streaming (SparkStreaming, KStream, Storm, Flink, ...),\nconvaincu de l'importance de l'observabilit\u00e9 des syst\u00e8mes qui regroupe m\u00e9trologie, logging et tracing, vous avez d\u00e9j\u00e0 mis en place une stack de ce type (Prometheus, Telegraph, OpenTelemetry, Jaeger, ELK, \u2026),\nfamilier avec un outil de gestion de configuration (Ansible, Puppet, ...),\nexp\u00e9rience sur les clusters Kafka, Hadoop, HBase ou Elasticsearch de plusieurs n\u0153uds.\nLes plus de l\u2019offre\nContexte d\u2019activit\u00e9s unique\nDiversit\u00e9 des projets\nTechnologies \u00e0 la pointe\nContact\nEnvoyez-nous votre candidature \u00e0 l\u2019adresse :\ndgse-macandidature.cer.fct@intradef.gouv.fr\nPlus d\u2019information sur www.dgse.gouv.fr > Nous rejoindre.\nRESTEZ DISCRET SUR VOTRE CANDIDATURE A LA DGSE\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "Java",
                "Scala",
                "R",
                "Go"
            ],
            "DataBase": [
                "HBase",
                "Elasticsearch"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [
                "Hadoop",
                "Spark",
                "Flink"
            ],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [],
            "DevTools": [
                "Git",
                "Jenkins"
            ],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [
                "HBase"
            ],
            "Automation": [
                "Ansible",
                "Puppet"
            ],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [
                "DevOps",
                "Big Data"
            ],
            "FrSoftSkills": [],
            "EnSoftSkils": []
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "title": "Data Engineer (F/H)",
        "company": "Aubay",
        "location": "\u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/data-engineer-f-h-at-aubay-3573871076?position=35&pageNum=0&refId=TDTc9UZJy78L%2BED7EV%2BMrg%3D%3D&trackingId=h3dJGitbn9AqvYtDTfW1hQ%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Passionn\u00e9 par la Data, tu souhaites rejoindre une communaut\u00e9 d\u2019experts dans le domaine afin de d\u00e9velopper tes comp\u00e9tences en Data Engineering. Aubay renforce ses \u00e9quipes Data et recherche des Data Engineers pour int\u00e9grer des dispositifs de projets pointus et vari\u00e9s.\nTon quotidien en tant que Data Engineer chez Aubay, :\nD\u00e9finition de la strat\u00e9gie de stockage et mise en \u0153uvre des technologie appropri\u00e9es (base de donn\u00e9es SQL, NoSQL, stockage distribu\u00e9,\u2026)\nIngestion des donn\u00e9es (structur\u00e9es, semi-structur\u00e9es ou non-structur\u00e9es) selon diff\u00e9rentes fr\u00e9quences : batch, micro-batch ou temps r\u00e9el\nConception et mise en \u0153uvre de pipelines de donn\u00e9es afin de fournir des donn\u00e9es pr\u00eates \u00e0 l\u2019emploi aux consommateurs : uniformisation, mise en qualit\u00e9, enrichissement, calcul d\u2019indicateurs,\u2026\nConception et d\u00e9veloppement d\u2019API pour exposer les donn\u00e9es aupr\u00e8s d\u2019applications tierces\nAppui aux Data Scientists pour industrialiser et optimiser les algorithmes de Machine Learning\nPr\u00e9paration et animation d\u2019ateliers de travail avec des interlocuteurs vari\u00e9s : recueil/approfondissement des besoins m\u00e9tiers, avancement/restitution des travaux, transfert de comp\u00e9tences,\u2026\nTon profil :\nTu dispose d\u2019une formation niveau BAC+5 (Master 2 ou \u00e9cole d\u2019ing\u00e9nieur) sp\u00e9cialis\u00e9e en informatique\nTu as d\u00e9j\u00e0 une premi\u00e8re exp\u00e9rience significative (a minima 2 ans) en Data Engineering sur des technologies Big Data\nLes technologies telles que Hadoop, Spark ou Kafka sont tes technologies de pr\u00e9dilection\nLa programmation n\u2019a plus de secret pour toi et tu maitrise parfaitement un ou plusieurs langages de programmation suivants : Java, Scala et Python\nTu ma\u00eetrises les tenants et aboutissants de la philosophie DevOps et des outils orient\u00e9s CI/CD\nTu es soucieux de la qualit\u00e9 et de la performance de tes d\u00e9veloppements et tu t'int\u00e9resse \u00e0 l\u2019innovation frugale\nTu es un expert technique dans ton domaine sans pour autant oublier l\u2019importance d\u2019une communication orale et \u00e9crite de qualit\u00e9 et adapt\u00e9e \u00e0 chacun de tes interlocuteurs\nTu travaille au quotidien en mode agile et tu en maitrise les fondements\nCe qui nous caract\u00e9rise :\nDes missions et projets dans le domaine du Data Engineering en nombre et dans des secteurs vari\u00e9s (Banque, Assurance, Telecom, Industrie,\u2026) qui permettent \u00e0 nos collaborateurs de monter en comp\u00e9tences et de devenir des experts Data reconnus\nDe l\u2019apprentissage en continu avec des formations et des certifications sur les technologies Data d\u2019aujourd\u2019hui et de demain\nDes experts Data mobilisables pour accompagner et soutenir techniquement les collaborateurs sur leurs projets\nDes communaut\u00e9s de savoir-faire Data proposant de mani\u00e8re r\u00e9guli\u00e8re aux collaborateurs d\u2019Aubay du contenu et des \u00e9v\u00e8nements de partage (webinar, meetup/afterwork, BBL,\u2026) sur les th\u00e9matiques suivantes : Data Engineering, Data Viz, Data Science/IA, Data Platform & Architecture,\u2026\nAubay encourage la diversit\u00e9 sous toutes ses formes et garantit l'\u00e9galit\u00e9 des chances \u00e0 tous les candidats. Tous nos postes sont ouverts aux personnes en situation de handicap et nous proposons tous les am\u00e9nagements n\u00e9cessaires.\nTa carri\u00e8re chez Aubay :\nTu auras la possibilit\u00e9 de d\u00e9velopper et certifier tes comp\u00e9tences sur les derni\u00e8res technologies Data avec un focus fort sur les plateformes Data Cloud telles qu\u2019Azure Synapse Analytics, Google Cloud Platform, Snowflake et Databricks\nTu pourras rejoindre la BU d\u2019excellence Data et \u00e9voluer au sein d\u2019un environnement humain et professionnel de haut niveau. Tu profiteras d\u2019un management sur-mesure pour t'accompagner dans ta trajectoire de carri\u00e8re\nAu sein de la BU d\u2019excellence, de multiples perspectives s\u2019offriront \u00e0 toi :\nR\u00f4le de \u00ab Lead \u00bb : Vous pourrez gagner en responsabilit\u00e9 sur le plan technologique et devenir un r\u00e9f\u00e9rent aupr\u00e8s de nos clients et des collaborateurs de la communaut\u00e9 Data Engineering\nR\u00f4le de \u00ab Champion \u00bb : Vous repr\u00e9senterez Aubay aupr\u00e8s d\u2019un ou plusieurs de nos partenaires \u00e9diteurs strat\u00e9giques et vous participerez activement \u00e0 l\u2019animation de la relation sur le plan technologique\nR\u00f4le de \u00ab Head \u00bb : Vous pourrez prendre la responsabilit\u00e9 du savoir-faire Data Engineering et de ses offres et en assurer le d\u00e9veloppement au sens large (d\u00e9veloppement business, recrutement, management de collaborateurs, d\u00e9finition de la strat\u00e9gie et animation de la communaut\u00e9 au sein du groupe Aubay,\u2026)\nBesoin d\u2019en savoir plus sur le processus de recrutement ?\nUn \u00e9change macro au niveau RH avec Doriane\nUn entretien technique avec Marius ou Peter, deux de nos r\u00e9f\u00e9rents techniques\nUn \u00e9change manag\u00e9rial avec le Directeur de la BU Modern BI & Data\nA savoir que l\u2019ordre des \u00e9tapes peut varier selon tes envies (ex : \u00e9change manag\u00e9rial avec l\u2019\u00e9change technique)\nAubay encourage la diversit\u00e9 sous toutes ses formes et garantit l'\u00e9galit\u00e9 des chances \u00e0 tous les candidats. Tous nos postes sont ouverts aux personnes en situation de handicap et nous proposons tous les am\u00e9nagements n\u00e9cessaires.\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "Java",
                "Scala",
                "R",
                "Go"
            ],
            "DataBase": [
                "SQL",
                "NoSQL"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [
                "Hadoop",
                "Spark",
                "Databricks"
            ],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [
                "Azure",
                "Google Cloud Platform"
            ],
            "DevTools": [],
            "Os": [],
            "DBMS": [
                "Snowflake",
                "Snowflake"
            ],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [
                "DevOps",
                "Big Data",
                "Machine Learning",
                "Cloud",
                "CI/CD"
            ],
            "FrSoftSkills": [
                "Communication"
            ],
            "EnSoftSkils": [
                "Communication"
            ]
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [],
            "Salary": [],
            "Level": [
                "Bac+5"
            ],
            "Experience": [
                "a",
                "n",
                "s",
                "2",
                "2",
                "2"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "title": "Data engineer - F / H",
        "company": "United Robotics Group",
        "location": "Paris, \u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/data-engineer-f-h-at-united-robotics-group-3891680780?position=36&pageNum=0&refId=TDTc9UZJy78L%2BED7EV%2BMrg%3D%3D&trackingId=nFxE35kmFCphA0TLbxr9wg%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Bienvenue chez\nAldebaran\n, leader europ\u00e9en de la robotique\nau sein du groupe\nUnited Robotics Group\n.\nNous concevons et industrialisons des robots innovants avec une vision soci\u00e9tale ambitieuse pour fa\u00e7onner un monde plus humain. Depuis 2005, nous sommes \u00e0 l'avant-garde de l'interaction homme-robot avec des produits embl\u00e9matiques tels que NAO et Pepper.\nNotre dernier-n\u00e9,\nPlato\n,\nincarne notre engagement envers la technologie de pointe et la s\u00e9curit\u00e9,\nfabriqu\u00e9 en France avec des composants europ\u00e9ens.\nRejoignez nos \u00e9quipes multiculturelles et dynamiques pour \u00eatre au c\u0153ur de la r\u00e9volution de la robotique.\nSi vous \u00eates passionn\u00e9.e par la robotique et l'intelligence artificielle, et que vous souhaitez contribuer \u00e0 fa\u00e7onner l'avenir, nous vous offrons une exp\u00e9rience enrichissante et stimulante.\nEn tant que membre de notre \u00e9quipe, vous b\u00e9n\u00e9ficierez d'une culture d'entreprise ax\u00e9e sur le sens de ce que nous faisons et valorisant la responsabilit\u00e9 sociale et environnementale.\nChez Aldebaran, nous valorisons l'innovation, la diversit\u00e9 et l'\u00e9galit\u00e9 et encourageons chacun.e \u00e0 \u00eatre ouvert.e, authentique, courageux.se, responsable et engag\u00e9.e.\nFinalit\u00e9 du poste\nAu sein de l'\u00e9quipe Cloud-Online Services, le Data engineer int\u00e9grera l'\u00e9quipe Data, responsable du d\u00e9veloppement des produits destin\u00e9s \u00e0 la collecte, aux process et \u00e0 l'exploitation des donn\u00e9es de nos robots.\nIl aura pour r\u00f4le de d\u00e9finir et d'impl\u00e9menter des services data, sur une infrastructure Cloud AWS, supportant des services en ligne qui g\u00e8rent les robots du groupe.\nMissions principales\nLe Data engineer aura pour responsabilit\u00e9s de :\n\u00e9valuer les choix d'architecture et de solutions techniques lors de la mise en place de PoC,\nconcevoir et d\u00e9velopper des services Data en respectant la sp\u00e9cification fonctionnelle et la m\u00e9thodologie agile,\nagr\u00e9ger et stocker de grandes quantit\u00e9s de donn\u00e9es,\nmettre en place des solutions de data processing,\nint\u00e9grer/d\u00e9velopper des outils de visualisation de donn\u00e9es et analyser les KPI,\nd\u00e9velopper, tester, s\u00e9lectionner et mettre en production des algorithmes qui permettent de r\u00e9pondre aux besoins,\nr\u00e9aliser des analyses de donn\u00e9es,\nmettre en place des tests de charge et fonctionnels pour les solutions Data,\ninvestiguer et corriger les bugs remont\u00e9s par les utilisateurs,\ncontribuer \u00e0 la mise en place de l'infrastructure et outil de d\u00e9ploiement (CI/CD)\nRejoignez-nous pour faire partie d'une aventure passionnante o\u00f9 Pepper, NAO, Plato et leurs futurs successeurs attendent votre contribution pour repousser les limites de la technologie robotique !\nRequirements\nPour la bonne ex\u00e9cution des missions confi\u00e9es, vous t\u00e9moignez d'au moins 6 ans d'exp\u00e9rience en tant que d\u00e9veloppeur sur des projets data en Cloud en Python et Spark et avec comme Cloud provider AWS.\nComp\u00e9tences demand\u00e9es :\nBonne compr\u00e9hension des technologies d'infrastructure et de d\u00e9ploiement,\nComp\u00e9tences techniques sur les services AWS : IOT core , Glue, lambda, Kinesis, S3, RDS,\nBonne compr\u00e9hension technique dans la mise en place et l'automatisation de tests de charge et fonctionnels,\nBonne maitrise d'outils BI ou de dashboarding (POWER BI, TABLEAU, QUICKSIGHT)\nBonne connaissance et une exp\u00e9rience pratique de Scrum\\Scrumban et des m\u00e9thodes agiles,\nUne certification AWS sera appr\u00e9ci\u00e9e,\nUn niveau de fran\u00e7ais et d'anglais courant est indispensable,\nDes exp\u00e9riences dans des environnements fortement internationaux sont un plus\nBenefits\nNos principaux avantages :\nUne culture du bien-\u00eatre en entreprise qui a fait ses preuves (budget c\u00e9l\u00e9bration et moments de convivialit\u00e9 par \u00e9quipes et directions, restauration collective de qualit\u00e9, environnement de travail agr\u00e9able)\nUn engagement fort en mati\u00e8re de responsabilit\u00e9 sociale et environnementale (promotion de l'\u00e9galit\u00e9 professionnelle, performance de notre plan diversit\u00e9 et inclusion, r\u00e9f\u00e9rent handicap, fresque du num\u00e9rique)\nUne culture du t\u00e9l\u00e9travail encadr\u00e9e de mani\u00e8re appropri\u00e9e !\nTous nos postes sont ouverts aux personnes en situation de handicap.\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "R",
                "Go"
            ],
            "DataBase": [],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [
                "Spark"
            ],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [
                "Tableau",
                "Power BI"
            ],
            "Statistics": [],
            "CloudComputing": [
                "AWS"
            ],
            "DevTools": [],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [
                "Cloud",
                "CI/CD"
            ],
            "FrSoftSkills": [],
            "EnSoftSkils": []
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s",
                "6",
                "6",
                "6"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "title": "Data Engineer H/F",
        "company": "Chantelle",
        "location": "Cachan, \u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/data-engineer-h-f-at-chantelle-3909775663?position=37&pageNum=0&refId=TDTc9UZJy78L%2BED7EV%2BMrg%3D%3D&trackingId=B7M58zT%2F%2FcerBjMK2k9%2F7g%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "La Direction des Syst\u00e8mes d'Information et du Digital du groupe Chantelle recherche son/sa futur.e Data Engineer H/F, pour le lancement du grand chantier de r\u00e9novation de l'architecture Data : la bascule de l'int\u00e9gralit\u00e9 de son Data Warehouse vers Google Big Query.\nNous souhaitons recruter un Data Engineer H/F confirm\u00e9.e, charg\u00e9.e de contribuer \u00e0 la d\u00e9finition de la feuille de route de la Chantelle Data Plaform. En tant que Data Engineer vous travaillerez au sein de l'\u00e9quipe Data Int\u00e9gration en charge de la Chantelle Data Platform.\nVos Missions :\n- Mettre en \u0153uvre une infrastructure autour de Google Cloud Platform permettant de collecter (airbyte, API, ...) , transformer (dataform, Bigquery ...), exposer (dataviz, API, applications, ...) et historiser les donn\u00e9es g\u00e9n\u00e9r\u00e9es par l'entreprise.\n- Travailler en \u00e9troite proximit\u00e9 avec les responsables des diff\u00e9rents domaines fonctionnels (R\u00e9f\u00e9rentiels, Supply Chain, Manufacturing, B2B, Retail & e-commerce, Finance, ...), avec notre \u00e9quipe de Data Analysts ainsi qu'avec l'\u00e9quipe technique en charge des infrastructures transverses\n- \u00catre force de proposition sur tous les sujets d'architecture et de mod\u00e9lisation (choix de mise en place de pipeline temps r\u00e9els ou au contraire de flux de donn\u00e9es en mode batch, ou bien encore stockage sur Big Query / Big Table en fonction des cas d'usage).\n- D\u00e9finir les \u00e9l\u00e9ments structurants, en justifiant vos choix, et les mettre en \u0153uvre.\n- Rationaliser et moderniser notre architecture d'int\u00e9gration inter-applicative; se projeter sur la cr\u00e9ation d'un mod\u00e8le de donn\u00e9es de type Datamesh.\n- Faire la refonte de la BI de nombreux use cases tels que le pilotage de nos stocks, personnalisation de nos sites e-commerce en temps r\u00e9el en fonction de nos profils client, etc\u2026\nStack technique : Google Cloud Platform, BigQuery, DataForm, DataFlow, PubSub, Airbyte, Github ...\nBonne ma\u00eetrise des langages Python et SQL\nPourquoi travailler chez Chantelle ?\nUne flexibilit\u00e9 dans votre lieu de travail, selon la politique de t\u00e9l\u00e9travail de l'entreprise.\n11 jours de RTT/an ainsi qu'un 13\u00e8me mois.\nUne culture d'entreprise familiale bas\u00e9e sur des valeurs de respect, de cr\u00e9ativit\u00e9, de durabilit\u00e9 et de transparence\nUne aventure dans laquelle vous pourrez vous \u00e9panouir, apprendre et entreprendre, avec une grande vari\u00e9t\u00e9 de missions et beaucoup d'autonomie\nDes \u00e9quipes ressources humaines et des managers \u00e0 votre \u00e9coute pour vous accompagner dans votre parcours professionnel\nDes r\u00e9ductions sur nos produits et des ventes au personnel\nDes avantages dans votre qualit\u00e9 de vie au travail : une conciergerie compl\u00e8te proposant un large panel de services, des activit\u00e9s en interne, un CSE.\nVous souhaitez rejoindre un Groupe familial, innovant, engag\u00e9 et leader dans son secteur en France comme \u00e0 l'international et vous souhaitez apporter votre expertise et authenticit\u00e9 pour guider votre \u00e9quipe vers le succ\u00e8s : postulez et rejoignez le Groupe Chantelle !\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "R",
                "Go"
            ],
            "DataBase": [
                "SQL"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [
                "Google Cloud Platform"
            ],
            "DevTools": [
                "Git"
            ],
            "Os": [],
            "DBMS": [
                "BigQuery",
                "Big Query"
            ],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [
                "Cloud"
            ],
            "FrSoftSkills": [
                "Cr\u00e9ativit\u00e9",
                "Flexibilit\u00e9"
            ],
            "EnSoftSkils": []
        },
        "details": {
            "JobDetail": [
                "Confirm\u00e9"
            ],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "title": "Data Engineer / Developpeur Talend",
        "company": "Siderlog Conseil",
        "location": "Niort, Nouvelle-Aquitaine, France",
        "link": "https://fr.linkedin.com/jobs/view/data-engineer-developpeur-talend-at-siderlog-conseil-3861714639?position=38&pageNum=0&refId=TDTc9UZJy78L%2BED7EV%2BMrg%3D%3D&trackingId=OI1YfXE1D5T6TJRZFOucYA%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Siderlog est un cabinet de conseil sp\u00e9cialis\u00e9 implant\u00e9 \u00e0 Niort depuis 2004 qui accompagne les directions m\u00e9tiers et SI sur des projets de:\n- Business et Data Analyse\n- Management de projets\n- Conduite du changement\nPour soutenir notre croissance, nous pr\u00e9voyons \u00e0 Niort le recrutement de 20 consultants d'ici 2025.\nNos consultants b\u00e9n\u00e9ficient d'un mod\u00e8le qui favorise l'\u00e9panouissement professionnel et le bien \u00eatre:\n\ud83c\udf43Un processus d'int\u00e9gration sp\u00e9cifique et un suivi r\u00e9gulier\n\ud83c\udf43Une \u00e9coute active des attentes, notamment en terme de formations, certifications\n\ud83c\udf43Des d\u00e9jeuners et \u00e9v\u00e8nements mensuels\n\ud83c\udf43Un management et un accompagnement de proximit\u00e9\n\ud83c\udf43Un package salarial attractif\n\ud83c\udf43La possibilit\u00e9 de contribuer aux projets d'entreprise ( RSE, communaut\u00e9s m\u00e9tiers, p\u00f4le conseil et expertise)\n\ud83c\udf43Entreprise labellis\u00e9e Happy At Work, charte T\u00e9l\u00e9travail...\n\ud83c\udf43De nombreux autres avantages que nous vous invitons \u00e0 venir d\u00e9couvrir\nSiderlog recherche pour renforcer son \u00e9quipe, \u00e0 Niort un(e) consultant(e) Data Engineer / Developpeur Talend.\nDans ce cadre vous devrez :\n\u2714\ufe0fConcevoir et d\u00e9velopper des traitements/job de donn\u00e9es complexes \u00e0 l'aide de Talend pour l'ingestion, le nettoyage, la transformation et la distribution des donn\u00e9es.\n\u2714\ufe0fCollaborer \u00e9troitement avec les \u00e9quipes m\u00e9tier pour comprendre les besoins en mati\u00e8re de donn\u00e9es et concevoir des solutions adapt\u00e9es.\n\u2714\ufe0fMettre en \u0153uvre des bonnes pratiques de d\u00e9veloppement ETL, y compris la documentation, les tests unitaires et l'int\u00e9gration continue.\n\u2714\ufe0fAssurer la surveillance et la maintenance des traitements/job de donn\u00e9es en production, en r\u00e9solvant les incidents et en effectuant des mises \u00e0 jour si n\u00e9cessaire.\n\ud83d\udccb Qualifications et comp\u00e9tences :\n\ud83d\udc49Exp\u00e9rience av\u00e9r\u00e9e dans le d\u00e9veloppement de solutions de gestion et d'int\u00e9gration de donn\u00e9es, sur Talend.\n\ud83d\udc49Ma\u00eetrise des langages de requ\u00eate SQL pour l'extraction et la manipulation des donn\u00e9es.\n\ud83d\udc49Connaissance approfondie des bases de donn\u00e9es relationnelles et des entrep\u00f4ts de donn\u00e9es.\n\ud83d\udc49Comp\u00e9tences en programmation avec Java, Python ou d'autres langages similaires.\n\ud83d\udc49Capacit\u00e9 \u00e0 travailler de mani\u00e8re autonome tout en collaborant efficacement avec les membres de l'\u00e9quipe.\n\ud83d\udc49Excellentes comp\u00e9tences en communication \u00e9crite et verbale.\n\ud83d\udc49Maitrise de l'outil ETL Talend.\n\ud83d\udc49Exp\u00e9rience avec d'autres outils d'int\u00e9gration de donn\u00e9es tels que Informatica, BODS, Alt\u00e9ryx.\n\ud83d\udc49Certification Talend serait un plus.\n\ud83d\udc49Exp\u00e9rience dans le domaine de l'assurance souhait\u00e9e\nCette offre vous int\u00e9resse ! Postulez !\n\ud83c\udfc6\ud83d\ude4f\ud83d\ude80\ud83c\udf89 !\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "Java",
                "R"
            ],
            "DataBase": [
                "SQL"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [],
            "DevTools": [],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [],
            "FrSoftSkills": [
                "Communication"
            ],
            "EnSoftSkils": [
                "Communication"
            ]
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [],
            "Salary": [
                "Package"
            ],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "title": "DATA Engineer (H/F)",
        "company": "Boulanger",
        "location": "Lesquin, Hauts-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/data-engineer-h-f-at-boulanger-3854554057?position=39&pageNum=0&refId=TDTc9UZJy78L%2BED7EV%2BMrg%3D%3D&trackingId=rzwJ7eGfBAYHY19wsvY09w%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Au sein de la direction informatique, le p\u00f4le DATA a pour missions de maximiser la mise en valeur des donn\u00e9es de BOULANGER ,ELECTRO-DEPOT et KREFEL/HIFI afin d\u2019aider nos d\u00e9cideurs \u00e0 agir sur les leviers de leur performance par des processus d\u00e9cisionnels efficients.\nAu sein de ce p\u00f4le, tu prendras en charge un large domaine m\u00e9tier qu'il te faudra maitriser de bout en bout : de la donn\u00e9es brutes, sa transformation jusqu'\u00e0 son exposition dans les reporting. Cela afin d'en assurer le bon fonctionnement, les \u00e9volutions constantes et sa p\u00e9rennit\u00e9\nTes t\u00e2ches principales portent sur :\nLe pilotage et la mise en \u0153uvre de projets DATA.\nLa collecte, le stockage et l\u2019exploitation fluides des donn\u00e9es par le d\u00e9veloppement de solutions\nMissions\nMaitriser les r\u00e8gles fonctionnelles et les KPI de ton domaine afin de challenger les m\u00e9tiers dans les \u00e9volutions et les nouveaux projets\nAccompagner des \u00e9quipes m\u00e9tiers dans leurs travaux d\u2019identification et expression des besoins sur la data\nParticiper aux ateliers de conception et d\u00e9veloppement des applications data\nMod\u00e9liser la solution \u00e0 mettre en \u0153uvre\nConcevoir et mettre (ou faire mettre) en \u0153uvre des flux les pipelines d\u2019int\u00e9gration (en mode batch ou fil de l'eau) de donn\u00e9es structur\u00e9es/semi-structur\u00e9es\nTransformer les donn\u00e9es : consolider, enrichir et optimiser les donn\u00e9es, qui seront exploit\u00e9es par le m\u00e9tier\nCr\u00e9er, faire \u00e9voluer et optimiser les restitutions\nSuivre et animer les d\u00e9veloppeurs (ETL, restitution, self-BI internes ou externes)\nG\u00e9rer le RUN\nMaitrise le SQL et la base de donn\u00e9es (Oracle, Snowflake)\nMa\u00eetrise d\u2019outils de restitution (tel que Business Object (BO), PowerBI\u2026)\nCapacit\u00e9 relationnelle, rigueur et dynamisme\nMa\u00eetrise un ou plusieurs outils de pr\u00e9paration et traitement de la donn\u00e9e (DataStage, Stambia, ...)\nCapacit\u00e9 \u00e0 s\u2019adapter \u00e0 tout type d\u2019interlocuteurs (technique, m\u00e9tiers, Direction)\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "R"
            ],
            "DataBase": [
                "SQL"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [
                "PowerBI"
            ],
            "Statistics": [],
            "CloudComputing": [],
            "DevTools": [],
            "Os": [],
            "DBMS": [
                "Oracle",
                "Snowflake",
                "Snowflake"
            ],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [],
            "FrSoftSkills": [],
            "EnSoftSkils": []
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "title": "Ing\u00e9nieur Data Talend (F/H)",
        "company": "Thales",
        "location": "V\u00e9lizy-Villacoublay, \u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/ing%C3%A9nieur-data-talend-f-h-at-thales-3890948785?position=40&pageNum=0&refId=TDTc9UZJy78L%2BED7EV%2BMrg%3D%3D&trackingId=joJb400uS2PS7%2FhJB7d5wA%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "QUI SOMMES-NOUS ?\nThales est un leader mondial des hautes technologies comptant plus de 81 000 collaborateurs pr\u00e9sents sur tous les continents. Le Groupe investit dans les innovations du num\u00e9rique et de la \u00ab deep tech \u00bb \u2013 big data, intelligence artificielle, connectivit\u00e9, cybers\u00e9curit\u00e9 et quantique \u2013 pour construire un avenir de confiance, essentiel au d\u00e9veloppement de nos soci\u00e9t\u00e9s, en pla\u00e7ant l\u2019humain au c\u0153ur des d\u00e9cisions.\nThales propose des solutions, services et produits qui aident ses clients \u2013 entreprises, organisations, Etats \u2013 dans cinq grands march\u00e9s vitaux pour le fonctionnement de nos soci\u00e9t\u00e9s : identit\u00e9 et s\u00e9curit\u00e9 num\u00e9riques, d\u00e9fense, a\u00e9ronautique, espace, et transport.\nQUI ETES-VOUS ?\nDipl\u00f4m\u00e9 d\u2019un Bac+5 en \u00e9cole d\u2019ing\u00e9nieur ou \u00e9quivalent universitaire avec une sp\u00e9cialisation en informatique, vous avez au moins 3 ans d'exp\u00e9rience dans les technologies Big Data.\nCE QUE NOUS POUVONS ACCOMPLIR ENSEMBLE :\nEn tant que Data Engineer, vous jouerez un r\u00f4le cl\u00e9 dans la conception, le d\u00e9veloppement et la maintenance de notre infrastructure de donn\u00e9es, ainsi que dans la transformation et la gestion des flux de donn\u00e9es.\nVOS MISSIONS :\n\u2022 Concevoir, d\u00e9velopper et d\u00e9ployer des solutions Big Data en utilisant les technologies Talend.\n\u2022 Mettre en place des pipelines de donn\u00e9es performants pour l'ingestion, le traitement et le stockage des donn\u00e9es massives.\n\u2022 Collaborer \u00e9troitement avec les \u00e9quipes m\u00e9tier pour comprendre leurs besoins en mati\u00e8re d'analyse de donn\u00e9es et proposer des solutions adapt\u00e9es.\n\u2022 Optimiser les performances des clusters Hadoop pour garantir une exploitation efficace des donn\u00e9es.\n\u2022 Assurer la qualit\u00e9 et la fiabilit\u00e9 des donn\u00e9es trait\u00e9es, en mettant en place des processus de validation et de nettoyage.\n\u2022 Identifier et r\u00e9soudre les probl\u00e8mes li\u00e9s \u00e0 l'infrastructure Big Data et proposer des am\u00e9liorations.\n\u2022 Travailler en \u00e9troite collaboration avec les Data Scientists et les Data Analysts pour fournir des insights pertinents \u00e0 partir des donn\u00e9es.\nInnovation, passion, ambition : rejoignez Thales et cr\u00e9ez le monde de demain, d\u00e8s aujourd\u2019hui.\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "R"
            ],
            "DataBase": [],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [
                "Hadoop"
            ],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [],
            "DevTools": [],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [
                "Big Data"
            ],
            "FrSoftSkills": [
                "Collaboration",
                "Organisation"
            ],
            "EnSoftSkils": [
                "Collaboration"
            ]
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [],
            "Salary": [],
            "Level": [
                "Bac+5"
            ],
            "Experience": [
                "a",
                "n",
                "s",
                "3",
                "3",
                "3"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "title": "Data Engineer (Snowflake)",
        "company": "MindPal",
        "location": "Toulouse, Occitanie, France",
        "link": "https://fr.linkedin.com/jobs/view/data-engineer-snowflake-at-mindpal-3896992742?position=41&pageNum=0&refId=TDTc9UZJy78L%2BED7EV%2BMrg%3D%3D&trackingId=tSBp1Wb79voGnfrm%2F3nyZg%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "We are looking for experienced\nData Engineers\nwith knowledge of\nSnowflake\nplatform.\nResponsibilities\nCreating and managing data in the Snowflake environment\nDesigning and implementing ETL (Extract, Transform, Load) solutions for transferring data between various sources and platforms\nOptimizing the performance of Snowflake databases, including designing and implementing data structures and using indexes appropriately\nAutomating data processing workflows using tools such as Airflow or other workflow management tools\nDeploying and configuring tools to monitor and report on the performance of the Snowflake system\nRequirements\nMinimum 1 year of experience as a Data Engineer\nAbility to use Snowflake\nVery good knowledge of SQL and programming in Python\nAbility to work with databases, including the Snowflake platform\nKnowledge of ETL tools and data integration\nAbility to work in a team and good communication skills\nFluent English in speaking and writing\nWe Offer\nB2B contract type\nFull-time job\nRemote and flexible working hours\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "R",
                "Go"
            ],
            "DataBase": [
                "SQL"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [],
            "DevTools": [],
            "Os": [],
            "DBMS": [
                "Snowflake",
                "Snowflake"
            ],
            "SoftBigDataProcessing": [],
            "Automation": [
                "Airflow"
            ],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [],
            "FrSoftSkills": [
                "Communication"
            ],
            "EnSoftSkils": [
                "Communication"
            ]
        },
        "details": {
            "JobDetail": [
                "Remote",
                "Full"
            ],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "title": "Data Engineer Snowflake",
        "company": "Key Performance Consulting (KPC)",
        "location": "Bordeaux, Nouvelle-Aquitaine, France",
        "link": "https://fr.linkedin.com/jobs/view/data-engineer-snowflake-at-key-performance-consulting-kpc-3915036342?position=42&pageNum=0&refId=TDTc9UZJy78L%2BED7EV%2BMrg%3D%3D&trackingId=87iaB3Zrtg5V1NO0NwSbCQ%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Rejoignez la plus grosse \u00e9quipe SNOWFLAKE certifi\u00e9e en France !\nKPC est Partner Elite Snowflake, le plus haut niveau de certification.\nVous souhaitez int\u00e9grer une ESN \u00e0 taille humaine vous permettant de travailler sur des projets challengeant et de monter en comp\u00e9tences ? Ce poste est pour vous !\nVOS MISSIONS :\nElaboration d'architectures optimis\u00e9es dans un contexte Snowflake,\nConception et mise en place des ingestions de donn\u00e9es (temps r\u00e9el, Kafka, Snowpipe),\nMod\u00e9lisation de donn\u00e9es (Star Sch\u00e9ma, DataVault, DataMesh, virtualisation) - DataOps\nMise en oeuvre des transformations et de la valorisation des donn\u00e9es (SQL, Python, Java, Scala) - DataOps\nOptimisation des performances et des co\u00fbts d utilisation Snowflake (FinOps)\nVOTRE PROFIL :\nVous \u00eates issu d'une \u00e9cole d'ing\u00e9nieur ou d'un Master 2\nVous avez une premi\u00e8re exp\u00e9rience sur du Snowflake ou au moins 2 ans de SQL\nDEVENEZ NOTRE PROCHAIN(E) Data Engineer Snowflake !\nVous recherchez une entreprise o\u00f9 vous pouvez t\u00e9l\u00e9travailler tout en gardant un lien de proximit\u00e9, qui laisse de l\u2019autonomie, et o\u00f9 il fait bon travailler, alors nous vous souhaitons la bienvenue chez KPC.\nVous avez une exp\u00e9rience d'au moins 2 ans en d\u00e9veloppement SQL ou une premi\u00e8re exp\u00e9rience sur Snowflake ?\nVous souhaitez travailler au sein d\u2019une \u00e9quipe d'experts technico-fonctionnels ?\nRejoignez l\u2019entreprise KPC ! Une entreprise \u00e0 taille humaine avec un mode de management dynamique et de proximit\u00e9.\nNotre c\u0153ur de m\u00e9tier de KPC : la business intelligence. Nous sommes int\u00e9grateurs de solutions GOLD PARTENAIRE de SAP, Qlik, Microsoft BI, Tableau, Snowflake, Semarchy etc.\nNotre gold partenariat nous permet d'offrir des formations certifiantes pour nos collaborateurs, d'avoir des liens de proximit\u00e9s avec les \u00e9diteurs et de revendre leurs solutions.\nRejoignez la plus grosse \u00e9quipe SNOWFLAKE certifi\u00e9e en France ! KPC est Partner Elite Snowflake, le plus haut niveau de certification.\nVous souhaitez int\u00e9grer une ESN \u00e0 taille humaine vous permettant de travailler sur des projets challengeant et de monter en comp\u00e9tences ? Ce poste est pour vous !\nVOS MISSIONS :\nElaboration d'architectures optimis\u00e9es dans un contexte Snowflake,\nConception et mise en place des ingestions de donn\u00e9es (temps r\u00e9el, Kafka, Snowpipe),\nMod\u00e9lisation de donn\u00e9es (Star Sch\u00e9ma, DataVault, DataMesh, virtualisation) - DataOps\nMise en oeuvre des transformations et de la valorisation des donn\u00e9es (SQL, Python, Java, Scala) - DataOps\nOptimisation des performances et des co\u00fbts d utilisation Snowflake (FinOps)\nVOTRE PROFIL :\nVous \u00eates issu d'une \u00e9cole d'ing\u00e9nieur ou d'un Master 2\nVous avez une premi\u00e8re exp\u00e9rience sur du Snowflake ou deux/trois ans de SQL\nPROCESSUS DE RECRUTEMENT :\nVous pensez \u00eatre celui, celle qu\u2019il nous faut et vous vous \u00eates reconnu dans notre organisation, alors venez vivre votre premi\u00e8re exp\u00e9rience KPC en postulant \u00e0 cette offre :\nVous serez appel\u00e9(e) par Ludivine (charg\u00e9e de recrutement) pour une premi\u00e8re prise de contact\nNous pourrons poursuivre les \u00e9changes avec Olivier (Directeur Sud-Ouest) pour l\u2019approche projet et technique\nPour clore ce processus de recrutement, nous vous inviterons \u00e0 rencontrer Gabriel (Directeur Sud-Ouest)\nEt tout \u00e7a dans un temps record \ud83d\ude0a : 15 jours en moyenne pour allier r\u00e9activit\u00e9 et efficacit\u00e9.\nNous garantissons l\u2019\u00e9galit\u00e9 des chances pour toutes et tous car pour nous la diversit\u00e9 est une force !\nKPC EN QUELQUES MOTS ?\nNous sommes une entreprise sp\u00e9cialis\u00e9e dans la Data.\nDepuis treize ans, nous accompagnons nos clients \u00e0 valoriser leurs donn\u00e9es de mani\u00e8re innovante et efficace pour d\u00e9velopper leur performance, am\u00e9liorer leurs processus et exp\u00e9riences utilisateurs. Nous intervenons en mode projet (50% r\u00e9gie, 50% forfait)\nNous avons d\u00e9velopp\u00e9 3 grandes activit\u00e9s :\nANALYTICS (BI, Data Science/Big Data, Data Gouvernance, EPM, Digital)\nERP SAP\nCRM\nPour cela, nous travaillons en partenariat avec les plus grands \u00e9diteurs du march\u00e9 tels que : SAP, QLIK, DATAGALAXY, SALESFORCES, SNOWFLAKE, TALEND, MICROSOFT, ONESTREAM, IMAGINO.\nEn forte croissance, nous cherchons de nouveaux talents pour participer \u00e0 cette aventure humaine au service des entreprises de demain.\nKPC EN QUELQUES CHIFFRES :\n300 collaborateurs\n20 % Croissance annuelle\n8 agences en France (Aix-en-Provence, Nice, Montpellier, Lyon, Toulouse, Bordeaux, Paris et Nantes)\nDes grands groupes en tant que clients : CMA CGM, PERNOD RICARD, AIRBUS, CDISCOUNT, CULTURA, GIFI, POLE EMPLOI, L'OREAL ...\nVOS AVANTAGES :\nOrganisation du travail 100% flexible avec du t\u00e9l\u00e9travail, participation aux frais t\u00e9l\u00e9phonique et internet et un forfait \u00e9quipement fourniture\nUn parcours d'int\u00e9gration\nDes formations et des certifications avec les \u00e9diteurs sur les technos de pointe\nIK voiture, v\u00e9lo\nCarte resto, mutuelle, pr\u00e9voyance sant\u00e9\nPrime \u00ab Vacances \u00bb\nPOURQUOI NOUS REJOINDRE ?\nUne entreprise \u00e0 taille humaine\nUn mode de management dynamique, agile et de proximit\u00e9\nUne vie d'agence anim\u00e9e, engag\u00e9e et conviviale dans des locaux sympas\nUne attention particuli\u00e8re \u00e0 un \u00e9quilibre de vie pro / perso\nUne entreprise qui encourage les initiatives et l'autonomie\nUne entreprise certifi\u00e9e Ecovadis Silver pour des actions concr\u00e8tes en termes de RSE\nUn cadre de travail agr\u00e9able prenant en compte les enjeux soci\u00e9taux et environnementaux\nVous \u00eates ou voulez \u00eatre consultant(e), chef de projet, expert(e) technique, manager ? Notre promesse : vous accompagner de fa\u00e7on personnalis\u00e9e et continue quel que soit votre projet \u00e0 court, moyen et long terme.\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "Java",
                "Scala",
                "R",
                "Go"
            ],
            "DataBase": [
                "SQL"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [
                "Tableau"
            ],
            "Statistics": [],
            "CloudComputing": [],
            "DevTools": [
                "Git"
            ],
            "Os": [],
            "DBMS": [
                "Snowflake",
                "Snowflake"
            ],
            "SoftBigDataProcessing": [],
            "Automation": [
                "Chef"
            ],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [
                "Big Data"
            ],
            "FrSoftSkills": [
                "Organisation"
            ],
            "EnSoftSkils": [
                "Initiative"
            ]
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [
                "CDI"
            ],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s",
                "2",
                "2",
                "2"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "title": "Data Engineer (H/F)",
        "company": "iPepperGroup",
        "location": "Valbonne, Provence-Alpes-C\u00f4te d'Azur, France",
        "link": "https://fr.linkedin.com/jobs/view/data-engineer-h-f-at-ipeppergroup-3894091360?position=43&pageNum=0&refId=TDTc9UZJy78L%2BED7EV%2BMrg%3D%3D&trackingId=tEwLeqmjPSQfhAClCp4pfA%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "iPepper recrute pour l'un de ses clients une PME \u00e9diteur de logiciel dans le domaine du voyage, un\nData Engineer (H/F)\npassionn\u00e9(e) et exp\u00e9riment\u00e9(e) pour rejoindre une \u00e9quipe dynamique.\nEn tant qu'Ing\u00e9nieur(e) Data, vous serez en charge d'extraire et de transformer des donn\u00e9es, de construire et d'optimiser des pipelines de donn\u00e9es, ainsi que de concevoir des visualisations de donn\u00e9es intuitives et informatives.\nResponsabilit\u00e9s :\nConcevoir, construire et maintenir des pipelines de donn\u00e9es \u00e9volutifs et efficaces pour transf\u00e9rer des donn\u00e9es entre des bases de donn\u00e9es SQL et NoSQL.\nD\u00e9velopper et mettre en \u0153uvre des processus ETL pour extraire, transformer et charger des donn\u00e9es \u00e0 partir de diff\u00e9rentes sources dans notre entrep\u00f4t de donn\u00e9es.\nCollaborer avec des \u00e9quipes pluridisciplinaires pour comprendre les besoins en donn\u00e9es et garantir la fourniture r\u00e9ussie de solutions de donn\u00e9es.\nOptimiser et ajuster les pipelines de donn\u00e9es existants pour la performance et la fiabilit\u00e9.\nConcevoir et d\u00e9velopper des visualisations de donn\u00e9es et des tableaux de bord pour fournir des insights exploitables aux parties prenantes.\nSurveiller et r\u00e9soudre les probl\u00e8mes de pipelines de donn\u00e9es, en veillant \u00e0 la qualit\u00e9 et \u00e0 l'int\u00e9grit\u00e9 des donn\u00e9es.\nProfil recherch\u00e9 :\nDipl\u00f4me universitaire en informatique, en ing\u00e9nierie ou dans un domaine connexe.\nExp\u00e9rience av\u00e9r\u00e9e en tant que Data Engineer ou dans un r\u00f4le similaire, avec un accent particulier sur la construction de pipelines de donn\u00e9es et de processus ETL.\nCompr\u00e9hension solide des bases de donn\u00e9es\nSQL\net\nNoSQL\n, y compris la mod\u00e9lisation des donn\u00e9es et la conception de sch\u00e9mas.\nMa\u00eetrise des langages de programmation tels que\nPython, Java ou Scala.\nExp\u00e9rience avec des outils de visualisation de donn\u00e9es tels que\nTableau, Power BI.\nSolides comp\u00e9tences en analyse et en r\u00e9solution de probl\u00e8mes, avec la capacit\u00e9 de traduire des donn\u00e9es complexes en insights exploitables.\nExcellentes comp\u00e9tences en communication et en collaboration, avec la capacit\u00e9 de travailler efficacement dans un environnement d'\u00e9quipe pluridisciplinaire.\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "Java",
                "Scala",
                "R"
            ],
            "DataBase": [
                "SQL",
                "NoSQL"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [
                "Tableau",
                "Power BI"
            ],
            "Statistics": [],
            "CloudComputing": [],
            "DevTools": [],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [],
            "FrSoftSkills": [
                "Communication",
                "R\u00e9solution de probl\u00e8mes",
                "Collaboration"
            ],
            "EnSoftSkils": [
                "Communication",
                "Collaboration"
            ]
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "title": "Ing\u00e9nieur Data (H/F) | POEI",
        "company": "DataScientest.com",
        "location": "Puteaux, \u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/ing%C3%A9nieur-data-h-f-poei-at-datascientest-com-3909360157?position=44&pageNum=0&refId=TDTc9UZJy78L%2BED7EV%2BMrg%3D%3D&trackingId=FHcjn5vGWt2bAC0sneS4jg%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Ing\u00e9nieur Data (H/F) | POEI\nPuteaux\nCDI\nPostuler\nRetour\nDatascientest Is Hiring!\nIng\u00e9nieur Data (H/F) | POEI\n\u00c0 propos\nDATASCIENTEST ? LA REFERENCE EN DATASCIENCE\nCr\u00e9\u00e9e en 2017, DataScientest r\u00e9volutionne la formation en Data Science et devient leader en France !\nNotre \u00e9cole compte plus de 6 000 apprenants \u00e0 son actif, et a s\u00e9duit 50 entreprises dont une trentaine du CAC40 et des leaders internationaux (BCG, Allianz, Christian Dior, Axa\u2026),\nNous formons aussi les demandeurs d'emploi en leur offrant un CDI au sein de nos entreprises partenaires\nPr\u00e9sents en Espagne et en Allemagne, notre p\u00e9dagogie repose sur une structure hybride :\nQui allie l\u2019adaptabilit\u00e9 du distanciel avec une plateforme enti\u00e8rement con\u00e7ue par nous-m\u00eame et\nLa motivation du pr\u00e9sentiel avec des s\u00e9ances de coaching anim\u00e9es par nos enseignants data scientists !\nDescriptif du poste\nEn Tant Qu'Ing\u00e9nieur Data, Vous Serez Charg\u00e9(e) De Proposer Les Meilleures Solutions \u00e0 L'entreprise En Leur Permettant D'optimiser Leur Activit\u00e9, \u00e0 Travers Quelques Missions Principales\nD\u00e9velopper des solutions pour traiter des volumes importants de donn\u00e9es,\nConcevoir, collecter et fabriquer des donn\u00e9es brutes,\nCr\u00e9er des outils et algorithmes pour le traitement des donn\u00e9es,\nPr\u00e9parer des donn\u00e9es pour le Data Analyst,\nS\u00e9curiser des Pipelines donn\u00e9es pour les Data Analysts et Data Scientists,\nOrganiser l'architecture du cloud,\nContribuer \u00e0 l'effort d'animation technique, de veille technologique et d'innovation\nProfil recherch\u00e9\nEt si nous parlions de vous ?\nIssu(e) d\u2019une fili\u00e8re scientifique bac+5 ou d\u2019un dipl\u00f4me d\u2019ing\u00e9nieur,\nVous disposez id\u00e9alement d\u2019une exp\u00e9rience significative en d\u00e9veloppement informatique, en architecture r\u00e9seaux ou dans la Data,\nVous ma\u00eetrisez un langage objet type Java, Python, C++, etc.\nVous \u00eates demandeur d'emploi\nN'attendez plus, envoyez nous votre CV, nos \u00e9quipes se feront un plaisir de vous contacter et de vous accompagner pour pr\u00e9parer vos entretiens avec notre entreprise partenaire.\nInformations compl\u00e9mentaires\nType de contrat : CDI\nLieu : Puteaux\nNiveau d'\u00e9tudes : Bac +5 / Master\nExp\u00e9rience : > 1 an\nT\u00e9l\u00e9travail ponctuel autoris\u00e9\nSalaire : entre 38000\u20ac et 48000\u20ac / an\nVous \u00eates int\u00e9ress\u00e9 par cette offre ?\nPostuler\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "Java",
                "C++",
                "R",
                "Go"
            ],
            "DataBase": [],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [],
            "DevTools": [],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [
                "Cloud"
            ],
            "FrSoftSkills": [
                "Adaptabilit\u00e9"
            ],
            "EnSoftSkils": []
        },
        "details": {
            "JobDetail": [
                "Hybride"
            ],
            "TypeContract": [
                "CDI"
            ],
            "Salary": [
                "38000"
            ],
            "Level": [
                "Bac+5"
            ],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "title": "Data Engineer DevOps H/F",
        "company": "Inetum",
        "location": "Courbevoie, \u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/data-engineer-devops-h-f-at-inetum-3843956952?position=45&pageNum=0&refId=TDTc9UZJy78L%2BED7EV%2BMrg%3D%3D&trackingId=LN1KQRS61sKKEPaDT%2FUBBA%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "D\u00e9tail de l'offre\nInformations g\u00e9n\u00e9rales\nEntit\u00e9 de rattachement\nNous sommes une ESN agile, un groupe international certifi\u00e9 Top Employer Europe 2024.\nA l'\u00e8re de la post-transformation digitale, nous mettons tout en \u0153uvre pour que chacun de nos 28 000 athl\u00e8tes du digital puisse se renouveler perp\u00e9tuellement, en vivant positivement son propre flow digital.\nChacun de nos talents peut ainsi fa\u00e7onner son parcours de carri\u00e8re selon ses app\u00e9tences, entreprendre de mani\u00e8re pragmatique avec ses clients pour un monde \u00e0 impact positif, innover localement dans 27 pays et harmoniser son investissement professionnel et son bien-\u00eatre personnel.\nRejoignez Inetum. Live your positive digital flow.\nTous nos postes sont ouverts aux personnes en situation de handicap.\nDescription du poste\nM\u00e9tier\nConseil et Int\u00e9gration - Business Consulting\nIntitul\u00e9 du poste\nData Engineer DevOps H/F\nContrat\nCDI\nDescription De La Mission\nQui sommes-nous ?\nNous sommes une ESN agile et un groupe international. A l'\u00e8re de la post-transformation digitale, nous mettons tout en \u0153uvre pour que chacun de nos 27 000 collaborateurs puisse se renouveler perp\u00e9tuellement, en vivant positivement son propre flow digital. Chacun d'entre eux peut ainsi fa\u00e7onner son parcours de carri\u00e8re selon ses app\u00e9tences, entreprendre de mani\u00e8re pragmatique avec ses clients pour un monde plus positif, innover localement dans 26 pays et harmoniser son investissement professionnel et son bien-\u00eatre personnel.\nRejoignez\nCapital Market, entit\u00e9 Inetum en Finance de March\u00e9\n. Nous accompagnons les acteurs majeurs du secteur de la finance en France et \u00e0 l\u2019International.\nCultivant la double comp\u00e9tence technique et fonctionnelle, nous intervenons sur des projets innovants \u00e0 haute valeur ajout\u00e9e.\nQuelles sont nos valeurs ?\n\ud83c\udfc6 Excellence Notre culture de l\u2019excellence na\u00eet de notre audace.\n\ud83e\udd1d Engagement S\u2019associer et grandir ensemble !\n\ud83d\udef0 Innovation Nos FabLab au service de la transformation digitale de nos clients.\nMissions propos\u00e9es\nPour accompagner notre forte croissance, nous recherchons des\nData Engineer DevOps\npour le compte d\u2019un acteur majeur de la finance de march\u00e9 en Europe et dans le monde. Dans ce contexte international et exigeant, vous travaillez sur la conception de solutions Big Data afin de r\u00e9pondre aux besoins des op\u00e9rationnels m\u00e9tiers.\nPour mener \u00e0 bien ce projet, vous aurez pour responsabilit\u00e9s de\nComprendre les enjeux des \u00e9quipes Data et les accompagner. Faire le lien entre les environnements (datalake, datawarehouse et environnement de d\u00e9ploiement du mod\u00e8le) gr\u00e2ce \u00e0 des pipelines sophistiqu\u00e9s\n\u00catre r\u00e9f\u00e9rent et garant des bonnes pratiques pour le d\u00e9veloppement des langages utilis\u00e9s par l'\u00e9quipe. Accompagner les Data Scientists dans l'optimisation de leurs algorithmes\nAssurer la viabilit\u00e9 des solutions de datamining et de machine learning de l'\u00e9quipe Data et les mettre en production.Construire et optimiser des pipelines de donn\u00e9es complexes (ETL et ELT)\nCoordonner le d\u00e9veloppement et les op\u00e9rations gr\u00e2ce \u00e0 l\u2019automatisation des flux de travail, la cr\u00e9ation de services Web pr\u00e9dictifs.\nD\u00e9ployez ces mod\u00e8les en utilisant les derni\u00e8res techniques et pratiques (API REST, Docker, Tensorflow Serving, etc.)\nAnalyser et r\u00e9soudre les anomalies li\u00e9es aux performances et \u00e0 l\u2019\u00e9volutivit\u00e9 des solutions Cloud BI et Big Data\nProfil\nProfil souhait\u00e9\nDe formation Ing\u00e9nieur Grande Ecole ou \u00e9quivalent, vous poss\u00e9dez une premi\u00e8re exp\u00e9rience r\u00e9ussite de trois ans minimum sur un poste \u00e9quivalent id\u00e9alement en banque d\u2019investissement ou asset management.\nVous \u00eates familier avec l\u2019environnement Big Data (data grids, compute grids, REST based architectures, SGBDR, No-SQL Databases, GPUs)\nVous avez d\u00e9j\u00e0 travaill\u00e9 avec la m\u00e9thodologie Agile\nUne certaine aisance technique est \u00e9galement requise (Jenkins, Docker, Ansible, Git, Scala, Kubernetes, Python/Java, Maven)\nUne double comp\u00e9tence Cloud (AWS, Google Cloud, Azure) serait un v\u00e9ritable plus\nEvoluant dans un contexte international, la ma\u00eetrise de l'Anglais est n\u00e9cessaire.\nL\u2019aisance relationnelle, de l\u2019autonomie, la gestion des priorit\u00e9s, des capacit\u00e9s d\u2019analyse et de synth\u00e8se, \u2026 le savoir-\u00eatre est une composante importante dans notre processus de recrutement.\nTous nos postes sont ouverts aux personnes en situation de handicap.\nEt pourquoi Inetum Capital Market ?\n\ud83d\ude04 Des missions int\u00e9ressantes\n\ud83e\udd29 Des perspectives d'\u00e9volutions professionnelles et financi\u00e8res\n\ud83d\ude0e Les avantages d'un grand groupe international\n\ud83d\ude09 Un suivi r\u00e9gulier\n\u2708\ufe0f Une aide \u00e0 la mobilit\u00e9 g\u00e9ographique que vous soyez localis\u00e9 en France ou \u00e0 l'\u00e9tranger\n\ud83d\udc68\u200d\ud83c\udf93 Des formations certifiantes\n\ud83e\udd73 Des moments de FUN !\nLocalisation du poste\nLocalisation du poste\nFrance, Ile-de-France, 75 Paris\nVille\nCourbevoie\nCrit\u00e8res candidat\nNiveau d'\u00e9tudes min. requis\nBac+5\nNiveau d'exp\u00e9rience min. requis\nPlus de 2 ans\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "Java",
                "Scala",
                "R",
                "Go"
            ],
            "DataBase": [
                "SQL"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [],
            "MachingLearning": [
                "TensorFlow"
            ],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [
                "AWS",
                "Azure"
            ],
            "DevTools": [
                "Git",
                "Docker",
                "Jenkins"
            ],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [
                "Ansible",
                "Kubernetes"
            ],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [
                "Docker",
                "Kubernetes"
            ],
            "Collaboration": [],
            "Other": [
                "DevOps",
                "Big Data",
                "Machine Learning",
                "Cloud"
            ],
            "FrSoftSkills": [],
            "EnSoftSkils": []
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [
                "CDI"
            ],
            "Salary": [],
            "Level": [
                "Bac+5"
            ],
            "Experience": [
                "a",
                "n",
                "s",
                "2",
                "2",
                "2"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "title": "D\u00e9veloppeur Big Data Junior H/F",
        "company": "Inetum",
        "location": "St.-Ouen, \u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/d%C3%A9veloppeur-big-data-junior-h-f-at-inetum-3887272015?position=46&pageNum=0&refId=TDTc9UZJy78L%2BED7EV%2BMrg%3D%3D&trackingId=GY4l3RNWLP3B0lXdrBu2dw%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "D\u00e9tail de l'offre\nInformations g\u00e9n\u00e9rales\nEntit\u00e9 de rattachement\nInetum est un leader europ\u00e9en des services num\u00e9riques. Pour les entreprises, les acteurs publics et la soci\u00e9t\u00e9 dans son ensemble, les 28 000 consultants et sp\u00e9cialistes du groupe visent chaque jour l'impact digital des solutions qui contribuent \u00e0 la performance, \u00e0 l'innovation et au bien commun.\nPr\u00e9sent dans 19 pays au plus pr\u00e8s des territoires, et avec ses grands partenaires \u00e9diteurs de logiciels, Inetum r\u00e9pond aux enjeux de la transformation digitale avec proximit\u00e9 et flexibilit\u00e9.\nPort\u00e9 par son ambition de croissance et d'industrialisation, Inetum a g\u00e9n\u00e9r\u00e9 en 2023 un chiffre d'affaires de 2,5 milliards d'\u20ac.\nPour r\u00e9pondre \u00e0 un march\u00e9 en croissance continue depuis plus de 30ans, Inetum a fait le choix d\u00e9lib\u00e9r\u00e9 de se recentrer sur 4 m\u00e9tiers afin de gagner en puissance et proposer des solutions sur mesure, adapt\u00e9es aux besoins sp\u00e9cifiques de ses clients le conseil (Inetum Consulting), la gestion des infrastructures et applications \u00e0 fa\u00e7on (Inetum Technologies), l'impl\u00e9mentation de progiciels (Inetum Solutions) et sa propre activit\u00e9 d'\u00e9diteur de logiciels (Inetum Software). Inetum a conclu des partenariats strat\u00e9giques avec 4 grands \u00e9diteurs mondiaux - Salesforce, ServiceNow, Microsoft et SAP et poursuit une strat\u00e9gie d'acquisitions d\u00e9di\u00e9e afin d'entrer dans le top 5 europ\u00e9en sur ces technologies et proposer la meilleure expertise \u00e0 ses clients.\nTous nos postes sont ouverts aux personnes en situation de handicap.\nDescription du poste\nM\u00e9tier\nConseil et Int\u00e9gration - Conseil Technique\nIntitul\u00e9 du poste\nD\u00e9veloppeur Big Data Junior H/F\nContrat\nCDI\nDescription De La Mission\nNous sommes une ESN agile, un groupe international certifi\u00e9 Top Employer Europe 2023.\nA l'\u00e8re de la post-transformation digitale, nous mettons tout en \u0153uvre pour que chacun de nos 28 000 athl\u00e8tes du digital puisse se renouveler perp\u00e9tuellement, en vivant positivement son propre flow digital.\nChacun de nos talents peut ainsi fa\u00e7onner son parcours de carri\u00e8re selon ses app\u00e9tences, entreprendre de mani\u00e8re pragmatique avec ses clients pour un monde \u00e0 impact positif, innover localement dans 27 pays et harmoniser son investissement professionnel et son bien-\u00eatre personnel.\nRejoignez Inetum. Live your positive digital flow.\nTous nos postes sont ouverts aux personnes en situation de handicap\nA la recherche de d\u00e9veloppeurs Big Data juniors pour rejoindre notre \u00e9quipe. Les candidats doivent \u00eatre des ing\u00e9nieurs Big Data passionn\u00e9s et motiv\u00e9s, capables de travailler en \u00e9quipe et de r\u00e9soudre des probl\u00e8mes complexes.\nResponsabilit\u00e9s\nParticiper \u00e0 la conception et au d\u00e9veloppement de solutions Big Data\nTravailler en \u00e9troite collaboration avec les \u00e9quipes de d\u00e9veloppement pour int\u00e9grer les solutions Big Data dans les applications existantes\nParticiper \u00e0 la mise en place de l'architecture Big Data\nD\u00e9velopper des scripts et des programmes pour automatiser les t\u00e2ches de traitement de donn\u00e9es\nParticiper \u00e0 la maintenance et \u00e0 l'am\u00e9lioration des solutions Big Data existantes\nProfil\nComp\u00e9tences requises\nConnaissance des technologies Big Data telles que Hadoop, Hive, Iceberg, Kafka, Spark, Cloudera, Databricks, Snowflake\nMa\u00eetrise d'au moins un langage de programmation parmi Scala et Java\nConnaissance des environnements Cloud tels que AWS, Azure serait un plus\nDipl\u00f4me d'ing\u00e9nieur ou Master 2 en informatique ou en statistiques\nUne premi\u00e8re exp\u00e9rience en d\u00e9veloppement Big Data serait un plus\nProfil recherch\u00e9\nNous recherchons des candidats passionn\u00e9s par les technologies Big Data, ayant une bonne capacit\u00e9 d'analyse et de r\u00e9solution de probl\u00e8mes. Les candidats doivent \u00eatre capables de travailler en \u00e9quipe et de communiquer efficacement avec les autres membres de l'\u00e9quipe.\nPourquoi nous rejoindre ?\nRejoindre Inetum, Certifi\u00e9 TOP EMPLOYER EUROPE 2024, c'est\nFaire partie d'une \u00e9quipe \u00e0 taille humaine, soud\u00e9e, encourageant la diversit\u00e9 des profils et des exp\u00e9riences et favorisant l'autonomie et l'initiative de chacun ;\nAvoir un impact chez nos clients en \u00e9tant responsabilis\u00e9 dans le cadre de missions \u00e0 forts enjeux et sur un large panel d'activit\u00e9s ;\nS'int\u00e9grer dans une dynamique de croissance et de d\u00e9veloppement de notre marque de conseil.\nNous vous proposons\nUne trajectoire de carri\u00e8re personnalis\u00e9e et adapt\u00e9e \u00e0 vos souhaits d'\u00e9volution gr\u00e2ce \u00e0 une implantation \u00e0 l\u2019international (26 pays, 7 Fablab), des formations cibl\u00e9es et des projets couvrant l\u2019ensemble de la cha\u00eene de valeur IT (+25 fili\u00e8res m\u00e9tiers)\nInt\u00e9grer un collectif d\u2019experts partageant des valeurs de solidarit\u00e9 et d\u2019excellence\nUne culture de la proximit\u00e9 au sein de nos 45 agences en France\nLocalisation du poste\nLocalisation du poste\nFrance, Ile-de-France, 75 Paris\nVille\n5-7 rue Touzet Gaillard - 93400 Saint-Ouen-sur-Seine\nCrit\u00e8res candidat\nNiveau d'\u00e9tudes min. requis\nBac+5\nNiveau d'exp\u00e9rience min. requis\nMoins de 2 ans\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Java",
                "Scala",
                "R"
            ],
            "DataBase": [],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [
                "Hadoop",
                "Spark",
                "Databricks"
            ],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [
                "Statistiques"
            ],
            "CloudComputing": [
                "AWS",
                "Azure"
            ],
            "DevTools": [
                "Git"
            ],
            "Os": [],
            "DBMS": [
                "Snowflake",
                "Snowflake"
            ],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [
                "Big Data",
                "Statistiques",
                "Cloud"
            ],
            "FrSoftSkills": [
                "R\u00e9solution de probl\u00e8mes",
                "Collaboration",
                "Flexibilit\u00e9"
            ],
            "EnSoftSkils": [
                "Collaboration",
                "Initiative"
            ]
        },
        "details": {
            "JobDetail": [
                "Junior"
            ],
            "TypeContract": [
                "CDI"
            ],
            "Salary": [],
            "Level": [
                "Bac+5"
            ],
            "Experience": [
                "a",
                "n",
                "s",
                "30",
                "30",
                "30"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "title": "Data engineer python",
        "company": "FINAXYS",
        "location": "Paris, \u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/data-engineer-python-at-finaxys-3887107285?position=47&pageNum=0&refId=TDTc9UZJy78L%2BED7EV%2BMrg%3D%3D&trackingId=eBg06AwxyNxRUXDsMZTakg%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "LE CONTEXTE\nLeader en\nIT\n, dans les domaines Banque\n,\nFinance\net\nAssurance\n,\nFinaxys\nest un cabinet de\nconseil\ncr\u00e9\u00e9 en 2008. Nous accompagnons au quotidien les plus grandes banques du pays sur leur\ntransformation digitale\n(BNP Paribas, Soci\u00e9t\u00e9 G\u00e9n\u00e9rale, Cr\u00e9dit Agricole, Natixis, etc.)\nNos clients bancaires travaillent \u00e9galement dans des contextes Big Data sur des applications centrales rattach\u00e9es aux Datalakes.\nLES MISSIONS\nD\u00e9veloppement et traitements sur des applications Big Data (Python)\n\u00catre force de proposition sur les choix techniques les plus pertinents\nMaintenir la qualit\u00e9 des solutions, mesure de cette qualit\u00e9, alerte sur les non-conformit\u00e9s et validation des solutions d\u00e9finitives.\nAnalyser des risques li\u00e9s aux solutions envisag\u00e9es et proposition des actions de rem\u00e9diation.\nApporter des solutions IT r\u00e9pondant au mieux aux besoins du business port\u00e9 par la/le Product Owner (M\u00e9tiers/Fonctions) en cherchant toujours la maximisation de la valeur g\u00e9n\u00e9r\u00e9e\nAccompagner les \u00e9quipes dans les migrations Cloud\nENVIRONNEMENT TECHNIQUE\nPython\nPandas\nScirpting Big Data\nCulture DevOps (Jenkins, Maven, Ansible)\nPROFIL\nComp\u00e9tences Techniques et Fonctionnelles requises\nMaitrise obligatoire de l\u2019anglais\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "R"
            ],
            "DataBase": [],
            "DataAnalytics": [
                "Pandas",
                "R"
            ],
            "BigData": [],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [],
            "DevTools": [
                "Git",
                "Jenkins"
            ],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [
                "Ansible"
            ],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [
                "DevOps",
                "Big Data",
                "Cloud"
            ],
            "FrSoftSkills": [],
            "EnSoftSkils": []
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "title": "Data Engineer (F/H)",
        "company": "Renault Digital",
        "location": "Boulogne-Billancourt, \u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/data-engineer-f-h-at-renault-digital-3911202728?position=48&pageNum=0&refId=TDTc9UZJy78L%2BED7EV%2BMrg%3D%3D&trackingId=ZkQXgjIjA2SgSdRtYuvyYA%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Contexte :\nDans le cadre de son programme Industrie 4.0, Renault d\u00e9veloppe depuis 2017 sa propre plateforme pour connecter et agr\u00e9ger les donn\u00e9es industrielles des 22 sites du Groupe et de plus de 2500 machines.\nFort de partenariats strat\u00e9giques sign\u00e9s avec Google Cloud (stack data full GCP), Renault Digital est \u00e0 la recherche d\u2019un(e) Data Engineer au sein du P\u00f4le Architecture et Data pour mettre en place des cha\u00eenes de traitement de donn\u00e9es r\u00e9pondant \u00e0 de nouveaux besoins m\u00e9tiers.\nVous collaborerez au jour le jour avec les \u00e9quipes m\u00e9tiers ainsi qu\u2019avec les autres fonctions du P\u00f4le Architecture & Data (Data Analysts et Scientists, architectes, \u2026), exploitant des t\u00e9raoctets de donn\u00e9es (\u00e9v\u00e9nements en mode streaming, traitements en batch et temps r\u00e9els et les appels aux APIs) afin entre autres d\u2019alimenter des mod\u00e8les de machine learning (segmentation clients, d\u00e9tection automatiquement des pannes des v\u00e9hicules, \u2026).\nResponsabilit\u00e9s principales :\nVous participez aux phases de framing, MVP et release des produits, services et APIs orient\u00e9s data ;\nVous argumentez les choix d\u2019architecture des projets et de la plateforme datalake sur GCP ;\nVous contribuez \u00e0 la valeur m\u00e9tier des produits orient\u00e9s Data s\u2019appuyant sur le Datalake, en mettant en place des cha\u00eenes bout en bout de traitement de la data, de l\u2019ingestion \u00e0 l\u2019exposition d\u2019APIs et \u00e0 la visualisation des donn\u00e9es et des solutions ML/DS ;\nVous \u00eates garant de la qualit\u00e9 des donn\u00e9es transform\u00e9es dans le Datalake, du bon fonctionnement des cha\u00eenes de traitement et de l\u2019optimisation de l\u2019utilisation des ressources des ressources cloud ;\nVous proposez des standards d\u2019architecture et de d\u00e9veloppement ;\nVous \u00eates force de proposition, innovant(e) et bienveillant(e).\nEnvironement technique :\nSpark, Scala, Python, Java, Airflow, SQL, Google Cloud Platform (BigQuery, Cloud Storage, PubSub, Beam, Dataflow, Cloud ML, TensorFlow, Kubernetes), Git, Docker, JSON, Bash, Spotfire\nProfil recherch\u00e9 :\nVous avez minimum 5 ans d\u2019exp\u00e9rience en tant que Data Engineer ;\nVous disposez d\u2019une exp\u00e9rience en d\u00e9veloppement Spark, Scala, Python et requ\u00eatage SQL sur des gros volumes de donn\u00e9es ;\nVous avez une app\u00e9tence pour la data : validation, transformation, analyse, valorisation ;\nVous poss\u00e9dez une exp\u00e9rience de d\u00e9veloppement et orchestration de chaines ETL complexes via Airflow ou \u00e9quivalent ;\nVous pratiquez la m\u00e9thodologie agile (Agile Scrum et/ou Kanban) ;\nVous utilisez les services cloud (pr\u00e9f\u00e9rablement GCP) ;\nVous \u00eates capable d\u2019\u00e9changer en anglais technique \u00e9crit et oral.\nInformations compl\u00e9mentaires :\nVotre poste sera bas\u00e9 \u00e0 Boulogne-Billancourt (France) en CDI (temps plein)\nVous b\u00e9n\u00e9ficiez de 2 \u00e0 3 jours de t\u00e9l\u00e9travail par semaine\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "Java",
                "Scala",
                "R",
                "Go",
                "Bash"
            ],
            "DataBase": [
                "SQL"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [
                "Spark"
            ],
            "MachingLearning": [
                "TensorFlow"
            ],
            "DataSerialization": [
                "Json"
            ],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [
                "Google Cloud Platform"
            ],
            "DevTools": [
                "Git",
                "Docker"
            ],
            "Os": [],
            "DBMS": [
                "BigQuery"
            ],
            "SoftBigDataProcessing": [],
            "Automation": [
                "Kubernetes",
                "Airflow"
            ],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [
                "Docker",
                "Kubernetes"
            ],
            "Collaboration": [],
            "Other": [
                "ML",
                "Machine Learning",
                "Cloud"
            ],
            "FrSoftSkills": [],
            "EnSoftSkils": []
        },
        "details": {
            "JobDetail": [
                "Temps plein",
                "Full"
            ],
            "TypeContract": [
                "CDI"
            ],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s",
                "5",
                "5",
                "5"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "title": "Data Engineer - Internship",
        "company": "Equativ",
        "location": "Paris, \u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/data-engineer-internship-at-equativ-3821045783?position=49&pageNum=0&refId=TDTc9UZJy78L%2BED7EV%2BMrg%3D%3D&trackingId=%2FuGqbRz65o7d93Q2HdgHZQ%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "\ud83d\udc6b About the team\nAt Equativ, we\u2019re on a mission to develop advertising technologies that empower our customers to reach their digital business goals. This means that we rely on massively scalable, widely distributed, highly available, and efficient software systems; the platform deals with over 3 millions requests per second managed by 3,000 servers.\nOur innovation team based in Paris, Nantes, Limoges, Krakow and Berlin is composed of 100+ straightforward and energetic engineers working in an Agile environment and ready to tackle the most complex technical challenges.\nOur data engineering team is composed of 8 skilled engineers and is based in Paris. We are part of the R&D department which is composed of 120+ engineers spread across Paris, Nantes, Limoges, Krakow and Berlin all working in an Agile environment and ready to tackle the most complex technical challenges.\nThe data engineers are split in two sub-teams working in close collaboration:\nPipeline team: Maintaining and enhancing the operationality of our on-premise and cloud data pipelines which feed our warehouses and APIs\nFeature team: Apply best in class data modeling and orchestrating data transformations in our warehouses, leading the day-to-day management of these warehouses\nOur Mission \ud83d\udc47\nOur Data Engineering team is central to Equativ\u2019s data centric business and is responsible to ingest, transform, model and redistribute all data coming from our ad tech platform.\nWe aim at building scalable and robust Big Data platforms from ingestion to business actionable consumption. Our Big Data ecosystem must handle huge volumes (15 Tb per day), short & long term data storage, complex data modeling, real-time and batch ELT as well as providing external access through dedicated APIs.\nWe enhance and deliver Equativ data directly to our customers and throughout the company whether it is for BI analysis, data science models feeding, customer reporting, invoicing and more.\nWe rely on a top tier on-premise & cloud stack (Kafka, Flink, ClickHouse, Bigquery, Dataflow, Airflow, DBT\u2026) and work hard to increase reporting capabilities, lower maintenance time, improve performances and simplify the access to our raw data.\nWhat you'll do \u270f\ufe0f\nAs a data engineer intern, you will be supporting one of the two sub-team (pipeline or feature) in their tasks and projects:\nTake a leading part on a data engineering project such as but not limited to:\nProof of Concept of Clickhouse Cloud\nImprovement of the data transformation process with DBT, BigQuery and Airflow\nDevelopment of new functionalities on our internal tools (APIs, software applications)\nSetup a data lineage application (castor doc)\nSupport the data engineering team in their day-to-day activities:\nEnhance our DevOps process with CI/CD and testing framework\nMonitor performances and workflow of our applications using reporting tool (Grafana)\nTake part in improving and deploying data engineering standards, documentation and operational guidelines around data usage at Equativ\n\ud83d\udcaa About you\nMaster degree in Computer Science or similar technical field of study\nPrior experience in data or software development related environment is desired\nExperience with a cloud datawarehouse (BigQuery, Snowflake, Databrick,..) is a plus\nGood knowledge of SQL and one other data programming language (Java preferred, Python, Scala..).\nKnowledge on the software development process (Git, CI/CD, test, scrum)\nWorking proficiency and communication skills in verbal and written English\nStrong interest in big data and cloud computing technologies.\n\ud83d\udc4b About us\nEquativ is the new single name for Smart Adserver, DynAdmic, LiquidM and Nowtilus \u2014 four proven innovators in advertising technology. The vertically integrated company provides brand and privacy-safe solutions that empower its clients to achieve maximum impact while respecting the rights of consumers. The union combines client expertise and engineering excellence to serve the interests of both the supply- side and demand-side with equal professionalism and technical sophistication.\nHeadquartered in Paris and New York, Equativ operates globally with a team of more than 550 people in 20 offices. Equativ offers the market its own independent ad server, SSP, buyer tools, and media services to fulfill the promise of advertising technology. Learn more at Equativ.com.\nThe company is ranked on the Deloitte Technology Fast 500 EMEA and in the Financial Times\u2019 FT 1000: Europe\u2019s Fastest-Growing Companies.\nEquativ (formerly Smart AdServer) has been awarded the HappyIndex@Work label and is proud to be among the best companies in the ChooseMyCompany ranking, recognized for its flexible working environment.\nCome and lead the charge with us in building a transparent ecosystem based on quality!\nEquativ is an equal opportunity employer. Equal access to employment, services, and programs are available to everyone, regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity, or Veteran status. If you require reasonable accommodation throughout the application and/or interview process, please contact the recruitment team at ta-team@equativ.com\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "Java",
                "Scala",
                "R",
                "Go"
            ],
            "DataBase": [
                "SQL"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [
                "Flink"
            ],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [],
            "DevTools": [
                "Git"
            ],
            "Os": [],
            "DBMS": [
                "Snowflake",
                "Snowflake",
                "BigQuery"
            ],
            "SoftBigDataProcessing": [],
            "Automation": [
                "Airflow"
            ],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [
                "Teams"
            ],
            "Other": [
                "DevOps",
                "Big Data",
                "Cloud",
                "CI/CD"
            ],
            "FrSoftSkills": [
                "Communication",
                "Collaboration"
            ],
            "EnSoftSkils": [
                "Communication",
                "Collaboration"
            ]
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "title": "Data Engineer (H/F) - Lille - CDI",
        "company": "METEOJOB by CleverConnect",
        "location": "Lille, Hauts-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/data-engineer-h-f-lille-cdi-at-meteojob-by-cleverconnect-3858145866?position=50&pageNum=0&refId=TDTc9UZJy78L%2BED7EV%2BMrg%3D%3D&trackingId=Yq6xoHndecJYfbsKu%2F1jGg%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Entreprise\nChez LJE Solutions, nous pla\u00e7ons l\u2019humain au c\u0153ur de chaque projet. Au-del\u00e0 des comp\u00e9tences, nous valorisons les\naspirations\net les\nvaleurs\nde chaque individu.\nNous intervenons dans tous les secteurs d'activit\u00e9 en France et en Suisse.\nDescription Du Poste\nLJE Solutions recherche pour un de ses clients bas\u00e9 \u00e0 Lille, un/une Data Engineer.\nNotre client est une\nESN dynamique bas\u00e9e \u00e0 Lille, qui se distingue dans l'int\u00e9gration et la restitution de donn\u00e9es. Partenaire privil\u00e9gi\u00e9 de technologies de pointe comme Power BI, Tableau et Qlik, il recherche des talents d\u00e9sireux de participer \u00e0 notre aventure entrepreneuriale.\nNous recherchons un Data Engineer curieux et motiv\u00e9 pour jouer un r\u00f4le cl\u00e9 dans l'organisation et le d\u00e9veloppement de l'agence. Ce poste offre une opportunit\u00e9 unique de travailler directement avec les fondateurs, experts en technologies, et de contribuer significativement \u00e0 la formation interne et \u00e0 l'expertise chez nos clients.\nVos Responsabilit\u00e9s\nTravailler en \u00e9troite collaboration avec les fondateurs sur des projets d'int\u00e9gration et de restitution de donn\u00e9es,\nParticiper activement \u00e0 la croissance de l'entreprise en apportant des id\u00e9es innovantes et en prenant part \u00e0 des projets vari\u00e9s,\nMonter en comp\u00e9tence techniquement, avec la possibilit\u00e9 d'\u00e9voluer vers des r\u00f4les de Team Lead ou Tech Lead selon vos aspirations.\nCette entreprise offre un environnement convivial et ambitieux, encourageant la prise d'initiative. Leur structure \u00e0 taille humaine valorise chaque collaborateur, avec une approche personnalis\u00e9e et une hi\u00e9rarchie plate qui favorise l'expression et la participation active de tous.\nR\u00e9mun\u00e9ration Et Avantages\nPoste bas\u00e9 \u00e0 Lille, avec possibilit\u00e9 de t\u00e9l\u00e9travail partiel,\nR\u00e9mun\u00e9ration comp\u00e9titive bas\u00e9e sur l'exp\u00e9rience, fourchette indicative de 44k \u00e0 48k \u20ac en fixe, + variables,\nTickets restaurant,\nMutuelle d'entreprise.\nDescription Du Profil\nPassion pour les technologies de la data, avec une expertise ou un int\u00e9r\u00eat pour XDi et Talend, sans exclure d'autres ETL du march\u00e9,\nPlus de 4 ans d'exp\u00e9rience dans le domaine de la data engineering,\nCuriosit\u00e9 intellectuelle, agilit\u00e9, excellent savoir-\u00eatre, forte capacit\u00e9 de travail en \u00e9quipe et de partage de connaissances,\nLocalisation \u00e0 Lille ou disposition \u00e0 d\u00e9m\u00e9nager, avec une pr\u00e9f\u00e9rence pour les candidats de la r\u00e9gion pour faciliter la collaboration et le partage au sein de notre agence physique.\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "R"
            ],
            "DataBase": [],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [
                "Tableau",
                "Power BI"
            ],
            "Statistics": [],
            "CloudComputing": [],
            "DevTools": [],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [],
            "FrSoftSkills": [
                "Collaboration",
                "Organisation"
            ],
            "EnSoftSkils": [
                "Collaboration",
                "Initiative"
            ]
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s",
                "4",
                "4",
                "4"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "title": "Data Engineer",
        "company": "Digital Waffle",
        "location": "Paris, \u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/data-engineer-at-digital-waffle-3913824888?position=51&pageNum=0&refId=TDTc9UZJy78L%2BED7EV%2BMrg%3D%3D&trackingId=8uQpOuoHSTAxlgIAc6XcKw%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Digital Waffle is proud to have partnered with an innovative tech startup in Paris, who are looking for a talented Data Engineer to join their growing team!\nThey are made up of a powerhouse of experts, combining\ndata engineers, business process gurus, and Project managers\nwho leverage the most advanced solutions available; utilising process mining, automation tools, and smart execution systems.\nLooking for an experienced Data Engineer (3-5 years)\nWhat You'll Do:\nThis is a full-time,\nhybrid role (Paris-based)\nwhere you'll wear many hats: data exploration, system integration, data prep, data modeling, and implementing data solutions.\nExperience:\nExpertise in data engineering, data modeling, and ETL (Extract, Transform, Load) processes\nData warehousing and data analytics skills\nExperience handling large, complex datasets\nProficiency in SQL and programming languages like Python or Java\nStellar problem-solving and analytical skills\nTop-notch communication and collaboration abilities\nBachelor's or Master's in Computer Science, Information Systems, or a similar field (a plus for process mining or intelligent process automation experience)\nIf you are an experienced and driven Data Engineer, please apply here!\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "Java",
                "R"
            ],
            "DataBase": [
                "SQL"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [],
            "DevTools": [
                "Git"
            ],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [],
            "FrSoftSkills": [
                "Communication",
                "Collaboration"
            ],
            "EnSoftSkils": [
                "Communication",
                "Collaboration"
            ]
        },
        "details": {
            "JobDetail": [
                "Full"
            ],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "title": "Data Engineer H/F",
        "company": "Ippon Technologies",
        "location": "Greater Nantes Metropolitan Area",
        "link": "https://fr.linkedin.com/jobs/view/data-engineer-h-f-at-ippon-technologies-3902436649?position=52&pageNum=0&refId=TDTc9UZJy78L%2BED7EV%2BMrg%3D%3D&trackingId=DqSfWwLB6EnRE5u%2BjZ6DkA%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Envie de rejoindre la communaut\u00e9 DATA la plus dynamique de France ?\nNotre sp\u00e9cialit\u00e9 est de construire des data platform dans le Cloud public avec les meilleurs technos du moment : Snowflake, Databricks, Matillion, DBT.\nMembre de la Practice Data, le/la futur(e) Data Engineer sera int\u00e9gr\u00e9(e) \u00e0 nos \u00e9quipes de conseil et sera suivi(e) par un(e) mentor qui l\u2019aidera \u00e0 monter en comp\u00e9tences.\nVotre champs d\u2019expertise :\nIntervenir sur les data platforms de nos clients pour d\u00e9velopper de nouveaux pipelines de donn\u00e9es (ingestion, traitement, exposition).\nTravailler en collaboration avec les m\u00e9tiers et les data scientists pour leur fournir un support \u00e0 l\u2019industrialisation de leurs travaux (tests, int\u00e9gration continue, scalabilit\u00e9 des mod\u00e8les, craftsmanship etc\u2026)\nD\u00e9ployer des infrastructures cloud full\ninfra-as-code\n(Terraform, CloudFormation).\nParticiper aux \u00e9v\u00e8nements internes \u00e0 la communaut\u00e9 data (BBL, webinar, datap\u00e9ro interne, meetup, blog, dojos) et externes (Salon du Big Data, GCP Summit, Spark Summit, AWS Summit, Devoxx, workshop partenaire, meetups).\nCapitaliser sur les missions et les diff\u00e9rents \u00e9v\u00e8nements de la communaut\u00e9 au travers d\u2019articles de blogs, REX, BBL interne.\nVos connaissances :\nUn framework de calcul distribu\u00e9 tel que Spark, Storm, Flink.\nUn ou plusieurs langages de programmation (Python, Scala, Java...)\nDiff\u00e9rents syst\u00e8mes de stockage de donn\u00e9es (SQL ou NoSQL) et bien s\u00fbr le langage SQL.\nLa connaissance de Snowflake est bienvenue ;-)\nUn framework de streaming de donn\u00e9es tel que Kafka ou Amazon Kinesis.\nUne exp\u00e9rience sur les technologies Cloud : AWS, GCP, Azure\nLe delivery et les projets en production faisant partie de notre ADN, vous \u00eates capable de livrer du code de qualit\u00e9 dans des environnements agiles.\nDe plus en plus de nos projets se font en remote avec des clients du monde entier, il devient n\u00e9cessaire d\u2019\u00eatre \u00e0 l\u2019aise en Anglais.\nIppon technologies c\u2019est aussi :\n\ud83d\udc4d B\u00e9n\u00e9ficier d'un suivi de proximit\u00e9 r\u00e9alis\u00e9 par votre manager technique : points r\u00e9guliers pour votre suivi en mission, votre formation et votre \u00e9volution de carri\u00e8re\n\u270c\ufe0f Rejoindre une entreprise o\u00f9 les valeurs du sport sont nos leitmotiv : d\u00e9passement de soi, travail en \u00e9quipe, bienveillance.\n\ud83d\uddd2\ufe0f Apprendre via notre programme de formation BlackBelt : https://bit.ly/3ByqcIL\n\ud83d\ude01 Travailler en pair programming ou avec un.e mentor pour gravir les \u00e9chelons !\n\ud83d\udcaa Pouvoir participer \u00e0 une aventure humaine au sein de notre Fondation Ippon pour r\u00e9duire la fracture num\u00e9rique dans le monde !\n\ud83e\udd1d Participer \u00e0 nos ap\u00e9ros et divers \u00e9v\u00e8nements internes pour consolider la coh\u00e9sion d\u2019\u00e9quipe\nEt apr\u00e8s ?\nEt oui alors ? Que se passe-t-il une fois que vous \u00eates convaincu d\u2019avoir lu l\u2019offre d\u2019emploi qui vous correspond bien ?\nNous vous proposons de prendre contact et de nous rencontrer !\nLes Next Steps :\n1 call RH\n1 \u00e9change RH\n1 \u00e9change Technique\nSi le match est bon des deux c\u00f4t\u00e9s : Hadjim\u00e9 ! Vous vous lancerez sur le tatami Ippon !\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "Java",
                "Scala",
                "R"
            ],
            "DataBase": [
                "SQL",
                "NoSQL"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [
                "Spark",
                "Databricks",
                "Flink"
            ],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [
                "AWS",
                "Azure"
            ],
            "DevTools": [],
            "Os": [],
            "DBMS": [
                "Snowflake",
                "Snowflake"
            ],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [
                "Terraform",
                "CloudFormation"
            ],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [
                "Big Data",
                "Cloud"
            ],
            "FrSoftSkills": [
                "Collaboration"
            ],
            "EnSoftSkils": [
                "Collaboration"
            ]
        },
        "details": {
            "JobDetail": [
                "Remote",
                "Full"
            ],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "title": "Data Engineer \u2013 Antibes, France (H/F)",
        "company": "Astek",
        "location": "Antibes, Provence-Alpes-C\u00f4te d'Azur, France",
        "link": "https://fr.linkedin.com/jobs/view/data-engineer-%E2%80%93-antibes-france-h-f-at-astek-3909192086?position=53&pageNum=0&refId=TDTc9UZJy78L%2BED7EV%2BMrg%3D%3D&trackingId=ln5VxaOXXVRJsDTyWf0TrQ%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "CDI\nAntibes - France\nPubli\u00e9e il y a 2 semaines\nLe Groupe Astek\nCe Que Nous Allons Accomplir Ensemble :\nIntervenir dans la conception, le d\u00e9veloppement, les tests unitaires, la qualification, l\u2019int\u00e9gration continue et la mise en production d\u2019\u00e9volutions sur les projets du p\u00f4le produits scoring (un p\u00f4le visant \u00e0 d\u00e9velopper des solutions permettant de g\u00e9n\u00e9rer des scores ou des segments d\u2019information pertinents dans divers domaines, notamment : profiling TV, PUB, SAB, MMDM, Voscastview) chez l\u2019un de nos partenaires sp\u00e9cialis\u00e9 dans le secteur des t\u00e9l\u00e9coms.\nVotre Mission, Si Vous L\u2019acceptez :\nEn collaboration avec les autres membres de l\u2019\u00e9quipe, vous devrez prendre en charge le RUN des applications du p\u00f4le produit scoring.\nConception d\u2019une solution se basant sur les d\u00e9veloppements existants et les besoins m\u00e9tiers remont\u00e9s par le Product Owner.\nR\u00e9alisation et d\u00e9veloppement de nouvelles fonctionnalit\u00e9s sur les composants des applications du p\u00f4le produits scoring et environnement CGP.\nVotre Future \u00c9quipe :\nAu sein d\u2019un environnement riche et complexe, vous \u00e9voluerez avec des experts passionn\u00e9s \u00e0 la fois techniques et fonctionnels (Ing\u00e9nieurs sp\u00e9cialis\u00e9s, chef de projet, scrum master, product owner, analystes \u2026).\nVotre stack de jeu\nD ans un environnement SAFE sous cloud GCP, Big Query, OnPrime, Grafana, Python et Ansible.\nVous ?\nDe formation Ing\u00e9nieur, vous justifiez d\u2019une premi\u00e8re exp\u00e9rience sur un poste de Data engineer. Vous poss\u00e9dez des comp\u00e9tences d\u2019autonomie et d\u2019adaptabilit\u00e9 et vous avez une capacit\u00e9 \u00e0 communiquer efficacement au sein d\u2019une \u00e9quipe.\nLe Groupe Astek\nCr\u00e9\u00e9 en France en 1988, Astek est un acteur mondial de l\u2019ing\u00e9nierie et du conseil en technologies. Fort de son expertise dans de nombreux secteurs industriels et tertiaires, Astek accompagne ses clients internationaux dans le d\u00e9ploiement intelligent de leurs produits et de leurs services, et dans la mise en \u0153uvre de leur transformation digitale.\nDepuis sa cr\u00e9ation, le Groupe a fond\u00e9 son d\u00e9veloppement sur une forte culture d\u2019entrepreneuriat et d\u2019innovation, et sur l\u2019accompagnement et la mont\u00e9e en comp\u00e9tence de\nses 7800 collaborateurs\nqui s\u2019engagent chaque jour \u00e0 promouvoir la compl\u00e9mentarit\u00e9 entre les technologies num\u00e9riques et l\u2019ing\u00e9nierie des syst\u00e8mes complexes.\nRejoignez un Groupe en fort d\u00e9veloppement en France et \u00e0 travers le monde ayant r\u00e9alis\u00e9 un chiffre d\u2019affaires de 600 M\u20ac en 2023.\nTous les d\u00e9tails sur le Groupe sur le site https://astekgroup.fr. Et vous pouvez aussi nous suivre sur notre blog : https://blog.groupeastek.com.\nRencontrons-nous\nCr\u00e9\u00e9 en France en 1988, Astek est un acteur mondial de l\u2019ing\u00e9nierie et du conseil en technologies, pr\u00e9sent sur les 5 continents. Fort de son expertise dans de nombreux secteurs industriels et tertiaires, Astek accompagne ses clients internationaux dans le d\u00e9ploiement intelligent de leurs produits et de leurs services, et dans la mise en \u0153uvre de leur transformation digitale.\nDepuis sa cr\u00e9ation, le Groupe a fond\u00e9 son d\u00e9veloppement sur une forte culture d\u2019entrepreneuriat et d\u2019innovation, et sur l\u2019accompagnement et la mont\u00e9e en comp\u00e9tence de ses 7800 collaborateurs qui s\u2019engagent chaque jour \u00e0 promouvoir la compl\u00e9mentarit\u00e9 entre les technologies num\u00e9riques et l\u2019ing\u00e9nierie des syst\u00e8mes complexes.\nRejoignez un Groupe en fort d\u00e9veloppement en France et \u00e0 travers le monde et ayant r\u00e9alis\u00e9 un chiffre d\u2019affaires hors\nacquisitions de 600M\u20ac en 2023.\nTous les d\u00e9tails sur le Groupe sur le site\nNos Plus\nAstek est green et fait b\u00e9n\u00e9ficier ses salari\u00e9s d\u2019une indemnit\u00e9 kilom\u00e9trique v\u00e9lo\nUne politique CARE sur-mesure d\u00e9ploy\u00e9e par nos \u00e9quipes RH pour nos collaborateurs (https://astekgroup.fr/engagements)\nNotre charte de la Diversit\u00e9\nMots-cl\u00e9s :\ning\u00e9nieur \u2013 ing\u00e9nieure \u2013 consultant \u2013 consultante \u2013 Data engineer \u2013 Big Data\nCaract\u00e9ristiques de l'emploi\nCat\u00e9gorie Ing\u00e9nieur\nJob Industry T\u00e9l\u00e9com / M\u00e9dia\nPostuler en ligne\nNom *\nPr\u00e9nom *\nEmail *\nUn email valide est requis.\nT\u00e9l\u00e9phone *\nUn num\u00e9ro de t\u00e9l\u00e9phone valide est requis.\nJoindre un CV *\nMots-cl\u00e9s :\ning\u00e9nieur \u2013 ing\u00e9nieure \u2013 consultant \u2013 consultante \u2013 Data engineer \u2013 Big Data\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "R",
                "Go"
            ],
            "DataBase": [],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [],
            "DevTools": [
                "Git"
            ],
            "Os": [],
            "DBMS": [
                "Big Query"
            ],
            "SoftBigDataProcessing": [],
            "Automation": [
                "Ansible",
                "Chef"
            ],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [
                "Big Data",
                "Cloud"
            ],
            "FrSoftSkills": [
                "Adaptabilit\u00e9",
                "Collaboration"
            ],
            "EnSoftSkils": [
                "Collaboration"
            ]
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [
                "CDI"
            ],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "title": "Data Engineer - Profils exp\u00e9riment\u00e9s H/F",
        "company": "LCL",
        "location": "Villejuif, \u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/data-engineer-profils-exp%C3%A9riment%C3%A9s-h-f-at-lcl-3888403052?position=54&pageNum=0&refId=TDTc9UZJy78L%2BED7EV%2BMrg%3D%3D&trackingId=B2xAp1M9k1B%2FmH5%2FSOf%2BVg%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "\ud83c\udfe6 LCL, c\u2019est LA banque urbaine du Groupe Cr\u00e9dit Agricole - avec nous, accompagnez la transformation, le d\u00e9veloppement et le maintien technologiques de nos outils avec une vision business et de satisfaction de nos 6 millions de clients.\nEn tant qu\u2019acteur majeur de la banque de d\u00e9tail, nous nous adaptons chaque jour aux nouveaux modes de consommation et les projets de nos de clients internes et externes tout en garantissant le besoin de s\u00e9curit\u00e9 et de d\u00e9veloppement technologique qu\u2019impliquent nos activit\u00e9s.\n\ud83d\udca1Organis\u00e9es en mode Agile, les 8 squads de la tribu DATA (6 squads M\u00e9tier et 2 squads transverses) \u0153uvrent au quotidien pour r\u00e9pondre \u00e0 un enjeu majeur pour la banque : la collecte, le stockage, la gestion et l\u2019usage de la donn\u00e9e. En interaction permanente avec les autres tribus IT et les m\u00e9tiers, elles \u00e9tudient et proposent les solutions et architectures \u00e0 d\u00e9ployer pour r\u00e9pondre au mieux aux strat\u00e9gies de d\u00e9veloppement et de pilotage de l\u2019ensemble des m\u00e9tiers de la banque.\nRejoignez-nous si vous souhaitez participer aux r\u00e9flexions et au d\u00e9veloppement de la trajectoire technique et DataCentric du SI LCL et plus largement du Groupe CA. Vous c\u00f4toierez et serez au c\u0153ur de l\u2019impl\u00e9mentation de technologies vari\u00e9es telles que les plateformes Teradata, les solutions d\u2019architecture applicative des technologies BigData ou IA, des environnements analytiques ou encore des solutions de datavisualisation. Vous assurerez le traitement de donn\u00e9es en temps r\u00e9el ou en batch et exposerez les donn\u00e9es sous diff\u00e9rentes formes.\nQue vous souhaitiez devenir expert sur les socles technologiques ou relever le challenge de la gestion de projets M\u00e9tier, nous vous aiderons \u00e0 atteindre vos propres objectifs.\nVous rejoindrez une \u00e9quipe pluridisciplinaire, clairement orient\u00e9e vers le d\u00e9veloppement de ses collaborateurs \u00e0 de nouvelles technologies !\n\ud83c\udfaf En tant que Data Engineer :\n\u00b7 Vous aimez analyser les besoins avec les m\u00e9tiers, challenger, identifier les sources de donn\u00e9es dans les diff\u00e9rents univers technologiques, industrialiser des algorithmes, concevoir et d\u00e9velopper des Datalab ou des Datamart sur les plateformes ? Vous saurez relever les challenges propos\u00e9s par les squads m\u00e9tier !\n\u00b7 Vous pr\u00e9f\u00e9rez travailler \u00e0 l\u2019architecture et au d\u00e9ploiement de nouvelles plateformes, \u00e0 la lev\u00e9e de la dette technologique ou encore r\u00e9aliser de la veille au service de notre trajectoire ? La squad Socles Data est faite pour vous !\n\u00b7 Au-del\u00e0 des projets que vous g\u00e9rerez, garant du bon fonctionnement de votre parc applicatif, vous attacherez une grande attention \u00e0 la mise en \u0153uvre de solutions optimis\u00e9es.\n\u00b7 La rigueur, la communication, l\u2019esprit d\u2019\u00e9quipe mais aussi la curiosit\u00e9 et la cr\u00e9ativit\u00e9 font partie de vos soft skills ! ils vous permettront de r\u00e9pondre aux enjeux de s\u00e9curit\u00e9, de qualit\u00e9, de transmission de la connaissance et contribueront \u00e0 l\u2019atteinte des objectifs de l\u2019IT et plus largement de LCL, au service de ses clients.\n\ud83d\udcbb Voici les principales technologies utilis\u00e9es au sein de la tribu, si certaines vous sont famili\u00e8res, nous vous aiderons \u00e0 monter en comp\u00e9tence sur d\u2019autres !\nLangages utilis\u00e9s : SQL, Python, Scala\nSGBD : Teradata et utilitaires (TPT, BTEQ, \u2026)\nStreaming : Kafka\nSearch : ElasticSearch, SolR\nEnvironnement : Unix\nSolutions Big Data : Hadoop Cloudera, DataIku, HDFS, Hive, Impala,\nDevops : GitLab, Jenkins, Nexus\nOutils de visualisation : MS BI (SSIS, SSAS, SSRS) Qlik Sens, BO\nMod\u00e9lisation : MEGA\nOutils collaboratifs : GIT, Jira, Confluence, Teams\n\u26a1Si les nouveaux enjeux bancaires vous int\u00e9ressent, que vous souhaitez int\u00e9grer une \u00e9quipe Agile au service des m\u00e9tiers dans laquelle vous serez force de proposition et que vous aimez travailler dans un environnement motivant et dynamique, rejoignez-nous, cette offre est faite pour vous !\n\ud83d\udd25 Les + de notre entreprise :\nAcc\u00e8s au Plan d\u2019\u00e9pargne Groupe, int\u00e9ressement et participation aux b\u00e9n\u00e9fices de l\u2019entreprise + abondement\nPrix pr\u00e9f\u00e9rentiels bancaires et avantages CSE\nParcours \u00e9volutif dans l\u2019entreprise et/ou dans le Groupe CA.S.A\nT\u00e9l\u00e9travail (jusqu'\u00e0 2 jours de t\u00e9l\u00e9travail par semaine)\nDe multiples commodit\u00e9s sur le campus (restaurants d'entreprise, salle de sport, cr\u00e8che, centre m\u00e9dical, m\u00e9diath\u00e8que...)\nForfait et avantages pratiques \u00ab mobilit\u00e9 durable \u00bb pour les velotafeurs\nDes \u00e9quipes aussi diversifi\u00e9es que structur\u00e9es dans une dynamique de transformation\nLCL s\u2019engage en faveur de la diversit\u00e9 et nous encourageons tout(e) candidat(e) ayant l\u2019exp\u00e9rience requise \u00e0 postuler \u00e0 nos offres. Tous nos postes sont ouverts aux personnes en situation de handicap.\nNous avons encore de nombreuses raisons \u00e0 vous pr\u00e9senter pour vous convaincre de nous rejoindre mais pour cela, il faudra postuler ici !\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "Scala",
                "R",
                "Go"
            ],
            "DataBase": [
                "SQL",
                "Elasticsearch"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [
                "Hadoop"
            ],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [],
            "DevTools": [
                "Git",
                "Jenkins"
            ],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [
                "JIRA",
                "Confluence",
                "Teams"
            ],
            "Other": [
                "DevOps",
                "Big Data",
                "Cloud"
            ],
            "FrSoftSkills": [
                "Communication",
                "Cr\u00e9ativit\u00e9"
            ],
            "EnSoftSkils": [
                "Communication"
            ]
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "title": "Big Data Engineer Confirm\u00e9 \u2013 Paris, France (H/F)",
        "company": "Astek",
        "location": "Paris, \u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/big-data-engineer-confirm%C3%A9-%E2%80%93-paris-france-h-f-at-astek-3839098103?position=55&pageNum=0&refId=TDTc9UZJy78L%2BED7EV%2BMrg%3D%3D&trackingId=Zls1eavoxiIyF27%2BQNvkaw%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "CDI\nParis - France\nPubli\u00e9e il y a 2 mois\nLe Groupe Astek\nCe Que Nous Allons Accomplir Ensemble :\nNous rejoindre en tant que\nBig Data Engineer Confirm\u00e9 (H/F),\nafin d\u2019accompagner un op\u00e9rateur t\u00e9l\u00e9coms, Leader en Europe dans l\u2019assistance et le support applicatif de niveau 3 (r\u00e9solution des probl\u00e8mes utilisateurs, exploitation des environnements hors production).\nUn challenge portant sur des millions d\u2019utilisateurs dans un environnement technique innovant, strat\u00e9gique et o\u00f9 l\u2019entraide et la bonne humeur priment !\nVotre Mission, Si Vous L\u2019acceptez :\nSupervision et d\u00e9tection et r\u00e9solution des probl\u00e8mes utilisateurs (d\u00e9veloppeurs, exploitants et data exploreurs)\nD\u00e9veloppement de solutions de self-service ou d\u2019une solution de r\u00e9solutions automatiques des probl\u00e8mes\nQualifier les donn\u00e9es et les r\u00e9sultats\nConception technique des solutions\nAssurer l\u2019accompagnement et le d\u00e9ploiement des \u00e9volutions des processus et outils\nAccompagner la phase de mise en production\nVotre Future \u00c9quipe :\nVous int\u00e9grerez une \u00e9quipe \u00e0 la fois technique et fonctionnel, qui \u0153uvre chaque jour pour d\u00e9velopper et maintenir en conditions op\u00e9rationnelles l\u2019ensemble des solutions IT !\nL\u2019\u00e9quipe est en interaction avec des clients \u00e0 la fois internes et externes.\nVotre stack de jeu\nSyst\u00e8me d\u2019exploitation : Linux\nOutils des distributions : HDP, HDF, ELK\nEnvironnement Big data : Hadoop, Spark,\nLangage : Scala, Shell, Python\nCloud computing : GCP ou AWS\nBase de donn\u00e9es : No SQL (Cassandra, Mongo DB), Shell, Ansible\nDataviz : Power BI ou Kibana\nDes notions en R\u00e9seau et Syst\u00e8mes feront la diff\u00e9rence !\nLes Petits Plus Du Projet :\nVous \u00e9voluerez au sein d\u2019une \u00e9quipe impliqu\u00e9e et r\u00e9active et interviendrez sur un projet polyvalent et \u00e0 forte valeur ajout\u00e9e.\nVous ?\nDipl\u00f4m\u00e9(e) d\u2019une \u00e9cole d\u2019ing\u00e9nieur ou \u00e9quivalent de niveau Bac+5.\nVous justifiez id\u00e9alement d\u2019une exp\u00e9rience d\u2019au moins 3 ans d\u2019exp\u00e9riences sur un poste similaire ?\nVous faite preuve de proactivit\u00e9 et d\u2019esprit d\u2019\u00e9quipe, \u00eates dot\u00e9(e) d\u2019un excellent sens de l\u2019organisation et vous aimez les challenges et la r\u00e9solution de probl\u00e8me ?\nAlors ce poste est fait pour vous, n\u2019h\u00e9sitez plus et rejoignez l\u2019aventure ASTEK !\nAstek\nCr\u00e9\u00e9 en France en 1988, Astek est un acteur mondial de l\u2019ing\u00e9nierie et du conseil en technologies. Fort de son expertise dans de nombreux secteurs industriels et tertiaires, Astek accompagne ses clients internationaux dans le d\u00e9ploiement intelligent de leurs produits et de leurs services, et dans la mise en \u0153uvre de leur transformation digitale.\nDepuis sa cr\u00e9ation, le Groupe a fond\u00e9 son d\u00e9veloppement sur une forte culture d\u2019entrepreneuriat et d\u2019innovation, et sur l\u2019accompagnement et la mont\u00e9e en comp\u00e9tence de\nses 7800 collaborateurs\nqui s\u2019engagent chaque jour \u00e0 promouvoir la compl\u00e9mentarit\u00e9 entre les technologies num\u00e9riques et l\u2019ing\u00e9nierie des syst\u00e8mes complexes.\nRejoignez un Groupe en fort d\u00e9veloppement en France et \u00e0 travers le monde ayant r\u00e9alis\u00e9 un chiffre d\u2019affaires de 600 M\u20ac en 2023.\nTous les d\u00e9tails sur le Groupe sur le site https://astekgroup.fr. Et vous pouvez aussi nous suivre sur notre blog : https://blog.groupeastek.com.\nRencontrons-nous\nNotre projet commun vous plait ?\nPostulez \u00e0 cette annonce, et soyez transparent !\nMaud, notre Talent Acquisition Referent, vous contactera pour un premier \u00e9change.\nPuis vous rencontrerez Martin, votre futur manager, avec lequel vous \u00e9changerez autour d\u2019Astek, de votre parcours, de vos attentes et de votre future mission .\nEnfin, vous rencontrerez J\u00e9r\u00e9my, notre Directeur d\u2019agence avec lequel vous pourrez valider votre int\u00e9r\u00eat et ad\u00e9quation pour le poste et finaliser les \u00e9l\u00e9ments contractuels.\nNos Plus\nAstek est green et fait b\u00e9n\u00e9ficier ses salari\u00e9s d\u2019une indemnit\u00e9 kilom\u00e9trique v\u00e9lo\nUne politique CARE sur-mesure d\u00e9ploy\u00e9e par nos \u00e9quipes RH pour nos collaborateurs (https://astekgroup.fr/engagements)\nNotre charte de la Diversit\u00e9\nMots-cl\u00e9s :\ning\u00e9nieur \u2013 ing\u00e9nieure \u2013 consultant \u2013 consultante \u2013 Hadoop \u2013 Scala \u2013 Data\nCaract\u00e9ristiques de l'emploi\nCat\u00e9gorie Ing\u00e9nieur\nJob Industry T\u00e9l\u00e9com / M\u00e9dia\nPostuler en ligne\nNom *\nPr\u00e9nom *\nEmail *\nUn email valide est requis.\nT\u00e9l\u00e9phone *\nUn num\u00e9ro de t\u00e9l\u00e9phone valide est requis.\nJoindre un CV *\nMots-cl\u00e9s :\ning\u00e9nieur \u2013 ing\u00e9nieure \u2013 consultant \u2013 consultante \u2013 Hadoop \u2013 Scala \u2013 Data\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "Scala",
                "R",
                "Go"
            ],
            "DataBase": [
                "SQL",
                "Cassandra"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [
                "Hadoop",
                "Spark"
            ],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [
                "Power BI"
            ],
            "Statistics": [],
            "CloudComputing": [
                "AWS"
            ],
            "DevTools": [
                "Git"
            ],
            "Os": [
                "Linux"
            ],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [
                "Ansible"
            ],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [
                "Big Data",
                "Cloud"
            ],
            "FrSoftSkills": [
                "Organisation"
            ],
            "EnSoftSkils": []
        },
        "details": {
            "JobDetail": [
                "Confirm\u00e9"
            ],
            "TypeContract": [
                "CDI"
            ],
            "Salary": [],
            "Level": [
                "Bac+5"
            ],
            "Experience": [
                "a",
                "n",
                "s",
                "3",
                "3",
                "3"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "title": "Data Engineer (H/F) - Lille",
        "company": "Logic@l Conseils",
        "location": "Lille, Hauts-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/data-engineer-h-f-lille-at-logic%40l-conseils-3811575649?position=56&pageNum=0&refId=TDTc9UZJy78L%2BED7EV%2BMrg%3D%3D&trackingId=dy9XohBb6wp2uWIn1KF0hw%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Dans le cadre du d\u00e9veloppement de nos activit\u00e9s sur la m\u00e9tropole Lilloise, nous recherchons un\nconsultant data engineer\n(H/F) pour intervenir chez l'un de nos grands comptes clients.\nVos missions :\nRecueillir\nles besoins m\u00e9tiers et des \u00e9quipes data\nConcevoir et mettre en place les\ntraitements de donn\u00e9es\nR\u00e9aliser les\ntests de validation\nAssurer\nl\u2019alimentation du dataware\nR\u00e9aliser les\nordonnancements des traitements\nEtre garant de la\nmise en place\n, du\nsuivi\net de l\u2019\nexploitation\ndes outils d\u00e9ploy\u00e9s\nAssurer\nune veille technologique\nr\u00e9guli\u00e8re\nEnvironnement technique :\nD\u00e9veloppement :\nPython, Scala, R, Java,\nFramework :\nSpark,\nHadoop,\nOutils Big data :\nYarn, Pig, Hive, Kafka, Splunk\nBases de donn\u00e9es :\nMongoDB, HBase, Cassandra\nETL :\nTalend, Stambia\nPlateforme :\nHortonworks, Cloudera, Map Reduce\n,\nAWS, GCP, Azure\nVotre profil :\nVous disposez d\u2019une exp\u00e9rience\nd\u2019au moins 2 ans en tant que data engineer\nou dans le domaine de l\u2019analyse et du traitement de donn\u00e9es.\nV\u00e9ritable\npassionn\u00e9 de la data\n, vous \u00eates\nforce de proposition\nsur les solutions techniques \u00e0 mettre en \u0153uvre. Vous maitrisez l\u2019anglais dans un contexte professionnel.\nComp\u00e9tences requises :\nAnalyses qualitatives et quantitatives (Interm\u00e9diaire)\nAnglais (Interm\u00e9diaire)\nArchitecture fonctionnelle SI (D\u00e9butant)\nD\u00e9veloppement d'ouvrages, produits ou \u00e9v\u00e9nements (D\u00e9butant)\nGestion des contr\u00f4les, tests et diagnostics (D\u00e9butant)\nGestion des risques (Interm\u00e9diaire)\nMa\u00eetrise des logiciels (Interm\u00e9diaire)\nMise en exploitation / Production et maintenance (D\u00e9butant)\nNos valeurs\nNous avons d\u00e9cid\u00e9 de renverser la pyramide du management pour placer nos collaborateurs en t\u00eate des priorit\u00e9s de l\u2019entreprise.\nEn effet, attach\u00e9 \u00e0 des valeurs fortes, telles que la proximit\u00e9, la sinc\u00e9rit\u00e9, la fid\u00e9lit\u00e9, la confiance et le respect, nous sommes persuad\u00e9s que la r\u00e9ussite r\u00e9side dans le bien-\u00eatre de nos collaborateurs.\nCela se traduit par un accompagnement de proximit\u00e9, de la transparence sans langue de bois, des \u00e9changes r\u00e9guliers avec les managers r\u00e9f\u00e9rents, un accompagnement dans le d\u00e9veloppement de carri\u00e8re qui est construit et jalonn\u00e9 avec les formations et certifications n\u00e9cessaires et les missions en ad\u00e9quation, pour mener \u00e0 bien l\u2019\u00e9volution de carri\u00e8re.\nPour vous convaincre de nous rejoindre, nos avantages salari\u00e9s compl\u00e9mentaires :\nEnvironnement bienveillant et stimulant au sein de 3 p\u00f4les d\u2019expertises\nFormations et Certifications \u00e0 la demande\nTickets restaurants : 13\u20ac par ticket\nRemboursement \u00e0 100 % des abonnements de transports en commun\nMutuelle frais de sant\u00e9 avec de hautes garanties\nPrise en charge \u00e0 100% de l\u2019assurance Pr\u00e9voyance\nCh\u00e8que Cadeau Culture 120 \u20ac\nCompte CSE avec une cagnotte de 390 \u20ac\nCompte CE : billetterie, voyages, culture, sorties, \u00e0 des tarifs pr\u00e9f\u00e9rentiels\nDes \u00e9v\u00e8nements chaque mois : activit\u00e9s associatives, sportives, afterwork, s\u00e9minaire,\nPartenariat Losc (participation aux match dans la loge VIP logical conseils \u2013 (Une Vingtaine de match par an)\nPossibilit\u00e9 de t\u00e9l\u00e9travail\nEn int\u00e9grant Logic@l Conseils, vous participez \u00e0 une r\u00e9elle aventure humaine, alors pour postuler, il suffit de cliquer ci-dessous !\nTous nos postes sont ouverts, \u00e0 comp\u00e9tences \u00e9gales, aux personnes en situation de handicap.\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "Java",
                "Scala",
                "R",
                "Go"
            ],
            "DataBase": [
                "Cassandra",
                "HBase"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [
                "Hadoop",
                "Spark"
            ],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [
                "AWS",
                "Azure"
            ],
            "DevTools": [],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [
                "HBase"
            ],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [
                "Big Data",
                "Cloud"
            ],
            "FrSoftSkills": [],
            "EnSoftSkils": []
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s",
                "2",
                "2",
                "2"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "title": "Data Engineer",
        "company": "CGI",
        "location": "Niort, Nouvelle-Aquitaine, France",
        "link": "https://fr.linkedin.com/jobs/view/data-engineer-at-cgi-3902057928?position=57&pageNum=0&refId=TDTc9UZJy78L%2BED7EV%2BMrg%3D%3D&trackingId=nya1Wu5YHzOoOY6TKfTIXA%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Description de poste\nBig Data, Data Science, Data analyse, Data architecture ... \u00c7a n\u2019a pas de secret pour vous ?\nQue vous commenciez votre carri\u00e8re professionnelle ou que vous soyez sp\u00e9cialiste de l\u2019une de ces disciplines, int\u00e9grer notre communaut\u00e9 Data, c\u2019est l\u2019assurance de progresser, innover, partager, vous certifier et rendre service \u00e0 nos clients.\nSi vous souhaitez int\u00e9grer nos \u00e9quipes \u00e0 Niort et accompagner les plus grands acteurs du secteur des Assurances, cette annonce est susceptible de vous int\u00e9resser.\nEn tant que Data Engineer, vous serez responsable de la conception, du d\u00e9veloppement, de la gestion et de l'int\u00e9gration des syst\u00e8mes bas\u00e9s sur les technologies AWS, Terraform, OpenShift, Kafka et Hadoop. Ce r\u00f4le implique la mise en place d'architectures \u00e9volutives et hautement disponibles pour r\u00e9pondre aux besoins de traitement et de stockage de donn\u00e9es de l'entreprise.\nFonctions et responsabilit\u00e9s\nVos responsabilit\u00e9s seront les suivantes:\n-Maintenir et d\u00e9velopper des solutions bas\u00e9es sur les services AWS pour le stockage, le traitement et l'analyse de donn\u00e9es\n-Utiliser les services AWS appropri\u00e9s tels que Amazon EC2, S3, RDS, Lambda, etc., pour r\u00e9pondre aux exigences du projet.\n-Cr\u00e9er et maintenir les configurations Terraform pour la gestion de l'infrastructure en tant que code (IaC) sur AWS\n-Participer \u00e0 la maintenance et \u00e0 la mise en place d'environnements OpenShift pour l'h\u00e9bergement d'applications et de services\n-G\u00e9rer et administrer les clusters Kafka pour garantir la disponibilit\u00e9, la performance et la s\u00e9curit\u00e9 du syst\u00e8me de messagerie\nParticiper \u00e0 l\u2019assistance utilisateurs sur les briques de la plateforme Hadoop Cloudera Data\n-Travailler avec les projets et les devOps pour assurer un traitement efficace des donn\u00e9es\nEn rejoignant CGI, vous b\u00e9n\u00e9ficiez notamment d\u2019une offre compl\u00e8te de formations (techniques, m\u00e9tiers, d\u00e9veloppement personnel,\u2026), de flexibilit\u00e9 gr\u00e2ce \u00e0 notre accord t\u00e9l\u00e9travail (jusqu\u2019\u00e0 3 jours de t\u00e9l\u00e9travail par semaine), d\u2019une politique de cong\u00e9s avantageuse (27 jours de cong\u00e9s pay\u00e9s, RTT, cong\u00e9s anciennet\u00e9 et enfant malade,\u2026) et d\u2019un package d\u2019avantages int\u00e9ressant (r\u00e9gime d\u2019achats d\u2019actions, participation, CSE,...).\nQualit\u00e9s requises pour r\u00e9ussir dans ce r\u00f4le\nAyant une premi\u00e8re exp\u00e9rience en tant que Data Engineer, vous avez une premi\u00e8re exp\u00e9rience relative aux points suivants:\n-D\u00e9veloppement et int\u00e9gration sur les technologies AWS, Terraform, OpenShift, Kafka et Hadoop\n-Connaissance avanc\u00e9e de l'administration Kafka, y compris la configuration, la gestion et la r\u00e9solution des probl\u00e8mes\n-Mise en \u0153uvre de l'infrastructure en tant que code \u00e0 l'aide de Terraform\n-Bonne compr\u00e9hension des bonnes pratiques de s\u00e9curit\u00e9 pour les syst\u00e8mes cloud, les clusters Kafka et les plateformes Hadoop\nCGI est un employeur inclusif et attentif aux candidatures des personnes en situation de handicap, \u00e0 l\u2019\u00e9volution de carri\u00e8res des hommes et des femmes et au bien-\u00eatre de nos salari\u00e9s LGBT+. Dans un souci d\u2019accessibilit\u00e9 et de clart\u00e9, le point m\u00e9dian n\u2019est pas utilis\u00e9 dans cette annonce. Tous les termes employ\u00e9s se r\u00e9f\u00e8rent aussi bien au genre f\u00e9minin que masculin.\nEnsemble, en tant que propri\u00e9taires, mettons notre savoir-faire \u00e0 l\u2019\u0153uvre.\nLa vie chez CGI est ancr\u00e9e dans l\u2019actionnariat, le travail d\u2019\u00e9quipe, le respect et un sentiment d\u2019appartenance. Chez nous, vous pourrez exploiter votre plein potentiel parce que\u2026\nNous vous invitons \u00e0 devenir propri\u00e9taire d\u00e8s le jour 1 alors que nous travaillons ensemble \u00e0 faire de notre r\u00eave une r\u00e9alit\u00e9. C\u2019est pourquoi nous nous d\u00e9signons comme associ\u00e9s de CGI, plut\u00f4t que comme employ\u00e9s. Nous tirons profit des retomb\u00e9es de notre succ\u00e8s collectif et contribuons activement \u00e0 l\u2019orientation et \u00e0 la strat\u00e9gie de notre entreprise.\nVotre travail cr\u00e9e de la valeur. Vous \u00e9laborerez des solutions novatrices et d\u00e9velopperez des relations durables avec vos coll\u00e8gues et clients, tout en ayant acc\u00e8s \u00e0 des capacit\u00e9s mondiales pour concr\u00e9tiser vos id\u00e9es, saisir de nouvelles opportunit\u00e9s, et b\u00e9n\u00e9ficier d\u2019une expertise sectorielle et technologique de pointe.\nVous ferez \u00e9voluer votre carri\u00e8re en vous joignant \u00e0 une entreprise b\u00e2tie pour cro\u00eetre et durer. Vous serez soutenus par des leaders qui ont votre sant\u00e9 et bien-\u00eatre \u00e0 c\u0153ur et qui vous permettront de saisir des occasions afin de parfaire vos comp\u00e9tences et \u00e9largir les horizons.\nJoignez-vous \u00e0 nous, l\u2019une des plus importantes entreprises de conseil en technologie de l\u2019information (TI) et en management au monde.\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "R"
            ],
            "DataBase": [],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [
                "Hadoop"
            ],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [
                "AWS"
            ],
            "DevTools": [],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [
                "Terraform"
            ],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [
                "OpenShift"
            ],
            "Collaboration": [],
            "Other": [
                "DevOps",
                "Big Data",
                "Cloud"
            ],
            "FrSoftSkills": [
                "Flexibilit\u00e9"
            ],
            "EnSoftSkils": []
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [],
            "Salary": [
                "1"
            ],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "title": "Data Engineer (H/F)",
        "company": "ternair",
        "location": "Greater Lille Metropolitan Area",
        "link": "https://fr.linkedin.com/jobs/view/data-engineer-h-f-at-ternair-3915757963?position=58&pageNum=0&refId=TDTc9UZJy78L%2BED7EV%2BMrg%3D%3D&trackingId=dWBVkZEg5jT0dB6SX9Q7Mg%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "\ud83d\udc68\u200d\ud83d\ude80 MISSION : \ud83d\udc69\u200d\ud83d\ude80\nEn coh\u00e9rence avec la strat\u00e9gie d\u2019entreprise et la roadmap data, vous aurez pour principales missions de :\nEn lien avec l\u2019\u00e9quipe DevOps, construire, maintenir et faire \u00e9voluer la plateforme de donn\u00e9es;\nD\u00e9finir et piloter la coh\u00e9rence de la collecte, la gestion et l\u2019alimentation des donn\u00e9es internes et externes, en diff\u00e9rents modes : batch, streaming, API (architecture micro-services);\nPr\u00e9parer et mettre en qualit\u00e9 les donn\u00e9es pour les rendre disponibles dans les diff\u00e9rents environnements de travail (datalake, datawarehouse, datamart);\nV\u00e9rifier la qualit\u00e9 des donn\u00e9es, de leur bonne et r\u00e9guli\u00e8re ex\u00e9cution ainsi que de leur utilisation ad\u00e9quate (gestion des co\u00fbts);\nTravailler en \u00e9troite collaboration avec les data analysts, scientists et data stewards et business de l\u2019entreprise ;\nEn lien avec l\u2019IT et la s\u00e9curit\u00e9, veiller aux r\u00e8gles d'int\u00e9grit\u00e9 et de s\u00e9curit\u00e9 des donn\u00e9es;\nVeille technologique.\n\ud83e\uddee Les outils :\nPlateforme data : Google Cloud Platform (Big Query, Airflow)\nD\u00e9veloppement : Github/GitLab, Docker, Terraform, Python\nAnalytiques : Qlik\nGestion de projet s: Jira, Confluence, Miro, Drive, Docs, Sheets, Slides\n\ud83e\udd29 Profil recherch\u00e9 : \ud83e\udd29\nExp\u00e9rience d'au moins 4-5 ans (apr\u00e8s \u00e9tudes) en data ing\u00e9nierie (flux, mod\u00e9lisation, run)\nA l\u2019aise avec l\u2019environnement Cloud et les infrastructures digitales\nCommuniquant, p\u00e9dagogue et fortes capacit\u00e9s relationnelles\nAnglais (\u00e0 l\u2019\u00e9crit)\nR\u00e9mun\u00e9ration : 42-60 k\u20ac en package selon exp\u00e9rience\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "R",
                "Go"
            ],
            "DataBase": [],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [
                "Google Cloud Platform"
            ],
            "DevTools": [
                "Git",
                "Docker"
            ],
            "Os": [],
            "DBMS": [
                "Big Query"
            ],
            "SoftBigDataProcessing": [],
            "Automation": [
                "Airflow"
            ],
            "InfrastructureAsCode": [
                "Terraform"
            ],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [
                "Docker"
            ],
            "Collaboration": [
                "JIRA",
                "Confluence"
            ],
            "Other": [
                "DevOps",
                "Cloud"
            ],
            "FrSoftSkills": [
                "Collaboration"
            ],
            "EnSoftSkils": [
                "Collaboration"
            ]
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [],
            "Salary": [
                "Package"
            ],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s",
                "5",
                "5",
                "5"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "title": "Data Solutions Engineer (Data & AI)",
        "company": "LVMH",
        "location": "Paris, \u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/data-solutions-engineer-data-ai-at-lvmh-3900392289?position=59&pageNum=0&refId=TDTc9UZJy78L%2BED7EV%2BMrg%3D%3D&trackingId=Ii5OaSH%2Bx4fLih9wC%2BWMmA%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "LVMH is the #1 Luxury group and is currently accelerating rapidly on digitalisation. It is bringing technology and innovation in the core of the established 75+ Maisons by inventing unique and powerful products and services.\nWe are looking for talented solution engineers (Software, Cloud, Data and AI) to join our team and be part of this tech revolution of bringing the Group and its Maisons to the next level.\nIf you believe Data and AI can enhance the retail industry, from the day-to-day operational tasks to the long term customer experience,\nIf you think that the Cloud technologies (we love Google Cloud) is a revolution for Data and AI products,\nIf you like building tech solutions having direct impacts on billion-dollar-valued businesses,\nIf you have good communication skills and like sharing your knowledge,\nApply now, and join us!\nThe mission\nThe Solution Engineer is providing advices and technical assets to the Maisons having Data & AI projects.\nOur team (Group Data team) is building a technical framework for all the Maisons to implement easily and quickly Data and AI use cases. Your mission will be to support the Maisons to convert their use case needs to concrete and production ready technical solutions using our framework and tools.\nYou will cover a portfolio of Maisons, in direct contact with their business analysts, data scientists and IT teams. You will be their dedicated referent on the Data & AI technical topics (Data platform, AI/ML softwares, data transport and transformations, data quality).\nMain responsibilities\nYou will be responsible of providing support and advices to a portfolio of Maisons on Data & AI tech topics (Cloud, Data stacks, Data transformations, Data transfers, ML ops).\nYou will keep a recurrent discussion with the Maisons to accelerate their projects and immediately provide our support when it's needed.\nYou will follow-up the engaged productions in the Maisons and report them to the global group data strategy committees.\nApplying the quality and security standards. Making them evolve if necessary.\nProducing realistic, understandable and documented solutions following the group guidelines.\nSharing and learning from the team by communicating difficulties and successes, taking and bringing honest feedbacks and improving the identified pain points.\nTaking responsibility as member of the team on the product performances (delivery and long term usage)\nRequired expertise and knowledge\nAbility to build technical solutions answering concrete usage (User Stories) and communicate them to the team.\nDimension and evaluate complexity for technical solution productions.\nExtensive knowledge and experience with good learning and sharing abilities.\nEvaluate quickly risks and opportunities about technical choices.\nSolid oral, written, presentation and interpersonal communication and relationship skills.\nProblem-solving skills on Data and AI, coding and software development\nTech lover\nFeedback taker and giver\nTeam player\nKey benefits to join our team\nAttractive packages\nOffices in the 8th arrondissement near the Champs Elys\u00e9es\nFlexibility on the working hours\nRemote work possible (~40%)\n7 weeks of holidays (cong\u00e9s pay\u00e9s + RTT)\nLVMH brands exclusive private sales\nGreat employee committee and health insurance (CE, mutuelle)\nLast generation MacBooks\nPart of a young, motivated and tech savvy team. Get prepared for the Thursday drinks and the tech meet-ups!\nYou\u2019re eligible if\nYou have a strong experience (3+ years) in cloud data architecting or consultancy.\nYou graduated from an engineering (or equivalent) with a master\u2019s degree. Computer Science knowledge is mandatory.\nExperience on data stacks and/or Google Cloud (built in components) is a huge plus.\nFrench and English both written and oral (Maisons are all over the world)\nYou\u2019re thrilled to support the #1 luxury group to get even better.\nHiring Process\nCall with our HR partner dedicated to the Tech Team\nTechnical interview with the Solution Engineering Manager\nTechnical test\nInterview with the Head of Engineering\nStill here? Apply now!!\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "R",
                "Go"
            ],
            "DataBase": [],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [],
            "DevTools": [
                "Git"
            ],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [
                "Teams"
            ],
            "Other": [
                "ML",
                "Cloud"
            ],
            "FrSoftSkills": [
                "Communication"
            ],
            "EnSoftSkils": [
                "Communication",
                "Flexibility"
            ]
        },
        "details": {
            "JobDetail": [
                "Remote"
            ],
            "TypeContract": [],
            "Salary": [
                "40"
            ],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "title": "Big Data Engineer \u2013 Secteur T\u00e9l\u00e9com \u2013 Paris, France (H/F)",
        "company": "Astek",
        "location": "Paris, \u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/big-data-engineer-%E2%80%93-secteur-t%C3%A9l%C3%A9com-%E2%80%93-paris-france-h-f-at-astek-3832149765?position=60&pageNum=0&refId=TDTc9UZJy78L%2BED7EV%2BMrg%3D%3D&trackingId=Z8j5uhBScZ1Pfkab7NeYTg%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "CDI\nParis - France\nPubli\u00e9e il y a 2 semaines\nLe Groupe Astek\nCe Que Nous Allons Accomplir Ensemble :\nNous rejoindre en tant que\nBig Data Engineer (H/F),\nafin d\u2019accompagner un op\u00e9rateur t\u00e9l\u00e9coms, Leader en Europe dans la gestion de ses portails clients grands publics (multimarques mobile et internet).\nUn challenge portant sur des millions d\u2019utilisateurs dans un environnement technique innovant et strat\u00e9gique.\nVotre Mission, Si Vous L\u2019acceptez :\nQualifier les donn\u00e9es et les r\u00e9sultats\nConception technique des solutions\nD\u00e9cliner les impacts de la strat\u00e9gie et des innovations technologiques au sein des processus et outils de l\u2019exploitant SI\nAssurer l\u2019accompagnement et le d\u00e9ploiement des \u00e9volutions des processus et outils\nContribuer aux programmes de transformation DevOps, Cloud et catalogues des offres SI\nD\u00e9velopper des fonctions transverses et les \u00ab uses cases \u00bb\nAccompagner la phase de mise en production\nVotre Future \u00c9quipe :\nAu sein d\u2019un environnement riche et complexe, vous \u00e9voluerez avec des experts passionn\u00e9(e)s \u00e0 la fois techniques et fonctionnels (Ing\u00e9nieurs sp\u00e9cialis\u00e9es, chef de projet, scrum master, product owner, analystes\u2026).\nL\u2019\u00e9quipe est en interaction avec des clients \u00e0 la fois internes et externes.\nVotre stack de jeu\nSyst\u00e8me d\u2019exploitation Linux\nBig data (Hadoop, Spark, Scala)\nCloud computing (GCP\u2026)\nS QL, No SQL (Cassandra, Mongo DB)\nDataviz : Power BI ou Kibana\nDes notions en d\u00e9veloppement feront la diff\u00e9rence !\nLes Petits Plus Du Projet :\nVous \u00e9voluerez au sein d\u2019une \u00e9quipe impliqu\u00e9e et r\u00e9active et interviendrez sur un projet polyvalent et \u00e0 forte valeur ajout\u00e9e.\nVous ?\nDipl\u00f4m\u00e9(e) d\u2019une\n\u00e9cole d\u2019ing\u00e9nieur\nou \u00e9quivalent de niveau Bac+5. Vous justifiez id\u00e9alement d\u2019une exp\u00e9rience d\u2019au moins 2 ans sur un poste similaire.\nCe descriptif vous interpelle ?\nAlors ce poste est fait pour vous, n\u2019h\u00e9sitez plus et rejoignez l\u2019aventure ASTEK !\nAstek\nCr\u00e9\u00e9 en France en 1988, Astek est un acteur mondial de l\u2019ing\u00e9nierie et du conseil en technologies. Fort de son expertise dans de nombreux secteurs industriels et tertiaires, Astek accompagne ses clients internationaux dans le d\u00e9ploiement intelligent de leurs produits et de leurs services, et dans la mise en \u0153uvre de leur transformation digitale.\nDepuis sa cr\u00e9ation, le Groupe a fond\u00e9 son d\u00e9veloppement sur une forte culture d\u2019entrepreneuriat et d\u2019innovation, et sur l\u2019accompagnement et la mont\u00e9e en comp\u00e9tence de\nses 7800 collaborateurs\nqui s\u2019engagent chaque jour \u00e0 promouvoir la compl\u00e9mentarit\u00e9 entre les technologies num\u00e9riques et l\u2019ing\u00e9nierie des syst\u00e8mes complexes.\nRejoignez un Groupe en fort d\u00e9veloppement en France et \u00e0 travers le monde ayant r\u00e9alis\u00e9 un chiffre d\u2019affaires de 600 M\u20ac en 2023.\nTous les d\u00e9tails sur le Groupe sur le site https://astekgroup.fr. Et vous pouvez aussi nous suivre sur notre blog : https://blog.groupeastek.com.\nRencontrons-nous\nVous vous \u00eates reconnu(e) sur l\u2019annonce et Astek vous pla\u00eet !\nJulie , Talent Acquisition Officer vous contactera pour en savoir plus sur vous.\nPar La Suite, 2 \u00c9changes Maximum :\nLe premier avec Mathieu (votre futur N+1, avec lequel vous \u00e9changerez autour d\u2019ASTEK, de votre parcours, de vos attentes et de la mission)\nLe second avec Anthime (Notre Directeur d\u2019agence pour valider votre int\u00e9r\u00eat pour le poste et vous pr\u00e9senter les \u00e9l\u00e9ments contractuels).\nNos Plus\nAstek est green et fait b\u00e9n\u00e9ficier ses salari\u00e9s d\u2019une indemnit\u00e9 kilom\u00e9trique v\u00e9lo\nUne politique CARE sur-mesure d\u00e9ploy\u00e9e par nos \u00e9quipes RH pour nos collaborateurs (https://astekgroup.fr/engagements)\nNotre charte de la Diversit\u00e9\nBienvenue dans la team ! Allez-y, maintenant c\u2019est \u00e0 vous de jouer !\nMots-cl\u00e9s :\ning\u00e9nieur \u2013 ing\u00e9nieure \u2013 consultant \u2013 consultante \u2013 big data engineer\nCaract\u00e9ristiques de l'emploi\nCat\u00e9gorie Ing\u00e9nieur\nJob Industry T\u00e9l\u00e9com / M\u00e9dia\nPostuler en ligne\nNom *\nPr\u00e9nom *\nEmail *\nUn email valide est requis.\nT\u00e9l\u00e9phone *\nUn num\u00e9ro de t\u00e9l\u00e9phone valide est requis.\nJoindre un CV *\nMots-cl\u00e9s :\ning\u00e9nieur \u2013 ing\u00e9nieure \u2013 consultant \u2013 consultante \u2013 big data engineer\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Scala",
                "R",
                "Go"
            ],
            "DataBase": [
                "SQL",
                "Cassandra"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [
                "Hadoop",
                "Spark"
            ],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [
                "Power BI"
            ],
            "Statistics": [],
            "CloudComputing": [],
            "DevTools": [
                "Git"
            ],
            "Os": [
                "Linux"
            ],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [
                "Chef"
            ],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [
                "DevOps",
                "Big Data",
                "Cloud"
            ],
            "FrSoftSkills": [],
            "EnSoftSkils": []
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [
                "CDI"
            ],
            "Salary": [],
            "Level": [
                "Bac+5"
            ],
            "Experience": [
                "a",
                "n",
                "s",
                "2",
                "2",
                "2"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "title": "Data Engineer \u2013 Grenoble",
        "company": "Capgemini",
        "location": "Grenoble, Auvergne-Rh\u00f4ne-Alpes, France",
        "link": "https://fr.linkedin.com/jobs/view/data-engineer-%E2%80%93-grenoble-at-capgemini-3905836212?position=1&pageNum=2&refId=EunNu8klDuKd8PhUvgvx0Q%3D%3D&trackingId=rVM%2FWT4txhii7kUBqMd4jw%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Choisir Capgemini, c'est choisir une entreprise o\u00f9 vous serez en mesure de fa\u00e7onner votre carri\u00e8re selon vos aspirations. Avec le soutien et l'inspiration d'une communaut\u00e9 d\u2019experts dans le monde entier, vous pourrez r\u00e9\u00e9crire votre futur. Rejoignez-nous pour red\u00e9finir les limites de ce qui est possible, contribuer \u00e0 lib\u00e9rer la valeur de la technologie pour les plus grandes organisations et participer \u00e0 la construction d\u2019un monde plus durable et inclusif.\nVos missions :\nEn tant que Data Engineer au sein d'une \u00e9quipe multidisciplinaire, vos responsabilit\u00e9s principales seront les suivantes :\nIntervenir sur les diff\u00e9rentes phases d'un projet dans un environnement Cloud et Agile.\nContribuer \u00e0 la gestion de la qualit\u00e9 des donn\u00e9es et extraction et analyse de celle-ci, ainsi qu\u2019\u00e0 la pr\u00e9sentation des donn\u00e9es dans leur forme raffin\u00e9e.\nProposer des nouvelles lectures de donn\u00e9es via un travail de fouille sur les gisements d\u2019information, notamment client.\nAdopter une posture de consultant : proposer de nouvelles solutions et accompagner le client dans ses choix.\nVotre profil :\nTitulaire d'un Bac+5 en \u00e9cole d\u2019ing\u00e9nieur ou en universit\u00e9.\nConnaissances approfondies des ETL (Talend, Informatica ou SSIS), du traitement de donn\u00e9es (Spark, Python, Scala) ainsi que des bases de donn\u00e9es (Oracle, SQL Server, Postgres).\nFacult\u00e9 pour se montrer curieux, autonome et proactif dans la r\u00e9alisation de ses t\u00e2ches.\nCapacit\u00e9 \u00e0 faire preuve de rigueur et \u00e0 travailler en \u00e9quipe.\nBon niveau d\u2019anglais (B2 minimum).\n3 raisons de nous rejoindre :\nQualit\u00e9 de vie au travail\n: accord de t\u00e9l\u00e9travail en France et \u00e0 l\u2019international, accord sur l\u2019\u00e9galit\u00e9 professionnelle, la parentalit\u00e9, l\u2019\u00e9quilibre des temps et la mobilit\u00e9 durable.\nApprentissage en continu\n: certifications et formations en libre acc\u00e8s, accompagnement sur mesure avec votre career manager, parcours d\u2019int\u00e9gration sur 9 mois.\nAvantages groupe & CSE\n: plan actionnariat, tarif pr\u00e9f\u00e9rentiels, remboursement partiel vacances, remboursement de votre abonnement sportif ou culturel.\nNos engagements et priorit\u00e9s\n:\nLe groupe Capgemini encourage une culture inclusive dans un cadre multiculturel et handi-accueillant. En nous rejoignant, vous int\u00e9grez un collectif qui valorise la diversit\u00e9, d\u00e9veloppe le potentiel de ses talents, s\u2019engage dans des initiatives solidaires avec ses partenaires, et se mobilise pour r\u00e9duire son impact environnemental sur tous ses sites et aupr\u00e8s de ses clients.\n\u00c0 propos de Capgemini :\nCapgemini est un leader mondial, responsable et multiculturel, regroupant pr\u00e8s de 350 000 personnes dans plus de 50 pays. Fort de 55 ans d\u2019exp\u00e9rience, nous sommes un partenaire strat\u00e9gique des entreprises pour la transformation de leurs activit\u00e9s en tirant profit de toute la puissance de la technologie et des innovations dans les domaines en perp\u00e9tuelle \u00e9volution tels que le cloud, la data, l\u2019Intelligence Artificielle, la connectivit\u00e9, les logiciels, l\u2019ing\u00e9nierie digitale ou les plateformes.\nGet The Future You Want* | www.capgemini.com/fr-fr\n*Capgemini, le futur que vous voulez\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "Scala",
                "R"
            ],
            "DataBase": [
                "SQL"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [
                "Spark"
            ],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [],
            "DevTools": [
                "Git"
            ],
            "Os": [],
            "DBMS": [
                "Oracle",
                "SQL Server"
            ],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [
                "Cloud"
            ],
            "FrSoftSkills": [
                "Organisation"
            ],
            "EnSoftSkils": [
                "Initiative"
            ]
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [],
            "Salary": [],
            "Level": [
                "Bac+5"
            ],
            "Experience": [
                "a",
                "n",
                "s",
                "55",
                "55",
                "55"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "title": "Data Engineer",
        "company": "eXalt Value",
        "location": "\u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/data-engineer-at-exalt-value-3897767649?position=2&pageNum=2&refId=EunNu8klDuKd8PhUvgvx0Q%3D%3D&trackingId=iUyZScP6JnVgtR9o6D%2Bz8w%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "eXalt\nest un cabinet de conseil IT\nPure player Data\n& IA bas\u00e9 \u00e0 Paris.\nNotre offre s\u2019articule autour de 4 piliers r\u00e9unis au sein d\u2019une m\u00eame communaut\u00e9 pour un accompagnement \u00e0 360\u00b0 alliant une expertise technique et m\u00e9thodologique \u00e0 une approche conseil m\u00e9tier:\nData Gouvernance & Project\nData Engineering & Big Data\nData Performance & Analytics\nData Science & IA\nFiliale du groupe eXalt, cr\u00e9\u00e9 en 2018,\nregroupant plus de\n950 collaborateurs en France\n(Paris, Lyon, Bordeaux, Lille, Nantes, Marseille)\net \u00e0 l\u2019international\n(Colombie, Etats-Unis, Espagne, Belgique),\neXalt Value\napporte une\nexpertise approfondie\ndans le domaine de la Data & IA et conseille les entreprises dans le d\u00e9ploiement de leurs strat\u00e9gies data-driven.\nB\u00e9n\u00e9ficiant du support du groupe eXalt\n(1er dans la cat\u00e9gorie Conseil & Audit au classement des Champions de la Croissance 2024), eXalt Value\nest en pleine croissance et regroupe aujourd\u2019hui une communaut\u00e9 d\u2019expertise de plus de 60 collaborateurs en r\u00e9gion parisienne.\nNos consultants interviennent sur d\nes projets d\u2019envergure\ndans divers secteurs d\u2019activit\u00e9,\nBanque & Assurance, M\u00e9dias, Transports, Retail, Tourisme, etc.\nNous recherchons un\nData Engineer Confirm\u00e9 H/F (minimum 4 ans d'exp\u00e9rience dans la fonction)\npour rejoindre notre communaut\u00e9 sur le\npilier Data Engineering & Big Data.\nVos missions:\nConcevoir et d\u00e9velopper des pipelines et des flux de donn\u00e9es.\nInt\u00e9grer et transformer des donn\u00e9es provenant de diff\u00e9rentes sources.\nD\u00e9velopper et mettre en \u0153uvre des algorithmes de traitement de donn\u00e9es avanc\u00e9s.\nCollaborer \u00e9troitement avec les \u00e9quipes clients pour comprendre leurs besoins et fournir des solutions adapt\u00e9es.\nAssurer la qualit\u00e9 et la fiabilit\u00e9 des solutions d\u00e9velopp\u00e9es.\nConseiller les \u00e9quipes clients sur les solutions \u00e0 mettre en place.\nLes Pr\u00e9requis :\nTitulaire d'un Bac+5, Ecole d'Ing\u00e9nieur\nMa\u00eetrise d'un ou plusieurs langages de programmation (\nPython, Scala, Spark, etc\n.).\nExp\u00e9rience approfondie des technologies\nBig Data (Hadoop, Spark, Kafka, Talend, etc.)\nExp\u00e9rience av\u00e9r\u00e9e\nen\nenvironnement Cloud (AWS, GCP, ou Azure)\n.\nSolides comp\u00e9tences en conception et en optimisation de pipelines de donn\u00e9es.\nExp\u00e9rience de travail en\nm\u00e9thode Agile\nCapacit\u00e9 \u00e0 travailler de mani\u00e8re autonome et en \u00e9quipe.\nExcellentes comp\u00e9tences en communication et en r\u00e9solution de probl\u00e8mes.\nMa\u00eetrise de l\u2019anglais (oral & \u00e9crit dans un contexte international professionnel).\nVotre environnement eXalt\u00e9:\nUn environnement de travail Collaboratif\nfavorisant les initiatives et projets transverses \u00e0 la Practice Data & IA (Lab IA, Data Hub, etc.).\nUn collectif de consultants passionn\u00e9s,\ns\u2019int\u00e9ressant aux tendances innovantes du secteur.\nUne Practice de proximit\u00e9,\nprivil\u00e9giant la mont\u00e9e en comp\u00e9tence de ses collaborateurs (formations, coachings, mentorats, etc.)\nUn suivi individualis\u00e9 et de proximit\u00e9\npar un.e Data Sales Manager r\u00e9f\u00e9rent du compte client, un.e Charg\u00e9.e RH et un.e Practice Manager\nUne \u00e9quipe ouverte et dynamique,\nqui privil\u00e9gie les moments de partage et de convivialit\u00e9 (s\u00e9minaires, eXaltemps, meet-up, d\u00e9jeuners d\u2019\u00e9quipe, etc.)\nNotre processus de recrutement :\nUn entretien RH avec Estelle,\n\u00e0 la suite duquel vous saurez tout (ou presque) d\u2019eXalt Value,\nUn entretien technique avec un Manager assorti d\u2019un test technique,\nlors duquel vous aurez l\u2019occasion de d\u00e9montrer vos talents mais aussi d\u2019apprendre avant m\u00eame de dire oui,\nUn entretien final avec la Directrice Associ\u00e9e ou le Directeur Op\u00e9rationnel,\npour finir de vous convaincre de nous rejoindre \ud83d\ude0a\nNous avons h\u00e2te de recevoir vos CV, et de faire votre connaissance!\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "Scala",
                "R",
                "Go"
            ],
            "DataBase": [],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [
                "Hadoop",
                "Spark"
            ],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [
                "AWS",
                "Azure"
            ],
            "DevTools": [],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [
                "Big Data",
                "Cloud"
            ],
            "FrSoftSkills": [
                "Communication",
                "R\u00e9solution de probl\u00e8mes"
            ],
            "EnSoftSkils": [
                "Communication",
                "Initiative"
            ]
        },
        "details": {
            "JobDetail": [
                "Confirm\u00e9"
            ],
            "TypeContract": [],
            "Salary": [],
            "Level": [
                "Bac+5"
            ],
            "Experience": [
                "a",
                "n",
                "s",
                "4",
                "4",
                "4"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "title": "Data Engineer | Python - Spark - Hadoop | Sp\u00e9cialis\u00e9 en Big Data | Paris ou Remote Partiel",
        "company": "Octopus IT - Expert du recrutement tech",
        "location": "Paris, \u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/data-engineer-python-spark-hadoop-sp%C3%A9cialis%C3%A9-en-big-data-paris-ou-remote-partiel-at-octopus-it-expert-du-recrutement-tech-3685740787?position=3&pageNum=2&refId=EunNu8klDuKd8PhUvgvx0Q%3D%3D&trackingId=2wRnF1bj7F62V7tFqLDvzA%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "La soci\u00e9t\u00e9\nCr\u00e9\u00e9e il y a 7 ans, cette entreprise de conseil en hyper croissance, se compose d'environ 90 personnes. Elle est devenue experte en Data et IA (NLP, Deep Learning, Machine Learning) et accompagne leurs clients sur l\u2019ensemble de leurs projets data \u00e0 travers la valorisation de leurs donn\u00e9es.\nLeur valeur ajout\u00e9e ? Leur sp\u00e9cialisation en Data ce qui leur permet d'offrir 3 expertises m\u00e9tiers distinctes : la Data Science, la Data Engineering et le Machine Learning Engineering. Autour de ces expertises gravitent bien s\u00fbr les m\u00e9tiers de Lead et d'Architecte.\nUne autre de leur force est leur formation interne (avec des profils de seniors ou d'architectes) et externe (avec des partenaires pour passer les certifications).\nChez eux, le collaborateur est plac\u00e9 au centre des pr\u00e9occupations, permettant ainsi de cr\u00e9er une coh\u00e9sion et une v\u00e9ritable culture au sein de l'entreprise. Par exemple la majorit\u00e9 des projets se font en \u00e9quipe et non seul.\nConnu et reconnu pour leur expertise en Big Data, ils sont devenu le partenaire principal d'un grand groupe du CAC 40 et ont pris le lead sur tous les sujets touchant \u00e0 la transformation Big Data de ce groupe.\nPour poursuivre leur croissance, r\u00e9pondre \u00e0 leurs ambitions et d\u00e9velopper de nouveaux march\u00e9s, nous recherchons plusieurs profils pour renforcer leurs effectifs.\nLe poste\nEn les rejoignant vous travaillerez sur les probl\u00e9matiques suivantes :\nMise en place et/ou scale d'architectures\nConstruction de Datalake\nMise en production de model de ML\nPipelining de donn\u00e9es\nStreaming de donn\u00e9es et temps r\u00e9el\nLa stack sur laquelle vous travaillerez :\nPython, Scala, Spark, Architectures distribu\u00e9es : Hadoop, HDFS, Cloud : Aws, GCP, Azure\nVotre profil\nA partir de 3 ans d'exp\u00e9rience en CDI\nVous avez une exp\u00e9rience significative sur des probl\u00e9matiques Big Data\nTr\u00e8s bonne comp\u00e9tences en Python et/ou Scala et en Spark\nVous \u00eates familier avec Hadoop, Hive, Hbase\nUne logique cloud (Aws, GCP ou Azure)\nLe salaire & avantages\n50-60 K\u20ac selon exp\u00e9rience\nRTT\nCarte Swile & Mutuelle\n3/4 jours de t\u00e9l\u00e9travail par semaine\nEt plus encore\u2026\nCe qu\u2019on pr\u00e9f\u00e8re\n\u00catre impliqu\u00e9 \u00e0 fond dans une aventure avec de nombreux challenges techniques\nBelles opportunit\u00e9s d'\u00e9volutions sur des postes d'Architecte, de Lead ou de Ml Ops\nTr\u00e8s bonne ambiance, \u00e9quipe solidaire et orient\u00e9e partage d\u2019informations\nBeaucoup de workshops en interne et catalogue de formations \u00e0 votre guise\nCe poste a \u00e9t\u00e9 soigneusement choisi par votre coach. Powered by Octopus IT, cabinet d\u2019Experts en Recrutement Tech (CDI et clients finaux uniquement) \u2013 Visitez nous pour plus d\u2019opportunit\u00e9s :\nwww.octopusit.fr\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "Scala",
                "R"
            ],
            "DataBase": [
                "HBase"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [
                "Hadoop",
                "Spark"
            ],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [
                "AWS",
                "Azure"
            ],
            "DevTools": [],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [
                "HBase"
            ],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [
                "Big Data",
                "ML",
                "Machine Learning",
                "Cloud"
            ],
            "FrSoftSkills": [],
            "EnSoftSkils": []
        },
        "details": {
            "JobDetail": [
                "Senior"
            ],
            "TypeContract": [
                "CDI"
            ],
            "Salary": [
                "50"
            ],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s",
                "7",
                "7",
                "7"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "title": "Data Engineer (H/F)",
        "company": "MP DATA",
        "location": "Toulouse, Occitanie, France",
        "link": "https://fr.linkedin.com/jobs/view/data-engineer-h-f-at-mp-data-3908719610?position=4&pageNum=2&refId=EunNu8klDuKd8PhUvgvx0Q%3D%3D&trackingId=B0719RxYRCpvjHVP51zIXQ%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "MP DATA est une soci\u00e9t\u00e9 sp\u00e9cialis\u00e9e dans l\u2019acquisition, le traitement, et la valorisation des donn\u00e9es.\nDepuis sa cr\u00e9ation en 2015, MP DATA accompagne ses clients, majoritairement industriels, dans le management de leur performance et l\u2019exploitation de leurs donn\u00e9es.\nLes collaborateurs, tous issus de grandes \u00e9coles, incarnent au quotidien les valeurs d\u2019Excellence, de Partage et d\u2019Engagement.\nIls associent savoir-faire technique, m\u00e9thodologie et passion et mettent leurs comp\u00e9tences au service de missions et projets au sein de grands groupes fran\u00e7ais.\nMP DATA accompagne ses clients sur toute la chaine au travers de 3 p\u00f4les d\u2019expertise : Conseil et Strat\u00e9gie, Infrastructure & CloudOPS, Data Science.\nChez MP DATA, les \u00e9quipes commerciales cherchent des missions en fonction des envies des collaborateurs et non pas l\u2019inverse. Les consultants sont accompagn\u00e9s dans tous leurs projets, de la mobilit\u00e9 g\u00e9ographique, au changement de secteur d\u2019activit\u00e9 en passant par le d\u00e9veloppement de nouvelles comp\u00e9tences.\nRejoindre MP DATA, c\u2019est la garantie de travailler sur des sujets passionnants avec un cadre technique fort.\nDescriptif du poste :\nNous recherchons un Data Engineer exp\u00e9riment\u00e9 pour rejoindre notre \u00e9quipe.\nEn tant que Data Engineer, vous serez responsable de la conception, du d\u00e9veloppement et de la mise en \u0153uvre de pipelines de traitement de donn\u00e9es en temps r\u00e9el \u00e0 grande \u00e9chelle.\nVous travaillerez avec des technologies telles que Kafka, Flink, Kinesis et vous utiliserez les services du cloud AWS pour stocker et traiter les donn\u00e9es.\nVos responsabilit\u00e9s :\nUtiliser Kafka pour le traitement de flux de donn\u00e9es en temps r\u00e9el \u00e0 grande \u00e9chelle, en travaillant avec les producteurs, les consommateurs et les topics.\nMettre en \u0153uvre des pipelines de traitement de donn\u00e9es en streaming avec Flink, en appliquant des transformations complexes et en g\u00e9rant les \u00e9tats.\n\u00c9crire du code efficace et maintenable en Java / Python pour manipuler et analyser les donn\u00e9es en temps r\u00e9el.\nUtiliser Kubernetes pour d\u00e9ployer et g\u00e9rer des applications conteneuris\u00e9es \u00e0 grande \u00e9chelle, en assurant la r\u00e9silience et l\u2019\u00e9volutivit\u00e9 des services.\nUtiliser les services AWS tels que Amazon S3, AWS Lambda, Elastic Kubernetes Service (EKS), Elastic Container Service (ECS) et Elastic Compute Cloud (EC2) pour le stockage, le traitement et le calcul des donn\u00e9es en temps r\u00e9el.\nSuivre les meilleures pratiques pour une utilisation efficace du cloud, en assurant la gestion des co\u00fbts, la s\u00e9curit\u00e9 des donn\u00e9es et la disponibilit\u00e9 des services.\nCollaborer avec l\u2019\u00e9quipe de d\u00e9veloppement logiciel et la gestion de projets pour assurer un flux de d\u00e9veloppement fluide et une livraison efficace des fonctionnalit\u00e9s.\nBon \u00e0 savoir :\nCDI / ASAP / Toulouse\nProfil recherch\u00e9:\nNous recherchons un candidat dipl\u00f4m\u00e9 d'une grande \u00e9cole d'Ing\u00e9nieur avec une premi\u00e8re exp\u00e9rience.\nComp\u00e9tences n\u00e9cessaires :\nExp\u00e9rience significative dans un environnement industriel en mode DevOps, avec des outils tels que CICD, gitlab, Jenkins, Sonar, Nexus, XLdeploy, Camunda, etc.\nMa\u00eetrise des langages de programmation tels que Python, Java et expertise dans l\u2019\u00e9criture et l\u2019optimisation du code SQL\nMa\u00eetrise du fran\u00e7ais et bonne maitrise de l\u2019anglais.\nCapacit\u00e9 \u00e0 travailler en \u00e9quipe et esprit d\u2019\u00e9quipe.\nLe processus de recrutement se d\u00e9roule en 3 entretiens :\nPrise de contact\n1er entretien : Pr\u00e9sentation et projet du candidat + pr\u00e9sentation MP DATA\n2\u00e8me entretien : Entretien de qualification technique\n3\u00e8me entretien : Rencontre avec les \u00e9quipes dans les locaux MP DATA + Proposition de collaboration\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "Java",
                "R"
            ],
            "DataBase": [
                "SQL"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [
                "Flink"
            ],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [
                "AWS"
            ],
            "DevTools": [
                "Git",
                "Jenkins"
            ],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [
                "Kubernetes"
            ],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [
                "Kubernetes"
            ],
            "Collaboration": [],
            "Other": [
                "DevOps",
                "Cloud"
            ],
            "FrSoftSkills": [
                "Collaboration"
            ],
            "EnSoftSkils": [
                "Collaboration"
            ]
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [
                "CDI"
            ],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "title": "Data Engineer (H/F)",
        "company": "Technology & Strategy",
        "location": "Lyon, Auvergne-Rh\u00f4ne-Alpes, France",
        "link": "https://fr.linkedin.com/jobs/view/data-engineer-h-f-at-technology-strategy-3881556102?position=5&pageNum=2&refId=EunNu8klDuKd8PhUvgvx0Q%3D%3D&trackingId=Tp%2BxV8D3CpC1FtkRjSsGJA%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "D\u00e9couvrez Novencia\n:\nExpert en Data et Intelligence Artificielle, nous aidons nos clients \u00e0 exploiter et \u00e0 valoriser leurs donn\u00e9es sous toutes ses formes en les accompagnant sur des projets de Data Analyse, Data Gourvernance, Data Architecture, Data Science, et Data Engineering\u2026\nVous avez une solide exp\u00e9rience de minimum 2 ans dans l'ing\u00e9nierie des donn\u00e9es et vous \u00eates \u00e0 la recherche de nouveaux d\u00e9fis ? Bouclez votre ceinture, la suite est pour vous !\nType de contrat : CDI\nLieu : Lyon\nEn qualit\u00e9 de Data Engineer (H/F), votre r\u00f4le sera :\nConcevoir et proposer les solutions de d\u00e9veloppement r\u00e9pondant aux besoins fonctionnels et techniques des projets big data.\nTu participes \u00e0 la conception de solutions permettant le traitement de volumes importants de pipelines donn\u00e9es.\nR\u00e9aliser ces solutions par l\u2019\u00e9criture de code, en respectant les m\u00e9thodes et proc\u00e9dures qualit\u00e9s d\u00e9finies au sein du d\u00e9partement Technique.\nMise \u00e0 disposition s\u00e9curis\u00e9 et lisible de la data.\nS\u2019assurer de la conformit\u00e9 fonctionnelle et technique de ces r\u00e9alisations en effectuant les tests automatis\u00e9s n\u00e9cessaire et la mise en place de monitoring (syst\u00e8me et qualit\u00e9).\nAssurer la maintenance des applicatifs / plateforme data science\nAssurer une veille technologique\nVous disposez des comp\u00e9tences suivantes :\nMaitrise des plateformes Cloud (AWS, GCP ou Azure), de Scala et de SQL.\nUn.e touche \u00e0 tout : poss\u00e9dant des comp\u00e9tences en langage Python/Spark, de bonnes capacit\u00e9s de mod\u00e9lisation, une forte app\u00e9tence pour le Big Data\nFin.e connaisseur.euse : Data Engineer convaincu, tr\u00e8s peu de secrets pour les clusters et pour les calculs parall\u00e8les\nExplorateur.trice : d\u00e9couvre de nouvelles technos gr\u00e2ce \u00e0 une veille r\u00e9guli\u00e8re\nD\u00e9brouillard.e : rel\u00e8ve de nouveaux d\u00e9fis\nNotre objectif commun est de co-construire votre carri\u00e8re en fonction de vos aspirations et de vos comp\u00e9tences.\nContactez-moi en message priv\u00e9 ou par mail \u00e0 s.ziki@technologyandstrategy.com !\nLet's make it possible #together\n*Nos postes sont ouverts aux personnes b\u00e9n\u00e9ficiant d\u2019une Reconnaissance de la Qualit\u00e9 de Travailleur Handicap\u00e9 (RQTH). T&S Groupe encourage la diversit\u00e9 et l\u2019\u00e9galit\u00e9 sur le lieu de travail. Tous les candidats qualifi\u00e9s H/F/* sont pris en consid\u00e9ration pour un emploi sur un m\u00eame pied d'\u00e9galit\u00e9.\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "Scala",
                "R",
                "Go"
            ],
            "DataBase": [
                "SQL"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [
                "Spark"
            ],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [
                "AWS",
                "Azure"
            ],
            "DevTools": [],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [
                "Big Data",
                "Cloud"
            ],
            "FrSoftSkills": [],
            "EnSoftSkils": []
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [
                "CDI"
            ],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s",
                "2",
                "2",
                "2"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "title": "Stage - Data Engineer - ML (H/F)",
        "company": "Withings",
        "location": "Issy-les-Moulineaux, \u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/stage-data-engineer-ml-h-f-at-withings-3613476264?position=6&pageNum=2&refId=EunNu8klDuKd8PhUvgvx0Q%3D%3D&trackingId=wgKY5I%2FqN%2BXtVHXYWR5xEw%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Chez Withings, nous d\u00e9veloppons des appareils de sant\u00e9 connect\u00e9e : nos balances connect\u00e9es, montres hybrides, tensiom\u00e8tres, moniteurs de sommeil et tous les dispositifs de notre gamme sont aujourd'hui utilis\u00e9s par des millions d'utilisateurs. Notre objectif est de permettre la pr\u00e9vention, le d\u00e9pistage et l'accompagnement d'un certain nombre de maladies chroniques via des produits et des services innovants afin de r\u00e9volutionner la mani\u00e8re dont on prend soin de notre sant\u00e9.\nAu sein de l'\u00e9quipe Machine Learning, nous d\u00e9veloppons des algorithmes pour extraire des informations physiologiques et m\u00e9dicales pour nos utilisateurs tels que le SPO2, la fr\u00e9quence cardiaque, la d\u00e9tection de diverses pathologies comme la fibrillation atriale, l'apn\u00e9e du sommeil...\nInt\u00e9gr\u00e9.e au sein de l'\u00e9quipe Machine Learning, tu auras une ou plusieurs des responsabilit\u00e9s suivantes :\nD\u00e9velopper un outil de monitoring de la dette technique, des mauvaises pratiques de code, des failles de s\u00e9curit\u00e9 ;\nConstruire des dashboards de visualisation ;\nConstruire un syst\u00e8me d'alerte pour notifier les contributeurs d'\u00e9ventuels probl\u00e8mes ;\nD\u00e9velopper des outils permettant de corriger les \u00e9ventuels probl\u00e8mes de fa\u00e7on automatis\u00e9e ;\nRequirements\n\u00c0 la recherche d'un stage d'une dur\u00e9e de 3 \u00e0 6 mois ;\nPr\u00e9paration d'un Master en \u00e9cole d'ing\u00e9nieur ou \u00e9quivalent / ann\u00e9e de c\u00e9sure possible ;\nMa\u00eetrise de Python ;\nMa\u00eetrise de Debian ou de Ubuntu, de Shell et de l'environnement Linux ;\nPremi\u00e8re exp\u00e9rience sur du d\u00e9veloppement logiciel ;\nCulture DevOps (omnipr\u00e9sence du monitoring, automatisation des t\u00e2ches, ...)\nCompr\u00e9hension de la culture et des besoins des diff\u00e9rents membres de l'\u00e9quipe ;\nRigueur, autonomie, prise d'initiative, curiosit\u00e9\nBenefits\nRejoindre l'aventure Withings, c'est :\nInt\u00e9grer un des pionniers et leaders mondiaux de la sant\u00e9 connect\u00e9e, plusieurs fois prim\u00e9 au Consumer Electronic Show\nContribuer \u00e0 des projets innovants et ambitieux pour la sant\u00e9 de demain dans un environnement agile et en constante \u00e9volution\nInt\u00e9grer une entreprise internationale, membre de la FrenchTech 120, dont les \u00e9quipes sont bas\u00e9es \u00e0 Issy-les-Moulineaux, Boston, Hong-Kong et Shenzhen\nParticiper \u00e0 l'am\u00e9lioration continue de nos produits et services en les b\u00eata-testant avant leur sortie, notamment lors de nos nombreuses sessions sportives entre coll\u00e8gues\nParticiper \u00e0 la Withings Med Academy en assistant \u00e0 des conf\u00e9rences de professionnels de sant\u00e9 afin de renforcer ses connaissances dans le domaine m\u00e9dical\nCollaborer avec des coll\u00e8gues passionn\u00e9s et c\u00e9l\u00e9brer ensemble chacune de nos r\u00e9ussites !\nToutes les candidatures re\u00e7ues sont \u00e9tudi\u00e9es ind\u00e9pendamment de l'origine ethnique, des croyances, de la religion, du genre, de l'orientation sexuelle ou de la sant\u00e9 des candidats. Withings aspire \u00e0 offrir et garantir l'\u00e9galit\u00e9 des chances aux candidats et seules les personnes habilit\u00e9es (RH et Management) auront acc\u00e8s aux informations concernant votre candidature.\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "R",
                "Go"
            ],
            "DataBase": [],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [],
            "DevTools": [],
            "Os": [
                "Linux"
            ],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [
                "DevOps",
                "Machine Learning"
            ],
            "FrSoftSkills": [],
            "EnSoftSkils": [
                "Initiative"
            ]
        },
        "details": {
            "JobDetail": [
                "Hybride"
            ],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "title": "Data Engineer",
        "company": "Thales",
        "location": "Ollioules, Provence-Alpes-C\u00f4te d'Azur, France",
        "link": "https://fr.linkedin.com/jobs/view/data-engineer-at-thales-3902424527?position=7&pageNum=2&refId=EunNu8klDuKd8PhUvgvx0Q%3D%3D&trackingId=0nf93AXX17MnZHS4OFuw%2Fw%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "QUI SOMMES-NOUS ?\nThales est un leader mondial des hautes technologies comptant plus de 81 000 collaborateurs pr\u00e9sents sur tous les continents. Le Groupe investit dans les innovations du num\u00e9rique et de la \u00ab deep tech \u00bb \u2013 big data, intelligence artificielle, connectivit\u00e9, cybers\u00e9curit\u00e9 et quantique \u2013 pour construire un avenir de confiance, essentiel au d\u00e9veloppement de nos soci\u00e9t\u00e9s, en pla\u00e7ant l\u2019humain au c\u0153ur des d\u00e9cisions.\nThales propose des solutions, services et produits qui aident ses clients \u2013 entreprises, organisations, Etats \u2013 dans cinq grands march\u00e9s vitaux pour le fonctionnement de nos soci\u00e9t\u00e9s : identit\u00e9 et s\u00e9curit\u00e9 num\u00e9riques, d\u00e9fense, a\u00e9ronautique, espace, et transport.\nQUI ETES-VOUS ?\nDipl\u00f4m\u00e9 d\u2019un Bac+5 en \u00e9cole d\u2019ing\u00e9nieur ou \u00e9quivalent universitaire avec une sp\u00e9cialisation en informatique, vous avez a\nu moins 3 ans d'exp\u00e9rience\ndans les technologies Big Data.\nPassionn\u00e9 par le\nsecteur de la D\u00e9fense et du Naval.\nCE QUE NOUS POUVONS ACCOMPLIR ENSEMBLE :\nEn tant que\nData Engineer,\nvous jouerez un r\u00f4le cl\u00e9 dans la conception, le d\u00e9veloppement et la maintenance de notre infrastructure de donn\u00e9es, ainsi que dans la transformation et la gestion des flux de donn\u00e9es.\nVOS MISSIONS :\n\u2022 Concevoir, d\u00e9velopper et d\u00e9ployer des solutions Big Data en utilisant les technologies\nHadoop, Spark, Scala\n.\n\u2022 Mettre en place des pipelines de donn\u00e9es performants pour l'ingestion, le traitement et le stockage des donn\u00e9es massives.\n\u2022 Collaborer \u00e9troitement avec les \u00e9quipes m\u00e9tier pour comprendre leurs besoins en mati\u00e8re d'analyse de donn\u00e9es et proposer des solutions adapt\u00e9es.\n\u2022 Optimiser les performances des clusters Hadoop pour garantir une exploitation efficace des donn\u00e9es.\n\u2022 Assurer la qualit\u00e9 et la fiabilit\u00e9 des donn\u00e9es trait\u00e9es, en mettant en place des processus de validation et de nettoyage.\n\u2022 Identifier et r\u00e9soudre les probl\u00e8mes li\u00e9s \u00e0 l'infrastructure Big Data et proposer des am\u00e9liorations.\nInnovation, passion, ambition : rejoignez Thales et cr\u00e9ez le monde de demain, d\u00e8s aujourd\u2019hui.\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Scala",
                "R"
            ],
            "DataBase": [],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [
                "Hadoop",
                "Spark"
            ],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [],
            "DevTools": [],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [
                "Big Data"
            ],
            "FrSoftSkills": [
                "Organisation"
            ],
            "EnSoftSkils": []
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [],
            "Salary": [],
            "Level": [
                "Bac+5"
            ],
            "Experience": [
                "a",
                "n",
                "s",
                "3",
                "3",
                "3"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "title": "Data Engineer - Nantes",
        "company": "Capgemini",
        "location": "Nantes, Pays de la Loire, France",
        "link": "https://fr.linkedin.com/jobs/view/data-engineer-nantes-at-capgemini-3803998213?position=8&pageNum=2&refId=EunNu8klDuKd8PhUvgvx0Q%3D%3D&trackingId=Mef8ntH2ikGhIaILEuhGJw%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Capgemini\nChoisir Capgemini, c'est choisir une entreprise o\u00f9 vous serez en mesure de fa\u00e7onner votre carri\u00e8re selon vos aspirations, o\u00f9 vous serez soutenu et inspir\u00e9 par une communaut\u00e9 d\u2019experts dans le monde entier, o\u00f9 vous pourrez r\u00e9\u00e9crire votre futur. Rejoignez-nous pour red\u00e9finir les limites de ce qui est possible, contribuer \u00e0 lib\u00e9rer la valeur de la technologie pour les plus grandes organisations et participez \u00e0 la construction d\u2019un monde plus durable et inclusif.\nVos missions :\nInt\u00e9gr\u00e9(e) au sein d'une \u00e9quipe projets intervenant pour des clients dans des secteurs d'activit\u00e9s vari\u00e9es, vous serez notamment en charge des missions suivantes :\nConcevoir et mettre en oeuvre des strat\u00e9gies s\u00e9curis\u00e9es d'acquisition et d'int\u00e9gration de donn\u00e9es,\nConfigurer des r\u00e9f\u00e9rentiels de donn\u00e9es \u00e0 la pointe de la technologie dans des environnements distribu\u00e9s, majoritairement dans le cloud (Google Cloud Platform, Azure Databricks, AWS) et/ou en environnement Hadoop (distribution MapR, Cloudera, Hortonworks),\nConstruire des pipelines de donn\u00e9es pour collecter, transformer et traiter des donn\u00e9es en collaboration avec des scientifiques de donn\u00e9es afin de r\u00e9pondre aux exigences de la mod\u00e9lisation de donn\u00e9es d'analyse avanc\u00e9e.\nVotre profil :\nDipl\u00f4me d\u2019ing\u00e9nieur ou \u00e9quivalent universitaire\nMinimum 3 ans d'exp\u00e9rience\nAnglais courant\nMa\u00eetrise des langages Java, Scala ou Python et expertise sur les framework Spark et/ou Hadoop.\nExpertise sur les services Cloud Data Platform suivants : Azure Data Lake, Azure synapse, Azure Data Factory, Azure Data Explorer, GCP, AWS, Snowflake, Databricks\u2026\n3 raisons de nous rejoindre :\nQualit\u00e9 de vie au travail : accord de t\u00e9l\u00e9travail en France et \u00e0 l\u2019international, accord sur l\u2019\u00e9galit\u00e9\nprofessionnelle, la parentalit\u00e9, l\u2019\u00e9quilibre des temps et la mobilit\u00e9 durable.\nApprentissage en continu : certifications et formations en libre acc\u00e8s, accompagnement sur mesure avec votre carreer manager, parcours d\u2019int\u00e9gration sur 9 mois.\nAvantages groupe & CSE : plan actionnariat, activit\u00e9s \u00e0 tarifs pr\u00e9f\u00e9rentiels, remboursement partiel\nvacances, remboursement de votre abonnement sportif ou culturel.\nNos engagements et priorit\u00e9s :\nLe groupe Capgemini encourage une culture inclusive dans un cadre multiculturel et handi-accueillant. En nous rejoignant, vous int\u00e9grez un collectif qui valorise la diversit\u00e9, d\u00e9veloppe le potentiel de ses talents, s\u2019engage dans des initiatives solidaires avec ses partenaires, et se mobilise pour r\u00e9duire son impact environnemental sur tous ses sites et aupr\u00e8s de ses clients.\nCapgemini\nCapgemini est un leader mondial, responsable et multiculturel, regroupant pr\u00e8s de 350 000 personnes dans plus de 50 pays. Fort de 55 ans d\u2019exp\u00e9rience, nous sommes un partenaire strat\u00e9gique des entreprises pour la transformation de leurs activit\u00e9s en tirant profit de toute la puissance de la technologie et des innovations dans les domaines en perp\u00e9tuelle \u00e9volution tels que le cloud, la data, l\u2019Intelligence Artificielle, la connectivit\u00e9, les logiciels, l\u2019ing\u00e9nierie digitale ou les plateformes.\nGet The Future You Want* | www.capgemini.com/fr-fr\n*Capgemini, le futur que vous voulez\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "Java",
                "Scala",
                "R",
                "Go"
            ],
            "DataBase": [],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [
                "Hadoop",
                "Spark",
                "Databricks"
            ],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [
                "AWS",
                "Azure",
                "Google Cloud Platform"
            ],
            "DevTools": [
                "Git"
            ],
            "Os": [],
            "DBMS": [
                "Snowflake",
                "Snowflake"
            ],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [
                "Cloud"
            ],
            "FrSoftSkills": [
                "Collaboration",
                "Organisation"
            ],
            "EnSoftSkils": [
                "Collaboration",
                "Initiative"
            ]
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s",
                "3",
                "3",
                "3"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "title": "Big Data engineer \u2013 Ing\u00e9nieur des donn\u00e9es massives (H/F)",
        "company": "DGSE - Direction G\u00e9n\u00e9rale de la S\u00e9curit\u00e9 Ext\u00e9rieure",
        "location": "Paris, \u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/big-data-engineer-%E2%80%93-ing%C3%A9nieur-des-donn%C3%A9es-massives-h-f-at-dgse-direction-g%C3%A9n%C3%A9rale-de-la-s%C3%A9curit%C3%A9-ext%C3%A9rieure-3778473628?position=9&pageNum=2&refId=EunNu8klDuKd8PhUvgvx0Q%3D%3D&trackingId=6VmCvsOgk1%2BOB3QFaDw2dg%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Introduction\nLa Direction G\u00e9n\u00e9rale de la S\u00e9curit\u00e9 Ext\u00e9rieure, DGSE, recrute Big Data engineer \u2013 Ing\u00e9nieur des donn\u00e9es massives (H/F).\nLe poste est situ\u00e9 \u00e0 Paris.\nLa nationalit\u00e9 fran\u00e7aise est obligatoire.\nDomaine m\u00e9tier\nSciences et Technologies\nVotre environnement de travail\nLe flux de donn\u00e9es trait\u00e9es par la DGSE est \u00e9quivalent \u00e0 celui des GAFAM. Ces donn\u00e9es sont au centre du travail des analystes de renseignement, qui doivent pouvoir compter sur des syst\u00e8mes leur permettant de rechercher, croiser, traiter ces donn\u00e9es, en temps r\u00e9el ou en batch. Dans ce contexte, la DGSE cherche \u00e0 renforcer ses \u00e9quipes de traitement de la donn\u00e9e massive.\nAu sein d'un service centr\u00e9 sur le stockage, l'exploitation et la valorisation des donn\u00e9es, nous vous proposons d'int\u00e9grer les \u00e9quipes en charge des plateformes de stockage ou des traitements temps r\u00e9el des donn\u00e9es. Ces \u00e9quipes pluridisciplinaires d\u00e9veloppent et maintiennent de bout en bout diverses plateformes reposant sur les technologies Kafka, Yarn, Hadoop, HBase ou encore Elasticsearch. Plus sp\u00e9cifiquement, l\u2019\u00e9quipe Stockage administre des entrep\u00f4ts Big Data ainsi que des couches d\u2019acc\u00e8s \u00e0 leurs donn\u00e9es. L\u2019\u00e9quipe Temps r\u00e9el con\u00e7oit des algorithmes r\u00e9pondant \u00e0 des besoins de temps de r\u00e9action tr\u00e8s courts (lev\u00e9e d\u2019alertes, enrichissement \u00e0 la vol\u00e9e, r\u00e9ponse \u00e0 des besoins op\u00e9rationnels).\nEn nous rejoignant, vous d\u00e9couvrirez :\nun environnement unique, qu'aucune autre structure ne peut vous proposer,\nun m\u00e9tier proche du renseignement et de l'op\u00e9rationnel,\nune action sur l'int\u00e9gralit\u00e9 de la cha\u00eene, du d\u00e9veloppement au d\u00e9ploiement en production,\nun minimum de 48 jours de cong\u00e9s par an,\nune ambiance propice \u00e0 l\u2019\u00e9panouissement professionnel.\nVos missions\nLes missions des \u00e9quipes auxquelles vous serez amen\u00e9s \u00e0 contribuer seront d\u00e9termin\u00e9es en fonction de votre exp\u00e9rience et de vos app\u00e9tences.\nVous serez en charge de plusieurs activit\u00e9s parmi les suivantes :\nconcevoir, impl\u00e9menter et optimiser des algorithmes de traitement de donn\u00e9es distribu\u00e9s (Scala, Spark, Java),\ngarantir le bon fonctionnement, la disponibilit\u00e9 et la performance des plateformes de traitement,\nparticiper \u00e0 l\u2019\u00e9volution de l\u2019architecture, en int\u00e9grant de nouveaux composants (frameworks, biblioth\u00e8ques, \u2026) permettant de mieux r\u00e9pondre aux besoins,\nassurer une veille technologique constante pour rester au plus haut niveau et garantir une ad\u00e9quation des clusters existants avec l\u2019\u00e9tat de l\u2019art du domaine,\ncontribuer \u00e0 l'am\u00e9lioration continue de l'\u00e9quipe,\ninteragir avec l\u2019\u00e9quipe SRE/Devops pour am\u00e9liorer la fiabilit\u00e9 des architectures, l\u2019automatisation des d\u00e9ploiements et l'observabilit\u00e9 des syst\u00e8mes mis en \u0153uvre.\nVotre profil\nVous \u00eates titulaire d\u2019un dipl\u00f4me en informatique, niveau master ou \u00e9cole d\u2019ing\u00e9nieur, ou pouvez d\u00e9montrer une exp\u00e9rience \u00e9quivalente.\nVous devez poss\u00e9der les comp\u00e9tences et qualit\u00e9s suivantes :\nbonnes connaissances fondamentales logicielles (structures de donn\u00e9es, algorithmique, architecture),\nma\u00eetrise des langages Scala, Java ou python, vous n'avez pas peur de monter en comp\u00e9tences sur ceux que vous ne ma\u00eetrisez pas,\nadepte de l'int\u00e9gration continue, vous \u00eates familier de Gitlab CI, Github Actions ou Jenkins,\nfamilier avec les bonnes pratiques de d\u00e9veloppement collaboratif (usage de git, pratique de relecture de code).\nEn bonus :\npremi\u00e8re exp\u00e9rience avec un framework de traitement en streaming (SparkStreaming, KStream, Storm, Flink, ...),\nconvaincu de l'importance de l'observabilit\u00e9 des syst\u00e8mes qui regroupe m\u00e9trologie, logging et tracing, vous avez d\u00e9j\u00e0 mis en place une stack de ce type (Prometheus, Telegraph, OpenTelemetry, Jaeger, ELK, \u2026),\nfamilier avec un outil de gestion de configuration (Ansible, Puppet, ...),\nexp\u00e9rience sur les clusters Kafka, Hadoop, HBase ou Elasticsearch de plusieurs n\u0153uds.\nLes plus de l\u2019offre\nContexte d\u2019activit\u00e9s unique\nDiversit\u00e9 des projets\nTechnologies \u00e0 la pointe\nContact\nEnvoyez-nous votre candidature \u00e0 l\u2019adresse :\ndgse-macandidature.cer.fct@intradef.gouv.fr\nPlus d\u2019information sur www.dgse.gouv.fr > Nous rejoindre.\nRESTEZ DISCRET SUR VOTRE CANDIDATURE A LA DGSE\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "Java",
                "Scala",
                "R",
                "Go"
            ],
            "DataBase": [
                "HBase",
                "Elasticsearch"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [
                "Hadoop",
                "Spark",
                "Flink"
            ],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [],
            "DevTools": [
                "Git",
                "Jenkins"
            ],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [
                "HBase"
            ],
            "Automation": [
                "Ansible",
                "Puppet"
            ],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [
                "DevOps",
                "Big Data"
            ],
            "FrSoftSkills": [],
            "EnSoftSkils": []
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "title": "Data Engineer (F/H)",
        "company": "Aubay",
        "location": "\u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/data-engineer-f-h-at-aubay-3573871076?position=10&pageNum=2&refId=EunNu8klDuKd8PhUvgvx0Q%3D%3D&trackingId=Fi2i%2BPsUT%2FrkOzoKgGwkpQ%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Passionn\u00e9 par la Data, tu souhaites rejoindre une communaut\u00e9 d\u2019experts dans le domaine afin de d\u00e9velopper tes comp\u00e9tences en Data Engineering. Aubay renforce ses \u00e9quipes Data et recherche des Data Engineers pour int\u00e9grer des dispositifs de projets pointus et vari\u00e9s.\nTon quotidien en tant que Data Engineer chez Aubay, :\nD\u00e9finition de la strat\u00e9gie de stockage et mise en \u0153uvre des technologie appropri\u00e9es (base de donn\u00e9es SQL, NoSQL, stockage distribu\u00e9,\u2026)\nIngestion des donn\u00e9es (structur\u00e9es, semi-structur\u00e9es ou non-structur\u00e9es) selon diff\u00e9rentes fr\u00e9quences : batch, micro-batch ou temps r\u00e9el\nConception et mise en \u0153uvre de pipelines de donn\u00e9es afin de fournir des donn\u00e9es pr\u00eates \u00e0 l\u2019emploi aux consommateurs : uniformisation, mise en qualit\u00e9, enrichissement, calcul d\u2019indicateurs,\u2026\nConception et d\u00e9veloppement d\u2019API pour exposer les donn\u00e9es aupr\u00e8s d\u2019applications tierces\nAppui aux Data Scientists pour industrialiser et optimiser les algorithmes de Machine Learning\nPr\u00e9paration et animation d\u2019ateliers de travail avec des interlocuteurs vari\u00e9s : recueil/approfondissement des besoins m\u00e9tiers, avancement/restitution des travaux, transfert de comp\u00e9tences,\u2026\nTon profil :\nTu dispose d\u2019une formation niveau BAC+5 (Master 2 ou \u00e9cole d\u2019ing\u00e9nieur) sp\u00e9cialis\u00e9e en informatique\nTu as d\u00e9j\u00e0 une premi\u00e8re exp\u00e9rience significative (a minima 2 ans) en Data Engineering sur des technologies Big Data\nLes technologies telles que Hadoop, Spark ou Kafka sont tes technologies de pr\u00e9dilection\nLa programmation n\u2019a plus de secret pour toi et tu maitrise parfaitement un ou plusieurs langages de programmation suivants : Java, Scala et Python\nTu ma\u00eetrises les tenants et aboutissants de la philosophie DevOps et des outils orient\u00e9s CI/CD\nTu es soucieux de la qualit\u00e9 et de la performance de tes d\u00e9veloppements et tu t'int\u00e9resse \u00e0 l\u2019innovation frugale\nTu es un expert technique dans ton domaine sans pour autant oublier l\u2019importance d\u2019une communication orale et \u00e9crite de qualit\u00e9 et adapt\u00e9e \u00e0 chacun de tes interlocuteurs\nTu travaille au quotidien en mode agile et tu en maitrise les fondements\nCe qui nous caract\u00e9rise :\nDes missions et projets dans le domaine du Data Engineering en nombre et dans des secteurs vari\u00e9s (Banque, Assurance, Telecom, Industrie,\u2026) qui permettent \u00e0 nos collaborateurs de monter en comp\u00e9tences et de devenir des experts Data reconnus\nDe l\u2019apprentissage en continu avec des formations et des certifications sur les technologies Data d\u2019aujourd\u2019hui et de demain\nDes experts Data mobilisables pour accompagner et soutenir techniquement les collaborateurs sur leurs projets\nDes communaut\u00e9s de savoir-faire Data proposant de mani\u00e8re r\u00e9guli\u00e8re aux collaborateurs d\u2019Aubay du contenu et des \u00e9v\u00e8nements de partage (webinar, meetup/afterwork, BBL,\u2026) sur les th\u00e9matiques suivantes : Data Engineering, Data Viz, Data Science/IA, Data Platform & Architecture,\u2026\nAubay encourage la diversit\u00e9 sous toutes ses formes et garantit l'\u00e9galit\u00e9 des chances \u00e0 tous les candidats. Tous nos postes sont ouverts aux personnes en situation de handicap et nous proposons tous les am\u00e9nagements n\u00e9cessaires.\nTa carri\u00e8re chez Aubay :\nTu auras la possibilit\u00e9 de d\u00e9velopper et certifier tes comp\u00e9tences sur les derni\u00e8res technologies Data avec un focus fort sur les plateformes Data Cloud telles qu\u2019Azure Synapse Analytics, Google Cloud Platform, Snowflake et Databricks\nTu pourras rejoindre la BU d\u2019excellence Data et \u00e9voluer au sein d\u2019un environnement humain et professionnel de haut niveau. Tu profiteras d\u2019un management sur-mesure pour t'accompagner dans ta trajectoire de carri\u00e8re\nAu sein de la BU d\u2019excellence, de multiples perspectives s\u2019offriront \u00e0 toi :\nR\u00f4le de \u00ab Lead \u00bb : Vous pourrez gagner en responsabilit\u00e9 sur le plan technologique et devenir un r\u00e9f\u00e9rent aupr\u00e8s de nos clients et des collaborateurs de la communaut\u00e9 Data Engineering\nR\u00f4le de \u00ab Champion \u00bb : Vous repr\u00e9senterez Aubay aupr\u00e8s d\u2019un ou plusieurs de nos partenaires \u00e9diteurs strat\u00e9giques et vous participerez activement \u00e0 l\u2019animation de la relation sur le plan technologique\nR\u00f4le de \u00ab Head \u00bb : Vous pourrez prendre la responsabilit\u00e9 du savoir-faire Data Engineering et de ses offres et en assurer le d\u00e9veloppement au sens large (d\u00e9veloppement business, recrutement, management de collaborateurs, d\u00e9finition de la strat\u00e9gie et animation de la communaut\u00e9 au sein du groupe Aubay,\u2026)\nBesoin d\u2019en savoir plus sur le processus de recrutement ?\nUn \u00e9change macro au niveau RH avec Doriane\nUn entretien technique avec Marius ou Peter, deux de nos r\u00e9f\u00e9rents techniques\nUn \u00e9change manag\u00e9rial avec le Directeur de la BU Modern BI & Data\nA savoir que l\u2019ordre des \u00e9tapes peut varier selon tes envies (ex : \u00e9change manag\u00e9rial avec l\u2019\u00e9change technique)\nAubay encourage la diversit\u00e9 sous toutes ses formes et garantit l'\u00e9galit\u00e9 des chances \u00e0 tous les candidats. Tous nos postes sont ouverts aux personnes en situation de handicap et nous proposons tous les am\u00e9nagements n\u00e9cessaires.\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "Java",
                "Scala",
                "R",
                "Go"
            ],
            "DataBase": [
                "SQL",
                "NoSQL"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [
                "Hadoop",
                "Spark",
                "Databricks"
            ],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [
                "Azure",
                "Google Cloud Platform"
            ],
            "DevTools": [],
            "Os": [],
            "DBMS": [
                "Snowflake",
                "Snowflake"
            ],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [
                "DevOps",
                "Big Data",
                "Machine Learning",
                "Cloud",
                "CI/CD"
            ],
            "FrSoftSkills": [
                "Communication"
            ],
            "EnSoftSkils": [
                "Communication"
            ]
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [],
            "Salary": [],
            "Level": [
                "Bac+5"
            ],
            "Experience": [
                "a",
                "n",
                "s",
                "2",
                "2",
                "2"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "title": "Data Engineer",
        "company": "Digital Waffle",
        "location": "Paris, \u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/data-engineer-at-digital-waffle-3913824888?position=1&pageNum=5&refId=63c0Bj1atjsufX74pWwghg%3D%3D&trackingId=CIbs7PPg0iqB6Iyk37LUGw%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Digital Waffle is proud to have partnered with an innovative tech startup in Paris, who are looking for a talented Data Engineer to join their growing team!\nThey are made up of a powerhouse of experts, combining\ndata engineers, business process gurus, and Project managers\nwho leverage the most advanced solutions available; utilising process mining, automation tools, and smart execution systems.\nLooking for an experienced Data Engineer (3-5 years)\nWhat You'll Do:\nThis is a full-time,\nhybrid role (Paris-based)\nwhere you'll wear many hats: data exploration, system integration, data prep, data modeling, and implementing data solutions.\nExperience:\nExpertise in data engineering, data modeling, and ETL (Extract, Transform, Load) processes\nData warehousing and data analytics skills\nExperience handling large, complex datasets\nProficiency in SQL and programming languages like Python or Java\nStellar problem-solving and analytical skills\nTop-notch communication and collaboration abilities\nBachelor's or Master's in Computer Science, Information Systems, or a similar field (a plus for process mining or intelligent process automation experience)\nIf you are an experienced and driven Data Engineer, please apply here!\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "Java",
                "R"
            ],
            "DataBase": [
                "SQL"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [],
            "DevTools": [
                "Git"
            ],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [],
            "FrSoftSkills": [
                "Communication",
                "Collaboration"
            ],
            "EnSoftSkils": [
                "Communication",
                "Collaboration"
            ]
        },
        "details": {
            "JobDetail": [
                "Full"
            ],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "title": "Data Engineer H/F",
        "company": "Ippon Technologies",
        "location": "Greater Nantes Metropolitan Area",
        "link": "https://fr.linkedin.com/jobs/view/data-engineer-h-f-at-ippon-technologies-3902436649?position=2&pageNum=5&refId=63c0Bj1atjsufX74pWwghg%3D%3D&trackingId=GH7vg4huWWuTwG0Xe%2FwWPg%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Envie de rejoindre la communaut\u00e9 DATA la plus dynamique de France ?\nNotre sp\u00e9cialit\u00e9 est de construire des data platform dans le Cloud public avec les meilleurs technos du moment : Snowflake, Databricks, Matillion, DBT.\nMembre de la Practice Data, le/la futur(e) Data Engineer sera int\u00e9gr\u00e9(e) \u00e0 nos \u00e9quipes de conseil et sera suivi(e) par un(e) mentor qui l\u2019aidera \u00e0 monter en comp\u00e9tences.\nVotre champs d\u2019expertise :\nIntervenir sur les data platforms de nos clients pour d\u00e9velopper de nouveaux pipelines de donn\u00e9es (ingestion, traitement, exposition).\nTravailler en collaboration avec les m\u00e9tiers et les data scientists pour leur fournir un support \u00e0 l\u2019industrialisation de leurs travaux (tests, int\u00e9gration continue, scalabilit\u00e9 des mod\u00e8les, craftsmanship etc\u2026)\nD\u00e9ployer des infrastructures cloud full\ninfra-as-code\n(Terraform, CloudFormation).\nParticiper aux \u00e9v\u00e8nements internes \u00e0 la communaut\u00e9 data (BBL, webinar, datap\u00e9ro interne, meetup, blog, dojos) et externes (Salon du Big Data, GCP Summit, Spark Summit, AWS Summit, Devoxx, workshop partenaire, meetups).\nCapitaliser sur les missions et les diff\u00e9rents \u00e9v\u00e8nements de la communaut\u00e9 au travers d\u2019articles de blogs, REX, BBL interne.\nVos connaissances :\nUn framework de calcul distribu\u00e9 tel que Spark, Storm, Flink.\nUn ou plusieurs langages de programmation (Python, Scala, Java...)\nDiff\u00e9rents syst\u00e8mes de stockage de donn\u00e9es (SQL ou NoSQL) et bien s\u00fbr le langage SQL.\nLa connaissance de Snowflake est bienvenue ;-)\nUn framework de streaming de donn\u00e9es tel que Kafka ou Amazon Kinesis.\nUne exp\u00e9rience sur les technologies Cloud : AWS, GCP, Azure\nLe delivery et les projets en production faisant partie de notre ADN, vous \u00eates capable de livrer du code de qualit\u00e9 dans des environnements agiles.\nDe plus en plus de nos projets se font en remote avec des clients du monde entier, il devient n\u00e9cessaire d\u2019\u00eatre \u00e0 l\u2019aise en Anglais.\nIppon technologies c\u2019est aussi :\n\ud83d\udc4d B\u00e9n\u00e9ficier d'un suivi de proximit\u00e9 r\u00e9alis\u00e9 par votre manager technique : points r\u00e9guliers pour votre suivi en mission, votre formation et votre \u00e9volution de carri\u00e8re\n\u270c\ufe0f Rejoindre une entreprise o\u00f9 les valeurs du sport sont nos leitmotiv : d\u00e9passement de soi, travail en \u00e9quipe, bienveillance.\n\ud83d\uddd2\ufe0f Apprendre via notre programme de formation BlackBelt : https://bit.ly/3ByqcIL\n\ud83d\ude01 Travailler en pair programming ou avec un.e mentor pour gravir les \u00e9chelons !\n\ud83d\udcaa Pouvoir participer \u00e0 une aventure humaine au sein de notre Fondation Ippon pour r\u00e9duire la fracture num\u00e9rique dans le monde !\n\ud83e\udd1d Participer \u00e0 nos ap\u00e9ros et divers \u00e9v\u00e8nements internes pour consolider la coh\u00e9sion d\u2019\u00e9quipe\nEt apr\u00e8s ?\nEt oui alors ? Que se passe-t-il une fois que vous \u00eates convaincu d\u2019avoir lu l\u2019offre d\u2019emploi qui vous correspond bien ?\nNous vous proposons de prendre contact et de nous rencontrer !\nLes Next Steps :\n1 call RH\n1 \u00e9change RH\n1 \u00e9change Technique\nSi le match est bon des deux c\u00f4t\u00e9s : Hadjim\u00e9 ! Vous vous lancerez sur le tatami Ippon !\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "Java",
                "Scala",
                "R"
            ],
            "DataBase": [
                "SQL",
                "NoSQL"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [
                "Spark",
                "Databricks",
                "Flink"
            ],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [
                "AWS",
                "Azure"
            ],
            "DevTools": [],
            "Os": [],
            "DBMS": [
                "Snowflake",
                "Snowflake"
            ],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [
                "Terraform",
                "CloudFormation"
            ],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [
                "Big Data",
                "Cloud"
            ],
            "FrSoftSkills": [
                "Collaboration"
            ],
            "EnSoftSkils": [
                "Collaboration"
            ]
        },
        "details": {
            "JobDetail": [
                "Remote",
                "Full"
            ],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "title": "Data Engineer \u2013 Antibes, France (H/F)",
        "company": "Astek",
        "location": "Antibes, Provence-Alpes-C\u00f4te d'Azur, France",
        "link": "https://fr.linkedin.com/jobs/view/data-engineer-%E2%80%93-antibes-france-h-f-at-astek-3909192086?position=3&pageNum=5&refId=63c0Bj1atjsufX74pWwghg%3D%3D&trackingId=UlDBekVCS59%2Ffa2Hrk0odA%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "CDI\nAntibes - France\nPubli\u00e9e il y a 2 semaines\nLe Groupe Astek\nCe Que Nous Allons Accomplir Ensemble :\nIntervenir dans la conception, le d\u00e9veloppement, les tests unitaires, la qualification, l\u2019int\u00e9gration continue et la mise en production d\u2019\u00e9volutions sur les projets du p\u00f4le produits scoring (un p\u00f4le visant \u00e0 d\u00e9velopper des solutions permettant de g\u00e9n\u00e9rer des scores ou des segments d\u2019information pertinents dans divers domaines, notamment : profiling TV, PUB, SAB, MMDM, Voscastview) chez l\u2019un de nos partenaires sp\u00e9cialis\u00e9 dans le secteur des t\u00e9l\u00e9coms.\nVotre Mission, Si Vous L\u2019acceptez :\nEn collaboration avec les autres membres de l\u2019\u00e9quipe, vous devrez prendre en charge le RUN des applications du p\u00f4le produit scoring.\nConception d\u2019une solution se basant sur les d\u00e9veloppements existants et les besoins m\u00e9tiers remont\u00e9s par le Product Owner.\nR\u00e9alisation et d\u00e9veloppement de nouvelles fonctionnalit\u00e9s sur les composants des applications du p\u00f4le produits scoring et environnement CGP.\nVotre Future \u00c9quipe :\nAu sein d\u2019un environnement riche et complexe, vous \u00e9voluerez avec des experts passionn\u00e9s \u00e0 la fois techniques et fonctionnels (Ing\u00e9nieurs sp\u00e9cialis\u00e9s, chef de projet, scrum master, product owner, analystes \u2026).\nVotre stack de jeu\nD ans un environnement SAFE sous cloud GCP, Big Query, OnPrime, Grafana, Python et Ansible.\nVous ?\nDe formation Ing\u00e9nieur, vous justifiez d\u2019une premi\u00e8re exp\u00e9rience sur un poste de Data engineer. Vous poss\u00e9dez des comp\u00e9tences d\u2019autonomie et d\u2019adaptabilit\u00e9 et vous avez une capacit\u00e9 \u00e0 communiquer efficacement au sein d\u2019une \u00e9quipe.\nLe Groupe Astek\nCr\u00e9\u00e9 en France en 1988, Astek est un acteur mondial de l\u2019ing\u00e9nierie et du conseil en technologies. Fort de son expertise dans de nombreux secteurs industriels et tertiaires, Astek accompagne ses clients internationaux dans le d\u00e9ploiement intelligent de leurs produits et de leurs services, et dans la mise en \u0153uvre de leur transformation digitale.\nDepuis sa cr\u00e9ation, le Groupe a fond\u00e9 son d\u00e9veloppement sur une forte culture d\u2019entrepreneuriat et d\u2019innovation, et sur l\u2019accompagnement et la mont\u00e9e en comp\u00e9tence de\nses 7800 collaborateurs\nqui s\u2019engagent chaque jour \u00e0 promouvoir la compl\u00e9mentarit\u00e9 entre les technologies num\u00e9riques et l\u2019ing\u00e9nierie des syst\u00e8mes complexes.\nRejoignez un Groupe en fort d\u00e9veloppement en France et \u00e0 travers le monde ayant r\u00e9alis\u00e9 un chiffre d\u2019affaires de 600 M\u20ac en 2023.\nTous les d\u00e9tails sur le Groupe sur le site https://astekgroup.fr. Et vous pouvez aussi nous suivre sur notre blog : https://blog.groupeastek.com.\nRencontrons-nous\nCr\u00e9\u00e9 en France en 1988, Astek est un acteur mondial de l\u2019ing\u00e9nierie et du conseil en technologies, pr\u00e9sent sur les 5 continents. Fort de son expertise dans de nombreux secteurs industriels et tertiaires, Astek accompagne ses clients internationaux dans le d\u00e9ploiement intelligent de leurs produits et de leurs services, et dans la mise en \u0153uvre de leur transformation digitale.\nDepuis sa cr\u00e9ation, le Groupe a fond\u00e9 son d\u00e9veloppement sur une forte culture d\u2019entrepreneuriat et d\u2019innovation, et sur l\u2019accompagnement et la mont\u00e9e en comp\u00e9tence de ses 7800 collaborateurs qui s\u2019engagent chaque jour \u00e0 promouvoir la compl\u00e9mentarit\u00e9 entre les technologies num\u00e9riques et l\u2019ing\u00e9nierie des syst\u00e8mes complexes.\nRejoignez un Groupe en fort d\u00e9veloppement en France et \u00e0 travers le monde et ayant r\u00e9alis\u00e9 un chiffre d\u2019affaires hors\nacquisitions de 600M\u20ac en 2023.\nTous les d\u00e9tails sur le Groupe sur le site\nNos Plus\nAstek est green et fait b\u00e9n\u00e9ficier ses salari\u00e9s d\u2019une indemnit\u00e9 kilom\u00e9trique v\u00e9lo\nUne politique CARE sur-mesure d\u00e9ploy\u00e9e par nos \u00e9quipes RH pour nos collaborateurs (https://astekgroup.fr/engagements)\nNotre charte de la Diversit\u00e9\nMots-cl\u00e9s :\ning\u00e9nieur \u2013 ing\u00e9nieure \u2013 consultant \u2013 consultante \u2013 Data engineer \u2013 Big Data\nCaract\u00e9ristiques de l'emploi\nCat\u00e9gorie Ing\u00e9nieur\nJob Industry T\u00e9l\u00e9com / M\u00e9dia\nPostuler en ligne\nNom *\nPr\u00e9nom *\nEmail *\nUn email valide est requis.\nT\u00e9l\u00e9phone *\nUn num\u00e9ro de t\u00e9l\u00e9phone valide est requis.\nJoindre un CV *\nMots-cl\u00e9s :\ning\u00e9nieur \u2013 ing\u00e9nieure \u2013 consultant \u2013 consultante \u2013 Data engineer \u2013 Big Data\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "R",
                "Go"
            ],
            "DataBase": [],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [],
            "DevTools": [
                "Git"
            ],
            "Os": [],
            "DBMS": [
                "Big Query"
            ],
            "SoftBigDataProcessing": [],
            "Automation": [
                "Ansible",
                "Chef"
            ],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [
                "Big Data",
                "Cloud"
            ],
            "FrSoftSkills": [
                "Adaptabilit\u00e9",
                "Collaboration"
            ],
            "EnSoftSkils": [
                "Collaboration"
            ]
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [
                "CDI"
            ],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "title": "Data Engineer - Profils exp\u00e9riment\u00e9s H/F",
        "company": "LCL",
        "location": "Villejuif, \u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/data-engineer-profils-exp%C3%A9riment%C3%A9s-h-f-at-lcl-3888403052?position=4&pageNum=5&refId=63c0Bj1atjsufX74pWwghg%3D%3D&trackingId=gIHYgeFCEYY8kCc8uBBh3Q%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "\ud83c\udfe6 LCL, c\u2019est LA banque urbaine du Groupe Cr\u00e9dit Agricole - avec nous, accompagnez la transformation, le d\u00e9veloppement et le maintien technologiques de nos outils avec une vision business et de satisfaction de nos 6 millions de clients.\nEn tant qu\u2019acteur majeur de la banque de d\u00e9tail, nous nous adaptons chaque jour aux nouveaux modes de consommation et les projets de nos de clients internes et externes tout en garantissant le besoin de s\u00e9curit\u00e9 et de d\u00e9veloppement technologique qu\u2019impliquent nos activit\u00e9s.\n\ud83d\udca1Organis\u00e9es en mode Agile, les 8 squads de la tribu DATA (6 squads M\u00e9tier et 2 squads transverses) \u0153uvrent au quotidien pour r\u00e9pondre \u00e0 un enjeu majeur pour la banque : la collecte, le stockage, la gestion et l\u2019usage de la donn\u00e9e. En interaction permanente avec les autres tribus IT et les m\u00e9tiers, elles \u00e9tudient et proposent les solutions et architectures \u00e0 d\u00e9ployer pour r\u00e9pondre au mieux aux strat\u00e9gies de d\u00e9veloppement et de pilotage de l\u2019ensemble des m\u00e9tiers de la banque.\nRejoignez-nous si vous souhaitez participer aux r\u00e9flexions et au d\u00e9veloppement de la trajectoire technique et DataCentric du SI LCL et plus largement du Groupe CA. Vous c\u00f4toierez et serez au c\u0153ur de l\u2019impl\u00e9mentation de technologies vari\u00e9es telles que les plateformes Teradata, les solutions d\u2019architecture applicative des technologies BigData ou IA, des environnements analytiques ou encore des solutions de datavisualisation. Vous assurerez le traitement de donn\u00e9es en temps r\u00e9el ou en batch et exposerez les donn\u00e9es sous diff\u00e9rentes formes.\nQue vous souhaitiez devenir expert sur les socles technologiques ou relever le challenge de la gestion de projets M\u00e9tier, nous vous aiderons \u00e0 atteindre vos propres objectifs.\nVous rejoindrez une \u00e9quipe pluridisciplinaire, clairement orient\u00e9e vers le d\u00e9veloppement de ses collaborateurs \u00e0 de nouvelles technologies !\n\ud83c\udfaf En tant que Data Engineer :\n\u00b7 Vous aimez analyser les besoins avec les m\u00e9tiers, challenger, identifier les sources de donn\u00e9es dans les diff\u00e9rents univers technologiques, industrialiser des algorithmes, concevoir et d\u00e9velopper des Datalab ou des Datamart sur les plateformes ? Vous saurez relever les challenges propos\u00e9s par les squads m\u00e9tier !\n\u00b7 Vous pr\u00e9f\u00e9rez travailler \u00e0 l\u2019architecture et au d\u00e9ploiement de nouvelles plateformes, \u00e0 la lev\u00e9e de la dette technologique ou encore r\u00e9aliser de la veille au service de notre trajectoire ? La squad Socles Data est faite pour vous !\n\u00b7 Au-del\u00e0 des projets que vous g\u00e9rerez, garant du bon fonctionnement de votre parc applicatif, vous attacherez une grande attention \u00e0 la mise en \u0153uvre de solutions optimis\u00e9es.\n\u00b7 La rigueur, la communication, l\u2019esprit d\u2019\u00e9quipe mais aussi la curiosit\u00e9 et la cr\u00e9ativit\u00e9 font partie de vos soft skills ! ils vous permettront de r\u00e9pondre aux enjeux de s\u00e9curit\u00e9, de qualit\u00e9, de transmission de la connaissance et contribueront \u00e0 l\u2019atteinte des objectifs de l\u2019IT et plus largement de LCL, au service de ses clients.\n\ud83d\udcbb Voici les principales technologies utilis\u00e9es au sein de la tribu, si certaines vous sont famili\u00e8res, nous vous aiderons \u00e0 monter en comp\u00e9tence sur d\u2019autres !\nLangages utilis\u00e9s : SQL, Python, Scala\nSGBD : Teradata et utilitaires (TPT, BTEQ, \u2026)\nStreaming : Kafka\nSearch : ElasticSearch, SolR\nEnvironnement : Unix\nSolutions Big Data : Hadoop Cloudera, DataIku, HDFS, Hive, Impala,\nDevops : GitLab, Jenkins, Nexus\nOutils de visualisation : MS BI (SSIS, SSAS, SSRS) Qlik Sens, BO\nMod\u00e9lisation : MEGA\nOutils collaboratifs : GIT, Jira, Confluence, Teams\n\u26a1Si les nouveaux enjeux bancaires vous int\u00e9ressent, que vous souhaitez int\u00e9grer une \u00e9quipe Agile au service des m\u00e9tiers dans laquelle vous serez force de proposition et que vous aimez travailler dans un environnement motivant et dynamique, rejoignez-nous, cette offre est faite pour vous !\n\ud83d\udd25 Les + de notre entreprise :\nAcc\u00e8s au Plan d\u2019\u00e9pargne Groupe, int\u00e9ressement et participation aux b\u00e9n\u00e9fices de l\u2019entreprise + abondement\nPrix pr\u00e9f\u00e9rentiels bancaires et avantages CSE\nParcours \u00e9volutif dans l\u2019entreprise et/ou dans le Groupe CA.S.A\nT\u00e9l\u00e9travail (jusqu'\u00e0 2 jours de t\u00e9l\u00e9travail par semaine)\nDe multiples commodit\u00e9s sur le campus (restaurants d'entreprise, salle de sport, cr\u00e8che, centre m\u00e9dical, m\u00e9diath\u00e8que...)\nForfait et avantages pratiques \u00ab mobilit\u00e9 durable \u00bb pour les velotafeurs\nDes \u00e9quipes aussi diversifi\u00e9es que structur\u00e9es dans une dynamique de transformation\nLCL s\u2019engage en faveur de la diversit\u00e9 et nous encourageons tout(e) candidat(e) ayant l\u2019exp\u00e9rience requise \u00e0 postuler \u00e0 nos offres. Tous nos postes sont ouverts aux personnes en situation de handicap.\nNous avons encore de nombreuses raisons \u00e0 vous pr\u00e9senter pour vous convaincre de nous rejoindre mais pour cela, il faudra postuler ici !\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "Scala",
                "R",
                "Go"
            ],
            "DataBase": [
                "SQL",
                "Elasticsearch"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [
                "Hadoop"
            ],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [],
            "DevTools": [
                "Git",
                "Jenkins"
            ],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [
                "JIRA",
                "Confluence",
                "Teams"
            ],
            "Other": [
                "DevOps",
                "Big Data",
                "Cloud"
            ],
            "FrSoftSkills": [
                "Communication",
                "Cr\u00e9ativit\u00e9"
            ],
            "EnSoftSkils": [
                "Communication"
            ]
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "title": "Big Data Engineer Confirm\u00e9 \u2013 Paris, France (H/F)",
        "company": "Astek",
        "location": "Paris, \u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/big-data-engineer-confirm%C3%A9-%E2%80%93-paris-france-h-f-at-astek-3839098103?position=5&pageNum=5&refId=63c0Bj1atjsufX74pWwghg%3D%3D&trackingId=%2Fgv3ywdDRdhT0vOlps7OZw%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "CDI\nParis - France\nPubli\u00e9e il y a 2 mois\nLe Groupe Astek\nCe Que Nous Allons Accomplir Ensemble :\nNous rejoindre en tant que\nBig Data Engineer Confirm\u00e9 (H/F),\nafin d\u2019accompagner un op\u00e9rateur t\u00e9l\u00e9coms, Leader en Europe dans l\u2019assistance et le support applicatif de niveau 3 (r\u00e9solution des probl\u00e8mes utilisateurs, exploitation des environnements hors production).\nUn challenge portant sur des millions d\u2019utilisateurs dans un environnement technique innovant, strat\u00e9gique et o\u00f9 l\u2019entraide et la bonne humeur priment !\nVotre Mission, Si Vous L\u2019acceptez :\nSupervision et d\u00e9tection et r\u00e9solution des probl\u00e8mes utilisateurs (d\u00e9veloppeurs, exploitants et data exploreurs)\nD\u00e9veloppement de solutions de self-service ou d\u2019une solution de r\u00e9solutions automatiques des probl\u00e8mes\nQualifier les donn\u00e9es et les r\u00e9sultats\nConception technique des solutions\nAssurer l\u2019accompagnement et le d\u00e9ploiement des \u00e9volutions des processus et outils\nAccompagner la phase de mise en production\nVotre Future \u00c9quipe :\nVous int\u00e9grerez une \u00e9quipe \u00e0 la fois technique et fonctionnel, qui \u0153uvre chaque jour pour d\u00e9velopper et maintenir en conditions op\u00e9rationnelles l\u2019ensemble des solutions IT !\nL\u2019\u00e9quipe est en interaction avec des clients \u00e0 la fois internes et externes.\nVotre stack de jeu\nSyst\u00e8me d\u2019exploitation : Linux\nOutils des distributions : HDP, HDF, ELK\nEnvironnement Big data : Hadoop, Spark,\nLangage : Scala, Shell, Python\nCloud computing : GCP ou AWS\nBase de donn\u00e9es : No SQL (Cassandra, Mongo DB), Shell, Ansible\nDataviz : Power BI ou Kibana\nDes notions en R\u00e9seau et Syst\u00e8mes feront la diff\u00e9rence !\nLes Petits Plus Du Projet :\nVous \u00e9voluerez au sein d\u2019une \u00e9quipe impliqu\u00e9e et r\u00e9active et interviendrez sur un projet polyvalent et \u00e0 forte valeur ajout\u00e9e.\nVous ?\nDipl\u00f4m\u00e9(e) d\u2019une \u00e9cole d\u2019ing\u00e9nieur ou \u00e9quivalent de niveau Bac+5.\nVous justifiez id\u00e9alement d\u2019une exp\u00e9rience d\u2019au moins 3 ans d\u2019exp\u00e9riences sur un poste similaire ?\nVous faite preuve de proactivit\u00e9 et d\u2019esprit d\u2019\u00e9quipe, \u00eates dot\u00e9(e) d\u2019un excellent sens de l\u2019organisation et vous aimez les challenges et la r\u00e9solution de probl\u00e8me ?\nAlors ce poste est fait pour vous, n\u2019h\u00e9sitez plus et rejoignez l\u2019aventure ASTEK !\nAstek\nCr\u00e9\u00e9 en France en 1988, Astek est un acteur mondial de l\u2019ing\u00e9nierie et du conseil en technologies. Fort de son expertise dans de nombreux secteurs industriels et tertiaires, Astek accompagne ses clients internationaux dans le d\u00e9ploiement intelligent de leurs produits et de leurs services, et dans la mise en \u0153uvre de leur transformation digitale.\nDepuis sa cr\u00e9ation, le Groupe a fond\u00e9 son d\u00e9veloppement sur une forte culture d\u2019entrepreneuriat et d\u2019innovation, et sur l\u2019accompagnement et la mont\u00e9e en comp\u00e9tence de\nses 7800 collaborateurs\nqui s\u2019engagent chaque jour \u00e0 promouvoir la compl\u00e9mentarit\u00e9 entre les technologies num\u00e9riques et l\u2019ing\u00e9nierie des syst\u00e8mes complexes.\nRejoignez un Groupe en fort d\u00e9veloppement en France et \u00e0 travers le monde ayant r\u00e9alis\u00e9 un chiffre d\u2019affaires de 600 M\u20ac en 2023.\nTous les d\u00e9tails sur le Groupe sur le site https://astekgroup.fr. Et vous pouvez aussi nous suivre sur notre blog : https://blog.groupeastek.com.\nRencontrons-nous\nNotre projet commun vous plait ?\nPostulez \u00e0 cette annonce, et soyez transparent !\nMaud, notre Talent Acquisition Referent, vous contactera pour un premier \u00e9change.\nPuis vous rencontrerez Martin, votre futur manager, avec lequel vous \u00e9changerez autour d\u2019Astek, de votre parcours, de vos attentes et de votre future mission .\nEnfin, vous rencontrerez J\u00e9r\u00e9my, notre Directeur d\u2019agence avec lequel vous pourrez valider votre int\u00e9r\u00eat et ad\u00e9quation pour le poste et finaliser les \u00e9l\u00e9ments contractuels.\nNos Plus\nAstek est green et fait b\u00e9n\u00e9ficier ses salari\u00e9s d\u2019une indemnit\u00e9 kilom\u00e9trique v\u00e9lo\nUne politique CARE sur-mesure d\u00e9ploy\u00e9e par nos \u00e9quipes RH pour nos collaborateurs (https://astekgroup.fr/engagements)\nNotre charte de la Diversit\u00e9\nMots-cl\u00e9s :\ning\u00e9nieur \u2013 ing\u00e9nieure \u2013 consultant \u2013 consultante \u2013 Hadoop \u2013 Scala \u2013 Data\nCaract\u00e9ristiques de l'emploi\nCat\u00e9gorie Ing\u00e9nieur\nJob Industry T\u00e9l\u00e9com / M\u00e9dia\nPostuler en ligne\nNom *\nPr\u00e9nom *\nEmail *\nUn email valide est requis.\nT\u00e9l\u00e9phone *\nUn num\u00e9ro de t\u00e9l\u00e9phone valide est requis.\nJoindre un CV *\nMots-cl\u00e9s :\ning\u00e9nieur \u2013 ing\u00e9nieure \u2013 consultant \u2013 consultante \u2013 Hadoop \u2013 Scala \u2013 Data\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "Scala",
                "R",
                "Go"
            ],
            "DataBase": [
                "SQL",
                "Cassandra"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [
                "Hadoop",
                "Spark"
            ],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [
                "Power BI"
            ],
            "Statistics": [],
            "CloudComputing": [
                "AWS"
            ],
            "DevTools": [
                "Git"
            ],
            "Os": [
                "Linux"
            ],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [
                "Ansible"
            ],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [
                "Big Data",
                "Cloud"
            ],
            "FrSoftSkills": [
                "Organisation"
            ],
            "EnSoftSkils": []
        },
        "details": {
            "JobDetail": [
                "Confirm\u00e9"
            ],
            "TypeContract": [
                "CDI"
            ],
            "Salary": [],
            "Level": [
                "Bac+5"
            ],
            "Experience": [
                "a",
                "n",
                "s",
                "3",
                "3",
                "3"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "title": "Data Engineer (H/F) - Lille",
        "company": "Logic@l Conseils",
        "location": "Lille, Hauts-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/data-engineer-h-f-lille-at-logic%40l-conseils-3811575649?position=6&pageNum=5&refId=63c0Bj1atjsufX74pWwghg%3D%3D&trackingId=lsnSMaZYOtp54jPBFAW7cQ%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Dans le cadre du d\u00e9veloppement de nos activit\u00e9s sur la m\u00e9tropole Lilloise, nous recherchons un\nconsultant data engineer\n(H/F) pour intervenir chez l'un de nos grands comptes clients.\nVos missions :\nRecueillir\nles besoins m\u00e9tiers et des \u00e9quipes data\nConcevoir et mettre en place les\ntraitements de donn\u00e9es\nR\u00e9aliser les\ntests de validation\nAssurer\nl\u2019alimentation du dataware\nR\u00e9aliser les\nordonnancements des traitements\nEtre garant de la\nmise en place\n, du\nsuivi\net de l\u2019\nexploitation\ndes outils d\u00e9ploy\u00e9s\nAssurer\nune veille technologique\nr\u00e9guli\u00e8re\nEnvironnement technique :\nD\u00e9veloppement :\nPython, Scala, R, Java,\nFramework :\nSpark,\nHadoop,\nOutils Big data :\nYarn, Pig, Hive, Kafka, Splunk\nBases de donn\u00e9es :\nMongoDB, HBase, Cassandra\nETL :\nTalend, Stambia\nPlateforme :\nHortonworks, Cloudera, Map Reduce\n,\nAWS, GCP, Azure\nVotre profil :\nVous disposez d\u2019une exp\u00e9rience\nd\u2019au moins 2 ans en tant que data engineer\nou dans le domaine de l\u2019analyse et du traitement de donn\u00e9es.\nV\u00e9ritable\npassionn\u00e9 de la data\n, vous \u00eates\nforce de proposition\nsur les solutions techniques \u00e0 mettre en \u0153uvre. Vous maitrisez l\u2019anglais dans un contexte professionnel.\nComp\u00e9tences requises :\nAnalyses qualitatives et quantitatives (Interm\u00e9diaire)\nAnglais (Interm\u00e9diaire)\nArchitecture fonctionnelle SI (D\u00e9butant)\nD\u00e9veloppement d'ouvrages, produits ou \u00e9v\u00e9nements (D\u00e9butant)\nGestion des contr\u00f4les, tests et diagnostics (D\u00e9butant)\nGestion des risques (Interm\u00e9diaire)\nMa\u00eetrise des logiciels (Interm\u00e9diaire)\nMise en exploitation / Production et maintenance (D\u00e9butant)\nNos valeurs\nNous avons d\u00e9cid\u00e9 de renverser la pyramide du management pour placer nos collaborateurs en t\u00eate des priorit\u00e9s de l\u2019entreprise.\nEn effet, attach\u00e9 \u00e0 des valeurs fortes, telles que la proximit\u00e9, la sinc\u00e9rit\u00e9, la fid\u00e9lit\u00e9, la confiance et le respect, nous sommes persuad\u00e9s que la r\u00e9ussite r\u00e9side dans le bien-\u00eatre de nos collaborateurs.\nCela se traduit par un accompagnement de proximit\u00e9, de la transparence sans langue de bois, des \u00e9changes r\u00e9guliers avec les managers r\u00e9f\u00e9rents, un accompagnement dans le d\u00e9veloppement de carri\u00e8re qui est construit et jalonn\u00e9 avec les formations et certifications n\u00e9cessaires et les missions en ad\u00e9quation, pour mener \u00e0 bien l\u2019\u00e9volution de carri\u00e8re.\nPour vous convaincre de nous rejoindre, nos avantages salari\u00e9s compl\u00e9mentaires :\nEnvironnement bienveillant et stimulant au sein de 3 p\u00f4les d\u2019expertises\nFormations et Certifications \u00e0 la demande\nTickets restaurants : 13\u20ac par ticket\nRemboursement \u00e0 100 % des abonnements de transports en commun\nMutuelle frais de sant\u00e9 avec de hautes garanties\nPrise en charge \u00e0 100% de l\u2019assurance Pr\u00e9voyance\nCh\u00e8que Cadeau Culture 120 \u20ac\nCompte CSE avec une cagnotte de 390 \u20ac\nCompte CE : billetterie, voyages, culture, sorties, \u00e0 des tarifs pr\u00e9f\u00e9rentiels\nDes \u00e9v\u00e8nements chaque mois : activit\u00e9s associatives, sportives, afterwork, s\u00e9minaire,\nPartenariat Losc (participation aux match dans la loge VIP logical conseils \u2013 (Une Vingtaine de match par an)\nPossibilit\u00e9 de t\u00e9l\u00e9travail\nEn int\u00e9grant Logic@l Conseils, vous participez \u00e0 une r\u00e9elle aventure humaine, alors pour postuler, il suffit de cliquer ci-dessous !\nTous nos postes sont ouverts, \u00e0 comp\u00e9tences \u00e9gales, aux personnes en situation de handicap.\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "Java",
                "Scala",
                "R",
                "Go"
            ],
            "DataBase": [
                "Cassandra",
                "HBase"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [
                "Hadoop",
                "Spark"
            ],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [
                "AWS",
                "Azure"
            ],
            "DevTools": [],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [
                "HBase"
            ],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [
                "Big Data",
                "Cloud"
            ],
            "FrSoftSkills": [],
            "EnSoftSkils": []
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s",
                "2",
                "2",
                "2"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "title": "Data Engineer",
        "company": "CGI",
        "location": "Niort, Nouvelle-Aquitaine, France",
        "link": "https://fr.linkedin.com/jobs/view/data-engineer-at-cgi-3902057928?position=7&pageNum=5&refId=63c0Bj1atjsufX74pWwghg%3D%3D&trackingId=rAZwnI6BIvOJVViuEWO5Cw%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Description de poste\nBig Data, Data Science, Data analyse, Data architecture ... \u00c7a n\u2019a pas de secret pour vous ?\nQue vous commenciez votre carri\u00e8re professionnelle ou que vous soyez sp\u00e9cialiste de l\u2019une de ces disciplines, int\u00e9grer notre communaut\u00e9 Data, c\u2019est l\u2019assurance de progresser, innover, partager, vous certifier et rendre service \u00e0 nos clients.\nSi vous souhaitez int\u00e9grer nos \u00e9quipes \u00e0 Niort et accompagner les plus grands acteurs du secteur des Assurances, cette annonce est susceptible de vous int\u00e9resser.\nEn tant que Data Engineer, vous serez responsable de la conception, du d\u00e9veloppement, de la gestion et de l'int\u00e9gration des syst\u00e8mes bas\u00e9s sur les technologies AWS, Terraform, OpenShift, Kafka et Hadoop. Ce r\u00f4le implique la mise en place d'architectures \u00e9volutives et hautement disponibles pour r\u00e9pondre aux besoins de traitement et de stockage de donn\u00e9es de l'entreprise.\nFonctions et responsabilit\u00e9s\nVos responsabilit\u00e9s seront les suivantes:\n-Maintenir et d\u00e9velopper des solutions bas\u00e9es sur les services AWS pour le stockage, le traitement et l'analyse de donn\u00e9es\n-Utiliser les services AWS appropri\u00e9s tels que Amazon EC2, S3, RDS, Lambda, etc., pour r\u00e9pondre aux exigences du projet.\n-Cr\u00e9er et maintenir les configurations Terraform pour la gestion de l'infrastructure en tant que code (IaC) sur AWS\n-Participer \u00e0 la maintenance et \u00e0 la mise en place d'environnements OpenShift pour l'h\u00e9bergement d'applications et de services\n-G\u00e9rer et administrer les clusters Kafka pour garantir la disponibilit\u00e9, la performance et la s\u00e9curit\u00e9 du syst\u00e8me de messagerie\nParticiper \u00e0 l\u2019assistance utilisateurs sur les briques de la plateforme Hadoop Cloudera Data\n-Travailler avec les projets et les devOps pour assurer un traitement efficace des donn\u00e9es\nEn rejoignant CGI, vous b\u00e9n\u00e9ficiez notamment d\u2019une offre compl\u00e8te de formations (techniques, m\u00e9tiers, d\u00e9veloppement personnel,\u2026), de flexibilit\u00e9 gr\u00e2ce \u00e0 notre accord t\u00e9l\u00e9travail (jusqu\u2019\u00e0 3 jours de t\u00e9l\u00e9travail par semaine), d\u2019une politique de cong\u00e9s avantageuse (27 jours de cong\u00e9s pay\u00e9s, RTT, cong\u00e9s anciennet\u00e9 et enfant malade,\u2026) et d\u2019un package d\u2019avantages int\u00e9ressant (r\u00e9gime d\u2019achats d\u2019actions, participation, CSE,...).\nQualit\u00e9s requises pour r\u00e9ussir dans ce r\u00f4le\nAyant une premi\u00e8re exp\u00e9rience en tant que Data Engineer, vous avez une premi\u00e8re exp\u00e9rience relative aux points suivants:\n-D\u00e9veloppement et int\u00e9gration sur les technologies AWS, Terraform, OpenShift, Kafka et Hadoop\n-Connaissance avanc\u00e9e de l'administration Kafka, y compris la configuration, la gestion et la r\u00e9solution des probl\u00e8mes\n-Mise en \u0153uvre de l'infrastructure en tant que code \u00e0 l'aide de Terraform\n-Bonne compr\u00e9hension des bonnes pratiques de s\u00e9curit\u00e9 pour les syst\u00e8mes cloud, les clusters Kafka et les plateformes Hadoop\nCGI est un employeur inclusif et attentif aux candidatures des personnes en situation de handicap, \u00e0 l\u2019\u00e9volution de carri\u00e8res des hommes et des femmes et au bien-\u00eatre de nos salari\u00e9s LGBT+. Dans un souci d\u2019accessibilit\u00e9 et de clart\u00e9, le point m\u00e9dian n\u2019est pas utilis\u00e9 dans cette annonce. Tous les termes employ\u00e9s se r\u00e9f\u00e8rent aussi bien au genre f\u00e9minin que masculin.\nEnsemble, en tant que propri\u00e9taires, mettons notre savoir-faire \u00e0 l\u2019\u0153uvre.\nLa vie chez CGI est ancr\u00e9e dans l\u2019actionnariat, le travail d\u2019\u00e9quipe, le respect et un sentiment d\u2019appartenance. Chez nous, vous pourrez exploiter votre plein potentiel parce que\u2026\nNous vous invitons \u00e0 devenir propri\u00e9taire d\u00e8s le jour 1 alors que nous travaillons ensemble \u00e0 faire de notre r\u00eave une r\u00e9alit\u00e9. C\u2019est pourquoi nous nous d\u00e9signons comme associ\u00e9s de CGI, plut\u00f4t que comme employ\u00e9s. Nous tirons profit des retomb\u00e9es de notre succ\u00e8s collectif et contribuons activement \u00e0 l\u2019orientation et \u00e0 la strat\u00e9gie de notre entreprise.\nVotre travail cr\u00e9e de la valeur. Vous \u00e9laborerez des solutions novatrices et d\u00e9velopperez des relations durables avec vos coll\u00e8gues et clients, tout en ayant acc\u00e8s \u00e0 des capacit\u00e9s mondiales pour concr\u00e9tiser vos id\u00e9es, saisir de nouvelles opportunit\u00e9s, et b\u00e9n\u00e9ficier d\u2019une expertise sectorielle et technologique de pointe.\nVous ferez \u00e9voluer votre carri\u00e8re en vous joignant \u00e0 une entreprise b\u00e2tie pour cro\u00eetre et durer. Vous serez soutenus par des leaders qui ont votre sant\u00e9 et bien-\u00eatre \u00e0 c\u0153ur et qui vous permettront de saisir des occasions afin de parfaire vos comp\u00e9tences et \u00e9largir les horizons.\nJoignez-vous \u00e0 nous, l\u2019une des plus importantes entreprises de conseil en technologie de l\u2019information (TI) et en management au monde.\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "R"
            ],
            "DataBase": [],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [
                "Hadoop"
            ],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [
                "AWS"
            ],
            "DevTools": [],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [
                "Terraform"
            ],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [
                "OpenShift"
            ],
            "Collaboration": [],
            "Other": [
                "DevOps",
                "Big Data",
                "Cloud"
            ],
            "FrSoftSkills": [
                "Flexibilit\u00e9"
            ],
            "EnSoftSkils": []
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [],
            "Salary": [
                "1"
            ],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "title": "Data Engineer (H/F)",
        "company": "ternair",
        "location": "Greater Lille Metropolitan Area",
        "link": "https://fr.linkedin.com/jobs/view/data-engineer-h-f-at-ternair-3915757963?position=8&pageNum=5&refId=63c0Bj1atjsufX74pWwghg%3D%3D&trackingId=fnWL1RHsXOUn1571MFK17A%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "\ud83d\udc68\u200d\ud83d\ude80 MISSION : \ud83d\udc69\u200d\ud83d\ude80\nEn coh\u00e9rence avec la strat\u00e9gie d\u2019entreprise et la roadmap data, vous aurez pour principales missions de :\nEn lien avec l\u2019\u00e9quipe DevOps, construire, maintenir et faire \u00e9voluer la plateforme de donn\u00e9es;\nD\u00e9finir et piloter la coh\u00e9rence de la collecte, la gestion et l\u2019alimentation des donn\u00e9es internes et externes, en diff\u00e9rents modes : batch, streaming, API (architecture micro-services);\nPr\u00e9parer et mettre en qualit\u00e9 les donn\u00e9es pour les rendre disponibles dans les diff\u00e9rents environnements de travail (datalake, datawarehouse, datamart);\nV\u00e9rifier la qualit\u00e9 des donn\u00e9es, de leur bonne et r\u00e9guli\u00e8re ex\u00e9cution ainsi que de leur utilisation ad\u00e9quate (gestion des co\u00fbts);\nTravailler en \u00e9troite collaboration avec les data analysts, scientists et data stewards et business de l\u2019entreprise ;\nEn lien avec l\u2019IT et la s\u00e9curit\u00e9, veiller aux r\u00e8gles d'int\u00e9grit\u00e9 et de s\u00e9curit\u00e9 des donn\u00e9es;\nVeille technologique.\n\ud83e\uddee Les outils :\nPlateforme data : Google Cloud Platform (Big Query, Airflow)\nD\u00e9veloppement : Github/GitLab, Docker, Terraform, Python\nAnalytiques : Qlik\nGestion de projet s: Jira, Confluence, Miro, Drive, Docs, Sheets, Slides\n\ud83e\udd29 Profil recherch\u00e9 : \ud83e\udd29\nExp\u00e9rience d'au moins 4-5 ans (apr\u00e8s \u00e9tudes) en data ing\u00e9nierie (flux, mod\u00e9lisation, run)\nA l\u2019aise avec l\u2019environnement Cloud et les infrastructures digitales\nCommuniquant, p\u00e9dagogue et fortes capacit\u00e9s relationnelles\nAnglais (\u00e0 l\u2019\u00e9crit)\nR\u00e9mun\u00e9ration : 42-60 k\u20ac en package selon exp\u00e9rience\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "R",
                "Go"
            ],
            "DataBase": [],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [
                "Google Cloud Platform"
            ],
            "DevTools": [
                "Git",
                "Docker"
            ],
            "Os": [],
            "DBMS": [
                "Big Query"
            ],
            "SoftBigDataProcessing": [],
            "Automation": [
                "Airflow"
            ],
            "InfrastructureAsCode": [
                "Terraform"
            ],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [
                "Docker"
            ],
            "Collaboration": [
                "JIRA",
                "Confluence"
            ],
            "Other": [
                "DevOps",
                "Cloud"
            ],
            "FrSoftSkills": [
                "Collaboration"
            ],
            "EnSoftSkils": [
                "Collaboration"
            ]
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [],
            "Salary": [
                "Package"
            ],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s",
                "5",
                "5",
                "5"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "title": "Data Solutions Engineer (Data & AI)",
        "company": "LVMH",
        "location": "Paris, \u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/data-solutions-engineer-data-ai-at-lvmh-3900392289?position=9&pageNum=5&refId=63c0Bj1atjsufX74pWwghg%3D%3D&trackingId=IQD19zGtUnDkMOS73%2BJYWQ%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "LVMH is the #1 Luxury group and is currently accelerating rapidly on digitalisation. It is bringing technology and innovation in the core of the established 75+ Maisons by inventing unique and powerful products and services.\nWe are looking for talented solution engineers (Software, Cloud, Data and AI) to join our team and be part of this tech revolution of bringing the Group and its Maisons to the next level.\nIf you believe Data and AI can enhance the retail industry, from the day-to-day operational tasks to the long term customer experience,\nIf you think that the Cloud technologies (we love Google Cloud) is a revolution for Data and AI products,\nIf you like building tech solutions having direct impacts on billion-dollar-valued businesses,\nIf you have good communication skills and like sharing your knowledge,\nApply now, and join us!\nThe mission\nThe Solution Engineer is providing advices and technical assets to the Maisons having Data & AI projects.\nOur team (Group Data team) is building a technical framework for all the Maisons to implement easily and quickly Data and AI use cases. Your mission will be to support the Maisons to convert their use case needs to concrete and production ready technical solutions using our framework and tools.\nYou will cover a portfolio of Maisons, in direct contact with their business analysts, data scientists and IT teams. You will be their dedicated referent on the Data & AI technical topics (Data platform, AI/ML softwares, data transport and transformations, data quality).\nMain responsibilities\nYou will be responsible of providing support and advices to a portfolio of Maisons on Data & AI tech topics (Cloud, Data stacks, Data transformations, Data transfers, ML ops).\nYou will keep a recurrent discussion with the Maisons to accelerate their projects and immediately provide our support when it's needed.\nYou will follow-up the engaged productions in the Maisons and report them to the global group data strategy committees.\nApplying the quality and security standards. Making them evolve if necessary.\nProducing realistic, understandable and documented solutions following the group guidelines.\nSharing and learning from the team by communicating difficulties and successes, taking and bringing honest feedbacks and improving the identified pain points.\nTaking responsibility as member of the team on the product performances (delivery and long term usage)\nRequired expertise and knowledge\nAbility to build technical solutions answering concrete usage (User Stories) and communicate them to the team.\nDimension and evaluate complexity for technical solution productions.\nExtensive knowledge and experience with good learning and sharing abilities.\nEvaluate quickly risks and opportunities about technical choices.\nSolid oral, written, presentation and interpersonal communication and relationship skills.\nProblem-solving skills on Data and AI, coding and software development\nTech lover\nFeedback taker and giver\nTeam player\nKey benefits to join our team\nAttractive packages\nOffices in the 8th arrondissement near the Champs Elys\u00e9es\nFlexibility on the working hours\nRemote work possible (~40%)\n7 weeks of holidays (cong\u00e9s pay\u00e9s + RTT)\nLVMH brands exclusive private sales\nGreat employee committee and health insurance (CE, mutuelle)\nLast generation MacBooks\nPart of a young, motivated and tech savvy team. Get prepared for the Thursday drinks and the tech meet-ups!\nYou\u2019re eligible if\nYou have a strong experience (3+ years) in cloud data architecting or consultancy.\nYou graduated from an engineering (or equivalent) with a master\u2019s degree. Computer Science knowledge is mandatory.\nExperience on data stacks and/or Google Cloud (built in components) is a huge plus.\nFrench and English both written and oral (Maisons are all over the world)\nYou\u2019re thrilled to support the #1 luxury group to get even better.\nHiring Process\nCall with our HR partner dedicated to the Tech Team\nTechnical interview with the Solution Engineering Manager\nTechnical test\nInterview with the Head of Engineering\nStill here? Apply now!!\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "R",
                "Go"
            ],
            "DataBase": [],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [],
            "DevTools": [
                "Git"
            ],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [
                "Teams"
            ],
            "Other": [
                "ML",
                "Cloud"
            ],
            "FrSoftSkills": [
                "Communication"
            ],
            "EnSoftSkils": [
                "Communication",
                "Flexibility"
            ]
        },
        "details": {
            "JobDetail": [
                "Remote"
            ],
            "TypeContract": [],
            "Salary": [
                "40"
            ],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "title": "Big Data Engineer \u2013 Secteur T\u00e9l\u00e9com \u2013 Paris, France (H/F)",
        "company": "Astek",
        "location": "Paris, \u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/big-data-engineer-%E2%80%93-secteur-t%C3%A9l%C3%A9com-%E2%80%93-paris-france-h-f-at-astek-3832149765?position=10&pageNum=5&refId=63c0Bj1atjsufX74pWwghg%3D%3D&trackingId=%2Fgwdg%2BYdGKwK5zWpSPfDOg%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "CDI\nParis - France\nPubli\u00e9e il y a 2 semaines\nLe Groupe Astek\nCe Que Nous Allons Accomplir Ensemble :\nNous rejoindre en tant que\nBig Data Engineer (H/F),\nafin d\u2019accompagner un op\u00e9rateur t\u00e9l\u00e9coms, Leader en Europe dans la gestion de ses portails clients grands publics (multimarques mobile et internet).\nUn challenge portant sur des millions d\u2019utilisateurs dans un environnement technique innovant et strat\u00e9gique.\nVotre Mission, Si Vous L\u2019acceptez :\nQualifier les donn\u00e9es et les r\u00e9sultats\nConception technique des solutions\nD\u00e9cliner les impacts de la strat\u00e9gie et des innovations technologiques au sein des processus et outils de l\u2019exploitant SI\nAssurer l\u2019accompagnement et le d\u00e9ploiement des \u00e9volutions des processus et outils\nContribuer aux programmes de transformation DevOps, Cloud et catalogues des offres SI\nD\u00e9velopper des fonctions transverses et les \u00ab uses cases \u00bb\nAccompagner la phase de mise en production\nVotre Future \u00c9quipe :\nAu sein d\u2019un environnement riche et complexe, vous \u00e9voluerez avec des experts passionn\u00e9(e)s \u00e0 la fois techniques et fonctionnels (Ing\u00e9nieurs sp\u00e9cialis\u00e9es, chef de projet, scrum master, product owner, analystes\u2026).\nL\u2019\u00e9quipe est en interaction avec des clients \u00e0 la fois internes et externes.\nVotre stack de jeu\nSyst\u00e8me d\u2019exploitation Linux\nBig data (Hadoop, Spark, Scala)\nCloud computing (GCP\u2026)\nS QL, No SQL (Cassandra, Mongo DB)\nDataviz : Power BI ou Kibana\nDes notions en d\u00e9veloppement feront la diff\u00e9rence !\nLes Petits Plus Du Projet :\nVous \u00e9voluerez au sein d\u2019une \u00e9quipe impliqu\u00e9e et r\u00e9active et interviendrez sur un projet polyvalent et \u00e0 forte valeur ajout\u00e9e.\nVous ?\nDipl\u00f4m\u00e9(e) d\u2019une\n\u00e9cole d\u2019ing\u00e9nieur\nou \u00e9quivalent de niveau Bac+5. Vous justifiez id\u00e9alement d\u2019une exp\u00e9rience d\u2019au moins 2 ans sur un poste similaire.\nCe descriptif vous interpelle ?\nAlors ce poste est fait pour vous, n\u2019h\u00e9sitez plus et rejoignez l\u2019aventure ASTEK !\nAstek\nCr\u00e9\u00e9 en France en 1988, Astek est un acteur mondial de l\u2019ing\u00e9nierie et du conseil en technologies. Fort de son expertise dans de nombreux secteurs industriels et tertiaires, Astek accompagne ses clients internationaux dans le d\u00e9ploiement intelligent de leurs produits et de leurs services, et dans la mise en \u0153uvre de leur transformation digitale.\nDepuis sa cr\u00e9ation, le Groupe a fond\u00e9 son d\u00e9veloppement sur une forte culture d\u2019entrepreneuriat et d\u2019innovation, et sur l\u2019accompagnement et la mont\u00e9e en comp\u00e9tence de\nses 7800 collaborateurs\nqui s\u2019engagent chaque jour \u00e0 promouvoir la compl\u00e9mentarit\u00e9 entre les technologies num\u00e9riques et l\u2019ing\u00e9nierie des syst\u00e8mes complexes.\nRejoignez un Groupe en fort d\u00e9veloppement en France et \u00e0 travers le monde ayant r\u00e9alis\u00e9 un chiffre d\u2019affaires de 600 M\u20ac en 2023.\nTous les d\u00e9tails sur le Groupe sur le site https://astekgroup.fr. Et vous pouvez aussi nous suivre sur notre blog : https://blog.groupeastek.com.\nRencontrons-nous\nVous vous \u00eates reconnu(e) sur l\u2019annonce et Astek vous pla\u00eet !\nJulie , Talent Acquisition Officer vous contactera pour en savoir plus sur vous.\nPar La Suite, 2 \u00c9changes Maximum :\nLe premier avec Mathieu (votre futur N+1, avec lequel vous \u00e9changerez autour d\u2019ASTEK, de votre parcours, de vos attentes et de la mission)\nLe second avec Anthime (Notre Directeur d\u2019agence pour valider votre int\u00e9r\u00eat pour le poste et vous pr\u00e9senter les \u00e9l\u00e9ments contractuels).\nNos Plus\nAstek est green et fait b\u00e9n\u00e9ficier ses salari\u00e9s d\u2019une indemnit\u00e9 kilom\u00e9trique v\u00e9lo\nUne politique CARE sur-mesure d\u00e9ploy\u00e9e par nos \u00e9quipes RH pour nos collaborateurs (https://astekgroup.fr/engagements)\nNotre charte de la Diversit\u00e9\nBienvenue dans la team ! Allez-y, maintenant c\u2019est \u00e0 vous de jouer !\nMots-cl\u00e9s :\ning\u00e9nieur \u2013 ing\u00e9nieure \u2013 consultant \u2013 consultante \u2013 big data engineer\nCaract\u00e9ristiques de l'emploi\nCat\u00e9gorie Ing\u00e9nieur\nJob Industry T\u00e9l\u00e9com / M\u00e9dia\nPostuler en ligne\nNom *\nPr\u00e9nom *\nEmail *\nUn email valide est requis.\nT\u00e9l\u00e9phone *\nUn num\u00e9ro de t\u00e9l\u00e9phone valide est requis.\nJoindre un CV *\nMots-cl\u00e9s :\ning\u00e9nieur \u2013 ing\u00e9nieure \u2013 consultant \u2013 consultante \u2013 big data engineer\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Scala",
                "R",
                "Go"
            ],
            "DataBase": [
                "SQL",
                "Cassandra"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [
                "Hadoop",
                "Spark"
            ],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [
                "Power BI"
            ],
            "Statistics": [],
            "CloudComputing": [],
            "DevTools": [
                "Git"
            ],
            "Os": [
                "Linux"
            ],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [
                "Chef"
            ],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [
                "DevOps",
                "Big Data",
                "Cloud"
            ],
            "FrSoftSkills": [],
            "EnSoftSkils": []
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [
                "CDI"
            ],
            "Salary": [],
            "Level": [
                "Bac+5"
            ],
            "Experience": [
                "a",
                "n",
                "s",
                "2",
                "2",
                "2"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "title": "DATA ENGINEER S\u00c9CURIT\u00c9 H/F",
        "company": "Akademija Oxford",
        "location": "Boulogne-Billancourt, \u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/data-engineer-s%C3%A9curit%C3%A9-h-f-at-akademija-oxford-3917866657?position=1&pageNum=7&refId=c6HmMlA6dBcVTsy5H43rIw%3D%3D&trackingId=Mk9nataTJV4b3v8yeh%2BlWQ%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Une entreprise du secteur de la protection de l\u2019environnement et bas\u00e9e dans les Hauts-De-Seine recherche un.e Data Engineer S\u00e9curit\u00e9 dans le cadre d\u2019un contrat d\u2019apprentissage.\nAu sein de son Data Service, votre r\u00f4le sera d\u2019\u00e9tablir la strat\u00e9gie des architectures data sur les aspects s\u00e9curit\u00e9 en lien avec la strat\u00e9gie globale m\u00e9tier et contribuer \u00e0 la d\u00e9clinaison des principes du mod\u00e8le de s\u00e9curit\u00e9 globale.\nVous devrez \u00e9galement \u00e9laborer des mod\u00e8les de r\u00e9f\u00e9rence pour les architectures data, mais aussi contribuer \u00e0 la d\u00e9clinaison des politiques de s\u00e9curit\u00e9 en standards de s\u00e9curit\u00e9 op\u00e9rationnels.\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "R"
            ],
            "DataBase": [],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [],
            "DevTools": [],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [],
            "FrSoftSkills": [],
            "EnSoftSkils": []
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "title": "Data Engineer",
        "company": "MindPal",
        "location": "Paris, \u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/data-engineer-at-mindpal-3919800161?position=2&pageNum=7&refId=c6HmMlA6dBcVTsy5H43rIw%3D%3D&trackingId=l1UUPOQsgk8%2BcVvdL4FkwA%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "We are looking for\nData Engineer!\nResponsibilities\nDesigning, creating, and maintaining data processing systems\nAnalyzing and optimizing data processing workflows\nCollaborating with the team to ensure data quality and efficiency\nTesting and implementing new solutions\nRequirements\nAt least 2 years of experience in designing and creating data processing systems\nProficiency in tools and programming languages related to data engineering (e.g. Hadoop, Spark, Scala, Python)\nExcellent knowledge of databases and SQL language\nAbility to work in a team and communicate effectively with other departments\nCommunicative English skills\nExperience with AWS/AWS Glue is a plus\nWe Offer\nB2B contract\nFull-time job\nRemote work and flexible hours\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "Scala",
                "R"
            ],
            "DataBase": [
                "SQL"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [
                "Hadoop",
                "Spark"
            ],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [
                "AWS"
            ],
            "DevTools": [],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [],
            "FrSoftSkills": [],
            "EnSoftSkils": []
        },
        "details": {
            "JobDetail": [
                "Remote",
                "Full"
            ],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "title": "Data Engineer (H/F)",
        "company": "Web Transition",
        "location": "Lille, Hauts-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/data-engineer-h-f-at-web-transition-3909147172?position=3&pageNum=7&refId=c6HmMlA6dBcVTsy5H43rIw%3D%3D&trackingId=WhWEfSHP6nlUfjNFUtD%2BOw%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Web Transition, c\u2019est qui ?\nFond\u00e9e en 2011,\nWeb transition\nest une entreprise de services num\u00e9riques op\u00e9rant sur le march\u00e9 de l\u2019IT/Digital !\nConstituant une part essentielle de\nMoOngy Digital Lab\n, Web Transition accompagne ses clients grands comptes sur leurs projets de Webmarketing, de Design, Gestion de projet et \u00e9galement en Data !\nNotre objectif : nous implanter comme un acteur principal sur le march\u00e9 de la Transformation Digitale en accompagnant et valorisant les comp\u00e9tences de nos collaborateurs !\nNous sommes convaincus que le succ\u00e8s de MoOngy Digital Lab r\u00e9side dans la somme des potentiels de nos \u00e9quipes \ud83e\udd1d\nTon \u00e9quipe : La tribu Data\nParce qu\u2019il est indispensable que tu puisses partager tes connaissances mais aussi en acqu\u00e9rir de nouvelles, tu feras partie de l\u2019une de nos tribus : celle de la Data. De plus, cela te permettra d\u2019\u00eatre acteur dans le d\u00e9veloppement et la strat\u00e9gie de Web Transition. Ce syst\u00e8me de co-r\u00e9flexion et co-construction est un fondement essentiel chez nous !\nDans cette aventure, tu :\nT\u2019assures\nde la ma\u00eetrise de la donn\u00e9e et est garant de la qualit\u00e9 de son utilisation (r\u00e9f\u00e9rencement, normalisation, et qualification)\nTravailles\n\u00e0 la compr\u00e9hension et l'int\u00e9gration des donn\u00e9es en provenance des diff\u00e9rents formats\ndes interfaces de flux\n\u00e9galement \u00e0 la d\u00e9finition de la politique de la donn\u00e9e et \u00e0 la structuration de son cycle de vie dans le respect des r\u00e9glementations en vigueur\nla supervision et l'int\u00e9gration des donn\u00e9es de diverse nature qui proviennent de ces sources multiples et v\u00e9rifie la qualit\u00e9 des donn\u00e9es qui entrent dans le Data Lake\nGarantis\nl'acc\u00e8s qualitatif aux sources de donn\u00e9es\nFacilites\nl\u2019acc\u00e8s aux donn\u00e9es pour tes coll\u00e8gues (data scientists, data analysts\u2026)\nAssistes\nles autres \u00e9quipes dans l'acc\u00e8s et la compr\u00e9hension des donn\u00e9es des socles.\nRejoins-nous si tu as :\nExp\u00e9rience d\u2019au-moins 4 ans dans la Data\nApp\u00e9tence \u00e0 la qualit\u00e9 des donn\u00e9es.\nConnaissance famili\u00e8re des Datawarehouses.\nMaitrise de Python, Oracle SQL, GCP/Power BI\nAisance avec les indicateurs, tu as une bonne capacit\u00e9 d'analyse et de r\u00e9daction.\nTon savoir-\u00eatre :\nOuvert d\u2019esprit\nRigoureux\nAutonome\nRespectueux des diff\u00e9rences de chacun\nCurieux\nProactif\nAgile\nPar o\u00f9 on commence ?\nUn premier entretien RH d\u20191h pour comprendre ton parcours et tes aspirations\nUn second entretien de 45 minutes avec l\u2019un de nos Business Manager afin de valider tes comp\u00e9tences et qu\u2019il se projette sur l\u2019une des missions qu\u2019il pourrait te proposer\nUn troisi\u00e8me entretien de quelques minutes avec notre responsable d\u2019agence pour te proposer d\u2019int\u00e9grer notre superbe Team Web !\n3 entretiens en peu de temps, si ton profil correspond tu int\u00e8greras tr\u00e8s vite nos \u00e9quipes \ud83d\ude09\nPr\u00eat pour embarquer dans notre grande aventure humaine ? Deviens notre futur Weber en postulant \u00e0 cette offre ! Voici les avantages qui t\u2019attendent en tant que Weber :\n\ud83e\udd29 Des coll\u00e8gues incroyables\n\ud83c\udfc6 Certifi\u00e9e Great Place to Work\n\ud83c\udfae Des bureaux sympas (o\u00f9 vous serez toujours les bienvenus)\n\ud83c\udf89 Des teambuilding et \u00e9vents tous les mois\n\ud83d\udcbb Des tributs m\u00e9tiers pour \u00e9changer entre Weber du m\u00eame m\u00e9tier\nDes missions chez le client qui sont accompagn\u00e9es et coach\u00e9es par ton manager\nUn accompagnement dans ton plan de carri\u00e8re et tes envies de re skilling\n\ud83e\udd13 Un catalogue de formations certifiantes ouvert \u00e0 tous les salari\u00e9s\n\ud83c\udf7d\ufe0f Une carte tickets restaurant MyEdenred\n\u2764\ufe0f Une mutuelle GrasSavoye\n\ud83d\ude8e Une prise en charge des frais de transport \u00e0 100%\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "R",
                "Go"
            ],
            "DataBase": [
                "SQL"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [
                "Power BI"
            ],
            "Statistics": [],
            "CloudComputing": [],
            "DevTools": [
                "Git"
            ],
            "Os": [],
            "DBMS": [
                "Oracle"
            ],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [],
            "FrSoftSkills": [],
            "EnSoftSkils": []
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s",
                "4",
                "4",
                "4"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "title": "Data Engineer / Ops H/F",
        "company": "Chantelle",
        "location": "Cachan, \u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/data-engineer-ops-h-f-at-chantelle-3909858815?position=4&pageNum=7&refId=c6HmMlA6dBcVTsy5H43rIw%3D%3D&trackingId=L4rwOAa52tSFHDVPvaDZeg%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "La Direction des Syst\u00e8mes d'Information et du Digital du groupe Chantelle recherche son/sa futur.e Data Engineer / Ops H/F, pour le lancement du grand chantier de r\u00e9novation de l'architecture Data : la bascule de l'int\u00e9gralit\u00e9 de son Data Warehouse vers Google Big Query.\nVos Missions Sont Les Suivantes\nVous concevez et mettez en \u0153uvre une infrastructure autour de Google Cloud Platform permettant de collecter, transformer, charger et historiser les donn\u00e9es g\u00e9n\u00e9r\u00e9es par l'entreprise.\nVous travaillez en \u00e9troite proximit\u00e9 avec le lead data engineer de l'\u00e9quipe, l'\u00e9quipe\nint\u00e9gration en charge du d\u00e9veloppement des interfaces, avec notre \u00e9quipe de Data Analysts qui sont en charge d'exposer cette donn\u00e9e au reste de l'entreprise ainsi qu'avec l'\u00e9quipe technique en charge des infrastructures transverses.\nVous collaborez avec l'ensemble des domaines fonctionnels de la DSI (MasterData, Supply Chain, Manufacturing, B2B, et B2C, Finance ...) dans le cadre des projets men\u00e9s par le Groupe.\nVous apportez l'assertivit\u00e9 technique sur tous les sujets d'architecture data, et \u00eates force de proposition, par exemple choix de mise en place de pipeline temps r\u00e9els ou au contraire de flux de donn\u00e9es en mode batch, ou bien encore stockage sur Big Query / Big Table en fonction des cas d'usage.\nVous d\u00e9finissez ces \u00e9l\u00e9ments structurants, en justifiant vos choix, et les\nmettez en \u0153uvre.\nLes enjeux sont forts et les use cases nombreux \u00e0 l'\u00e9chelle du groupe : am\u00e9lioration du pilotage de nos stocks en dimensionnant mieux nos quantit\u00e9s \u00e0 produire et nos assortiments, par magasin, meilleure ad\u00e9quation des achats mati\u00e8res premi\u00e8res vs objectifs de stocks, produits finis, personnalisation de nos sites e-commerce en temps r\u00e9el en fonction de nos profils client, refonte de nos flux / Apisation, ...\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "R",
                "Go"
            ],
            "DataBase": [],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [
                "Google Cloud Platform"
            ],
            "DevTools": [
                "Git"
            ],
            "Os": [],
            "DBMS": [
                "Big Query"
            ],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [
                "Cloud"
            ],
            "FrSoftSkills": [],
            "EnSoftSkils": []
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "title": "Data Engineer (F/H/X)",
        "company": "Goaheadspace",
        "location": "Pantin, \u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/data-engineer-f-h-x-at-goaheadspace-3915359112?position=5&pageNum=7&refId=c6HmMlA6dBcVTsy5H43rIw%3D%3D&trackingId=l%2FLvWhMpcc6a1c7uxwyTjQ%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "MFG Labs est une soci\u00e9t\u00e9 de conseil et r\u00e9alisation experte en data, qui aide les entreprises \u00e0 am\u00e9liorer leurs prises de d\u00e9cision, \u00e0 automatiser leurs processus et \u00e0 cr\u00e9er de nouveaux services gr\u00e2ce \u00e0 la data science, au design et \u00e0 l'utilisation des derni\u00e8res technologies.\nMFG Labs intervient \u00e0 toutes les \u00e9tapes de votre transformation data : de la cr\u00e9ation d'une feuille de route de projets data, \u00e0 la d\u00e9couverte d'insights, \u00e0 la mod\u00e9lisation de probl\u00e9matiques complexes, de la cr\u00e9ation d'un mod\u00e8le pr\u00e9dictif \u00e0 l'impl\u00e9mentation technique d'une solution data sur-mesure\nMFG Labs accompagne ses clients de diff\u00e9rentes mani\u00e8res :\nStrat\u00e9gie\nSolutions\nFondations\nMFG Labs d\u00e9ploie une approche holistique pluridisciplinaire, en m\u00ealant des data scientists, des designers, des data engineers et des consultants, afin d'apporter des solutions compl\u00e8tes de bout en bout \u00e0 des probl\u00e9matiques complexes.\nDans le cadre du d\u00e9veloppement de l\u2019\u00e9quipe, nous recherchons un.e Data Engineer \u00e0\nPantin (magasins g\u00e9n\u00e9raux).\nAu sein de l\u2019\u00e9quipe Data Technology, vous aurez pour mission de travailler sur des probl\u00e9matiques de collecte de la donn\u00e9e sur tout type de support digital : web, mobile, application, voire IoT.\nVotre r\u00f4le au sein de l\u2019\u00e9quipe :\nFaire partie d\u2019une \u00e9quipe pluridisciplinaire avec des talents en Design de Service, Consulting et Data science.\nD\u00e9velopper des applications de production int\u00e9grant diff\u00e9rents outils : des Math\u00e9matiques Appliqu\u00e9s, Machine (Deep) Learning, Recherche Op\u00e9rationnelle, Statistiques.\nD\u00e9velopper des pipelines de traitement de donn\u00e9es avec l\u2019\u00e9quipe de Data Science pour : ing\u00e9rer, transformer et d\u00e9livrer des donn\u00e9es et mod\ufffd\ufffdles \u00e0 nos applications.\nD\u00e9ployer des applications utilisant les derniers outils mis \u00e0 disposition par les diff\u00e9rents Clouds publics.\n\u00c0 propos de vous :\nVous \u00eates titulaire d'un niveau Bac +4/Bac +5 d'une \u00e9cole d'ing\u00e9nieur\nVous avez au minimum deux ans d'exp\u00e9rience hors stage ou alternance\nVous \u00eates rigoureux\u00b7se vis-\u00e0-vis de vous-m\u00eame et des autres quant \u00e0 la qualit\u00e9 du code.\nVous avez quelques connaissances et comp\u00e9tences solides en d\u00e9veloppement et en en Data Ing\u00e9nierie au sens large.\nEn\nd\u00e9veloppement\nPython 3 et SQL\nFramework de traitement de donn\u00e9es (Spark ou \u00e9quivalent)\nDocker\nGIT\nEn +\nFramework permettant de d\u00e9ployer des APIs (Flask ou \u00e9quivalent)\nCI/CD\nLa pratique d'au moins un cloud (AWS, GCP ou Azure) est appr\u00e9ci\u00e9e\nEn Data Ing\u00e9nierie\nDatawarehouse ou Datalake\nData Pipelines Batch et/ou Straming\nEn +\nOutils de BI (Tableau, Power BI\u2026)\nOutils MLOps (Sagemaker, VertexAI, etc.)\nSi vous vous reconnaissez dans cette annonce, n'h\u00e9sitez pas \u00e0 postuler !\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "R",
                "Go"
            ],
            "DataBase": [
                "SQL"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [
                "Spark"
            ],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [
                "Tableau",
                "Power BI"
            ],
            "Statistics": [
                "Statistiques"
            ],
            "CloudComputing": [
                "AWS",
                "Azure"
            ],
            "DevTools": [
                "Git",
                "Docker"
            ],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [
                "Docker"
            ],
            "Collaboration": [],
            "Other": [
                "ML",
                "Statistiques",
                "Cloud",
                "CI/CD"
            ],
            "FrSoftSkills": [],
            "EnSoftSkils": []
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "title": "Data Engineer / Big Data",
        "company": "ALTEN",
        "location": "Antibes, Provence-Alpes-C\u00f4te d'Azur, France",
        "link": "https://fr.linkedin.com/jobs/view/data-engineer-big-data-at-alten-3896177673?position=6&pageNum=7&refId=c6HmMlA6dBcVTsy5H43rIw%3D%3D&trackingId=y%2FMsM8w7nqJAVlPH8FLpHg%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Alten is one of the 3 main consulting societies in France. It is present in more than 30 countries in the word. Sophia-Antipolis is the first and largest technopole in Europe, located in the South of France between Nice and Cannes, near Antibes. It\u2019s also called the European Silicon Valley.\nReporting to our consulting team, you will work in an IT environment as an IT Business Analyst, taking part in projects in an Agile environment.\nJob Description\nThe mission consists in taking part toprojectsthat are collecting, processing, and converting raw data into information (Flat Data + KPIs) that can be interpreted by data/business analysts.\nTheData accessibilityis the ultimate goal of this mission, by enabling the Digital data users to utilize data for their business decisions.\nThis role is more Pipeline-centric, for which you need in-depth knowledge of distributed systems and computer science.\nThe mission scope will encompass the design and delivery of some key components of the Digital Data platform(Spark environment, Scala language) including following activities:\nParticipate to specifications reviews, propose technical solutions and perform feasibility studies.\nAcquire datasets that align with business needs.\nDevelop algorithms to transform data into useful, actionable information.\nDevelop, construct, test, and maintain optimal data pipeline architectures.\nCreate new data validation methods and data analysis tools.\nEnsure compliance with data governance and security policies.\nIdentify ways to improve data reliability, efficiency, and quality.\nIdentify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.\nPrepare data for predictive and prescriptive modeling.\nWork with data and analytics experts to strive for greater functionality in our data systems; which requires a closed collaboration with the other trains.\nDevelop software according to Amadeus Standards, including documentation\nPerform code reviews in line with Amadeus quality standards.\nConduct unit, package and performance tests of the software and ensure a level of quality in line with the Amadeus guidelines.\nParticipate in the validation / acceptance phase of the product cycle ensuring the fine-tuning necessary to finalize the product.\nProduce software documentation necessary for the application and issue it to the requesting departments.\nSupport the end user in the Production phase by debugging existing software solutions in response to Problem Tracking Records (PTR) and Change Requests (CR) issued from Product Management or Product Definition.\nAs part of the team, the consultant will, as well, work as DevOps, releasing the software load to production, monitoring jobs and being involved in maintenance activities. Quality analyst activities are also handled by the Devs.\nOur current data platform is a MapR architecture, and we are in the process to migrate the whole platform to the Azure cloud., which is one of the key focuses for the team in the upcoming months. This will trigger easier adoption of data and foster collaboration within Amadeus around data.\nQualifications\nTechnical skills:\nPrevious experience as a data engineer or in a similar role\nExperience building or optimizing \u201cbig data\u201d data pipelines, architectures and data sets.\nHands-on experience with Scala (>2 years or a strong experience with Java/C++ with a good knowledge level of Scala)\nExperience with big data tool: Spark, Kafka, MapR , Hadoop\nUnderstanding extract, transform, and load ETL systems\nKnowledge of cloud services: MS Azure\nSoft skills:\nAgile Mindset: must be comfortable working with Agile values and artifacts\nFast learning: must be able to adapt quickly to the existing environment and new changes\nAnalytical thinking and problem-solving mindset: must be able to quickly identify, implement work-around to solve incidents and work on long term data solutions\nTeam spirit, knowledge sharing, Empathy: must be able to work in a team and to communicate clearly with the other team members and users\nPro-activity, Professionalism, Opennessand Innovative mindset\nVarious:\nEnglish: professional level\nKnowledge of Scrum framework and Agile methodologies.\nKnowledge of airline business is a plus\nAdditional Information\nALTEN places the career development of the Engineers at the heart of its model and allows you to quickly take on responsibilities and evolve in line with your professional objective. It's the promise of growing your skills on concrete subjects in a project team, with a permanent contract as an ALTEN consultant!\nDo you recognize yourself in this description? Then send us your CV.\nOur teams will be delighted to study your application and meet you!\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Java",
                "C++",
                "Scala",
                "R",
                "Go"
            ],
            "DataBase": [],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [
                "Hadoop",
                "Spark"
            ],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [
                "Azure"
            ],
            "DevTools": [
                "Git"
            ],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [
                "Teams"
            ],
            "Other": [
                "DevOps",
                "Big Data",
                "Cloud"
            ],
            "FrSoftSkills": [
                "Collaboration"
            ],
            "EnSoftSkils": [
                "Empathy",
                "Collaboration"
            ]
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [],
            "Salary": [
                "2"
            ],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "title": "Data Engineer (H/F)",
        "company": "Wewyse",
        "location": "Paris, \u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/data-engineer-h-f-at-wewyse-3912830682?position=7&pageNum=7&refId=c6HmMlA6dBcVTsy5H43rIw%3D%3D&trackingId=NaOlOQcNmnyGl8uU35Ujaw%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Cette offre d\u2019emploi est fournie par P\u00f4le emploi\nDescription\nWewyse est un cabinet de conseil sp\u00e9cialis\u00e9 en Data et en Intelligence Artificielle. C'est aussi et surtout une communaut\u00e9 de passionn\u00e9s partageant l'ambition de grandir ensemble et d'ouvrir le champ des possibles dans leurs domaines. Si vous pensez que la Data et l'Intelligence Artificielle ont beaucoup \u00e0 offrir au monde de demain, et si vous souhaitez apporter votre contribution \u00e0 ce monde, avec humilit\u00e9 et enthousiasme, alors vous \u00eates un Wyser en puissance. \u00catre Data Engineer chez Wewyse c'est : Int\u00e9grer une communaut\u00e9 d'experts Data passionn\u00e9s. Recevoir et partager de la connaissance et des savoirs-faire lors de nombreux \u00e9v\u00e8nements. Intervenir chez des clients pour y porter l'expertise Wewyse dans des contextes et des secteurs vari\u00e9s. Participer \u00e0 des projets innovants au sein de notre Datalab, avec des Wysers mais aussi avec des partenaires acad\u00e9miques et des start up. Viser l'excellence des d\u00e9veloppement en s'appuyant sur le Software craftsmanship Concevoir des architectures logicielles modernes. Penser DevOps pour l'automatisation des d\u00e9ploiements et la continuit\u00e9 des services. \u00catre encourag\u00e9, conseill\u00e9 et accompagn\u00e9 dans un parcours de formation adapt\u00e9 \u00e0 vos ambitions professionnelles. Faire partie de la famille Wemanity avec ses \u00e9v\u00e8nements et ses multiples opportunit\u00e9s de carri\u00e8re. Ce que nous aimons : Les personnalit\u00e9s ouvertes, curieuses, ambitieuses Les langages Scala, Python et Java Le cloud : AWS, GCP, Azure Les \u00e9cosyst\u00e8mes : Hadoop et Spark La conteneurisation : Docker et Kubernetes Les m\u00e9thodes Agiles Le SQL et le NoSQL . L'approche DevOps : Jenkins, Ansible et Terraform Le versionning : Git L'anglais Vous vous reconnaissez ? Alors n'h\u00e9sitez pas \u00e0 postuler !\nPROFIL SOUHAIT\u00c9\nExp\u00e9rience\nD\u00e9butant accept\u00e9\nSource: Pole emploi (https://www.pole-emploi.fr)\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "Java",
                "Scala",
                "R"
            ],
            "DataBase": [
                "SQL",
                "NoSQL"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [
                "Hadoop",
                "Spark"
            ],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [
                "AWS",
                "Azure"
            ],
            "DevTools": [
                "Git",
                "Docker",
                "Jenkins"
            ],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [
                "Ansible",
                "Kubernetes"
            ],
            "InfrastructureAsCode": [
                "Terraform"
            ],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [
                "Docker",
                "Kubernetes"
            ],
            "Collaboration": [],
            "Other": [
                "DevOps",
                "Cloud"
            ],
            "FrSoftSkills": [],
            "EnSoftSkils": []
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "title": "Data Engineer H/F",
        "company": "Dalkia",
        "location": "Angers, Pays de la Loire, France",
        "link": "https://fr.linkedin.com/jobs/view/data-engineer-h-f-at-dalkia-3907349741?position=8&pageNum=7&refId=c6HmMlA6dBcVTsy5H43rIw%3D%3D&trackingId=z4UpMnjSuKlynOh279nU7Q%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Descriptif du poste\nEt si vous faisiez \u00e9quipe avec nous ? Rejoindre Dalkia, c'est plus de sens et d'implication contre le r\u00e9chauffement climatique ; plus de relations humaines, avec un m\u00e9tier de service anim\u00e9 par l'esprit d'\u00e9quipe ; plus de technicit\u00e9, avec des projets ambitieux et innovants fond\u00e9s sur nos expertises ; plus d'employabilit\u00e9, avec des parcours diversifi\u00e9s et individualis\u00e9s. Rejoindre Dalkia, c'est rejoindre plus qu'une entreprise : un collectif de 20 000 collaborateurs engag\u00e9s en faveur de la transition \u00e9nerg\u00e9tique.\nDalkia Froid Solutions, acteur majeur de la r\u00e9frig\u00e9ration, sp\u00e9cialis\u00e9 dans les services \u00e9nerg\u00e9tiques pour les process industriels et tertiaires, recherche un(e) Data Engineer\n(H/F)\n. Rattach\u00e9 (e) au Responsable Data au sein de la Direction des Syst\u00e8mes D'Informations, vous \u00eates le garant du bon d\u00e9roulement des d\u00e9veloppements de flux de donn\u00e9es et de leur pr\u00e9paration pour leur analyse. Vous aurez l'opportunit\u00e9 de rejoindre une \u00e9quipe en construction.\nCandidater chez Dalkia Froid Solutions, c\u2019est avoir l\u2019envie d\u2019int\u00e9grer un grand groupe \u00e0 l\u2019esprit familial. L\u2019humain est au c\u0153ur de nos m\u00e9tiers, nous donnons la chance \u00e0 tous, afin de d\u00e9couvrir nos talents de demain. Venez renforcer notre Direction des Syst\u00e8mes d'Informations et contribuez \u00e0 l'optimisation \u00e9nerg\u00e9tique \u00e0 travers la data !\nVos Principales Missions\nD\u00e9finir l'architecture ETL et d\u00e9velopper les jobs d'int\u00e9gration de donn\u00e9es pour notre environnement Big Data.\nAssurer le monitoring quotidien des jobs et optimiser les performances de traitement.\nGarantir la qualit\u00e9 et l'int\u00e9grit\u00e9 des donn\u00e9es en industrialisant leur nettoyage.\nAdapter les DataMarts pour le reporting en collaboration avec les \u00e9quipes m\u00e9tiers : comprendre et analyser les besoins utilisateurs, et r\u00e9diger les sp\u00e9cifications fonctionnelles et techniques.\nVous serez \u00e9galement ammen\u00e9 \u00e0 collaborer avec l'\u00e9quipe Infrastructure pour d\u00e9finir les besoins techniques et planifier les investissements. En lien avec votre \u00e9quipe vous conduirez des projets vari\u00e9s et participerez \u00e0 la mise en oeuvre de rapports BI et de mod\u00e8les de machine learning.\nLieu :\nSi\u00e8ge Social - Angers / T\u00e9l\u00e9travail possible \u00e0 raison de 2 jours par semaine apr\u00e8s p\u00e9riode d'essaie\nVotre profil\nDipl\u00f4m\u00e9 (e) d'un bac + 5 minimum sp\u00e9cialis\u00e9 en Data Engineer ,vous avez de bonnes qualit\u00e9s relationnelles afin d'accompagner le d\u00e9ploiement des projets. Votre rigueur et votre logique sont incontestables. Vous aimez travailler en \u00e9quipe pour accompagner l'entreprise vers l'excellence op\u00e9rationnelle.\nC\u00f4t\u00e9 Outils ? Vous maitrisez les langages SQL et Pyhton et vous avez d\u00e9j\u00e0 pratiqu\u00e9 les outils DBT et GitLab. Une premi\u00e8re exp\u00e9rience avec un outil de BI/Datavisualisation est souhait\u00e9e.\nLa connaissance des outils Qlik Sense ou Talend serait un plus!\nPr\u00eat(e) \u00e0 faire une diff\u00e9rence avec nous ? Postulez d\u00e8s maintenant !\nEnsemble, nous contribuons collectivement \u00e0 la transition \u00e9nerg\u00e9tique. C'est pourquoi chez Dalkia Froid Solutions, nous sommes convaincus que chacun peut participer \u00e0 relever ce d\u00e9fi. De ce fait, chaque candidature recevra la m\u00eame attention.\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "R"
            ],
            "DataBase": [
                "SQL"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [],
            "DevTools": [
                "Git"
            ],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [
                "Big Data",
                "Machine Learning"
            ],
            "FrSoftSkills": [
                "Collaboration"
            ],
            "EnSoftSkils": [
                "Collaboration"
            ]
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "title": "Data Engineer",
        "company": "Ramify",
        "location": "Greater Paris Metropolitan Region",
        "link": "https://fr.linkedin.com/jobs/view/data-engineer-at-ramify-3896146641?position=9&pageNum=7&refId=c6HmMlA6dBcVTsy5H43rIw%3D%3D&trackingId=yafYlDeSmYQN1tAFxdDJVA%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "ABOUT\nRamify\u2019s mission is to help people achieve financial freedom, no matter who they are and how much they have. We are revolutionizing the private wealth management industry by making smart and affordable financial products for everyone.\nNo more standardized solutions, hidden fees and complicated words, Ramify enables everyone to become a smart investor. The team combines elements of its research with technology to design customized investment portfolios composed of world-class financial products.\nThe team comprises around 15 talented individuals. Ramify is looking for talented people in all sectors, who want to have a huge impact, move fast and deliver.\nJOB DESCRIPTION\nThe Quantitative Investment Solutions (QIS) Team is dedicated to designing innovative investment portfolio models and developing cutting-edge investment features within our product suite. Moreover, the QIS Team is at the forefront of driving AI-based solutions for Ramify. This involves conceptualizing and implementing transformative AI solutions tailored to meet the diverse needs of various teams within Ramify.\nAs a Data Engineer on our QIS Team, you will play a pivotal role in shaping the future of investment strategies through data-driven insights and AI-based solutions. Collaborating closely with our talented team of quantitative researchers, and investment experts, your responsibilities will encompass architecting and implementing robust data pipelines. These pipelines will facilitate the seamless integration of diverse data sources, empowering Ramify teams to make informed decision-making.\nKey Responsibilities:\nDesign, build and launch data pipelines at scale to move data across Ramify platform with SQL technologies.\nDesign and implement processes and tools for data onboarding and quality, helping to deliver an industry best-practice solution for managing the data lifecycle.\nProduce stand-alone tools that can be used by other teams to automate data quality and discover faults.\nBuild analytical tools that provide insight into business metrics across Ramify.\nArchitect and lead the implementation of AI based solutions within Ramify\nPREFERRED EXPERIENCE\nWe're looking for people who:\nWant to make a difference. We are a small team effectively reshaping how people look at the industry. We need people who 'get it' and want to play an integral part in helping us accomplish this mission and are persistent in getting the job done.\nSkills we're looking for:\nMaster\u2019s or upper-year undergraduate-level coursework in either Computer Science, Management Information Systems, Business Information Systems, Mathematics or Finance related field.\n2+ years of professional experience in data engineering.\n2+ years of experience with one or more coding languages such as Python (is a must), Java.\nExperience with data modeling and ETL design, implementation and maintenance.\nDemonstrable mastery of industry best practices in the data lifecycle, including data quality automation and tooling.\nExcellent written and verbal communication skills with ability to communicate complex designs and solutions to non-technical and highly technical audiences alike.\nGood attention to detail.\nStrong analytics and strategic thinking skills\nNice-to-haves :\nUnderstanding of ML/ Generative AI technologies and their applications.\nPossess a passion, curiosity, and energy for finance + investing. You understand the ins and outs of the wealth management, trading, and more importantly - know how to explain these concepts simply\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "Java",
                "R",
                "Go"
            ],
            "DataBase": [
                "SQL"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [],
            "DevTools": [],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [
                "Teams"
            ],
            "Other": [
                "ML"
            ],
            "FrSoftSkills": [
                "Communication"
            ],
            "EnSoftSkils": [
                "Communication"
            ]
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "title": "Data Engineer",
        "company": "Beelix",
        "location": "Paris, \u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/data-engineer-at-beelix-3865239426?position=10&pageNum=7&refId=c6HmMlA6dBcVTsy5H43rIw%3D%3D&trackingId=pX8nmXsW8q1tbsDo0F4T0A%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Qui sommes-nous ?\nDepuis 2016, nous accompagnons nos clients sur des probl\u00e9matiques de Product Management, Data et Design Thinking. Beelix contribue \u00e0 fa\u00e7onner le monde de demain en participant aux grandes avanc\u00e9es des secteurs suivants:\n\ud83d\ude97Automobile\n\u26a1Energie\n\ud83d\udce1M\u00e9dias & T\u00e9l\u00e9coms\n\ud83d\udc57Luxe & Retail\n\ud83d\udcb6 Banque, Finance & Assurance\n\u2708\ufe0fD\u00e9fense\nAujourd\u2019hui, Beelix compte plus de 200 collaborateurs motiv\u00e9s et dynamiques. Lab\u00e9lis\u00e9e Great Place To work en 2023, Beelix est aussi une entreprise engag\u00e9e o\u00f9 il fait bon vivre.\nDans le cadre de notre d\u00e9veloppement, nous recherchons un Data Engineer en \u00cele-de-France.\nQuelles missions au quotidien ?\nVous aurez pour missions principales de d\u00e9velopper les projets Big Data demand\u00e9s par le m\u00e9tier, et notamment :\nPasser de la donn\u00e9e brute \u00e0 de la donn\u00e9e exploitable, expos\u00e9e sous forme de tables requ\u00eatables dans le Datalake\nConsolider ces donn\u00e9es au fur et \u00e0 mesure de leur alimentation r\u00e9currente dans le Datalake\nLes exploiter pour atteindre la finalit\u00e9 business (exposition de Business View, r\u00e9int\u00e9gration des r\u00e9sultats dans le SI, service de scoring, \u2026)\nDe mettre en place et de garantir le respect dans la dur\u00e9e d'un processus qualit\u00e9 sur l'ensemble du cycle de DEV (documents, tests unitaires / int\u00e9gration / fonctionnels, commentaires, versionning, etc.)\nAccompagner les Data Engineers sur son p\u00e9rim\u00e8tre pour garantir la qualit\u00e9 des livrables\nExpertise souhait\u00e9e\nExpertise en SPARK et PySpark\nExpertise sur Databricks\nUne exp\u00e9rience sur un cloud provider public comme Azure (id\u00e9alement), AWS, ou GCP\nConnaissances avanc\u00e9es d'outils de BI comme PowerBI (id\u00e9alement) ou Spotfire\nCapacit\u00e9 \u00e0 interagir avec des parties prenantes diverses : Business analyst, Architectes, M\u00e9tier\nEtre expert dans les pratiques du Software Craftsmanship (Test Driven Development, Behavior Driven Development, Clean Code, Code Reviews, etc.)\nDes Connaissances sur Azure DevOps, Azure Pipeline, GIT\nMaitrise des Traitements Big Data en mode Streaming\nMaitrise des Bases de donn\u00e9es relationnelles et NoSQL\nUne exp\u00e9rience professionnelle avec des outils comme Azure Databricks, Azure Data Lake Storage ou encore Azure Data Factory\nA propos de vous ?\nDipl\u00f4m\u00e9 d'une \u00e9cole d'ing\u00e9nieurs ou \u00e9quivalent\nAu moins 3 ans d'exp\u00e9rience en tant que Data Engineer\nExp\u00e9rience en mode de Delivery Agile (Scrum, Kanban, etc.\u2026)\nVous avez un bon niveau d\u2019anglais tant \u00e0 l\u2019\u00e9crit qu\u2019\u00e0 l\u2019oral\nPourquoi nous rejoindre ?\nUn suivi et un accompagnement au quotidien\nUn organisme de formation certifi\u00e9 Qualiopi, un abonnement linkedin learning pour chaque salari\u00e9 et des partenariats avec des sp\u00e9cialistes pour d\u2019autres expertises\nDe nombreux \u00e9v\u00e9nements : Afterworks, Communaut\u00e9s m\u00e9tiers, Happy talks\u2026\nune Exp\u00e9rience personnalis\u00e9e bas\u00e9e sur vos besoins gr\u00e2ce au Pr\u00e9dictive Index\nNotre package \u00ab unBeelievable \u00bb : 100% du titre de transport, Tickets restaurants, CSE, Prime de participation ...\nNombreux \u00e9v\u00e8nements (afterworks, sport, etc) et des communaut\u00e9s m\u00e9tiers dynamiques\nLe processus de recrutement ?\n\u00c9change t\u00e9l\u00e9phonique (15 min)\nEntretien 1 RH pour apprendre \u00e0 vous conna\u00eetre\nEntretien 2 avec votre futur N+1 pour appr\u00e9hender la relation manag\u00e9riale\nEntretien 3 avec un Responsable commercial pour avoir la vision strat\u00e9gique\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "R"
            ],
            "DataBase": [
                "SQL",
                "NoSQL"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [
                "Spark",
                "Databricks"
            ],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [
                "PowerBI"
            ],
            "Statistics": [],
            "CloudComputing": [
                "AWS",
                "Azure"
            ],
            "DevTools": [
                "Git"
            ],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [
                "DevOps",
                "Big Data",
                "Cloud"
            ],
            "FrSoftSkills": [],
            "EnSoftSkils": []
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [],
            "Salary": [
                "100"
            ],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s",
                "3",
                "3",
                "3"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "title": "Data Engineer / Data Ops",
        "company": "FRG Technology Consulting",
        "location": "\u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/data-engineer-data-ops-at-frg-technology-consulting-3913842168?position=1&pageNum=10&refId=Wt7FrOruL4%2BCplGL9tAn0A%3D%3D&trackingId=G1%2BA824Nb12%2FuKAKVjCsiA%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Vous \u00eates un expert passionn\u00e9 par la Data et \u00e0 la recherche de d\u00e9fis excitants ? Mon client recherche actuellement un\nData Engineer\n/ Data Ops\ntalentueux pour rejoindre une \u00e9quipe dynamique et humaine.\nMissions principales :\nParticipation active au d\u00e9ploiement de la nouvelle plateforme sur Azure & Snowflake\nForte autonomie et gestion compl\u00e8te des projets data\nAnalyse des besoins actuels et futurs\nCr\u00e9ation de sp\u00e9cifications fonctionnelles et techniques\nMod\u00e9lisation de donn\u00e9es\nD\u00e9veloppement de packages SSIS\nInt\u00e9gration des donn\u00e9es dans SnowFlake & Azure,\nCr\u00e9ation de rapports avec Power BI et Excel\nProfil recherch\u00e9 :\n3 \u00e0 4 ans d'exp\u00e9rience\nminimum\ndans la BI (SSIS, SQLServer, SSAS, SSRS) et/ou le cloud (Azure , Snowflake) ainsi qu'en SQL\nComp\u00e9tences en\narchitecture sur Snowflake\nfortement appr\u00e9ci\u00e9es\n1 \u00e0 2 ans d'exp\u00e9rience en tant que DevOps ( CI/CD ; GitLab)\nAutonome, rigoureux et anglais courant\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "R",
                "Go"
            ],
            "DataBase": [
                "SQL"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [
                "Power BI"
            ],
            "Statistics": [],
            "CloudComputing": [
                "Azure"
            ],
            "DevTools": [
                "Git"
            ],
            "Os": [],
            "DBMS": [
                "Snowflake",
                "Snowflake"
            ],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [
                "DevOps",
                "Cloud",
                "CI/CD"
            ],
            "FrSoftSkills": [],
            "EnSoftSkils": []
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [],
            "Salary": [
                "3"
            ],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s",
                "4",
                "4",
                "4"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "title": "Data Engineer",
        "company": "ADVANCED Schema",
        "location": "Greater Lille Metropolitan Area",
        "link": "https://fr.linkedin.com/jobs/view/data-engineer-at-advanced-schema-3539059697?position=2&pageNum=10&refId=Wt7FrOruL4%2BCplGL9tAn0A%3D%3D&trackingId=xYdxyEx6HBpgfQXeuvfj1g%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "ADVANCED SCHEMA\nest une soci\u00e9t\u00e9 de services informatiques\nsp\u00e9cialis\u00e9e dans la donn\u00e9e.\nDepuis 20 ans, nous cr\u00e9ons des plateformes data sur mesure pour nos clients, orient\u00e9es usages et alliant qualit\u00e9, performance, s\u00e9curit\u00e9 et gouvernance.\nADVANCED SCHEMA\na d\u00e9velopp\u00e9 de nouvelles activit\u00e9s pour r\u00e9aliser l'ambition du groupe : devenir\nune entreprise end-to-end,\nen proposant une offre \u00e0 360\u00b0 \u00e0 nos clients pour les\naccompagner \u00e0 chaque \u00e9tape de leurs projets.\n\u00c0 ce jour, nous sommes pr\u00e8s de 220 passionn\u00e9s r\u00e9partis entre Paris, Lille, Nantes, Lyon mettant \u00e0 profit leur expertises aussi bien dans le domaine du retail, de la finance/assurance, du luxe, des m\u00e9dias, de la sant\u00e9 et de l'industrie.\nAujourd\u2019hui, nous souhaitons int\u00e9grer de nouveaux renforts dans nos \u00e9quipes Lilloises.\nEn tant que Data Engineer, vous aurez les missions suivantes :\nConcevoir des mode\u0301lisations physiques\nConstruire des mappings techniques et r\u00e9daction de sp\u00e9cifications d\u2019alimentation.\nD\u00e9velopper des flux des donn\u00e9es\nContribuer au pilotage de projets, de proof of concepts\nParticiper a\u0300 des missions d\u2019expertise\nComp\u00e9tences professionnelles & niveau d'\u00e9tudes requis :\nVous \u00eates titulaire d'un dipl\u00f4me Bac +3 minimum dans le domaine de la data\nVous poss\u00e9dez minimum 2 ans d'exp\u00e9rience dans le m\u00e9tier\nPositif(ve), curieux(se), rigoureux(se) et dot\u00e9(e) d'une bonne aisance relationnelle\n\u00catre enthousiaste \u00e0 l'id\u00e9e d'apprendre de nouvelles technologies\nExp\u00e9rience de la m\u00e9thodologie Agile / Scrum\nCapacit\u00e9 \u00e0 planifier et \u00e0 prioriser les t\u00e2ches et les activit\u00e9s confi\u00e9es en autonomie\nMa\u00eetrise de l\u2019anglais oral et technique obligatoire\nExp\u00e9rience av\u00e9r\u00e9e dans l'\u00e9criture de code propre avec 2 ou plusieurs des technologies suivantes : BASH, SQL, Java, Python, NoSQL\nNotre proposition :\nTemps plein en\nCDI\navec un\nsalaire attractif\n+ participation aux b\u00e9n\u00e9fices + prime(s) sur investissement personnel\nMode de\ntravail hybride\n(agence, site, t\u00e9l\u00e9travail selon projets/clients)\nTicket restaurant (Sodexo)\nMutuelle financ\u00e9e \u00e0 50%\nPr\u00e9voyance\nComit\u00e9 entreprise\n5 jours d\u2019onboarding plein temps via la\nADVANCED SCHEMA Academy\nNotre investissement :\nChez\nADVANCED SCHEMA\n, nous t\u2019offrons un environnement de travail stimulant et collaboratif ainsi que des possibilit\u00e9s de croissance et de d\u00e9veloppement professionnel. \u00c9galement un\naccompagnement/support au quotidien\npour te faire grandir et monter en comp\u00e9tences, sur des projets qui r\u00e9pondent \u00e0 de\nvrais enjeux pour nos clients\n. Si tu es passionn\u00e9(e) par les donn\u00e9es et pr\u00eat(e) \u00e0 relever de nouveaux d\u00e9fis, alors nous aussi nous aimerions te rencontrer\nProcess de recrutement :\nSi ta candidature retient notre attention, nous te proposons :\nUn premier \u00e9change t\u00e9l\u00e9phonique/visio\nUn entretien physique (+questionnaire d\u2019\u00e9valuation) avec un senior manager\nUn entretien final \u00e0 notre si\u00e8ge Parisien afin de rencontrer le DG\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "Java",
                "R",
                "Go",
                "Bash"
            ],
            "DataBase": [
                "SQL",
                "NoSQL"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [],
            "DevTools": [],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [],
            "FrSoftSkills": [],
            "EnSoftSkils": []
        },
        "details": {
            "JobDetail": [
                "Hybride",
                "Temps plein",
                "Senior"
            ],
            "TypeContract": [
                "CDI"
            ],
            "Salary": [
                "50"
            ],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s",
                "20",
                "20",
                "20"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "title": "(Senior) Data Engineer",
        "company": "Mirakl",
        "location": "Paris, \u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/senior-data-engineer-at-mirakl-3904071960?position=3&pageNum=10&refId=Wt7FrOruL4%2BCplGL9tAn0A%3D%3D&trackingId=Q7xsnmeByL9zBjTSiMtetQ%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Mirakl, leader et pionnier de l\u2019\u00e9conomie de plateforme, propose aux entreprises une suite unique de solutions leur permettant de transformer significativement leur e-commerce afin d'acc\u00e9l\u00e9rer de fa\u00e7on durable et rentable leur croissance. Depuis 2012, Mirakl accompagne les entreprises B2C et B2B avec la technologie la plus avanc\u00e9e, s\u00e9curis\u00e9e et \u00e9volutive leur permettant de digitaliser leur activit\u00e9 et d'\u00e9largir leur offre via la marketplace ou le dropship, faciliter la gestion des catalogues et des paiements de leurs fournisseurs pour plus d'efficacit\u00e9, offrir une exp\u00e9rience d'achat personnalis\u00e9e \u00e0 leurs clients, et augmenter leurs profits gr\u00e2ce au retail media. Bas\u00e9e \u00e0 Paris et Boston, Mirakl est certifi\u00e9e Great Place to Work.\nA propos de Mirakl Labs\nNos \u00e9quipes techniques et produits, nomm\u00e9es Mirakl Labs, sont principalement r\u00e9parties entre nos 2 hubs situ\u00e9s \u00e0 Paris et \u00e0 Bordeaux. Elles collaborent au quotidien afin d'adresser les probl\u00e9matiques de nos clients et utilisateurs en r\u00e9pondant \u00e0 diff\u00e9rents challenges li\u00e9s aux nouvelles fonctionnalit\u00e9s, \u00e0 la scalabilit\u00e9, la s\u00e9curit\u00e9 et l\u2019ergonomie\u2026\nElles op\u00e8rent en mode agile et s'organisent en Squads compos\u00e9es d'un Squad Lead, de 5 d\u00e9veloppeurs, d'un Product Manager et d'un QA. Chaque Squad est sp\u00e9cialis\u00e9e sur un scope fonctionnel afin de concevoir et r\u00e9aliser de nouvelles features, leurs \u00e9volutions et des APIs (avec un d\u00e9coupage en micro-services). Nos \u00e9quipes Infrastructure, Architecture, S\u00e9curit\u00e9, Documentation, Product Design, Data et Support op\u00e8rent en transverse en apportant leur expertise et de la coh\u00e9rence sur l\u2019ensemble des produits.\nToutes les \u00e9quipes sont responsables de leur p\u00e9rim\u00e8tre et chacun des collaborateurs apporte son exp\u00e9rience et ses id\u00e9es. Innovation, feedback et implication dans les prises de d\u00e9cision sont au c\u0153ur de notre philosophie.\nEt pour favoriser ce partage avec d\u2019autres passionn\u00e9s, nous sommes sponsors, speakers, et h\u00f4tes de diff\u00e9rents \u00e9v\u00e9nements, meetups, et associations de la sc\u00e8ne Tech en France. Au cours des derni\u00e8res ann\u00e9es, nous avons particip\u00e9 \u00e0 des \u00e9v\u00e9nements tels que Devoxx, ReactEurope, ProductConf et Flupa UX Days.\nA propos du job\nLa solution SaaS Mirakl est le moteur des marketplaces des plus importants e-commer\u00e7ants \u00e0 travers le monde. Cette solution g\u00e8re et produit de gros volumes de donn\u00e9es qui pr\u00e9sentent des challenges extr\u00eamement int\u00e9ressants pour les sp\u00e9cialistes de la donn\u00e9e (produits, commandes, clients, niveaux de stock, prix, messages, appels API, donn\u00e9es de navigation, s\u00e9ries temporelles, donn\u00e9es g\u00e9olocalis\u00e9es etc.).\nEn tant que (Senior) Data Engineer au sein de l\u2019\u00e9quipe Data Mirakl, vos principales missions seront de :\ncontribuer \u00e0 l'enrichissement de la Data Platform (ETL)\nam\u00e9liorer la robustesse de nos pipelines de production pour nos applications Machine Learning (inf\u00e9rence real time etc.)\nInt\u00e9gr\u00e9(e) dans une \u00e9quipe de sp\u00e9cialistes de la donn\u00e9e (data engineers, machine learning engineers, data scientists, data analysts), vous \u00eates un des acteurs cl\u00e9s pour garantir la place de Mirakl comme solution dominante sur son march\u00e9.\nNotre stack et nos outils\nApache Spark, Kafka, AWS, Databricks, Python, Airflow, Mlflow, Tensorflow, Delta lake, Superset, Kubernetes, Redshift, SQL, Terraform, Ansible\nAu quotidien, vous allez :\nParticiper \u00e0 la d\u00e9finition et \u00e0 l\u2019impl\u00e9mentation d\u2019une architecture performante, robuste, scalable et aux co\u00fbts ma\u00eetris\u00e9s pour nos applications Spark ainsi que pour nos pipelines de production de Machine Learning (\u00e9valuation des feature stores, refactoring de DAG Airflow)\nAccompagner les Data Scientists lors de leur mise en production (relecture de code, pair programming) et mettre en place les best practices\nOptimiser et am\u00e9liorer la CI/CD de l\u2019\u00e9quipe en collaboration avec l\u2019\u00e9quipe SRE\nAssurer la mont\u00e9e en comp\u00e9tence des membres de l\u2019\u00e9quipe sur les sujets de MLOps et Data Engineering\nR\u00e9fl\u00e9chir \u00e0 la meilleure fa\u00e7on d'int\u00e9grer les donn\u00e9es Google Analytics dans la data platform\nPartager ses connaissances et pr\u00e9senter les travaux devant toutes les \u00e9quipes Labs\nCe qu\u2019on peut vous apporter :\nDes projets data driven, divers et vari\u00e9s (traitements massifs d\u2019images, de textes, time series etc.) pour des produits diff\u00e9rents de Mirakl\nUne culture orient\u00e9e sur la veille technologique\nDes projets qui ont un vrai impact business devant \u00eatre d\u00e9ploy\u00e9s sur des centaines de clients dans un contexte multilingue\nQuelques exemples de sujets en cours :\nEnrichissement des donn\u00e9es produit \u00e0 partir des images et des descriptions\nMod\u00e9ration automatique des produits\nMapping automatique des donn\u00e9es produit\nIdentification des produits \u00e0 fort potentiels\nD\u00e9tection de comportements frauduleux\nSentiment analysis sur les messages \u00e9chang\u00e9s entre clients et vendeurs et dans les \u00e9valuations\nD\u00e9termination de prix optimaux\nMonitoring de la qualit\u00e9 de service des vendeurs\nDes applications d\u2019inf\u00e9rence en synchrone de nos mod\u00e8les de ML\nVous aimerez ce job si :\nVous \u00eates passionn\u00e9(e) par la data et les technologies modernes permettant d'en tirer partie\nVous vous int\u00e9ressez \u00e0 la data science et avez des connaissances g\u00e9n\u00e9rales sur les algorithmes de Machine Learning\nVous avez un background en d\u00e9veloppement et avez \u00e9volu\u00e9 dans un environnement Data\nVous avez a minima 4 ans d\u2019exp\u00e9rience en environnement Machine Learning et/ou Data\nVous avez mis en production avec succ\u00e8s des applications Big Data faisant appel \u00e0 du Machine Learning, du NLP, du traitement d\u2019images dans des projets d'envergure, \u00e0 fort volume de donn\u00e9es\nVotre ma\u00eetrisez Python, \u00eates un pro des frameworks data de la fondation Apache et \u00eates \u00e0 l'aise dans un environnement AWS\nVous ma\u00eetrisez au moins un outil d\u2019orchestration (Airflow, Data Pipeline ou tout autre outil similaire)\nVous pr\u00e9sentez vos travaux de mani\u00e8re simple et accessible\nVous fa\u00eetes preuve d'un bon relationnel et vous aimez mentorer des collaborateurs\nVous parlez couramment anglais et fran\u00e7ais\nLes plus pour le poste :\nVous avez une exp\u00e9rience significative dans le domaine du e-commerce\nVous avez d\u00e9j\u00e0 mis en place un Data Lake, Data Warehouse ou une Data Platform\nVous avez d\u00e9ploy\u00e9 des applicatifs en environnement Kubernetes\nVous avez mis en place des pipelines d'ingestion de donn\u00e9es avec une approche CDC \u00e0 l'aide de Debezium ou autre\nVous ma\u00eetrisez Java/Scala\nMirakl est engag\u00e9e en faveur de la diversit\u00e9, de l\u2019\u00e9galit\u00e9 des chances et de l\u2019inclusion. Nous c\u00e9l\u00e9brons nos diff\u00e9rences car nous sommes convaincus que les qualit\u00e9s visibles et invisibles de chaque Mirakl Worker sont une source de force et d\u2019innovation. Dans le cadre de cet engagement, nous \u00e9tudions toutes les candidatures sans distinction de : genre, ethnicit\u00e9, religion, orientation sexuelle, handicap, \u00e2ge ou toute autre caract\u00e9ristique prot\u00e9g\u00e9e par la loi.\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "Java",
                "Scala",
                "R",
                "Go"
            ],
            "DataBase": [
                "SQL"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [
                "Spark",
                "Databricks"
            ],
            "MachingLearning": [
                "TensorFlow"
            ],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [
                "AWS"
            ],
            "DevTools": [
                "Git"
            ],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [
                "Ansible",
                "Kubernetes",
                "Airflow"
            ],
            "InfrastructureAsCode": [
                "Terraform"
            ],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [
                "Kubernetes"
            ],
            "Collaboration": [],
            "Other": [
                "Big Data",
                "ML",
                "Machine Learning",
                "CI/CD"
            ],
            "FrSoftSkills": [
                "Collaboration"
            ],
            "EnSoftSkils": [
                "Collaboration"
            ]
        },
        "details": {
            "JobDetail": [
                "Senior"
            ],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s",
                "4",
                "4",
                "4"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "title": "Data Engineer (H/F)",
        "company": "Scalian",
        "location": "Valbonne, Provence-Alpes-C\u00f4te d'Azur, France",
        "link": "https://fr.linkedin.com/jobs/view/data-engineer-h-f-at-scalian-3819563847?position=4&pageNum=10&refId=Wt7FrOruL4%2BCplGL9tAn0A%3D%3D&trackingId=inh7goY5tExGCo%2B1yjcFcg%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Ing\u00e9nieur DATA / Data engineer (H/F)\nValbonne/Sophia-Antipolis\nType : CDI\nLieu : Locaux Scalian Sophia-Antipolis\nT\u00e9l\u00e9travail : En fonction des possibilit\u00e9s\nDate de prise de poste : imm\u00e9diatement ou en fonction de votre pr\u00e9avis\nSalaire : en fonction du profil - entre 40 et 48K Brut annuels (hors avantages Scalian)\nAvantages Scalian : Accord d'entreprise t\u00e9l\u00e9travail, Tickets restaurants, Mutuelle groupe, accord am\u00e9nagement temps de travail, compte \u00e9pargne temps, accord de participation et int\u00e9ressement groupe, programme cooptation et apports d'affaires, accompagnement parentalit\u00e9, avantages CSE\nVous \u00eates data engineer ou vous souhaitez le devenir !\nQuel sera votre r\u00f4le ?\nLa port\u00e9e de la mission comprend (sans toutefois s'y limiter) :\nScience des donn\u00e9es\nIng\u00e9nierie des donn\u00e9es\nAnalyse des donn\u00e9es\nG\u00e9nie logiciel\nCe que cette exp\u00e9rience va vous apporter\nVous \u00eates autonome, vous avez le sens du service et de l\u2019analyse, vous \u00eates impliqu\u00e9, nous vous offrons une ouverture sur des projets complexes et une rapide \u00e9volution de carri\u00e8re. Vous rejoignez notre business unit \u00e0 Sophia Antipolis compos\u00e9e d'environ 50 consultants, avec possibilit\u00e9 de t\u00e9l\u00e9travail en fonction des sujets.\nNous co-construisons votre trajectoire professionnelle et assurons votre mont\u00e9e en comp\u00e9tences.\nNous nous inscrivons ensemble dans la dur\u00e9e, nous assurons votre mont\u00e9e en comp\u00e9tences et disposons d'une vari\u00e9t\u00e9 de sujets passionnants.\nCe que nous recherchons chez vous\nDe formation sup\u00e9rieure (Bac+5, \u00e9cole ou universit\u00e9), vous poss\u00e9dez id\u00e9alement une premi\u00e8re exp\u00e9rience r\u00e9ussie dans ce domaine (d\u00e9butants accept\u00e9s), vous aimez le travail en \u00e9quipe.\nComp\u00e9tences requises\n:\nEtape d\u2019analyse : Comprendre l\u2019architecture technique, les sources de donn\u00e9es, les objectifs fonctionnels.\nEtape de conception : Solution de conception avec un fort centrage sur les pipelines de donn\u00e9es et les mod\u00e8les ML et l\u2019exposition des KPI via API\nMise en \u0153uvre : Apr\u00e8s les phases d\u2019analyse et de conception, proc\u00e9der \u00e0 a mise en \u0153uvre dans des technologies s\u00e9lectionn\u00e9es (Java,Scala,Python,Spark)\nCr\u00e9er un code test\u00e9 et document\u00e9\nTechno : Linux, Shell, Hadoop, Scrum, Python, Spark, Scala\nPourquoi feriez-vous le grand saut ?\nParce que Scalian vous accompagne dans le d\u00e9veloppement de votre carri\u00e8re :\nProgramme d'onboarding complet sur 1 an avec votre manager et votre RH\nProgramme de formation (Scalian Academy, e-learning, webinaires et formations externes)\nCommunaut\u00e9s techniques (Squads, Practices) afin de valoriser et d\u00e9velopper votre expertise\n\u00c9v\u00e9nements internes (Afterworks, Awards Dinner, Kick Off, Live Event du COMEX, Stand Up) et externes (participation \u00e0 des salons et forums sp\u00e9cialis\u00e9s dans nos domaines d\u2019activit\u00e9s\u2026)\nDispositif d\u2019acc\u00e9l\u00e9ration d\u2019acc\u00e8s \u00e0 la mobilit\u00e9 interne et \u00e0 des \u00e9changes internationaux type Erasmus\nParce que Scalian favorise la Qualit\u00e9 de Vie au Travail :\nCertifications Great Place to Work\u00ae et Best Workplaces for Women\u00ae\nPrime de cooptation, prime vacances, prise en charge par l\u2019employeur de 60% des titres-restaurant, Accord t\u00e9l\u00e9travail (jusqu\u2019\u00e0 2,5 jours par semaine indemnis\u00e9s), RTT (dont une partie mon\u00e9tisable), CSE (activit\u00e9s ludiques, ch\u00e8ques-cadeaux, ch\u00e8ques vacances)\nBerceaux en cr\u00e8ches inter-entreprises\nDon ou r\u00e9ception de jours de cong\u00e9s en cas de difficult\u00e9s personnelles\nParce que Scalian d\u00e9veloppe une politique RSE concr\u00e8te et ambitieuse :\nMobilit\u00e9 durable (indemnit\u00e9 kilom\u00e9trique v\u00e9lo, leasing de v\u00e9los \u00e0 assistance \u00e9lectrique)\nActions environnementales (Fresque du Climat, Reforest'Action, Clean Up Day, m\u00e9c\u00e9nat ONF)\nPostes ouverts aux personnes en situation de Handicap\nDiverses politiques de diversit\u00e9, d\u2019inclusion et d\u2019int\u00e9gration mises en place\nScalian c\u2019est aussi :\nUne entreprise en tr\u00e8s forte croissance qui, cr\u00e9\u00e9e en 1989, compte aujourd\u2019hui plus de 5500 personnes\nDes r\u00e9f\u00e9rences clients \u00e0 forte valeur ajout\u00e9e aupr\u00e8s de grands industriels fran\u00e7ais (du CAC40) et internationaux\nUn terrain de jeu o\u00f9 l\u2019expertise se conjugue avec audace, libert\u00e9 d\u2019entreprendre et convivialit\u00e9\nSi vous aspirez \u00e0 un environnement de travail qui valorise autant votre bien-\u00eatre que votre d\u00e9veloppement professionnel,\nrejoignez-nous et exprimez pleinement votre talent !\nEnvie d'\u00e9largir le cadre ?\nJe suis Liza Djehel, Talent Acquisition Officer.\nSi votre CV est retenu, je vous contacte pour un premier \u00e9change t\u00e9l\u00e9phonique de 15 \u00e0 20 minutes.\nNous d\u00e9terminons ensemble si ce poste est en ad\u00e9quation avec vos comp\u00e9tences et surtout, avec vos attentes.\nL'\u00e9change est positif ? Nous convenons d'un entretien de 1h (en pr\u00e9sentiel ou en visio) avec Lucas Daunar, Business Manager \u00e0 Sophia-Antipolis. Cet \u00e9change permet de revenir en d\u00e9tail sur vos comp\u00e9tences, vos attentes, de vous pr\u00e9senter le poste plus en d\u00e9tail, et d'\u00e9voquer d'autres opportunit\u00e9s.\nNous pr\u00e9voyons ensuite un rendez-vous technique de 1h (en pr\u00e9sentiel ou en visio) avec un de nos responsable technique.\nEnfin, nous vous pr\u00e9sentons notre proposition d'embauche.\nNotre processus de recrutement dure entre 15 et 30 jours\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "Java",
                "Scala",
                "R"
            ],
            "DataBase": [],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [
                "Hadoop",
                "Spark"
            ],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [],
            "DevTools": [],
            "Os": [
                "Linux"
            ],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [
                "ML"
            ],
            "FrSoftSkills": [],
            "EnSoftSkils": []
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [
                "CDI"
            ],
            "Salary": [
                "40"
            ],
            "Level": [
                "Bac+5"
            ],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "title": "Data Engineer confirm\u00e9 (H/F)",
        "company": "BforBank",
        "location": "Greater Paris Metropolitan Region",
        "link": "https://fr.linkedin.com/jobs/view/data-engineer-confirm%C3%A9-h-f-at-bforbank-3918327555?position=5&pageNum=10&refId=Wt7FrOruL4%2BCplGL9tAn0A%3D%3D&trackingId=YLN7BIC2OVrtG%2B8DPUdn2Q%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Sur le mod\u00e8le d'une\n\"Tech company\",\nBforBank place\nl'humain et le digital\nau c\u0153ur de sa transformation. Notre mission,\noffrir \u00e0 nos clients une exp\u00e9rience bancaire incomparable\npour r\u00e9pondre \u00e0 leurs besoins et usages mobile. \ud83c\udf1f \ud83d\udcf1\nRejoindre BforBank c\u2019est\nrejoindre une \u00e9quipe engag\u00e9e\ndans un\ngrand projet de d\u00e9veloppement strat\u00e9gique en France et en Europe.\nNous sommes aujourd\u2019hui 350 passionn\u00e9(e)s et\nrecherchons nos talents pour construire la banque de demain\n. \ud83d\ude80\nNous croyons en la force du collectif, chaque jour rassembl\u00e9s autour de nos valeurs, de simplicit\u00e9, d'optimisme et d\u2019engagement, encourageant chacun \u00e0 oser, essayer et accepter d\u2019\u00e9chouer.\n\ud83c\udfaf Au sein de la Direction Technologie, la Data Factory a pour objectifs de piloter, d\u00e9finir, d\u00e9ployer et op\u00e9rer les meilleures solutions technologiques r\u00e9pondant aux cas d\u2019usage data et d\u2019automatisations de processus de la banque au travers de plateformes. \u00c9galement, la Data Factory contribue au d\u00e9veloppement des produits, \u00e0 la cristallisation et \u00e0 la diffusion des pratiques au sein des Squads BforBank sur les usages data dans la banque.\nTu rejoindras une squad en charge de r\u00e9soudre des probl\u00e9matiques m\u00e9tiers en cr\u00e9ant des solutions applicatives utilisant les donn\u00e9es, des data products, avec pour finalit\u00e9s la prise de d\u00e9cision via des moteurs de calcul ou des dashboards, la cr\u00e9ation de flux r\u00e9glementaires, la cr\u00e9ation de data layer ou de reportings.\n\ud83d\ude80 Tes missions principales sont les suivantes :\n\u00b7 Participer aux analyses, \u00e9tudes d\u2019impacts et cadrage techniques\n\u00b7 Concevoir des solutions en respectant les bonnes pratiques d\u2019architecture data et d\u00e9veloppement\n\u00b7 R\u00e9aliser le d\u00e9veloppement de nouveaux data products et assurer la maintenance \u00e9volutive et corrective des data products existants\n\u00b7 R\u00e9diger la documentation technique des data products\n\u00b7 Assurer un support aux testeurs\n\u00b7 Reporter de ton activit\u00e9 \u00e0 ta Squad et travailler dans une d\u00e9marche d\u2019efficacit\u00e9 collective\nConcr\u00e8tement tu seras amen\u00e9(e) \u00e0 produire les livrables suivants :\n\u00b7 R\u00e9aliser du code applicatif \u00e0 l\u2019\u00e9tat de l\u2019art sur notre nouvelle Data Platform\n\u00b7 Cr\u00e9er des data layer et des rapports sur notre outil de Data Visualisation\n\u00b7 R\u00e9diger les documentations techniques li\u00e9es \u00e0 ta solution, incluant le mod\u00e8le de donn\u00e9es, les proc\u00e9dures, l\u2019ordonnancement\nCe que tu ma\u00eetrises :\n\u00b7 Maitrise des services manag\u00e9s de GCP (BigQuery, dataproc, dataflow, CloudSQL \u2026)\n\u00b7 Maitrise du langage Python, Pandas, Spark\n\u00b7 Maitrise de la mod\u00e9lisation de base de donn\u00e9es et du langage SQL\n\u00b7 Maitrise d\u2019une chaine CI/CD (GitLab\u2026)\n\u00b7 Bonne connaissance de Kafka\n\u00b7 Bonne connaissance d\u2019un outil d\u2019int\u00e9gration de donn\u00e9es type ETL (Informatica\u2026)\n\u00b7 Connaissance de l\u2019infra as code (Terraform)\n\u00b7 Connaissance d\u2019un outil de reporting (Looker, BO\u2026)\n\ud83e\udd1d Ce poste est fait pour toi si :\n\u00b7 Tu es passionn\u00e9(e) par la Data et leurs usages\n\u00b7 Tu es orient\u00e9 r\u00e9solution de probl\u00e8me, est curieux(se) et force de proposition\n\u00b7 Tu appr\u00e9cies le travail en \u00e9quipe\n\u00b7 Tu as un bon relationnel et est rigoureux(se)\n\u00b7 Tu as une bonne capacit\u00e9 d\u2019analyse et r\u00e9dactionnelle\n\u00b7 Tu t\u2019adaptes rapidement aux changements\n\ud83c\udf93\nFormation :\nTu es dipl\u00f4m\u00e9(e) d\u2019un master en \u00e9cole de commerce, \u00e9cole d\u2019ing\u00e9nieur ou \u00e9quivalent.\nChez BforBank nous recherchons avant tout des comp\u00e9tences. Tu ne disposes pas du dipl\u00f4me requis mais as des exp\u00e9riences \u00e9quivalentes ? N'h\u00e9site pas \u00e0 postuler !\n\ud83d\udcbc\nExp\u00e9rience :\nExp\u00e9rience confirm\u00e9e de 3 ans en tant que Data Engineer.\nEn rejoignant BforBank tu trouveras\u2026\n\u00b7 Un projet ambitieux de transformation digitale et culturelle \u00e0 l\u2019\u00e9chelon europ\u00e9en, terrain d\u2019innovation et d\u2019ouverture d\u2019esprit\n\u00b7 Une organisation apprenante, proposant un large choix de formations toute l\u2019ann\u00e9e, et qui favorise l\u2019\u00e9change avec les autres marques du Groupe\n\u00b7 Une promo RSE multi-m\u00e9tiers qui fait \u00e9voluer en continu les actions de BforBank vers une banque plus responsable\n\u00b7 Une organisation du travail en mode Agile, impliquant un degr\u00e9 \u00e9lev\u00e9 de collaboration et d'autonomie tout en travaillant avec un groupe de pairs diversifi\u00e9s.\n\u00b7 Une Direction Technologie en pleine expansion, porteuse de nombreux d\u00e9fis strat\u00e9giques\nMais aussi\u2026\nDe 2 jours \u00e0 5 jours de t\u00e9l\u00e9travail modulables par semaine, dans la limite de 84 jours par an (frais de fonctionnement pris en charge)\n25 jours de cong\u00e9s + 16 jours de RTT\n80% du co\u00fbt de la mutuelle d\u2019entreprise pris en charge / couvert\nAvantages collaborateurs Cr\u00e9dit Agricole : taux et tarifs pr\u00e9f\u00e9rentiels\nDes frais de transports rembours\u00e9s \u00e0 75%\nUn restaurant d\u2019entreprise\nDes douches pour les sportifs et un tarif avantageux aupr\u00e8s d\u2019une salle de sport toute proche\n\ud83d\udccd Le poste est bas\u00e9 \u00e0 La D\u00e9fense, dans des locaux flambant neufs !\nBforBank s'engage \u00e0 garantir l'\u00e9galit\u00e9 des chances aux candidats car nous sommes convaincus de la richesse apport\u00e9e par la diversit\u00e9 et l'inclusion dans nos \u00e9quipes.\nRencontrons-nous !\nLe processus de recrutement se d\u00e9roule en 4 \u00e9tapes :\n\ud83e\uddd1\ud83c\udffc\u200d\ud83d\udcbb\nCall de 30 minutes avec notre \u00e9quipe Talent Acquisition\nEchange avec le Data Factory Manager et notre \u00e9quipe Talent Acquisition (pr\u00e9sentiel)\nEchange avec une personne de l\u2019\u00e9quipe avec qui tu seras amen\u00e9 \u00e0 travailler (visio)\nEchange avec le CTO (visio ou pr\u00e9sentiel)\nNotre processus de recrutement dure en moyenne 3 semaines et l\u2019\u00e9quipe Talent Acquisition se tiendra \u00e0 ta disposition pour te donner un maximum de visibilit\u00e9 sur l\u2019avanc\u00e9e du process.\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "R",
                "Go"
            ],
            "DataBase": [
                "SQL"
            ],
            "DataAnalytics": [
                "Pandas",
                "R"
            ],
            "BigData": [
                "Spark"
            ],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [],
            "DevTools": [
                "Git"
            ],
            "Os": [],
            "DBMS": [
                "BigQuery"
            ],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [
                "Terraform"
            ],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [
                "Cloud",
                "CI/CD"
            ],
            "FrSoftSkills": [
                "Collaboration",
                "Organisation"
            ],
            "EnSoftSkils": [
                "Collaboration"
            ]
        },
        "details": {
            "JobDetail": [
                "Confirm\u00e9"
            ],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s",
                "3",
                "3",
                "3"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "title": "DATA ENGINEER",
        "company": "Action for Market Transformation - A4MT",
        "location": "Paris, \u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/data-engineer-at-action-for-market-transformation-a4mt-3910049004?position=6&pageNum=10&refId=Wt7FrOruL4%2BCplGL9tAn0A%3D%3D&trackingId=a5VzP6Z29J%2BQGi4BQ1%2F3Dg%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "A4MT \u2013 Action pour la Transformation des March\u00e9s\nA4MT con\u00e7oit et impl\u00e9mente des programmes d\u2019engagement et de \u00ab Market Transformation \u00bb qui visent \u00e0 g\u00e9n\u00e9raliser des pratiques vertueuses \u2013 au sens environnemental et soci\u00e9tal \u2013 en modifiant la donne du march\u00e9, en reconfigurant le jeu d\u2019acteurs, g\u00e9n\u00e9ralement via des actions collectives.\nCes programmes agissent sur la demande en suscitant de nouvelles pratiques individuelles et collectives. A4MT assure le r\u00f4le de pilote, orchestrant les plans d\u2019action des parties prenantes gr\u00e2ce \u00e0 une \u00e9quipe de qualit\u00e9 \u00e0 caract\u00e8re international, un savoir-faire sur la mise en \u0153uvre des programmes, une connaissance technico-\u00e9conomique experte des sujets trait\u00e9s, et une capacit\u00e9 \u00e0 interpeller les d\u00e9cideurs \u00e0 bon niveau.\nChampionnat de France des \u00e9conomies d\u2019\u00e9nergie\nA4MT avec ses partenaires op\u00e8re l\u2019ensemble des concours CUBE en France (Championnat de France des Economies d\u2019Energies) et assure son d\u00e9veloppement international (Europe, Asie, etc.). CUBE est un concours original d\u2019\u00e9conomies d\u2019\u00e9nergie et de CO2 pour les b\u00e2timents tertiaires et r\u00e9sidentiels qui acc\u00e9l\u00e8re fortement l\u2019action de terrain gr\u00e2ce \u00e0 une intelligence collective sur le terrain.\nLe concours est aujourd\u2019hui pr\u00e9sent dans 8 pays et se d\u00e9veloppe encore. Au-del\u00e0 des \u00e9conomies les plus faciles, il s\u2019agit de mettre en \u0153uvre la trajectoire de gestion immobili\u00e8re et d\u2019investissement qui permettra, au-del\u00e0 des avanc\u00e9es dans ce programme \u00e0 faible investissement, de progresser sur la trajectoire de la neutralit\u00e9 carbone.\nhttps://championnatdefrancedeseconomiesdenergie.org/\nMISSION\nRendant compte au directeur d\u2019A4MT et en \u00e9troite collaboration avec le directeur technique A4MT, vous \u00eates Data Engineer, vous serez responsable de la conception, du d\u00e9veloppement et de la maintenance des bases de donn\u00e9es, et des outils de reporting. Vous travaillerez en \u00e9troite collaboration avec l'\u00e9quipe de d\u00e9veloppement (prestataire externe) et vous participez \u00e0 la structuration d\u2019une \u00e9quipe IT interne pour cr\u00e9er des solutions innovantes r\u00e9pondant aux besoins de l'entreprise.\nVotre mission s'articule autours des 3 axes ci-dessous:\n1/ Pilotage et et d\u00e9veloppement\nd\u00e9velopper et d\u00e9ployer des reporting robustes et \u00e9volutifs.\nle planning de d\u00e9veloppement et le budget allou\u00e9.\navec les \u00e9quipes d\u2019animation et le back office technique du programme et avec les prestataires externes pour comprendre les exigences et les sp\u00e9cifications du projet.\n\u00e0 la conception de l'architecture des bases de donn\u00e9es et \u00e0 la prise de d\u00e9cisions techniques.\nla qualit\u00e9 des donn\u00e9es en effectuant des contr\u00f4les qualit\u00e9.\nles performances des applications pour garantir une exp\u00e9rience utilisateur fluide.\nla maintenance et les mises \u00e0 jour r\u00e9guli\u00e8res des applications existantes.\n\u00e0 l'aff\u00fbt des tendances et des technologies \u00e9mergentes.\nVous serez responsable du process, de la ma\u00eetrise d\u2019ouvrage li\u00e9e \u00e0 la Data et garant(e) de la qualit\u00e9 de service.\n2/ Implication des \u00e9quipes et de la sous-traitance\nVous serez impliqu\u00e9 dans une \u00e9quipe informatique naissante et dans une \u00e9quipe projet avec les diff\u00e9rentes fonctions m\u00e9tiers. Vous devrez faire le suivi de votre implication avec le responsable de programme et le directeur technique d\u2019 A4MT :\n3/ Gestion de projet\nVous tiendrez le tableau de bord des outils : budgets, engagements, planning, r\u00e9sultats, d\u00e9veloppements.\nPROFIL\nVous avez une exp\u00e9rience significative d\u2019au moins 3 ann\u00e9es dans l\u2019\u00e9cosyst\u00e8me de big data, des serveurs et bases de donn\u00e9es dans des contextes de projets, d\u2019exploitation de migration.\nCOMPETENCES\nBac +5 dipl\u00f4m\u00e9(e) d\u2019une grande \u00e9cole d\u2019ing\u00e9nieur ou \u00e9quivalent, vous \u00eates :\n+5 dipl\u00f4m\u00e9 (e) d\u2019une \u00e9cole d\u2019ing\u00e9nieurs ou \u00e9quivalent, en Data science, Informatique, g\u00e9nie logiciel ou domaine connexe.\nprofessionnelle d\u00e9montr\u00e9e de 3 ans ou plus en tant que Data Engineer\ndes langages structur\u00e9s (JavaScript, Scala, Python\u2026),\navec les bases de donn\u00e9es relationnelles (MySQL, PostgreSQL) et non relationnelles (MongoDB, Firebase).\nau moins un outil de reporting (Power BI, Tableau \u2026)\ndes services de d\u00e9ploiement et d'h\u00e9bergement cloud comme AWS, Azure ou Google Cloud Platform.\ncomp\u00e9tences en d\u00e9veloppement back-end avec des technologies comme Node.js, Python, Ruby on Rails, ou Java. et notamment en PHP sont recommand\u00e9es\ndes langages de programmation front-end tels que HTML5, CSS3 et JavaScript (notamment frameworks: comme React, Angular ou Vue.js).\n\u00e0 travailler en \u00e9quipe, \u00e0 communiquer efficacement et \u00e0 r\u00e9soudre les probl\u00e8mes de mani\u00e8re autonome.\ndes principes de s\u00e9curit\u00e9 des applications web et des meilleures pratiques en mati\u00e8re de d\u00e9veloppement s\u00e9curis\u00e9 ainsi que le respect du RGPD.\nDate d\u2019entr\u00e9e et conditions\nLe poste est \u00e0 pourvoir imm\u00e9diatement; il est bas\u00e9 au 54, rue de Clichy, Paris (IX\u00e8me). Niveau de r\u00e9mun\u00e9ration selon exp\u00e9rience.\nContact\nMerci d\u2019adresser votre candidature compl\u00e8te (CV, lettre de motivation, pr\u00e9sentation du cursus en cours de conclusions et r\u00e9f\u00e9rences \u00e9ventuelles) \u00e0 l\u2019attention de M. Adrien Brunella sur le mail elisabeth.clement@a4mt.com\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "Java",
                "Scala",
                "R",
                "Go",
                "JavaScript",
                "HTML"
            ],
            "DataBase": [
                "SQL"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [
                "Tableau",
                "Power BI"
            ],
            "Statistics": [],
            "CloudComputing": [
                "AWS",
                "Azure",
                "Google Cloud Platform"
            ],
            "DevTools": [
                "Git"
            ],
            "Os": [],
            "DBMS": [
                "MySQL",
                "PostgreSQL"
            ],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [
                "Big Data",
                "ML",
                "Cloud"
            ],
            "FrSoftSkills": [
                "Collaboration"
            ],
            "EnSoftSkils": [
                "Collaboration"
            ]
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s",
                "3",
                "3",
                "3"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "title": "(Senior) Data Engineer",
        "company": "Mirakl",
        "location": "France",
        "link": "https://fr.linkedin.com/jobs/view/senior-data-engineer-at-mirakl-3904076524?position=7&pageNum=10&refId=Wt7FrOruL4%2BCplGL9tAn0A%3D%3D&trackingId=nk2bB5vqPzMQmCDY62Tvyg%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Mirakl, leader et pionnier de l\u2019\u00e9conomie de plateforme, propose aux entreprises une suite unique de solutions leur permettant de transformer significativement leur e-commerce afin d'acc\u00e9l\u00e9rer de fa\u00e7on durable et rentable leur croissance. Depuis 2012, Mirakl accompagne les entreprises B2C et B2B avec la technologie la plus avanc\u00e9e, s\u00e9curis\u00e9e et \u00e9volutive leur permettant de digitaliser leur activit\u00e9 et d'\u00e9largir leur offre via la marketplace ou le dropship, faciliter la gestion des catalogues et des paiements de leurs fournisseurs pour plus d'efficacit\u00e9, offrir une exp\u00e9rience d'achat personnalis\u00e9e \u00e0 leurs clients, et augmenter leurs profits gr\u00e2ce au retail media. Bas\u00e9e \u00e0 Paris et Boston, Mirakl est certifi\u00e9e Great Place to Work.\nA propos de Mirakl Labs\nNos \u00e9quipes techniques et produits, nomm\u00e9es Mirakl Labs, sont principalement r\u00e9parties entre nos 2 hubs situ\u00e9s \u00e0 Paris et \u00e0 Bordeaux. Elles collaborent au quotidien afin d'adresser les probl\u00e9matiques de nos clients et utilisateurs en r\u00e9pondant \u00e0 diff\u00e9rents challenges li\u00e9s aux nouvelles fonctionnalit\u00e9s, \u00e0 la scalabilit\u00e9, la s\u00e9curit\u00e9 et l\u2019ergonomie\u2026\nElles op\u00e8rent en mode agile et s'organisent en Squads compos\u00e9es d'un Squad Lead, de 5 d\u00e9veloppeurs, d'un Product Manager et d'un QA. Chaque Squad est sp\u00e9cialis\u00e9e sur un scope fonctionnel afin de concevoir et r\u00e9aliser de nouvelles features, leurs \u00e9volutions et des APIs (avec un d\u00e9coupage en micro-services). Nos \u00e9quipes Infrastructure, Architecture, S\u00e9curit\u00e9, Documentation, Product Design, Data et Support op\u00e8rent en transverse en apportant leur expertise et de la coh\u00e9rence sur l\u2019ensemble des produits.\nToutes les \u00e9quipes sont responsables de leur p\u00e9rim\u00e8tre et chacun des collaborateurs apporte son exp\u00e9rience et ses id\u00e9es. Innovation, feedback et implication dans les prises de d\u00e9cision sont au c\u0153ur de notre philosophie.\nEt pour favoriser ce partage avec d\u2019autres passionn\u00e9s, nous sommes sponsors, speakers, et h\u00f4tes de diff\u00e9rents \u00e9v\u00e9nements, meetups, et associations de la sc\u00e8ne Tech en France. Au cours des derni\u00e8res ann\u00e9es, nous avons particip\u00e9 \u00e0 des \u00e9v\u00e9nements tels que Devoxx, ReactEurope, ProductConf et Flupa UX Days.\nA propos du job\nLa solution SaaS Mirakl est le moteur des marketplaces des plus importants e-commer\u00e7ants \u00e0 travers le monde. Cette solution g\u00e8re et produit de gros volumes de donn\u00e9es qui pr\u00e9sentent des challenges extr\u00eamement int\u00e9ressants pour les sp\u00e9cialistes de la donn\u00e9e (produits, commandes, clients, niveaux de stock, prix, messages, appels API, donn\u00e9es de navigation, s\u00e9ries temporelles, donn\u00e9es g\u00e9olocalis\u00e9es etc.).\nEn tant que (Senior) Data Engineer au sein de l\u2019\u00e9quipe Data Mirakl, vos principales missions seront de :\ncontribuer \u00e0 l'enrichissement de la Data Platform (ETL)\nam\u00e9liorer la robustesse de nos pipelines de production pour nos applications Machine Learning (inf\u00e9rence real time etc.)\nInt\u00e9gr\u00e9(e) dans une \u00e9quipe de sp\u00e9cialistes de la donn\u00e9e (data engineers, machine learning engineers, data scientists, data analysts), vous \u00eates un des acteurs cl\u00e9s pour garantir la place de Mirakl comme solution dominante sur son march\u00e9.\nNotre stack et nos outils\nApache Spark, Kafka, AWS, Databricks, Python, Airflow, Mlflow, Tensorflow, Delta lake, Superset, Kubernetes, Redshift, SQL, Terraform, Ansible\nAu quotidien, vous allez :\nParticiper \u00e0 la d\u00e9finition et \u00e0 l\u2019impl\u00e9mentation d\u2019une architecture performante, robuste, scalable et aux co\u00fbts ma\u00eetris\u00e9s pour nos applications Spark ainsi que pour nos pipelines de production de Machine Learning (\u00e9valuation des feature stores, refactoring de DAG Airflow)\nAccompagner les Data Scientists lors de leur mise en production (relecture de code, pair programming) et mettre en place les best practices\nOptimiser et am\u00e9liorer la CI/CD de l\u2019\u00e9quipe en collaboration avec l\u2019\u00e9quipe SRE\nAssurer la mont\u00e9e en comp\u00e9tence des membres de l\u2019\u00e9quipe sur les sujets de MLOps et Data Engineering\nR\u00e9fl\u00e9chir \u00e0 la meilleure fa\u00e7on d'int\u00e9grer les donn\u00e9es Google Analytics dans la data platform\nPartager ses connaissances et pr\u00e9senter les travaux devant toutes les \u00e9quipes Labs\nCe qu\u2019on peut vous apporter :\nDes projets data driven, divers et vari\u00e9s (traitements massifs d\u2019images, de textes, time series etc.) pour des produits diff\u00e9rents de Mirakl\nUne culture orient\u00e9e sur la veille technologique\nDes projets qui ont un vrai impact business devant \u00eatre d\u00e9ploy\u00e9s sur des centaines de clients dans un contexte multilingue\nQuelques exemples de sujets en cours :\nEnrichissement des donn\u00e9es produit \u00e0 partir des images et des descriptions\nMod\u00e9ration automatique des produits\nMapping automatique des donn\u00e9es produit\nIdentification des produits \u00e0 fort potentiels\nD\u00e9tection de comportements frauduleux\nSentiment analysis sur les messages \u00e9chang\u00e9s entre clients et vendeurs et dans les \u00e9valuations\nD\u00e9termination de prix optimaux\nMonitoring de la qualit\u00e9 de service des vendeurs\nDes applications d\u2019inf\u00e9rence en synchrone de nos mod\u00e8les de ML\nVous aimerez ce job si :\nVous \u00eates passionn\u00e9(e) par la data et les technologies modernes permettant d'en tirer partie\nVous vous int\u00e9ressez \u00e0 la data science et avez des connaissances g\u00e9n\u00e9rales sur les algorithmes de Machine Learning\nVous avez un background en d\u00e9veloppement et avez \u00e9volu\u00e9 dans un environnement Data\nVous avez a minima 4 ans d\u2019exp\u00e9rience en environnement Machine Learning et/ou Data\nVous avez mis en production avec succ\u00e8s des applications Big Data faisant appel \u00e0 du Machine Learning, du NLP, du traitement d\u2019images dans des projets d'envergure, \u00e0 fort volume de donn\u00e9es\nVotre ma\u00eetrisez Python, \u00eates un pro des frameworks data de la fondation Apache et \u00eates \u00e0 l'aise dans un environnement AWS\nVous ma\u00eetrisez au moins un outil d\u2019orchestration (Airflow, Data Pipeline ou tout autre outil similaire)\nVous pr\u00e9sentez vos travaux de mani\u00e8re simple et accessible\nVous fa\u00eetes preuve d'un bon relationnel et vous aimez mentorer des collaborateurs\nVous parlez couramment anglais et fran\u00e7ais\nLes plus pour le poste :\nVous avez une exp\u00e9rience significative dans le domaine du e-commerce\nVous avez d\u00e9j\u00e0 mis en place un Data Lake, Data Warehouse ou une Data Platform\nVous avez d\u00e9ploy\u00e9 des applicatifs en environnement Kubernetes\nVous avez mis en place des pipelines d'ingestion de donn\u00e9es avec une approche CDC \u00e0 l'aide de Debezium ou autre\nVous ma\u00eetrisez Java/Scala\nMirakl est engag\u00e9e en faveur de la diversit\u00e9, de l\u2019\u00e9galit\u00e9 des chances et de l\u2019inclusion. Nous c\u00e9l\u00e9brons nos diff\u00e9rences car nous sommes convaincus que les qualit\u00e9s visibles et invisibles de chaque Mirakl Worker sont une source de force et d\u2019innovation. Dans le cadre de cet engagement, nous \u00e9tudions toutes les candidatures sans distinction de : genre, ethnicit\u00e9, religion, orientation sexuelle, handicap, \u00e2ge ou toute autre caract\u00e9ristique prot\u00e9g\u00e9e par la loi.\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "Java",
                "Scala",
                "R",
                "Go"
            ],
            "DataBase": [
                "SQL"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [
                "Spark",
                "Databricks"
            ],
            "MachingLearning": [
                "TensorFlow"
            ],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [
                "AWS"
            ],
            "DevTools": [
                "Git"
            ],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [
                "Ansible",
                "Kubernetes",
                "Airflow"
            ],
            "InfrastructureAsCode": [
                "Terraform"
            ],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [
                "Kubernetes"
            ],
            "Collaboration": [],
            "Other": [
                "Big Data",
                "ML",
                "Machine Learning",
                "CI/CD"
            ],
            "FrSoftSkills": [
                "Collaboration"
            ],
            "EnSoftSkils": [
                "Collaboration"
            ]
        },
        "details": {
            "JobDetail": [
                "Senior"
            ],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s",
                "4",
                "4",
                "4"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "title": "Data Engineer Senior",
        "company": "AXA en France",
        "location": "Hauts-de-Seine, \u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/data-engineer-senior-at-axa-en-france-3884386043?position=8&pageNum=10&refId=Wt7FrOruL4%2BCplGL9tAn0A%3D%3D&trackingId=3U%2F2pMNXXaCLmgpNUaVdcg%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Environnement\nEn tant que\nSenior Data Engineer F/H\n, vous allez contribuer directement aux projets des directions m\u00e9tier (ex : fraude sant\u00e9, multi\u00e9quipements, pricing IARD, optimisation du lead management, fragilit\u00e9 auto, \u2026) d\u2019AXA France et \u00e0 la construction du socle technique Big Data.\nVous allez int\u00e9grer une \u00e9quipe d'une dizaine de personne compos\u00e9e de Data Engineer et des Tech Lead travaillant en mode Feature Team au sein des tribus m\u00e9tier de la Direction Transformation Digital Tech et DATA (DT2).\nLa Direction Transformation Digital Tech et DATA d'AXA France en quelques mots :\n- Une organisation agile en feature teams : tribus, guildes, squads\n- Des projets sur des applications innovantes \u00e0 fort trafic (web, mobile\u2026)\n- Des m\u00e9thodologies craft (TDD, BDD, clean code, code review\u2026) et DevOps\n- Une communaut\u00e9 de partage de bonnes pratiques (BBL, dojo, meetup, conf\u2026)\nVotre r\u00f4le et vos missions\nVous aurez pour missions principales de d\u00e9velopper les projets Big Data demand\u00e9s par le m\u00e9tier, et notamment :\nPasser de la donn\u00e9e brute \u00e0 de la donn\u00e9e exploitable, expos\u00e9e sous forme de tables requ\u00eatables dans le datalake\nConsolider ces donn\u00e9es au fur et \u00e0 mesure de leur alimentation r\u00e9currente dans le data lake\nLes exploiter pour atteindre la finalit\u00e9 business (exposition de business view, r\u00e9int\u00e9gration des r\u00e9sultats dans le SI, service de scoring, \u2026)\nDe travailler \u00e0 la cr\u00e9ation du socle technique Big Data et industrialiser le cycle de d\u00e9veloppement de l'\u00e9quipe\nDe mettre en place et de garantir le respect dans la dur\u00e9e d'un processus qualit\u00e9 sur l'ensemble du cycle de DEV (documents, tests unitaires / int\u00e9gration / fonctionnels, commentaires, versionning, etc.)\nVotre profil\nVous justifiez de plusieurs exp\u00e9riences significatives (+ de 5 ans) sur du\nd\u00e9veloppement big data, en particulier sur du PySpark.\nComp\u00e9tences techniques :\nConnaissances avanc\u00e9es en d\u00e9veloppement en\nPySpark\n(Spark avec le langage Python)\nMaitrise de l'environnement\nMicrosoft Azure\nConnaissances avanc\u00e9es d'outils de BI comme\nPowerBI\nComp\u00e9tences transverses :\nCapacit\u00e9 \u00e0 interagir avec des parties prenantes diverses : Business analyst, Architectes, M\u00e9tier\nExp\u00e9rience en mode de delivery Agile (Scrum, Kanban, etc...)\nDriver et accompagner des Data Engineer junior sur les aspects technique\nEt Id\u00e9alement :\nDes Connaissances sur Azure DevOps, Azure Pipeline, GIT, JIRA\nMaitrise des Traitements Big Data en mode Streaming\nMaitrise des Bases de donn\u00e9es relationnelles et NoSQL\nUne exp\u00e9rience professionnelle avec des outils comme Azure Databricks, Azure Data Lake Storage ou encore Azure Data Factory\nQui sommes nous ?\nAXA est un des leaders de l\u2019assurance et de la gestion d\u2019actifs dans le monde.\nNous aidons nos 108 millions de clients \u00e0 traverser les petites et grandes difficult\u00e9s de la vie.\nChaque jour, nous agissons ensemble pour inventer la meilleure mani\u00e8re de les prot\u00e9ger et voulons donner \u00e0 chacun les moyens de vivre une vie meilleure.\nUn challenge qui donne le sourire et envie de se lever le matin !\nChez AXA, nous sommes persuad\u00e9s que pour bien prendre soin de nos clients, nous devons commencer par bien prendre soin de nos collaborateurs. C\u2019est pour cette raison que nous menons une politique RH engag\u00e9e qui favorise la diversit\u00e9, qui pr\u00e9serve l\u2019\u00e9quilibre vie priv\u00e9e-vie professionnelle et acc\u00e9l\u00e8re le d\u00e9veloppement des comp\u00e9tences et des carri\u00e8res.\nAinsi, en rejoignant AXA France vous travaillerez dans une entreprise responsable, offrant une v\u00e9ritable culture d\u2019expertise, acc\u00e9l\u00e9rant le d\u00e9veloppement des comp\u00e9tences de chacun et proposant une r\u00e9mun\u00e9ration attractive.\nPourquoi nous rejoindre ?\nVous \u00eates porteur d\u2019id\u00e9es et d\u2019initiatives innovantes ? Vous proposez des solutions et \u00eates au service du client ? Faites partie de notre grande famille en rejoignant\nUn leader mondial offrant des opportunit\u00e9s de carri\u00e8res int\u00e9ressantes\nUne entreprise qui donne une place de choix \u00e0 l\u2019innovation, \u00e0 l\u2019initiative et aux actions solidaires (notamment via l\u2019association AXA Atout C\u0153ur)\nUn environnement inclusif \u00e0 tous les niveaux (mixit\u00e9, handicap, initiatives pour favoriser l\u2019insertion des jeunes, orientation sexuelle, etc.)\nUn acc\u00e8s \u00e0 de multiples avantages (cong\u00e9s, temps partiel, t\u00e9l\u00e9travail, etc.)\nUn cadre stimulant, qui permet de rencontrer des collaborateurs performants et d\u2019enrichir ses comp\u00e9tences\nVictime ou t\u00e9moin, en cas de discrimination, vous pouvez adresser vos signalements et/ou alertes discrimination \u00e0 alerte.discrimination.harcelement@axa.fr\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "R"
            ],
            "DataBase": [
                "SQL",
                "NoSQL"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [
                "Spark",
                "Databricks"
            ],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [
                "PowerBI"
            ],
            "Statistics": [],
            "CloudComputing": [
                "Azure"
            ],
            "DevTools": [
                "Git"
            ],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [
                "JIRA",
                "Teams"
            ],
            "Other": [
                "DevOps",
                "Big Data"
            ],
            "FrSoftSkills": [
                "Organisation"
            ],
            "EnSoftSkils": [
                "Initiative"
            ]
        },
        "details": {
            "JobDetail": [
                "Junior",
                "Senior"
            ],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s",
                "5",
                "5",
                "5"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "title": "Data Engineer (Snowflake)",
        "company": "MindPal",
        "location": "Lyon, Auvergne-Rh\u00f4ne-Alpes, France",
        "link": "https://fr.linkedin.com/jobs/view/data-engineer-snowflake-at-mindpal-3910994899?position=9&pageNum=10&refId=Wt7FrOruL4%2BCplGL9tAn0A%3D%3D&trackingId=9jrBl%2BUf0qJsGQTz6OU5UQ%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "We are looking for experienced\nData Engineers\nwith knowledge of\nSnowflake\nplatform.\nResponsibilities\nCreating and managing data in the Snowflake environment\nDesigning and implementing ETL (Extract, Transform, Load) solutions for transferring data between various sources and platforms\nOptimizing the performance of Snowflake databases, including designing and implementing data structures and using indexes appropriately\nAutomating data processing workflows using tools such as Airflow or other workflow management tools\nDeploying and configuring tools to monitor and report on the performance of the Snowflake system\nRequirements\nMinimum 1 year of experience as a Data Engineer\nAbility to use Snowflake\nVery good knowledge of SQL and programming in Python\nAbility to work with databases, including the Snowflake platform\nKnowledge of ETL tools and data integration\nAbility to work in a team and good communication skills\nFluent English in speaking and writing\nWe Offer\nB2B contract type\nFull-time job\nRemote and flexible working hours\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "R",
                "Go"
            ],
            "DataBase": [
                "SQL"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [],
            "DevTools": [],
            "Os": [],
            "DBMS": [
                "Snowflake",
                "Snowflake"
            ],
            "SoftBigDataProcessing": [],
            "Automation": [
                "Airflow"
            ],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [],
            "FrSoftSkills": [
                "Communication"
            ],
            "EnSoftSkils": [
                "Communication"
            ]
        },
        "details": {
            "JobDetail": [
                "Remote",
                "Full"
            ],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "title": "Data Engineer",
        "company": "ASTRELYA",
        "location": "Greater Paris Metropolitan Region",
        "link": "https://fr.linkedin.com/jobs/view/data-engineer-at-astrelya-3910760230?position=10&pageNum=10&refId=Wt7FrOruL4%2BCplGL9tAn0A%3D%3D&trackingId=yV6o8FO4VtUJdgoHfgWavQ%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "ASTRELYA est un groupe de conseil et d\u2019expertise IT fond\u00e9 en 2017, pr\u00e9sent en France (Paris et r\u00e9gions) et en Suisse (Gen\u00e8ve). Aujourd'hui plus de 280 collaborateurs accompagnent nos clients dans l\u2019acc\u00e9l\u00e9ration et la transformation de leurs organisations.\nDans le cadre de notre d\u00e9veloppement, nous recherchons un\nData Engineeer F/H\n.\nVos r\u00f4les et responsabilit\u00e9s :\nD\u00e9veloppements Java Spark\nOptimisation et gestion des \u00e9volutions de l&#39;architecture pour int\u00e9grer des calculs sur des volum\u00e9tries de plus en plus importantes\nSupport technique aupr\u00e8s des \u00e9quipes de d\u00e9veloppement et du responsable applicatif\nConception des solutions applicatives coh\u00e9rentes avec l&#39;ensemble du SI et avec les normes et standards\nD\u00e9velopper et garantir les pratiques de d\u00e9veloppement et de documentation associ\u00e9s (DevOps\nL\u2019environnement technique dans lequel vous \u00e9voluerez :\nJava, Scala, Spark, \u00e9cosyst\u00e8me Hadoop, environnement DevOps\nLes comp\u00e9tences recherch\u00e9es :\nFormation : \u00c9cole d\u2019ing\u00e9nieur ou \u00e9quivalent Bac+5\nExp\u00e9riences : Minimum 5 ans d\u2019exp\u00e9rience\nLangues : Anglais technique\nExcellent relationnel, force de proposition, autonome\nPourquoi rejoindre ASTRELYA ?\nUne gestion de carri\u00e8re personnalis\u00e9e et un management de proximit\u00e9\nUne politique active de formations / certifications (technique, m\u00e9tier, leadership)\nUne offre vari\u00e9e de missions d\u2019expertise\nUn engagement RSE fort : Ecovadis Gold, Signataire de la charte pour la diversit\u00e9, du Pacte des Nations Unies et mise en place du M\u00e9c\u00e9nat de comp\u00e9tences\nUn programme de cooptation attractif\nAfterworks, conf\u00e9rences techniques et activit\u00e9s sportives r\u00e9guliers\nCette annonce vous correspond ? Postulez !\n\ud83d\ude80\nTous nos postes sont ouverts aux personnes en situation de handicap.\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Java",
                "Scala",
                "R",
                "Go"
            ],
            "DataBase": [],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [
                "Hadoop",
                "Spark"
            ],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [],
            "DevTools": [],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [
                "DevOps"
            ],
            "FrSoftSkills": [
                "Leadership",
                "Organisation"
            ],
            "EnSoftSkils": [
                "Leadership"
            ]
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [],
            "Salary": [],
            "Level": [
                "Bac+5"
            ],
            "Experience": [
                "a",
                "n",
                "s",
                "5",
                "5",
                "5"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "title": "Data Engineer  H/F",
        "company": "Groupe INGENA",
        "location": "Greater Paris Metropolitan Region",
        "link": "https://fr.linkedin.com/jobs/view/data-engineer-h-f-at-groupe-ingena-3883689479?position=1&pageNum=12&refId=a575NEEXj%2F5ZYoAYMJyABw%3D%3D&trackingId=PTJFmVLol0NZPIc8rRt%2BRw%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Le groupe INGENA promeut la transition num\u00e9rique en \u00e9tant acteur d\u2019un monde souhaitable.\nVotre mission :\nConcevoir, d\u00e9velopper et tester des algorithmes de collecte et de traitement de gros volumes de donn\u00e9es sous Scala, Python ou Java\nAutomatiser et optimiser les flux de donn\u00e9es et leurs visualisations en dashboards\nIndustrialiser les traitements, la qualit\u00e9 et l\u2019int\u00e9grit\u00e9 des donn\u00e9es\nParticiper \u00e0 la Mod\u00e9lisation et \u00e0 la Gouvernance des donn\u00e9es (process, normalisation, r\u00e9f\u00e9rentiel,\u2026)\nContribuer \u00e0 la scalabilit\u00e9, la s\u00e9curit\u00e9, la stabilit\u00e9 et la disponibilit\u00e9 des donn\u00e9es de la plateforme\nAnalyser les donn\u00e9es pour r\u00e9pondre aux questions m\u00e9tiers et participer \u00e0 l\u2019\u00e9volution de l\u2019architecture Big Data\nConcevoir, D\u00e9velopper et Industrialiser des mod\u00e8les de Machine Learning, Deep Learning, en collaboration avec les Data Scientists\nAppliquer une d\u00e9marche CI/CD (Git, Jira, Jenkins)\nLes comp\u00e9tences techniques n\u00e9cessaires sont :\nExp\u00e9rience de 5 ans minimum en d\u00e9veloppements Scala, Python ou Java\nExp\u00e9rience de 2 ans minimum sur SPARK et sur le traitement des flux en streaming\nExpertise sur Hadoop (Hive, HBase, HDFS) sous distributions MapR ou Hortonworks\nExp\u00e9rience souhait\u00e9e sur ELK, Terraform, NoSQL,\u2026\nFort background en Mod\u00e9lisation de donn\u00e9es ou ETL\nMa\u00eetrise des briques analytiques des clouds AWS, GCP ou Azure\nSensibilisation \u00e0 la d\u00e9marche CI/CD tools (Git, Jenkins)\nLa connaissance de Docker, Kubernetes et Ansible est un plus\nMise en \u0153uvre des m\u00e9thodes Agile (Scrum, Kanban,\u2026)\nAnglais souhait\u00e9\nGroupe INGENA\n:\nLe Groupe INGENA est sp\u00e9cialis\u00e9 en Conseil M\u00e9tier et en Int\u00e9gration pour les march\u00e9s de l\u2019assurance, de la banque et de la Finance. INGENA intervient notamment sur les projets associ\u00e9s \u00e0 la Data, aux Risques et \u00e0 la Distribution.\nLe groupe comprend \u00e9galement la soci\u00e9t\u00e9 DRiMS sp\u00e9cialis\u00e9e en Finance de March\u00e9.\nNos valeurs : Engagement, Int\u00e9grit\u00e9 et Bienveillance.\nLa mise en pratique du monde souhaitable, c\u2019est pour nous une entreprise \u00e9co-responsable, \u00e9thique, inclusive, sociale, soucieuse du bien-\u00eatre, de l\u2019\u00e9volution et de l\u2019\u00e9panouissement de ses \u00e9quipes. Ce sont aussi des offres pour un monde durable comme la ma\u00eetrise des risques ou l\u2019ESG.\nDans un esprit convivial et engag\u00e9, nous faisons en sorte que chacun puisse \u00eatre acteur de l\u2019INGENA souhaitable.\nBureau \u00e0 Paris 9\u00e8me (M\u00e9tro Le Peletier). Clients \u00e0 Paris ou tr\u00e8s proche banlieue.\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "Java",
                "Scala",
                "R",
                "Go"
            ],
            "DataBase": [
                "SQL",
                "NoSQL",
                "HBase"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [
                "Hadoop",
                "Spark"
            ],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [
                "AWS",
                "Azure"
            ],
            "DevTools": [
                "Git",
                "Docker",
                "Jenkins"
            ],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [
                "HBase"
            ],
            "Automation": [
                "Ansible",
                "Kubernetes"
            ],
            "InfrastructureAsCode": [
                "Terraform"
            ],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [
                "Docker",
                "Kubernetes"
            ],
            "Collaboration": [
                "JIRA"
            ],
            "Other": [
                "Big Data",
                "Machine Learning",
                "Cloud",
                "CI/CD"
            ],
            "FrSoftSkills": [
                "Collaboration"
            ],
            "EnSoftSkils": [
                "Collaboration"
            ]
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s",
                "5",
                "5",
                "5"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "title": "DATA ENGINEER-LYON H/F",
        "company": "Lincoln France",
        "location": "Auvergne-Rh\u00f4ne-Alpes, France",
        "link": "https://fr.linkedin.com/jobs/view/data-engineer-lyon-h-f-at-lincoln-france-3851734549?position=2&pageNum=12&refId=a575NEEXj%2F5ZYoAYMJyABw%3D%3D&trackingId=VeypythEIv8Md9nnB3RwPA%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Poste CDI : Data Engineer (Scala, Spark, GCP, etc.) -H/F - Lyon\nLincoln Pure Player Data\n\ud83d\udca1: R\u00e9inventant l'analyse\ndepuis 30 ans\n. Experts en Modern BI, Big Data et Science des donn\u00e9es \ud83d\udcca. Nous transformons vos donn\u00e9es en solutions pour les grands comptes, des secteurs bancaire, retail, t\u00e9l\u00e9coms, industriel, sant\u00e9, et plus encore \ud83d\udcbc.\nDescription de poste\n\ud83c\udfaf\nMissions\n:\nConcevoir et d\u00e9velopper des pipelines de donn\u00e9es robustes et \u00e9volutifs.\nInt\u00e9grer et transformer des donn\u00e9es provenant de diff\u00e9rentes sources.\nD\u00e9velopper et mettre en \u0153uvre des algorithmes de traitement de donn\u00e9es avanc\u00e9s.\nCollaborer \u00e9troitement avec les \u00e9quipes clients pour comprendre leurs besoins et fournir des solutions adapt\u00e9es.\nAssurer la qualit\u00e9 et la fiabilit\u00e9 des solutions d\u00e9velopp\u00e9es.\n\ud83d\udd0d\nPr\u00e9requis\n:\nMa\u00eetrise des langages de programmation (\nPython, Scala, Spark, etc\n.).\nConnaissance approfondie des bases de donn\u00e9es et des technologies\nBig Data (Hadoop, Spark, Kafka, Talend,...) et Cloud (AWS, GCP, Azure,...)\n.\nExp\u00e9rience avec\nMySQL, PostgreSQL, MongoDB.\nSolides comp\u00e9tences en conception et en optimisation de pipelines de donn\u00e9es.\nExp\u00e9rience de travail en\nm\u00e9thode Agile\npour la gestion de projet et le d\u00e9veloppement de solutions.\nCapacit\u00e9 \u00e0 travailler de mani\u00e8re autonome et en \u00e9quipe.\nExcellentes comp\u00e9tences en communication et en r\u00e9solution de probl\u00e8mes.\n\ud83c\udf1f\nAvantages :\nEnvironnement collaboratif et innovant\nFormations certifiantes et accompagnement individualis\u00e9\nT\u00e9l\u00e9travail et horaires flexibles\nR\u00e9mun\u00e9ration comp\u00e9titive avec avantages sociaux attrayants\nPossibilit\u00e9 de mobilit\u00e9 \u00e0 Lille, Paris ou Aix-en-Provence\n\u2728\nProcessus de recrutement\n: 2 entretiens (RH et technique)\nSi vous \u00eates passionn\u00e9 par les d\u00e9fis de la Data et que vous souhaitez rejoindre une \u00e9quipe dynamique et innovante,\npostulez d\u00e8s maintenant et contribuez \u00e0 red\u00e9finir l'avenir de l'analyse de donn\u00e9es chez Lincoln! \ud83d\ude09\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "Scala",
                "R",
                "Go"
            ],
            "DataBase": [
                "SQL",
                " MongoDB"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [
                "Hadoop",
                "Spark"
            ],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [
                "AWS",
                "Azure"
            ],
            "DevTools": [],
            "Os": [],
            "DBMS": [
                "MySQL",
                "PostgreSQL"
            ],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [
                "Big Data",
                "Cloud"
            ],
            "FrSoftSkills": [
                "Communication",
                "R\u00e9solution de probl\u00e8mes"
            ],
            "EnSoftSkils": [
                "Communication"
            ]
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [
                "CDI"
            ],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s",
                "30",
                "30",
                "30"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "title": "D\u00e9veloppeur Big Data H/F",
        "company": "Inetum",
        "location": "St.-Ouen, \u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/d%C3%A9veloppeur-big-data-h-f-at-inetum-3843965989?position=3&pageNum=12&refId=a575NEEXj%2F5ZYoAYMJyABw%3D%3D&trackingId=cF9s3MXmDqgW8F6HUp9rFw%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "D\u00e9tail de l'offre\nInformations g\u00e9n\u00e9rales\nEntit\u00e9 de rattachement\nInetum est un leader europ\u00e9en des services num\u00e9riques. Pour les entreprises, les acteurs publics et la soci\u00e9t\u00e9 dans son ensemble, les 28 000 consultants et sp\u00e9cialistes du groupe visent chaque jour l'impact digital des solutions qui contribuent \u00e0 la performance, \u00e0 l'innovation et au bien commun.\nPr\u00e9sent dans 19 pays au plus pr\u00e8s des territoires, et avec ses grands partenaires \u00e9diteurs de logiciels, Inetum r\u00e9pond aux enjeux de la transformation digitale avec proximit\u00e9 et flexibilit\u00e9.\nPort\u00e9 par son ambition de croissance et d'industrialisation, Inetum a g\u00e9n\u00e9r\u00e9 en 2023 un chiffre d'affaires de 2,5 milliards d'\u20ac.\nPour r\u00e9pondre \u00e0 un march\u00e9 en croissance continue depuis plus de 30ans, Inetum a fait le choix d\u00e9lib\u00e9r\u00e9 de se recentrer sur 4 m\u00e9tiers afin de gagner en puissance et proposer des solutions sur mesure, adapt\u00e9es aux besoins sp\u00e9cifiques de ses clients le conseil (Inetum Consulting), la gestion des infrastructures et applications \u00e0 fa\u00e7on (Inetum Technologies), l'impl\u00e9mentation de progiciels (Inetum Solutions) et sa propre activit\u00e9 d'\u00e9diteur de logiciels (Inetum Software). Inetum a conclu des partenariats strat\u00e9giques avec 4 grands \u00e9diteurs mondiaux - Salesforce, ServiceNow, Microsoft et SAP et poursuit une strat\u00e9gie d'acquisitions d\u00e9di\u00e9e afin d'entrer dans le top 5 europ\u00e9en sur ces technologies et proposer la meilleure expertise \u00e0 ses clients.\nTous nos postes sont ouverts aux personnes en situation de handicap.\nDescription du poste\nM\u00e9tier\nApplications Delivery - Software Development\nIntitul\u00e9 du poste\nD\u00e9veloppeur Big Data H/F\nContrat\nCDI\nDescription De La Mission\nLe p\u00f4le\nBFA\nde la branche Application Services du groupe\nINETUM\n, recherche plusieurs d\u00e9veloppeurs\nBig Data\nafin d'intervenir aupr\u00e8s de clients grands comptes au sein\ndes march\u00e9s bancaires et de l'assurance.\nDirectement int\u00e9gr\u00e9(e) chez l'un de nos clients sur des sujets strat\u00e9giques et aux enjeux forts, vous serez amen\u00e9(e) \u00e0\nParticiper \u00e0 l'analyse d\u00e9taill\u00e9e \u00e0 partir des besoins des utilisateurs et de l'analyse fonctionnelle\nConcevoir l'application et les tests \u00e0 partir de l'analyse d\u00e9taill\u00e9e\nD\u00e9rouler les tests et corriger les anomalies\nTravailler sur la mise en place d\u2019infrastructures Big Data\nR\u00e9aliser les flux de donn\u00e9es\nValider leur fonctionnement en s\u00e9curit\u00e9 et performance\nAssurer la p\u00e9rennit\u00e9 de leurs \u00e9volutions\nParticiper quotidiennement aux r\u00e9unions d\u2019\u00e9quipe (daily meeting) afin de contribuer \u00e0 l\u2019\u00e9valuation de l\u2019effort de travail n\u00e9cessaire\nProfil\nIssue d'une formation d'ing\u00e9nieur / Bac+5 en Informatique\nDot\u00e9 d'une exp\u00e9rience d\u2019au moins 2 ans sur ce type poste\nMa\u00eetrise des technologies Hadoop, Spark, Hive, Impala, ETL (Talend, Informatica, \u2026), Java, Scala, Python, SQL, les bases de donn\u00e9es SQL (oracle, \u2026) et NoSQL (Cassandra, \u2026)\nDes notions de Machine Learning et d\u2019IA sont recommand\u00e9es pour bien appr\u00e9hender les besoins de nos Data Scientists.\nExp\u00e9rience au sein d'un environnement agile (Scrum) indispensable\nAnglais obligatoire\nLocalisation du poste\nLocalisation du poste\nFrance, Ile-de-France\nVille\n145, Boulevard Victor Hugo 93400 Saint-Ouen\nCrit\u00e8res candidat\nNiveau d'exp\u00e9rience min. requis\nPlus de 2 ans\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "Java",
                "Scala",
                "R",
                "Go"
            ],
            "DataBase": [
                "SQL",
                "NoSQL",
                "Cassandra"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [
                "Hadoop",
                "Spark"
            ],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [],
            "DevTools": [
                "Git"
            ],
            "Os": [],
            "DBMS": [
                "Oracle"
            ],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [
                "Big Data",
                "Machine Learning"
            ],
            "FrSoftSkills": [
                "Flexibilit\u00e9"
            ],
            "EnSoftSkils": []
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [
                "CDI"
            ],
            "Salary": [],
            "Level": [
                "Bac+5"
            ],
            "Experience": [
                "a",
                "n",
                "s",
                "30",
                "30",
                "30"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "title": "Data Engineer - D\u00e9veloppeur - 38 - 42K\u20ac Nantes H/F",
        "company": "L2C / Sp\u00e9cialiste du recrutement IT",
        "location": "Nantes, Pays de la Loire, France",
        "link": "https://fr.linkedin.com/jobs/view/data-engineer-d%C3%A9veloppeur-38-42k%E2%82%AC-nantes-h-f-at-l2c-sp%C3%A9cialiste-du-recrutement-it-3913996457?position=4&pageNum=12&refId=a575NEEXj%2F5ZYoAYMJyABw%3D%3D&trackingId=qmrHjOejaWqg6MEzmYhDuQ%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "L2C est un cabinet sp\u00e9cialis\u00e9 dans le recrutement de profils informatiques, tech' et data en CDI pour des clients finaux.\nCLIENT\nPr\u00e9curseur, innovant et visionnaire, notre client a d\u00e9velopp\u00e9 une plateforme bas\u00e9e sur l'IA pr\u00e9dictive, qui permet aux entreprises de prendre les meilleures d\u00e9cisions.\nR\u00e9f\u00e9rence reconnue et leader dans le domaine de la Business Intelligence, notre client d\u00e9veloppe des solutions d'intelligence artificielle commerciale BtoB pointues, compl\u00e8tes, avec un haut niveau de qualit\u00e9 : aide \u00e0 la prospection, gestion des appels d'offres, pr\u00e9diction financi\u00e8re\nSolidement \u00e9tabli, en croissance continue, notre client se r\u00e9invente constamment afin de rester \u00e0 la pointe et de prendre soin de ses collaborateurs.\nDepuis plus de 20 ans, notre client a conquis pr\u00e8s de 15 000 clients. (Paypal, Dassault, KPMG)\nC'est une soci\u00e9t\u00e9 saine, bijou de la tech, pr\u00e9curseur en termes de stack technique et fa\u00e7on de fonctionner, avec un bon \u00e9tat d'esprit, offrant des conditions de travail agr\u00e9ables.\nNous recherchons un candidat polyvalent, \u00e0 la crois\u00e9e entre le traitement de donn\u00e9es et le d\u00e9veloppement. (Proche Nantes)\nPoste \u00e0 pourvoir en interne en CDI. (t\u00e9l\u00e9travail 3 jours/semaine)\nMissions\nVous participerez \u00e0 l'am\u00e9lioration des outils r\u00e9f\u00e9rentiels Big Data, en \u00e9troite collaboration avec les \u00e9quipes de d\u00e9veloppeurs (10 personnes) et les data scientists (6 personnes)\nVous d\u00e9velopperez des solutions de captation et d'int\u00e9gration des donn\u00e9es issues de l'Open Data et des partenaires, crawls, scraping, imports de fichiers\nVous mod\u00e9liserez des bases de donn\u00e9es\nVous orchestrerez des flux de donn\u00e9es entre les applicatifs, r\u00e9f\u00e9rentiels, bases de donn\u00e9es (SQL/NoSQL) avec des outils ETL.\nVous valoriserez les donn\u00e9es avec des traitements compl\u00e9mentaires (g\u00e9ocodage, oc\u00e9risation)\nVous d\u00e9velopperez des APIs pour des usages internes et pour les clients\nVous assurerez la supervision et l'exploitation des outils (surveillance des performances et garantie de la disponibilit\u00e9.\nVous assurerez la qualit\u00e9 des donn\u00e9es (nettoyage, standardisation, valorisation pour garantir la fiabilit\u00e9)\nVous r\u00e9digerez la documentation technique et accompagnerez les utilisateurs\nLes plus\nSoci\u00e9t\u00e9 pr\u00e9curseur, innovante et visionnaire, qui prend soin de ses collaborateurs\nR\u00e9f\u00e9rence reconnue et leader dans le domaine de la Business Intelligence (IA pr\u00e9dictive, sujets tech modernes et riches)\nGroupe solide en forte croissance\nSoci\u00e9t\u00e9 solidement implant\u00e9e en France et \u00e0 l'international depuis une vingtaine d'ann\u00e9es\nT\u00e9l\u00e9travail partiel\nEnvironnement de travail sain et agr\u00e9able\nCompl\u00e9mentaire sant\u00e9/Pr\u00e9voyance, comit\u00e9 d'entreprise, prime vacances, tickets restaurant\nVous disposez d'un bon bagage technique sur Python.\nVous avez l'habitude de vous auto-former sur les outils et langages et vous savez maintenir une veille active sur les outils de traitement des donn\u00e9es.\nComp\u00e9tences / Connaissances\nData-Management, Audit de qualit\u00e9 des donn\u00e9es et usage des ETL\nSyst\u00e8mes Linux, gestion et administration des containers (Docker, Kubernetes)\nD\u00e9veloppement / Scripts : Python ++ (Avec Spark), JavaScript, C#\nBases De Donn\u00e9es\nSQL Server ou autres SGBD Relationnels\nMongoDB\nElasticsearch\nBases de donn\u00e9es orient\u00e9es Graph (Neo4J)\nConnaissances CI/CD, Git\nConnaissance g\u00e9n\u00e9rale des technologies et framework big data usuels.\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "Java",
                "C#",
                "R",
                "Go",
                "JavaScript"
            ],
            "DataBase": [
                "SQL",
                "NoSQL",
                "Neo4j",
                "Elasticsearch"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [
                "Spark"
            ],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [],
            "DevTools": [
                "Git",
                "Docker"
            ],
            "Os": [
                "Linux"
            ],
            "DBMS": [
                "SQL Server"
            ],
            "SoftBigDataProcessing": [],
            "Automation": [
                "Kubernetes"
            ],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [
                "Docker",
                "Kubernetes"
            ],
            "Collaboration": [],
            "Other": [
                "Big Data",
                "CI/CD"
            ],
            "FrSoftSkills": [
                "Collaboration"
            ],
            "EnSoftSkils": [
                "Collaboration"
            ]
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [
                "CDI"
            ],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s",
                "20",
                "20",
                "20"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "title": "Data Engineer (H/F)",
        "company": "Harry Hope.",
        "location": "Paris, \u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/data-engineer-h-f-at-harry-hope-3920545043?position=5&pageNum=12&refId=a575NEEXj%2F5ZYoAYMJyABw%3D%3D&trackingId=kGbVGmURBYVn0rXlEKV%2BSg%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Harry Hope, cabinet de recrutement accompagne candidats et entreprises dans leurs recherches des meilleures opportunit\u00e9s en France et \u00e0 l'international. Afin de mieux r\u00e9pondre \u00e0 vos enjeux, tous nos consultants sont sp\u00e9cialis\u00e9s par secteur d'activit\u00e9 et zone g\u00e9ographique.\nNotre client, soci\u00e9t\u00e9 en pleine croissance, sp\u00e9cialis\u00e9 dans le domaine de la Big Data, recherche des Consultants Data Engineer ! Participez \u00e0 cette aventure et rejoignez une formidable \u00e9quipe.\nVos missions principales seront diversifi\u00e9es, comprenant notamment :\nParticipation aux processus d'avant-vente : Vous contribuerez \u00e0 l'\u00e9laboration des propositions techniques, mettant en avant votre expertise pour r\u00e9pondre aux besoins des clients.\nQualification technique des prestataires : Vous participerez activement \u00e0 l'\u00e9valuation et \u00e0 la s\u00e9lection des prestataires, garantissant un partenariat de qualit\u00e9.\nDirection et coordination des projets : Vous dirigerez et coordonnerez la conception et la mise en oeuvre des projets, assurant leur r\u00e9ussite technique.\nDocumentation technique : Vous \u00e9laborerez, au besoin, des dossiers d'architecture, d'installation et d'exploitation, assurant une tra\u00e7abilit\u00e9 et une compr\u00e9hension optimale des solutions mises en place.\nParticipation active aux d\u00e9veloppements : Vous apporterez votre expertise en contribuant directement aux d\u00e9veloppements dans le cadre des projets.\nDe mani\u00e8re plus \u00e9tendue, vous aurez l'opportunit\u00e9 de :\nEnrichir les bonnes pratiques : Vous contribuerez \u00e0 l'\u00e9volution et \u00e0 l'am\u00e9lioration des bonnes pratiques d'architecture et de d\u00e9veloppement dans le domaine du Big Data.\nVeille technologique : Vous r\u00e9aliserez une veille constante sur les avanc\u00e9es technologiques du secteur, assurant ainsi la pertinence des solutions propos\u00e9es.\nFormation technique : Vous \u00e9laborerez des supports de formation technique pour nos clients et/ou nos consultants juniors, partageant ainsi votre savoir-faire.\nAnimation du p\u00f4le technique : Vous participerez activement \u00e0 l'animation du p\u00f4le technique favorisant un environnement collaboratif et innovant.\nVous \u00eates d\u00e9tenteur d'un dipl\u00f4me d'ing\u00e9nieur (\u00e9cole ou universit\u00e9), et vous avez 5 ans d'exp\u00e9rience en tant que Data Engineer.\nEn tant que Consultant Data Engineer, nous recherchons des professionnels poss\u00e9dant des comp\u00e9tences solides et des convictions dans les domaines suivants :\nArchitectures Big Data : Kappa, Lambda, R\u00e9active, SMACK, etc.\nSolutions technologiques : Hadoop, SGBD NoSQL, Kafka, Spark, etc.\nOutils de d\u00e9veloppement : Vous \u00eates \u00e0 l'aise avec des outils tels que Hive, Pig, Python, Scala, etc.\nEnvironnements d'exploitation et de supervision : Vous avez une exp\u00e9rience pratique avec des outils tels qu'Ambari, Oozie, Zookeeper, etc. 20681288-55584\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "Scala",
                "R"
            ],
            "DataBase": [
                "SQL",
                "NoSQL"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [
                "Hadoop",
                "Spark"
            ],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [],
            "DevTools": [],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [
                "Big Data"
            ],
            "FrSoftSkills": [],
            "EnSoftSkils": []
        },
        "details": {
            "JobDetail": [
                "Junior"
            ],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s",
                "5",
                "5",
                "5"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "title": "Data Engineer",
        "company": "Mobiskill | WEFY Group",
        "location": "Paris, \u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/data-engineer-at-mobiskill-wefy-group-3907391938?position=6&pageNum=12&refId=a575NEEXj%2F5ZYoAYMJyABw%3D%3D&trackingId=d9sK3EdR8JW0CN1NTR9hag%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "La soci\u00e9t\u00e9 ?\nCette startup a \u00e9t\u00e9 cr\u00e9\u00e9e en 2018 et vise \u00e0 aider la prise de d\u00e9cision de ses clients qui sont principalement dans le secteur du retail ou de l'alimentaire.\nIls permettent d'enrichir la donn\u00e9e afin d'am\u00e9liorer la strat\u00e9gie de vente et marketing d'une entreprise gr\u00e2ce \u00e0 leur plateforme Saas bas\u00e9e sur des algorithmes d'IA.\nIls ont besoin de renforcer leur \u00e9quipe en Data Engineering pour g\u00e9rer au mieux leur volum\u00e9trie.\nLes missions ?\n- Editer le cahier des charges des donn\u00e9es \u00e0 collecter aupr\u00e8s de nos partenaires distributeurs\n- Prendre en main la gestion de la donn\u00e9e dans le cloud de la soci\u00e9t\u00e9 pour optimiser les co\u00fbts et l\u2019efficacit\u00e9 des analyses effectu\u00e9es par l\u2019\u00e9quipe Analytics\n- Anticiper les \u00e9volutions et participer aux choix structurants de la soci\u00e9t\u00e9 li\u00e9s \u00e0 la gestion de la data\nLe profil recherch\u00e9 ?\n- Avoir 2/3 ans d'exp\u00e9rience en Data Engineering (hors stage et alternance)\n- Avoir pu travaill\u00e9 en Python comme langage de programmation\nAvoir travaill\u00e9 au moins deux ans et si possible sur des sujets d'optimisation avec Spark !\n- La ma\u00eetrise des outils tels Airflow, Kafka et Snowflake seraient un plus appr\u00e9ci\u00e9\n- Ma\u00eetriser un des cloud providers et si possible avoir une exp\u00e9rience sur Azure\nPourquoi les rejoindre ?\n- Une soci\u00e9t\u00e9 stable financi\u00e8rement (fonds propres uniquement)\n- Une startup en pleine croissance\n- Une r\u00e9mun\u00e9ration en fonction de votre s\u00e9niorit\u00e9\n- Volum\u00e9trie de donn\u00e9es incroyable, il y a de quoi s'amuser !\n- Faire parti de l'unique retail-tech qui a un impact \u00e9cologique positif (fin des prospectus, \u00e9viter le g\u00e2chis alimentaire)\nH\u00e2te de vous en dire plus rapidement !\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "R",
                "Go"
            ],
            "DataBase": [],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [
                "Spark"
            ],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [
                "Azure"
            ],
            "DevTools": [],
            "Os": [],
            "DBMS": [
                "Snowflake",
                "Snowflake"
            ],
            "SoftBigDataProcessing": [],
            "Automation": [
                "Airflow"
            ],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [
                "Cloud"
            ],
            "FrSoftSkills": [],
            "EnSoftSkils": []
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s",
                "3",
                "3",
                "3"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "title": "Data Engineer",
        "company": "MindPal",
        "location": "Lyon, Auvergne-Rh\u00f4ne-Alpes, France",
        "link": "https://fr.linkedin.com/jobs/view/data-engineer-at-mindpal-3896997013?position=7&pageNum=12&refId=a575NEEXj%2F5ZYoAYMJyABw%3D%3D&trackingId=GrAS148%2BSqUlVtQ2ePplOg%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "We are looking for\nData Engineer!\nResponsibilities\nDesigning, creating, and maintaining data processing systems\nAnalyzing and optimizing data processing workflows\nCollaborating with the team to ensure data quality and efficiency\nTesting and implementing new solutions\nRequirements\nAt least 2 years of experience in designing and creating data processing systems\nProficiency in tools and programming languages related to data engineering (e.g. Hadoop, Spark, Scala, Python)\nExcellent knowledge of databases and SQL language\nAbility to work in a team and communicate effectively with other departments\nCommunicative English skills\nExperience with AWS/AWS Glue is a plus\nWe Offer\nB2B contract\nFull-time job\nRemote work and flexible hours\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "Scala",
                "R"
            ],
            "DataBase": [
                "SQL"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [
                "Hadoop",
                "Spark"
            ],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [
                "AWS"
            ],
            "DevTools": [],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [],
            "FrSoftSkills": [],
            "EnSoftSkils": []
        },
        "details": {
            "JobDetail": [
                "Remote",
                "Full"
            ],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "title": "Data Engineer Alternant(e)",
        "company": "Wakam",
        "location": "Paris, \u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/data-engineer-alternant-e-at-wakam-3918901392?position=8&pageNum=12&refId=a575NEEXj%2F5ZYoAYMJyABw%3D%3D&trackingId=xnrf2vRnerqq3Y11vT3uZQ%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Who are we?\nWakam is a B2B2C insurance company that creates white-label insurance solutions via its Play&Plug\u00ae technology platform for more than 150 distribution partners. We provide most of our insurance products through API, and hosts white label insurance solutions via our Play&Plug technology platform.\nWith a footprint spanning 32 countries and revenue of more than \u20ac900 million in 2023, mostly generated outside France, Wakam is the European leader in digital and embedded insurance.\nStrongly committed to social responsibility,\nWakam is a mission-driven company\ndedicated to \"enabling transparent and impactful insurance\".\n\u270e\nMissions\nWakam assure la conception de produits d'assurances sur-mesure qui sont ensuite commercialis\u00e9s par des partenaires distributeurs (courtiers, insurtech, retailers) sur un mod\u00e8le B2B2C en marque blanche. Pour accompagner la forte croissance de l'entreprise, Wakam est \u00e0 la recherche d'un(e) alternant(e) pour rejoindre notre Office Data.\nRattach\u00e9(e) \u00e0 l'\u00e9quipe Data Platform (DPF), vous contribuerez activement \u00e0 l'\u00e9laboration de la nouvelle plateforme en y d\u00e9veloppant de nouveaux cas d'usages techniques et business.\nVos principales missions sont les suivantes :\nConstruire des pipelines ETL/ELT et reverse ETL sur les donn\u00e9es des partenaires Wakam;\nComprendre l'architecture existante, incluant le portail d'ingestion des donn\u00e9es, le framework de self-service et l'infrastructure technique;\nR\u00e9aliser des transformations de donn\u00e9es \u00e0 l'aide du framework DBT en SQL;\nContribuer au d\u00e9veloppement des produits de la Data Platform en utilisant Python et partager les connaissances acquises avec la communaut\u00e9 techniques de Wakam;\nCollecter des donn\u00e9es aux formats vari\u00e9s provenant des diff\u00e9rentes sources;\nParticiper activement au d\u00e9veloppement de la data platform sur Snowflake;\nAider et assister les utilisateurs m\u00e9tier dans l'utilisation des outils fournis par l'\u00e9quipe DPF;\nDocumenter les diff\u00e9rentes \u00e9tapes de transformation et d'historisation des donn\u00e9es;\n\u272f\nProfil recherch\u00e9\nVous suivez actuellement des \u00e9tudes dans l'un de ces domaines : \u00e9cole d'ing\u00e9nieurs, master en informatique, data science, data engineering;\nVous avez de fortes capacit\u00e9s d'analyse et de r\u00e9flexion et savez \u00e9galement \u00eatre dans l'action et orient\u00e9.e r\u00e9sultats ;\nVous \u00eates curieux, autonome et agile;\nVous devez avoir de fortes capacit\u00e9s d'analyse et de r\u00e9flexion, mais \u00e9galement \u00eatre dans l'action et orient\u00e9.e r\u00e9sultats;\nExcellente ma\u00eetrise du fran\u00e7ais et de l'anglais, \u00e0 l'oral comme \u00e0 l'\u00e9crit;\nBonne connaissance de Python, SQL, entrep\u00f4ts de donn\u00e9es, syst\u00e8mes distribu\u00e9s, Cloud;\nProcess de recrutement\nTo help you get a complete picture of our hiring process and Wakam's work culture, please visit our dedicated page: Interviews at Wakam\n\u00c9change avec Jade, Talent Acquisition\n\u00c9change avec Mariana Gherghina (Senior Data Engineer) et Simon Pichon (Engineering Manager)\n=> Welcome @Wakam\nPositive energy, agility, and team spirit are essential to support Wakam in its hyper-growth!\nYou have the Wakam mindset? Join us!\nMore about us\nOur culture?\nFree to impact\n. A culture where everything is possible, where all ideas are taken into consideration, where everyone has an impact on the transformation of insurance! Hungry for freedom? Thirsty for autonomy? If you are adventurous and like challenges, then the Wakam adventure might be made for you!\nDiscover on our website who we really are with the 11 cultural markers that so well describe us!\nWhat we are looking for ?\nMindset compatibility with our 'Free to Impact' culture:\nThink big\nBiased for action\nCurious and eager to learn\nCan say no and find solutions\nAims for the moon (but please don't stick on the moon)\nAnd above all: have fun working together \ud83e\udd1c\ud83e\udd1b !\nGood to know !\nWakam is not based on a hierarchy but on a methodology where everyone finds their role and knows their objectives.\nWith a flat hierarchical system and a highly collaborative operating model, Wakam is an extremely agile and transparent company.\nEvery last Friday of the month, it's Free.day @Wakam, a day without meetings to take a step aside and dedicate ourselves to skills sponsorship or other activities (because we are curious, I remind you).\nFull-remote is a reality at Wakam (there is even one Wakamee who works from his sailing boat \u26f5) with our Wakam From Anywhere (WFA) program.\nLast but not least : we are nice and we have fun! (you'll find out by yourself \ud83d\ude09)\nAt Wakam, we are committed to fostering an inclusive environment where diversity is celebrated. If you require any reasonable adjustments during the recruitment process, please feel free to reach out to your recruiter.\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "R",
                "Go"
            ],
            "DataBase": [
                "SQL"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [],
            "DevTools": [
                "Git"
            ],
            "Os": [],
            "DBMS": [
                "Snowflake",
                "Snowflake"
            ],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [
                "Cloud"
            ],
            "FrSoftSkills": [],
            "EnSoftSkils": []
        },
        "details": {
            "JobDetail": [
                "Remote",
                "Full",
                "Senior"
            ],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "title": "Data Engineer Cloud (H/F)",
        "company": "Beelix",
        "location": "Mougins, Provence-Alpes-C\u00f4te d'Azur, France",
        "link": "https://fr.linkedin.com/jobs/view/data-engineer-cloud-h-f-at-beelix-3909193730?position=9&pageNum=12&refId=a575NEEXj%2F5ZYoAYMJyABw%3D%3D&trackingId=%2Bx0Epim5PeLAZ9pvSZREUQ%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Qui sommes-nous ?\nDepuis 2016, nous accompagnons nos clients sur des probl\u00e9matiques de Product Management, Data et Design Thinking. Beelix contribue \u00e0 fa\u00e7onner le monde de demain en participant aux grandes avanc\u00e9es des secteurs suivants:\n\ud83d\ude97Automobile\n\u26a1Energie\n\ud83d\udce1M\u00e9dias & T\u00e9l\u00e9coms\n\ud83d\udc57Luxe & Retail\n\ud83d\udcb6 Banque, Finance & Assurance\n\u2708\ufe0fD\u00e9fense\nAujourd\u2019hui, Beelix compte plus de 200 collaborateurs motiv\u00e9s et dynamiques. Lab\u00e9lis\u00e9e Great Place To work en 2023, Beelix est aussi une entreprise engag\u00e9e o\u00f9 il fait bon vivre.\nDans le cadre de notre d\u00e9veloppement, nous recherchons un Data Engineer Cloud (H/F) en r\u00e9gion PACA.\nQuelles missions au quotidien ?\nConcevoir, d\u00e9velopper et d\u00e9ployer des pipelines de donn\u00e9es fiables et \u00e9volutifs sur GCP.\nCollaborer avec les \u00e9quipes m\u00e9tier pour comprendre les besoins en donn\u00e9es et fournir des solutions adapt\u00e9es.\nOptimiser les performances et la disponibilit\u00e9 des solutions de donn\u00e9es sur GCP.\nMettre en \u0153uvre des pratiques de s\u00e9curit\u00e9 des donn\u00e9es et assurer la conformit\u00e9 aux r\u00e9glementations.\nTravailler en \u00e9troite collaboration avec les \u00e9quipes de d\u00e9veloppement dans un environnement agile pour fournir des solutions dans des d\u00e9lais serr\u00e9s.\nExpertise souhait\u00e9e\nExp\u00e9rience significative dans le d\u00e9veloppement et la gestion de pipelines de donn\u00e9es sur GCP ou autre plateforme cloud.\nMa\u00eetrise des outils GCP tels que BigQuery, Dataflow, Pub/Sub, et Cloud Storage.\nSolide exp\u00e9rience en Python, Java ou Scala.\nCompr\u00e9hension des principes de l'ing\u00e9nierie des donn\u00e9es, du traitement des donn\u00e9es en continu et des entrep\u00f4ts de donn\u00e9es.\nCapacit\u00e9 \u00e0 travailler de mani\u00e8re autonome et en \u00e9quipe, avec d'excellentes comp\u00e9tences en communication.\nA propos de vous ?\nDipl\u00f4m\u00e9 d'une \u00e9cole d'ing\u00e9nieurs ou \u00e9quivalent\nAu moins 3 ans d'exp\u00e9rience en tant que Data Engineer\nExp\u00e9rience en mode de Delivery Agile (Scrum, Kanban, etc.\u2026)\nVous avez un bon niveau d\u2019anglais tant \u00e0 l\u2019\u00e9crit qu\u2019\u00e0 l\u2019oral\nPourquoi nous rejoindre ?\nUn suivi et un accompagnement au quotidien\nUn organisme de formation certifi\u00e9 Qualiopi, un abonnement linkedin learning pour chaque salari\u00e9 et des partenariats avec des sp\u00e9cialistes pour d\u2019autres expertises\nDe nombreux \u00e9v\u00e9nements : Afterworks, Communaut\u00e9s m\u00e9tiers, Happy talks\u2026\nune Exp\u00e9rience personnalis\u00e9e bas\u00e9e sur vos besoins gr\u00e2ce au Pr\u00e9dictive Index\nNotre package \u00ab unBeelievable \u00bb : 100% du titre de transport, Tickets restaurants, CSE, Prime de participation...\nNombreux \u00e9v\u00e8nements (afterworks, sport, etc) et des communaut\u00e9s m\u00e9tiers dynamiques\nLe processus de recrutement ?\n\u00c9change t\u00e9l\u00e9phonique (15 min)\nEntretien 1 RH pour apprendre \u00e0 vous conna\u00eetre\nEntretien 2 avec votre futur N+1 pour appr\u00e9hender la relation manag\u00e9riale\nEntretien 3 avec un Responsable commercial pour avoir la vision strat\u00e9gique\nLocalisation : Mougins, format hybride\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "Java",
                "Scala",
                "R"
            ],
            "DataBase": [],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [],
            "DevTools": [],
            "Os": [],
            "DBMS": [
                "BigQuery"
            ],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [
                "Cloud"
            ],
            "FrSoftSkills": [
                "Communication",
                "Collaboration"
            ],
            "EnSoftSkils": [
                "Communication",
                "Collaboration"
            ]
        },
        "details": {
            "JobDetail": [
                "Hybride"
            ],
            "TypeContract": [],
            "Salary": [
                "100"
            ],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s",
                "3",
                "3",
                "3"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "title": "Data Engineer & Analyst - Paris - F/H/X - CDI",
        "company": "Partoo",
        "location": "Paris, \u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/data-engineer-analyst-paris-f-h-x-cdi-at-partoo-3892387658?position=10&pageNum=12&refId=a575NEEXj%2F5ZYoAYMJyABw%3D%3D&trackingId=1AWLZFifjjDn5cL6tE%2Bgvw%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Partoo, who are we? \ud83d\udc40\nPartoo est une scale-up saas B2B qui a \u00e0 c\u0153ur d\u2019aider les commerces locaux, grandes entreprises ou PME \u00e0 se rapprocher de leurs clients. Pour cela, ils ont d\u00e9velopp\u00e9 une plateforme tout-en-un et diff\u00e9rentes solutions qui s\u2019articulent autour de 3 propositions de valeur : Get found, Get chosen & Get clients.\n\u00c0 travers ces 3 propositions, ils ont d\u00e9velopp\u00e9 plusieurs produits qui s\u2019adaptent aux \u00e9volutions du parcours d\u2019achat des clients :\n\ud83d\udd0e Get found\nPresence: Synchroniser les informations des magasins sur les principales plateformes (Google, Facebook, Waze, etc.), annuaires et GPS\nStore Locator: Aider les clients \u00e0 trouver le magasin qui leur convient gr\u00e2ce \u00e0 des donn\u00e9es locales actualis\u00e9es et des filtres d\u00e9di\u00e9s sur les sites web des enseignes\nR\u00e9seaux sociaux: G\u00e9rer les publications sur Facebook, Google, Instagram, etc\n\ud83c\udfaf Get chosen\nReview: Centraliser, r\u00e9pondre et analyser les avis clients re\u00e7us sur Google et Facebook\nBooster: Obtenir des avis positifs suppl\u00e9mentaires sur Google par le biais de SMS et de QR codes\n\ud83e\udd17 Get clients\nMessages: Centraliser et r\u00e9pondre \u00e0 tous les messages de chat re\u00e7us via Google Business Messages, Messenger et bient\u00f4t aussi via Instagram, whatsapp, etc. (templates messages, conversations starter, appels manqu\u00e9s...)\nQuelques chiffres \ud83d\udddd\ufe0f\n> Un label Happy at Work et l'une des meilleures notes Glassdoor de l'\u00e9cosyst\u00e8me avec 4.6/5 pour plus de 260 avis\u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f \ufe0f\ufe0f\ufe0f\ufe0f\ufe0f\ufe0f\n> 450+ employ\u00e9s heureux, 37 nationalit\u00e9s diff\u00e9rentes, des bureaux \u00e0 Paris et Barcelone \ud83d\ude80\n> Ils g\u00e8rent 300 000 points de vente et travaillent de mani\u00e8re transversale avec +1000 cha\u00eenes (Carrefour, Generali, Toyota, D\u00e9cathlon, Leroy Merlin etc.) et +6000 pme dans environ 150 pays\nNotre m\u00e9mo 2024: le mot du CEO (https://www.partoo.co/fr/blog/memo-2024/)\nIMPACT \ud83d\udca5\nPartoo compte aujourd\u2019hui pas moins de 400 collaborateurs, qui \u0153uvrent au quotidien \u00e0 maintenir une croissance saine, en phase avec les enjeux et challenges \u00e9conomiques du moment.\nUne des composantes clefs pour y parvenir r\u00e9side en notre capacit\u00e9 \u00e0 d\u00e9velopper et maintenir un haut niveau d\u2019efficacit\u00e9 op\u00e9rationnelle. Dans cette logique, am\u00e9liorer notre capacit\u00e9 \u00e0 exploiter et utiliser la donn\u00e9e pr\u00e9sente dans nos syst\u00e8mes est indispensable. Si nous avons d\u00e9j\u00e0 une \u00e9quipe Data en place, celle-ci est aujourd\u2019hui mobilis\u00e9e presque exclusivement sur les th\u00e9matiques data relatives au fonctionnement de notre application ainsi qu\u2019\u00e0 la construction d\u2019\u00e9l\u00e9ments de visibilit\u00e9 pour nos clients.\nNous souhaitons donc recruter un Data Engineer & Analyst dont l\u2019objectif principal sera de permettre aux \u00e9quipes Op\u00e9rations et client-facing de visibiliser et tirer le meilleur parti d\u2019une donn\u00e9e aujourd\u2019hui difficile d\u2019acc\u00e8s.\nManager : Adel Adman (cc. Cl\u00e9ment Bouillaud, en charge de la team Operations)\nTEAM \ud83d\udc99\nMeetings r\u00e9current avec les membres de Partoo :\nMembre \u00e0 part enti\u00e8re de l\u2019\u00e9quipe Data (elle-m\u00eame int\u00e9gr\u00e9e dans l\u2019\u00e9quipe Produit), tu seras n\u00e9anmoins en contact r\u00e9gulier avec les \u00e9quipes Op\u00e9rations, qui seront tes principales interlocutrices.\nEn d\u2019autres termes, tu seras le pilier central entre les \u00e9quipes Ops et Data.\nDans un premier temps, tu auras un meeting hebdomadaire avec Adel (Lead Data) et avec Cl\u00e9ment (COO), le temps de cadrer tes premi\u00e8res priorit\u00e9s et de trouver la bonne r\u00e9currence de rencontre avec les \u00e9quipes Op\u00e9rations.\nMISSIONS \ud83d\udd25\nTon principal objectif consiste \u00e0 faire en sorte que chaque personne, des \u00e9quipes Op\u00e9rations comme des \u00e9quipes client-facing, ait acc\u00e8s \u00e0 la donn\u00e9e dont elle a besoin, au moment o\u00f9 elle en a besoin, sur le support le plus ad\u00e9quat. Pour y parvenir, plusieurs missions seront tiennes :\nArchitecture\n:\nCr\u00e9er des architectures de donn\u00e9es robustes et \u00e9volutives pour collecter, stocker et analyser de grandes quantit\u00e9s de donn\u00e9es provenant de diverses sources (Salesforce, Intercom, Chargebee, back office de Partoo, etc.)\nAnalyser et am\u00e9liorer continuellement le mod\u00e8le de donn\u00e9es Salesforce (SF), en accompagnant l'\u00e9quipe Ops dans le monitoring des anomalies et l'optimisation des performances\nInt\u00e9grations et flux\n:\nD\u00e9velopper et optimiser des pipelines de donn\u00e9es, assurant l'int\u00e9gration fluide des donn\u00e9es dans notre Data Warehouse depuis diff\u00e9rentes sources, et inversement\nTransformation & analyse\n:\nConcevoir et ex\u00e9cuter des requ\u00eates SQL complexes pour l'analyse de donn\u00e9es, permettant de soutenir les d\u00e9cisions business\nIdentifier et construire des KPI cruciaux, fournissant des insights pr\u00e9cieux aux \u00e9quipes business\nVisualisation\n:\nFournir aux \u00e9quipes Ops et client-facing des outils de visualisation de donn\u00e9es (Looker Studio, embedding, etc.), cl\u00e9s dans l'optimisation de notre gestion de client\u00e8le.\nFormation\n:\nFormer les \u00e9quipes Op\u00e9rations sur l\u2019exploitation des tables de notre Datawarehouse ainsi que sur l\u2019usage de Looker Studio et propager les principales best practices associ\u00e9es. Tout \u00e7a, en collaboration au quotidien avec les \u00e9quipes Ops !\nDESIRED PROFILE \ud83c\udfaf\nComp\u00e9tences recherch\u00e9es :\nUne tr\u00e8s bonne connaissance du langage SQL, notamment PostgreSQL et BigQuery.\nMa\u00eetrise du scripting Python et des notebooks pour l'analyse de donn\u00e9es\nD\u2019excellentes capacit\u00e9s d'analyse pour comprendre les besoins business, identifier les anomalies dans les donn\u00e9es et proposer des am\u00e9liorations pertinentes\nUne bonne aptitude \u00e0 manipuler et analyser de grands ensembles de donn\u00e9es et en extraire des insights actionnables\nUne tr\u00e8s bonne ma\u00eetrise d'au moins un outil de business intelligence tel que Looker Studio, PowerBI ou Tableau\nProfils recherch\u00e9 :\nTu as plus de 3 ans d'exp\u00e9rience en Data Engineering /Advanced Data Analysis\nTu ma\u00eetrises les stacks de data les plus r\u00e9centes (dbt, Airflow, Airbyte, etc.) et les meilleures pratiques en mati\u00e8re de donn\u00e9es (ETL, reverse-ETL, etc.)\nTu es orient\u00e9(e) utilisateur et sais convertir les besoins commerciaux en solutions techniques\nTu sais communiquer avec les \u00e9quipes et t'assurer que les meilleures pratiques sont adopt\u00e9es\nTu es un team player !\nTu souhaites apprendre et grandir avec nous\nRECRUITMENT PROCESS \ud83d\udee0\ufe0f\nA first video call with Marine, Talent Acquisition Specialist, 45 min\nInterview with Adel, Lead Data Engineer, 1h\nCase Study\nInterview with Cl\u00e9ment, Chief Operations Officer, 1h\n\u00c0 comp\u00e9tences \u00e9gales, ce poste est ouvert aux travailleurs et travailleuses en situation de handicap ou assimil\u00e9s au sens de l\u2019article L5212-13 du Code du travail. Partoo s\u2019engage en faveur de la diversit\u00e9, l\u2019\u00e9galit\u00e9 professionnelle, l\u2019emploi des travailleurs handicap\u00e9s.\nWith equal skills, this position is open to disabled workers or those considered to be disabled within the meaning of Article L5212-13 of the French Labour Code. Partoo is committed to diversity, professional equality and the employment of disabled workers.\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "R",
                "Go"
            ],
            "DataBase": [
                "SQL"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [
                "Tableau",
                "PowerBI"
            ],
            "Statistics": [],
            "CloudComputing": [],
            "DevTools": [],
            "Os": [],
            "DBMS": [
                "PostgreSQL",
                "BigQuery"
            ],
            "SoftBigDataProcessing": [],
            "Automation": [
                "Airflow"
            ],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [],
            "FrSoftSkills": [
                "Collaboration"
            ],
            "EnSoftSkils": [
                "Collaboration"
            ]
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s",
                "3",
                "3",
                "3"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "title": "Senior Data & Cloud Engineer (H/F)",
        "company": "fifty-five",
        "location": "Paris, \u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/senior-data-cloud-engineer-h-f-at-fifty-five-3915044673?position=1&pageNum=15&refId=3Lir5Tz0viOiyHjhQOdm%2FQ%3D%3D&trackingId=19LhPvryuXNgBpkjdc5ogw%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Senior Data & Cloud Engineer\nfifty-five est une data-company d'un genre nouveau qui aide les marques \u00e0 exploiter les donn\u00e9es pour am\u00e9liorer le marketing, les m\u00e9dias et l'exp\u00e9rience client gr\u00e2ce \u00e0 une combinaison de services de conseil et de technologie sp\u00e9cialis\u00e9s.\nEn tant que pilier data et marketing du Brandtech Group, nous offrons des services qui combinent le conseil en strat\u00e9gie, les services de cloud, le conseil en m\u00e9dia et l'exp\u00e9rience client.\nfifty-five, c'est plus de 400 experts du num\u00e9rique. Des digital consultants, des sp\u00e9cialistes du tracking et du m\u00e9dia, des ing\u00e9nieurs et des data scientists, travaillent tous en \u00e9troite collaboration pour fournir des conseils marketing de haut niveau et une assistance technique aux marques, dans tout type d'industrie, partout dans le monde.\nPartenaire des annonceurs de la collecte \u00e0 l'activation et l'exploitation des donn\u00e9es, nous aidons les organisations \u00e0 devenir de v\u00e9ritables entit\u00e9s omnicanales ma\u00eetrisant l'efficacit\u00e9 de leur \u00e9cosyst\u00e8me digital et ses synergies avec le monde physique.\nBas\u00e9 \u00e0 Paris, nous op\u00e9rons sur 3 fuseaux horaires depuis nos 10 bureaux, situ\u00e9s \u00e0 Paris, Londres, Gen\u00e8ve, Milan, Shanghai, Hong Kong, Shenzhen, Taipei, Singapour et New York. fifty-five attache une importance particuli\u00e8re au bien-\u00eatre de ses collaborateurs, ce qui lui a permis de figurer dans le classement Best Workplaces France en 2018.\nContexte :\nL'\u00e9quipe d'ing\u00e9nierie d\u00e9veloppe et met en \u0153uvre les solutions techniques permettant la r\u00e9alisation de pipelines de donn\u00e9es et l'impl\u00e9mentation de data platform pour nos clients : r\u00e9cup\u00e9ration de datas sur de multiples sources de donn\u00e9es (APIs, files, etc.), data cleaning, data processing, automation et monitoring de l'ensemble. L'\u00e9quipe s'appuie sur des technologies r\u00e9centes (docker, kubernetes, terraform, notebooks, etc.) et met en place ses projets dans les diff\u00e9rents clouds du march\u00e9 (GCP, Azure, AWS...).\nMission :\nNous sommes \u00e0 la recherche d'une personne capable de r\u00e9aliser des projets techniques pour r\u00e9pondre aux besoins de nos clients (par exemple: syst\u00e8me de recommandations de produits, d\u00e9tection d'anomalies, ranking). Les activit\u00e9s vont du chiffrage et du sizing technique \u00e0 la mise en \u0153uvre des architectures, en passant par la revue des sp\u00e9cifications fonctionnelles et la production de code. Le Data & Cloud Engineer sera \u00e9paul\u00e9 par un Lead dans ses missions. Il sera \u00e9galement amen\u00e9 \u00e0 participer \u00e0 la R&D et \u00e0 accompagner les \u00e9quipes transverses dans la mise en place d'outils de travail internes (librairies pour les data scientists, environnement Notebooks pour les data analysts et data scientists, d\u00e9veloppement de frameworks sur diff\u00e9rents cloud providers, etc.).\nNous souhaitons trouver la bonne personne pour faire \u00e9voluer ou cr\u00e9er de nouvelles solutions dans ce cadre. Les missions comprennent aussi bien du prototypage rapide pour des d\u00e9monstrateurs, que de la production de code robuste qui tourne en production tous les jours.\nComp\u00e9tences et exp\u00e9riences :\n4-5 ans d'exp\u00e9rience en tant que Data Engineer\nMa\u00eetrise de Python, SQL\nMa\u00eetrise des environnements Cloud. Id\u00e9alement certifi\u00e9 GCP, Azure ou AWS\nBonne connaissance de Docker/Kubernetes\nBonne connaissance d'au moins un data warehouse (BigQuery, Snowflake, etc)\nConnaissance autour des Notebooks (Jupyter)\nA l'aise avec des concepts li\u00e9s aux APIs (OAuth, REST, etc.)\nA l'aise avec les notions d'Infrastructure as Code (Terraform)\nAu courant des pratiques GitOps et connaissances des concepts autour du CI/CD\nLa ma\u00eetrise d'un orchestrateur, comme Apache Airflow, est un plus\nEsprit d'\u00e9quipe (collaborer aux tests unitaires, revue de code, partage de code, sprints)\nBon niveau en fran\u00e7ais et en anglais\nA d\u00e9j\u00e0 travaill\u00e9 en mode projet avec des interlocuteurs vari\u00e9s (consultant, data analyst, data scientist)\nUne exp\u00e9rience en marketing digital est un plus\nNous proposons :\nun bureau au centre de Paris avec terrasse et jardin\nun environnement multiculturel avec des collaborateurs aux nationalit\u00e9s multiples (France, Royaume-Uni, Etats-Unis, Chine, Tunisie, Italie et plus)\ndes projets avec nos bureaux \u00e0 Londres, Hong Kong, New York, Shanghai, Gen\u00e8ve, Shenzhen et Taipei\ndes TGIF et supers soir\u00e9es\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "R"
            ],
            "DataBase": [
                "SQL"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [
                "Apache Airflow"
            ],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [
                "AWS",
                "Azure"
            ],
            "DevTools": [
                "Git",
                "Docker"
            ],
            "Os": [],
            "DBMS": [
                "Snowflake",
                "Snowflake",
                "BigQuery"
            ],
            "SoftBigDataProcessing": [],
            "Automation": [
                "Kubernetes",
                "Airflow"
            ],
            "InfrastructureAsCode": [
                "Terraform"
            ],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [
                "Docker",
                "Kubernetes"
            ],
            "Collaboration": [],
            "Other": [
                "Cloud",
                "CI/CD"
            ],
            "FrSoftSkills": [
                "Collaboration",
                "Organisation"
            ],
            "EnSoftSkils": [
                "Collaboration"
            ]
        },
        "details": {
            "JobDetail": [
                "Senior"
            ],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s",
                "5",
                "5",
                "5"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "title": "Data Engineer",
        "company": "NW",
        "location": "Paris, \u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/data-engineer-at-nw-3904072453?position=2&pageNum=15&refId=3Lir5Tz0viOiyHjhQOdm%2FQ%3D%3D&trackingId=FFg227%2BWLr13f6Zrujr8iA%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Type de contrat :\nCDI\nLocalisation :\nParis, 7\u00e8me (pr\u00e9sentiel)\nDate de d\u00e9but :\nd\u00e8s que possible\nExp\u00e9rience requise :\n1 ou 2 ans d\u2019exp\u00e9rience\nA propos de NW\nNW vise \u00e0 rendre la transition \u00e9nerg\u00e9tique accessible \u00e0 tous. Depuis 2007, le groupe d\u00e9ploie des solutions innovantes pour augmenter la part des \u00e9nergies d\u00e9carbon\u00e9es dans le mix \u00e9lectrique fran\u00e7ais, soutenir la stabilit\u00e9 du r\u00e9seau \u00e9lectrique et contribuer au d\u00e9veloppement de la mobilit\u00e9 \u00e9lectrique.\nPremi\u00e8re licorne fran\u00e7aise de la transition \u00e9nerg\u00e9tique, NW est le leader en France du stockage d'\u00e9lectricit\u00e9 avec sa solution JBox\u00ae et le pr\u00e9curseur de la recharge haute puissance gr\u00e2ce \u00e0 ses bornes IECharge\u00ae. L'entreprise se d\u00e9veloppe \u00e9galement \u00e0 l'international, en particulier en Europe et aux Etats-Unis. En f\u00e9vrier 2023, NW a rejoint la FrenchTech Next40.\nDans le cadre de notre forte croissance, nous recherchons un(e) Data Engineer pour rejoindre notre \u00e9quipe tech. De formation Bac+5 Ing\u00e9nieur ou similaire, vous souhaitez contribuer dans le domaine des \u00e9nergies renouvelables, sur un poste \u00e0 fort impact et au sein d\u2019une jeune \u00e9quipe et engag\u00e9e.\nVos principales missions\nMettre en place des outils de traitement et stockage de donn\u00e9es\nBenchmarking des solutions les plus adapt\u00e9es aux besoins des \u00e9quipes\nAssurer la s\u00e9curit\u00e9 de l\u2019architecture de donn\u00e9es\nParticiper \u00e0 la s\u00e9lection de la stack technique\nActualisation et adaptation des solutions utilis\u00e9es selon l\u2019\u00e9volution des technologies\nAssurer la gestion des co\u00fbts li\u00e9s aux besoins data avec les \u00e9quipes internes\nSupport technique aux utilisateurs internes\nImpl\u00e9menter les processus de stockage et pr\u00e9paration des donn\u00e9es\nConfigurer la connexion aux APIs internes et externes\nFormation des \u00e9quipes internes sur les sujets data\nVos comp\u00e9tences\nVous \u00eates int\u00e9ress\u00e9(e) par les \u00e9nergies renouvelables\nVous avez une r\u00e9elle aisance relationnelle et une bonne capacit\u00e9 r\u00e9dactionnelle\nVous avez la volont\u00e9 de rejoindre une entreprise en pleine croissance avec un projet de d\u00e9veloppement ambitieux\nVous assurez la conversion des donn\u00e9es\nVous ma\u00eetrisez de l\u2019automatisation de la CI/CD\nVous parlez l\u2019anglais couramment\nVotre profil\nId\u00e9alement, vous avez 1 ou 2 ans d\u2019exp\u00e9rience dans un poste similaire\nVous avez un Bac +5 Ing\u00e9nieur ou similaire\nVous \u00eates curieux(se), rigoureux(se), proactif(ve) et autonome\nTech stack\nPython\nDocker\nKubernetes\nApache Kafka\nApache Flink\nGithub Actions\nApache Iceberg\nPourquoi NW ?\nD\u00e9couvrir le secteur de la mobilit\u00e9 \u00e9lectrique, du stockage d'\u00e9nergie et du d\u00e9veloppement de projet dans une entreprise\nRejoindre une \u00e9quipe dynamique, positive, engag\u00e9e\nParticipez activement aux d\u00e9fis majeurs de la transition \u00e9nerg\u00e9tique et de la d\u00e9carbonisation des \u00e9nergies\nEntreprise en pleine croissance, possibilit\u00e9 d\u2019avoir un impact important dans la valorisation de l\u2019entreprise\nProcessus de recrutement :\nEntretien RH\nEntretien manager\nTest technique\nEntretien fit \u00e9quipe\nNW Groupe est un employeur garantissant l'\u00e9galit\u00e9 des chances. NW Groupe c\u00e9l\u00e8bre la diversit\u00e9 et s'engage \u00e0 fournir un environnement de respect mutuel o\u00f9 toutes les d\u00e9cisions de recrutement sont bas\u00e9es sur les qualifications, le m\u00e9rite et les besoins de l'entreprise.\nOrganisation et m\u00e9thodologies \u2705\nNous travaillons en Squad sur le principe du roulement de projet avec pour but de participer activement \u00e0 la r\u00e9flexion et au d\u00e9veloppement de chacune des applications de l'entreprise.\nProjets et d\u00e9fis techniques \ud83d\udcbb\nNos outils sont d\u00e9velopp\u00e9s en interne et permettent de d\u00e9velopper, installer et superviser plusieurs centaines de sites de stockage d'\u00e9nergie. Chaque jour, ces outils permettent d'optimiser la gestion de notre activit\u00e9 et d'acc\u00e9l\u00e9rer la transition \u00e9nerg\u00e9tique visant la d\u00e9carbonisation des \u00e9nergies.\nRecherche et D\u00e9veloppement \ud83d\udd0d\nNous travaillons activement sur l\u2019am\u00e9lioration continue des concepts et des solutions existantes autour de la transition \u00e9nerg\u00e9tique. Nos \u00e9quipes s'occupent non seulement de la conception et de la l'am\u00e9lioration de ces syst\u00e8mes mais aussi de l'exploration de futures opportunit\u00e9s dans le secteur.\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "R",
                "Go"
            ],
            "DataBase": [],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [
                "Flink"
            ],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [],
            "DevTools": [
                "Git",
                "Docker"
            ],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [
                "Apache Kafka",
                "Apache Flink"
            ],
            "Automation": [
                "Kubernetes"
            ],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [
                "Docker",
                "Kubernetes"
            ],
            "Collaboration": [],
            "Other": [
                "CI/CD"
            ],
            "FrSoftSkills": [
                "Organisation"
            ],
            "EnSoftSkils": []
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [
                "CDI"
            ],
            "Salary": [],
            "Level": [
                "Bac+5"
            ],
            "Experience": [
                "a",
                "n",
                "s",
                "2",
                "2",
                "2"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "title": "Data Engineer F/H - Syst\u00e8me, r\u00e9seaux, donn\u00e9es (H/F)",
        "company": "UpMan Consulting",
        "location": "Lille, Hauts-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/data-engineer-f-h-syst%C3%A8me-r%C3%A9seaux-donn%C3%A9es-h-f-at-upman-consulting-3901572843?position=3&pageNum=15&refId=3Lir5Tz0viOiyHjhQOdm%2FQ%3D%3D&trackingId=5F%2FT5Lsts3uu%2FuZVqqv4gQ%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Cette offre d\u2019emploi est fournie par P\u00f4le emploi\nDescription\nDescriptif du poste: C est maintenant l occasion pour toi de rejoindre UpMan Consulting Notre ambition est de trouver les meilleurs profils Data Engineer pour intervenir chez nos clients grands comptes de la m\u00e9tropole lilloise. On te propose une exp\u00e9rience professionnelle en ad\u00e9quation avec ce que tu souhaites r\u00e9ellement. Tu d\u00e9couvriras une ambiance de travail saine & bienveillante, tu participeras activement au d\u00e9veloppement d une Happy StartUp, actuellement en forte croissance. O\u00f9 convivialit\u00e9 rime avec efficacit\u00e9 & o\u00f9 ta performance individuelle contribue \u00e0 notre r\u00e9ussite globale. Tes missions / comp\u00e9tences techniques Si tu l acceptes, ton r\u00f4le & tes missions seront les suivantes : * R\u00e9aliser le processus d int\u00e9gration de nouvelles donn\u00e9es (r\u00e9flexion sur la solution, mise en place d ETL, r\u00e8gles de nettoyage, anonymisation ) * \u00catre garant de l'acc\u00e8s aux sources de donn\u00e9es. * Ma\u00eetrise de la donn\u00e9e et \u00eatre le garant de sa qualit\u00e9 (r\u00e9f\u00e9rencement, normalisation et qualification) afin d'en faciliter l'exploitation par les \u00e9quipes (Data Analysts et Data Scientists). * Ma\u00eetrise de technologies Big Data et Cloud : Hadoop, Spark * Assurer la supervision et l'int\u00e9gration de donn\u00e9es structur\u00e9es et non structur\u00e9es venant de sources multiples, tout en veillant \u00e0 garder des donn\u00e9es de qualit\u00e9. * Assurer le suivi, la cartographie et la documentation des donn\u00e9es int\u00e9gr\u00e9es * Afin de garantir une bonne ex\u00e9cution de ta mission, nous recherchons les comp\u00e9tences techniques suivantes : Langages de programmation : * SQL * Python / Pyspark * Java/Scala (plus rare, mais important) Diff\u00e9rents types d ETL & orchestrateurs : * Airflow * Dagster * Prefect * SSIS/informatica * Talend Plateformes cloud : * GCP * Microsoft Azure * AWS Base de donn\u00e9es relationnelles & NoSQL : * postgreSQL, MySQL,... * Redis, graphDB * Data warehouse/data transform : * Snowflake, Bigquery (tr\u00e8s important) * DBT Qualit\u00e9 & comp\u00e9tences n\u00e9cessaires * Communiquant.e dans l \u00e2me * Avoir une bonne capacit\u00e9 de synth\u00e8se & l esprit critique * Travail d \u00e9quipe * Curiosit\u00e9 aigu\u00eb * Comprendre les objectifs & les besoins Nice to have * Anglais courant * Connaissance de la m\u00e9thodologie DevOps * Notions en Data-science The office Pas de full remote (pour l instant) mais de l hybride dans la plupart des missions. En moyenne, 2 jours de t\u00e9l\u00e9travail par semaine. Cependant, les portes de nos bureaux \u00e0 Wambrechies sont toujours ouvertes pour accueillir nos collaborateurs pendant leurs journ\u00e9es de t\u00e9l\u00e9travail & passer une bonne journ\u00e9e tous ensemble ! Le salaire Junior : 30K \u00e0 36K Ma\u00eetrisant : 37K \u00e0 43K Expert : 44K \u00e0 50K & plus + notre package avantage Profil recherch\u00e9: Ton Profil Tu es une personne passionn\u00e9e & passionnante. Tu as envie d'\u00e9voluer, de partager, de participer \u00e0 une mission collective & d\u00e9couvrir LA nouvelle fa\u00e7on de collaborer avec une ESN made in Lille. Tu peux justifier d'une exp\u00e9rience forte & significative en tant que Tech Lead Java, dans le d\u00e9veloppement Java ! Pas besoin d'avoir trop ou pas assez de dipl\u00f4mes, chez nous, ce sont les comp\u00e9tences qui priment \u202f! On se rencontre, on discute, on \u00e9change sur tes envies professionnelles & on laisse la magie op\u00e9rer. L'envie de grandir & de monter en comp\u00e9tences est ton moteur au quotidien. Tu aimes les probl\u00e9matiques complexes et les d\u00e9fis technologiques. On dit de toi que tu es un.e agiliste dans l'\u00e2me, qui effectue une veille constante, \u00e0 l'aff\u00fbt de tout ce qui \u00e9volue autour de toi... Ne r\u00e9fl\u00e9chis plus, saute le pas & d\u00e9couvre UpMan Consulting, tu ne seras pas d\u00e9\u00e7u. Tu balances ta d\u00e9mission ?\nPROFIL SOUHAIT\u00c9\nExp\u00e9rience\nExp\u00e9rience exig\u00e9e de 1 An(s)\nSource: Pole emploi (https://www.pole-emploi.fr)\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "Java",
                "Scala",
                "R"
            ],
            "DataBase": [
                "SQL",
                "NoSQL"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [
                "Hadoop",
                "Spark"
            ],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [
                "AWS",
                "Azure"
            ],
            "DevTools": [],
            "Os": [],
            "DBMS": [
                "MySQL",
                "PostgreSQL",
                "Snowflake",
                "Snowflake",
                "BigQuery"
            ],
            "SoftBigDataProcessing": [],
            "Automation": [
                "Airflow"
            ],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [
                "DevOps",
                "Big Data",
                "Cloud"
            ],
            "FrSoftSkills": [],
            "EnSoftSkils": []
        },
        "details": {
            "JobDetail": [
                "Hybride",
                "Remote",
                "Full",
                "Junior"
            ],
            "TypeContract": [],
            "Salary": [
                "30K",
                "1"
            ],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "title": "Data Engineer GCP (F/H)",
        "company": "Apside",
        "location": "Paris, \u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/data-engineer-gcp-f-h-at-apside-2859485219?position=4&pageNum=15&refId=3Lir5Tz0viOiyHjhQOdm%2FQ%3D%3D&trackingId=wv7OLTbzzRJCbMwFBnb29w%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Envie de rejoindre une entreprise apprenante ? Engag\u00e9e pour t\u2019accompagner dans ton \u00e9volution professionnelle et dans tes projets personnels ?\nRejoins Apside Paris pour travailler sur nos projets de demain !\nLe poste :\nTu seras amen\u00e9 \u00e0 participer \u00e0 la migration des donn\u00e9es et le traitements Big Data depuis un cluster Hadoop interne vers l'infrastructure Google Cloud Platform.\nDans ce sens, tes missions seront les suivantes :\nParticipation aux chantiers de cadrage de la migration\nContribution \u00e0 la mise en place des environnements et outils de d\u00e9ploiement automatis\u00e9s\nAccompagnement et formation des \u00e9quipes \u00e0 l\u2019outil GCP\n...\nEnvironnement technique :\nJira Big data\nCloud GCP\nHadoop\nKubernetes\nSpark, Kafka, Python\nToi ?\nTu as d\u00e9j\u00e0 particip\u00e9 \u00e0 un projet de\nmigration Google Cloud Platform (GCP)\n?\nTu es\nrigoureux\n,\nbon communiquant\n?\nTu souhaites participer \u00e0 un\nprojet d\u2019envergure associant cloud et Big Data\n?\nAlors ce poste de\nData Engineer GCP\nest fait pour toi !\nEt la suite ?\nTu rencontres d\u2019abord l\u2019\u00e9quipe RH pour parler de tes attentes, ton projet, ton futur !\nPuis les managers pour parler concret : missions, projets, parcours de carri\u00e8re, et bien s\u00fbr salaire et avantages :)\nEt tu discutes avec un de nos Tech Leads, pour \u00e9valuer tes comp\u00e9tences et te challenger.\nTu souhaites donner un nouvel \u00e9lan \u00e0 ta carri\u00e8re ? Rejoins la vie Apsidienne !\nPour en savoir plus \u00e0 www.apside.com\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "R",
                "Go"
            ],
            "DataBase": [],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [
                "Hadoop",
                "Spark"
            ],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [
                "Google Cloud Platform"
            ],
            "DevTools": [],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [
                "Kubernetes"
            ],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [
                "Kubernetes"
            ],
            "Collaboration": [
                "JIRA"
            ],
            "Other": [
                "Big Data",
                "Cloud"
            ],
            "FrSoftSkills": [],
            "EnSoftSkils": []
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [],
            "Salary": [
                "Salaire"
            ],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "title": "Data Engineer Spark Scala - Services Financiers - Ile de France",
        "company": "Sopra Steria",
        "location": "Paris, \u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/data-engineer-spark-scala-services-financiers-ile-de-france-at-sopra-steria-3913390665?position=5&pageNum=15&refId=3Lir5Tz0viOiyHjhQOdm%2FQ%3D%3D&trackingId=jSrg1Q0BPIqKrW7h8N2KDQ%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Company Description\nSopra Steria\n, acteur majeur de la Tech en Europe, reconnu pour ses activit\u00e9s de conseil, de services num\u00e9riques et d\u2019\u00e9dition de logiciels, aide ses clients \u00e0 mener leur transformation digitale et \u00e0 obtenir des b\u00e9n\u00e9fices concrets et durables. Il apporte une r\u00e9ponse globale aux enjeux de comp\u00e9titivit\u00e9 des grandes entreprises et organisations, combinant une connaissance approfondie des secteurs d\u2019activit\u00e9 et des technologies innovantes \u00e0 une approche r\u00e9solument collaborative.\nSopra Steria place l\u2019humain au centre de son action et s\u2019engage aupr\u00e8s de ses clients \u00e0 tirer le meilleur parti du digital pour construire un avenir positif.\nFort de 56 000 collaborateurs dans pr\u00e8s de 30 pays, le Groupe a r\u00e9alis\u00e9 un chiffre d\u2019affaires de 5,8 milliards d\u2019euros en 2023.\nThe world is how we shape it\nJob Description\nVotre futur environnement de travail :\nChez notre client, grande banque commerciale fran\u00e7aise, vous int\u00e9grez nos squads pour intervenir sur des projets de grande envergure, des projets transformants et structurants de la banque de demain. Vous interviendrez sur la gestion d\u2019applications sur des domaines tels que : la conformit\u00e9, la fraude, la lutte anti-blanchiment, les risques de cr\u00e9dit, la tr\u00e9sorerie, les paiements, les financements structur\u00e9s ou encore le r\u00e9glementaire bancaire.\nAu sein de notre Data Factory, vous \u00eates pleinement impliqu\u00e9(e) dans toutes les phases de nos projets pour le compte de grands clients, contribuant ainsi \u00e0 leur succ\u00e8s. Vous avez l'occasion de d\u00e9velopper vos comp\u00e9tences techniques et fonctionnelles de mani\u00e8re approfondie, tout en travaillant sur des projets exigeants et passionnants pour le compte de grands clients du secteur bancaire.\nVotre r\u00f4le et vos missions :\nVous avez pour r\u00f4le la mise en place de pipelines de donn\u00e9es fiables, s\u00e9curis\u00e9s et \u00e0 l\u2019\u00e9chelle pour soutenir la mise \u00e0 disposition des donn\u00e9es aux cas d\u2019usage m\u00e9tier qui en ont besoin.\nVos activit\u00e9s principales sont les suivantes :\nVous travaillez avec le client pour \u00e9valuer, concevoir, d\u00e9ployer, am\u00e9liorer et maintenir les pipelines de donn\u00e9es;\nVous vous assurez que les pipelines de donn\u00e9es cr\u00e9\u00e9s sont r\u00e9silients, s\u00e9curis\u00e9s et accessibles;\nVous d\u00e9finissez le mod\u00e8le op\u00e9rationnel pour monitorer et supporter les pipelines de donn\u00e9es\nVous fournissez une expertise \u00e0 nos clients sur leurs donn\u00e9es pour assurer leur optimisation et leur s\u00e9curit\u00e9 par rapport \u00e0 leurs besoins;\nVous apportez un savoir en gestion de la qualit\u00e9 et la gouvernance de la donn\u00e9e pour assurer le suivi de la conformit\u00e9 \u00e0 la gouvernance de la donn\u00e9e\nVous faites de la veille technologique dans le domaine afin d\u2019enrichir les roadmaps technologiques et fournir des solutions modernes \u00e0 nos clients.\nQualifications\nVotre profil :\nDe formation Master 2 Ecole d'Ing\u00e9nieurs ou Informatique, ou \u00e9quivalent, vous justifiez d'une exp\u00e9rience technique de 3 ans minimum et souhaitez \u00e9voluer rapidement dans un contexte motivant. Vous avez ces comp\u00e9tences requises :\nMa\u00eetrise des technologies de bases de donn\u00e9es Relationnelles et NoSQL\nMa\u00eetrise d\u2019au moins un outil d\u2019ETL/ELT (Informatica, datastage, etc.)\nMa\u00eetrise des technologies de traitement distribu\u00e9 de donn\u00e9es (spark, scala, Hadoop)\nMa\u00eetrise d\u2019au moins un framework de streaming de donn\u00e9es (Kafka, RabbitMQ, etc.)\nMa\u00eetrise de chaines CI/CD et de des bonnes pratiques de DataOps\nMa\u00eetrise de solution de Vitrtualisation de donn\u00e9es (Denodo, Dremio, etc.)\nM\u00e9thodologie Agile Scrum\nAnglais professionnel\nVous \u00eates attir\u00e9(e) par le monde du num\u00e9rique, le Cloud (maitrise d'un environnement public ou priv\u00e9 est un plus) et des technologies innovantes.\nVous avez un bon esprit d'analyse, \u00eates curieux(se) et passionn\u00e9(e) et vous avez le sens du travail en \u00e9quipe.\nAdditional Information\nCe que nous vous proposons :\nUn accord t\u00e9l\u00e9travail pour t\u00e9l\u00e9travailler jusqu'\u00e0 2 jours par semaine selon vos missions.\nUn package avantages int\u00e9ressants : une mutuelle, un CSE, des titres restaurants, un accord d'int\u00e9ressement, des primes vacances et cooptation.\nUn accompagnement individualis\u00e9 avec un mentor.\nDes opportunit\u00e9s de carri\u00e8res multiples : plus de 50 m\u00e9tiers, autant de passerelles \u00e0 imaginer ensemble.\nPlusieurs centaines de formations accessibles en toute autonomie depuis l'app mobile avec Sopra Steria Academy.\n.La possibilit\u00e9 de s'engager aupr\u00e8s de notre fondation ou de notre partenaire \u00ab Vendredi \u00bb.\nL'opportunit\u00e9 de rejoindre le collectif Tech'Me UP (formations, conf\u00e9rences, veille, et bien plus encore).\nEmployeur inclusif et engag\u00e9, notre soci\u00e9t\u00e9 \u0153uvre chaque jour pour lutter contre toute forme de discrimination et favoriser un environnement de travail respectueux. C\u2019est pourquoi, attach\u00e9s \u00e0 la mixit\u00e9 et \u00e0 la diversit\u00e9, nous encourageons toutes les candidatures et tous les profils.\nhttps://www.soprasteria.fr/nous-connaitre/nos-engagements\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Scala",
                "R",
                "Go"
            ],
            "DataBase": [
                "SQL",
                "NoSQL"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [
                "Hadoop",
                "Spark"
            ],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [],
            "DevTools": [
                "Git"
            ],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [
                "Cloud",
                "CI/CD"
            ],
            "FrSoftSkills": [
                "Organisation"
            ],
            "EnSoftSkils": []
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [],
            "Salary": [
                "50"
            ],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s",
                "3",
                "3",
                "3"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "title": "Data Engineer (Python/Spark/Hadoop)-Aix-en-Provence F/H - Syst\u00e8me, r\u00e9seaux, donn\u00e9es (H/F)",
        "company": "scient",
        "location": "Aix-en-Provence, Provence-Alpes-C\u00f4te d'Azur, France",
        "link": "https://fr.linkedin.com/jobs/view/data-engineer-python-spark-hadoop-aix-en-provence-f-h-syst%C3%A8me-r%C3%A9seaux-donn%C3%A9es-h-f-at-scient-3904578388?position=6&pageNum=15&refId=3Lir5Tz0viOiyHjhQOdm%2FQ%3D%3D&trackingId=J%2B0%2BLvS4df0oncADPyQXRg%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Cette offre d\u2019emploi est fournie par P\u00f4le emploi\nDescription\nDescriptif du poste: Votre travail quotidien consistera \u00e0 : * Concevoir des mod\u00e8les efficaces pour stocker et analyser des t\u00e9raoctets de donn\u00e9es. * Mettre en \u0153uvre des flux d'acquisition et de transformation complexes * Construire des mod\u00e8les de donn\u00e9es intelligents pour servir nos \u00e9quipes produits et nos \u00e9quipes BI, Insights et data science tout en minimisant les co\u00fbts. * D\u00e9velopper des outils pour aider nos data scientists \u00e0 industrialiser les projets d'apprentissage automatique. * Travailler sur la qualit\u00e9 et la fiabilit\u00e9 des donn\u00e9es pour garantir que nous fournissons des mesures fiables \u00e0 l'ensemble de l'entreprise. * D\u00e9velopper des outils pour aider nos scientifiques \u00e0 industrialiser les projets d'apprentissage automatique. * D\u00e9velopper notre plateforme de science des donn\u00e9es * Industrialiser les projets d'apprentissage automatique avec les scientifiques sp\u00e9cialis\u00e9s dans les donn\u00e9es. Les enjeux * Data powerBI sur un data center -> doit \u00eatre migr\u00e9 dans 1 autre serveur * Travailler sur une infra hadoop / migration de MariaDB \u00e0 techno GPAS. * Aujourd'hui re\u00e7oit des flux de fichiers avec un ETL et met dans sa base MariaDB. L'environnement va \u00eatre remplac\u00e9 en plus du changement de serveur. L'ETL fait dans MariaDB va devoir \u00eatre recr\u00e9\u00e9 dans GPAS Profil recherch\u00e9: Votre profil : * Avec un minimum de 3 ans d'exp\u00e9rience, vous avez une parfaite connaissance des Data Engineering, des technologies et vous ma\u00eetrisez python (id\u00e9alement avec plusieurs autres langages backend et vous connaissez bien les meilleures pratiques de d\u00e9veloppement logiciel, telles que CI/CD, tests unitaires, QA et cr\u00e9ation de mocks...). * Excellent esprit d'\u00e9quipe et \u00e0 l'aise pour interagir avec les parties prenantes techniques et commerciales. * Habitu\u00e9 \u00e0 travailler dans un environnement agile et \u00e0 accepter les changements de priorit\u00e9s. * Curieux, humble et faisant preuve d'un \u00e9quilibre entre cr\u00e9ativit\u00e9 et pragmatisme. * Grande volont\u00e9 d'apprendre et d'enseigner aux autres * Ma\u00eetrise de l'anglais (\u00e9crit et parl\u00e9) Comp\u00e9tences techniques : * Ma\u00eetrise de Python, Scala, Spark et PostgreSQL * Maitrise Pyspark, Hive et Hadoop * Vous \u00eates curieux, autonome, rigoureux et proactif, vous souhaitez rejoindre une \u00e9quipe passionn\u00e9e d'informatique, d'IA et d'innovations et que vous ma\u00eetrisez les comp\u00e9tences n\u00e9cessaires.\nPROFIL SOUHAIT\u00c9\nExp\u00e9rience\nExp\u00e9rience exig\u00e9e de 1 An(s)\nSource: Pole emploi (https://www.pole-emploi.fr)\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "Scala",
                "R",
                "Go"
            ],
            "DataBase": [
                "SQL"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [
                "Hadoop",
                "Spark"
            ],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [
                "PowerBI"
            ],
            "Statistics": [],
            "CloudComputing": [],
            "DevTools": [],
            "Os": [],
            "DBMS": [
                "PostgreSQL"
            ],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [
                "CI/CD"
            ],
            "FrSoftSkills": [
                "Cr\u00e9ativit\u00e9"
            ],
            "EnSoftSkils": []
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s",
                "3",
                "3",
                "3"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "title": "Data Engineer",
        "company": "Pictarine",
        "location": "Toulouse, Occitanie, France",
        "link": "https://fr.linkedin.com/jobs/view/data-engineer-at-pictarine-3911913926?position=7&pageNum=15&refId=3Lir5Tz0viOiyHjhQOdm%2FQ%3D%3D&trackingId=U7AF5ggHYB4XAUH2FvxmZQ%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Mission and challenges \ud83c\udfaf\nSi tu es enthousiaste \u00e0 embarquer dans la nouvelle \u00e9quipe data de Pictarine pour la faire rayonner avec tout ton savoir-faire, alors c\u2019est l\u2019aventure qu\u2019il te faut! \ud83c\udfd4\ufe0f\nAvec plus de 1K tables, 2M de clients et 4M de commandes en 2022, les \u00e9quipes de Pictarine ne sont jamais \u00e0 court d\u2019id\u00e9es pour explorer de nouveaux horizons. \ud83d\ude80\nEn tant que Data Engineer chez Pictarine tu vas pouvoir utiliser toutes tes comp\u00e9tences SQL pour garantir la qualit\u00e9 de la data sur GCP, accompagner et challenger les besoins data.\nTu \u00e9volueras au sein de l\u2019\u00e9quipe Engineering, compos\u00e9e des p\u00f4les dev & data.\nTon r\u00f4le comprendra les aspects suivants \ud83d\udc47\ud83c\udffb\nTu es garant de la qualit\u00e9 de la data !\nEn simplifiant la structure de la data et r\u00e9duisant le nombre de tables\nEn transformant les donn\u00e9es pour les rendre facilement utilisables\nEn orchestrant le flux des donn\u00e9es de mani\u00e8re continue et automatique\nTu accompagnes et challenges les \u00e9quipes de Pictarine !\nEn co-construisant des solutions data appropri\u00e9es\nEn \u00e9levant le niveau de jeu des m\u00e9thodes data existantes\nEn faisant rayonner la data autour de bonnes pratiques et d\u2019outillages ad\u00e9quates\nProfil Recherch\u00e9\nAbout you \ud83d\udc8e\nTu as au moins 5 ans d\u2019exp\u00e9rience sur un poste similaire\nTu ma\u00eetrises le data warehouse BigQuery et son langage SQL\nTu es \u00e0 l'aise avec les services GCP\nTu as de bonnes connaissances dans la conception de mod\u00e8les de donn\u00e9es et les strat\u00e9gies d'optimisation des requ\u00eates SQL\nTu as des comp\u00e9tences en DevOps pour le d\u00e9ploiement et la gestion efficace des pipelines de donn\u00e9es\nTu as une bonne ma\u00eetrise de Python & Github\nTu es organis\u00e9, rigoureux et portes une grande attention aux d\u00e9tails\nTu es dot\u00e9 d\u2019excellentes qualit\u00e9s relationnelles, de communication et de vulgarisation\nTu as une passion pour r\u00e9soudre des probl\u00e8mes business avec la programmation\nTu es curieux de tester des nouvelles technologies\nTu es un team player et toujours \u00e0 l'aff\u00fbt de nouvelles id\u00e9es\nWork @ Pictarine\u2728\nUn environnement de travail agile, collaboratif, international et multiculturel\nDes perspectives d\u2019\u00e9volution rapides\nDes locaux tout beaux \u00e0 Lab\u00e8ge avec du mat\u00e9riel dernier cri (mais aussi des snacks \u00e0 profusion et un frigo \u00e0 boissons toujours bien rempli)\nUn apprentissage permanent : conf\u00e9rence, meet-up, Pictarine Academy, cours d\u2019anglais.\nDes events tous les mois : massage, pilates, TGIF, team building .\nUn environnement de travail flexible : horaires, politique de remote hybride.\nUn package de r\u00e9mun\u00e9ration attractif : salaire comp\u00e9titif, RTT, mutuelle & pr\u00e9voyance 100% prise en charge, int\u00e9ressement.\nDes petits + : D\u00e9veloppement de photos gratuit, subvention sport, 3 jours \u201centraide familiale\u201d, jours de cong\u00e9s en plus avec l'anciennet\u00e9... \ud83e\udd2b on ne te d\u00e9voile pas tout !\nRecruitment process \u2699\ufe0f\nTu souhaites nous rejoindre ? Viens rencontrer les gens avec qui tu vas bosser :\n1er \u00e9change pour apprendre \u00e0 se conna\u00eetre avec Marie - Engineering Manager Data (15\u2019)\nEntretien Manager avec Marie (60-90\u2019)\nTest pratique afin de nous montrer tes talents \ud83d\ude42 (3 heures)\nEntretien final avec 2 membres du Codir (90\u2019)\nWelcome aboard !\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "R",
                "Go"
            ],
            "DataBase": [
                "SQL"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [],
            "DevTools": [
                "Git"
            ],
            "Os": [],
            "DBMS": [
                "BigQuery"
            ],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [
                "DevOps"
            ],
            "FrSoftSkills": [
                "Communication"
            ],
            "EnSoftSkils": [
                "Communication"
            ]
        },
        "details": {
            "JobDetail": [
                "Hybride",
                "Remote"
            ],
            "TypeContract": [],
            "Salary": [
                "100",
                "100"
            ],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s",
                "5",
                "5",
                "5"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "title": "D\u00e9veloppeur Big Data - Spark",
        "company": "NEXTON",
        "location": "Lyon, Auvergne-Rh\u00f4ne-Alpes, France",
        "link": "https://fr.linkedin.com/jobs/view/d%C3%A9veloppeur-big-data-spark-at-nexton-3911787310?position=8&pageNum=15&refId=3Lir5Tz0viOiyHjhQOdm%2FQ%3D%3D&trackingId=gspnV%2B2uQbImXFxdlEEzMQ%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Mission (fiche m\u00e9tier)\nNEXTON recrute un\nD\u00e9veloppeur Big Data - Spark\n, en CDI, \u00e0\nLyon\n!\nQui sommes-nous ?\nNEXTON c\u2019est avant tout une entreprise qui accompagne ses clients dans leur transformation digitale. Tous les jours, nous travaillons avec des grands comptes et des pures players (SNCF, Orange, BNP PARIBAS\u2026).\nNous sommes experts du digital aussi bien sur de l\u2019accompagnement strat\u00e9gique qu\u2019op\u00e9rationnel.\nFort du succ\u00e8s, Nexton conna\u00eet aujourd\u2019hui un d\u00e9veloppement significatif, autour de ses valeurs piliers : coh\u00e9sion, confiance et performance.\nEt pour toi ? Notre politique de d\u00e9veloppement des comp\u00e9tences dynamique saura te s\u00e9duire avec un programme de suivi de carri\u00e8re sur-mesure.\nLe contexte :\nPour l'un de nos clients, dans le secteur de l'\u00e9nergie, nous sommes \u00e0 la recherche d'un d\u00e9veloppeur Big Data.\nLes missions :\nApporter une expertise\nBig Data\npour faciliter la manipulation des donn\u00e9es.\nD\u00e9finir les solutions techniques permettant le traitement massif des donn\u00e9es.\nMettre en place des\nsolutions de stockage de donn\u00e9es\n(SQL, NoSQL etc.)\nVeiller la s\u00e9curisation et la clart\u00e9 des pipelines de donn\u00e9es pour faciliter\nl'analyse\net la\ntransformation\n.\nAssurer la cr\u00e9ation, la maintenance, l'optimisation et la s\u00e9curit\u00e9 des bases de donn\u00e9es.\nAssurer le support aux \u00e9quipes de\nd\u00e9veloppement\nafin d'identifier et proposer des solutions performantes.\nProfil (fiche m\u00e9tier)\nDe formation sup\u00e9rieure, tu justifies d'une exp\u00e9rience d'au moins\n4 ans\ndans le domaine.\nTu maitrises\nSpark\n,\nPython\net\nSQL\n.\nTu es\nautonome\n,\nrigoureux\net\nforce de proposition\n.\nDe plus, tu as acquis une\ncapacit\u00e9 d'analyse\net de\nsynth\u00e8se\ngr\u00e2ce \u00e0 tes diff\u00e9rentes exp\u00e9rience.\nTu maitrises \u00e9galement les fondamentaux de\nl'agilit\u00e9\n.\nEnfin, ton\nesprit d'\u00e9quipe\nte permet de communiquer et de travailler dans les meilleures conditions.\nNEXTON c\u2019est aussi et surtout de nombreux moments de rencontres tout au long de l\u2019ann\u00e9e :\n- Des communaut\u00e9s : 2 Meet Up par mois pour partager et \u00e9changer avec des experts\n- De nombreux moments de rencontres professionnels et extra professionnels tout au long de l\u2019ann\u00e9e\n- Des moments privil\u00e9gi\u00e9s avec ton manager\nPr\u00eats \u00e0 nous rejoindre ? Rencontrons-nous !\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "R",
                "Go"
            ],
            "DataBase": [
                "SQL",
                "NoSQL"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [
                "Spark"
            ],
            "MachingLearning": [
                "Orange"
            ],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [],
            "DevTools": [
                "Git"
            ],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [
                "Big Data"
            ],
            "FrSoftSkills": [],
            "EnSoftSkils": []
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [
                "CDI"
            ],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s",
                "4",
                "4",
                "4"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "title": "Data Engineer Talend / Spark / Scala / MSBI",
        "company": "Sibylone",
        "location": "Paris, \u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/data-engineer-talend-spark-scala-msbi-at-sibylone-3918822674?position=9&pageNum=15&refId=3Lir5Tz0viOiyHjhQOdm%2FQ%3D%3D&trackingId=GQ2byteWKyn3cPr%2FE6GnrA%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "SIBYLONE\n, soci\u00e9t\u00e9 de conseil sp\u00e9cialis\u00e9e dans les syst\u00e8mes d\u2019information de synth\u00e8se et de pilotage, aide ses clients \u00e0 tirer toute la valeur de leur patrimoine de donn\u00e9es, levier strat\u00e9gique majeur de d\u00e9veloppement et de rentabilit\u00e9.\nNotre ambition : rendre les diff\u00e9rents acteurs de l\u2019entreprise autonomes dans l\u2019exploitation des donn\u00e9es, lib\u00e9rer les usages M\u00e9tier, pour qu\u2019ils soient en mesure de relever les d\u00e9fis de performance, de couverture de risque, de financement, de conqu\u00eate client, de RSE\u2026 qui s\u2019imposent \u00e0 eux.\nSp\u00e9cialistes reconnus, nos consultants s\u2019appuient pour cela sur une connaissance approfondie de l\u2019activit\u00e9 business de nos clients, en lien avec nos trois piliers que sont le M\u00e9tier, la Data et le Projet.\nSIBYLONE emploie 250 salari\u00e9s et r\u00e9alise un CA de 30m\u20ac dans la prestation de services aupr\u00e8s de grandes entreprises (8 grands comptes repr\u00e9sentant 80% du CA). SIBYLONE est une filiale du Groupe Smart 4 Engineering cr\u00e9\u00e9 en 2020. Le groupe s\u2019est constitu\u00e9 en proc\u00e9dant \u00e0 l\u2019acquisition de 12 soci\u00e9t\u00e9s en France, en Italie, en Espagne et au Portugal dans le domaine de l\u2019ing\u00e9nierie. Avec nos 3,000 ing\u00e9nieurs / consultants hautement qualifi\u00e9s, le Groupe offre ses services dans les domaines tr\u00e8s porteurs du Digital, de la Data, de l\u2019Intelligence Artificielle, de la Cybers\u00e9curit\u00e9, du Cloud.\nNous recherchons pour l\u2019un de nos clients du domaine bancaire :\nUn.e Data Engineer\nLe Data Engineer int\u00e9grera une \u00e9quipe projet Big Data dont l\u2019objectif premier est de conduire des projets ayant traits \u00e0 des probl\u00e9matiques d\u2019architecture et de conception.\nLe Data Engineer sera en charge de la maintenance, du support et de l\u2019\u00e9volution d\u2019un outil de pilotage financier d\u00e9ploy\u00e9 au sein des directions centrales du groupe et de la facturation interne. Il participera notamment \u00e0 la conception, la construction, le d\u00e9ploiement et le maintien en production d\u2019architectures Big Data, ces derni\u00e8res ayant pour objectif de permettre tant l\u2019\u00e9volution que l\u2019optimisation du syst\u00e8me d\u2019information d\u00e9cisionnel existant.\nMissions\nAnalyser, comprendre et cadrer une architecture permettant de r\u00e9pondre aux besoins m\u00e9tiers des clients\nConcevoir et mettre en place des plateformes Data en tenant compte des contraintes tant techniques que fonctionnelles\nIntervenir sur la conception et le d\u00e9ploiement d\u2019environnements\nD\u00e9veloppement de pipelines d\u2019ingestion et de pr\u00e9paration\nGestion du stockage de donn\u00e9es (syst\u00e8mes de fichiers comme HDFS, bases SQL ou NoSQL)\nAlimentation d\u2019entrep\u00f4ts de donn\u00e9es (Hive, Impala, Hbase, Snowflake, BigQuery, \u2026)\nD\u00e9velopper des applications d\u2019exploration et de manipulation de donn\u00e9es (SPARK / pySpark, Scala) afin d\u2019alimenter les flux sortants, les reporting et d\u2019exposer les donn\u00e9es\nEvoluer sur l\u2019ordonnancement des traitements de donn\u00e9es (Oozie, Bash / Shell)\nAssurer le maintien en conditions op\u00e9rationnelles des plateformes produites\nEtablir, formaliser, et promouvoir les best practices\nPourquoi pas vous ?\nProfil recherch\u00e9 :\nDe formation sup\u00e9rieure ing\u00e9nieur en Informatique, vous justifiez d\u2019une premi\u00e8re exp\u00e9rience r\u00e9ussie en data engineering acquise dans un contexte projet au sein d\u2019une start-up, d\u2019un pure player, ou d\u2019une ESN.\nVous disposez d\u2019une bonne maitrise des langages propres aux environnements Big Data tels que :\nHadoop\nTalend (Data Integration, Big Data)\nLes solutions Cloud (Azure, AWS, GPC)\nSpark, Scala, Python, Unix, SQL\nMicrosoft Power BI\nUne connaissance de : Docker, ELK, Kubernetes, Cassandra, Kafka, \u2026 serait un plus, de m\u00eame que des fondamentaux DevOps (CI / CD).\nVous avez d\u00e9j\u00e0 \u00e9volu\u00e9 dans un contexte projet agile ou scrum et faites preuve de flexibilit\u00e9, d\u2019adaptabilit\u00e9 et savez \u00eatre force de proposition.\nAu-del\u00e0 de vos comp\u00e9tences techniques, vous \u00eates curieux, autonome, organis\u00e9, dot\u00e9 d\u2019un bon sens relationnel et d\u2019un esprit de synth\u00e8se.\nVous vous reconnaissez dans la description du poste ?\nVous souhaitez travailler dans un environnement stimulant et dynamique ?\nVous souhaitez rejoindre une soci\u00e9t\u00e9 ambitieuse ?\nVous souhaitez comprendre l\u2019origine de Sibylone ?\nVenez-nous rencontrer :\nLa Team Talent Acquisition sera ravie d'\u00e9changer avec vous !\nCe poste est ouvert aux personnes en situation de handicap.\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "Scala",
                "R",
                "Bash"
            ],
            "DataBase": [
                "SQL",
                "NoSQL",
                "Cassandra",
                "HBase"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [
                "Hadoop",
                "Spark"
            ],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [
                "Power BI"
            ],
            "Statistics": [],
            "CloudComputing": [
                "AWS",
                "Azure"
            ],
            "DevTools": [
                "Git",
                "Docker"
            ],
            "Os": [],
            "DBMS": [
                "Snowflake",
                "Snowflake",
                "BigQuery"
            ],
            "SoftBigDataProcessing": [
                "HBase"
            ],
            "Automation": [
                "Kubernetes"
            ],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [
                "Docker",
                "Kubernetes"
            ],
            "Collaboration": [],
            "Other": [
                "DevOps",
                "Big Data",
                "Cloud",
                "CI / CD"
            ],
            "FrSoftSkills": [
                "Adaptabilit\u00e9",
                "Flexibilit\u00e9"
            ],
            "EnSoftSkils": []
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "title": "Data Engineer H/F",
        "company": "Amiltone",
        "location": "Lille, Hauts-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/data-engineer-h-f-at-amiltone-3846492584?position=10&pageNum=15&refId=3Lir5Tz0viOiyHjhQOdm%2FQ%3D%3D&trackingId=nJmMAJWbmBew3htigNQ6mA%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Qui sommes-nous ?\nNous sommes passionn\u00e9s par les nouvelles technologies, et vous ?\nRejoindre Amiltone, c\u2019est int\u00e9grer des \u00e9quipes dynamiques et soud\u00e9es dans le cadre de projets novateurs et ambitieux. Nous relevons les challenges techniques de nos clients et les accompagnons dans leur transformation digitale.\nPourquoi choisir Amiltone\u202f?\nAmiltone, plus qu\u2019une entreprise, un \u00e9tat d\u2019esprit !\nNotre objectif ? Votre \u00e9panouissement professionnel !\nNous Avons \u00e0 C\u0153ur De\nVous accompagner au mieux au travers d\u2019un suivi personnalis\u00e9\nVous faire monter en comp\u00e9tences en vous proposant des formations tout au long de votre carri\u00e8re\nComprendre vos besoins et respecter nos engagements\nVous proposer des missions de qualit\u00e9 avec des technologies innovantes\nCultiver votre potentiel gr\u00e2ce \u00e0 notre programme de d\u00e9veloppement personnel Addvise\nVotre bien-\u00eatre passe aussi par des activit\u00e9s extraprofessionnelles, c\u2019est pourquoi nous vous proposons des s\u00e9ances sportives anim\u00e9es par nos coachs, soir\u00e9es pour se retrouver et animations (\u00e0 l'agence ou en visio), Gaming nights\u2026\nLes Missions D'un Amiltonien\nEn tant que Data Engineer\n(H/F)\n, vous serez en charge des missions suivantes :\n\u2013 Concevoir et d\u00e9velopper les futures fonctionnalit\u00e9s de la plateforme Big Data sous Google Cloud Platform.\n\u2013 Concevoir les flux d'alimentation et les tables (structure de donn\u00e9e).\n\u2013 Automatiser et industrialiser les flux.\n\u2013 Assurer le run applicatif, le cas \u00e9ch\u00e9ant.\nLa Stack Technique\nMa\u00eetrise des langages suivants : SQL, Talend, BigQuery\nConnaissances de Google (GCP)\nNotion de programmation fonctionnelle\nLe Profil D\u2019un Amiltonien\nDipl\u00f4m\u00e9 Bac+4/5 (Ecole d'ing\u00e9nieur/Master), vous disposez de 2 ann\u00e9es d'exp\u00e9rience dans le d\u00e9veloppement de data.\nToujours sur le qui-vive des nouveaut\u00e9s technologiques, vous \u00eates force de proposition sur des technos, des outils ou des process qui permettent d'am\u00e9liorer la qualit\u00e9 du code et la stabilit\u00e9 de nos applications.\nOutre vos comp\u00e9tences techniques, nous nous int\u00e9ressons \u00e9galement \u00e0 votre potentiel et votre motivation.\nNos postes sont ouverts aux personnes en situation de handicap.\nPostuler\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "R",
                "Go"
            ],
            "DataBase": [
                "SQL"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [],
            "MachingLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [
                "Google Cloud Platform"
            ],
            "DevTools": [
                "Git"
            ],
            "Os": [],
            "DBMS": [
                "BigQuery"
            ],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [
                "Big Data",
                "Cloud"
            ],
            "FrSoftSkills": [],
            "EnSoftSkils": []
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    }
]