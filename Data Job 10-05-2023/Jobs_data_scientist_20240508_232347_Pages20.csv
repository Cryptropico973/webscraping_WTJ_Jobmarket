srouce,title,company,location,link,description,skills,details
LinkedIn,Data Scientist,"Unreal Staffing, Inc","Paris, Île-de-France, France",https://fr.linkedin.com/jobs/view/data-scientist-at-unreal-staffing-inc-3913911173?position=2&pageNum=0&refId=EGCcUYgUshGnwQGGB%2BWgjg%3D%3D&trackingId=b8dp62KUpDcMYlHJdBr4Mg%3D%3D&trk=public_jobs_jserp-result_search-card,"About Us
The fashion industry contributes significantly to global greenhouse gas emissions. To address this, we developed a Carbon Management Platform tailored for the textile and fashion industry. We automate life-cycle assessment to help brands understand and reduce their environmental footprint.
Data At Our Company
Our Data team manages customer data parsing and analytics. We clean and normalize customer data for accurate analysis and provide analytics on product-level environmental impacts.
Requirements
What You'll Be Working With
Interesting data: Our data describes physical objects, such as shoes, t-shirts, and packaging boxes, enabling real insights into the environmental impact of products
Unique opportunity: Apply your data science skills to reduce the environmental footprint of fashion companies
What We're Looking For
Strong communication skills
Experience with heterogeneous data and basic NLP techniques
Proficiency in Python and SQL
Basic software engineering skills
Benefits
Remote work in Europe
Coworking space allowance up to €300/month
Modern amenities including MacBook, headset, ChatGPT subscription, GitHub Copilot, etc
100% health insurance coverage with Alan at the best coverage level
Option to work from our office in Paris
Work retreats organized 3 times a year
Transparent compensation package with salary range €60k - €80k and significant equity
Opportunities for promotion based on performance and impact on the company
Strong belief in open-source software and contribution to the community
Show more
Show less","{'ProgLanguage': ['Python', 'R'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git'], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': [], 'FrSoftSkills': ['Communication'], 'EnSoftSkils': ['Communication']}","{'JobDetail': ['Remote'], 'TypeContract': [], 'Salary': ['60k', '60k'], 'Level': [], 'Experience': ['a', 'n', 's']}"
LinkedIn,Data Scientist (F/M),VINCI Airports,"Nanterre, Île-de-France, France",https://fr.linkedin.com/jobs/view/data-scientist-f-m-at-vinci-airports-3888479165?position=3&pageNum=0&refId=EGCcUYgUshGnwQGGB%2BWgjg%3D%3D&trackingId=%2B7dnXJx9uGyCKqHmokVW%2Bw%3D%3D&trk=public_jobs_jserp-result_search-card,"Premier opérateur aéroportuaire privé au monde,
VINCI Airports
gère plus de 70 aéroports dans 13 pays en Europe, en Asie et sur le continent américain. Grâce à son expertise d’intégrateur global, VINCI Airports développe, finance, construit et exploite les aéroports en apportant sa capacité d’investissement et son savoir-faire dans l’optimisation de la performance opérationnelle, la modernisation des infrastructures et la conduite de leur transition environnementale.
Nous recherchons actuellement
un(e) Data Scientist (F/M)
en CDI.
Rattaché(e) au Département Data de la Direction financière de VINCI Airports, vous participerez, en coordination avec les équipes métiers et appuyé(e) par l’équipe d’ingénieurs Data (siège VINCI Airports et Pays), à la mise en œuvre du projet « SMART DATA HUB », un projet stratégique et passionnant, qui a pour vocation de fournir à l’ensemble des aéroports du groupe la capacité à mieux piloter la performance de l’activité autour de la Data.
Pour ce faire vous serez amené(e) à développer des solutions avancées en Data Science, Modèles de Machine Learning, avec un accent particulier sur le traitement du langage naturel (NLP) dans le département Data de VINCI Airports pour les besoins de digitalisation et d’amélioration des processus de VINCI Airports.
Missions :
Modélisation et prévision : Concevoir, développer et mettre en œuvre des modèles statistiques et algorithmiques. Utiliser des méthodes d'apprentissage automatique et d'intelligence artificielle (IA) pour créer des modèles prédictifs.
Analyse des données : Collecter, nettoyer et préparer les données brutes en vue de leur analyse. Utiliser des techniques de visualisation et des outils statistiques pour explorer et comprendre les ensembles de données.
Exploitation des données : Identifier les opportunités d'amélioration des processus et des performances en utilisant les données disponibles. Travailler en étroite collaboration avec les équipes opérationnelles pour comprendre leurs besoins et proposer des solutions basées sur les données.
Communication des résultats : Présenter les résultats de l'analyse de manière claire et compréhensible à des publics non techniques. Collaborer avec des équipes multidisciplinaires pour fournir des recommandations basées sur les données pour la prise de décision stratégique.
Travailler sur des projets impliquant des modèles de langage comme GPT développés par Open AI ou Google (ou autres nouvelles solutions sur le marché).
Participer à des formations et des ateliers avec les analystes de VINCI Airports pour développer leurs compétences techniques et méthodologiques grâce aux solutions Data science/NLP.
L’ensemble de ces actions seront à entreprendre sur l’ensemble des domaines métiers de VINCI Airports : Trafic, commercial, opérations...
Effectuer une veille constante sur les dernières avancées en Data Science, LLM et NLP pour proposer des solutions innovantes et les intégrer aux modèles développés par l’équipe Data.
Le profil que nous recherchons à ce poste :
Diplôme universitaire (Bac+5) en statistiques, mathématiques, informatique, science des données, Intelligence Artificielle ou un domaine connexe.
Expérience pratique dans l'analyse de données et l'utilisation d'outils d'analyse tels que Python, R, SAS, SQL,…
Bonne connaissance des techniques d'apprentissage automatique (machine learning), des algorithmes statistiques et de l'analyse prédictive.
Connaissance approfondie des concepts de Machine Learning et des bibliothèques telles que TensorFlow, PyTorch, Scikit-Learn.
Motivation pour la recherche et la résolution de problèmes complexes.
Intérêt et expérience en traitement du langage naturel (NLP), y compris la familiarité avec les modèles de langage comme GPT.
Capacité à travailler de manière autonome et à gérer efficacement les projets, tout en respectant les délais impartis.
Compétences en communication orale et écrite pour présenter des résultats complexes de manière claire et concise.
Curiosité intellectuelle et passion pour l'exploration des données afin de découvrir des informations cachées et de générer des idées novatrices.
Travail en équipe.
Vous êtes capable de converser en Anglais.
Show more
Show less","{'ProgLanguage': ['Python', 'R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': ['Scikit-Learn', 'TensorFlow', 'PyTorch'], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': ['Statistiques'], 'CloudComputing': [], 'DevTools': ['Git'], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Machine Learning', 'Statistiques'], 'FrSoftSkills': ['Communication', 'Résolution de problèmes', 'Collaboration'], 'EnSoftSkils': ['Communication', 'Collaboration']}","{'JobDetail': [], 'TypeContract': ['CDI'], 'Salary': [], 'Level': ['Bac+5'], 'Experience': ['a', 'n', 's']}"
LinkedIn,Data Scientist AI,Cephalgo,France,https://fr.linkedin.com/jobs/view/data-scientist-ai-at-cephalgo-3817203204?position=4&pageNum=0&refId=EGCcUYgUshGnwQGGB%2BWgjg%3D%3D&trackingId=a8LjCKmMx3Wpf%2FidiQ7Now%3D%3D&trk=public_jobs_jserp-result_search-card,"The ideal candidate's favorite words are learning, data, scale, and agility. You will leverage your strong collaboration skills and ability to extract valuable insights from highly complex data sets to ask the right questions and find the right answers.
Responsibilities
Collect, process, and clean data from diverse sources to prepare it for analysis, ensuring consistency and reliability
Analyze raw data: assessing quality, cleansing, structuring for downstream processing and applying machine learning (ML) and deep learning (DL) techniques
A focus on quantitative analytics and data modeling.
Design accurate and scalable prediction algorithms
Ensuring scalable ML/DL pipeline construction
Implementing data storage solutions that optimize for volume, velocity, and variety of EEG data
Collaborate with the team to bring analytical prototypes to production
Stay up-to-date with the latest technologies and trends in data science and machine learning
Qualifications
Master's degree or equivalent experience in Computer Science
At least 2 years' of experience in DL, quantitative analytics and data modeling
A strong statistical and programming background
Experienced in MLOP pipeline construction and big data technologies like Spark, MLFlow, Snowflake, Hadoop for hosting the data
Deep understanding of predictive modeling, machine-learning, clustering and classification techniques, and algorithms
Fluency in a programming language (Python, C,C++, Java, SQL)
Excellent problem-solving skills and ability to work independently or as part of a team
Experienced in working interdisciplinary tasks
We Offer
Competitive salary and benefits package
A collaborative work environment with a supportive team
Opportunities for professional growth and development
Access to the latest tools and technologies.
Flexible working hours and remote work options
CEPHALGO focuses on introducing technological innovations to assist medical professionals to provide better mental health care. Located in Strasbourg, extended beyond Europe, CEPHALGO’s patient monitoring technique using EEG and AI has been applied in psychiatry across Europe. Further information can be found at https://cephalgo.com.
Show more
Show less","{'ProgLanguage': ['Python', 'Java', 'C++', 'Scala', 'R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': ['Hadoop', 'Spark'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'DBMS': ['Snowflake', 'Snowflake'], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Big Data', 'ML', 'Machine Learning'], 'FrSoftSkills': ['Collaboration'], 'EnSoftSkils': ['Collaboration']}","{'JobDetail': ['Remote'], 'TypeContract': [], 'Salary': ['Salary', 'Package'], 'Level': [], 'Experience': ['a', 'n', 's']}"
LinkedIn,Data Scientist IA Gen,eXalt Value,"Île-de-France, France",https://fr.linkedin.com/jobs/view/data-scientist-ia-gen-at-exalt-value-3897781437?position=5&pageNum=0&refId=EGCcUYgUshGnwQGGB%2BWgjg%3D%3D&trackingId=UM27Hzftn9Wm7ZgAxIx6TA%3D%3D&trk=public_jobs_jserp-result_search-card,"eXalt
est un cabinet de conseil IT
Pure player Data
& IA basé à Paris (1er arrondissement).
Notre offre s’articule autour de 4 piliers réunis au sein d’une même communauté pour un accompagnement à 360° alliant une expertise technique et méthodologique à une approche conseil métier:
Data Gouvernance & Project
Data Engineering & Big Data
Data Performance & Analytics
Data Science & IA
Filiale du groupe eXalt créé en 2018,
regroupant plus de
950 collaborateurs en France
(Paris, Lyon, Bordeaux, Lille, Nantes, Marseille)
et à l’international
(Colombie, Etats-Unis, Espagne, Belgique),
eXalt Value
démontre une
expertise approfondie
dans le domaine de la Data & IA et conseille les entreprises dans le déploiement de leurs stratégies data-driven.
Bénéficiant de la renommée et des relations client du groupe eXalt
(1er dans la catégorie Conseil & Audit au classement des Champions de la Croissance 2024), eXalt Value
est en pleine croissance et regroupe aujourd’hui une communauté d’expertise de plus de 60 collaborateurs en région parisienne.
Nos consultants interviennent sur d
es projets d’envergure stimulants
dans divers secteurs d’activité, Banque & Assurance, Médias, Transports, Retail, Tourisme, etc.
Nous recherchons un
Data Scientist IA Gen H/F
pour rejoindre notre communauté sur le
pilier Data Science & IA.
Vos missions:
Identifier les besoins spécifiques des différentes équipes, à travers des ateliers d'idéation, et proposer des solutions algorithmiques innovantes et adaptées à chaque situation.
Analyser les données disponibles pour sélectionner les modèles d'IA les plus pertinents face aux besoins identifiés, en tenant compte des particularités de chaque cas d'usage.
Développer, tester et déployer les algorithmes des modèles d'apprentissage automatique et des algorithmes avancés pour résoudre des problèmes complexes grâce à des méthodes statistiques, mathématiques et de machine learning.
Collaborer avec les Data Engineer afin d’intégrer les solutions IA dans les produits et les applications existants.
Exploiter les dernières avancées en matière d'IA, notamment le Deep Learning, le Reinforcement Learning, le Traitement du Langage Naturel (NLP), la vision par ordinateur, etc., pour créer des solutions innovantes.
Conseiller les clients tout au long du cycle de vie des projets sur les solutions techniques les plus adaptées à leurs environnements.
Les Prérequis :
Titulaire d'un Bac+5, idéalement Ecole d'Ingénieur
Compréhension des enjeux business autours de
l’exploitation des données et le déploiement des solutions IA
Maîtrise du
Machine Learning et du Deep Learning,
y compris des principaux frameworks (TensorFlow, PyTorch, Scikit-learn, Pandas, NumPy,) et des méthodes statistiques.
Solides connaissances de
Python
(Java, Spark, Scala sont un plus).
Aisance avec l'ensemble du cycle de vie de développement et de déploiement de modèles d'IA (MLOps).
Expérience de travail en
méthode Agile
Capacité à travailler de manière autonome et en équipe.
Excellentes compétences en communication et présentation.
Maîtrise de l’anglais (oral & écrit dans un contexte international professionnel).
Votre environnement eXalté:
Rejoindre
eXalt Value
, c’est également :
Un Lab IA
au sein duquel vous pourrez expérimenter les divers outils et techniques, autour de use cases internes et externes.
Un environnement de travail Collaboratif
favorisant les initiatives et projets transverses à la Practice Data & IA (Data Hub, etc ;)
Un collectif de consultants passionnés,
s’intéressant aux tendances innovantes du secteur
Une Practice de proximité,
privilégiant la montée en compétence de ses collaborateurs (formations, coachings, mentorats, etc.)
Un suivi individualisé et de proximité
par un.e Data Sales Manager référent du compte client, un.e Chargé.e RH et un.e Practice Manager
Une équipe sympa et dynamique,
qui privilégie des moments de partage (séminaires, eXaltemps, meet-ups, déjeuners d’équipe, etc.)
Notre processus de recrutement :
Un entretien RH avec Estelle,
à la suite duquel vous saurez tout (ou presque) d’eXalt Value,
Un entretien technique avec un Manager IA assorti d’un échange technique,
lors duquel vous aurez l’occasion de démontrer vos talents et de challenger vos acquis.
Un entretien final avec la Directrice Associée ou le Directeur Opérationnel,
pour finir de vous convaincre de nous rejoindre 😊
Show more
Show less","{'ProgLanguage': ['Python', 'Java', 'Scala', 'R', 'Go'], 'DataBase': [], 'DataAnalytics': ['Pandas', 'NumPy', 'R'], 'BigData': ['Spark'], 'MachingLearning': ['Scikit-Learn', 'TensorFlow', 'PyTorch'], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': ['Statistiques'], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Big Data', 'ML', 'Machine Learning', 'Statistiques'], 'FrSoftSkills': ['Communication'], 'EnSoftSkils': ['Communication', 'Initiative']}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': ['Bac+5'], 'Experience': ['a', 'n', 's']}"
LinkedIn,Data Scientist - Payment Success,Checkout.com,"Paris, Île-de-France, France",https://fr.linkedin.com/jobs/view/data-scientist-payment-success-at-checkout-com-3903448233?position=6&pageNum=0&refId=EGCcUYgUshGnwQGGB%2BWgjg%3D%3D&trackingId=Hb2W42IAFVrE0Fn6NSTnyQ%3D%3D&trk=public_jobs_jserp-result_search-card,"Company Description
Checkout.com is one of the most exciting fintechs in the world. Our mission is to enable businesses and their communities to thrive in the digital economy. We’re the strategic payments partner for some of the best known fast-moving brands globally such as Wise, Hut Group, Sony Electronics, Homebase, Henkel, Klarna and many others. Purpose-built with performance and scalability in mind, our flexible cloud-based payments platform helps global enterprises launch new products and create experiences customers love. And it's not just what we build that makes us different. It's how.
We empower passionate problem-solvers to collaborate, innovate and do their best work. That’s why we’re on the Forbes Cloud 100 list and a Great Place to Work accredited company. And we’re just getting started. We’re building diverse and inclusive teams around the world — because that’s how we create even better experiences for our merchants and our partners. And we need your help. Join us to build the digital economy of tomorrow.
Job Description
About the opportunity:
We empower businesses in the digital economy, and we know that every payment counts. Our Payment Performance team’s mission is to manage and optimise merchants’ payment flow, to achieve optimal conversion, compliance and cost.
Checkout.com is looking for a data scientist to automate research and investigations tailored for our Tier-1 merchants. This role encompasses the development of automation tools for monitoring, including dashboards and auto-generated presentations, as well as in-depth diagnostic solutions powered by machine learning and recommendation engines.
You will also work closely with Payment Performance Managers to ensure the delivery of a high level of service to our key merchants, underpinned by data-driven expertise. The ideal candidate must be a driven technologist with an affinity for problem solving and creating new tools.
What you'll be doing:
Conduct deep-dive exploratory data analysis to uncover insights and anomalies
Develop cutting-edge automation tools aimed at monitoring and optimising merchants’ performance
Create intuitive, real-time dashboards and reports to provide merchant performance visibility, enabling data-driven decision-making
Propose enhancements of existing processes/tools by utilising statistical and machine learning techniques
Effectively communicate research findings to both technical and non-technical stakeholders through reports and presentations
Qualifications
2+ years experience as data scientist, working with large and diversified data sets
Bachelor’s degree, preferably in Mathematics / Statistics / Computer Science / Engineering, Finance or equivalent
SQL/ Python knowledge to extract & analyse data from our Data Warehouse
Experience with Git & Spark, Databricks, Retool, API
Ability to find creative and effective solutions for business problems
Flexible, adaptable and has a willingness to learn
Payments or Fintech experience is a plus
If you don't meet all the requirements but think you might still be right for the role, please apply anyway. We're always keen to speak to people who connect with our mission and values
If possible, please submit CVs in English.
Additional Information
Apply without meeting all requirements statement
If you don't meet all the requirements but think you might still be right for the role, please apply anyway. We're always keen to speak to people who connect with our mission and values.
We believe in equal opportunities
We work as one team. Wherever you come from. However you identify. And whichever payment method you use.
Our clients come from all over the world — and so do we. Hiring hard-working people and giving them a community to thrive in is critical to our success.
When you join our team, we’ll empower you to unlock your potential so you can do your best work. We’d love to hear how you think you could make a difference here with us.
We want to set you up for success and make our process as accessible as possible. So let us know in your application, or tell your recruiter directly, if you need anything to make your experience or working environment more comfortable. We’ll be happy to support you.
Take a peek inside life at Checkout.com via
Our Culture video https://youtu.be/BEwnpHuadSw
Our careers page https://www.checkout.com/careers
Our LinkedIn Life pages bit.ly/3OaoN1U
Our Instagram https://www.instagram.com/checkout_com/
Apply Without Meeting All Requirements Statement
If you don't meet all the requirements but think you might still be right for the role, please apply anyway. We're always keen to speak to people who connect with our mission and values.
We believe in equal opportunities
We work as one team. Wherever you come from. However you identify. And whichever payment method you use.
Our clients come from all over the world — and so do we. Hiring hard-working people and giving them a community to thrive in is critical to our success.
When you join our team, we’ll empower you to unlock your potential so you can do your best work. We’d love to hear how you think you could make a difference here with us.
We want to set you up for success and make our process as accessible as possible. So let us know in your application, or tell your recruiter directly, if you need anything to make your experience or working environment more comfortable. We’ll be happy to support you.
Take a peek inside life at Checkout.com via
Our Culture video https://youtu.be/BEwnpHuadSw
Our careers page https://www.checkout.com/careers
Our LinkedIn Life pages bit.ly/3OaoN1U
Our Instagram https://www.instagram.com/checkout_com/
Show more
Show less","{'ProgLanguage': ['Python', 'Scala', 'R'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': ['Spark', 'Databricks'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': ['Statistics'], 'CloudComputing': [], 'DevTools': ['Git'], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': ['Teams'], 'Other': ['Machine Learning', 'Cloud'], 'FrSoftSkills': [], 'EnSoftSkils': ['Problem Solving']}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's']}"
LinkedIn,APPRENTI.E DATA SCIENTIST,Akademija Oxford,"Val-De-Marne, Île-de-France, France",https://fr.linkedin.com/jobs/view/apprenti-e-data-scientist-at-akademija-oxford-3917870308?position=7&pageNum=0&refId=EGCcUYgUshGnwQGGB%2BWgjg%3D%3D&trackingId=ud3qOaXRCUmekjhAemQzEA%3D%3D&trk=public_jobs_jserp-result_search-card,"Une des entreprises leader sur le marché de la santé, située dans le Val-De-Marne, recherche un.e Apprenti.e Data Scientist dans le cadre d’un contrat d’apprentissage et pour un démarrage en Octobre 2021.
Show more
Show less","{'ProgLanguage': ['R'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': [], 'FrSoftSkills': [], 'EnSoftSkils': []}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's']}"
LinkedIn,Data Scientist,Keley Consulting,Greater Paris Metropolitan Region,https://fr.linkedin.com/jobs/view/data-scientist-at-keley-consulting-3908861590?position=8&pageNum=0&refId=EGCcUYgUshGnwQGGB%2BWgjg%3D%3D&trackingId=I4lzorkLRhl%2F8tNlJ5FOew%3D%3D&trk=public_jobs_jserp-result_search-card,"Data Scientist F/H
Description de l'offre d'emploi
Au sein de la practice data, vous accompagnerez nos clients dans la gestion, l’analyse et l’exploitation de leur données notamment grâce au développement de modèles IA et la mise en production de ceux-ci.
Responsabilités
Vous interviendrez dans des secteurs variés sur des problématiques telles que :
Evaluer les solutions technologiques liées à la data en effectuant des benchmarks
Collecter, traiter et analyser des données volumineuses
Communiquer efficacement les résultats des analyses
Créer de la valeur à partir des données en utilisant l’intelligence artificielle et la Data Science
Travailler en étroite collaboration avec les métiers afin de comprendre leurs besoins et les impliquer dans le développement des outils IA
Déployer les outils développés en environnement de prod (MLOps)
A titre d’exemple, nous avons récemment mené les missions suivantes :
Développement d’outils d’optimisation des revenus pour le compte d’une compagnie aérienne
Etude de l’impact du traitement de plaintes sur la customer lifetime value
Industrialisation de proof-of-concepts (ML Ops)
Développement de GPTMaker, un outil de création de chatbot s’appuyant sur des LLM
Profil recherché
Diplôme Bac+5 type école d’ingénieur ou université en Data Science / Statistiques
Expérience de 2 à 5 ans en Data, avec au moins 1 an en tant que Data Scientist / Engineer
Maîtrise des méthodes statistiques et leurs applications opérationnelles, ainsi que Python/Spark
Forte capacité d’organisation, d’analyse, d’écoute et de communication tout en étant force de conviction
Anglais courant
Qualifications supplémentaires (atouts) :
Expérience avec les outils du cloud (GCP, Azure, AWS …)
Expérience dans le NLP (natural language processing)
Pourquoi rejoindre Keley ?
Keley est un cabinet de conseil à taille humaine.
Accélérateur de projet, nous accompagnons nos clients sur des programmes de transformation digitale & Data en apportant sens et performance. Autour de méthodologies produits issues du design et orientées résultat, nous cocréons avec nos clients en les accompagnant dans toutes les étapes de leurs projets, jusqu’à l’autonomie.
Parce que les Humains sont au cœur de la transformation digitale des entreprises, celle-ci est aussi culturelle : nous alignons stratégie produit, culture métiers et modèles opérationnels pour concevoir avec nos clients des solutions qui leur ressemblent et qui font le succès de leurs projets.
Nos valeurs
Passionnés par notre métier, nous sommes des consultants en transformation digitale avec un sens aigu de l’engagement et du partage.
Dans un esprit coopératif et chaleureux, chaque collaborateur pourra trouver sa place, évoluer au cœur de nos métiers et atteindre ses objectifs grâce à des parcours de carrière évolutifs, clairs et transparents.
Nous croyons en la valeur de la diversité et de l'inclusion et encourageons les candidats de tous horizons à postuler.
Keley vous propose une carrière passionnante dans un environnement stimulant, en vous permettant de travailler avec des grands comptes et sur des missions variées.
Pour vous offrir le meilleur environnement de travail possible, nous vous proposons :
Un parcours de carrière clair et partagé pour évoluer rapidement au sein du cabinet
Une politique de rémunération transparente et équitable
Une charte de télétravail
Des bureaux au cœur de Paris dans le 8ème arrondissement
Des mentors et des buddys à l’écoute
Des évènements de team building réguliers
Une direction et un management toujours disponibles pour échanger (organisation flat)
Un programme de formation adapté à vos besoins et incluant des formations externes certifiantes
Des méthodes et outils de partage de connaissance pour vous nourrir mais aussi vous offrir une tribune : conférences internes hebdomadaires, articles, livres blancs, enquêtes et contenus vidéo
Un MacBook car on aime les belles choses (surtout quand elles marchent bien)
Une carte tickets restaurants
Une prise en charge de la mutuelle à 100%
Une prime de vacances
Show more
Show less","{'ProgLanguage': ['Python', 'R'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': ['Spark'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': ['Statistiques'], 'CloudComputing': ['AWS', 'Azure'], 'DevTools': ['Git'], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['ML', 'Statistiques', 'Cloud'], 'FrSoftSkills': ['Communication', 'Collaboration', 'Organisation'], 'EnSoftSkils': ['Communication', 'Collaboration']}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': ['Bac+5'], 'Experience': ['a', 'n', 's', '5', '5', '5']}"
LinkedIn,Data Scientist (M/W),Mines Paris,"Valbonne, Provence-Alpes-Côte d'Azur, France",https://fr.linkedin.com/jobs/view/data-scientist-m-w-at-mines-paris-3908686193?position=9&pageNum=0&refId=EGCcUYgUshGnwQGGB%2BWgjg%3D%3D&trackingId=%2FvXoxGYJ%2B1nc%2Fn%2B0%2BkVQgg%3D%3D&trk=public_jobs_jserp-result_search-card,"À propos de nous
Mines Paris est une des plus prestigieuses écoles d'ingénieurs en France. Mines Paris est un établissement public qui forme des ingénieurs généralistes via une expérience pédagogique innovante et pluridisciplinaire (sciences de l'ingénieur et sciences humaines et sociales). Son appartenance à l'Université PSL, qui se positionne dans le top 50 des classements internationaux, constitue une véritable opportunité d'enrichissement des parcours.
Mission
Your Environment
As part of the scientific program of The Transition Institute 1.5 (TTI.5), which focuses on the conditions for the emergence of a transition to a low-carbon planet, taking into account technical, social, economic, political and geopolitical issues, Mines Paris - PSL has an opening for a Data Scientist.
Insofar as these issues may represent obstacles to the transition, it is essential to understand their fundamentals and decipher the mechanisms that drive them. The TTI.5 scientific program has been designed to harmonize, enhance and extend the various research projects already on offer at Mines Paris - PSL. It is also intended to provide new impetus in areas that have been little addressed until now, but which are nonetheless essential to steering the transition, or to filling gaps such as that of a complete vision of the distribution of resources worldwide.
Your Challenges And Responsabilities
In order to tackle the various transition strategies, it is essential to have a picture of the production of the various raw materials needed for today's and tomorrow's world. At the same time, the exploitation and circulation of different resources can be strongly impacted by geopolitical conditions and times of tension and conflict.
The aim of this project, with its high methodological stakes, is to develop and couple:
global resource mapping for two critical ""identifiable"" resources (lithium and cobalt)
a mapping of armed tensions (conflicts, installation of military bases, etc.).
To achieve this, we will need to develop a tool for extracting data from a very large mass of information, to be identified, in a changing context that will need to be taken into account for the tool's sustainability.
The Development Prospects For This Work Could Include
a double cartography animated over time ;
the enrichment of military base and tension indicators, with an equal focus on cases of local armed non-tension around the resource
a scalable database that can be continuously updated
a tool that can be replicated for other resources in a rapidly changing world
Profil
Let's talk about you !...
The position is aimed at an engineer / master data scientist with a degree from a university or Grande Ecole. Additional skills in GIS would be a plus. He/she may receive in-house training on mining resource issues.
The candidate will be strongly encouraged to participate in TTI.5 activities, and may also take part in those of the referral centers. He/she must have demonstrated good teamwork skills.
Fluency in spoken and written English is imperative.
Knowledge And Skills
The main skills required for this post are :
Mastery of algorithms and programming languages (ability to write efficient, scalable code)
Mastery of data management language and databases (ability to find, collect and analyze large volumes of data)
Mastery of data visualization tools
Soft Skills
Self-motivated
Spirit of initiative
Sense of teamwork
creativity
Flexibility
Communication and teaching skills
Analytical skills
Thoroughness
…And about us ! Working at Mines Paris also means :
Joining a prestigious institution with a rich history
Playing a part in the digital transition and the transition to carbon neutrality to tackle the climate emergency
Belonging to PSL University, ranked 41st in the Academic Ranking of World Universities
Join a dynamic, multidisciplinary team!
A pleasant living environment in a pine forest, at the heart of the 1st technology cluster on the Côte d'Azur and 1st technology park in Europe!
Référence de l'offre : 6jpx490r88
Show more
Show less","{'ProgLanguage': ['Scala', 'R', 'Go'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git'], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': [], 'FrSoftSkills': ['Communication'], 'EnSoftSkils': ['Communication', 'Teamwork', 'Creativity', 'Flexibility', 'Initiative']}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's']}"
LinkedIn,Data Scientist H/F,Valeuriad,"Nantes, Pays de la Loire, France",https://fr.linkedin.com/jobs/view/data-scientist-h-f-at-valeuriad-3741220588?position=10&pageNum=0&refId=EGCcUYgUshGnwQGGB%2BWgjg%3D%3D&trackingId=0NzlaazCIgt%2Fyy7fA73seQ%3D%3D&trk=public_jobs_jserp-result_search-card,"Rejoins la
Team Data
créée par
Nicolas Greffard,
Docteur en Intelligence Artificielle
, déjà composée de
20
Data Scientists
et
Data Engineer
talentueux 😍
Nous recherchons de
nouvelles pépites
pour rejoindre notre équipe de choc et répondre aux
multiples problématiques Data science
de nos
clients nantais
mais également
contribuer à nos projets de R&D
et travailler sur des
conférences incroyables
(DevFest, Salon de la Data)
🤩
Ta future mission si tu l'acceptes
😉
Nous te proposons d'intervenir au sein de nos
grandes DSI clientes
, sur des sujets de
collecte
, d
'alimentation
et de
transformation de données
autour de l’intelligence artificielle.
Le job en détail
🤩
Toutes Les Missions Ne Sont Pas Identiques, Mais Voici Des Exemples De Choses Sur Lesquelles Nos Data Scientists Sont Intervenus
Échange avec les architectes, les PO et PPO, les développeurs et la gouvernance de données ;
Deep learning (RNN, LSTM, CNN, DQN) et Machine learning ;
Analyse de données : statistiques descriptives et exploratoires, Data Mining ;
Traitement d’images (pattern matching, extraction de descripteurs, tf-idf et classification, etc..) et traitement de texte.
Traitement du langage / Text-Mining (Word2Vec, BoW, BERT, etc..) ;
Restitutiondes résultats : dataviz, indicateurs, dashboards (tableaux de bord), optimisation d’application streamlit ;
MLOps : pour pour amener l'IA jusqu'à la prod ;
Amélioration de modèles : validation croisée, sélection de descripteurs, métriques d’erreurs ;
Assurer la veille technologique sur les algorithmes et outils de Data Science.
Langages : Principalement du Python, souvent du SQL et parfois du R ou même du SAS ;
Framework : ceux qui reviennent sans arrêt : Tensorflow, PyTorch, Huggingface, SkLearn, Lime, Streamlit, écosystème Hadoop ;
Intégration continue : en fonction des contextes applicatifs : docker, docker-compose, Docker Swarm, GitHub actions, Jenkins, kubernetes, concourse.
Pourquoi choisir Valeuriad ?
😊
En plus d’être aujourd’hui un acteur nantais reconnu de l’expertise IT, nous nous inscrivons depuis notre création dans une démarche d'entreprise
Opale
et
Holacratique
, où l'ensemble de nos prises de décisions et projets sont réalisés par et avec l'ensemble de nos
120 coéquipiers
💪
Rejoindre Valeuriad, c'est pouvoir s'investir dans la co-construction de l'entreprise :
Par un rôle, avec une fiche de poste et un temps dédié (gestionnaire des Ci’s, porteur des partenariats écoles, organisateur d’événements, PO des projets internes, gestion de l'Académie Valeuriad…).
Par les projets stratégiques (200 jours mis à disposition pour les coéquipiers chaque année) pour créer et faire grandir des projets structurants (création de nouveaux avantages à l'ancienneté, création d'indicateurs mensuels pour être toujours plus transparents, mécénat de compétences pour des associations caritatives...).
Par les projets cagnottes (150€ par coéquipiers et par an) pour réaliser des projets collaboratifs qui te tiennent à cœur avec d'autres Valeurieux (découverte du cécifoot, challenge écologique, challenges sportifs pour des dons à des associations humanitaires, borne photo...).
Par les ateliers collaboratifs, chaque mois des brainstorming et ateliers de travail sont proposés par les différents porteurs de projets et sont ouverts à tous les volontaires.
Mais avant-tout nous sommes une
équipe soudée
, des collègues qui apprécient passer du temps ensemble lors de nos soirées hebdomadaires et se créer des
souvenirs inoubliables
🤩 C'est pour ça que chez Valeuriad, le plus important pour nous reste le savoir-être : des passionnés, du dynamisme, des sourires, de l'écoute et le sens de la fête 😉
Show more
Show less","{'ProgLanguage': ['Python', 'R', ' R ', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R', ' R '], 'BigData': ['Hadoop'], 'MachingLearning': ['TensorFlow', 'PyTorch'], 'DataSerialization': [], 'DataVisualization': ['Tableau'], 'Statistics': ['Statistiques', 'Statistiques Descriptives'], 'CloudComputing': [], 'DevTools': ['Git', 'Docker', 'Jenkins'], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': ['Kubernetes'], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': ['Docker', 'Kubernetes'], 'Collaboration': [], 'Other': ['ML', 'Machine Learning', 'Statistiques'], 'FrSoftSkills': [], 'EnSoftSkils': []}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's']}"
LinkedIn,Machine Learning Engineer,AXA Group Operations,"Paris, Île-de-France, France",https://fr.linkedin.com/jobs/view/machine-learning-engineer-at-axa-group-operations-3856840119?position=11&pageNum=0&refId=EGCcUYgUshGnwQGGB%2BWgjg%3D%3D&trackingId=IfpsSmfjsoUsU7D9rO3JrA%3D%3D&trk=public_jobs_jserp-result_search-card,"Ready to shape the future? Join our team as a Machine Learning Engineer Extraordinaire!
About the job
Based in Paris or Barcelona, you will be part of the Artificial Intelligence Engineering team, in the Group Emerging Technologies and Data (GETD) division of AXA. This transversal team’s mission is both to build AI-powered initiatives (proofs of concept, proofs of value, pilots) with AXA entities & strategic partners and to define & implement MLOps best practices, tools, and collaboration models to be followed across the whole AXA Group. Our team is composed of 10 people, spread in 3 countries (France, Spain & Switzerland) and we work in hybrid mode (60% remote + 40% on-site).
AXA is a global leader in insurance and asset management present in nearly 60 countries. We leverage Artificial Intelligence to protect our 100+ million customers, in every domain of core insurance (Property & Casualty, Life & Savings, Health, …). As a responsible company, AXA defined and follows strong Responsible AI principles around robustness, interpretability, fairness, and sustainability.
Key responsibilities
In this role, you will:
Build and improve reusable tools & modelling pipelines and support knowledge sharing across several teams.
Work with Data Scientists to improve both technical and statistical performance of models.
Convert the machine learning models into application program interfaces (APIs) so that other applications can use them in alignment with architecture & infrastructure standards.
Secure and monitor ML processing, including safeguards, A/B testing, fault-tolerance, and failover.
Contribute to the definition and deployment of best practices in Machine Learning & MLOps,
Contribute to the sharing of knowledge and expertise through communities and working groups (internal and external).
Help the different actors of the organization (such as product managers and stakeholders) understand what results they gain from MLOps and best engineering practices in Data and AI.
What is needed to succeed
As we want you to succeed in this role, here is a list of examples of key factors:
4+ years of experience with DevOps: versioning (Git), containers (Docker/Kubernetes), CI/CD, Static analysis tools, …
Proficiency in ML Ops and ML Engineering frameworks: experiment trackers (like mlFlow) & orchestrators (Airflow, Kubeflow, Sagemaker Pipeline)
A practical knowledge in one of the popular ML Python libraries (TensorFlow, PyTorch, Keras, Scikit-Learn) and Open-Source libraries.
A good understanding of Agile methodologies and a mindset of continuous improvement.
Ability to articulate the results of your work for various audiences.
Good communication in English and interpersonal skills for working in a multicultural work environment.
Passion about solving challenging problems leveraging new technologies.
Nice to have
Here are other elements we will consider:
2+ years of experience in delivering and running ML models in production, using at least one of some of the main Big Data frameworks and platforms: Spark, Databricks, Snowflake, …
Practical knowledge in Infrastructure as code (Terraform, CloudFormation, …).
Practical knowledge of cloud services (Azure or Amazon Web Services).
Theoretical knowledge in Event Driven Architecture (using Kafka, Event Hub, or Rabbit MQ).
Insurance & Finance functional knowledge
What we offer
On top of usual benefits, we also offer:
Hybrid working (60% remote + 40% on-site).
Global communities of practice and 2 yearly global events gathering Engineers and Data Scientists.
Learning and mentoring opportunities through partnerships with LinkedIn Learning and O’Reilly.
Among a strong Employee benefit program, mental health, and well-being platform to access personalised care.
We bring together the expertise, cultural diversity and creativity of over 8,000 employees worldwide. We’re committed to equal opportunities in all aspects of employment (gender, LGBT+, disabled persons, or people of different origins) and to promoting Diversity & Inclusion by creating a work environment where all employees are treated with dignity and respect, and where individual differences are valued.
Show more
Show less","{'ProgLanguage': ['Python', 'R', 'Go'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': ['Spark', 'Databricks'], 'MachingLearning': ['Scikit-Learn', 'TensorFlow', 'Keras', 'PyTorch'], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': ['Azure'], 'DevTools': ['Git', 'Docker'], 'Os': [], 'DBMS': ['Snowflake', 'Snowflake'], 'SoftBigDataProcessing': [], 'Automation': ['Kubernetes', 'Airflow'], 'InfrastructureAsCode': ['Terraform', 'CloudFormation'], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': ['Docker', 'Kubernetes'], 'Collaboration': ['Teams'], 'Other': ['DevOps', 'Big Data', 'ML', 'Machine Learning', 'Cloud', 'CI/CD'], 'FrSoftSkills': ['Communication', 'Collaboration'], 'EnSoftSkils': ['Communication', 'Creativity', 'Collaboration', 'Organization', 'Initiative', 'Interpersonal Skills']}","{'JobDetail': ['Remote'], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's']}"
LinkedIn,Data Scientist– Machine Learning,EyeTech Solutions,"Paris, Île-de-France, France",https://fr.linkedin.com/jobs/view/data-scientist%E2%80%93-machine-learning-at-eyetech-solutions-3913336440?position=12&pageNum=0&refId=EGCcUYgUshGnwQGGB%2BWgjg%3D%3D&trackingId=n53I6DfQwIRgoS6pyiYOcw%3D%3D&trk=public_jobs_jserp-result_search-card,"Data Scientist– Machine Learning
Travailler sur le développement de modèle de machine learning prédictif.
Pour une Solution SaaS de monitoring analytique, prédictif et prescriptif en milieu industriel.
Data Scientist– Machine Learning
Fondée en 2016, notre société développe une solution SAAS dédiée au monitoring automatique des lignes de production.
Notre équipe spécialisée dans les données est responsable de la conception, du développement et de la maintenance de la plateforme IA de notre solution, dont les principales fonctionnalités incluent le monitoring analytique, prédictif et prescriptif.
Cette même équipe est également chargée du développement d'une nouvelle plateforme IA qui sera intégrée à nos solutions existantes.
Nos solutions reposent sur une stack technologique moderne, utilisant des outils tels que Airflow, Mlflow, MongoDB, Kubernetes, CI/CD.
Data Scientist– Machine Learning
Travaux sur le développement de modèle de machine learning prédictif
Collaboration avec le Lead Data Scientist et le Lead Tech Senior pour définir les orientations du produit et organiser les tâches.
Contribution au développement des fonctionnalités liées aux données et à l’intelligence artificielle.
Communication et présentation clients.
Veille scientifique et travaux de recherche et développement.
Data Scientist– Machine Learning
3 ans d’expérience minimum en tant que Data Scientist (IA, ML) dans l’industrialisation d’un produit
Capaciter à vulgariser, comprendre et transformer les besoins
Diplome universitaire
Data Scientist– Machine Learning
Locaux à Paris
Salaire selon profil, entre 50K et 55K
Télétravail 2 jours / semaine
Show more
Show less","{'ProgLanguage': ['R', 'Go'], 'DataBase': [' MongoDB'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': ['Kubernetes', 'Airflow'], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': ['Kubernetes'], 'Collaboration': [], 'Other': ['ML', 'Machine Learning', 'CI/CD'], 'FrSoftSkills': ['Communication', 'Collaboration'], 'EnSoftSkils': ['Communication', 'Collaboration']}","{'JobDetail': ['Senior'], 'TypeContract': [], 'Salary': ['50K'], 'Level': [], 'Experience': ['a', 'n', 's', '3', '3', '3']}"
LinkedIn,Machine Learning Engineer,Aether Energy (YC W24),"Paris, Île-de-France, France",https://fr.linkedin.com/jobs/view/machine-learning-engineer-at-aether-energy-yc-w24-3911654324?position=13&pageNum=0&refId=EGCcUYgUshGnwQGGB%2BWgjg%3D%3D&trackingId=LBa35KRODLiTFj01rb%2BGBg%3D%3D&trk=public_jobs_jserp-result_search-card,"We raised a $3M seed recently.
We encourage all applicants from the EU to apply.
Overview
Aether is on a mission to develop a comprehensive AI-driven platform for the solar energy industry. Our founders have strong technical academic background from UC Berkeley, complemented by extensive technical experience gained at some of the most influential companies in the energy sector.
Aether is seeking a machine learning engineer with a strong background in software engineering.
Ideal candidates should have backgrounds in Physics, Mechanical Engineering, Electrical Engineering, or Materials Science, coupled with expertise in Computational Mathematics. A Master's degree is essential for this role, while a PhD, though not mandatory, would be highly valuable.
We are proud of our recent success and invite you to check out our YCombinator launch at
this link
.
We're Looking For Someone Who:
Gets things done. This is an emerging Y Combinator seed company, and we require you to make an impact from day one.
Your growth potential here is unlimited.
Qualifications
This role will be 60% Machine Learning/Data Science focused, and 40% backend engineering focused. You will need to be comfortable writing production-level code.
REQUIRED
Strong proficiency in Python
Knowledge of unsupervised and supervised machine learning techniques
A deep understanding of Computer Vision models such as UNET, DeepLab, or HRNet (High-Resolution Network).
Interested in developing foundational LLM models (our use-case is energy)
Proficiency in data exploration (using BigQuery, Jupyter notebooks, and SQL), model development, and the establishment of data/ML pipelines
Comfortable working with APIs and Databases.
Knowledge of best practices in collaborative coding with tools like Git and CI/CD.
Strong software engineering skills and an understanding of good design patterns.
You must be Fluent in English.
Preferred -
We know you won’t know everything but having a good general breadth of the requirements below will set you apart.
A keen interest in the intersection of physical systems and AI.
Knowledge of the Django framework.
Familiarity with Python libraries, including Pandas, NumPy, scikit-learn, PyTorch/Tensorflow, PyTorch Lightning, and vector databases.
Competency in deploying data and code to cloud platforms (GCP/Digital Ocean).
Understanding of energy related data: battery data, solar data, etc.
Ideally, previous experience in high-growth start-ups.
Your math has to be good. We will check for this.
Compensation/Time Commitment/Location:
You will need to work US EST hours from Monday to Thursday. You must be in our Paris office 3x a week starting in August.
1st 3 months will be on a contract basis to assess performance.
Show more
Show less","{'ProgLanguage': ['Python', 'R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['Pandas', 'NumPy', 'R'], 'BigData': [], 'MachingLearning': ['Scikit-Learn', 'TensorFlow', 'PyTorch'], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git'], 'Os': [], 'DBMS': ['BigQuery'], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['ML', 'Machine Learning', 'Cloud', 'CI/CD'], 'FrSoftSkills': [], 'EnSoftSkils': []}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's']}"
LinkedIn,Machine Learning Engineer,Mirakl,"Paris, Île-de-France, France",https://fr.linkedin.com/jobs/view/machine-learning-engineer-at-mirakl-3879686188?position=14&pageNum=0&refId=EGCcUYgUshGnwQGGB%2BWgjg%3D%3D&trackingId=wddjfeLCyDYNCFGzs9oqcw%3D%3D&trk=public_jobs_jserp-result_search-card,"Mirakl, leader et pionnier de l’économie de plateforme, propose aux entreprises une suite unique de solutions leur permettant de transformer significativement leur e-commerce afin d'accélérer de façon durable et rentable leur croissance. Depuis 2012, Mirakl accompagne les entreprises B2C et B2B avec la technologie la plus avancée, sécurisée et évolutive leur permettant de digitaliser leur activité et d'élargir leur offre via la marketplace ou le dropship, faciliter la gestion des catalogues et des paiements de leurs fournisseurs pour plus d'efficacité, offrir une expérience d'achat personnalisée à leurs clients, et augmenter leurs profits grâce au retail media. Basée à Paris et Boston, Mirakl est certifiée Great Place to Work.
A propos de Mirakl Labs
Nos équipes techniques et produits, nommées Mirakl Labs, sont principalement réparties entre nos 2 hubs situés à Paris et à Bordeaux. Elles collaborent au quotidien afin d'adresser les problématiques de nos clients et utilisateurs en répondant à différents challenges liés aux nouvelles fonctionnalités, à la scalabilité, la sécurité et l’ergonomie…
Elles opèrent en mode agile et s'organisent en Squads composées d'un Squad Lead, de 5 développeurs, d'un Product Manager et d'un QA. Chaque Squad est spécialisée sur un scope fonctionnel afin de concevoir et réaliser de nouvelles features, leurs évolutions et des APIs (avec un découpage en micro-services). Nos équipes Infrastructure, Architecture, Sécurité, Documentation, Product Design, Data et Support opèrent en transverse en apportant leur expertise et de la cohérence sur l’ensemble des produits.
Toutes les équipes sont responsables de leur périmètre et chacun des collaborateurs apporte son expérience et ses idées. Innovation, feedback et implication dans les prises de décision sont au cœur de notre philosophie.
Et pour favoriser ce partage avec d’autres passionnés, nous sommes sponsors, speakers, et hôtes de différents événements, meetups, et associations de la scène Tech en France. Au cours des dernières années, nous avons participé à des événements tels que Devoxx, ReactEurope, ProductConf et Flupa UX Days.
A propos du job
Intégré.e dans notre équipe Data Science, votre principale mission sera de prototyper, itérer, et mettre en production des algorithmes en collaboration avec les équipes Produit, les Data Engineers et les équipes de développement. Les sujets que vous traiterez auront un vrai impact sur nos clients : l’ambition est d’exploiter au maximum nos données riches et variées afin de développer leur chiffre d'affaires, d’optimiser la gestion opérationnelle de leur marketplace et de garantir la sécurité des utilisateurs et des transactions.
A propos de l’équipe
Get to Know the Data Science Team That Powers the Mirakl Platform
Ce qu’il y a pour vous dans ce job
Implémenter, optimiser et déployer des algorithmes qui auront un impact visible sur plus de 500 sites e-commerce/marketplaces dans 40 pays dont certains une volumétrie très importantes (millions de produits, de clients, de commandes par an)
Traiter des sujets très divers et variés d’un point de vue:
Business
Machine learning (NLP, Image processing, Time series, LLM, système de recommandation, etc.)
Infrastructure (spark, model endpoints, etc.)
Une plateforme Machine Learning et Data Platform state-of-the-art
Concevoir et déployer des infrastructures à faible latence avec les Data Engineers
Une vraie autonomie et responsabilité dans les projets dont vous avez l’ownership
La possibilité d'avoir un contrat freelance ou CDI
Notre stack et nos outils
Python, Tensorflow, Pytorch, Databricks, Spark, Aws, Airflow, MLflow, Delta Lake, SQL
Au quotidien
,
vous allez :
Designer, optimiser et mettre en production des modèles de machine learning de façon scalable (apprentissage et inférence)
Rassembler et manipuler les données, prototyper des algorithmes de machine learning
Mettre en place et monitorer des serving endpoints
Participer à l’évolution de la plateforme Machine Learning de Mirakl
Continuer à mettre en place des best practices de programmation mais aussi de déploiement
Effectuer de la veille technologique sur les modèles state-of-the-art, ainsi que sur les stack machine learning
Présenter les résultats au weekly data science et aux sessions de brainstorming de l’équipe
Échanger avec les autres équipes pour affiner les cas d’utilisation, l’expérience utilisateur et les modes d’intégration
Vous aimerez ce job si :
Vous avez minimum 3 ans d’expérience en tant que Machine Learning Engineer (le poste est évolutif selon votre séniorité)
Vous avez de solides compétences en développement Python
Vous aimez le software engineering et le machine learning
Vous avez une expérience significative dans la mise en production, le scaling des modèles et des bests practices MLOps
Vous avez l’habitude de chercher, manipuler et analyser des données à forte volumétrie, idéalement avec Spark
Vous avez une bonne connaissance des algorithmes de Deep Learning (texte et/ou image), des architectures State-Of-the-Art - par exemple les Transformers
Vous avez de l’expérience dans l’optimisation de modèles de machine learning et de leur inférence
Vous avez de l’expérience dans la mise en place de serving de modèles
Vous aimez avoir l’ownership de vos sujets et aimez partager votre travail dans le cadre de présentations internes, dans des conférences ou en rédigeant des articles
Petit plus :
Vous avez une expérience en environnement e-commerce, sur des algorithmes de systèmes de recommandations et/ou retail media
Vous avez une expérience dans le serving de modèles à faible latence
Vous êtes spécialiste NLP
Optimisation de LLM
Mirakl est engagée en faveur de la diversité, de l’égalité des chances et de l’inclusion. Nous célébrons nos différences car nous sommes convaincus que les qualités visibles et invisibles de chaque Mirakl Worker sont une source de force et d’innovation. Dans le cadre de cet engagement, nous étudions toutes les candidatures sans distinction de : genre, ethnicité, religion, orientation sexuelle, handicap, âge ou toute autre caractéristique protégée par la loi.
Show more
Show less","{'ProgLanguage': ['Python', 'Scala', 'R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': ['Spark', 'Databricks'], 'MachingLearning': ['TensorFlow', 'PyTorch'], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': ['AWS'], 'DevTools': ['Git'], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': ['Airflow'], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['ML', 'Machine Learning'], 'FrSoftSkills': ['Collaboration'], 'EnSoftSkils': ['Collaboration']}","{'JobDetail': [], 'TypeContract': ['CDI'], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's', '3', '3', '3']}"
LinkedIn,Machine Learning Engineer,Mirakl,"Paris, Île-de-France, France",https://fr.linkedin.com/jobs/view/machine-learning-engineer-at-mirakl-3879682593?position=15&pageNum=0&refId=EGCcUYgUshGnwQGGB%2BWgjg%3D%3D&trackingId=a%2Bf3OjukV2mgUJef50tD0w%3D%3D&trk=public_jobs_jserp-result_search-card,"Mirakl, leader et pionnier de l’économie de plateforme, propose aux entreprises une suite unique de solutions leur permettant de transformer significativement leur e-commerce afin d'accélérer de façon durable et rentable leur croissance. Depuis 2012, Mirakl accompagne les entreprises B2C et B2B avec la technologie la plus avancée, sécurisée et évolutive leur permettant de digitaliser leur activité et d'élargir leur offre via la marketplace ou le dropship, faciliter la gestion des catalogues et des paiements de leurs fournisseurs pour plus d'efficacité, offrir une expérience d'achat personnalisée à leurs clients, et augmenter leurs profits grâce au retail media. Basée à Paris et Boston, Mirakl est certifiée Great Place to Work.
A propos de Mirakl Labs
Nos équipes techniques et produits, nommées Mirakl Labs, sont principalement réparties entre nos 2 hubs situés à Paris et à Bordeaux. Elles collaborent au quotidien afin d'adresser les problématiques de nos clients et utilisateurs en répondant à différents challenges liés aux nouvelles fonctionnalités, à la scalabilité, la sécurité et l’ergonomie…
Elles opèrent en mode agile et s'organisent en Squads composées d'un Squad Lead, de 5 développeurs, d'un Product Manager et d'un QA. Chaque Squad est spécialisée sur un scope fonctionnel afin de concevoir et réaliser de nouvelles features, leurs évolutions et des APIs (avec un découpage en micro-services). Nos équipes Infrastructure, Architecture, Sécurité, Documentation, Product Design, Data et Support opèrent en transverse en apportant leur expertise et de la cohérence sur l’ensemble des produits.
Toutes les équipes sont responsables de leur périmètre et chacun des collaborateurs apporte son expérience et ses idées. Innovation, feedback et implication dans les prises de décision sont au cœur de notre philosophie.
Et pour favoriser ce partage avec d’autres passionnés, nous sommes sponsors, speakers, et hôtes de différents événements, meetups, et associations de la scène Tech en France. Au cours des dernières années, nous avons participé à des événements tels que Devoxx, ReactEurope, ProductConf et Flupa UX Days.
A propos du job
Intégré.e dans notre équipe Data Science, votre principale mission sera de prototyper, itérer, et mettre en production des algorithmes en collaboration avec les équipes Produit, les Data Engineers et les équipes de développement. Les sujets que vous traiterez auront un vrai impact sur nos clients : l’ambition est d’exploiter au maximum nos données riches et variées afin de développer leur chiffre d'affaires, d’optimiser la gestion opérationnelle de leur marketplace et de garantir la sécurité des utilisateurs et des transactions.
A propos de l’équipe
Get to Know the Data Science Team That Powers the Mirakl Platform
Ce qu’il y a pour vous dans ce job
Implémenter, optimiser et déployer des algorithmes qui auront un impact visible sur plus de 500 sites e-commerce/marketplaces dans 40 pays dont certains une volumétrie très importantes (millions de produits, de clients, de commandes par an)
Traiter des sujets très divers et variés d’un point de vue:
Business
Machine learning (NLP, Image processing, Time series, LLM, système de recommandation, etc.)
Infrastructure (spark, model endpoints, etc.)
Une plateforme Machine Learning et Data Platform state-of-the-art
Concevoir et déployer des infrastructures à faible latence avec les Data Engineers
Une vraie autonomie et responsabilité dans les projets dont vous avez l’ownership
La possibilité d'avoir un contrat freelance ou CDI
Notre stack et nos outils
Python, Tensorflow, Pytorch, Databricks, Spark, Aws, Airflow, MLflow, Delta Lake, SQL
Au quotidien
,
vous allez :
Designer, optimiser et mettre en production des modèles de machine learning de façon scalable (apprentissage et inférence)
Rassembler et manipuler les données, prototyper des algorithmes de machine learning
Mettre en place et monitorer des serving endpoints
Participer à l’évolution de la plateforme Machine Learning de Mirakl
Continuer à mettre en place des best practices de programmation mais aussi de déploiement
Effectuer de la veille technologique sur les modèles state-of-the-art, ainsi que sur les stack machine learning
Présenter les résultats au weekly data science et aux sessions de brainstorming de l’équipe
Échanger avec les autres équipes pour affiner les cas d’utilisation, l’expérience utilisateur et les modes d’intégration
Vous aimerez ce job si :
Vous avez minimum 3 ans d’expérience en tant que Machine Learning Engineer (le poste est évolutif selon votre séniorité)
Vous avez de solides compétences en développement Python
Vous aimez le software engineering et le machine learning
Vous avez une expérience significative dans la mise en production, le scaling des modèles et des bests practices MLOps
Vous avez l’habitude de chercher, manipuler et analyser des données à forte volumétrie, idéalement avec Spark
Vous avez une bonne connaissance des algorithmes de Deep Learning (texte et/ou image), des architectures State-Of-the-Art - par exemple les Transformers
Vous avez de l’expérience dans l’optimisation de modèles de machine learning et de leur inférence
Vous avez de l’expérience dans la mise en place de serving de modèles
Vous aimez avoir l’ownership de vos sujets et aimez partager votre travail dans le cadre de présentations internes, dans des conférences ou en rédigeant des articles
Petit plus :
Vous avez une expérience en environnement e-commerce, sur des algorithmes de systèmes de recommandations et/ou retail media*
Vous avez une expérience dans le serving de modèles à faible latence
Vous êtes spécialiste NLP
Optimisation de LLM
Mirakl est engagée en faveur de la diversité, de l’égalité des chances et de l’inclusion. Nous célébrons nos différences car nous sommes convaincus que les qualités visibles et invisibles de chaque Mirakl Worker sont une source de force et d’innovation. Dans le cadre de cet engagement, nous étudions toutes les candidatures sans distinction de : genre, ethnicité, religion, orientation sexuelle, handicap, âge ou toute autre caractéristique protégée par la loi.
Show more
Show less","{'ProgLanguage': ['Python', 'Scala', 'R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': ['Spark', 'Databricks'], 'MachingLearning': ['TensorFlow', 'PyTorch'], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': ['AWS'], 'DevTools': ['Git'], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': ['Airflow'], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['ML', 'Machine Learning'], 'FrSoftSkills': ['Collaboration'], 'EnSoftSkils': ['Collaboration']}","{'JobDetail': [], 'TypeContract': ['CDI'], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's', '3', '3', '3']}"
LinkedIn,Machine Learning Scientist/Engineer,NuMind (YC S22),"Paris, Île-de-France, France",https://fr.linkedin.com/jobs/view/machine-learning-scientist-engineer-at-numind-yc-s22-3856851886?position=16&pageNum=0&refId=EGCcUYgUshGnwQGGB%2BWgjg%3D%3D&trackingId=o0yuwOQJ8MHxFaoofHaUqw%3D%3D&trk=public_jobs_jserp-result_search-card,"About Us
NuMind (https://www.numind.ai/) is a software company developing a tool to create custom NLP models specialized in information extraction (see https://www.youtube.com/watch?v=MQhYe5HXqss). We also develop open-source foundation models (https://huggingface.co/numind), and write research papers (see https://arxiv.org/abs/2402.15343).
We aim to become leader in the field of custom information extraction.
We are a team of 7: CEO, CTO, COO, 2 senior software engineers, and 2 machine learning scientists. Our CEO was head of ML at Wolfram Research and our CTO co-founded Make.org.
Most of the team are located in France (Paris).
We were part of YCombinator’s S22 batch, and raised a good seed round.
Job Description
NuMind is a tool to create NLP models (e.g. classifiers and entity recognizers). The user provides information about the task (e.g. by labeling documents), and the computer creates models automatically.
Your job will be to make this happen in the most effective way. This will involve designing & testing various machine learning solutions, and implementing these solutions directly into NuMind.
R&D topics include:
Transfer learning, few-shot learning
Active learning
Automatic machine learning
Performance measurements
Distillation
Probability calibration
Out-of-domain robustness
Model explanations
This position is for someone who has both a researcher and engineer mindset.
Responsibilities
Training task-specific foundation models
Setting up benchmarks to test ML solutions
Identifying & testing existing ML solutions
Designing & testing new ML solutions from scratch
Implementing selected solutions into the product
Staying up to date with relevant NLP research
Qualifications
Expert-level understanding of machine learning.
Ability to design, train, test deep learning models
Ability to conduct machine learning research (e.g. conducting experiments, drawing conclusions, communicating results)
Ability to develop production-grade code
Good understanding of the following field: statistics, computer science (esp. data structures & algorithms), and numerical analysis
Show more
Show less","{'ProgLanguage': ['R', 'Go'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': ['Statistics'], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['ML', 'Machine Learning'], 'FrSoftSkills': [], 'EnSoftSkils': []}","{'JobDetail': ['Senior'], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's']}"
LinkedIn,Data Scientist - Toulouse,Capgemini,"Toulouse, Occitanie, France",https://fr.linkedin.com/jobs/view/data-scientist-toulouse-at-capgemini-3913358664?position=17&pageNum=0&refId=EGCcUYgUshGnwQGGB%2BWgjg%3D%3D&trackingId=D7LWLFbnm7ToTrU28hLx3Q%3D%3D&trk=public_jobs_jserp-result_search-card,"Capgemini en quelques mots
Choisir Capgemini, c'est choisir une entreprise où vous serez en mesure de façonner votre carrière selon vos aspirations, où vous serez soutenu et inspiré par une communauté d’experts dans le monde entier, où vous pourrez réécrire votre futur. Rejoignez-nous pour redéfinir les limites de ce qui est possible, contribuer à libérer la valeur de la technologie pour les plus grandes organisations et participez à la construction d’un monde plus durable et inclusif.
Vos missions
En tant que
Lead Technique Data Science
au sein de la practice Insights & Data, vous serez amener à intervenir sur des projets data pour :
Idéaliser les cas d’usages et cadrer le projet afin de répondre aux exigences métiers à partir de solutions innovantes d’Intelligence Artificielle
Promouvoir les bonnes pratiques au sein de l’équipe avec le développement d’une méthodologie de travail et d’amélioration continue appropriés
Participer aux propositions commerciales sur la partie Data
Construire une relation de confiance avec le client en tant qu’interlocuteur privilégié et assurer la qualité des rendus finaux ainsi que le développement de nouveaux enjeux business
Faire parti des leaders de la communauté Data Science et influencer sur la stratégie Data d’Insights & Data
Continuer de vous former sur tous les aspects de votre métier et assurer une veille technologique sur les innovations les plus pertinentes à mettre en place
Votre profil
De formation Bac + 5 en école d’ingénieur ou équivalent universitaire avec une spécialisation Data Science
A partir de 6 ans d’expériences
Compréhension fine des enjeux business et pilotage d'une équipe
Connaissance de plusieurs langages de programmation (Python, Scala, Spark…) et Cloud (AWS, GCP, Azure, OVH)
Le Machine Learning, le NLP et le Deep Learning n’ont plus de secret pour vous
Bon niveau d'anglais
3 raisons de nous rejoindre
Qualité de vie au travail :
accord de télétravail en France et à l’international, accord sur l’égalité
professionnelle, la parentalité, l’équilibre des temps et la mobilité durable.
Apprentissage en continu :
certifications et formations en libre accès, accompagnement sur mesure avec
votre carreer manager, parcours d’intégration sur 9 mois.
Avantages groupe & CSE :
plan actionnariat, activités à tarifs préférentiels, remboursement partiel
vacances, remboursement de votre abonnement sportif ou culturel
Nos engagements et priorités
Le groupe Capgemini encourage une
culture inclusive dans un cadre multiculturel et handi-accueillant.
En nous rejoignant, vous intégrez un collectif qui valorise la diversité, développe le potentiel de ses talents, s’engage dans des
initiatives solidaires avec ses partenaires, et se mobilise pour réduire son impact environnemental sur tous ses sites et auprès de ses clients.
Capgemini
est un
leader mondial
, responsable et multiculturel, regroupant près de 350 000 personnes dans plus de 50 pays. Fort de
55 ans d’expérience
, nous sommes un partenaire stratégique des entreprises pour la transformation de leurs activités en tirant profit de toute la puissance de la technologie et des innovations dans les domaines en perpétuelle évolution tels que
le cloud, la data, l’Intelligence Artificielle, la connectivité, les logiciels, l’ingénierie digitale ou les plateformes.
Get The Future You Want* | www.capgemini.com/fr-fr
*Capgemini, le futur que vous voulez
Show more
Show less","{'ProgLanguage': ['Python', 'Scala', 'R'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': ['Spark'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': ['AWS', 'Azure'], 'DevTools': ['Git'], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Machine Learning', 'Cloud'], 'FrSoftSkills': ['Organisation'], 'EnSoftSkils': ['Initiative']}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's', '6', '6', '6']}"
LinkedIn,Data Scientist,Enzo Tech Group,"Île-de-France, France",https://fr.linkedin.com/jobs/view/data-scientist-at-enzo-tech-group-3914681877?position=18&pageNum=0&refId=EGCcUYgUshGnwQGGB%2BWgjg%3D%3D&trackingId=ohDkU5k3R423YD8rHWJhyQ%3D%3D&trk=public_jobs_jserp-result_search-card,"Role:
Data Scientist
Location:
Paris (3 days) / Remote (2 days)
Searching for a
Data Scientist
partnering with a global customer who are searching for multiple Data Scientist's as they continue to invest in designing and building high-quality AI solutions.
Responsibilities
Analyze raw data: assessing quality, cleansing, structuring for downstream processing
Design accurate and scalable prediction algorithms
Collaborate with engineering team to bring analytical prototypes to production
Generate actionable insights for business improvements
Qualifications
Bachelor's degree or equivalent experience in quantative field (Statistics, Mathematics, Computer Science, Engineering, etc.)
Tech Stack: GenAI, Databricks, Azure
At least 1 - 2 years' of experience in quantitative analytics or data modelling
Deep understanding of predictive modelling, machine-learning, clustering and classification techniques, and algorithms
Fluency in a programming language (Python, C,C++, Java, SQL)
CVs:
Apply via job post or directly
@
k.downs@enzotechgroup.com
Show more
Show less","{'ProgLanguage': ['Python', 'Java', 'C++', 'Scala', 'R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': ['Databricks'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': ['Statistics'], 'CloudComputing': ['Azure'], 'DevTools': [], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': [], 'FrSoftSkills': [], 'EnSoftSkils': []}","{'JobDetail': ['Remote'], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's']}"
LinkedIn,Data Scientist,Sidetrade,"Boulogne-Billancourt, Île-de-France, France",https://fr.linkedin.com/jobs/view/data-scientist-at-sidetrade-3894699040?position=19&pageNum=0&refId=EGCcUYgUshGnwQGGB%2BWgjg%3D%3D&trackingId=fi4rJXKOGiEroo0rb7FY%2Bw%3D%3D&trk=public_jobs_jserp-result_search-card,"Calling all tech enthusiasts! Are you a problem-solving, curious, and strategic Data Scientist ? Join us at Sidetrade, the leading global SaaS provider recognized by Gartner.(https://go.sidetrade.com/GartnerMagicQuadrant22.ht)
Indulge your passion for high-availability software and performance enhancement as part of our dynamic team. Embrace the challenge, embrace the excitement - become a Data Scientist and thrive! Shape the future of AI-powered Order-to-Cash at Sidetrade today. Join us in creating innovative solutions that redefine the industry!
About Sidetrade and its amazing R&D team
Sidetrade is a fast-growing international software company that is transforming the Order-to-Cash process for global enterprises. Its AI-powered SaaS platform digitizes the financial customer journey, empowering CFOs to secure and accelerate cash flow generation. Recognized as a Leader in Gartner's Magic Quadrant for two consecutive years, Sidetrade fosters a culture of innovation, collaboration, and customer-centricity from its headquarters in Europe and North America.
The R&D team comprises experienced tech professionals who share a deep passion for technology. Together, they are dedicated to developing cutting-edge software solutions that drive the transformation of our customers' work processes. We provide comprehensive training, coaching, resources, and mentorship to empower every team member's growth and nurture their success.
What you will love at Sidetrade:
We are seeking a passionate and knowledgeable Data Scientist with a multifaceted skill set. Immerse yourself in the exhilarating world of AI and Data Science within our cutting-edge tech environment. Collaborate with like-minded individuals, embracing the latest tools, techniques, and technologies. Fuel your professional growth and innovation within our agile development ecosystem.
Your missions :
Build solutions with AI, GenAI, LLM, Machine learning, Deep learning, Big Data for our products
Define the technical and functional orientations of the product in interaction with our Product, Marketing and Sales teams.
Participate in developing the architecture (LakeHouse, DataWareHouse, DataLake, ETL, Search Engine, NoSQL, SQL) and designing scalable and smart algorithms
Enhance your skills through constant discussions with specialists in their fields, and internal hackathons
Participate in data science guild projects: Exploratory research, Data mining, Data analysis, POC Machine learning,..
You will be involved in the entire development cycle: design, implementation, testing, release and maintenance.
Through your expertise, you will reinforce the continuous improvement of development processes.
Technical environment :
Languages : Python & SQL
Data Storage : Oracle, Postgres, Elasticsearch, Greenplum, MongoDB
Data Science framework : Dataiku, Jupyter Notebook, Metaflow
Dataviz : Tableau Server, PowerBI
Data processing : Talend, Python, DBT, Kafka
Source control : Git
Déployment: Bash, Ansible, Docker
Confluence, Jira, Teams
Requirements
Master degree
2 to 5 years' experience in a similar position
Proven data science experience with production launch of Machine Learning models
Applied knowledge of AI, GenAI and LLM
Solid knowledge of Python and object-oriented programming
Good knowledge of SQL and NoSQL databases
Familiarity with API Rest and Web development issues
Sensitivy to the performance of your algorithms, both in terms of relevance and hardware impact
A taste for discovery and technology watch
You know how to grasp a rich technical stack (Scheduling/Message queuing/Front/API/Data Workflow / Distributed Computing Framework / Machine Learning / SQL & NoSQL databases) and challenge it
Fluent in English (written and spoken) is a must (most of the meeting are in English).
Benefits
Join our Immersive Bootcamp
Review your onboarding plan with your manager and develop an action plan to achieve your goals
Collaborate with the team and participate to the roadmap to optimize software performancebuild your internal network across all departments
Expand your skill set, share your expertise and unlock your full potential
At Sidetrade, we cultivate a multicultural environment that fuels innovation. With over 22 nationalities represented, we strongly value diversity, gender equality, inclusivity, and fairness. As an equal opportunity employer, we reject all forms of discrimination and harassment. Your unique contributions are celebrated, driving collective success in our inclusive workplace.
Discover more on www.sidetrade.com
Agencies
Only applications from invited agencies through the Workable portal will be accepted. Unsolicited CVs sent directly to managers or HR will not incur any fees.
Apply for this job
Show more
Show less","{'ProgLanguage': ['Python', 'Scala', 'R', 'Go', 'Bash'], 'DataBase': ['SQL', 'NoSQL', ' MongoDB', 'Elasticsearch'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': ['Tableau', 'PowerBI'], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git', 'Docker'], 'Os': [], 'DBMS': ['Oracle'], 'SoftBigDataProcessing': [], 'Automation': ['Ansible'], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': ['Docker'], 'Collaboration': ['JIRA', 'Confluence', 'Teams'], 'Other': ['Big Data', 'Machine Learning'], 'FrSoftSkills': ['Collaboration'], 'EnSoftSkils': ['Collaboration']}","{'JobDetail': ['Full'], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's']}"
LinkedIn,Machine Learning Engineer,Mirakl,"Bordeaux, Nouvelle-Aquitaine, France",https://fr.linkedin.com/jobs/view/machine-learning-engineer-at-mirakl-3879681732?position=20&pageNum=0&refId=EGCcUYgUshGnwQGGB%2BWgjg%3D%3D&trackingId=lqE6h8iVcB0k9FL%2FdMIw1A%3D%3D&trk=public_jobs_jserp-result_search-card,"Mirakl, leader et pionnier de l’économie de plateforme, propose aux entreprises une suite unique de solutions leur permettant de transformer significativement leur e-commerce afin d'accélérer de façon durable et rentable leur croissance. Depuis 2012, Mirakl accompagne les entreprises B2C et B2B avec la technologie la plus avancée, sécurisée et évolutive leur permettant de digitaliser leur activité et d'élargir leur offre via la marketplace ou le dropship, faciliter la gestion des catalogues et des paiements de leurs fournisseurs pour plus d'efficacité, offrir une expérience d'achat personnalisée à leurs clients, et augmenter leurs profits grâce au retail media. Basée à Paris et Boston, Mirakl est certifiée Great Place to Work.
A propos de Mirakl Labs
Nos équipes techniques et produits, nommées Mirakl Labs, sont principalement réparties entre nos 2 hubs situés à Paris et à Bordeaux. Elles collaborent au quotidien afin d'adresser les problématiques de nos clients et utilisateurs en répondant à différents challenges liés aux nouvelles fonctionnalités, à la scalabilité, la sécurité et l’ergonomie…
Elles opèrent en mode agile et s'organisent en Squads composées d'un Squad Lead, de 5 développeurs, d'un Product Manager et d'un QA. Chaque Squad est spécialisée sur un scope fonctionnel afin de concevoir et réaliser de nouvelles features, leurs évolutions et des APIs (avec un découpage en micro-services). Nos équipes Infrastructure, Architecture, Sécurité, Documentation, Product Design, Data et Support opèrent en transverse en apportant leur expertise et de la cohérence sur l’ensemble des produits.
Toutes les équipes sont responsables de leur périmètre et chacun des collaborateurs apporte son expérience et ses idées. Innovation, feedback et implication dans les prises de décision sont au cœur de notre philosophie.
Et pour favoriser ce partage avec d’autres passionnés, nous sommes sponsors, speakers, et hôtes de différents événements, meetups, et associations de la scène Tech en France. Au cours des dernières années, nous avons participé à des événements tels que Devoxx, ReactEurope, ProductConf et Flupa UX Days.
A propos du job
Intégré.e dans notre équipe Data Science, votre principale mission sera de prototyper, itérer, et mettre en production des algorithmes en collaboration avec les équipes Produit, les Data Engineers et les équipes de développement. Les sujets que vous traiterez auront un vrai impact sur nos clients : l’ambition est d’exploiter au maximum nos données riches et variées afin de développer leur chiffre d'affaires, d’optimiser la gestion opérationnelle de leur marketplace et de garantir la sécurité des utilisateurs et des transactions.
A propos de l’équipe
Get to Know the Data Science Team That Powers the Mirakl Platform
Ce qu’il y a pour vous dans ce job
Implémenter, optimiser et déployer des algorithmes qui auront un impact visible sur plus de 500 sites e-commerce/marketplaces dans 40 pays dont certains une volumétrie très importantes (millions de produits, de clients, de commandes par an)
Traiter des sujets très divers et variés d’un point de vue:
Business
Machine learning (NLP, Image processing, Time series, LLM, système de recommandation, etc.)
Infrastructure (spark, model endpoints, etc.)
Une plateforme Machine Learning et Data Platform state-of-the-art
Concevoir et déployer des infrastructures à faible latence avec les Data Engineers
Une vraie autonomie et responsabilité dans les projets dont vous avez l’ownership
La possibilité d'avoir un contrat freelance ou CDI
Notre stack et nos outils
Python, Tensorflow, Pytorch, Databricks, Spark, Aws, Airflow, MLflow, Delta Lake, SQL
Au quotidien
,
vous allez :
Designer, optimiser et mettre en production des modèles de machine learning de façon scalable (apprentissage et inférence)
Rassembler et manipuler les données, prototyper des algorithmes de machine learning
Mettre en place et monitorer des serving endpoints
Participer à l’évolution de la plateforme Machine Learning de Mirakl
Continuer à mettre en place des best practices de programmation mais aussi de déploiement
Effectuer de la veille technologique sur les modèles state-of-the-art, ainsi que sur les stack machine learning
Présenter les résultats au weekly data science et aux sessions de brainstorming de l’équipe
Échanger avec les autres équipes pour affiner les cas d’utilisation, l’expérience utilisateur et les modes d’intégration
Vous aimerez ce job si :
Vous avez minimum 3 ans d’expérience en tant que Machine Learning Engineer (le poste est évolutif selon votre séniorité)
Vous avez de solides compétences en développement Python
Vous aimez le software engineering et le machine learning
Vous avez une expérience significative dans la mise en production, le scaling des modèles et des bests practices MLOps
Vous avez l’habitude de chercher, manipuler et analyser des données à forte volumétrie, idéalement avec Spark
Vous avez une bonne connaissance des algorithmes de Deep Learning (texte et/ou image), des architectures State-Of-the-Art - par exemple les Transformers
Vous avez de l’expérience dans l’optimisation de modèles de machine learning et de leur inférence
Vous avez de l’expérience dans la mise en place de serving de modèles
Vous aimez avoir l’ownership de vos sujets et aimez partager votre travail dans le cadre de présentations internes, dans des conférences ou en rédigeant des articles
Petit plus :
Vous avez une expérience en environnement e-commerce, sur des algorithmes de systèmes de recommandations et/ou retail media*
Vous avez une expérience dans le serving de modèles à faible latence
Vous êtes spécialiste NLP
Optimisation de LLM
Mirakl est engagée en faveur de la diversité, de l’égalité des chances et de l’inclusion. Nous célébrons nos différences car nous sommes convaincus que les qualités visibles et invisibles de chaque Mirakl Worker sont une source de force et d’innovation. Dans le cadre de cet engagement, nous étudions toutes les candidatures sans distinction de : genre, ethnicité, religion, orientation sexuelle, handicap, âge ou toute autre caractéristique protégée par la loi.
Show more
Show less","{'ProgLanguage': ['Python', 'Scala', 'R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': ['Spark', 'Databricks'], 'MachingLearning': ['TensorFlow', 'PyTorch'], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': ['AWS'], 'DevTools': ['Git'], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': ['Airflow'], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['ML', 'Machine Learning'], 'FrSoftSkills': ['Collaboration'], 'EnSoftSkils': ['Collaboration']}","{'JobDetail': [], 'TypeContract': ['CDI'], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's', '3', '3', '3']}"
LinkedIn,Senior Data Scientist - Deep Learning (x/f/m) - AI Teams,Doctolib,"Paris, Île-de-France, France",https://fr.linkedin.com/jobs/view/senior-data-scientist-deep-learning-x-f-m-ai-teams-at-doctolib-3778200205?position=21&pageNum=0&refId=EGCcUYgUshGnwQGGB%2BWgjg%3D%3D&trackingId=scc4mYT%2BeM%2F%2BUwLPDdTiFg%3D%3D&trk=public_jobs_jserp-result_search-card,"What You’ll Do
At Doctolib, we're on a mission to transform the way healthcare is delivered by leveraging the power of AI. As a Data Scientist, you'll play a critical role in developing and implementing cutting-edge AI solutions that will enable us to create an AI medical assistant that will support the Healthcare Professionals in their day to day job.
In this role, you'll have the opportunity to work with a team of talented data scientists, software engineers, machine learning engineers and healthcare professionals to develop and deploy AI models that will have a real impact on people's lives.
Doctolib is looking for a Senior Data Scientist to join our dedicated feature team in charge of shaping the new consultation experience powered by a medical assistant.
Let’s make a direct impact of your work with easy access to final users (practitioners) or subject matter experts to empower our Clinical Product with AI.
Your responsibilities include but are not limited to:
Create, find or adapt model architecture, annotation or validation strategies to improve our speech recognition, summarization and medical data structuration engines
Implement your ideas and test them
Deploy your algorithms in production guided by our ML platform team
Measure the uplift and continuously improve your approach
Who You Are
If you don’t meet all the requirements below but believe this opportunity matches your expectations and experience, we still encourage you to apply!
You could be our next team mate if you:
Have analytical skills, are result oriented and user first
Have 3 years of experience in the domain or shorter but with significant contribution (papers, open source)
Are proficient in Deep Learning framework: Pytorch or Tensorflow
Have knowledge of the latest NLP architecture (Transformer, LLM) and methods (fine tuning, distillation…)
Now, it would be fantastic if you:
Have already launched large scale model training
Have experience in collaborating with end users to refine your modeling approach
What We Offer
Employee share plan for every Doctoliber (BSPCE)
Free Health Insurance for you & your family
Quarterly or monthly bonus (based on your position)
Up to 14 days of RTT
Transparent internal mobility opportunities you're welcome to apply for
Parental care program (1 month off in addition to the legal parental leave and 0,5 days off per child when the school starts)
Solidarity Days (2 days per year to help health charities and create a positive social impact)
Wellbeing program (free mental health and coaching offer with our partner moka.care)
A flexible workplace policy offering both hybrid and office-based mode
Flexibility days allowing to work in EU countries and the UK 10 days per year
Lunch voucher with Swile card
Work Council subsidy to refund part of sport club membership or creative class
Bicycle subsidy
Reimbursement of public transportation
Relocation support for international mobilities
Slean voucher for home-office furniture
The interview process
HR Screen
Interview with 2 members of the Data Science team
Case Study & Case restitution
Final interview with the DS Director
At least one reference check
Criminal background check
Job details
Permanent position
Full Time
Workplace : Paris area
Start date: asap
Remuneration : fix + bonus on objectives (according to your profile)
At Doctolib, we believe in improving access to healthcare for everyone - regardless of where you come from, what you look like. This translates into our recruitment process: Doctolib is an equal opportunity employer. We don't just accept diversity at Doctolib, we respect and celebrate it!
The more diverse ideas are heard, the more our product will truly improve healthcare for all. You are welcome to apply to Doctolib, regardless of your gender, religion, age, sexual orientation, ethnicity, disability, or place of origin. If you have a disability, let us know if there's any way we can make the interview process smoother for you!
All the information transmitted via this form is processed by Doctolib for the purpose of managing applications. For more information on how Doctolib processes your application data, click
here
.
If you wish to exercise your rights or if you have any questions about the processing of your data, you can write to us at
hr.dataprivacy(at)doctolib.com
.
Show more
Show less","{'ProgLanguage': ['R', 'Go'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': ['TensorFlow', 'PyTorch'], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['ML', 'Machine Learning'], 'FrSoftSkills': [], 'EnSoftSkils': ['Flexibility']}","{'JobDetail': ['Full', 'Senior'], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's']}"
LinkedIn,Data scientist H/F,Manpower,Greater Saint-Etienne Metropolitan Area,https://fr.linkedin.com/jobs/view/data-scientist-h-f-at-manpower-3909184596?position=22&pageNum=0&refId=EGCcUYgUshGnwQGGB%2BWgjg%3D%3D&trackingId=tDjvqXV9XJ%2FK4RBewZZGUQ%3D%3D&trk=public_jobs_jserp-result_search-card,"Vous le saviez ?
​Le métier de DATA SCIENTIST H/F a été élu le « métier le plus sexy du XXIe siècle », par le Harvard Business Review !
​
Rejoignez donc une équipe passionnée et dynamique au sein d'une entreprise incontestée des systèmes automatisés et d'énergie, qui repousse constamment les limites de la technologie et en pleine croissance !
Les missions
En tant que Data Scientist H/F, vous êtes sensibilisés aux risques éventuels et vous pouvez envisager de mettre en place des mesures adéquates pour sécuriser les données et les systèmes contre les menaces.
Vos missions seront donc :
Rassemblement, purification et manipulation d'ensembles de données massifs provenant de diverses sources telles que des bases de données internes et externes, des API et des données non structurées.
Conception et implémentation de modèles prédictifs et d'algorithmes d'apprentissage automatique pour résoudre des défis commerciaux complexes.
Réalisation d'analyses statistiques approfondies afin d'identifier des tendances, des schémas et des insights significatifs.
Collaboration étroite avec les équipes interfonctionnelles pour comprendre leurs besoins en données et proposer des solutions analytiques.
Création de tableaux de bord interactifs, de visualisations de données et de rapports pour une communication efficace des résultats d'analyse aux parties prenantes.
Veille constante sur les avancées technologiques en science des données et proposition d'améliorations continues pour les processus et méthodologies existants.
Le profil
Et si on parlait de vous...
​Vous disposez de qualifications dans les domaines des sciences des données, de l'informatique, des mathématiques, des statistiques, de l'économie, de l'informatique, de la gestion, de l'ingénierie industrielle ou dans des domaines connexes.
Vous avez une expérience pertinente dans ce domaine.
Vous êtes familier avec les concepts de collecte, d'extraction et d'analyse de données.
Vous possédez des compétences analytiques et êtes capable de travailler en équipe.
Vous êtes capable de présenter des informations complexes de manière claire et compréhensible.
Vous maitrisez les langages de programmation courants tels que Python, R ou SQL ainsi que l'anglais professionnel.
Vous possédez des compétences avancées en analyse statistique et en modélisation prédictive.
Vous êtes doté d'une expérience pratique avec les bibliothèques et les frameworks d'apprentissage automatique tels que TensorFlow, Scikit-Learn ou PyTorch.
Conditions & avantages :
CDI Temps plein
Déplacements à prévoir en France et à l'international (EMEA Germany, Italy, Spain, UK) selon besoin de l'activité
Salaire ouvert fonction de vos prétentions salariales, adaptable au profil !
Statut cadre forfait jour
RTT
Tickets restaurant
Participation et intéressement
Vous vous reconnaissez ?
N'hésitez plus, postulez !!
Show more
Show less","{'ProgLanguage': ['Python', 'R', ' R ', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R', ' R '], 'BigData': [], 'MachingLearning': ['Scikit-Learn', 'TensorFlow', 'PyTorch'], 'DataSerialization': [], 'DataVisualization': ['Tableau'], 'Statistics': ['Statistiques'], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Statistiques'], 'FrSoftSkills': ['Communication', 'Collaboration'], 'EnSoftSkils': ['Communication', 'Collaboration']}","{'JobDetail': ['Temps plein'], 'TypeContract': ['CDI'], 'Salary': ['Salaire'], 'Level': [], 'Experience': ['a', 'n', 's']}"
LinkedIn,Data Scientist H/F,Harmonie Mutuelle,"Rennes, Brittany, France",https://fr.linkedin.com/jobs/view/data-scientist-h-f-at-harmonie-mutuelle-3903667706?position=23&pageNum=0&refId=EGCcUYgUshGnwQGGB%2BWgjg%3D%3D&trackingId=ybUIyKMl%2FSxeIDx9l%2BRdgg%3D%3D&trk=public_jobs_jserp-result_search-card,"Vous êtes en quête d'une nouvelle aventure professionnelle collective et porteuse de sens ?
Vous voulez un parcours qui vous ressemble ? Vous avez envie d'évoluer dans un
environnement de travail épanouissant fondé sur la confiance, la diversité et l'égalité des
chances ?
Vous êtes au bon endroit ! Ensemble, nous pouvons faire la différence.
Le poste :
Nous opérons notre transformation digitale et renforçons le besoin de pilotage de nos flux et activités au sein de la Direction des Services et de la Satisfaction Clients. Dans ce cadre, nous recherchons un(e) Data Scientist pour renforcer l'équipe Pilotage et Analyse Data Science. Parmi nos sujets : analyser les activités des centres de gestion, mesurer l'efficacité des actions de digitalisation, robotisation et dématérialisation, analyser et détecter les fraudes à la mutuelle, modéliser des dimensionnements de flux et d'équipes...
Vos missions principales :
Vous participez au développement de cette équipe avec pour mission principale la production opérationnelle d'algorithmes data science de détection de fraude :
- Exécuter des algorithmes existants, monitorer, valider les productions
- Maintenir ces modèles mathématiques. Suivre leurs performances réelles
- Collecter l'ensemble des informations (hypothèses, roadmap, projet, nouvelles données) nécessaires à l'amélioration continue des modèles et au développement de nouveaux
- Explorer et croiser les données, à des fins d'investigation et de détection unitaires de cas de fraudes
- Interpréter les données collectées, structurer et partager les résultats
En complément de cette activité, vous interviendrez sur les missions suivantes :
- Participer aux analyses de performances et de pilotage de cette activité globale de gestion de la fraude
- Intervenir sur des projets transverses au sein de l'équipe et d'Harmonie Mutuelle (datalab, analyse d'impact...)
Le profil recherché :
Issu(e) d'une formation Bac +5 avec une spécialisation en Statistiques / Econométrie / Analyse de données, vous avez au moins 2 ans d'expérience en data science. Vous maitrisez les techniques de data mining, machine learning, modélisations supervisées ou non et le pragmatisme.
Vous êtes à l'aise sous SAS, SQL, et Python.
Vous savez et aimez développer. Vous avez une appétence et expérience sur les sujets d'investigation de fautes/fraudes à impact directs sur notre société.
Vous êtes curieux(se), rigoureux(se) et doté(e) d'un bon esprit d'analyse et de synthèse. Vous êtes force de proposition, autonome, dynamique, innovant, créatif.
Vous aimez le travail en équipe.
Une connaissance des métiers de la mutuelle serait un plus.
Infos complémentaires :
- 22, 5 jours de RTT par an
- Des horaires flexibles pour la majorité des postes
- Jusqu'à 3 jours de télétravail par semaine (à partir de 6 mois d'ancienneté)
- Carte déjeuner et CSE (enveloppes loisirs, culture, avantages vacances...)
- Compte Epargne Temps
- Forfait mobilité durable : jusqu'à 300 € par an (cumulable avec le remboursement de l'abonnement aux transports en commun, dans la limite de 500 Euros au total)
- Contrat collectif santé et prévoyance
- PEE et Retraite
- Prime d'intéressement
Show more
Show less","{'ProgLanguage': ['Python', 'R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': ['Statistiques'], 'CloudComputing': [], 'DevTools': ['Git'], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Machine Learning', 'Statistiques'], 'FrSoftSkills': [], 'EnSoftSkils': []}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's', '2', '2', '2']}"
LinkedIn,Data Scientist,Withings,"Paris, Île-de-France, France",https://fr.linkedin.com/jobs/view/data-scientist-at-withings-3888804341?position=24&pageNum=0&refId=EGCcUYgUshGnwQGGB%2BWgjg%3D%3D&trackingId=3YkA1XkINgfX2cdtUbg6sQ%3D%3D&trk=public_jobs_jserp-result_search-card,"Vos missions
L'équipe Machine Learning est responsable du développement de tous les algorithmes de prédiction des produits Withings. Intégré.e en son sein, tu auras les responsabilités suivantes:
Recherche algorithmique pour analyser les données pertinentes et les partager avec l’équipe
Réalisation de prototypes par la mise en pratique des méthodes retenues
Implémentation de services sur la plateforme / produits Withings, en tenant compte des contraintes de ressources et de temps d’exécution
Mise en avant de nouvelles fonctionnalités pour les applications et produits Withings
Maintien du lien avec les équipes de Recherche Appliquée et de Développement Produit pour comprendre et exploiter les données recueillies
REQUIREMENTS
Formation Bac+5 type grande école d’ingénieur ou équivalent
Un
doctorat
dans un domaine connexe est très apprécié
Une première expérience réussie dans le domaine du Machine Learning, de l'algorithmie appliqué aux données de santé ou à l'embarqué est fortement appréciée
Fortes compétences informatiques : calculs scientifiques, Python...
Rigueur, autonomie, prise d'initiatives, curiosité...
Connaissances en traitement de signal, C/C++ appréciées
Maîtrise parfaite de la communication en français et en anglais, aussi bien à l’écrit qu’à l’oral
Rejoindre l’aventure Withings, c’est :
Intégrer un des pionniers et leaders mondiaux de la santé connectée, plusieurs fois primé au Consumer Electronic Show
Contribuer à des projets innovants et ambitieux pour la santé de demain dans un environnement agile et en constante évolution
Intégrer une entreprise internationale, membre de la FrenchTech 120, dont les équipes sont basées à Issy-les-Moulineaux, Boston, Hong-Kong et Shenzhen
Participer à l’amélioration continue de nos produits et services en les bêta-testant avant leur sortie, notamment lors de nos nombreuses sessions sportives entre collègues
Bénéficier de nombreux avantages : Stock Options, smartphone et ordinateur de votre choix, réductions pour des activités culturelles et sportives, restaurant d’entreprise, et bien plus encore
Participer à la Withings Med Academy en assistant à des conférences de professionnels de santé afin de renforcer ses connaissances dans le domaine médical
Collaborer avec des collègues passionnés et célébrer ensemble chacune de nos réussites !
Toutes les candidatures reçues sont étudiées indépendamment de l’origine ethnique, des croyances, de la religion, du genre, de l’orientation sexuelle ou de la santé des candidats. Withings aspire à offrir et garantir l’égalité des chances aux candidats et seules les personnes habilitées (RH et Management) auront accès aux informations concernant votre candidature.
Show more
Show less","{'ProgLanguage': ['Python', 'C++', 'R', 'Go'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Machine Learning'], 'FrSoftSkills': ['Communication'], 'EnSoftSkils': ['Communication', 'Initiative']}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': ['Bac+5'], 'Experience': ['a', 'n', 's']}"
LinkedIn,APPRENTI.E DATA SCIENTIST,Akademija Oxford,"Val-d'Oise, Île-de-France, France",https://fr.linkedin.com/jobs/view/apprenti-e-data-scientist-at-akademija-oxford-3917868440?position=25&pageNum=0&refId=EGCcUYgUshGnwQGGB%2BWgjg%3D%3D&trackingId=w%2BFbe%2BY6pBjPKB97PgOBQg%3D%3D&trk=public_jobs_jserp-result_search-card,"Un acteur majeur et en pleine croissance de la Biologie Médicale en Ile de France, recrute un.e Apprenti.e Data Scientist en alternance. Ce contrat d’apprentissage d’une durée de 12 mois débute en Octobre 2021.
Show more
Show less","{'ProgLanguage': ['R'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': [], 'FrSoftSkills': [], 'EnSoftSkils': []}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's']}"
LinkedIn,Data Scientist H/F,Lincoln France,"Île-de-France, France",https://fr.linkedin.com/jobs/view/data-scientist-h-f-at-lincoln-france-3892490370?position=26&pageNum=0&refId=EGCcUYgUshGnwQGGB%2BWgjg%3D%3D&trackingId=lb5IaStMsmncOHPm55zGcw%3D%3D&trk=public_jobs_jserp-result_search-card,"CDI
📊
4 ans minimum
Chez Lincoln
, nous formons une communauté d'innovateurs passionnés qui redéfinissent l'analyse de données depuis
plus de 30 ans
. En tant que
Pure Player Data
, notre expertise est reconnue dans les domaines
de la Modern BI, du Big Data et de la Science des données
.
Notre mission ?
Transformer les données en solutions concrètes pour nos clients grands comptes dans divers secteurs tels que la banque, le retail, les télécoms, l'industrie, la santé, etc.
Description du poste
Nous recherchons un
Data Scientist H/F
pour accompagner nos clients dans leurs projets stratégiques.
Vos missions
Collecter, nettoyer et préparer les données pour l'analyse.
Concevoir, développer et mettre en œuvre des modèles prédictifs et analytiques en utilisant des techniques avancées d'apprentissage automatique et de science des données.
Analyser les résultats des modèles et fournir des insights exploitables aux équipes clients.
Collaborer avec les équipes interfonctionnelles pour comprendre les besoins commerciaux et recommander des solutions basées sur les données.
Prérequis :
Solides compétences en programmation (
Python, R, SQL, etc.)
et en manipulation de données.
Expérience pratique avec des frameworks et des bibliothèques d'apprentissage automatique (
TensorFlow, PyTorch, Scikit-learn
,
etc
.).
Maîtrise des techniques avancées d'analyse de données, y compris l'apprentissage automatique, l'apprentissage profond, la vision par ordinateur, le traitement du langage naturel, etc.
Expérience de travail en
méthode Agile
pour la gestion de projet et le développement de solutions.
Capacité à travailler de manière autonome et en équipe.
Excellentes compétences en communication et en présentation.
Les plus du poste
Environnement Collaboratif
: projets innovants favorisant le partage des connaissances.
Accompagnement individualisé et de proximité
: formations certifiantes, attribution d’un Career Manager pour vous orienter dans votre trajectoire professionnelle, opportunités d’évolution de carrière.
Flexibilité du Travail
: Télétravail et horaires flexibles pour votre équilibre vie professionnelle-personnelle.
Rémunération Compétitive
: Salaire compétitif avec des avantages sociaux attrayants.
Mobilité
: Possibilité de mobilité à Lille, Lyon ou Aix-en-Provence offrant des expériences diversifiées au sein de Lincoln.
Notre processus de recrutement :
Un entretien RH (1h) et entretien technique (1h)
Cette annonce n’est pas faite pour vous si :
Vous êtes freelance et vous comptez le rester !
Toujours là ? Postulez et rejoignez nos
400 experts en Data
😉.
Show more
Show less","{'ProgLanguage': ['Python', 'R'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': ['Scikit-Learn', 'TensorFlow', 'PyTorch'], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Big Data'], 'FrSoftSkills': ['Communication', 'Flexibilité'], 'EnSoftSkils': ['Communication']}","{'JobDetail': [], 'TypeContract': ['CDI'], 'Salary': ['400'], 'Level': [], 'Experience': ['a', 'n', 's', '4', '4', '4']}"
LinkedIn,Data Scientist H/F,MERITIS,"Île-de-France, France",https://fr.linkedin.com/jobs/view/data-scientist-h-f-at-meritis-3869246366?position=27&pageNum=0&refId=EGCcUYgUshGnwQGGB%2BWgjg%3D%3D&trackingId=d8lTOx6mLHUmX0a4d6rR7A%3D%3D&trk=public_jobs_jserp-result_search-card,"Nous recherchons un
Data Scientist
pour intervenir dans le cadre d'un
projet de détection de document.
Vos missions :
Sujet de
fraude documentaire:
la problématique est de détecter si un document (RIB ou pièce d’identité) a été manipulé (montage, remplacement de la photo d’identité, changement du nom/prénom, ou de l’IBAN etc).
Les technos connues utilisées:
Python avec les libs/framework suivants : pytorch, jupyterlab, pandas
Modèles : layoutLM (techno à priori assez récente), yolo, resnet (classique), docTR (ocr)
Connaitre les transformers
Autre : Labelstudio
Ce poste est-il fait pour vous
? :
Vous êtes diplômé d'un
Bac +5
et justifiez d'
au moins 4 ans d'expérience
Vous êtes
proactif et autonome ​
Vous aimez travailler
au contact de plusieurs équipes métiers
Connaissance du secteur de l'assurance obligatoire
Descriptif de l’entreprise :
​
Meritis est un cabinet de conseil, pilotage et développement IT fondé en 2007 présent à Paris, Sophia-Antipolis, Aix-en-Provence, Montpellier, Toulouse, Nantes... Et bientôt sur de nouveaux territoires ! Notre mission ? Connecter les meilleurs talents aux entreprises pour leur donner un temps d’avance.​
Nous accompagnons nos clients dans l’intégralité de leurs besoins en transformation numérique à travers de nombreux domaines d’expertises : Software Engineering, Finance, Pilotage de projets, Devops, Data, Cloud, Cybersécurité ou encore Agilité.​
Intervenant aussi bien dans les secteurs de la Banque, de l'Assurance, des Télécommunications que de l'Industrie ou des Transports, aujourd'hui 40% des entreprises du CAC40 sont clientes Meritis.​
Fort de nos valeurs d’exigence, d’humilité, de bienveillance et de proximité, nous comptons aujourd’hui plus de 900 collaborateurs.​
Nous mettons un point d’honneur à être proche de nos collaborateurs et à les accompagner de manière individualisée quelles que soient leurs fonctions dans l’entreprise.
Certifiée Great Place To Work depuis 2013, notre conception du bien-être au travail va bien au-delà d'un simple label, ce sont nos collaborateurs qui en parlent le mieux : https://www.glassdoor.fr/Avis/Meritis-Avis-E1163008.htm.​
Vos différences sont nos atouts. C’est pourquoi Meritis est engagée en faveur de la diversité et de la non-discrimination. Tous nos métiers sont accessibles aux personnes en situation de handicap. Si vous avez une question ou pensez être victime ou témoin d’une discrimination, vous pouvez contacter ethiquegroup@meritis.fr. »
Show more
Show less","{'ProgLanguage': ['Python', 'R'], 'DataBase': [], 'DataAnalytics': ['Pandas', 'R'], 'BigData': [], 'MachingLearning': ['PyTorch'], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['DevOps', 'Cloud'], 'FrSoftSkills': ['Communication'], 'EnSoftSkils': ['Communication']}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's', '4', '4', '4']}"
LinkedIn,Data Scientist: Flexible working,SoftwareOne,"Levallois-Perret, Île-de-France, France",https://fr.linkedin.com/jobs/view/data-scientist-flexible-working-at-softwareone-3872563771?position=28&pageNum=0&refId=EGCcUYgUshGnwQGGB%2BWgjg%3D%3D&trackingId=yznFN8w%2FrSMaXZdjwzCkOg%3D%3D&trk=public_jobs_jserp-result_search-card,"Why SoftwareOne?
SoftwareOne is a leading global software and cloud solutions provider that is redefining how companies build, buy and manage everything in the cloud. By helping clients to migrate and modernize their workloads and applications – and in parallel, to navigate and optimize the resulting software and cloud changes – SoftwareOne unlocks the value of technology. The company’s 8,900 employees are driven to deliver a portfolio of 7,500 software brands with sales and delivery capabilities in 90 countries. Headquartered in Switzerland, SoftwareOne is listed on the SIX Swiss Exchange under the ticker symbol SWON. Visit us at https://www.softwareone.com/en
The role
DATA Scientist
The primary focus for a candidate will be in applying different techniques (data mining/statistical analysis/build prediction systems/recommendation systems) using large company data sets to find opportunities for services and products and using models to test the effectiveness of different courses of action. The Candidate must have strong experience using a variety of data mining/data analysis methods, using a variety of data tools, building and implementing models, using/creating algorithms and creating/running simulations.
Work with business cases to identify opportunities for leveraging company data to drive business solutions.
Mine and analyze data from company databases to drive optimization and improvement of product development and sales techniques
Assess the effectiveness and accuracy of new data sources and data gathering
Extending company’s data with third party sources of information when needed
Use predictive modeling to increase revenue generation, ad targeting and other business outcomes.
What We Need To See From You
Core:
Analyze business cases and identify data sources (internal/external) and data mining/analysis methods to use
Develop a normalization engine to execute cleansing/deduplication for a raw data through ETL process for data sources
Create, train and test predictive models to solve defined business cases
Develop algorithms to apply to data sets
Design data structure models for collected data
Facilitate the build of a solution from PoC to production
Work with business owners to gather additional information about business cases
Job Specific:
Work with Google Cloud data and AI tools
Be ready to work in agile style (daily, sprint planning, sprint review, retrospective)
Work in an environment that adapts quickly to creative change using agile principles
Actively work with different development groups inside of organization
Be ready to adapt a new tool/library/technology/platform
Desirable Skills:
Fluent in French and English
At least 4 years experience in Machine learning models creation
Master’s in Statistics, Mathematics, Computer Science preferred
Professional Machine learning engineering certification
Experience with common data science toolkits and libraries, such as pandas, keras, scipy, scikit, tensorflow, NumPy etc
Knowledge and interest in the following:
prediction models, Vertex AI, Tenserflow, BigQuery ML, Python,
natural language processing, deep learning models, dataPROC, Hadoop, SQL
Experience using statistical computer languages namely Python to manipulate data and draw insights from large data sets
Strong knowledge and experience using SQL language
Experience with C++/C# and Java as a plus
Background in technology or professional services preferably in one or more of the domains of GCP and Security,
Strong understanding of consulting business
Strong structural work methods, multitasking and time management skills
Self-driven independent work ethics that drives internal and external accountability
May require periodic travel for workshops
Job Function
Software & Cloud Services
Show more
Show less","{'ProgLanguage': ['Python', 'Java', 'C++', 'C#', 'R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['Pandas', 'NumPy', 'R'], 'BigData': ['Hadoop'], 'MachingLearning': ['TensorFlow', 'Keras'], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': ['Statistics'], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'DBMS': ['BigQuery'], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['ML', 'Machine Learning', 'Cloud'], 'FrSoftSkills': [], 'EnSoftSkils': ['Time Management', 'Organization']}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's']}"
LinkedIn,Data Scientist,Capital Fund Management (CFM),"Paris, Île-de-France, France",https://fr.linkedin.com/jobs/view/data-scientist-at-capital-fund-management-cfm-3911800992?position=29&pageNum=0&refId=EGCcUYgUshGnwQGGB%2BWgjg%3D%3D&trackingId=0kAZtI7%2Fd%2Fwy4lWWwJROOg%3D%3D&trk=public_jobs_jserp-result_search-card,"ABOUT CFM
Founded in 1991, we are a global quantitative and systematic asset management firm applying a scientific approach to finance to develop alternative investment strategies that create value for our clients.
We value innovation, dedication, collaboration and the ability to make an impact and together we create an environment for talented and passionate experts in research, technology and business to explore new ideas and challenge assumptions.
ABOUT THE ROLE
The context :
Data is the fuel that powers our investment strategies: intraday price dynamics are used to better our investment decisions; buy/sell intents of market participants help to trade at the best available price… Cfm Data team is in charge of preparing the data to make quant research easier and trading more reliable.
The position
As a Data Scientist and Tick Data Specialist, your involvement will be crucial to the effectiveness of our strategies. You will be tasked with identifying and specifying new input features from tick data to fuel our alpha predictor, constructing data pipelines, and guaranteeing their smooth functioning. This role necessitates strong collaboration with researchers, primarily aimed at furnishing them with essential data and tools to refine our trading strategies.
Key Responsibilities:
You collaborate with the research team to innovate and introduce new predictive features,
You provide functional and technical support to quantitative researchers,
You design and develop data pipelines,
You contribute to the enhancement of our platform tooling.
SKILLSET REQUIREMENTS/QUALIFICATIONS
You boast significant experience in financial markets, with a tenure of 7 years or more.
You have a comprehensive expertise in Matching Engines, Orderbooks, and High-Frequency Data,
You demonstrate recognized expertise in data science with a thorough mastery of its tools.
Your familiarity with big data technologies like Spark or Dask, coupled with proficiency in machine learning, would be highly advantageous.
Experience with C++ is considered an additional asset.
You exhibit a strong enthusiasm for technology.
As a collaborative team player, you excel in communication, particularly with quant teams.
Proficiency in French is an additional advantage.
EQUAL OPPORTUNITIES STATEMENT
We are continuously striving to be an equal opportunity employer and we prohibit any discrimination based on sex, disability, origin, sexual orientation, gender identity, age, race, or religion. We believe that our diversity, breadth of experience, and multiple points of view are among the leading factors in our success.
CFM is a signatory of the Women Empowerment Principles
FOLLOW US
Follow us on Twitter and LinkedIn or visit our website to find out more about CFM.
Show more
Show less","{'ProgLanguage': ['C++', 'R'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': ['Spark'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': ['Teams'], 'Other': ['Big Data', 'Machine Learning'], 'FrSoftSkills': ['Communication', 'Collaboration'], 'EnSoftSkils': ['Communication', 'Collaboration']}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's']}"
LinkedIn,Data scientist F/H,METEOJOB by CleverConnect,"Rontignon, Nouvelle-Aquitaine, France",https://fr.linkedin.com/jobs/view/data-scientist-f-h-at-meteojob-by-cleverconnect-3916294538?position=30&pageNum=0&refId=EGCcUYgUshGnwQGGB%2BWgjg%3D%3D&trackingId=yKbrAtaAN4yOVp8j1m8ELA%3D%3D&trk=public_jobs_jserp-result_search-card,"Entreprise
Cabinet de recrutement de dimension internationale, bénéficiant de l'expérience d'un grand Groupe RH, S&you est spécialisé dans le recrutement d'Experts, Cadres et Métiers du tertiaire. Nos 50 consultants expérimentés mettent en œuvre tout notre savoir-faire pour vous accompagner au mieux dans vos projets (recrutement, bilan professionnel, coaching, formation…). La relation de confiance que nous créons avec nos candidats et nos clients représente pour nous le facteur-clé de la performance.
Description Du Poste
Votre profil Vous disposez des compétences et aptitudes nécessaires à l'appropriation du périmètre du poste :
Formation supérieure Bac + 5 (statistiques, mathématiques appliquées …)
Expérience significative (2 ans alternance incluse) en qualité de data scientist / data analyst incluant idéalement une expérience en secteur assurantiel.
Maîtrise / connaissance de l'environnement technique : Python, SQL, R, algorithmes et frameworks, machine learning, RPA, datavisualisation (Power BI, Tableau)
Curiosité, discernement, agilité et esprit d'initiative : appropriation de données complexes, compréhension de problématiques transverses, veille technologique, proposition de solutions
Description Du Profil
Notre client est un acteur clé du secteur assurantiel dont les 250 collaborateurs accompagnent les compagnies et intermédiaires d'assurance sur l'ensemble des sujets intéressant la profession (information, concertation, mise en œuvre) : assurance de biens et responsabilités, assurance de personne, réassurance, co-assurance, évolutions réglementaires et conventionnelles, maîtrise des risques, médiation, intermédiation, référentiels …Notre client recrute un.e Data Scientist dans le cadre d'une création de poste (CDI) en vue d'accompagner le développement de sa stratégie Data.
Show more
Show less","{'ProgLanguage': ['Python', 'R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': ['Tableau', 'Power BI'], 'Statistics': ['Statistiques'], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Machine Learning', 'Statistiques'], 'FrSoftSkills': [""Esprit d'initiative""], 'EnSoftSkils': ['Initiative']}","{'JobDetail': [], 'TypeContract': ['CDI'], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's', '2', '2', '2']}"
LinkedIn,Machine Learning Engineer,HackerPulse,France,https://fr.linkedin.com/jobs/view/machine-learning-engineer-at-hackerpulse-3917868826?position=32&pageNum=0&refId=EGCcUYgUshGnwQGGB%2BWgjg%3D%3D&trackingId=dWrca%2F%2BwO%2B%2FVqKQBY0Zm1A%3D%3D&trk=public_jobs_jserp-result_search-card,"Showcase your software engineering talents using ML-powered profiles. Loved by 11k+ engineers! Backed by Antler.
The Role
You Will Be Responsible For
Developing scripts to process structured and unstructured data.
Recommending, developing and implementing ways to improve data reliability, efficiency and quality.
Supporting translation of data business needs into technical system requirements.
Working with stakeholders to understand needs in order with respect to data structure, availability, scalability and accessibility.
Developing high-quality code to build and deploy machine learning models.
Ideal Profile
You possess a degree in Computer Science, Applied Mathematics, Engineering or related field.
You have at least 1 year experience, ideally within a Data Engineer role.
Demonstrated experience working with large and complex data sets as well as experience analyzing volumes of data.
You are a strong networker & relationship builder
You pay strong attention to detail and deliver work that is of a high standard
You are a self-starter and demonstrate a high level of resilience
What's on Offer?
Great work environment
Excellent career development opportunities
Leadership Role
Show more
Show less","{'ProgLanguage': ['Scala', 'R'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['ML', 'Machine Learning'], 'FrSoftSkills': ['Leadership'], 'EnSoftSkils': ['Leadership']}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's']}"
LinkedIn,Data scientist H/F,MP DATA,"Clermont-Ferrand, Auvergne-Rhône-Alpes, France",https://fr.linkedin.com/jobs/view/data-scientist-h-f-at-mp-data-3904074177?position=33&pageNum=0&refId=EGCcUYgUshGnwQGGB%2BWgjg%3D%3D&trackingId=BeR7584K1zkFfnapkD4q4Q%3D%3D&trk=public_jobs_jserp-result_search-card,"MP DATA est une société spécialisée dans l’acquisition, le traitement, et la valorisation des données. Depuis sa création en 2015, MP DATA accompagne ses clients, majoritairement industriels, dans le management de leur performance et l’exploitation de leur donnée.
Les collaborateurs, tous issus de grandes écoles, incarnent au quotidien les valeurs d’Excellence, de Partage et d’Engagement. Ils associent savoir-faire technique, méthodologie et passion et mettent leurs compétences au service de missions et projets au sein de grands groupes français.
MP DATA accompagne ses clients sur toute la chaine au travers de 3 pôles d’expertise : Conseil et Stratégie, Infrastructure & CloudOPS, Data Science.
Nous recherchons un(e) Data Scientist passionné(e) pour rejoindre notre équipe dynamique.
En tant que membre clé du pôle Data Science de notre client, un grand acteur du secteur automobile, vous serez chargé(e) d'analyser, interpréter et exploiter les données pour fournir des solutions innovantes à nos clients.
Conception et mise en œuvre de modèles prédictifs et d'algorithmes avancés.
Analyse approfondie des données pour identifier des tendances et des opportunités.
Collaboration étroite avec les équipes clients pour comprendre leurs besoins et définir des solutions sur mesure.
Participation active à la veille technologique et à l'amélioration continue de nos pratiques en Data Science.
Profil :
Diplôme
ingénieur Grande École
en Data Science, Statistiques, Informatique ou domaine connexe.
Expérience pratique dans le développement et l'application de modèles prédictifs,
Maîtrise des langages de programmation tels que Python,
Excellentes compétences analytiques et capacité à traduire des résultats complexes en recommandations claires,
Forte aptitude à travailler en équipe et à communiquer efficacement.
Show more
Show less","{'ProgLanguage': ['Python', 'R', 'Go'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': ['Statistiques'], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Statistiques', 'Cloud'], 'FrSoftSkills': ['Collaboration'], 'EnSoftSkils': ['Collaboration']}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's']}"
LinkedIn,"Data Scientist - Python (Mid-senior, Senior)",Pathway,"Paris, Île-de-France, France",https://fr.linkedin.com/jobs/view/data-scientist-python-mid-senior-senior-at-pathway-3887683294?position=34&pageNum=0&refId=EGCcUYgUshGnwQGGB%2BWgjg%3D%3D&trackingId=1IFamQDNOslLqGqnZhfbtg%3D%3D&trk=public_jobs_jserp-result_search-card,"About Pathway
Deeptech start-up, founded in March 2020.
Our primary developer offering is an ultra-performant Data Processing Framework (unified streaming + batch) with a Python API, distributed Rust engine, and capabilities for data source integration & transformation at scale (Kafka, S3, databases/CDC,...)
The single-machine version is provided on a free-to-use license (`pip install pathway`)
Major data use cases are around event-stream data (including real-world data such as IoT), and graph data that changes over time
Our enterprise offering is currently used by leaders of the logistics industry, such as DB Schenker or La Poste, and tested across multiple industries. Pathway has been featured in Gartner's market guide for Event Stream Processing
Learn more at http://pathway.com/ and https://github.com/pathwaycom/
Pathway is VC-funded, with amazing BAs from the AI space and industry. We have operations across Europe and in the US. We are headquartered in Paris, with significant support from the French ecosystem (BPI, Agoranov, WILCO,...).
The Team
Pathway is built by and for overachievers. Its co-founders and employees have worked in the best AI labs in the world (Microsoft Research, Google Brain, ETH Zurich), worked at Google, and graduated from top universities (Polytechnique, ENSAE, Sciences Po, HEC Paris, PhD obtained at the age of 20, etc...). Pathway's CTO is a co-author with Goeff Hinton and Yoshua Bengio. The management team also includes the co-founder of Spoj.com (1M+ developer users) and NK.pl (13.5M+ users) and experienced growth leader who has scaled companies with multiple exits.
The opportunity
We are currently searching for
Data Scientists
with
experience in the Python stack
, to help explore and discover the most pertinent insights in datasets on spatio-temporal event streams. In this job, statistical rigor and beauty of visualization meet on equal footing.
You Will
be working with spatiotemporal data with advanced schemas (time-changing graph models)/
be designing data cross-sections, proposing analytics metrics and KPI's in line with clients' objectives, selecting clustering algorithms, and preparing visualizations, to enable fast data exploration and insight discovery - all within our product
be designing dashboards in SQL with some Python elements/extensions
be directly helping us with Customer Conversion and Adoption within Customer organizations, by contributing to both deployment instances and ""demonstrators"" of our product, performed on client data sets
work directly with our Product Owner and CTO to propose and implement extensions to our product, based on repetitive client needs
depending on your seniority, implement machine learning algorithms on spatiotemporal event streams and other geospatial data
The results of your work will play a crucial role in proving how our technology can help with compelling industry use cases.
Requirements
You Are
Ready for hands-on contribution to the product, helping to ensure the success of demonstrators for clients, and contribution to product codebase
Intuitive, with good visual taste, and good common sense judgment
Committed to beautiful user-centered design: you know that stories are made for people, and you are willing to listen to what they have to say
Curious at heart and thrilled to work with real-world data, especially spatio-temporal data
Like trains, trucks, cranes, pythons, pandas, and other things that move
Not afraid to switch between the roles of data scientist, data-vis magician, statistician, engineer, and detective, at a moment's notice
Have 2 years+ experience in positions related to Data Science.
Have a very good working knowledge of Python
Know SQL. Are able to work with tables and other data types (arrays, json,...)
Would be able to implement the Transit Node Routing algorithm in Python just based on reading its Wikipedia article
Have experience with git, build systems, and CI/CD
Have at least basic undergrad textbook familiarity with graph algorithms, finite automata, and text (string) search algorithms
Understand statistical concepts, such as correlated random variables, significance, and non-Gaussian noise
Prepared to be quizzed & grilled by the datasets you encounter, everyday. Here are some questions you should be able to answer off the top of your head: what can ""-273.15"" signify; why ""65535"" is a suspicious integer value; how many months does it take a containership to go around the world; and, roughly what order of g-force is attained by an astronaut in a space rocket at liftoff?
Respectful of others
Fluent in English
Bonus Points
Showing a portfolio: code on github, visualization works, a research paper or a PhD thesis with an original statistical / probabilistic analysis or experiment design,..
Successful track-record in Data Science or algorithms contests (Kaggle, Codeforces,...)
Experience in topics linked to logistics/moving assets
Familiarity with some form of GIS software
Familiarity with Pandas, SciPy, NetworkX, and similar tools from the Python stack
Experience in Data Visualization and UX
Some knowledge of French, Polish, or German
Why You Should Apply
Join an intellectually stimulating work environment
Be a pioneer: you get to work with a new type of data processing
Work in one of the hottest data/AI startups in France
Uncover exciting career prospects
Make significant contribution to our success
Join & co-create an inclusive workplace culture
Benefits
Type of contract: Permanent employment contract
Preferable joining date: February 2023. The positions (at least 2) are open until filled
Compensation: annual salary of €50K-€70K (mid) up to €60K-€90K (senior, upper band negotiable) + Employee stock option plan
Location: Remote work from home. Possibility to work or meet with other team members in one of our offices:
Paris Area - Drahi X-Novation Center, Ecole Polytechnique, Palaiseau
Paris - Agoranov (where Doctolib, Alan, and Criteo were born) near Saint-Placide Metro (75006)
Wroclaw - University area
Permanent residence will be required in France or Poland, exceptional candidates will be considered anywhere in the EU.
If you meet our broad requirements but are missing some experience, don't hesitate to reach out to us.
Note
: CS & engineering school students with exceptional profiles and/or strong motivation to join Pathway are invited to apply for Data Science internships. (Minimum duration: 5-6 months, remuneration level: €1500 / month.)
Show more
Show less","{'ProgLanguage': ['Python', 'R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['Pandas', 'R'], 'BigData': [], 'MachingLearning': [], 'DataSerialization': ['Json'], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git'], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Machine Learning', 'CI/CD'], 'FrSoftSkills': [], 'EnSoftSkils': ['Organization']}","{'JobDetail': ['Remote', 'Senior'], 'TypeContract': [], 'Salary': ['50K'], 'Level': [], 'Experience': ['a', 'n', 's']}"
LinkedIn,Data Scientist F/H,OUTSCALE,"St.-Cloud, Île-de-France, France",https://fr.linkedin.com/jobs/view/data-scientist-f-h-at-outscale-3891855564?position=35&pageNum=0&refId=EGCcUYgUshGnwQGGB%2BWgjg%3D%3D&trackingId=QUIPYOkgbNqnM3Bn12aBPg%3D%3D&trk=public_jobs_jserp-result_search-card,"OUTSCALE, marque de Dassault Systèmes, est un opérateur souverain et durable de l Expérience en tant que Service qui offre à ses clients des environnements technologiques de confiance.
Nous offrons des expériences uniques grâce au savoir-faire de nos équipes passionnées, qui se reflète notamment par la création de solutions de Business Expériences, le développement de notre propre orchestrateur Cloud, TINA OS, ou encore l obtention de la qualification SecNumCloud.
Notre mission ? Bâtir un monde numérique accessible et meilleur pour tous à travers la création du jumeau virtuel de l organisation.
Nous menons une politique RH engagée et inclusive favorisant le bien-être de nos collaborateur·rices : respect de l équilibre vie privée/vie professionnelle, développement personnel et des compétences professionnelles, onboarding complet
Nous rejoindre, c est partager une passion pour l innovation, des valeurs communes et imaginer ensemble des solutions de confiance pour construire un monde meilleur et durable !
Nous recrutons
un·e
Data Scientist
afin de renforcer notre équipe
Business Experience
.
Vos missions
Analyser des problématiques et proposer des solutions.
Modéliser, implémenter et évaluer des algorithmes.
Traiter des données non structurées.
Optimiser des modèles ML/DL pour la scalabilité, l'efficacité et les performances.
Industrialiser des algorithmes dans les services API.
Déployer des services sur le cloud.
Participer à la rédaction de spécifications et documentations techniques.
Participer à des événements et publications scientifiques.
Stack technique
Python
Frameworks ML/DL (Pytorch)
Architectures de réseaux neuronaux (LLMs)
Implémentation d’algorithmes ML/DL (apprentissage supervisé/non-supervisé)
Votre profil:
Diplômé·e d’un Master en Intelligence Artificielle, Machine Learning.
3 ans d’expérience minimum post-diplôme dans le domaine de l’IA, Data Science, Machine Learning, NLP, Computer Vision.
Vous maîtrisez l’analyse et la transformation des données.
Idéalement, vous avez de l’expérience dans le déploiement des modèles ML/DL sur le cloud.
Motivé·e, organisé·e, curieux·se, vous appréciez travailler en équipe.
La Diversité d’OUTSCALE trouve aussi son expression dans notre politique de recrutement qui privilégie l’égalité des chances, la diversité des individus au sein de nos équipes.
Show more
Show less","{'ProgLanguage': ['Python', 'Scala', 'R', 'Go'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': ['PyTorch'], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['ML', 'Machine Learning', 'Cloud'], 'FrSoftSkills': ['Organisation'], 'EnSoftSkils': []}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's', '3', '3', '3']}"
LinkedIn,Data Scientist (H/F),moOngy Digital Lab,Greater Lille Metropolitan Area,https://fr.linkedin.com/jobs/view/data-scientist-h-f-at-moongy-digital-lab-3888669115?position=36&pageNum=0&refId=EGCcUYgUshGnwQGGB%2BWgjg%3D%3D&trackingId=suQG0RAsX5dpKp3qJC%2FHBQ%3D%3D&trk=public_jobs_jserp-result_search-card,"Web Transition, c’est qui ?
Fondée en 2011,
Web transition
est une entreprise de services numériques opérant sur le marché de l’IT/Digital !
Constituant une part essentielle de
MoOngy Digital Lab
, Web Transition accompagne ses clients grands comptes sur leurs projets de Webmarketing, de Design, Gestion de projet et également en Data !
Notre objectif : nous implanter comme un acteur principal sur le marché de la Transformation Digitale en accompagnant et valorisant les compétences de nos collaborateurs !
Nous sommes convaincus que le succès de MoOngy Digital Lab réside dans la somme des potentiels de nos équipes 🤝
Ton équipe : La tribu Data
Parce qu’il est indispensable que tu puisses partager tes connaissances mais aussi en acquérir de nouvelles, tu feras partie de l’une de nos tribus : celle de la Data. De plus, cela te permettra d’être acteur dans le développement et la stratégie de Web Transition. Ce système de co-réflexion et co-construction est un fondement essentiel chez nous !
Dans cette aventure, tu :
Recueilles, analyses et formalises
les demandes correspondant aux besoins spécifiques de chaque métier/utilisateur,
Contrôles, sélectionnes et valides
les données pertinentes pour l'analyse & s'assurer de la cohérence et de la structuration de celles-ci avant exploitation,
Conçois, mets en œuvre et déploies
des modèles Machine Learning (ML) et Deep Learning (DL) dans un environnement GCP (BigQuery ML/Vertex AI) : qualité, possibilités d'exploitation, suivi de performances et versioning des mis à jour du modèle en production,
Présentes
les résultats des études réalisées auprès de vos différents interlocuteurs et leur donner du sens, en s’appuyant sur des KPIs adaptés, via les outils de visualisation des données et/ou de documentation,
Améliores
l'efficacité de livraison des modèles ML/DL en industrialisant le processus de livraison et en automatisant la préparation des données, l’entraînement des modèles et leur déploiement,
Effectues
une veille technologique et maintenir une connaissance approfondie des dernières technologies liées au ML/IA.
Rejoins-nous si tu as :
Une expérience de 5 ans au minimum dans l'analyse de données/data science, et plus globalement dans le développement des modèles ML et DL & de préférence sur l'écosystème GCP,
Une maîtrise du langage Python et des librairies d’analyse (Pandas, NumPy et Matplotlib) et ML/DL (Scikit-Learn, TensorFlow, PyTorch, XGBoost),
Une connaissance de l’environnement Retail serait un plus !
Ton savoir-être :
Ouvert d’esprit
Respectueux des différences de chacun
Curieux
Proactif
Par où on commence ?
Un premier entretien RH d’1h pour comprendre ton parcours et tes aspirations
Un second entretien de 45 minutes avec l’un de nos Business Manager afin de valider tes compétences et qu’il se projette sur l’une des missions qu’il pourrait te proposer
Un troisième entretien de quelques minutes avec notre responsable d’agence pour te proposer d’intégrer notre superbe Team Web !
3 entretiens en peu de temps, si ton profil correspond tu intègreras très vite nos équipes 😉
Prêt pour embarquer dans notre grande aventure humaine ? Deviens notre futur Weber en postulant à cette offre ! Voici les avantages qui t’attendent en tant que Weber :
🤩 Des collègues incroyables
🏆 Certifiée Great Place to Work
🎮 Des bureaux sympas (où vous serez toujours les bienvenus)
🎉 Des teambuilding et évents tous les mois
💻 Des tributs métiers pour échanger entre Weber du même métier
Des missions chez le client qui sont accompagnées et coachées par ton manager
Un accompagnement dans ton plan de carrière et tes envies de re skilling
🤓 Un catalogue de formations certifiantes ouvert à tous les salariés
🍽️ Une carte tickets restaurant MyEdenred
❤️ Une mutuelle GrasSavoye
🚎 Une prise en charge des frais de transport à 100%
Show more
Show less","{'ProgLanguage': ['Python', 'R'], 'DataBase': [], 'DataAnalytics': ['Pandas', 'NumPy', 'R'], 'BigData': [], 'MachingLearning': ['Scikit-Learn', 'TensorFlow', 'PyTorch', 'XGBoost'], 'DataSerialization': [], 'DataVisualization': ['Matplotlib'], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git'], 'Os': [], 'DBMS': ['BigQuery'], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['ML', 'Machine Learning'], 'FrSoftSkills': [], 'EnSoftSkils': []}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's', '5', '5', '5']}"
LinkedIn,Data Scientist H/F,IT&M STATS,"Île-de-France, France",https://fr.linkedin.com/jobs/view/data-scientist-h-f-at-it-m-stats-3803674187?position=37&pageNum=0&refId=EGCcUYgUshGnwQGGB%2BWgjg%3D%3D&trackingId=sJjMjWlmkfkPy1RECRs2ow%3D%3D&trk=public_jobs_jserp-result_search-card,"IT&M Stats intervient dans le domaine des statistiques, de la programmation et de la data science, principalement dans les secteurs de l’Industrie Pharmaceutique, Cosmétique, dans la Santé et l’Agro-alimentaire et auprès des Banques et Assurances. IT&M Stats est une filiale du Groupe Astek, acteur mondial de l’ingénierie et du conseil en technologies.
Nous basons notre relation sur :
Un respect des collaborateurs et des clients, de leurs aspirations,
Un suivi personnalisé des collaborateurs et des clients,
Une gestion régulière des carrières des collaborateurs,
Des échanges transparents,
Une réactivité, une disponibilité et une écoute permanentes.
Nous recherchons un
Data Scientist
pour intervenir dans le secteur
cosmétique
.
Cela vous intéresse ? Voici la suite !
👇
Maintenance et mise à jour de dashboards de suivi de tests sous PowerBi
Analyser les données générées en interne et externe et réaliser des analyses croisées /meta analyse pour une meilleure compréhension de la performance de nos produits/services
Réaliser des analyses prédictives de la performance cosmétique en fonction de la formulation
Réaliser des interfaces dynamiques sous R Shiny
Ré-analyser et vérifier les analyses statistiques réalisées par les prestataires externes le cas échéant
Contribuer à la mise en place des études et aider le département à l’amélioration des process (Plan d’expérience, calcul du nombre de sujets nécessaires, etc…)
Vous pensez être la perle rare ?
Vous êtes titulaire d’un diplôme de type Bac+5 (Master 2 ou école d’ingénieur) avec une spécialisation en statistiques, mathématiques ou data science
Vous justifiez d’une expérience professionnelle de 2 à 3 ans
Une bonne maitrise de R (dont R Shiny) est attendue
Vous maitrisez PowerBI
Vous êtes organisé, rigoureux, autonome, flexible, vous aimez communiquer et travailler en équipe et vous avez un bon esprit de synthèse et d’analyse
Vous avez un bon niveau d’anglais
🍀
Voici ce que nous pouvons vous offrir…
Un poste en CDI à pourvoir dès que possible, de la bonne humeur, des formations, des soirées, de la bienveillance, un suivi personnalisé, une gestion régulière de votre carrière, des échanges transparents et une écoute permanente.
Si vous êtes convaincu que vous êtes la perle rare, postulez ! Nous sommes impatients de vous rencontrer.
Show more
Show less","{'ProgLanguage': ['R', ' R ', 'Go'], 'DataBase': [], 'DataAnalytics': ['R', ' R '], 'BigData': [], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': ['PowerBI'], 'Statistics': ['Statistiques'], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Statistiques'], 'FrSoftSkills': [], 'EnSoftSkils': []}","{'JobDetail': [], 'TypeContract': ['CDI'], 'Salary': [], 'Level': ['Bac+5'], 'Experience': ['a', 'n', 's', '3', '3', '3']}"
LinkedIn,Machine Learning Developer,MindPal,"Marseille, Provence-Alpes-Côte d'Azur, France",https://fr.linkedin.com/jobs/view/machine-learning-developer-at-mindpal-3911352774?position=38&pageNum=0&refId=EGCcUYgUshGnwQGGB%2BWgjg%3D%3D&trackingId=JTK7oHiJR2xivPc23lsIJw%3D%3D&trk=public_jobs_jserp-result_search-card,"We are looking for
Machine Learning Developer
Job Responsibilities
Working on machine learning projects
Analyzing and processing data to create machine learning models
Implementing and optimizing machine learning algorithms
Testing and evaluating models
Collaborating with the programming team and other departments within the company to develop innovative solutions
Requirements
Minimum 2 years of experience in the field of machine learning
Knowledge of machine learning algorithms and techniques
Ability to analyze and process data
Familiarity with machine learning tools and technologies
Proficient in English communication
Education in computer science
We Offer
B2B contract type
Full-time employment
Remote and flexible working hours
Show more
Show less","{'ProgLanguage': ['R', 'Go'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Machine Learning'], 'FrSoftSkills': ['Communication'], 'EnSoftSkils': ['Communication']}","{'JobDetail': ['Remote', 'Full'], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's']}"
LinkedIn,Data Scientist F/H,TotalEnergies,"Courbevoie, Île-de-France, France",https://fr.linkedin.com/jobs/view/data-scientist-f-h-at-totalenergies-3892558727?position=39&pageNum=0&refId=EGCcUYgUshGnwQGGB%2BWgjg%3D%3D&trackingId=KYg3lXwxzf%2B1aOlCxyzoyg%3D%3D&trk=public_jobs_jserp-result_search-card,"TotalEnergies est une compagnie multi-énergies mondiale de production et de fourniture d'énergies : pétrole et biocarburants, gaz naturel et gaz verts, renouvelables et électricité. Ses 105 000 collaborateurs s'engagent pour une énergie toujours plus abordable, propre, fiable et accessible au plus grand nombre. Présent dans plus de 130 pays, TotalEnergies inscrit le développement durable dans toutes ses dimensions au cœur de ses projets et opérations pour contribuer au bien-être des populations.
Contexte & Environnement :
Environnement de travail international et multiculturel sur l'ensemble des domaines fonctionnels des activités commerciales de la Compagnie.
Participation active à la communauté Data de TotalEnergies.
Large éventail de métiers utilisateurs (activités historiques, nouvelles énergies, efficacité énergétique, etc.)
Multiplicité des intervenants en interne et externe
Poste :
Au sein de l'équipe Valorisation des Données, le titulaire du poste aura 2 types d'activités :
1. Data Scientist
, représentant environ 80% du temps de travail, pour laquelle il/elle :
est au contact direct des clients internes et participe à l'expression du besoin;
propose l'approche à mettre en œuvre pour répondre au besoin métier (bibliographie, méthodologie);
identifie, sur la base de l'analyse des données et de sa connaissance du métier des cas d'usages améliorant l'expérience utilisateur;
élabore et entraine des modèles (machine/deep learning) sur-mesure pour répondre aux besoins métier;
participe, au-delà de la création des modèles, à l'ensemble de la chaine de traitement de la donnée (nettoyage, enrichissement …);
assure une veille technologique en data science et plus généralement en architecture des données, pour être force de proposition sur de nouvelles études à fort impact potentiel pour l'entreprise ou le développement de nouvelles technologies;
rapporte les résultats des travaux, en s'assurant de leur robustesse, à l'écrit et/ou avec des présentations internes/externes.
2. Business Analyst
, représentant environ 20% du temps de travail, pour laquelle il/elle :
participe à la mise en production, en collaboration avec la Tierce Maintenance Applicative (TMA) et les équipes TGITS (TotalEnergies Global Information Technology Services);
accompagne également les métiers sur le delivery (run et projets) et garantit le « move to run »;
s'assure du maintien en conditions opérationnelles du parc applicatif;
met en place les KPIs appropriés et pilote le planning, le budget, la qualité des livrables et les risques des projets.
Profil recherché :
BAC +5 en mathématiques ou statistiques, une thèse de doctorat (PhD) ou une expérience professionnelle dans un domaine lié aux bases de données, BI et Datamining / Analytics
Minimum 6 ans d'expérience
Capacité à développer des algorithmes et coder, notamment en Python
Connaissance Databricks et ML Ops est un plus
Connaissance des environnements cloud, idéalement AWS sur des sujets data, est un plus
Anglais courant obligatoire
Show more
Show less","{'ProgLanguage': ['Python', 'R', 'Go'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': ['Databricks'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': ['Statistiques'], 'CloudComputing': ['AWS'], 'DevTools': ['Git'], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['ML', 'Statistiques', 'Cloud'], 'FrSoftSkills': ['Collaboration'], 'EnSoftSkils': ['Collaboration']}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's', '6', '6', '6']}"
LinkedIn,Data scientist (H/F),METEO FRANCE,"Toulouse, Occitanie, France",https://fr.linkedin.com/jobs/view/data-scientist-h-f-at-meteo-france-3914118639?position=40&pageNum=0&refId=EGCcUYgUshGnwQGGB%2BWgjg%3D%3D&trackingId=%2BUpA7U%2FYJxdVmVrUn9yGlw%3D%3D&trk=public_jobs_jserp-result_search-card,"Cette offre d’emploi est fournie par Pôle emploi
Description
L'offre d'apprentissage concerne un travail autour de la thématique de l'intelligence artificielle pour la prévision numérique du temps avec notamment pour cible principale la partie assimilation. Le travail consistera à voir l'apport de l'intelligence artificielle sur différentes thématiques : émulateur de modèle météorologique, apprentissage d'erreur modèle, ... Ce travail peut aussi inclure une partie sur le traitement initial des données, notamment sous la forme de la création de jeux de données, l'optimisation du chargement en mémoire des données, ou la visualisation de données. Le diplôme préparé doit être un diplôme d'ingénieur ou un master spécialisé dans une filière data. Les compétences de bases attendues sont celles d'un apprentis datascientist. Des compétences en mathématiques, en statistiques et en informatique (de préférence python) sont attendues. Une première expérience en deep learning serait intéressante. La pratique de git est un plus.
PROFIL SOUHAITÉ
Expérience
Expérience exigée de 1 An(s)
Langue
Français
Source: Pole emploi (https://www.pole-emploi.fr)
Show more
Show less","{'ProgLanguage': ['Python', 'R'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': ['Statistiques'], 'CloudComputing': [], 'DevTools': ['Git'], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Statistiques'], 'FrSoftSkills': [], 'EnSoftSkils': []}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's']}"
LinkedIn,Machine Learning Engineer,Enzo Tech Group,"Paris, Île-de-France, France",https://fr.linkedin.com/jobs/view/machine-learning-engineer-at-enzo-tech-group-3914687840?position=41&pageNum=0&refId=EGCcUYgUshGnwQGGB%2BWgjg%3D%3D&trackingId=%2BSNJ9hSa5uQxWvE%2BlzQ11g%3D%3D&trk=public_jobs_jserp-result_search-card,"Position:
Machine Learning Engineer / MLOps Engineer / AI Engineer
Location:
Paris
Type:
Freelance, Contract
Duration:
6 months
Searching for a
MLOps Engineer
to lead the implementation of
MLOps
practices at scale with a focus on
large language models
(LLM)
.
Role:
Lead the implementation of
MLOps
practices at scale, focusing on industrialising AI solutions and ensuring their efficient deployment.
Collaborate with software engineering teams to integrate machine learning models into production environments.
Manage and optimise
AI infrastructure
on
Azure
, including
Databricks
clusters and other relevant technologies.
Develop and maintain automation pipelines for model training, testing, monitoring, and retraining.
Requirements
Proven experience as an MLOps Engineer or similar role, with expertise in large-scale AI deployments.
Deep understanding of MLOps principles, including model versioning
Expertise and support to data scientists and engineers working on AI initiatives.
CVs: s.allenby@enzotechgroup.com
Show more
Show less","{'ProgLanguage': ['R'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': ['Databricks'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': ['Azure'], 'DevTools': [], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': ['Teams'], 'Other': ['ML', 'Machine Learning'], 'FrSoftSkills': [], 'EnSoftSkils': ['Initiative']}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's']}"
LinkedIn,Data Scientist,DxO Labs,"Boulogne-Billancourt, Île-de-France, France",https://fr.linkedin.com/jobs/view/data-scientist-at-dxo-labs-3915441544?position=42&pageNum=0&refId=EGCcUYgUshGnwQGGB%2BWgjg%3D%3D&trackingId=q32n1S6zIz%2BzzqOidauFiA%3D%3D&trk=public_jobs_jserp-result_search-card,"En 20 ans, DxO Labs s’est affirmée comme l’une des entreprises françaises les plus innovantes du secteur de la photographie numérique et du traitement d’image.
Nous concevons et commercialisons des logiciels d’édition photo avancée pour les photographes, amateurs ou experts. Nos solutions, issues de l’excellence et du savoir-faire incomparable de nos équipes d’experts internationales et multiculturelles, offrent les outils de correction et de traitement les plus performants.
DxO Labs s’appuie depuis toujours sur l’excellence et le savoir-faire incomparable de ses équipes d’experts internationales et multiculturelles.
Si vous souhaitez vous projeter et découvrir nos produits; cliquez sur https://www.dxo.com/fr/
Afin de renforcer notre équipe R&D, nous recrutons, dans le cadre d’un contrat en CDI plein temps un
Data Scientist
Basé à notre siège social de Boulogne-Billancourt et rapportant au Directeur Traitement Images.
Au sein de notre équipe R&D Image et en étroite collaboration avec nos équipes UX et produit, votre rôle sera de nous aider à doter nos logiciels fonctionnalités IA innovantes basées sur l’analyse d’une grande quantité de données.
Vos missions :
Avec nos product managers et nos chercheurs en traitement d’image, définir de nouvelles fonctionnalités utilisateur.
Constituer les bases d’apprentissage nécessaires.
Concevoir, implémenter et entrainer des modèles de deep learning.
Evaluer ces modèles grâce à des prototypes.
Aider nos experts logiciel à intégrer ces nouvelles fonctionnalités utilisateur dans nos produits.
Être au fait des dernières recherches et méthodes au croisement entre la data science, la vision par ordinateur et la retouche photo.
Votre profil :
Au moins 5 ans d'expérience en tant que Data Scientist, de préférence dans le secteur technologique ou des logiciels
Deep learning (connaissances à jour par rapport à l’état de l’art en 2024)
Python, PyTorch
Au moins B2 en Anglais et Français
Capacité à travailler de manière autonome et en équipe, avec un esprit curieux et tourné innovation
Idéalement
Connaissance en Traitement d’image (p.ex. analyse sémantique, génération d'images)
Traitement de la langue (LLM)
TensorFlow, AWS, WinML, CoreML, C++
Un vrai + : Passionné de photographie
Si vous vous retrouvez dans le descriptif candidat : Postulez sans attendre sur recruit@dxo.com
Nous verrons ensemble si vos compétences et votre savoir-être correspondent à notre ADN
Localisation :
Basé à Boulogne-Billancourt (Métro 9 station Billancourt – Tramway T2 station Les Moulineaux),
Télétravail possible à hauteur de 2j/semaine
Show more
Show less","{'ProgLanguage': ['Python', 'C++', 'R'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': ['TensorFlow', 'PyTorch'], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': ['AWS'], 'DevTools': [], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['ML'], 'FrSoftSkills': ['Collaboration'], 'EnSoftSkils': ['Collaboration']}","{'JobDetail': [], 'TypeContract': ['CDI'], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's', '20', '20', '20']}"
LinkedIn,Machine Learning Engineer,Alki,"Paris, Île-de-France, France",https://fr.linkedin.com/jobs/view/machine-learning-engineer-at-alki-3916860370?position=44&pageNum=0&refId=EGCcUYgUshGnwQGGB%2BWgjg%3D%3D&trackingId=dR6o7LsxIVtvsBdjeTwWXA%3D%3D&trk=public_jobs_jserp-result_search-card,"Full Stack Machine Learning Engineer (Time Series Forecasting)
Location:
Remote or Paris
Job Type
: Full-Time
Company overview
: At Alki, we’re leveraging cutting edge AI technologies to transform logistics warehouses and drive innovation. Our mission is to bridge the gap between Amazon and other logistics players. We are looking for a skilled full stack ML engineer with a strong focus on time series forecasting to industrialize and streamline our machine learning operations (MLOps) capabilities from R&D to production.
Responsibilities:
Design & build robust data pipelines specifically tailored for time series data, ensuring efficient data ingestion, pre-processing & exploration to support ML models
Design, implement, and optimize sophisticated time series forecasting algorithms
Translate advanced statistical and machine learning models from R&D into scalable production solutions
Manage the deployment of machine learning systems, including setting up continuous integration and delivery pipelines (CI/CD) for automated model training and deployment
Monitor and maintain operational ML models (thousands), quickly identifying and addressing performance degradation or shifts in model accuracy/data
Collaborate with cross-functional teams, including CTO, AI researcher, software engineer, to ensure models effectively address business needs and enhance decision-making
Stay abreast of the latest developments in machine learning, artificial intelligence, and related technologies to continuously improve our MLOps practices and time series models
Qualifications
Master’s/PhD degree in Computer Science, Applied Maths, Statistics, or a related field
Strong experience with a proven track record of deploying ML models to production
Strong understanding of the challenges associated with deploying, monitoring, and maintaining thousands of ML models in a production environment
Strong experience with AutoML, HPO, NAS
Proficient in Python, including extensive experience with ML libraries such as TensorFlow or PyTorch, and statistical modeling tools
Knowledge of AWS cloud services related to machine learning and data processing, including Amazon S3, EC2, RDS, Lambda, and SageMaker
Familiarity with data orchestration tools
Experience in building and maintaining CI/CD pipelines for automated model deployment
Excellent analytical and problem-solving abilities, with a strong collaborative mindset
Experience in time series analysis and forecasting is a plus
Benefits:
Competitive salary
Strong opportunities for professional development and career advancement
Flexible working hours and remote work options
Dynamic and innovative work environment
How to apply:
Please submit your resume and any relevant project portfolio to tanguy@alki.io. We are excited to hear how you can contribute to our team at Alki!
Show more
Show less","{'ProgLanguage': ['Python', 'Scala', 'R', 'Go'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': ['TensorFlow', 'PyTorch'], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': ['Statistics'], 'CloudComputing': ['AWS'], 'DevTools': [], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': ['Teams'], 'Other': ['ML', 'Machine Learning', 'Cloud', 'CI/CD'], 'FrSoftSkills': [], 'EnSoftSkils': []}","{'JobDetail': ['Remote', 'Full'], 'TypeContract': [], 'Salary': ['Salary'], 'Level': [], 'Experience': ['a', 'n', 's']}"
LinkedIn,Data Scientist @ start-up,Licorne Society,"Paris, Île-de-France, France",https://fr.linkedin.com/jobs/view/data-scientist-%40-start-up-at-licorne-society-3918084326?position=45&pageNum=0&refId=EGCcUYgUshGnwQGGB%2BWgjg%3D%3D&trackingId=9prKyMo8%2FLV9SMO9p4WfkA%3D%3D&trk=public_jobs_jserp-result_search-card,"Licorne Society est à la recherche de Data Scientist pour des startups innovantes, ne laisse pas passer ta chance !
C’est quoi Licorne Society ?
Licorne Society est le seul outil qui te met en relation avec plus de 3000 startups recrutant en France, tous secteurs et métiers confondus. Qu’elles soient en création ou en phase d’hypercroissance, toutes les startups t’attendent sur Licorne Society. Ah oui, et c’est gratuit !
Notre promesse : faire matcher ta recherche avec les meilleures opportunités et mettre en avant ton profil auprès des startups qui recrutent.
>> www.licornesociety.com <<
L'inscription Prend Moins De 10 Minutes. Tu Pourras Alors Accéder à L'ensemble Des Offres En Startup Du Marché Et Être Contacté Directement Par Les Recruteurs
1 - Remplis ton profil et tes attentes.
2 - Passe en revue les offres que nous te proposons en fonction de tes critères de recherche et reçois une notification à chaque nouvelle offre publiée. Avec notre mode Tinder, tu n’as qu’à swiper les offres. Matcher avec le job de tes rêves n’a jamais été aussi simple !
3 - Reçois des sollicitations directes pour des postes de Data Scientist au sein de nos startups préférées (pour ne citer que BackMarket, PlayPlay, Payfit, Trustpair ou encore Choco)
Profil Recherché
Tu as une première expérience de Data Scientist et tu es très motivé pour rejoindre une start-up / scale-up ou tu es prêt à décrocher ton tout premier job
Tu as la fibre entrepreneuriale
Tu as soif de challenge et de nouveaux apprentissages
Tu es prêt à cliquer sur le lien d’inscription : www.licornesociety.com
Les parcours particulièrement valorisés chez Licorne Society :
des exemples de prises d’initiatives ou projets menés avec l’esprit entrepreneurial
des expériences dans des environnements particulièrement exigeants
des exemples de réalisations édifiants ou résultats chiffrés
On se dit à tout de suite sur la plateforme ?
>> www.licornesociety.com <<
Show more
Show less","{'ProgLanguage': ['R'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': [], 'FrSoftSkills': [], 'EnSoftSkils': ['Initiative']}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's']}"
LinkedIn,Data Scientist - IA Défense F/H,Thales,"Paris, Île-de-France, France",https://fr.linkedin.com/jobs/view/data-scientist-ia-d%C3%A9fense-f-h-at-thales-3880160252?position=46&pageNum=0&refId=EGCcUYgUshGnwQGGB%2BWgjg%3D%3D&trackingId=4crGluEtbgS8C3IScJtzKw%3D%3D&trk=public_jobs_jserp-result_search-card,"QUI SOMMES-NOUS ?
Thales Digital Factory s’inscrit dans le programme de transformation de Thales qui a pour ambition de devenir un acteur incontournable et exemplaire du digital, et ce dans l’ensemble de ses marchés. Notre mission consiste à accélérer la transition numérique du Groupe Thales en s'aventurant dans de nouveaux modes de travail et de décision. Notre stratégie s’articule autour de 6 valeurs : Responsabilisation, Orientée sur la donnée, Centrée sur l’utilisateur, Collaboration, Amélioration continue et Culture de l’échec. Nos bureaux se répartissent de Paris à Singapour en passant par Montréal au cœur d'écosystèmes innovants. Thales Digital Factory se distingue également grâce à son incubateur qui accompagne des start-ups internes et externes, ses plateformes digitales, son centre d’excellence Cloud et le développement de MVP, porteurs d’innovation pour l’offre digitale du Groupe et de nos clients.
Avec plus de 600 experts IA et une centaine de doctorants en IA chaque année, et disposant d’un réseau de partenaires industriels, start-up et académiques de premier ordre, Thales est, depuis une décennie, un acteur majeur de l’IA de confiance, transparente, explicable et éthique. Le Groupe figure en tête, en Europe, dans le classement des déposants de brevets dans l’IA des systèmes critiques. Il intègre de l’IA dans plus d’une centaine de ses produits et services.
Nous recherchons notre futur
Data Scientist
dans le cadre du lancement de notre nouvelle entité CortAix :
CortAIx
est l’accélérateur IA qui dotera les forces armées, les avionneurs et tous les opérateurs d’infrastructures critiques, de solutions hautement sécurisées leur apportant plus d’efficacité dans l’analyse des données et la prise de décision, tout en tenant compte des contraintes spécifiques, telles que la cybersécurité, l’embarquabilité et la frugalité, liées aux environnements critiques.
Au sein de cette nouvelle organisation, nous représentons l'axe
""
cortAIx Factory""
qui vise à accélérer la qualification et l’industrialisation des outils de développement de l’IA ainsi que les cas d’usage pour les données des systèmes. Thales dote déjà ses systèmes d’IA et continue d’identifier de nouveaux cas d’usages pour accélérer la performance, comme par exemple la planification de missions, la gestion du trafic aérien, le pilotage de drones et de robots.
QUI ETES-VOUS ?
Vous êtes titulaire d'un Master 2 (BAC +5) d'une école d'Ingénieur ou d'un parcours universitaire et vous avez un minimum de 5 à 7 ans d'expérience pratique en IA, avec une solide expérience dans le déploiement de solutions ML
Vous faites preuve de motivation, d'autonomie et d'initiative
Vous avez une expérience de mise en place de solutions embarquant du machine learning, depuis la collecte de la donnée jusqu’à la mise en production de la solution par des utilisateurs
Vous faites preuve d'une grande disponibilité et d'une très forte réactivité
Vous êtes reconnu pour votre esprit d'équipe et aimez le travail collaboratif
Une expérience dans des environnements de projet agiles et dynamiques est un plus
Une expérience dans la conduite d'ateliers clients et de réunions face aux clients
Vous vous reconnaissez ?
Parlons missions !
COMPÉTENCES :
Vous comprenez les enjeux business autours de l’exploitation des données et le déploiement des solutions de Machine Learning et/ou de Deep Learning, ainsi que les problématiques inhérentes à la mise en production de telles solutions innovantes.
Vous maitrisez les statistiques, le Machine Learning et de Deep Learning.
Vous avez une écoute développée et une communication fluide et claire, ainsi, vous êtes à l’aise pour vous exprimer et convaincre sur les objectifs, la rentabilité et les étapes de résolution de problèmes associés à vos modèles, permettant de convaincre un interlocuteur peu au fait des techniques ML ou DL.
Maîtrise du ML/DL, y compris des principaux frameworks (TensorFlow, PyTorch) et des statistiques.
Solide connaissance de Python (Java, Spark, Scala sont un plus).
Expérience dans l'utilisation d'outils tels que Gitlab et Docker.
Familiarité avec l'ensemble du cycle de vie de développement et de déploiement de modèles d'IA (MLOps).
En collaboration avec les autres membres de CortAIx, composés d'experts en intelligence artificielle :
Vous participez activement à l'identification des besoins spécifiques des différentes branches de Thales ou de ses clients, à travers des ateliers d'idéation, et proposez des solutions algorithmiques sur mesure adaptées à chaque situation. Votre rôle ne se limite pas à répondre à une question technique, mais à imaginer et concevoir des solutions innovantes qui répondent aux défis et objectifs spécifiques identifiés lors des discussions avec les parties prenantes
Vous analysez rapidement les données disponibles pour sélectionner les modèles d'IA les plus pertinents face aux défis identifiés, en tenant compte des spécificités de chaque cas d'usage
Vous développez, testez et validez les algorithmes de traitement des données en utilisant des méthodes statistiques, mathématiques et de machine learning, adaptés à une variété d'environnements techniques prenant en compte des besoins précis en termes de sensibilité des données
Vous jouez un rôle clé dans la diffusion de la connaissance au sein de CortAIx, en partageant régulièrement des insights et des innovations issues de vos projets récents, contribuant ainsi à l'enrichissement collectif
Vous communiquez efficacement au sein de Thales et en externe pour mettre en valeur les succès, les avancées réalisées et les leçons apprises des différents projets, renforçant ainsi la réputation de Thales comme leader de l'IA dans les domaines de la défense et au-delà
Nous sommes toujours en phase ?
Rejoignez-nous !
Innovation, passion, ambition : rejoignez Thales et créez le monde de demain, dès aujourd’hui.
Show more
Show less","{'ProgLanguage': ['Python', 'Java', 'Scala', 'R', 'Go'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': ['Spark'], 'MachingLearning': ['TensorFlow', 'PyTorch'], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': ['Statistiques'], 'CloudComputing': [], 'DevTools': ['Git', 'Docker'], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': ['Docker'], 'Collaboration': [], 'Other': ['ML', 'Machine Learning', 'Statistiques', 'Cloud'], 'FrSoftSkills': ['Communication', 'Résolution de problèmes', 'Collaboration', 'Organisation'], 'EnSoftSkils': ['Communication', 'Collaboration', 'Initiative']}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's', '7', '7', '7']}"
LinkedIn,Data Scientist F/H,Orange,France,https://fr.linkedin.com/jobs/view/data-scientist-f-h-at-orange-3905556668?position=47&pageNum=0&refId=EGCcUYgUshGnwQGGB%2BWgjg%3D%3D&trackingId=YU9dsbTlprbPy2%2FDlBUjaw%3D%3D&trk=public_jobs_jserp-result_search-card,"Et si Business & Décision et le groupe Orange conjuguaient leurs forces pour devenir l'un des leaders européens de la Data transformation ?
Nous l'avons fait ! Notre alchimie nous positionne comme un acteur unique intervenant sur toutes les étapes du voyage de la donnée.
Business & Décision en croissance sur l'année 2021, continue sur sa lancée avec un nouvel objectif de plus de 500 recrutements de profils #DataSpecialist.
Nous intervenons sur l'ensemble du cycle de vie des projets de clients du CAC40 :
Dès la phase de réflexion d'un projet, en passant par le management consulting, le cadrage, les études métiers, le cadrage de l'architecture, jusqu'au run, et expertises.
Nous formons et certifions régulièrement nos consultants sur les technologies du marché ; la formation étant l'une de nos priorités afin de vous accompagner dans le développement de vos compétences et vos perspectives d'évolutions.
Nous recherchons aujourd'hui, un Data Scientist afin d'intervenir chez nos clients pour les accompagner sur les missions suivantes :
- Analyse et cadrage des besoins métiers,
- Préparation des données,
- Choix des algorithmes à mettre en oeuvre,
- Programmation et développement,
- Interprétation des résultats,
- Mise en production,
- Veille technologique,
En tant que Data Scientist expert, vous êtes capable de manipuler une grande quantité de bases de données et de sources, quels que soit leurs formats, de mettre en oeuvre les algorithmes nécessaires, de prendre de la hauteur par rapport aux résultats obtenus, et d'assurer une interaction avec le client sur les résultats obtenus.
De formation Bac +5 en Mathématiques, Statistiques ou IT
Vous maitrisez au moins un des langages de programmation suivants : Python, R, Scala, SQL, ... Vous avez des notions sur les solutions de studios Data Science (KNIME, Dataiku, H2O, Alteryx, SAS, SPSS, ...) et sur les environnements Cloud (Azure, AWS, GCP).
Vous avez déjà travaillé sur des problématiques de type : Machine Learning, Deep Learning, Time Series, Clustering, Anomly detection,
Un intérêt ou une première expérience sur les sujets d'IA Générative est un plus.
Ref : 20521918
Show more
Show less","{'ProgLanguage': ['Python', 'Scala', 'R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': ['Orange'], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': ['Statistiques'], 'CloudComputing': ['AWS', 'Azure'], 'DevTools': [], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['ML', 'Machine Learning', 'Statistiques', 'Cloud'], 'FrSoftSkills': [], 'EnSoftSkils': []}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's']}"
LinkedIn,Data Scientist F/H,Saint-Gobain,"Courbevoie, Île-de-France, France",https://fr.linkedin.com/jobs/view/data-scientist-f-h-at-saint-gobain-3916726404?position=48&pageNum=0&refId=EGCcUYgUshGnwQGGB%2BWgjg%3D%3D&trackingId=W8fLNWP5t8hiE7uv0wrNeA%3D%3D&trk=public_jobs_jserp-result_search-card,"Why do we need you ?
Vous rejoindrez l’équipe « AI & Data Analytics », intégrée au département «Data & Analytics» dans l’organisation « Global Digital & IT». «Data & Analytics» regroupe les activités suivantes :
Data Engineering, Data Capture & Delivery, BI & Visualization, Platform & Architecture, Data Governance and Data Engagement.
Au Sein De L’équipe Data Science, Sous La Responsabilité Du Head Of AI & Data Analytics, Vous Aurez Le Rôle De Data Scientist (H/F). En Tant Que Tel, Vous Aurez Les Responsabilités Suivantes
Construire des modèles descriptifs et prédictifs sur des sujets en constante évolution ;
Mener des projets exploratoires faisant appel à des techniques avancées de Data Science (NLP, deep learning, Generative AI, apprentissage par renforcement ou par transfert), de façon autonome ou avec des partenaires externes ;
Assurer une veille technologique permanente sur ces sujets ;
Participer à l’industrialisation des algorithmes en lien avec les équipes engineering basée sur MLOps;
Accompagner les équipes opérationnelles dans le déploiement des algorithmes, notamment sur le volet analytics ;
Mener des ateliers d’idéation avec les équipes métiers (industrie, marketing, ventes, logistique, e-commerce, finance, RH) pour identifier les opportunités d’exploitation de la donnée et diffuser la culture data au sein de l’entreprise.
Si vous recherchez des défis passionnants, pouvant impacter des centaines de milliers de clients, et aimez travailler avec des outils à la pointe de la technologie, venez et rejoignez-nous !
Vous participerez donc à la montée en puissance de l’équipe créée récemment, tout en intervenant sur un ou plusieurs cas d’utilisation.
Is this job for you ?
En complément des missions évoquées, une réelle appétence pour la gestion et la facilitation de projet, avec une certaine aisance en termes de communication, seraient fortement appréciées.
Notre équipe ayant vocation à travailler pour des clients internes pouvant être basés en France comme à l’étranger, la maitrise de l’anglais (écrite et orale) est obligatoire.
Profil recherché
Ingénieur diplômé d’une école généraliste (Centrale, X, Mines, ENS etc.) ayant au minimum 3 années d'expérience après le diplôme.
Grande connaissance du Machine Learning, des statistiques et des probabilités.
SQL et Python, packages de ML: scikit, xgboost, keras
Expérience de travail sur un cloud provider et savoir construire des data pipelines serait un plus
Gestion de code : Git, Gitlab, CI/CD
Maitriser la modélisation à la fois prédictive et descriptive
Savoir implémenter des dashboards et autres outils de data viz
Posséder de bonnes qualités de communication : vous pouvez expliquer vos modèles clairement à la fois à des data analysts mais aussi à des Directeurs Généraux ou des responsables opérationnels.
Etre organisé, structuré et motivé par l’innovation
Aimer le travail en équipe et savoir apprendre de chacun.
Un état d’esprit orienté business et apport de valeur pour les équipes métiers
A Little More About Us
Saint-Gobain est une entreprise française spécialisée dans la production, la transformation et distribution de matériaux.
Fondée en 1665 par Jean-Baptiste Colbert sous le nom de Manufacture royale des glaces, l'entreprise est présente dans soixante-sept pays et emploie en 2018 près de 180 000 personnes
To make sure nothing is forgotten
Détails pratiques du rôle
Début : Dès que vous êtes prêts
Localisation : La Tour Saint-Gobain, La Défense
Contrat: CDI
Saint-Gobain encourage la diversité des équipes et favorise notamment l’inclusion des personnes en situation de handicap.
Show more
Show less","{'ProgLanguage': ['Python', 'R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': ['Keras', 'XGBoost'], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': ['Statistiques'], 'CloudComputing': [], 'DevTools': ['Git'], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['ML', 'Machine Learning', 'Statistiques', 'Cloud', 'CI/CD'], 'FrSoftSkills': ['Communication', 'Organisation'], 'EnSoftSkils': ['Communication']}","{'JobDetail': [], 'TypeContract': ['CDI'], 'Salary': ['1665'], 'Level': [], 'Experience': ['a', 'n', 's']}"
LinkedIn,Geospatial Data Scientist,EarthDaily Agro,"Balma, Occitanie, France",https://fr.linkedin.com/jobs/view/geospatial-data-scientist-at-earthdaily-agro-3884744208?position=49&pageNum=0&refId=EGCcUYgUshGnwQGGB%2BWgjg%3D%3D&trackingId=jGH3IzxurslYYB7Wsb3Cag%3D%3D&trk=public_jobs_jserp-result_search-card,"STRUCTURE D’ACCUEIL
EarthDaily Agro fournit des données et des analyses de l'ère spatiale aux organisations et aux personnes qui nourrissent la planète !
Avec 35 ans d'expérience dans le secteur, EarthDaily Agro fournit à ses clients les données, les analyses et les connaissances dont ils ont besoin pour prendre des décisions plus efficaces. Les services B2B vont de la gestion globale des risques et du suivi des produits agricoles à la commercialisation d'intrants et au conseil en agriculture de précision, en utilisant les dernières recherches en agronomie, en technologies de l'information et en télédétection.
EarthDaily Agro développe également des solutions commerciales hautement personnalisées pour les prêteurs agricoles, les assureurs, les fournisseurs d'intrants et les entreprises alimentaires, avec des analyses faciles à utiliser, qui aident à réduire les risques quotidiens de l'agriculture.
EarthDaily Agro, dont le siège social se trouve à Minneapolis, MN, USA, et qui possède des bureaux en France, au Brésil, en Australie et en Suisse, est une division de EarthDaily Analytics Corp.
EarthDaily Analytics Corp, une société de traitement et d'analyse de données verticalement intégrée, lance une nouvelle constellation de satellites d'observation de la terre. La constellation de satellites EarthDaily améliorera considérablement les capacités d'analyse géospatiale dans les secteurs de l'agriculture, de la sylviculture, de l'environnement, des services financiers et du renseignement, parmi de nombreux autres segments.
RESPONSABILITÉS
Vous serez en charge de résoudre des challenges liés à l’agriculture en utilisant la télédétection, en particulier les images de la future constellation EarthDaily, et des données météo. Basé à Balma, à proximité de Toulouse, vous intégrerez une équipe internationale avec des collègues au Brésil et aux USA.
VOS RESPONSABILITÉS INCLURONT :
L’agriculture fait face à des challenges sans précédent : le changement climatique induit des risques accrus, et les agriculteurs doivent maintenir voire améliorer leur productivité tout en réduisant leur impact environnemental. Avec la future constellation EarthDaily (jusqu’à 5 m de résolution, revisite quotidienne avec 22 bandes spectrales du visible à l’infra-rouge thermique), EarthDaily Agro disposera d’une technologie clef pour répondre à ces problématiques. Rejoignez EarthDaily Agro pour contribuer à minimiser ces risques avec la technologie.
EarthDaily Agro est à la recherche d’un.e Data Scientist en télédétection pour rejoindre son équipe R&D et construire des analytiques à valeur ajoutée à destination de ses clients dans le monde agricole.
Vous mettez en place des solutions inventives pour répondre aux problématiques des clients, demandant des compétences fortes en analyse de données et en machine learning, dans un contexte de larges volumes de données et d’une base existante de plus de 100 analytiques. Vous développez des POCs et prototypes, définissez / testez / validez et spécifiez les algorithmes appropriés. Vous êtes activement impliqué.e dans le design et la mise en place de la solution opérationnelle sur notre plateforme Cloud.
Vos missions :
Comprendre les problématiques métier et les traduire en solution algorithmique basée sur les données issues de la télédétection.
Créer et implémenter des modèles basés sur l’état de l’art, pour extraire l’information pertinente d’un large volume de données
Collaborer au sein d’une équipe Agile pluridisciplinaire et internationale de Data Scientists, Data Engineers et experts métiers dans toutes les phases du projet : de l’idéation à l’industrialisation et déploiement opérationnel
Rédiger des supports de présentation des résultats, conditions d’utilisation, et défendre la solution proposée par une approche pragmatique
Être proactif(ve) pour alimenter le pipeline d’innovation avec des nouvelles idées, contribuer à définir la roadmap R&D
EDUCATION, CONNAISSANCES ET CAPACITÉS
Master ou doctorat en Machine Learning / Mathématiques appliquées, télédétection, ou domaine associé
Au moins 3 ans d’expérience professionnelle, expérience dans un domaine associé à l’agriculture et en entreprise privée appréciée
Etat d’esprit orienté résultats et pragmatique pour évoluer dans un contexte de plannings serrés
Maîtrise de Python, connaissance en SIG (QGIS, GDAL/OGR),
La connaissance des bibliothèques de Machine Learning / Deep Learning (Scikit-learn, Pytorch, Tensorflow…), des outils de MLOps (ZenML, MLFlow), des systèmes de gestion de version (git), de Docker, Kubernetes et du fonctionnement des workflows sur AWS (et Azure) est appréciée
Facilités de communication pour le travail en équipe dans un contexte international
Anglais courant (oral et écrit) : l’équipe d’accueil est internationale, les réunions internes se déroulent principalement en anglais.
Vous êtes curieux(se) et créatif(ve), collaboratif(ve) et adaptable ? Rejoignez-nous !
CONDITIONS
Emploi en CDI, démarrage dès que possible
Poste basé à Balma, première couronne de Toulouse accessible en transports en commun. Possibilité de télétravail partiel.
Powered by JazzHR
m5SHCur65r
Show more
Show less","{'ProgLanguage': ['Python', 'R', 'Go'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': ['Scikit-Learn', 'TensorFlow', 'PyTorch'], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': ['AWS', 'Azure'], 'DevTools': ['Git', 'Docker'], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': ['Kubernetes'], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': ['Docker', 'Kubernetes'], 'Collaboration': [], 'Other': ['ML', 'Machine Learning', 'Cloud'], 'FrSoftSkills': ['Communication', 'Organisation'], 'EnSoftSkils': ['Communication']}","{'JobDetail': [], 'TypeContract': ['CDI'], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's', '35', '35', '35']}"
LinkedIn,Data Scientist (confirmé/sénior) - H/F - CDI,Talan,"Paris, Île-de-France, France",https://fr.linkedin.com/jobs/view/data-scientist-confirm%C3%A9-s%C3%A9nior-h-f-cdi-at-talan-3909648101?position=50&pageNum=0&refId=EGCcUYgUshGnwQGGB%2BWgjg%3D%3D&trackingId=nzq%2BDoQB8i6NwtkUfvASow%3D%3D&trk=public_jobs_jserp-result_search-card,"Talan est un groupe international de conseil en transformation et en innovation par la technologie, créé en 2002.
Nos 5000 consultantes et consultants partagent à travers le monde l’audace d’innover, le goût de l’excellence, et l’envie de relever les défis les plus complexes.
Nous accompagnons les entreprises dans des secteurs variés : énergie, industrie, transport, finance, luxe… à travers 3 grandes expertises :
Le Conseil en Management et Innovation (320 Consultants en France)
La valorisation des données, leurs structurations, et leurs usages (Data et Technologies)
L’intégration de solutions logicielles (Cloud et Applications Services)
Nos valeurs : engagement, respect, partage, esprit d’équipe et optimisme.
Talan est une entreprise responsable, reconnue par ses collaborateurs et attachée à la diversité. Des aménagements peuvent être proposés si vous êtes en situation de handicap.
Retrouvez nos engagements RSEiciet nos actions en faveur de la diversitéici
Job Description
Nous sommes à la recherche d’un Data Scientist capable de participer à des projets techniques Data Science et IA. Vous devrez faire preuve d’un état d’esprit à la fois innovant, méthodique, orienté solution (et non problème!), et communiquant.
Votre but ultime sera de garantir l’excellence de vos solutions Data Science/IA, pièces maitresses de la réalisation de projets disruptifs pour nos clients.
VOTRE ROLE SUR NOS PROJETS
:
En mission: analyse des besoins métiers, définition des principes et méthodes de collecte et de traitement des données, choix des modèles de Machine Learning ou de Deep Learning, mise en application des techniques de traitement et de visualisation de la data, restitution des analyses et résultats obtenus auprès des métiers et des sponsors
Partager techniquement les membres de l’équipe: solutions et code reviews, recommandations, certifications à réaliser, …
Participation à des meet-up, coding dogo,…
Communication: écriture d’articles, retours d’expérience…
VOTRE ROLE CHEZ TALAN :
Benchmark de solutions et conseil auprès de nos clients sur les solutions technologiques à adopter, en lien avec leurs besoins
Réalisation de POC (Proof Of Concept)
Participation à des projets internes et partage de connaissances au sein de nos équipes.
Partage de connaissances et formations interne
Qualifications
VOTRE PROFIL:
Issu d’une formation Grande École d’Ingénieur/Doctorant, spécialisée en Data Science ou Intelligence Artificielle
Vous disposez d’au moins 3 années d’expérience dans le domaine
Maitrise des techniques d’analyses statistiques, de modélisations prédictives, de Machine Learning, de Deep Learning,...
Maitrise des techniques de data management et de DataViz
Maitrise de Python, R, RShiny, SQL…
Maitrise de l’utilisation des outils DevOps: Git, Docker, Jenkins/Nexus,…
Bonnes connaissances Big Data: pySpark, Spark, NoSQL…
Connaissance d’outils tels que Dataiku, AWS SageMaker, Azure ML,…
Autonomie, organisation, sens du partage
Excellente communication
Orientation métier
Additional Information
AVANTAGES
:
Plan de formation pour accompagner votre carrière (formations éditeurs, certifications) grâce à nos partenariats nous accordant une position de partenaire privilégié, et management de proximité par des experts
Locaux modernes en centre-ville
Top 5 du Palmarès Great Place to Work
Télétravail jusqu’à 5 jours selon les missions, prime d’équipement de 100€
Mobilité en France et à l’étranger
Top 1% des entreprises évaluées par Ecovadis dans le domaine social, environnemental et éthique
Tickets restaurant, prime vacances, 50% transport (abonnement transport public), mutuelle
Permanence handicap (consultant dédié aux collaborateurs en situation de handicap et aux proches aidants)
Actionnariat salarié
Prime de cooptations
RTT
PROCESS RECRUTEMENT
:
L’équipe recrutement s’engage à vous proposer un processus de recrutement rapide et fluide
1 entretien RHpar Teams (45min)
1 test technique
1 entretien opérationnel avec le responsable de domaine, au siège (1heure)
1 entretien avec le directeur de pôle, au siège(1heure)
Show more
Show less","{'ProgLanguage': ['Python', 'R', 'Go'], 'DataBase': ['SQL', 'NoSQL'], 'DataAnalytics': ['R'], 'BigData': ['Spark'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': ['Statistiques'], 'CloudComputing': ['AWS', 'Azure'], 'DevTools': ['Git', 'Docker', 'Jenkins'], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': ['Docker'], 'Collaboration': ['Teams'], 'Other': ['DevOps', 'Big Data', 'ML', 'Machine Learning', 'Statistiques', 'Cloud'], 'FrSoftSkills': ['Communication', 'Organisation'], 'EnSoftSkils': ['Communication']}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's']}"
LinkedIn,Data Scientist (H/F),Assurances Crédit Mutuel,"Strasbourg, Grand Est, France",https://fr.linkedin.com/jobs/view/data-scientist-h-f-at-assurances-cr%C3%A9dit-mutuel-3881495295?position=51&pageNum=0&refId=EGCcUYgUshGnwQGGB%2BWgjg%3D%3D&trackingId=9SvD0xehnXLGFyKBJXpCNg%3D%3D&trk=public_jobs_jserp-result_search-card,"Qui sommes nous
Depuis 1971, nous imaginons, concevons et orientons les offres et services qui contribuent au développement de l’activité assurance de Crédit Mutuel Alliance Fédérale, inventeur du concept de bancassurance.
Les Assurances du Crédit Mutuel sont présentes sur les marchés des assurances de biens, des assurances de personnes comme de l’assurance-vie. Nous proposons des solutions à tous ceux qui désirent se protéger et anticiper demain, qu’ils soient particuliers, professionnels ou entreprises.
Ce sont nos valeurs mutualistes et notre philosophie innovante qui guident nos actions. Loin de nous contenter de couvrir nos assurés aujourd’hui, nous cherchons à prévenir les risques futurs et à construire une assurance de demain plus juste.
Les Assurances du Crédit Mutuel, ce sont ainsi environ 3500 talents au service de près de 13 millions d’assurés, générant un chiffre d’affaires de 13,9 milliards d’euros. Nos offres et services sont principalement distribués par les réseaux bancaires Crédit Mutuel, CIC et Cofidis. Nous sommes parmi les acteurs majeurs de l’assurance en France.
Rejoindre les Assurances du Crédit Mutuel, c’est rejoindre un groupe qui porte haut et fort ses valeurs et où l’humain est toujours au centre. C’est rejoindre une entreprise où les innovations sont sources de simplicité et de solidarité et où chacun est engagé pour une société plus juste et plus durable. Intégrer les ACM c’est également intégrer le groupe Crédit Mutuel Alliance Fédérale et ses multiples opportunités de carrières.
Pourquoi nous recrutons
Dans un contexte de recherche constante d'une croissance responsable et durable, Les assurances du Crédit Mutuel continuent d'innover, de se développer et de renforcer leurs équipes dans de nombreux domaines.
Vos missions
Au sein de la Direction du Développement, de la transformation et de la Communication, vous intégrez l'équipe « Data et connaissance client » pour mener des projets de data science visant à accompagner la transformation de l'entreprise et favoriser le développement via l’analyse des profils clients.
En intégrant cette équipe, vous prendrez en main des projets de data science, avec le cadrage des problématiques, le recueil et l’analyse des données nécessaires. Vous testerez et comparerez différents modèles et études de performances.
Vous jouerez un rôle majeur dans la connaissance et l’anticipation des besoins de nos clients et travaillerez ainsi en relation avec les autres services de la direction (marketing, parcours client, projets digitaux, …), avec les différents services métiers des ACM et la direction commerciale du Groupe.
Vous serez aussi amené(e) à mener des études en collaboration avec d’autres Data Scientists du Groupe.
Activités / Tâches spécifiques du poste
Vos missions seront entre autres les suivantes :
Détenir, comprendre et exploiter la connaissance client
Proposer et développer des outils statistiques prédictifs et prescriptifs tels que des scores d’appétence ou d’attrition en mettant en œuvre des techniques de type scoring et segmentation via l’utilisation de méthodes classiques (régression logistique …) ou plus innovantes de type machine learning (random forest …).
Analyser, interpréter et synthétiser les données pour dégager des tendances et constats qui alimenteront la compréhension et la réflexion au sein de la direction dans le cadre d’études spécifiques (profils clients …).
Identifier les données existantes et de nouvelles sources de données pertinentes à collecter pour enrichir la connaissance client et modéliser leur comportement (données internes ou externes, structurées ou non structurées).
Etablir les suivis de l’activité commerciale et analyser les performances des actions commerciales et marketing pour améliorer leur efficacité.
Participer à différentes missions de type veille et partage de connaissance
Assurer une veille active sur les sujets de type Big Data et modélisation de données.
Aider au partage de bonnes pratiques au sein du groupe en tant qu’expert des données et des méthodes de modélisation.
Contribuer à la diffusion des travaux de l’équipe au sein de l’entreprise
Pouvoir représenter l'activité en intervenant dans des groupes de travail transverses.
Restituer et communiquer régulièrement les résultats des analyses et les préconisations associées de manière rigoureuse, pédagogique, accessible et exploitable
Ce que vous allez vivre chez nous
Concrètement, aux Assurances du Crédit Mutuel, nos collaborateurs bénéficient:
D'une rémunération fixe versée sur 13 mois
De l'intéressement, participation et de l'abondement pouvant atteindre plus de deux mois de salaire en fonction des résultats du groupe
D'un plan épargne entreprise (PEE), d’un plan épargne retraite collectif (PERECOL) et d’un compte épargne temps (CET),
D'un rythme de travail adapté fort d'un accord QVT groupe qui permet de télétravailler jusqu'à deux jours par semaine
De 22 jours de RTT par an selon le rythme de travail défini
D'une politique de protection sociale renforcée (régimes de remboursement de frais de santé et de prévoyance)
D'un régime de retraite supplémentaire (PERO) prise en charge à 100% par l’employeur
De conditions bancaires et assurances préférentielles
D'une politique parentale avantageuse
D'un parcours d'intégration pour tout nouvel arrivant
D'au moins une action de formation chaque année (95% des salariés)
D'un accompagnement pour favoriser votre mobilité géographique et fonctionnelle.
Ce que nous allons aimer chez vous
Connaissances et compétences
De formation supérieure Bac+5 minimum orientée statistiques, mathématiques, Data Science.
Un minimum de six ans d’expérience à un poste équivalent est demandé.
Vous possédez une expertise confirmée en Python (pandas, scikit-learn) ainsi que des connaissances poussées en Data Science (random forest, boosting, classification …).
Vous maîtrisez des langages / outils de traitement et d’analyse de données (SQL, SAS, Excel, …)
Vous possédez des compétences en présentation (PowerPoint) et êtes capable de mettre en valeur votre travail.
Une expérience en assurance constituerait un plus.
Une expérience en compétition de Data Science ou programmation (Kaggle, leetcode ...) constituerait un plus.
Savoir-être - savoir-faire
Vous appréciez le travail en équipe et faîtes preuve d'une bonne aisance relationnelle.
Curieux, vous possédez un bon esprit d'initiative et vous tenez au courant des dernières nouveautés en terme de Data Science.
Vous possédez un esprit analytique et créatif et êtes en mesure d’imaginer et de proposer des solutions innovantes.
Rigoureux et autonome, vous disposez d'excellentes capacités d'analyse et de synthèse.
Show more
Show less","{'ProgLanguage': ['Python', 'R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['Pandas', 'R'], 'BigData': [], 'MachingLearning': ['Scikit-Learn'], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': ['Statistiques'], 'CloudComputing': [], 'DevTools': ['Git'], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Big Data', 'Machine Learning', 'Statistiques'], 'FrSoftSkills': ['Communication', 'Collaboration', ""Esprit d'initiative""], 'EnSoftSkils': ['Communication', 'Collaboration', 'Initiative']}","{'JobDetail': ['Confirmé'], 'TypeContract': [], 'Salary': ['22'], 'Level': ['Bac+5'], 'Experience': ['a', 'n', 's']}"
LinkedIn,Data Scientist H/F,METEOJOB by CleverConnect,"Rennes, Brittany, France",https://fr.linkedin.com/jobs/view/data-scientist-h-f-at-meteojob-by-cleverconnect-3907968677?position=52&pageNum=0&refId=EGCcUYgUshGnwQGGB%2BWgjg%3D%3D&trackingId=m9Xh%2BLq863yfFLMd5eYlaQ%3D%3D&trk=public_jobs_jserp-result_search-card,"Entreprise
Qui sommes-nous ?
Nous sommes passionnés par les nouvelles technologies, et vous ?
Rejoindre Amiltone, c'est intégrer des équipes dynamiques et soudées dans le cadre de projets novateurs et ambitieux. Nous relevons les challenges techniques de nos clients et les accompagnons dans leur transformation digitale.
Pourquoi choisir Amiltone ?
Amiltone, plus qu'une entreprise, un état d'esprit !
Notre objectif ? Votre épanouissement professionnel !
Nous Avons à Cœur De
Vous accompagner au mieux au travers d'un suivi personnalisé
Vous faire monter en compétences en vous proposant des formations tout au long de votre carrière
Comprendre vos besoins et respecter nos engagements
Vous proposer des missions de qualité avec des technologies innovantes
Cultiver votre potentiel grâce à notre programme de développement personnel Addvise
Votre bien-être passe aussi par des activités extraprofessionnelles, c'est pourquoi nous vous proposons des séances sportives animées par nos coachs, soirées pour se retrouver et animations (à l'agence ou en visio), Gaming nights...
Description Du Poste
Vos missions ?
Intégré à notre équipe de 10 personnes, vous assurez les missions suivantes :
Réceptionner et analyser la donnée brute
Traiter la donnée en streaming ou en statique
Adapter ou créer des modèles de machine learning
Evaluer la précision/robustesse d'un modèle
Outils de monitoring et de visualisation
Développement des modèles
Maintenir et documenter les codes et les process
La stack Technique :
Outils : MongoDB, PostgreSQL
NLP (IA générative)
Qlik Sense
Docker, Jenkins
Gitlab/Github
Description Du Profil
Alors ? Prêt à devenir Amiltonien ?
N'hésitez Pas à Postuler Si Vous Vous Reconnaissez
Diplômé bac+5 (école d'ingénieur ou master), vous avez au moins 2 ans d'expérience en tant que Data Scientist.
Vous aimez découvrir de nouveaux contextes fonctionnels et comprendre les objectifs des applications que vous développez.
A l'aise dans une organisation agile, vous faites preuve de rigueur et appliquez les standards de qualité Amiltone durant toute la durée des développements.
Outre vos compétences techniques, nous nous intéressons également à votre potentiel et votre motivation.
Nos postes sont ouverts aux personnes en situation de handicap.
Show more
Show less","{'ProgLanguage': ['R', 'Go'], 'DataBase': ['SQL', ' MongoDB'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git', 'Docker', 'Jenkins'], 'Os': [], 'DBMS': ['PostgreSQL'], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': ['Docker'], 'Collaboration': [], 'Other': ['Machine Learning'], 'FrSoftSkills': ['Organisation'], 'EnSoftSkils': []}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': ['Bac+5'], 'Experience': ['a', 'n', 's', '2', '2', '2']}"
LinkedIn,"Machine Learning Engineer, Fast Optimized Inference - EMEA Remote",Hugging Face,France,https://fr.linkedin.com/jobs/view/machine-learning-engineer-fast-optimized-inference-emea-remote-at-hugging-face-3848456024?position=53&pageNum=0&refId=EGCcUYgUshGnwQGGB%2BWgjg%3D%3D&trackingId=%2FCf3FGESZO5JC2xrY8Rbqg%3D%3D&trk=public_jobs_jserp-result_search-card,"Here at Hugging Face, we're on a journey to advance good Machine Learning and make it more accessible. Along the way, we contribute to the development of technology for the better.
We have built the fastest-growing, open-source, library of pre-trained models in the world. With more than 1 Million+ models and 320K+ stars on GitHub, over 15.000 companies are using HF technology in production, including leading AI organizations such as Google, Elastic, Salesforce, Algolia, Grammarly and NASA.
About the role:
As a Machine learning Engineer, you work mainly on creating great libraries highly focused on real world ML use cases. We're building on top of our open-source to create more specialized code with a focus on industrial level of usage.
We are searching for someone who brings fresh ideas, demonstrates a unique and informed viewpoint, and enjoys collaborating with a progressive, nimble and decentralized approach to develop real-world solutions and positive user experiences at every interaction.
Objectives of this role:
Develop specialized software for specific machine learning (ML) use cases that have broad applications, similar to [text-generation-inference](https://github.com/huggingface/text-generation-inference).
Utilize existing library frameworks to create scalable software solutions for industrial purposes.
Enhance the reliability, quality, and time-to-market of our software suite. Measure and optimize system performance to stay ahead of customer needs and drive innovation.
Manage the production environment by monitoring availability and ensuring overall system health. We run our own tools
About you:
If you are a passionate Machine Learning Engineer with a keen interest in AI and proficient with Python, Rust and specialized Cuda kernels Frameworks (transformers of course + Keras or PyTorch), we would love to hear from you. Join our team and contribute to the advancement of AI technologies while working alongside talented professionals in a collaborative and stimulating environment.
More about Hugging Face
We are actively working to build a culture that values diversity, equity, and inclusivity
.
We are intentionally building a workplace where people feel respected and supported—regardless of who you are or where you come from. We believe this is foundational to building a great company and community. Hugging Face is an equal opportunity employer and we do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.
We value development.
You will work with some of the smartest people in our industry. We are an organization that has a bias for impact and is always challenging ourselves to continuously grow. We provide all employees with reimbursement for relevant conferences, training, and education.
We care about your well-being
.
We offer flexible working hours and remote options. We offer health, dental, and vision benefits for employees and their dependents. We also offer flexible parental leave and paid time off.
We support our employees wherever they are
.
While we have office spaces in NYC and Paris, we're very distributed and all remote employees have the opportunity to visit our offices. If needed, we'll also outfit your workstation to ensure you succeed.
We want our teammates to be shareholders
.
All employees have company equity as part of their compensation package. If we succeed in becoming a category-defining platform in machine learning and artificial intelligence, everyone enjoys the upside.
We support the community
.
We believe major scientific advancements are the result of collaboration across the field. Join a community supporting the ML/AI community.
Show more
Show less","{'ProgLanguage': ['Python', 'Scala', 'R', 'Go'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': ['Keras', 'PyTorch'], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git'], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['ML', 'Machine Learning'], 'FrSoftSkills': ['Collaboration'], 'EnSoftSkils': ['Collaboration', 'Organization']}","{'JobDetail': ['Remote'], 'TypeContract': [], 'Salary': ['Package'], 'Level': [], 'Experience': ['a', 'n', 's']}"
LinkedIn,Data Scientist H/F,ADHERENCE CONSULTING,"Capinghem, Hauts-de-France, France",https://fr.linkedin.com/jobs/view/data-scientist-h-f-at-adherence-consulting-3913994542?position=54&pageNum=0&refId=EGCcUYgUshGnwQGGB%2BWgjg%3D%3D&trackingId=txs3CoClQyUwsnwaIctBaQ%3D%3D&trk=public_jobs_jserp-result_search-card,"Adherence Consulting : Votre partenaire IT de choix !
Implantés à Paris, Lille et Marseille, nous sommes au coeur de l'innovation technologique et organisationnelle.
Notre mission ? Booster votre performance et vous accompagner dans chaque étape de votre transformation digitale.
Si vous êtes prêt(e) pour une carrière qui dépasse vos attentes, c'est le moment !
https://www.adherence-consulting.fr/
Les missions du poste
Contexte
Adhérence Consulting est une ESN implanté à Paris, Lille et Marseille. Nous sommes au coeur de l'innovation technologique et organisationnelle.
Notre mission ? Booster les performances et accompagner nos clients à chaque étape de leur transformation digitale. Nous cherchons actuellement un Data Scientist (F/H) pour le projet de notre client.
Vous participerez à la construction de nombreux projets tous aussi ambitieux les uns que les autres.
Quelles sont vos missions au quotidien ?
Applique des techniques (statistiques, text mining, comportementale, géolocalisation,) d'extraction et d'analyse d'informations, obtenues à partir de gisements de données (Big Data)
Obtient des données adéquates, trouve les sources de données pertinentes, fait des recommandations sur les bases de données à consolider, modifier, rapatrier, externaliser, internaliser, conçoit des datamarts, voire des entrepôts de données (data warehouses).
Évalue la qualité et la richesse des données, les analyse et en restitue les résultats pour ensuite les intégrer dans le système d'information cible du Métier.
Analyse les données pour traduire une problématique Métier en problème mathématiques/statistiques et réciproquement.
Compare et évalue différents modèles ou méthodes de calcul et anticipe les avantages et inconvénients dans un environnement Métier.
Intervenant auprès des Métiers, il exploite, analyse et évalue la richesse, de données structurées ou non, appartenant à l'entreprise ou non, pour établir des scénarios permettant de comprendre et d'anticiper de futurs levier Métiers ou opérationnels pour l'entreprise
Show more
Show less","{'ProgLanguage': ['R'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': ['Statistiques'], 'CloudComputing': [], 'DevTools': ['Git'], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Big Data', 'Statistiques'], 'FrSoftSkills': ['Organisation'], 'EnSoftSkils': []}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's']}"
LinkedIn,"Ingénieur Data scientist –Intelligence artificielle-  IDF, France (H/F)",Astek,"Île-de-France, France",https://fr.linkedin.com/jobs/view/ing%C3%A9nieur-data-scientist-%E2%80%93intelligence-artificielle-idf-france-h-f-at-astek-3886897805?position=55&pageNum=0&refId=EGCcUYgUshGnwQGGB%2BWgjg%3D%3D&trackingId=YGjzmQWUDVjj3KqtpfRzEw%3D%3D&trk=public_jobs_jserp-result_search-card,"Ce que nous allons accomplir ensemble :
Pour l’un de nos projets dans le domaine aéronautique, vous interviendrez en tant
qu’ingénieur Data scientist / Intelligence artificielle
sur la mise en place de systèmes experts destinés aux avions civils et militaires.
Votre future équipe :
Team IT de 12 personnes
Data scientist, ingénieurs systèmes, intégrateurs, architectes
Vous travaillerez avec de véritables passionnés !
Votre mission (...si vous l’acceptez !) :
Vous participerez au développement des fonctions d’analyses multisystèmes. Pour cela vous assurerez l’établissement d’une spécification formelles sur les modèles d’analyses.
Vous assurerez l’analyse des données et la proposition de méthodes pour le traitement des signaux.
Vous développerez les outils capables de traiter de manière automatique les données systèmes.
Vous assurerez la réalisation des scénarios, ainsi que les tests et simulations.
Vous réaliserez également une activité de support.
Votre stack de jeu :
Data scientist, python, principe de gestion de configuration, et traçabilité, systèmes aéronautiques, intelligence artificielle
Les petits plus du projet :
Vous évoluerez au sein d’équipes agiles impliquées et réactives.
Vous interviendrez de A à Z sur des projets riches fonctionnellement et ambitieux techniquement :
forte volumétrie, haut niveau de performance, exigence maximale en termes d’intelligence artificielle et encore bien d'autres sujets captivants.
Vous ?
De formation Ingénieur, vous justifiez d’une expérience significative en Data scientist et ou Intelligence artificielle.
Une connaissance des méthodes d’analyse de données serait un plus.
Idéalement vous avez une connaissance des systèmes aéronautiques.
Des postes également ouverts aux débutants si stages significatifs.
Nous ?
Créé en France en 1988, Astek est un acteur mondial de l’ingénierie et du conseil en technologies, présent sur les 5 continents. Fort de son expertise dans de nombreux secteurs industriels et tertiaires, Astek accompagne ses clients internationaux dans le déploiement intelligent de leurs produits et de leurs services, et dans la mise en œuvre de leur transformation digitale.
Depuis sa création, le Groupe a fondé son développement sur une forte culture d’entrepreneuriat et d’innovation, et sur l’accompagnement et la montée en compétence de ses 5 200 collaborateurs qui s’engagent chaque jour à promouvoir la complémentarité entre les technologies numériques et l’ingénierie des systèmes complexes.
Rejoignez un Groupe en fort développement en France et à travers le monde grâce à une levée de fonds de 200M€ réalisée en 2021. Ensemble « Let’s move forward! »
✨ Tous les détails sur le Groupe sur le site
https://astekgroup.fr.
Et vous pouvez aussi nous suivre sur
notre blog : https://blog.groupeastek.com
.
Rencontrons-nous !
Vous vous êtes reconnu sur l’annonce et Astek vous plaît !
Pour en savoir plus sur vous, Franck , notre Talent Acquisition vous contacte. Puis, vous aurez 3 entretiens max, avec Léonard (votre futur n+1), Léonard notre Directeur !
Nos plus
Astek est green et fait bénéficier ses salariés d’une indemnité kilométrique vélo
Un programme CARE sur-mesure déployé par nos équipes RH pour nos collaborateurs : https://astekgroup.fr/engagements
Notre charte de la Diversité
Bienvenue dans la team ! Allez-y, maintenant c’est à vous de jouer !
Show more
Show less","{'ProgLanguage': ['Python', 'R'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git'], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': [], 'FrSoftSkills': [], 'EnSoftSkils': []}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's']}"
LinkedIn,Data Scientist F/H,Saint-Gobain,"Courbevoie, Île-de-France, France",https://fr.linkedin.com/jobs/view/data-scientist-f-h-at-saint-gobain-3915274420?position=56&pageNum=0&refId=EGCcUYgUshGnwQGGB%2BWgjg%3D%3D&trackingId=iVy%2FgS0TYo2WhSjVAsbIOQ%3D%3D&trk=public_jobs_jserp-result_search-card,"Why do we need you ?
Vous rejoindrez l’équipe « AI & Data Analytics », intégrée au département «Data & Analytics» dans l’organisation « Global Digital & IT». «Data & Analytics» regroupe les activités suivantes :
Data Engineering, Data Capture & Delivery, BI & Visualization, Platform & Architecture, Data Governance and Data Engagement.
Au Sein De L’équipe Data Science, Sous La Responsabilité Du Head Of AI & Data Analytics, Vous Aurez Le Rôle De Data Scientist (H/F). En Tant Que Tel, Vous Aurez Les Responsabilités Suivantes
Construire des modèles descriptifs et prédictifs sur des sujets en constante évolution ;
Mener des projets exploratoires faisant appel à des techniques avancées de Data Science (NLP, deep learning, Generative AI, apprentissage par renforcement ou par transfert), de façon autonome ou avec des partenaires externes ;
Assurer une veille technologique permanente sur ces sujets ;
Participer à l’industrialisation des algorithmes en lien avec les équipes engineering basée sur MLOps;
Accompagner les équipes opérationnelles dans le déploiement des algorithmes, notamment sur le volet analytics ;
Mener des ateliers d’idéation avec les équipes métiers (industrie, marketing, ventes, logistique, e-commerce, finance, RH) pour identifier les opportunités d’exploitation de la donnée et diffuser la culture data au sein de l’entreprise.
Si vous recherchez des défis passionnants, pouvant impacter des centaines de milliers de clients, et aimez travailler avec des outils à la pointe de la technologie, venez et rejoignez-nous !
Vous participerez donc à la montée en puissance de l’équipe créée récemment, tout en intervenant sur un ou plusieurs cas d’utilisation.
Is this job for you ?
En complément des missions évoquées, une réelle appétence pour la gestion et la facilitation de projet, avec une certaine aisance en termes de communication, seraient fortement appréciées.
Notre équipe ayant vocation à travailler pour des clients internes pouvant être basés en France comme à l’étranger, la maitrise de l’anglais (écrite et orale) est obligatoire.
Profil recherché
Ingénieur diplômé d’une école généraliste (Centrale, X, Mines, ENS etc.) ayant au minimum 3 années d'expérience après le diplôme.
Grande connaissance du Machine Learning, des statistiques et des probabilités.
SQL et Python, packages de ML: scikit, xgboost, keras
Expérience de travail sur un cloud provider et savoir construire des data pipelines serait un plus
Gestion de code : Git, Gitlab, CI/CD
Maitriser la modélisation à la fois prédictive et descriptive
Savoir implémenter des dashboards et autres outils de data viz
Posséder de bonnes qualités de communication : vous pouvez expliquer vos modèles clairement à la fois à des data analysts mais aussi à des Directeurs Généraux ou des responsables opérationnels.
Etre organisé, structuré et motivé par l’innovation
Aimer le travail en équipe et savoir apprendre de chacun.
Un état d’esprit orienté business et apport de valeur pour les équipes métiers
A Little More About Us
Saint-Gobain est une entreprise française spécialisée dans la production, la transformation et distribution de matériaux.
Fondée en 1665 par Jean-Baptiste Colbert sous le nom de Manufacture royale des glaces, l'entreprise est présente dans soixante-sept pays et emploie en 2018 près de 180 000 personnes
To make sure nothing is forgotten
Détails pratiques du rôle
Début : Dès que vous êtes prêts
Localisation : La Tour Saint-Gobain, La Défense
Contrat: CDI
Saint-Gobain encourage la diversité des équipes et favorise notamment l’inclusion des personnes en situation de handicap.
Show more
Show less","{'ProgLanguage': ['Python', 'R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': ['Keras', 'XGBoost'], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': ['Statistiques'], 'CloudComputing': [], 'DevTools': ['Git'], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['ML', 'Machine Learning', 'Statistiques', 'Cloud', 'CI/CD'], 'FrSoftSkills': ['Communication', 'Organisation'], 'EnSoftSkils': ['Communication']}","{'JobDetail': [], 'TypeContract': ['CDI'], 'Salary': ['1665'], 'Level': [], 'Experience': ['a', 'n', 's']}"
LinkedIn,Machine Learning Developer,MindPal,"Lyon, Auvergne-Rhône-Alpes, France",https://fr.linkedin.com/jobs/view/machine-learning-developer-at-mindpal-3910999113?position=57&pageNum=0&refId=EGCcUYgUshGnwQGGB%2BWgjg%3D%3D&trackingId=uPBqLe0DylWuIDmsP56kxw%3D%3D&trk=public_jobs_jserp-result_search-card,"We are looking for
Machine Learning Developer
Job Responsibilities
Working on machine learning projects
Analyzing and processing data to create machine learning models
Implementing and optimizing machine learning algorithms
Testing and evaluating models
Collaborating with the programming team and other departments within the company to develop innovative solutions
Requirements
Minimum 2 years of experience in the field of machine learning
Knowledge of machine learning algorithms and techniques
Ability to analyze and process data
Familiarity with machine learning tools and technologies
Proficient in English communication
Education in computer science
We Offer
B2B contract type
Full-time employment
Remote and flexible working hours
Show more
Show less","{'ProgLanguage': ['R', 'Go'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Machine Learning'], 'FrSoftSkills': ['Communication'], 'EnSoftSkils': ['Communication']}","{'JobDetail': ['Remote', 'Full'], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's']}"
LinkedIn,DATASCIENTIST,GROUPE ALLIANCE,"Île-de-France, France",https://fr.linkedin.com/jobs/view/datascientist-at-groupe-alliance-3916080098?position=58&pageNum=0&refId=EGCcUYgUshGnwQGGB%2BWgjg%3D%3D&trackingId=eMJBqkidRy5X4xpxKR2WIQ%3D%3D&trk=public_jobs_jserp-result_search-card,"SI LA GESTION DES DONNEES EST TON DADA, TU PEUX GAGNER LA COURSE EN LISANT CETTE ANNONCE …
Ce que tu recherches :
au sein d’une équipe dynamique
à des projets innovants d’envergure
des défis
un nouveau souffle à ta carrière
Alors nous avons la mission idéale pour toi.
Au sein d’acteurs majeurs du secteur Bancaire, tu participeras des projets d’envergure sur des évolutions majeures à mettre en œuvre dans le SI du client :
des besoins, tu feras
techniques, tu rédigeras
et/ou socle technique, tu définiras
pratiques, tu instaureras
nouvelles fonctionnalités, tu développeras
bug, tu laisseras
équipe, tu accompagneras
instances de pilotage, tu participeras
Qui tu es :
de la formation qui va bien
ou dôté(e) d’une expérience de 3 ans minimum
de la Stack technique machine learning et python
avec les Frameworks et Outils : Ttensorflow, pytorch,scikit-learn, numpy, pandas
Au-delà des compétences techniques, tu es :
: tu n’aimes pas rester les deux pieds dans le même sabot
: un guide du Routard te suffira
de synthèse : tu sais aller à l’essentiel
d’adaptation : tu es un vrai caméléon
de la communication : les mots n’ont pas de secret pour toi
de proposition : tu es l’Aladdin de l’informatique
d’équipe : un pour tous et tous pour un !
Show more
Show less","{'ProgLanguage': ['Python', 'R'], 'DataBase': [], 'DataAnalytics': ['Pandas', 'NumPy', 'R'], 'BigData': [], 'MachingLearning': ['Scikit-Learn', 'TensorFlow', 'PyTorch'], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Machine Learning'], 'FrSoftSkills': ['Communication'], 'EnSoftSkils': ['Communication']}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's', '3', '3', '3']}"
LinkedIn,Data Scientist,CRIT France,Greater Saint-Etienne Metropolitan Area,https://fr.linkedin.com/jobs/view/data-scientist-at-crit-france-3908277901?position=59&pageNum=0&refId=EGCcUYgUshGnwQGGB%2BWgjg%3D%3D&trackingId=nZJOgHHRNA%2FamPFJynXc5A%3D%3D&trk=public_jobs_jserp-result_search-card,"Vous souhaitez rejoindre une entreprise, leader dans les Énergies Renouvelables et travaillant en mode projet ? Le domaine de la Data et de l'ingénierie informatique n'a plus aucun secret pour vous ? 🚀
Notre
Cabinet CRIT Experts & Cadres
recherche pour l’un de nos clients situé à proximité de Saint-Etienne,
un
Data Scientist H/F
, en CDI.
🌐 Qui est notre client ?
Leader et fleuron de l’énergie électrique, notre client est basé à proximité de Saint-Étienne (42), est une entreprise qui conçoit, produit et installe des systèmes automatisés, de conversion et de stockage d’énergie électrique
🌎 Les engagements de l’entreprise ?
#satisfaction client
#respect de la personne
#performance
#solidarité et le travail d’équipe
#intégrité
#développement des talents
Pourquoi postuler ?
Bien qu'étant une entreprise avec des projets à l'international, notre client su rester à taille humaine. Le fonctionnement en mode Projet offre la possibilité à leurs collaborateurs de s'impliquer et d'apporter leurs compétences à des projets variés. Leurs projets sont des défis techniques qui offrent la possibilité de travailler sur un cycle complet, de la conception à la mise en service.
📌 Quel sera votre rôle ?
Collecter, analyser et interpréter des données pour aider l'entreprise à prendre des décisions stratégiques basées sur des données probantes.
Rattaché hiérarchiquement directement au Président, vos missions seront :
Collecter, nettoyer et manipuler de grandes quantités de données provenant de diverses sources, y compris des bases de données internes et externes, des API et des données non structurées.
Développer et mettre en œuvre des modèles prédictifs et des algorithmes d'apprentissage automatique pour résoudre des problèmes commerciaux complexes.
Effectuer des analyses statistiques approfondies pour identifier des tendances, des modèles et des insights significatifs.
Travailler en étroite collaboration avec les équipes interfonctionnelles pour comprendre leurs besoins en matière de données et fournir des solutions analytiques.
Créer des tableaux de bord interactifs, des visualisations de données et des rapports pour communiquer efficacement les résultats de l'analyse aux parties prenantes.
Maintenir une veille technologique constante sur les avancées en matière de science des données et proposer des améliorations continues aux processus et méthodologies existants.
Vos responsabilités et périmètre d’action :
Sous directives et objectifs fixés par votre responsable hiérarchique, le Président :
Être conscient des risques et prendre des mesures appropriées pour protéger les données et les systèmes contre les menaces.
🎯
Profil recherché :
Domaine des sciences de données : informatique, en mathématiques, en statistiques, en économie, en sciences de l'informatique, en gestion, en ingénierie industrielle ou dans un domaine connexe.
Expérience antérieure dans un rôle similaire.
Maîtrise de l’anglais.
💡 Vos cartes secrètes idéales ?
👉 Connaissance des concepts en collecte, extraction & analyse de données.
👉 Compétences analytiques.
👉 Capacité à communiquer des informations complexes de manière claire et compréhensible.
👉 Capacité à travailler de manière collaborative.
👉 Maîtrise des langages de programmation courants tels que Python, R ou SQL.
👉 Solides compétences en analyse statistique et en modélisation prédictive.
👉 Expérience pratique avec les bibliothèques et les frameworks d'apprentissage automatique tels que TensorFlow, Scikit-Learn ou PyTorch.
Autres informations :
Contrat
: CDI
Statut
: cadre
Salaire
: en fonction du profil – à définir
📍
Lieu
: à proximité de Saint-Etienne
Avantages salariaux : Prime participation salariale, Tickets Restaurants, CSE…
Déplacements à prévoir :
France – EMEA Germany, Italy, Spain, UK
Fréquence : selon besoin de l’activité
Show more
Show less","{'ProgLanguage': ['Python', 'R', ' R ', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R', ' R '], 'BigData': [], 'MachingLearning': ['Scikit-Learn', 'TensorFlow', 'PyTorch'], 'DataSerialization': [], 'DataVisualization': ['Tableau'], 'Statistics': ['Statistiques'], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Statistiques'], 'FrSoftSkills': ['Collaboration'], 'EnSoftSkils': ['Collaboration']}","{'JobDetail': [], 'TypeContract': ['CDI'], 'Salary': ['Salaire'], 'Level': [], 'Experience': ['a', 'n', 's']}"
LinkedIn,Data Scientist H/F,Lincoln France,"Île-de-France, France",https://fr.linkedin.com/jobs/view/data-scientist-h-f-at-lincoln-france-3892490370?position=1&pageNum=2&refId=EAisFcfNV4WNL6Xe9UKYqQ%3D%3D&trackingId=CNMoLfhdQ3H5Q5uqpxWVcA%3D%3D&trk=public_jobs_jserp-result_search-card,"CDI
📊
4 ans minimum
Chez Lincoln
, nous formons une communauté d'innovateurs passionnés qui redéfinissent l'analyse de données depuis
plus de 30 ans
. En tant que
Pure Player Data
, notre expertise est reconnue dans les domaines
de la Modern BI, du Big Data et de la Science des données
.
Notre mission ?
Transformer les données en solutions concrètes pour nos clients grands comptes dans divers secteurs tels que la banque, le retail, les télécoms, l'industrie, la santé, etc.
Description du poste
Nous recherchons un
Data Scientist H/F
pour accompagner nos clients dans leurs projets stratégiques.
Vos missions
Collecter, nettoyer et préparer les données pour l'analyse.
Concevoir, développer et mettre en œuvre des modèles prédictifs et analytiques en utilisant des techniques avancées d'apprentissage automatique et de science des données.
Analyser les résultats des modèles et fournir des insights exploitables aux équipes clients.
Collaborer avec les équipes interfonctionnelles pour comprendre les besoins commerciaux et recommander des solutions basées sur les données.
Prérequis :
Solides compétences en programmation (
Python, R, SQL, etc.)
et en manipulation de données.
Expérience pratique avec des frameworks et des bibliothèques d'apprentissage automatique (
TensorFlow, PyTorch, Scikit-learn
,
etc
.).
Maîtrise des techniques avancées d'analyse de données, y compris l'apprentissage automatique, l'apprentissage profond, la vision par ordinateur, le traitement du langage naturel, etc.
Expérience de travail en
méthode Agile
pour la gestion de projet et le développement de solutions.
Capacité à travailler de manière autonome et en équipe.
Excellentes compétences en communication et en présentation.
Les plus du poste
Environnement Collaboratif
: projets innovants favorisant le partage des connaissances.
Accompagnement individualisé et de proximité
: formations certifiantes, attribution d’un Career Manager pour vous orienter dans votre trajectoire professionnelle, opportunités d’évolution de carrière.
Flexibilité du Travail
: Télétravail et horaires flexibles pour votre équilibre vie professionnelle-personnelle.
Rémunération Compétitive
: Salaire compétitif avec des avantages sociaux attrayants.
Mobilité
: Possibilité de mobilité à Lille, Lyon ou Aix-en-Provence offrant des expériences diversifiées au sein de Lincoln.
Notre processus de recrutement :
Un entretien RH (1h) et entretien technique (1h)
Cette annonce n’est pas faite pour vous si :
Vous êtes freelance et vous comptez le rester !
Toujours là ? Postulez et rejoignez nos
400 experts en Data
😉.
Show more
Show less","{'ProgLanguage': ['Python', 'R'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': ['Scikit-Learn', 'TensorFlow', 'PyTorch'], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Big Data'], 'FrSoftSkills': ['Communication', 'Flexibilité'], 'EnSoftSkils': ['Communication']}","{'JobDetail': [], 'TypeContract': ['CDI'], 'Salary': ['400'], 'Level': [], 'Experience': ['a', 'n', 's', '4', '4', '4']}"
LinkedIn,Data Scientist H/F,MERITIS,"Île-de-France, France",https://fr.linkedin.com/jobs/view/data-scientist-h-f-at-meritis-3869246366?position=2&pageNum=2&refId=EAisFcfNV4WNL6Xe9UKYqQ%3D%3D&trackingId=jUhkq4MU7YKcmyS9Qi7KKQ%3D%3D&trk=public_jobs_jserp-result_search-card,"Nous recherchons un
Data Scientist
pour intervenir dans le cadre d'un
projet de détection de document.
Vos missions :
Sujet de
fraude documentaire:
la problématique est de détecter si un document (RIB ou pièce d’identité) a été manipulé (montage, remplacement de la photo d’identité, changement du nom/prénom, ou de l’IBAN etc).
Les technos connues utilisées:
Python avec les libs/framework suivants : pytorch, jupyterlab, pandas
Modèles : layoutLM (techno à priori assez récente), yolo, resnet (classique), docTR (ocr)
Connaitre les transformers
Autre : Labelstudio
Ce poste est-il fait pour vous
? :
Vous êtes diplômé d'un
Bac +5
et justifiez d'
au moins 4 ans d'expérience
Vous êtes
proactif et autonome ​
Vous aimez travailler
au contact de plusieurs équipes métiers
Connaissance du secteur de l'assurance obligatoire
Descriptif de l’entreprise :
​
Meritis est un cabinet de conseil, pilotage et développement IT fondé en 2007 présent à Paris, Sophia-Antipolis, Aix-en-Provence, Montpellier, Toulouse, Nantes... Et bientôt sur de nouveaux territoires ! Notre mission ? Connecter les meilleurs talents aux entreprises pour leur donner un temps d’avance.​
Nous accompagnons nos clients dans l’intégralité de leurs besoins en transformation numérique à travers de nombreux domaines d’expertises : Software Engineering, Finance, Pilotage de projets, Devops, Data, Cloud, Cybersécurité ou encore Agilité.​
Intervenant aussi bien dans les secteurs de la Banque, de l'Assurance, des Télécommunications que de l'Industrie ou des Transports, aujourd'hui 40% des entreprises du CAC40 sont clientes Meritis.​
Fort de nos valeurs d’exigence, d’humilité, de bienveillance et de proximité, nous comptons aujourd’hui plus de 900 collaborateurs.​
Nous mettons un point d’honneur à être proche de nos collaborateurs et à les accompagner de manière individualisée quelles que soient leurs fonctions dans l’entreprise.
Certifiée Great Place To Work depuis 2013, notre conception du bien-être au travail va bien au-delà d'un simple label, ce sont nos collaborateurs qui en parlent le mieux : https://www.glassdoor.fr/Avis/Meritis-Avis-E1163008.htm.​
Vos différences sont nos atouts. C’est pourquoi Meritis est engagée en faveur de la diversité et de la non-discrimination. Tous nos métiers sont accessibles aux personnes en situation de handicap. Si vous avez une question ou pensez être victime ou témoin d’une discrimination, vous pouvez contacter ethiquegroup@meritis.fr. »
Show more
Show less","{'ProgLanguage': ['Python', 'R'], 'DataBase': [], 'DataAnalytics': ['Pandas', 'R'], 'BigData': [], 'MachingLearning': ['PyTorch'], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['DevOps', 'Cloud'], 'FrSoftSkills': ['Communication'], 'EnSoftSkils': ['Communication']}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's', '4', '4', '4']}"
LinkedIn,Data Scientist: Flexible working,SoftwareOne,"Levallois-Perret, Île-de-France, France",https://fr.linkedin.com/jobs/view/data-scientist-flexible-working-at-softwareone-3872563771?position=3&pageNum=2&refId=EAisFcfNV4WNL6Xe9UKYqQ%3D%3D&trackingId=GH0UFelX%2FcmY9RQT5cwbGA%3D%3D&trk=public_jobs_jserp-result_search-card,"Why SoftwareOne?
SoftwareOne is a leading global software and cloud solutions provider that is redefining how companies build, buy and manage everything in the cloud. By helping clients to migrate and modernize their workloads and applications – and in parallel, to navigate and optimize the resulting software and cloud changes – SoftwareOne unlocks the value of technology. The company’s 8,900 employees are driven to deliver a portfolio of 7,500 software brands with sales and delivery capabilities in 90 countries. Headquartered in Switzerland, SoftwareOne is listed on the SIX Swiss Exchange under the ticker symbol SWON. Visit us at https://www.softwareone.com/en
The role
DATA Scientist
The primary focus for a candidate will be in applying different techniques (data mining/statistical analysis/build prediction systems/recommendation systems) using large company data sets to find opportunities for services and products and using models to test the effectiveness of different courses of action. The Candidate must have strong experience using a variety of data mining/data analysis methods, using a variety of data tools, building and implementing models, using/creating algorithms and creating/running simulations.
Work with business cases to identify opportunities for leveraging company data to drive business solutions.
Mine and analyze data from company databases to drive optimization and improvement of product development and sales techniques
Assess the effectiveness and accuracy of new data sources and data gathering
Extending company’s data with third party sources of information when needed
Use predictive modeling to increase revenue generation, ad targeting and other business outcomes.
What We Need To See From You
Core:
Analyze business cases and identify data sources (internal/external) and data mining/analysis methods to use
Develop a normalization engine to execute cleansing/deduplication for a raw data through ETL process for data sources
Create, train and test predictive models to solve defined business cases
Develop algorithms to apply to data sets
Design data structure models for collected data
Facilitate the build of a solution from PoC to production
Work with business owners to gather additional information about business cases
Job Specific:
Work with Google Cloud data and AI tools
Be ready to work in agile style (daily, sprint planning, sprint review, retrospective)
Work in an environment that adapts quickly to creative change using agile principles
Actively work with different development groups inside of organization
Be ready to adapt a new tool/library/technology/platform
Desirable Skills:
Fluent in French and English
At least 4 years experience in Machine learning models creation
Master’s in Statistics, Mathematics, Computer Science preferred
Professional Machine learning engineering certification
Experience with common data science toolkits and libraries, such as pandas, keras, scipy, scikit, tensorflow, NumPy etc
Knowledge and interest in the following:
prediction models, Vertex AI, Tenserflow, BigQuery ML, Python,
natural language processing, deep learning models, dataPROC, Hadoop, SQL
Experience using statistical computer languages namely Python to manipulate data and draw insights from large data sets
Strong knowledge and experience using SQL language
Experience with C++/C# and Java as a plus
Background in technology or professional services preferably in one or more of the domains of GCP and Security,
Strong understanding of consulting business
Strong structural work methods, multitasking and time management skills
Self-driven independent work ethics that drives internal and external accountability
May require periodic travel for workshops
Job Function
Software & Cloud Services
Show more
Show less","{'ProgLanguage': ['Python', 'Java', 'C++', 'C#', 'R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['Pandas', 'NumPy', 'R'], 'BigData': ['Hadoop'], 'MachingLearning': ['TensorFlow', 'Keras'], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': ['Statistics'], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'DBMS': ['BigQuery'], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['ML', 'Machine Learning', 'Cloud'], 'FrSoftSkills': [], 'EnSoftSkils': ['Time Management', 'Organization']}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's']}"
LinkedIn,Data Scientist,Capital Fund Management (CFM),"Paris, Île-de-France, France",https://fr.linkedin.com/jobs/view/data-scientist-at-capital-fund-management-cfm-3911800992?position=4&pageNum=2&refId=EAisFcfNV4WNL6Xe9UKYqQ%3D%3D&trackingId=VcFHLZSmJrY3LMj3cbA0Vw%3D%3D&trk=public_jobs_jserp-result_search-card,"ABOUT CFM
Founded in 1991, we are a global quantitative and systematic asset management firm applying a scientific approach to finance to develop alternative investment strategies that create value for our clients.
We value innovation, dedication, collaboration and the ability to make an impact and together we create an environment for talented and passionate experts in research, technology and business to explore new ideas and challenge assumptions.
ABOUT THE ROLE
The context :
Data is the fuel that powers our investment strategies: intraday price dynamics are used to better our investment decisions; buy/sell intents of market participants help to trade at the best available price… Cfm Data team is in charge of preparing the data to make quant research easier and trading more reliable.
The position
As a Data Scientist and Tick Data Specialist, your involvement will be crucial to the effectiveness of our strategies. You will be tasked with identifying and specifying new input features from tick data to fuel our alpha predictor, constructing data pipelines, and guaranteeing their smooth functioning. This role necessitates strong collaboration with researchers, primarily aimed at furnishing them with essential data and tools to refine our trading strategies.
Key Responsibilities:
You collaborate with the research team to innovate and introduce new predictive features,
You provide functional and technical support to quantitative researchers,
You design and develop data pipelines,
You contribute to the enhancement of our platform tooling.
SKILLSET REQUIREMENTS/QUALIFICATIONS
You boast significant experience in financial markets, with a tenure of 7 years or more.
You have a comprehensive expertise in Matching Engines, Orderbooks, and High-Frequency Data,
You demonstrate recognized expertise in data science with a thorough mastery of its tools.
Your familiarity with big data technologies like Spark or Dask, coupled with proficiency in machine learning, would be highly advantageous.
Experience with C++ is considered an additional asset.
You exhibit a strong enthusiasm for technology.
As a collaborative team player, you excel in communication, particularly with quant teams.
Proficiency in French is an additional advantage.
EQUAL OPPORTUNITIES STATEMENT
We are continuously striving to be an equal opportunity employer and we prohibit any discrimination based on sex, disability, origin, sexual orientation, gender identity, age, race, or religion. We believe that our diversity, breadth of experience, and multiple points of view are among the leading factors in our success.
CFM is a signatory of the Women Empowerment Principles
FOLLOW US
Follow us on Twitter and LinkedIn or visit our website to find out more about CFM.
Show more
Show less","{'ProgLanguage': ['C++', 'R'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': ['Spark'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': ['Teams'], 'Other': ['Big Data', 'Machine Learning'], 'FrSoftSkills': ['Communication', 'Collaboration'], 'EnSoftSkils': ['Communication', 'Collaboration']}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's']}"
LinkedIn,Data scientist F/H,METEOJOB by CleverConnect,"Rontignon, Nouvelle-Aquitaine, France",https://fr.linkedin.com/jobs/view/data-scientist-f-h-at-meteojob-by-cleverconnect-3916294538?position=5&pageNum=2&refId=EAisFcfNV4WNL6Xe9UKYqQ%3D%3D&trackingId=j16vTOYQSrY1mtDyF6apzQ%3D%3D&trk=public_jobs_jserp-result_search-card,"Entreprise
Cabinet de recrutement de dimension internationale, bénéficiant de l'expérience d'un grand Groupe RH, S&you est spécialisé dans le recrutement d'Experts, Cadres et Métiers du tertiaire. Nos 50 consultants expérimentés mettent en œuvre tout notre savoir-faire pour vous accompagner au mieux dans vos projets (recrutement, bilan professionnel, coaching, formation…). La relation de confiance que nous créons avec nos candidats et nos clients représente pour nous le facteur-clé de la performance.
Description Du Poste
Votre profil Vous disposez des compétences et aptitudes nécessaires à l'appropriation du périmètre du poste :
Formation supérieure Bac + 5 (statistiques, mathématiques appliquées …)
Expérience significative (2 ans alternance incluse) en qualité de data scientist / data analyst incluant idéalement une expérience en secteur assurantiel.
Maîtrise / connaissance de l'environnement technique : Python, SQL, R, algorithmes et frameworks, machine learning, RPA, datavisualisation (Power BI, Tableau)
Curiosité, discernement, agilité et esprit d'initiative : appropriation de données complexes, compréhension de problématiques transverses, veille technologique, proposition de solutions
Description Du Profil
Notre client est un acteur clé du secteur assurantiel dont les 250 collaborateurs accompagnent les compagnies et intermédiaires d'assurance sur l'ensemble des sujets intéressant la profession (information, concertation, mise en œuvre) : assurance de biens et responsabilités, assurance de personne, réassurance, co-assurance, évolutions réglementaires et conventionnelles, maîtrise des risques, médiation, intermédiation, référentiels …Notre client recrute un.e Data Scientist dans le cadre d'une création de poste (CDI) en vue d'accompagner le développement de sa stratégie Data.
Show more
Show less","{'ProgLanguage': ['Python', 'R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': ['Tableau', 'Power BI'], 'Statistics': ['Statistiques'], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Machine Learning', 'Statistiques'], 'FrSoftSkills': [""Esprit d'initiative""], 'EnSoftSkils': ['Initiative']}","{'JobDetail': [], 'TypeContract': ['CDI'], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's', '2', '2', '2']}"
LinkedIn,Machine Learning Engineer,HackerPulse,France,https://fr.linkedin.com/jobs/view/machine-learning-engineer-at-hackerpulse-3917868826?position=7&pageNum=2&refId=EAisFcfNV4WNL6Xe9UKYqQ%3D%3D&trackingId=ZnU7XW04Z7AJsOBxKX8wOQ%3D%3D&trk=public_jobs_jserp-result_search-card,"Showcase your software engineering talents using ML-powered profiles. Loved by 11k+ engineers! Backed by Antler.
The Role
You Will Be Responsible For
Developing scripts to process structured and unstructured data.
Recommending, developing and implementing ways to improve data reliability, efficiency and quality.
Supporting translation of data business needs into technical system requirements.
Working with stakeholders to understand needs in order with respect to data structure, availability, scalability and accessibility.
Developing high-quality code to build and deploy machine learning models.
Ideal Profile
You possess a degree in Computer Science, Applied Mathematics, Engineering or related field.
You have at least 1 year experience, ideally within a Data Engineer role.
Demonstrated experience working with large and complex data sets as well as experience analyzing volumes of data.
You are a strong networker & relationship builder
You pay strong attention to detail and deliver work that is of a high standard
You are a self-starter and demonstrate a high level of resilience
What's on Offer?
Great work environment
Excellent career development opportunities
Leadership Role
Show more
Show less","{'ProgLanguage': ['Scala', 'R'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['ML', 'Machine Learning'], 'FrSoftSkills': ['Leadership'], 'EnSoftSkils': ['Leadership']}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's']}"
LinkedIn,Data scientist H/F,MP DATA,"Clermont-Ferrand, Auvergne-Rhône-Alpes, France",https://fr.linkedin.com/jobs/view/data-scientist-h-f-at-mp-data-3904074177?position=8&pageNum=2&refId=EAisFcfNV4WNL6Xe9UKYqQ%3D%3D&trackingId=chgwalNrt%2BjVYc%2BI5vYZHw%3D%3D&trk=public_jobs_jserp-result_search-card,"MP DATA est une société spécialisée dans l’acquisition, le traitement, et la valorisation des données. Depuis sa création en 2015, MP DATA accompagne ses clients, majoritairement industriels, dans le management de leur performance et l’exploitation de leur donnée.
Les collaborateurs, tous issus de grandes écoles, incarnent au quotidien les valeurs d’Excellence, de Partage et d’Engagement. Ils associent savoir-faire technique, méthodologie et passion et mettent leurs compétences au service de missions et projets au sein de grands groupes français.
MP DATA accompagne ses clients sur toute la chaine au travers de 3 pôles d’expertise : Conseil et Stratégie, Infrastructure & CloudOPS, Data Science.
Nous recherchons un(e) Data Scientist passionné(e) pour rejoindre notre équipe dynamique.
En tant que membre clé du pôle Data Science de notre client, un grand acteur du secteur automobile, vous serez chargé(e) d'analyser, interpréter et exploiter les données pour fournir des solutions innovantes à nos clients.
Conception et mise en œuvre de modèles prédictifs et d'algorithmes avancés.
Analyse approfondie des données pour identifier des tendances et des opportunités.
Collaboration étroite avec les équipes clients pour comprendre leurs besoins et définir des solutions sur mesure.
Participation active à la veille technologique et à l'amélioration continue de nos pratiques en Data Science.
Profil :
Diplôme
ingénieur Grande École
en Data Science, Statistiques, Informatique ou domaine connexe.
Expérience pratique dans le développement et l'application de modèles prédictifs,
Maîtrise des langages de programmation tels que Python,
Excellentes compétences analytiques et capacité à traduire des résultats complexes en recommandations claires,
Forte aptitude à travailler en équipe et à communiquer efficacement.
Show more
Show less","{'ProgLanguage': ['Python', 'R', 'Go'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': ['Statistiques'], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Statistiques', 'Cloud'], 'FrSoftSkills': ['Collaboration'], 'EnSoftSkils': ['Collaboration']}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's']}"
LinkedIn,"Data Scientist - Python (Mid-senior, Senior)",Pathway,"Paris, Île-de-France, France",https://fr.linkedin.com/jobs/view/data-scientist-python-mid-senior-senior-at-pathway-3887683294?position=9&pageNum=2&refId=EAisFcfNV4WNL6Xe9UKYqQ%3D%3D&trackingId=AG47%2Fhm4cbgAjP6i4KQGBw%3D%3D&trk=public_jobs_jserp-result_search-card,"About Pathway
Deeptech start-up, founded in March 2020.
Our primary developer offering is an ultra-performant Data Processing Framework (unified streaming + batch) with a Python API, distributed Rust engine, and capabilities for data source integration & transformation at scale (Kafka, S3, databases/CDC,...)
The single-machine version is provided on a free-to-use license (`pip install pathway`)
Major data use cases are around event-stream data (including real-world data such as IoT), and graph data that changes over time
Our enterprise offering is currently used by leaders of the logistics industry, such as DB Schenker or La Poste, and tested across multiple industries. Pathway has been featured in Gartner's market guide for Event Stream Processing
Learn more at http://pathway.com/ and https://github.com/pathwaycom/
Pathway is VC-funded, with amazing BAs from the AI space and industry. We have operations across Europe and in the US. We are headquartered in Paris, with significant support from the French ecosystem (BPI, Agoranov, WILCO,...).
The Team
Pathway is built by and for overachievers. Its co-founders and employees have worked in the best AI labs in the world (Microsoft Research, Google Brain, ETH Zurich), worked at Google, and graduated from top universities (Polytechnique, ENSAE, Sciences Po, HEC Paris, PhD obtained at the age of 20, etc...). Pathway's CTO is a co-author with Goeff Hinton and Yoshua Bengio. The management team also includes the co-founder of Spoj.com (1M+ developer users) and NK.pl (13.5M+ users) and experienced growth leader who has scaled companies with multiple exits.
The opportunity
We are currently searching for
Data Scientists
with
experience in the Python stack
, to help explore and discover the most pertinent insights in datasets on spatio-temporal event streams. In this job, statistical rigor and beauty of visualization meet on equal footing.
You Will
be working with spatiotemporal data with advanced schemas (time-changing graph models)/
be designing data cross-sections, proposing analytics metrics and KPI's in line with clients' objectives, selecting clustering algorithms, and preparing visualizations, to enable fast data exploration and insight discovery - all within our product
be designing dashboards in SQL with some Python elements/extensions
be directly helping us with Customer Conversion and Adoption within Customer organizations, by contributing to both deployment instances and ""demonstrators"" of our product, performed on client data sets
work directly with our Product Owner and CTO to propose and implement extensions to our product, based on repetitive client needs
depending on your seniority, implement machine learning algorithms on spatiotemporal event streams and other geospatial data
The results of your work will play a crucial role in proving how our technology can help with compelling industry use cases.
Requirements
You Are
Ready for hands-on contribution to the product, helping to ensure the success of demonstrators for clients, and contribution to product codebase
Intuitive, with good visual taste, and good common sense judgment
Committed to beautiful user-centered design: you know that stories are made for people, and you are willing to listen to what they have to say
Curious at heart and thrilled to work with real-world data, especially spatio-temporal data
Like trains, trucks, cranes, pythons, pandas, and other things that move
Not afraid to switch between the roles of data scientist, data-vis magician, statistician, engineer, and detective, at a moment's notice
Have 2 years+ experience in positions related to Data Science.
Have a very good working knowledge of Python
Know SQL. Are able to work with tables and other data types (arrays, json,...)
Would be able to implement the Transit Node Routing algorithm in Python just based on reading its Wikipedia article
Have experience with git, build systems, and CI/CD
Have at least basic undergrad textbook familiarity with graph algorithms, finite automata, and text (string) search algorithms
Understand statistical concepts, such as correlated random variables, significance, and non-Gaussian noise
Prepared to be quizzed & grilled by the datasets you encounter, everyday. Here are some questions you should be able to answer off the top of your head: what can ""-273.15"" signify; why ""65535"" is a suspicious integer value; how many months does it take a containership to go around the world; and, roughly what order of g-force is attained by an astronaut in a space rocket at liftoff?
Respectful of others
Fluent in English
Bonus Points
Showing a portfolio: code on github, visualization works, a research paper or a PhD thesis with an original statistical / probabilistic analysis or experiment design,..
Successful track-record in Data Science or algorithms contests (Kaggle, Codeforces,...)
Experience in topics linked to logistics/moving assets
Familiarity with some form of GIS software
Familiarity with Pandas, SciPy, NetworkX, and similar tools from the Python stack
Experience in Data Visualization and UX
Some knowledge of French, Polish, or German
Why You Should Apply
Join an intellectually stimulating work environment
Be a pioneer: you get to work with a new type of data processing
Work in one of the hottest data/AI startups in France
Uncover exciting career prospects
Make significant contribution to our success
Join & co-create an inclusive workplace culture
Benefits
Type of contract: Permanent employment contract
Preferable joining date: February 2023. The positions (at least 2) are open until filled
Compensation: annual salary of €50K-€70K (mid) up to €60K-€90K (senior, upper band negotiable) + Employee stock option plan
Location: Remote work from home. Possibility to work or meet with other team members in one of our offices:
Paris Area - Drahi X-Novation Center, Ecole Polytechnique, Palaiseau
Paris - Agoranov (where Doctolib, Alan, and Criteo were born) near Saint-Placide Metro (75006)
Wroclaw - University area
Permanent residence will be required in France or Poland, exceptional candidates will be considered anywhere in the EU.
If you meet our broad requirements but are missing some experience, don't hesitate to reach out to us.
Note
: CS & engineering school students with exceptional profiles and/or strong motivation to join Pathway are invited to apply for Data Science internships. (Minimum duration: 5-6 months, remuneration level: €1500 / month.)
Show more
Show less","{'ProgLanguage': ['Python', 'R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['Pandas', 'R'], 'BigData': [], 'MachingLearning': [], 'DataSerialization': ['Json'], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git'], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Machine Learning', 'CI/CD'], 'FrSoftSkills': [], 'EnSoftSkils': ['Organization']}","{'JobDetail': ['Remote', 'Senior'], 'TypeContract': [], 'Salary': ['50K'], 'Level': [], 'Experience': ['a', 'n', 's']}"
LinkedIn,Data Scientist F/H,OUTSCALE,"St.-Cloud, Île-de-France, France",https://fr.linkedin.com/jobs/view/data-scientist-f-h-at-outscale-3891855564?position=10&pageNum=2&refId=EAisFcfNV4WNL6Xe9UKYqQ%3D%3D&trackingId=vwPlZ7yIsbbe4%2FseNig%2F4g%3D%3D&trk=public_jobs_jserp-result_search-card,"OUTSCALE, marque de Dassault Systèmes, est un opérateur souverain et durable de l Expérience en tant que Service qui offre à ses clients des environnements technologiques de confiance.
Nous offrons des expériences uniques grâce au savoir-faire de nos équipes passionnées, qui se reflète notamment par la création de solutions de Business Expériences, le développement de notre propre orchestrateur Cloud, TINA OS, ou encore l obtention de la qualification SecNumCloud.
Notre mission ? Bâtir un monde numérique accessible et meilleur pour tous à travers la création du jumeau virtuel de l organisation.
Nous menons une politique RH engagée et inclusive favorisant le bien-être de nos collaborateur·rices : respect de l équilibre vie privée/vie professionnelle, développement personnel et des compétences professionnelles, onboarding complet
Nous rejoindre, c est partager une passion pour l innovation, des valeurs communes et imaginer ensemble des solutions de confiance pour construire un monde meilleur et durable !
Nous recrutons
un·e
Data Scientist
afin de renforcer notre équipe
Business Experience
.
Vos missions
Analyser des problématiques et proposer des solutions.
Modéliser, implémenter et évaluer des algorithmes.
Traiter des données non structurées.
Optimiser des modèles ML/DL pour la scalabilité, l'efficacité et les performances.
Industrialiser des algorithmes dans les services API.
Déployer des services sur le cloud.
Participer à la rédaction de spécifications et documentations techniques.
Participer à des événements et publications scientifiques.
Stack technique
Python
Frameworks ML/DL (Pytorch)
Architectures de réseaux neuronaux (LLMs)
Implémentation d’algorithmes ML/DL (apprentissage supervisé/non-supervisé)
Votre profil:
Diplômé·e d’un Master en Intelligence Artificielle, Machine Learning.
3 ans d’expérience minimum post-diplôme dans le domaine de l’IA, Data Science, Machine Learning, NLP, Computer Vision.
Vous maîtrisez l’analyse et la transformation des données.
Idéalement, vous avez de l’expérience dans le déploiement des modèles ML/DL sur le cloud.
Motivé·e, organisé·e, curieux·se, vous appréciez travailler en équipe.
La Diversité d’OUTSCALE trouve aussi son expression dans notre politique de recrutement qui privilégie l’égalité des chances, la diversité des individus au sein de nos équipes.
Show more
Show less","{'ProgLanguage': ['Python', 'Scala', 'R', 'Go'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': ['PyTorch'], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['ML', 'Machine Learning', 'Cloud'], 'FrSoftSkills': ['Organisation'], 'EnSoftSkils': []}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's', '3', '3', '3']}"
LinkedIn,Data Scientist (confirmé/sénior) - H/F - CDI,Talan,"Paris, Île-de-France, France",https://fr.linkedin.com/jobs/view/data-scientist-confirm%C3%A9-s%C3%A9nior-h-f-cdi-at-talan-3909648101?position=1&pageNum=5&refId=W%2BmbKJ%2BzlSnYV3NZlNoxRw%3D%3D&trackingId=5E17rP97%2FIQpNuN8X8ff9A%3D%3D&trk=public_jobs_jserp-result_search-card,"Talan est un groupe international de conseil en transformation et en innovation par la technologie, créé en 2002.
Nos 5000 consultantes et consultants partagent à travers le monde l’audace d’innover, le goût de l’excellence, et l’envie de relever les défis les plus complexes.
Nous accompagnons les entreprises dans des secteurs variés : énergie, industrie, transport, finance, luxe… à travers 3 grandes expertises :
Le Conseil en Management et Innovation (320 Consultants en France)
La valorisation des données, leurs structurations, et leurs usages (Data et Technologies)
L’intégration de solutions logicielles (Cloud et Applications Services)
Nos valeurs : engagement, respect, partage, esprit d’équipe et optimisme.
Talan est une entreprise responsable, reconnue par ses collaborateurs et attachée à la diversité. Des aménagements peuvent être proposés si vous êtes en situation de handicap.
Retrouvez nos engagements RSEiciet nos actions en faveur de la diversitéici
Job Description
Nous sommes à la recherche d’un Data Scientist capable de participer à des projets techniques Data Science et IA. Vous devrez faire preuve d’un état d’esprit à la fois innovant, méthodique, orienté solution (et non problème!), et communiquant.
Votre but ultime sera de garantir l’excellence de vos solutions Data Science/IA, pièces maitresses de la réalisation de projets disruptifs pour nos clients.
VOTRE ROLE SUR NOS PROJETS
:
En mission: analyse des besoins métiers, définition des principes et méthodes de collecte et de traitement des données, choix des modèles de Machine Learning ou de Deep Learning, mise en application des techniques de traitement et de visualisation de la data, restitution des analyses et résultats obtenus auprès des métiers et des sponsors
Partager techniquement les membres de l’équipe: solutions et code reviews, recommandations, certifications à réaliser, …
Participation à des meet-up, coding dogo,…
Communication: écriture d’articles, retours d’expérience…
VOTRE ROLE CHEZ TALAN :
Benchmark de solutions et conseil auprès de nos clients sur les solutions technologiques à adopter, en lien avec leurs besoins
Réalisation de POC (Proof Of Concept)
Participation à des projets internes et partage de connaissances au sein de nos équipes.
Partage de connaissances et formations interne
Qualifications
VOTRE PROFIL:
Issu d’une formation Grande École d’Ingénieur/Doctorant, spécialisée en Data Science ou Intelligence Artificielle
Vous disposez d’au moins 3 années d’expérience dans le domaine
Maitrise des techniques d’analyses statistiques, de modélisations prédictives, de Machine Learning, de Deep Learning,...
Maitrise des techniques de data management et de DataViz
Maitrise de Python, R, RShiny, SQL…
Maitrise de l’utilisation des outils DevOps: Git, Docker, Jenkins/Nexus,…
Bonnes connaissances Big Data: pySpark, Spark, NoSQL…
Connaissance d’outils tels que Dataiku, AWS SageMaker, Azure ML,…
Autonomie, organisation, sens du partage
Excellente communication
Orientation métier
Additional Information
AVANTAGES
:
Plan de formation pour accompagner votre carrière (formations éditeurs, certifications) grâce à nos partenariats nous accordant une position de partenaire privilégié, et management de proximité par des experts
Locaux modernes en centre-ville
Top 5 du Palmarès Great Place to Work
Télétravail jusqu’à 5 jours selon les missions, prime d’équipement de 100€
Mobilité en France et à l’étranger
Top 1% des entreprises évaluées par Ecovadis dans le domaine social, environnemental et éthique
Tickets restaurant, prime vacances, 50% transport (abonnement transport public), mutuelle
Permanence handicap (consultant dédié aux collaborateurs en situation de handicap et aux proches aidants)
Actionnariat salarié
Prime de cooptations
RTT
PROCESS RECRUTEMENT
:
L’équipe recrutement s’engage à vous proposer un processus de recrutement rapide et fluide
1 entretien RHpar Teams (45min)
1 test technique
1 entretien opérationnel avec le responsable de domaine, au siège (1heure)
1 entretien avec le directeur de pôle, au siège(1heure)
Show more
Show less","{'ProgLanguage': ['Python', 'R', 'Go'], 'DataBase': ['SQL', 'NoSQL'], 'DataAnalytics': ['R'], 'BigData': ['Spark'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': ['Statistiques'], 'CloudComputing': ['AWS', 'Azure'], 'DevTools': ['Git', 'Docker', 'Jenkins'], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': ['Docker'], 'Collaboration': ['Teams'], 'Other': ['DevOps', 'Big Data', 'ML', 'Machine Learning', 'Statistiques', 'Cloud'], 'FrSoftSkills': ['Communication', 'Organisation'], 'EnSoftSkils': ['Communication']}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's']}"
LinkedIn,Data Scientist (H/F),Assurances Crédit Mutuel,"Strasbourg, Grand Est, France",https://fr.linkedin.com/jobs/view/data-scientist-h-f-at-assurances-cr%C3%A9dit-mutuel-3881495295?position=2&pageNum=5&refId=W%2BmbKJ%2BzlSnYV3NZlNoxRw%3D%3D&trackingId=J7Bg515clDdz2SFaUDGZYQ%3D%3D&trk=public_jobs_jserp-result_search-card,"Qui sommes nous
Depuis 1971, nous imaginons, concevons et orientons les offres et services qui contribuent au développement de l’activité assurance de Crédit Mutuel Alliance Fédérale, inventeur du concept de bancassurance.
Les Assurances du Crédit Mutuel sont présentes sur les marchés des assurances de biens, des assurances de personnes comme de l’assurance-vie. Nous proposons des solutions à tous ceux qui désirent se protéger et anticiper demain, qu’ils soient particuliers, professionnels ou entreprises.
Ce sont nos valeurs mutualistes et notre philosophie innovante qui guident nos actions. Loin de nous contenter de couvrir nos assurés aujourd’hui, nous cherchons à prévenir les risques futurs et à construire une assurance de demain plus juste.
Les Assurances du Crédit Mutuel, ce sont ainsi environ 3500 talents au service de près de 13 millions d’assurés, générant un chiffre d’affaires de 13,9 milliards d’euros. Nos offres et services sont principalement distribués par les réseaux bancaires Crédit Mutuel, CIC et Cofidis. Nous sommes parmi les acteurs majeurs de l’assurance en France.
Rejoindre les Assurances du Crédit Mutuel, c’est rejoindre un groupe qui porte haut et fort ses valeurs et où l’humain est toujours au centre. C’est rejoindre une entreprise où les innovations sont sources de simplicité et de solidarité et où chacun est engagé pour une société plus juste et plus durable. Intégrer les ACM c’est également intégrer le groupe Crédit Mutuel Alliance Fédérale et ses multiples opportunités de carrières.
Pourquoi nous recrutons
Dans un contexte de recherche constante d'une croissance responsable et durable, Les assurances du Crédit Mutuel continuent d'innover, de se développer et de renforcer leurs équipes dans de nombreux domaines.
Vos missions
Au sein de la Direction du Développement, de la transformation et de la Communication, vous intégrez l'équipe « Data et connaissance client » pour mener des projets de data science visant à accompagner la transformation de l'entreprise et favoriser le développement via l’analyse des profils clients.
En intégrant cette équipe, vous prendrez en main des projets de data science, avec le cadrage des problématiques, le recueil et l’analyse des données nécessaires. Vous testerez et comparerez différents modèles et études de performances.
Vous jouerez un rôle majeur dans la connaissance et l’anticipation des besoins de nos clients et travaillerez ainsi en relation avec les autres services de la direction (marketing, parcours client, projets digitaux, …), avec les différents services métiers des ACM et la direction commerciale du Groupe.
Vous serez aussi amené(e) à mener des études en collaboration avec d’autres Data Scientists du Groupe.
Activités / Tâches spécifiques du poste
Vos missions seront entre autres les suivantes :
Détenir, comprendre et exploiter la connaissance client
Proposer et développer des outils statistiques prédictifs et prescriptifs tels que des scores d’appétence ou d’attrition en mettant en œuvre des techniques de type scoring et segmentation via l’utilisation de méthodes classiques (régression logistique …) ou plus innovantes de type machine learning (random forest …).
Analyser, interpréter et synthétiser les données pour dégager des tendances et constats qui alimenteront la compréhension et la réflexion au sein de la direction dans le cadre d’études spécifiques (profils clients …).
Identifier les données existantes et de nouvelles sources de données pertinentes à collecter pour enrichir la connaissance client et modéliser leur comportement (données internes ou externes, structurées ou non structurées).
Etablir les suivis de l’activité commerciale et analyser les performances des actions commerciales et marketing pour améliorer leur efficacité.
Participer à différentes missions de type veille et partage de connaissance
Assurer une veille active sur les sujets de type Big Data et modélisation de données.
Aider au partage de bonnes pratiques au sein du groupe en tant qu’expert des données et des méthodes de modélisation.
Contribuer à la diffusion des travaux de l’équipe au sein de l’entreprise
Pouvoir représenter l'activité en intervenant dans des groupes de travail transverses.
Restituer et communiquer régulièrement les résultats des analyses et les préconisations associées de manière rigoureuse, pédagogique, accessible et exploitable
Ce que vous allez vivre chez nous
Concrètement, aux Assurances du Crédit Mutuel, nos collaborateurs bénéficient:
D'une rémunération fixe versée sur 13 mois
De l'intéressement, participation et de l'abondement pouvant atteindre plus de deux mois de salaire en fonction des résultats du groupe
D'un plan épargne entreprise (PEE), d’un plan épargne retraite collectif (PERECOL) et d’un compte épargne temps (CET),
D'un rythme de travail adapté fort d'un accord QVT groupe qui permet de télétravailler jusqu'à deux jours par semaine
De 22 jours de RTT par an selon le rythme de travail défini
D'une politique de protection sociale renforcée (régimes de remboursement de frais de santé et de prévoyance)
D'un régime de retraite supplémentaire (PERO) prise en charge à 100% par l’employeur
De conditions bancaires et assurances préférentielles
D'une politique parentale avantageuse
D'un parcours d'intégration pour tout nouvel arrivant
D'au moins une action de formation chaque année (95% des salariés)
D'un accompagnement pour favoriser votre mobilité géographique et fonctionnelle.
Ce que nous allons aimer chez vous
Connaissances et compétences
De formation supérieure Bac+5 minimum orientée statistiques, mathématiques, Data Science.
Un minimum de six ans d’expérience à un poste équivalent est demandé.
Vous possédez une expertise confirmée en Python (pandas, scikit-learn) ainsi que des connaissances poussées en Data Science (random forest, boosting, classification …).
Vous maîtrisez des langages / outils de traitement et d’analyse de données (SQL, SAS, Excel, …)
Vous possédez des compétences en présentation (PowerPoint) et êtes capable de mettre en valeur votre travail.
Une expérience en assurance constituerait un plus.
Une expérience en compétition de Data Science ou programmation (Kaggle, leetcode ...) constituerait un plus.
Savoir-être - savoir-faire
Vous appréciez le travail en équipe et faîtes preuve d'une bonne aisance relationnelle.
Curieux, vous possédez un bon esprit d'initiative et vous tenez au courant des dernières nouveautés en terme de Data Science.
Vous possédez un esprit analytique et créatif et êtes en mesure d’imaginer et de proposer des solutions innovantes.
Rigoureux et autonome, vous disposez d'excellentes capacités d'analyse et de synthèse.
Show more
Show less","{'ProgLanguage': ['Python', 'R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['Pandas', 'R'], 'BigData': [], 'MachingLearning': ['Scikit-Learn'], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': ['Statistiques'], 'CloudComputing': [], 'DevTools': ['Git'], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Big Data', 'Machine Learning', 'Statistiques'], 'FrSoftSkills': ['Communication', 'Collaboration', ""Esprit d'initiative""], 'EnSoftSkils': ['Communication', 'Collaboration', 'Initiative']}","{'JobDetail': ['Confirmé'], 'TypeContract': [], 'Salary': ['22'], 'Level': ['Bac+5'], 'Experience': ['a', 'n', 's']}"
LinkedIn,Data Scientist H/F,METEOJOB by CleverConnect,"Rennes, Brittany, France",https://fr.linkedin.com/jobs/view/data-scientist-h-f-at-meteojob-by-cleverconnect-3907968677?position=3&pageNum=5&refId=W%2BmbKJ%2BzlSnYV3NZlNoxRw%3D%3D&trackingId=92xzcUc%2BQLQedngjK8RfNg%3D%3D&trk=public_jobs_jserp-result_search-card,"Entreprise
Qui sommes-nous ?
Nous sommes passionnés par les nouvelles technologies, et vous ?
Rejoindre Amiltone, c'est intégrer des équipes dynamiques et soudées dans le cadre de projets novateurs et ambitieux. Nous relevons les challenges techniques de nos clients et les accompagnons dans leur transformation digitale.
Pourquoi choisir Amiltone ?
Amiltone, plus qu'une entreprise, un état d'esprit !
Notre objectif ? Votre épanouissement professionnel !
Nous Avons à Cœur De
Vous accompagner au mieux au travers d'un suivi personnalisé
Vous faire monter en compétences en vous proposant des formations tout au long de votre carrière
Comprendre vos besoins et respecter nos engagements
Vous proposer des missions de qualité avec des technologies innovantes
Cultiver votre potentiel grâce à notre programme de développement personnel Addvise
Votre bien-être passe aussi par des activités extraprofessionnelles, c'est pourquoi nous vous proposons des séances sportives animées par nos coachs, soirées pour se retrouver et animations (à l'agence ou en visio), Gaming nights...
Description Du Poste
Vos missions ?
Intégré à notre équipe de 10 personnes, vous assurez les missions suivantes :
Réceptionner et analyser la donnée brute
Traiter la donnée en streaming ou en statique
Adapter ou créer des modèles de machine learning
Evaluer la précision/robustesse d'un modèle
Outils de monitoring et de visualisation
Développement des modèles
Maintenir et documenter les codes et les process
La stack Technique :
Outils : MongoDB, PostgreSQL
NLP (IA générative)
Qlik Sense
Docker, Jenkins
Gitlab/Github
Description Du Profil
Alors ? Prêt à devenir Amiltonien ?
N'hésitez Pas à Postuler Si Vous Vous Reconnaissez
Diplômé bac+5 (école d'ingénieur ou master), vous avez au moins 2 ans d'expérience en tant que Data Scientist.
Vous aimez découvrir de nouveaux contextes fonctionnels et comprendre les objectifs des applications que vous développez.
A l'aise dans une organisation agile, vous faites preuve de rigueur et appliquez les standards de qualité Amiltone durant toute la durée des développements.
Outre vos compétences techniques, nous nous intéressons également à votre potentiel et votre motivation.
Nos postes sont ouverts aux personnes en situation de handicap.
Show more
Show less","{'ProgLanguage': ['R', 'Go'], 'DataBase': ['SQL', ' MongoDB'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git', 'Docker', 'Jenkins'], 'Os': [], 'DBMS': ['PostgreSQL'], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': ['Docker'], 'Collaboration': [], 'Other': ['Machine Learning'], 'FrSoftSkills': ['Organisation'], 'EnSoftSkils': []}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': ['Bac+5'], 'Experience': ['a', 'n', 's', '2', '2', '2']}"
LinkedIn,"Machine Learning Engineer, Fast Optimized Inference - EMEA Remote",Hugging Face,France,https://fr.linkedin.com/jobs/view/machine-learning-engineer-fast-optimized-inference-emea-remote-at-hugging-face-3848456024?position=4&pageNum=5&refId=W%2BmbKJ%2BzlSnYV3NZlNoxRw%3D%3D&trackingId=%2BGu1iJX1H6RIkBl8Ycwdvw%3D%3D&trk=public_jobs_jserp-result_search-card,"Here at Hugging Face, we're on a journey to advance good Machine Learning and make it more accessible. Along the way, we contribute to the development of technology for the better.
We have built the fastest-growing, open-source, library of pre-trained models in the world. With more than 1 Million+ models and 320K+ stars on GitHub, over 15.000 companies are using HF technology in production, including leading AI organizations such as Google, Elastic, Salesforce, Algolia, Grammarly and NASA.
About the role:
As a Machine learning Engineer, you work mainly on creating great libraries highly focused on real world ML use cases. We're building on top of our open-source to create more specialized code with a focus on industrial level of usage.
We are searching for someone who brings fresh ideas, demonstrates a unique and informed viewpoint, and enjoys collaborating with a progressive, nimble and decentralized approach to develop real-world solutions and positive user experiences at every interaction.
Objectives of this role:
Develop specialized software for specific machine learning (ML) use cases that have broad applications, similar to [text-generation-inference](https://github.com/huggingface/text-generation-inference).
Utilize existing library frameworks to create scalable software solutions for industrial purposes.
Enhance the reliability, quality, and time-to-market of our software suite. Measure and optimize system performance to stay ahead of customer needs and drive innovation.
Manage the production environment by monitoring availability and ensuring overall system health. We run our own tools
About you:
If you are a passionate Machine Learning Engineer with a keen interest in AI and proficient with Python, Rust and specialized Cuda kernels Frameworks (transformers of course + Keras or PyTorch), we would love to hear from you. Join our team and contribute to the advancement of AI technologies while working alongside talented professionals in a collaborative and stimulating environment.
More about Hugging Face
We are actively working to build a culture that values diversity, equity, and inclusivity
.
We are intentionally building a workplace where people feel respected and supported—regardless of who you are or where you come from. We believe this is foundational to building a great company and community. Hugging Face is an equal opportunity employer and we do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.
We value development.
You will work with some of the smartest people in our industry. We are an organization that has a bias for impact and is always challenging ourselves to continuously grow. We provide all employees with reimbursement for relevant conferences, training, and education.
We care about your well-being
.
We offer flexible working hours and remote options. We offer health, dental, and vision benefits for employees and their dependents. We also offer flexible parental leave and paid time off.
We support our employees wherever they are
.
While we have office spaces in NYC and Paris, we're very distributed and all remote employees have the opportunity to visit our offices. If needed, we'll also outfit your workstation to ensure you succeed.
We want our teammates to be shareholders
.
All employees have company equity as part of their compensation package. If we succeed in becoming a category-defining platform in machine learning and artificial intelligence, everyone enjoys the upside.
We support the community
.
We believe major scientific advancements are the result of collaboration across the field. Join a community supporting the ML/AI community.
Show more
Show less","{'ProgLanguage': ['Python', 'Scala', 'R', 'Go'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': ['Keras', 'PyTorch'], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git'], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['ML', 'Machine Learning'], 'FrSoftSkills': ['Collaboration'], 'EnSoftSkils': ['Collaboration', 'Organization']}","{'JobDetail': ['Remote'], 'TypeContract': [], 'Salary': ['Package'], 'Level': [], 'Experience': ['a', 'n', 's']}"
LinkedIn,Data Scientist H/F,ADHERENCE CONSULTING,"Capinghem, Hauts-de-France, France",https://fr.linkedin.com/jobs/view/data-scientist-h-f-at-adherence-consulting-3913994542?position=5&pageNum=5&refId=W%2BmbKJ%2BzlSnYV3NZlNoxRw%3D%3D&trackingId=nODE9OBg72XqGPojQqUxag%3D%3D&trk=public_jobs_jserp-result_search-card,"Adherence Consulting : Votre partenaire IT de choix !
Implantés à Paris, Lille et Marseille, nous sommes au coeur de l'innovation technologique et organisationnelle.
Notre mission ? Booster votre performance et vous accompagner dans chaque étape de votre transformation digitale.
Si vous êtes prêt(e) pour une carrière qui dépasse vos attentes, c'est le moment !
https://www.adherence-consulting.fr/
Les missions du poste
Contexte
Adhérence Consulting est une ESN implanté à Paris, Lille et Marseille. Nous sommes au coeur de l'innovation technologique et organisationnelle.
Notre mission ? Booster les performances et accompagner nos clients à chaque étape de leur transformation digitale. Nous cherchons actuellement un Data Scientist (F/H) pour le projet de notre client.
Vous participerez à la construction de nombreux projets tous aussi ambitieux les uns que les autres.
Quelles sont vos missions au quotidien ?
Applique des techniques (statistiques, text mining, comportementale, géolocalisation,) d'extraction et d'analyse d'informations, obtenues à partir de gisements de données (Big Data)
Obtient des données adéquates, trouve les sources de données pertinentes, fait des recommandations sur les bases de données à consolider, modifier, rapatrier, externaliser, internaliser, conçoit des datamarts, voire des entrepôts de données (data warehouses).
Évalue la qualité et la richesse des données, les analyse et en restitue les résultats pour ensuite les intégrer dans le système d'information cible du Métier.
Analyse les données pour traduire une problématique Métier en problème mathématiques/statistiques et réciproquement.
Compare et évalue différents modèles ou méthodes de calcul et anticipe les avantages et inconvénients dans un environnement Métier.
Intervenant auprès des Métiers, il exploite, analyse et évalue la richesse, de données structurées ou non, appartenant à l'entreprise ou non, pour établir des scénarios permettant de comprendre et d'anticiper de futurs levier Métiers ou opérationnels pour l'entreprise
Show more
Show less","{'ProgLanguage': ['R'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': ['Statistiques'], 'CloudComputing': [], 'DevTools': ['Git'], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Big Data', 'Statistiques'], 'FrSoftSkills': ['Organisation'], 'EnSoftSkils': []}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's']}"
LinkedIn,"Ingénieur Data scientist –Intelligence artificielle-  IDF, France (H/F)",Astek,"Île-de-France, France",https://fr.linkedin.com/jobs/view/ing%C3%A9nieur-data-scientist-%E2%80%93intelligence-artificielle-idf-france-h-f-at-astek-3886897805?position=6&pageNum=5&refId=W%2BmbKJ%2BzlSnYV3NZlNoxRw%3D%3D&trackingId=udgrvdt5xDGV5tEe9Y5h2Q%3D%3D&trk=public_jobs_jserp-result_search-card,"Ce que nous allons accomplir ensemble :
Pour l’un de nos projets dans le domaine aéronautique, vous interviendrez en tant
qu’ingénieur Data scientist / Intelligence artificielle
sur la mise en place de systèmes experts destinés aux avions civils et militaires.
Votre future équipe :
Team IT de 12 personnes
Data scientist, ingénieurs systèmes, intégrateurs, architectes
Vous travaillerez avec de véritables passionnés !
Votre mission (...si vous l’acceptez !) :
Vous participerez au développement des fonctions d’analyses multisystèmes. Pour cela vous assurerez l’établissement d’une spécification formelles sur les modèles d’analyses.
Vous assurerez l’analyse des données et la proposition de méthodes pour le traitement des signaux.
Vous développerez les outils capables de traiter de manière automatique les données systèmes.
Vous assurerez la réalisation des scénarios, ainsi que les tests et simulations.
Vous réaliserez également une activité de support.
Votre stack de jeu :
Data scientist, python, principe de gestion de configuration, et traçabilité, systèmes aéronautiques, intelligence artificielle
Les petits plus du projet :
Vous évoluerez au sein d’équipes agiles impliquées et réactives.
Vous interviendrez de A à Z sur des projets riches fonctionnellement et ambitieux techniquement :
forte volumétrie, haut niveau de performance, exigence maximale en termes d’intelligence artificielle et encore bien d'autres sujets captivants.
Vous ?
De formation Ingénieur, vous justifiez d’une expérience significative en Data scientist et ou Intelligence artificielle.
Une connaissance des méthodes d’analyse de données serait un plus.
Idéalement vous avez une connaissance des systèmes aéronautiques.
Des postes également ouverts aux débutants si stages significatifs.
Nous ?
Créé en France en 1988, Astek est un acteur mondial de l’ingénierie et du conseil en technologies, présent sur les 5 continents. Fort de son expertise dans de nombreux secteurs industriels et tertiaires, Astek accompagne ses clients internationaux dans le déploiement intelligent de leurs produits et de leurs services, et dans la mise en œuvre de leur transformation digitale.
Depuis sa création, le Groupe a fondé son développement sur une forte culture d’entrepreneuriat et d’innovation, et sur l’accompagnement et la montée en compétence de ses 5 200 collaborateurs qui s’engagent chaque jour à promouvoir la complémentarité entre les technologies numériques et l’ingénierie des systèmes complexes.
Rejoignez un Groupe en fort développement en France et à travers le monde grâce à une levée de fonds de 200M€ réalisée en 2021. Ensemble « Let’s move forward! »
✨ Tous les détails sur le Groupe sur le site
https://astekgroup.fr.
Et vous pouvez aussi nous suivre sur
notre blog : https://blog.groupeastek.com
.
Rencontrons-nous !
Vous vous êtes reconnu sur l’annonce et Astek vous plaît !
Pour en savoir plus sur vous, Franck , notre Talent Acquisition vous contacte. Puis, vous aurez 3 entretiens max, avec Léonard (votre futur n+1), Léonard notre Directeur !
Nos plus
Astek est green et fait bénéficier ses salariés d’une indemnité kilométrique vélo
Un programme CARE sur-mesure déployé par nos équipes RH pour nos collaborateurs : https://astekgroup.fr/engagements
Notre charte de la Diversité
Bienvenue dans la team ! Allez-y, maintenant c’est à vous de jouer !
Show more
Show less","{'ProgLanguage': ['Python', 'R'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git'], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': [], 'FrSoftSkills': [], 'EnSoftSkils': []}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's']}"
LinkedIn,Data Scientist F/H,Saint-Gobain,"Courbevoie, Île-de-France, France",https://fr.linkedin.com/jobs/view/data-scientist-f-h-at-saint-gobain-3915274420?position=7&pageNum=5&refId=W%2BmbKJ%2BzlSnYV3NZlNoxRw%3D%3D&trackingId=rqMeKkKKTAPrl3%2Fn%2BdCEgA%3D%3D&trk=public_jobs_jserp-result_search-card,"Why do we need you ?
Vous rejoindrez l’équipe « AI & Data Analytics », intégrée au département «Data & Analytics» dans l’organisation « Global Digital & IT». «Data & Analytics» regroupe les activités suivantes :
Data Engineering, Data Capture & Delivery, BI & Visualization, Platform & Architecture, Data Governance and Data Engagement.
Au Sein De L’équipe Data Science, Sous La Responsabilité Du Head Of AI & Data Analytics, Vous Aurez Le Rôle De Data Scientist (H/F). En Tant Que Tel, Vous Aurez Les Responsabilités Suivantes
Construire des modèles descriptifs et prédictifs sur des sujets en constante évolution ;
Mener des projets exploratoires faisant appel à des techniques avancées de Data Science (NLP, deep learning, Generative AI, apprentissage par renforcement ou par transfert), de façon autonome ou avec des partenaires externes ;
Assurer une veille technologique permanente sur ces sujets ;
Participer à l’industrialisation des algorithmes en lien avec les équipes engineering basée sur MLOps;
Accompagner les équipes opérationnelles dans le déploiement des algorithmes, notamment sur le volet analytics ;
Mener des ateliers d’idéation avec les équipes métiers (industrie, marketing, ventes, logistique, e-commerce, finance, RH) pour identifier les opportunités d’exploitation de la donnée et diffuser la culture data au sein de l’entreprise.
Si vous recherchez des défis passionnants, pouvant impacter des centaines de milliers de clients, et aimez travailler avec des outils à la pointe de la technologie, venez et rejoignez-nous !
Vous participerez donc à la montée en puissance de l’équipe créée récemment, tout en intervenant sur un ou plusieurs cas d’utilisation.
Is this job for you ?
En complément des missions évoquées, une réelle appétence pour la gestion et la facilitation de projet, avec une certaine aisance en termes de communication, seraient fortement appréciées.
Notre équipe ayant vocation à travailler pour des clients internes pouvant être basés en France comme à l’étranger, la maitrise de l’anglais (écrite et orale) est obligatoire.
Profil recherché
Ingénieur diplômé d’une école généraliste (Centrale, X, Mines, ENS etc.) ayant au minimum 3 années d'expérience après le diplôme.
Grande connaissance du Machine Learning, des statistiques et des probabilités.
SQL et Python, packages de ML: scikit, xgboost, keras
Expérience de travail sur un cloud provider et savoir construire des data pipelines serait un plus
Gestion de code : Git, Gitlab, CI/CD
Maitriser la modélisation à la fois prédictive et descriptive
Savoir implémenter des dashboards et autres outils de data viz
Posséder de bonnes qualités de communication : vous pouvez expliquer vos modèles clairement à la fois à des data analysts mais aussi à des Directeurs Généraux ou des responsables opérationnels.
Etre organisé, structuré et motivé par l’innovation
Aimer le travail en équipe et savoir apprendre de chacun.
Un état d’esprit orienté business et apport de valeur pour les équipes métiers
A Little More About Us
Saint-Gobain est une entreprise française spécialisée dans la production, la transformation et distribution de matériaux.
Fondée en 1665 par Jean-Baptiste Colbert sous le nom de Manufacture royale des glaces, l'entreprise est présente dans soixante-sept pays et emploie en 2018 près de 180 000 personnes
To make sure nothing is forgotten
Détails pratiques du rôle
Début : Dès que vous êtes prêts
Localisation : La Tour Saint-Gobain, La Défense
Contrat: CDI
Saint-Gobain encourage la diversité des équipes et favorise notamment l’inclusion des personnes en situation de handicap.
Show more
Show less","{'ProgLanguage': ['Python', 'R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': ['Keras', 'XGBoost'], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': ['Statistiques'], 'CloudComputing': [], 'DevTools': ['Git'], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['ML', 'Machine Learning', 'Statistiques', 'Cloud', 'CI/CD'], 'FrSoftSkills': ['Communication', 'Organisation'], 'EnSoftSkils': ['Communication']}","{'JobDetail': [], 'TypeContract': ['CDI'], 'Salary': ['1665'], 'Level': [], 'Experience': ['a', 'n', 's']}"
LinkedIn,Machine Learning Developer,MindPal,"Lyon, Auvergne-Rhône-Alpes, France",https://fr.linkedin.com/jobs/view/machine-learning-developer-at-mindpal-3910999113?position=8&pageNum=5&refId=W%2BmbKJ%2BzlSnYV3NZlNoxRw%3D%3D&trackingId=BaQ0Eql2CBVU4gHlkHMYpg%3D%3D&trk=public_jobs_jserp-result_search-card,"We are looking for
Machine Learning Developer
Job Responsibilities
Working on machine learning projects
Analyzing and processing data to create machine learning models
Implementing and optimizing machine learning algorithms
Testing and evaluating models
Collaborating with the programming team and other departments within the company to develop innovative solutions
Requirements
Minimum 2 years of experience in the field of machine learning
Knowledge of machine learning algorithms and techniques
Ability to analyze and process data
Familiarity with machine learning tools and technologies
Proficient in English communication
Education in computer science
We Offer
B2B contract type
Full-time employment
Remote and flexible working hours
Show more
Show less","{'ProgLanguage': ['R', 'Go'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Machine Learning'], 'FrSoftSkills': ['Communication'], 'EnSoftSkils': ['Communication']}","{'JobDetail': ['Remote', 'Full'], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's']}"
LinkedIn,DATASCIENTIST,GROUPE ALLIANCE,"Île-de-France, France",https://fr.linkedin.com/jobs/view/datascientist-at-groupe-alliance-3916080098?position=9&pageNum=5&refId=W%2BmbKJ%2BzlSnYV3NZlNoxRw%3D%3D&trackingId=4oN38rxmbt06vitjIoqESA%3D%3D&trk=public_jobs_jserp-result_search-card,"SI LA GESTION DES DONNEES EST TON DADA, TU PEUX GAGNER LA COURSE EN LISANT CETTE ANNONCE …
Ce que tu recherches :
au sein d’une équipe dynamique
à des projets innovants d’envergure
des défis
un nouveau souffle à ta carrière
Alors nous avons la mission idéale pour toi.
Au sein d’acteurs majeurs du secteur Bancaire, tu participeras des projets d’envergure sur des évolutions majeures à mettre en œuvre dans le SI du client :
des besoins, tu feras
techniques, tu rédigeras
et/ou socle technique, tu définiras
pratiques, tu instaureras
nouvelles fonctionnalités, tu développeras
bug, tu laisseras
équipe, tu accompagneras
instances de pilotage, tu participeras
Qui tu es :
de la formation qui va bien
ou dôté(e) d’une expérience de 3 ans minimum
de la Stack technique machine learning et python
avec les Frameworks et Outils : Ttensorflow, pytorch,scikit-learn, numpy, pandas
Au-delà des compétences techniques, tu es :
: tu n’aimes pas rester les deux pieds dans le même sabot
: un guide du Routard te suffira
de synthèse : tu sais aller à l’essentiel
d’adaptation : tu es un vrai caméléon
de la communication : les mots n’ont pas de secret pour toi
de proposition : tu es l’Aladdin de l’informatique
d’équipe : un pour tous et tous pour un !
Show more
Show less","{'ProgLanguage': ['Python', 'R'], 'DataBase': [], 'DataAnalytics': ['Pandas', 'NumPy', 'R'], 'BigData': [], 'MachingLearning': ['Scikit-Learn', 'TensorFlow', 'PyTorch'], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Machine Learning'], 'FrSoftSkills': ['Communication'], 'EnSoftSkils': ['Communication']}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's', '3', '3', '3']}"
LinkedIn,Data Scientist,CRIT France,Greater Saint-Etienne Metropolitan Area,https://fr.linkedin.com/jobs/view/data-scientist-at-crit-france-3908277901?position=10&pageNum=5&refId=W%2BmbKJ%2BzlSnYV3NZlNoxRw%3D%3D&trackingId=u0Bv4piXqeM4zmhZT8ljtw%3D%3D&trk=public_jobs_jserp-result_search-card,"Vous souhaitez rejoindre une entreprise, leader dans les Énergies Renouvelables et travaillant en mode projet ? Le domaine de la Data et de l'ingénierie informatique n'a plus aucun secret pour vous ? 🚀
Notre
Cabinet CRIT Experts & Cadres
recherche pour l’un de nos clients situé à proximité de Saint-Etienne,
un
Data Scientist H/F
, en CDI.
🌐 Qui est notre client ?
Leader et fleuron de l’énergie électrique, notre client est basé à proximité de Saint-Étienne (42), est une entreprise qui conçoit, produit et installe des systèmes automatisés, de conversion et de stockage d’énergie électrique
🌎 Les engagements de l’entreprise ?
#satisfaction client
#respect de la personne
#performance
#solidarité et le travail d’équipe
#intégrité
#développement des talents
Pourquoi postuler ?
Bien qu'étant une entreprise avec des projets à l'international, notre client su rester à taille humaine. Le fonctionnement en mode Projet offre la possibilité à leurs collaborateurs de s'impliquer et d'apporter leurs compétences à des projets variés. Leurs projets sont des défis techniques qui offrent la possibilité de travailler sur un cycle complet, de la conception à la mise en service.
📌 Quel sera votre rôle ?
Collecter, analyser et interpréter des données pour aider l'entreprise à prendre des décisions stratégiques basées sur des données probantes.
Rattaché hiérarchiquement directement au Président, vos missions seront :
Collecter, nettoyer et manipuler de grandes quantités de données provenant de diverses sources, y compris des bases de données internes et externes, des API et des données non structurées.
Développer et mettre en œuvre des modèles prédictifs et des algorithmes d'apprentissage automatique pour résoudre des problèmes commerciaux complexes.
Effectuer des analyses statistiques approfondies pour identifier des tendances, des modèles et des insights significatifs.
Travailler en étroite collaboration avec les équipes interfonctionnelles pour comprendre leurs besoins en matière de données et fournir des solutions analytiques.
Créer des tableaux de bord interactifs, des visualisations de données et des rapports pour communiquer efficacement les résultats de l'analyse aux parties prenantes.
Maintenir une veille technologique constante sur les avancées en matière de science des données et proposer des améliorations continues aux processus et méthodologies existants.
Vos responsabilités et périmètre d’action :
Sous directives et objectifs fixés par votre responsable hiérarchique, le Président :
Être conscient des risques et prendre des mesures appropriées pour protéger les données et les systèmes contre les menaces.
🎯
Profil recherché :
Domaine des sciences de données : informatique, en mathématiques, en statistiques, en économie, en sciences de l'informatique, en gestion, en ingénierie industrielle ou dans un domaine connexe.
Expérience antérieure dans un rôle similaire.
Maîtrise de l’anglais.
💡 Vos cartes secrètes idéales ?
👉 Connaissance des concepts en collecte, extraction & analyse de données.
👉 Compétences analytiques.
👉 Capacité à communiquer des informations complexes de manière claire et compréhensible.
👉 Capacité à travailler de manière collaborative.
👉 Maîtrise des langages de programmation courants tels que Python, R ou SQL.
👉 Solides compétences en analyse statistique et en modélisation prédictive.
👉 Expérience pratique avec les bibliothèques et les frameworks d'apprentissage automatique tels que TensorFlow, Scikit-Learn ou PyTorch.
Autres informations :
Contrat
: CDI
Statut
: cadre
Salaire
: en fonction du profil – à définir
📍
Lieu
: à proximité de Saint-Etienne
Avantages salariaux : Prime participation salariale, Tickets Restaurants, CSE…
Déplacements à prévoir :
France – EMEA Germany, Italy, Spain, UK
Fréquence : selon besoin de l’activité
Show more
Show less","{'ProgLanguage': ['Python', 'R', ' R ', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R', ' R '], 'BigData': [], 'MachingLearning': ['Scikit-Learn', 'TensorFlow', 'PyTorch'], 'DataSerialization': [], 'DataVisualization': ['Tableau'], 'Statistics': ['Statistiques'], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Statistiques'], 'FrSoftSkills': ['Collaboration'], 'EnSoftSkils': ['Collaboration']}","{'JobDetail': [], 'TypeContract': ['CDI'], 'Salary': ['Salaire'], 'Level': [], 'Experience': ['a', 'n', 's']}"
LinkedIn,Senior Machine Learning Engineer,Homa,"Paris, Île-de-France, France",https://fr.linkedin.com/jobs/view/senior-machine-learning-engineer-at-homa-3911467922?position=1&pageNum=7&refId=jSHCf8SJlBfpMeJ3wOWkYQ%3D%3D&trackingId=qpEVx0pIvAU2%2FyI%2Bdv7UgQ%3D%3D&trk=public_jobs_jserp-result_search-card,"Welcome to Homa, the gaming technology lab that is taking the industry by storm! Our team of over 200 people, hailing from more than 35 different countries, is dedicated to empowering mobile game creators worldwide to bring their creative ideas to the top charts.
Our Homa Lab platform offers a comprehensive suite of cutting-edge tools that allow developers to stay on top of the latest trends, test new features in real-time, and easily distribute and monetize their games. Our success speaks for itself - our apps have been downloaded over 1 billion times!
Since our inception, we have raised $165 million in total from prominent investors, including Headline, Northzone, Eurazeo, Singular, Quadrille Capital, Fabric Ventures, and Bpifrance. We have also received support from renowned business angels, such as the founders of King, Sorare and Spotify founders.
But what really makes Homa special is our team. We are a diverse group of artists, business developers, engineers, entrepreneurs, and former strategy consultants who all share the same passion for taking over the gaming industry. When you become part of Homa, you'll be joining a dedicated team that creates innovative and high-performing games that resonate with players worldwide.
If you're ready to take your career to the next level and make a real impact in the company, then Homa is the perfect place for you. Join us and let's create the future of gaming together!
Meet the team
👩‍👩‍👧‍👧
You will join the Data department organized into:
A Data Platform team with 5 Data Engineers responsible for ingesting large amounts of data from multiple different sources, creating and maintaining a core data model which aims at making data standardized, reliable and easily available
A Data Science and ML Platform team with 6 Data Scientists / ML Engineer working on ML-driven data products: Autobidder for User Acquisition, N-Testing for experimentation
An Advanced Analytics & Data Science team with 6 Data Analysts and Scientists exploiting our data for:
Game Analytics
User Acquisition and Marketing Analytics
Market Inteligence Analytics
Ops Analytics
Role and Missions — What you will do
🚀
We are looking for a Senior Machine Learning Engineer to join the team in order to scale and industrialize Machine Learning & AI at Homa. Under the responsibility of our Associate Director, your responsibilities will be the following:
Lead ML Projects: Spearhead development and implementation of ML models for Marketing Tech (User Acquisition, Monetization) and Game Tech (Bayesian A/B Testing, Segmentation)
ML Industrialization & Democratization: Enhance ML engineering processes, adopt ML Ops tools, and contribute to model interpretability and collaborative efforts
Implement Scalable ML Solutions: Build Serving APIs for handling millions of requests daily with low latency
Collaborative Innovation: Work closely with diverse teams, leveraging GenAI tools for productivity and product improvements
Stay Updated: Integrate latest ML technologies and advancements into our tech stack
Current Tech Stack: AWS, Redshift, Databricks, Python, DBT, Spark, Airflow, Kafka, Kubernetes, LightGBM, MLFlow, Metabase
Requirements
If you're creative, ambitious, and up for taking over the industry, we want you on our team! We are also looking for:
Extensive ML Experience: 5+ years in implementing and deploying ML models to production
Key Technology Proficiency: Expertise in Neural Networks (TensorFlow / PyTorch), Gradient Boosting libraries (LightGBM / XGBoost), and at least one top Cloud provider (GCP, Azure, AWS)
MLOps Skills: Experience with ML Ops tools like MLFlow
API Development Expertise: Proven ability in building high-performance Serving APIs
Collaborative Skills: Excellent communication and teamwork abilities
Innovative Mindset: Passion for staying ahead in ML trends and technologies
Language Skills: Fluent English is mandatory (interviews will be led in English)
Our Culture—Who we are
🪐
At Homa, we are building a community of brilliant talents. We believe that true innovation comes from diversity and collaboration, and that's why we prioritize brainpower and determination over formal education. So if you have the talent, energy and motivation, there is no obstacle to your success here.
As the creative experts behind the platform, we provide developers with the data they need to bring their ideas to life. Our team lives by three central values that guide everything we do:
✨
Ambition
: we're not afraid to tackle difficult challenges and set our goals extremely high. We're on a mission to revolutionize an industry dominated by well-established companies, and we won't stop until we succeed.
✨
Humility
: we leave our pride & ego aside. We are always ready to lend a helping hand, celebrate each other's successes, and learn from our failures. As Mr. Lamar said, ""Sit down. Be humble.""
✨
Curiosity
: we keep our minds open and never stop learning. We believe that questioning everything is the best way to stay ahead of the curve, and we encourage all our team members to stay curious and never stop exploring new ideas.
At Homa, you'll be challenged, supported, and inspired every day, and we can't wait to see what you bring to the table.
Benefits
While success is its own reward, here are some of the benefits that come with working at Homa:
We offer essential benefits in France and specific locations, including health insurance, meal vouchers, public transport subsidies, childcare benefits, and life insurance
If you're interested in working from our newly renovated Paris HQ with a rooftop garden and WeWork amenities, we have a desk waiting for you
You will be working in English with our international team of top-tier talents from 35+ countries
You will have bi-annual reviews with your manager to reflect on your performance, celebrate wins, and receive constructive feedback
You will be able to attend diverse team events and Workations (the famous company-wide Homa trip)
Show more
Show less","{'ProgLanguage': ['Python', 'Scala', 'R', 'Go'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': ['Spark', 'Databricks'], 'MachingLearning': ['TensorFlow', 'PyTorch', 'XGBoost', 'LightGBM'], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': ['AWS', 'Azure'], 'DevTools': [], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': ['Kubernetes', 'Airflow'], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': ['Kubernetes'], 'Collaboration': ['Teams'], 'Other': ['ML', 'Machine Learning', 'Cloud'], 'FrSoftSkills': ['Communication', 'Collaboration'], 'EnSoftSkils': ['Communication', 'Teamwork', 'Collaboration']}","{'JobDetail': ['Senior'], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's']}"
LinkedIn,"Data Scientist - France, Paris",Dataiku,"Paris, Île-de-France, France",https://fr.linkedin.com/jobs/view/data-scientist-france-paris-at-dataiku-3834882798?position=2&pageNum=7&refId=jSHCf8SJlBfpMeJ3wOWkYQ%3D%3D&trackingId=23drlgg9Xn%2FF0W%2FrC2Hwbg%3D%3D&trk=public_jobs_jserp-result_search-card,"At Dataiku, we're not just adapting to the AI revolution, we're leading it. Since our beginning in Paris in 2013, we've been pioneering the future of AI with a platform that makes data actionable and accessible. With over 1,000 teammates across 25 countries and backed by a renowned set of investors, we're the architects of Everyday AI, enabling data experts and domain experts to work together to build AI into their daily operations, from advanced analytics to Generative AI.
Headquartered in New York City, Dataiku was founded in Paris in 2013 and achieved unicorn status in 2019. Now, more than 1,300 employees work across the globe in our offices and remotely. Backed by a renowned set of investors and partners including CapitalG, Tiger Global, and ICONIQ Growth, we’ve set out to build the future of AI.
The role of a Data Scientist at Dataiku is unique. Our Data Scientists not only develop solutions to real-world problems but also participate in client-facing endeavors throughout the customer journey. This includes supporting their discovery of the platform, helping integrate Dataiku with other tools and technologies, providing user training, and co-developing data science projects from design to deployment.
Just as the non-technical skills are important, so too are the technical. Our Data Scientists work on the Dataiku platform daily. Aside from the visual tools, our team uses mostly Python, with occasional work in other languages (e.g., R, SQL, Pyspark, JavaScript, etc.). An ideal candidate is excited to teach data science and how to use the Dataiku platform to customers, and learn about new technologies.
How you'll make an impact
Help users discover and master the Dataiku platform, via user training, office hours, demos, and ongoing consultative support.
Analyze and investigate various kinds of data and machine learning applications across industries and use cases.
Provide strategic input to the customer and account teams that help make our customers successful.
Scope and co-develop production-level data science projects with our customers.
Mentor and help educate data scientists and other customer team members to aid in career development and growth.
What you'll need to be successful
Curiosity and a desire to learn new technical skills.
Empathy and an eagerness to share your knowledge with your colleagues, Dataiku’s customers, and the general public.
Ability to clearly explain complex topics to technical as well as non-technical audiences.
Over 3 years of experience with coding (Python, R, SQL).
Over 3 years of experience building ML models.
Understanding of underlying data systems and platform mechanics such as Cloud architectures, K8S, Spark, and SQL.
What will make you stand out
Experience with Consulting and/or Customer-facing Data Science roles.
Experience with Data Engineering or MLOps.
Experience developing WebApps in Javascript, RShiny, or Dash.
Experience building APIs.
Experience using enterprise data science tools.
Passion for teaching or public speaking.
Benefits
Exposure to a wide range of enterprise customers across industries. Examples of Dataiku’s hundreds of customers include GE, Unilever, Comcast, Ubisoft, OVH, Santander, and Capgemini.
A wide diversity of projects.
Opportunity to contribute to the core vision of our company and product: simplify and democratize the way people work with data and use Artificial Intelligence.
Exposure to the latest, open-source technologies that Dataiku integrates. See our release notes for our latest developments: https://doc.dataiku.com/dss/latest/release_notes/index.html
Opportunity to work with a smart, passionate, and driven team in hypergrowth mode.
Dataiku has a strong culture based on key values: Transparency, Ambition, Excellence, Humility, and Empathy.
What are you waiting for!
At Dataiku, you'll be part of a journey to shape the ever-evolving world of AI. We're not just building a product; we're crafting the future of AI. If you're ready to make a significant impact in a company that values innovation, collaboration, and your personal growth, we can't wait to welcome you to Dataiku! And if you’d like to learn even more about working here, you can visit our Dataiku LinkedIn page .
Our practices are rooted in the idea that everyone should be treated with dignity, decency and fairness. Dataiku also believes that a diverse identity is a source of strength and allows us to optimize across the many dimensions that are needed for our success. Therefore, we are proud to be an equal opportunity employer. All employment practices are based on business needs, without regard to race, ethnicity, gender identity or expression, sexual orientation, religion, age, neurodiversity, disability status, citizenship, veteran status or any other aspect which makes an individual unique or protected by laws and regulations in the locations where we operate. This applies to all policies and procedures related to recruitment and hiring, compensation, benefits, performance, promotion and termination and all other conditions and terms of employment. If you need assistance or an accommodation, please contact us at: reasonable-accommodations@dataiku.com
Show more
Show less","{'ProgLanguage': ['Python', 'Java', 'R', 'Go', 'JavaScript', 'HTML'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': ['Spark'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': ['AWS'], 'DevTools': [], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': ['Teams'], 'Other': ['ML', 'Machine Learning', 'Cloud'], 'FrSoftSkills': ['Collaboration'], 'EnSoftSkils': ['Empathy', 'Collaboration']}","{'JobDetail': ['Remote'], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's']}"
LinkedIn,Data Scientist (h/f),METEOJOB by CleverConnect,"Nantes, Pays de la Loire, France",https://fr.linkedin.com/jobs/view/data-scientist-h-f-at-meteojob-by-cleverconnect-3913467533?position=3&pageNum=7&refId=jSHCf8SJlBfpMeJ3wOWkYQ%3D%3D&trackingId=f7hRpLcHOxygXRvSayk5Uw%3D%3D&trk=public_jobs_jserp-result_search-card,"Entreprise
iziwork est une agence de recrutement d'intérim totalement digitalisée, s'appuyant sur l'innovation technologique pour améliorer radicalement l'accès à l'expérience du travail pour tous. Elle offre aux travailleurs un accès simple et instantané à un grand choix de jobs mais aussi un accompagnement personnalisé au fil des missions qui donne du sens au mérite individuel. En rupture avec les pratiques du marché, iziwork offre une approche « worker centric » pour attirer et valoriser les personnes fiables et compétentes en recherche d'emploi.
Description Du Poste
Iziwork est une agence de recrutement digital qui sélectionne les meilleures missions et offres d'emploi pour les centaines de milliers d'intérimaires et candidats qu'elle a déjà séduits. Postulez en quelques minutes, gérez votre contrat en un clin d'oeil depuis notre app et bénéficiez du suivi personnalisé de votre recruteur au quotidien.
À propos de la mission
Organiser et conduire les ateliers de construction des modèles de données pour chaque référentiel groupe
Accompagner les métiers à la définition des règles d'archivage, de gestion et de contrôle qualité
Assurer les contrôles préliminaires de cohérence des données
Accompagner l'administrateur des données au transcodage des règles de contrôle qualité dans Talend
Assurer les contrôles préliminaires de cohérence des données
Participer au processus de migration des données dans l'ERP cible en accompagnant les métiers à l'identification des écarts et à la mise en conformité des data dans la/les solutions cible
Identifier les incohérences avec l'architecture et participer à la synchronisation de l'intégrité des flux
Assurer la supervision et l'intégration des données de diverses natures et vérifier la qualité des données qui entrent dans le Data Lake
Structurer le cycle de vie de la donnée dans le respect des réglementations RGPD & ISO24143
Rémunération & Avantages
Rémunération : 40 000 € - 50 000 € par an
Profil recherché
Issu(e) d'une formation en Informatique de niveau BAC+2/+3, vous disposez d'une expérience similaire de 2 à 3 ans idéalement en milieu industriel ou SSI.
Vous possédez une première expérience de gestion de projet informatique, vous savez animer des ateliers.
Très organisé(e), rigoureux(se), réactif(ve), vous savez gérer les priorités.
Votre sens du service et votre aisance relationnelle vous permettent d'instaurer un climat de confiance avec vos différents interlocuteurs.
Vous maitrisez les langages informatiques suivants : Java, Python, SQL. Connaissances souhaitées d'un outil MDM (Talend, Tibco) et d'un ETL.
Vous bénéficiez d'une bonne maîtrise d'Excel.
Notre environnement international requiert la maîtrise de l'anglais à un niveau B2 minimum (intermédiaire - avancé).
Expérience : Entre 24 mois et 5 ans
Certificats requis
Aucun certificat requis
Show more
Show less","{'ProgLanguage': ['Python', 'Java', 'R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git'], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': [], 'FrSoftSkills': [], 'EnSoftSkils': []}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's', '3', '3', '3']}"
LinkedIn,AI ENGINEER,STATION F,"Paris, Île-de-France, France",https://fr.linkedin.com/jobs/view/ai-engineer-at-station-f-3918860437?position=4&pageNum=7&refId=jSHCf8SJlBfpMeJ3wOWkYQ%3D%3D&trackingId=LfYYyiZyzITuvZSu5HbMtQ%3D%3D&trk=public_jobs_jserp-result_search-card,"À propos
Depuis 30 ans, les contrats n'ont pas changé.
Leur contenu est simplement passé d'une feuille de papier à un écran d'ordinateur et les entreprises ont dû s'adapter, en utilisant des outils de tous les jours, faute d'équipements adaptés.
Parce qu'ils sont au cœur du business et des relations commerciales, Tomorro réinvente la négociation contractuelle avec une expérience collaborative et intuitive.
Tomorro permet aux entreprises de gérer de manière simple et automatisée le cycle de vie complet d'un contrat, de sa création à son suivi, en passant par sa négociation et sa signature.
Descriptif du poste
Ta mission
Tu intégreras l'équipe technique de Tomorro, composée de 10 développeurs, 2 product designer et 3 product managers.
Ton but sera alors de contribuer au développement et à l'amélioration continue de notre application SaaS de gestion de contrats grâce aux LLMs au sein d’une squad dédiée.
Tu auras pour objectif de développer de nouvelles fonctionnalités, optimiser les performances et participer à l’architecture de la solution pour pouvoir offrir une expérience utilisateur fluide et fiable autour des technologies de GenAI.
Tes responsabilités
Contribuer au futur de Tomorro tant au niveau technique que produit en implémentant de nouvelles fonctionnalités autour de l’IA générative
Superviser l'intégration des modèles d'IA dans nos systèmes existants, en s'assurant qu'ils sont évolutifs, fiables et performants
Maintenir un niveau maximal de sécurité et de confidentialité dans un contexte juridique
Collaborer avec les autres membres de l’équipe et cultiver le partage de connaissances.
Prendre part aux revues de code et veiller à un niveau d’exigence élevé sur la qualité du code
Assurer une veille permanente sur les sujets IA / ML et proposer des innovations
Participer activement aux discussions sur l’architecture et challenger les choix techniques de manière pragmatique
Jouer un rôle essentiel dans la construction de notre équipe technique dans le recrutement et dans la mise en place d'une structure solide
Stack technique
Front-end: React, Typescript, Apollo, Storybook
Back-end: Nodejs, Typescript, Nestjs, GraphQL
Infrastructure: AWS (ECS, S3, SQS, SNS, Lambdas …), IAC with CDK, Docker
Database: Mysql, OpenSearch, Redis
Monitoring & Observability: Datadog, Sentry
CI / CD: Github, CircleCI
Gestion de projet: Notion, Linear, Figma
Profil recherché
A propos de toi
Tu as 3+ années d’expérience et déjà contribué à un projet GenAI
Tu as une solide expérience technique dans un environnement Typescript et des connaissances sur différentes langages de programmation et technique de conception (SQL, AWS, Docker, Message broker…)
Tu maitrises les API des foundation models (exemple : OpenAI GPT, Titan, LLama, Mistral, Claude…) et l’orchestration sur GenAI (LangChain, Prompt management, MLops...)
Tu as des connaissances en OCR et en traitement de langage naturel (NLP)
Tu es rigoureux·se en matière de tests et de qualité du code
Tu as l’ambition de livrer des applications présentant une haute fiabilité et une disponibilité optimale
Tu es enthousiaste à l'idée de travailler en équipe et tu as autant envie d'apprendre que d'enseigner
Comment nous travaillons
Ambition: Nous recherchons des personnes extrêmement ambitieuses qui veulent se battre pour changer les choses. Nous vous encouragerons toujours à oser.
Trust & Ownership: Rejoindre Tomorro c’est vouloir avoir des responsabilités. C’est vouloir grandir et faire grandir l’entreprise vite
Réunions: Nous n'organisons pas de réunions avant 14 heures et essayons de n’en faire que lorsque c'est nécessaire et non par défaut.
Prendre du plaisir: Pour finir, on fait tout ça dans la bonne humeur :)
Tomorro c’est aussi
Une équipe internationale, soudée et ambitieuse partageant des valeurs communes.
Une rémunération attractive avec plan de BSPCE pour tous les employés.
Une politique de remote flexible, si tu souhaites travailler depuis Berlin une semaine, pas de problème.
MacBook, écran, casque et tous les autres accessoires dont tu as besoin pour travailler dans les meilleures conditions.
Des bureaux centraux et spacieux situés en plein Paris, avec restaurants et autres lieux sympas à proximité.
Un abonnement sportif Gymlib pour que tu sois au top de ta forme.
Chèques-repas Swile (10€ de valeur faciale), remboursement de la mobilité douce et mutuelle de premier ordre.
Des afterworks et diners tous les mois, mais aussi deux séminaires par an avec toute l’équipe (Marseille ☀️🇫🇷, Tignes 🎿🇫🇷, Tunisie 🏜️🇹🇳, Megève 🎿🇫🇷).
Process de recrutement
Un appel de 30 minutes pour se présenter, te parler de Tomorro et voir si nos attentes respectives sont compatibles.
1h30 d’entretien avec un développeur et un membre de l’équipe produit pour discuter en détail du poste, de tes expériences et de tes attentes.
Un entretien technique avec le Sébastien (CTO). On sait que ton temps est précieux et nous avons conçu un cas qui ne te prendra pas trop de temps.
30 minutes d’entretien avec Antoine (CEO) pour mieux comprendre ton ambition et tes motivations à rejoindre Tomorro.
Drink Team🍹: Parce que c'est aussi très agréable de discuter de tout et de rien comme de bons vieux amis, on t’invite à venir boire un verre avec l'équipe.
Informations complémentaires
Type de contrat : CDI
Lieu : Paris
Niveau d'études : Bac +5 / Master
Expérience : > 3 ans
Télétravail ponctuel autorisé
Show more
Show less","{'ProgLanguage': ['R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': ['AWS'], 'DevTools': ['Git', 'Docker'], 'Os': [], 'DBMS': ['MySQL'], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': ['Docker'], 'Collaboration': [], 'Other': ['ML', 'CI / CD'], 'FrSoftSkills': [], 'EnSoftSkils': []}","{'JobDetail': ['Remote'], 'TypeContract': ['CDI'], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's', '30', '30', '30']}"
LinkedIn,Data Scientist IA GEN,eXalt,"Paris, Île-de-France, France",https://fr.linkedin.com/jobs/view/data-scientist-ia-gen-at-exalt-3856618698?position=5&pageNum=7&refId=jSHCf8SJlBfpMeJ3wOWkYQ%3D%3D&trackingId=s4rKX6nYpAJwBil147WL0g%3D%3D&trk=public_jobs_jserp-result_search-card,"Descriptif du poste
Nous recherchons un
Data Scientist IA Gen H/F
pour rejoindre notre communauté sur le
pilier Data Science & IA.
Vos missions:
Identifier les besoins spécifiques des différentes équipes, à travers des ateliers d’idéation, et proposition de solutions algorithmiques innovantes et adaptées à chaque situation.
Analyser les données disponibles pour sélectionner les modèles d’IA les plus pertinents face aux besoins identifiés, en tenant compte des particularités de chaque cas d’usage.
Développer, tester et déployer les algorithmes des modèles d’apprentissage automatique et des algorithmes avancés pour résoudre des problèmes complexes grâce à des méthodes statistiques, mathématiques et de machine learning.
Collaborer avec les Data Engineer afin d’intégrer les solutions IA dans les produits et les applications existants.
Exploiter les dernières avancées en matière d’IA, notamment le Deep Learning, le Reinforcement Learning, le Traitement du Langage Naturel (NLP), la vision par ordinateur, etc., pour créer des solutions innovantes.
Conseiller les clients tout au long du cycle de vie des projets sur les solutions techniques les plus adaptées à leurs environnements.
Profil recherché
Compréhension des enjeux business autours de l’exploitation des données et le déploiement des solutions IA
Maîtrise du Machine Learning et du Deep Learning, y compris des principaux frameworks (TensorFlow, PyTorch, Scikit-learn, Pandas, NumPy,) et des méthodes statistiques.
Solide connaissance de Python (Java, Spark, Scala sont un plus).
Expérience dans l’utilisation d’outils tels que Gitlab et Docker.
Aisance avec l’ensemble du cycle de vie de développement et de déploiement de modèles d’IA (MLOps).
Expérience de travail en méthode Agile
Capacité à travailler de manière autonome et en équipe.
Excellentes compétences en communication et présentation.
Maîtrise de l’anglais (oral & écrit dans un contexte international professionnel).
Déroulement des entretiens
Un entretien RH avec Estelle, à la suite duquel vous saurez tout (ou presque) d’eXalt Value,
Un entretien technique avec un Manager IA assorti d’un test technique, lors duquel vous aurez l’occasion de démontrer vos talents mais aussi d’apprendre avant même de dire oui,
Un entretien final avec la Directrice Associée ou le Directeur Opérationnel, pour finir de vous convaincre de nous rejoindre 😊
Votre environnement eXalté:
Rejoindre
eXalt Value
, c’est également :
Un Lab IA au sein duquel vous pourrez expérimenter les divers outils et techniques, autour de use cases internes et externes.
Un environnement de travail Collaboratif favorisant les initiatives et projets transverses à la Practice Data & IA (Data Hub, etc ;)
Un collectif de consultants passionnés, s’intéressant aux tendances innovantes du secteur
Une Practice de proximité, privilégiant la montée en compétence de ses collaborateurs (formations, coachings, mentorats, etc.)
Un suivi individualisé et de proximité par un.e Data Sales Manager référent du compte client, un.e Chargé.e RH et un.e Practice Manager
Une équipe sympa et dynamique, qui privilégie des moments de partage (séminaires, eXaltemps, meet-ups, déjeuners d’équipe,etc.)
Qui sont-ils ?
eXalt
est un cabinet de conseil IT
Pure player Data
& IA basé à Paris (1er arrondissement).
Notre offre s’articule autour de 4 piliers réunis au sein d’une même communauté pour un accompagnement à 360° alliant une expertise technique et méthodologique à une approche conseil métier:
Data Gouvernance & Project
Data Engineering & Big Data
Data Performance & Analytics
Data Science & IA
Filiale du groupe eXalt créé en 2018,
regroupant plus de
950 collaborateurs en France
(Paris, Lyon, Bordeaux, Lille, Nantes, Marseille)
et à l’international
(Colombie, Etats-Unis, Espagne, Belgique),
eXalt Value
démontre une
expertise approfondie
dans le domaine de la Data & IA et conseille les entreprises dans le déploiement de leurs stratégies data-driven.
Bénéficiant de la renommée et des relations client du groupe eXalt
(1er dans la catégorie Conseil & Audit au classement des Champions de la Croissance 2024), eXalt Value
est en pleine croissance et regroupe aujourd’hui une communauté d’expertise de plus de 60 collaborateurs en région parisienne.
Nos consultants interviennent sur d
es projets d’envergure stimulants
dans divers secteurs d’activité, Banque & Assurance, Médias, Transports, Retail, Tourisme, etc.
Show more
Show less","{'ProgLanguage': ['Python', 'Java', 'Scala', 'R', 'Go'], 'DataBase': [], 'DataAnalytics': ['Pandas', 'NumPy', 'R'], 'BigData': ['Spark'], 'MachingLearning': ['Scikit-Learn', 'TensorFlow', 'PyTorch'], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': ['Statistiques'], 'CloudComputing': [], 'DevTools': ['Git', 'Docker'], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': ['Docker'], 'Collaboration': [], 'Other': ['Big Data', 'ML', 'Machine Learning', 'Statistiques'], 'FrSoftSkills': ['Communication'], 'EnSoftSkils': ['Communication', 'Initiative']}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's']}"
LinkedIn,Data Scientist (H/F),Harry Hope.,"Nancy, Grand Est, France",https://fr.linkedin.com/jobs/view/data-scientist-h-f-at-harry-hope-3917140355?position=6&pageNum=7&refId=jSHCf8SJlBfpMeJ3wOWkYQ%3D%3D&trackingId=on%2F8v2XMzjUiXrJDWCh9%2Fg%3D%3D&trk=public_jobs_jserp-result_search-card,"Jean, consultant spécialisé sur les métiers de l'IT sur la lorraine au sein du cabinet de recrutement Harry Hope accompagne les candidats dans leurs recherches d'une meilleure opportunité professionnelle sur leur secteur géographique privilégié. Nous ne sommes pas une ESN, nous intervenons dans la mise en relation avec des clients finaux sur des postes en CDI. Notre client, une société en pleine croissance dans le secteur de l'IA, recherche un Data Scientist (H/F) pour compléter son équipe dédiée.
Intégré à une équipe technique composée de Data scientist, de développeurs et de chercheurs, vous aurez l'occasion d'intervenir dans la récupération, l'exploitation, la modélisation, l'évaluation et l'interprétation de données stockées dans les bases de données de la structure permettant de les exploiter selon les besoins. En parallèle de vos missions concernant les données propre à l'activité principale de l'entreprise, vous intervenez également dans l'exploitation et la structuration des datas récupérées sur internet en lien avec l'IA en cours de développement.
Diplômé en informatique, vous disposez à minima d'une première expérience à un poste similaire (alternance ou premier emploi). Techniquement, vous avez une grande expertise en statistiques et en mathématiques appliquées. Vous maitrisez les domaines du Big Data, du machine learning et de la programmation informatique (Python, Java, R, SQL ...). Humainement, vous êtes reconnu pour votre dynamisme, votre flexibilité et votre engagement. Vous êtes capable de vous impliquer à fond dans les projets qui vous sont confiés et vous appréciez le travail collaboratif. Passionné par la Data, vous assurez une veille constante sur les nouvelles technologies en lien avec votre activité. Enfin, vous maitrisez l'anglais à l'oral comme à l'écrit.
Informations complémentaires : Salaire selon profil et expériences (38/42kEUR), possibilité d'évoluer rapidement, CDI à pouvoir rapidement à Nancy.
Si cette opportunité correspond à vos aspirations professionnelles alors faites-moi parvenir votre candidature. J'étudierai cette dernière et reviendrai vers vous dans les meilleurs délais pour un suivi personnalisé de votre profil !
20624921-55584
Show more
Show less","{'ProgLanguage': ['Python', 'Java', 'R'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': ['Statistiques'], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Big Data', 'Machine Learning', 'Statistiques'], 'FrSoftSkills': ['Flexibilité'], 'EnSoftSkils': []}","{'JobDetail': [], 'TypeContract': ['CDI'], 'Salary': ['38'], 'Level': [], 'Experience': ['a', 'n', 's']}"
LinkedIn,Machine Learning Developer,MindPal,"Paris, Île-de-France, France",https://fr.linkedin.com/jobs/view/machine-learning-developer-at-mindpal-3896993704?position=7&pageNum=7&refId=jSHCf8SJlBfpMeJ3wOWkYQ%3D%3D&trackingId=%2BwC5oaYVFwVTsNj2TKJOtg%3D%3D&trk=public_jobs_jserp-result_search-card,"We are looking for
Machine Learning Developer
Job Responsibilities
Working on machine learning projects
Analyzing and processing data to create machine learning models
Implementing and optimizing machine learning algorithms
Testing and evaluating models
Collaborating with the programming team and other departments within the company to develop innovative solutions
Requirements
Minimum 2 years of experience in the field of machine learning
Knowledge of machine learning algorithms and techniques
Ability to analyze and process data
Familiarity with machine learning tools and technologies
Proficient in English communication
Education in computer science
We Offer
B2B contract type
Full-time employment
Remote and flexible working hours
Show more
Show less","{'ProgLanguage': ['R', 'Go'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Machine Learning'], 'FrSoftSkills': ['Communication'], 'EnSoftSkils': ['Communication']}","{'JobDetail': ['Remote', 'Full'], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's']}"
LinkedIn,CDI - DATA SCIENTIST / IA CONFIRME H/F,ITNOVEM.,"Paris, Île-de-France, France",https://fr.linkedin.com/jobs/view/cdi-data-scientist-ia-confirme-h-f-at-itnovem-3899543583?position=8&pageNum=7&refId=jSHCf8SJlBfpMeJ3wOWkYQ%3D%3D&trackingId=wnSlVnaIhncVBDe2l9rAVA%3D%3D&trk=public_jobs_jserp-result_search-card,"L’ENTREPRISE
Filiale privée technologique du
Groupe SNCF
, ITNOVEM se positionne comme accélérateur des projets Digitaux, numériques et de la transformation des Systèmes d’information du groupe. Porteuse de grands projets de la révolution digitale, notre société est en constante recherche de profils pour rejoindre la grande aventure de l’Internet des objets, de la data science, de la cybersécurité et de l’accompagnement des projets digitaux. Qu’il s’agisse de maintenance prédictive, d’aide à la décision sur la maintenance des infrastructures, de gare 4.0, d’usine du futur, ou de sécurisation des assets, nos équipes font valoir à la fois une expérience métier et une expertise technique sans cesse renouvelée, dans le respect des valeurs du groupe :
Excellence
,
Innovation
,
Collectif
,
Agile
,
Engagement.
LE POSTE
Au sein d’ITNOVEM, la « Factory Data & IA » accompagne les différentes entités du Groupe SNCF à répondre à leurs enjeux métiers via l’exploitation des données dont le groupe dispose et en mobilisant des compétences et expertises techniques en data science, data engineering et technologies Big Data & Cloud. Elle conçoit, construit, déploie, et exploite les projets data pour le Groupe SNCF (socles de données, traitements de données massives, transformations complexes, développement d'algorithmes, intelligence artificielle ...).
Au sein de la « Factory Data & IA », l’équipe « Data Science » intervient auprès des métiers et DSI de SNCF avec une forte ambition en matière d’industrialisation et des technologies Data et IA qui correspondent à l’état de l’art. Les problématiques sont variées et liées aux grands enjeux industriels, opérationnels et stratégiques du groupe SNCF, par exemple :
Maintenance du matériel roulant ;
Surveillance et la maintenance de l'infrastructure ferroviaire (voies et caténaires) ;
Mise en œuvre de l’IA Générative pour des applications ferroviaires ;
Construction de modèles IA pour améliorer la performance opérationnelle ;
Mise en place de solutions d’IA autour de l’image et la vidéo (computer vision) ;
Analyse et valorisation des données de capteurs (par ex., mesures, vidéo).
L’
Ingénieur Data Scientist
contribue au développement de l’activité de l’équipe « Data Science ». Il analyse, valorise et exploite l’ensemble des données mises à sa disposition. Il proposer, en proche collaboration avec les métiers, des solutions pour répondre aux cas d’usage identifiés.
MISSIONS ET RESPONSABILITÉS
Au sein de l’équipe « Data Science », le
Data Scientist
porte les responsabilités suivantes :
Accompagner, en tant que lead technique, les projets Data Science / IA (cadrages, études, prototypes et industrialisation) de la Factory, à la fois sur les aspects techniques / scientifiques et sur la relation client.
Mener des activités de conseil technique et scientifique sur l’usage et la valorisation de la donnée au sein du Groupe SNCF. Accompagner l’identification et la mise en œuvre de cas d’usage auprès des métiers.
Construire des solutions d’IA et de valorisation des données appliquées aux cas d’usage du Groupe SNCF.
Contribuer à la veille scientifique et technique, aux projets R&D internes, et à la construction de produits et de services techniques orientés data. Proposer des axes de développement des activités Data Science.
Être un référent technique de l'équipe sur les questions data science et accompagner les data scientists plus juniors dans leur montée en compétences.
Participer et contribuer à la vie de l’équipe Data Science : partage de connaissance, mise en place de bonnes pratiques, communication interne et externe, collaborations externes.
COMPETENCES ATTENDUES
Compétences techniques / métier
Maitrise des outils mathématiques de la Science des Données (statistiques, recherche opérationnelle, traitement du signal, traitement de l’image …).
Capacité à aborder et à résoudre des problèmes complexes avec méthode.
Capacité avérée de modélisation de problématiques métier en termes de données et d’analyse statistique.
Expérience en développement Python et une bonne capacité à produire du code industriel (modulaire, testé, non redondant, automatisé, robuste, optimisé).
Maîtrise des algorithmes de Machine Learning et de Deep Learning, ainsi que des outils associés (scikit-learn, TensorFlow, PyTorch, SparkML ...) pour le traitement de données structurées et non structurées.
Maitrise des outils de NLP et de l’IA générative / LLM / RAG.
Bonne connaissance des principes de la gestion de projet Data. Capacité à piloter, cadrer et chiffrer un projet et gérer des collaborateurs.
Maitrise de l’anglais technique.
Connaissance d’un écosystème cloud (Azure ou AWS) et de Databricks est un plus.
Idéalement, des connaissances du contexte et enjeux liés à l’industrie.
Compétences personnelles / transverses
Communication écrite et orale rigoureuse et claire. Sens de la pédagogie. Capacité à effectuer et synthétiser de la veille scientifique et technique.
Orienté résolution de problème.
Transversalité et capacité à travailler avec des équipes pluridisciplinaires.
Orientation client, qualité et résultats.
Capacité à piloter une équipe, cadrer et chiffrer un projet, manager des collaborateurs.
Capacité à mener des activités de conseil technique et scientifique auprès de non spécialistes.
Rigueur, gestion et organisation.
Curiosité fonctionnelle et technologique.
Appétence pour le milieu industriel, et particulièrement le domaine ferroviaire.
EXPÉRIENCES ET FORMATIONS
Vous avec obtenu une diplôme d’une formation scientifique Bac+5 ou supérieur (doctorat, école d’ingénieur), dans un domaine lié à l’usage de la données (par exemple, physique, mécanique, traitement du signal et de l’image, mathématiques appliquées).
Vous disposez d'au moins 4 ans d'expérience professionnelle dans le traitement avancé des données et le développement d'applications en Analyse / Intelligence Artificielle / Science des Données. Sont notamment appréciées les expériences en relation avec un domaine industriel.
D’autres raisons de rejoindre ITNOVEM !
🚀 En tant que filiale SNCF, des opportunités de carrières internes vous sont offertes.
📚 ITNOVEM croit en la formation continue de ses collaborateurs et leur donne l’opportunité de s’inscrire à une formation par an minimum.
🚊 Vos titres de transport sont pris en charge à hauteur de 75%.
🍽️ Via la carte titres-restaurant Swile, vous bénéficiez de 9,25 € par jour dont 60% pris en charge par ITNOVEM.
💻 Chez ITNOVEM, vous bénéficiez jusqu’à 3 jours de télétravail par semaine.
🏖️ ITNOVEM vous permet de profiter de 28 congés et de 16 RTT pour les cadres et 10 pour les non-cadres. Par ailleurs, 2 des 3 jours de congés pour enfant malade sont rémunérés.
👫 La mise en œuvre de l’égalité professionnelle femmes/hommes est primordiale chez ITNOVEM. A chaque nouvelle embauche, l'entreprise s'engage à proposer une rémunération équivalente tant aux femmes qu'aux hommes.
♻️ ITNOVEM incite tous les collaborateurs à trier leurs déchets et les gobelets ont été bannis. Par ailleurs, chaque année, ITNOVEM participe à « La grande collecte », une initiative SNCF qui permet de collecter les PC devenus obsolètes en leur offrant une seconde vie
Show more
Show less","{'ProgLanguage': ['Python', 'R', 'Go'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': ['Spark', 'Databricks'], 'MachingLearning': ['Scikit-Learn', 'TensorFlow', 'PyTorch'], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': ['Statistiques'], 'CloudComputing': ['AWS', 'Azure'], 'DevTools': ['Git'], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Big Data', 'ML', 'Machine Learning', 'Statistiques', 'Cloud'], 'FrSoftSkills': ['Communication', 'Collaboration', 'Organisation'], 'EnSoftSkils': ['Communication', 'Collaboration', 'Initiative']}","{'JobDetail': ['Junior'], 'TypeContract': [], 'Salary': [], 'Level': ['Bac+5'], 'Experience': ['a', 'n', 's', '4', '4', '4']}"
LinkedIn,Data scientist - Monaco,Klanik,"Nice, Provence-Alpes-Côte d'Azur, France",https://fr.linkedin.com/jobs/view/data-scientist-monaco-at-klanik-3912534166?position=9&pageNum=7&refId=jSHCf8SJlBfpMeJ3wOWkYQ%3D%3D&trackingId=ty%2Bj5ikNaHH1trpEsmjAXg%3D%3D&trk=public_jobs_jserp-result_search-card,"Le consultant travaillera sur des analyses de données et de participer au développement de modèles prédictifs et d'algorithmes d'apprentissage automatique.
Activités :
- Nettoyage / préparation / structuration / normalisation des données pour garantir leur qualité et leur fiabilité ;
- Exploration de données : utiliser des statistiques descriptives et des visualisations de données pour explorer les jeux de données, identifier des tendances, des anomalies éventuelles ;
- Modélisations : concevoir, développer et déployer des modèles statistiques et d'apprentissage automatique pour répondre à des questions spécifiques ou résoudre des problèmes métiers ;
- Développement et optimisation de pipelines de données pour faciliter l'acquisition, le traitement et la mise à disposition des données pour l'analyse ;
- Communication des résultats des analyses et des modélisations à travers des rapports et des visualisations de données claires et impactantes, permettant aux parties prenantes de prendre des décisions basées sur les données.
Profil
Être titulaire, d’un diplôme national d’ingénieur sanctionnant cinq années d’études supérieures ou d’un diplôme reconnu équivalent
Entre 2 et 5 ans d'expérience en tant que Data Scientist
Compétences Techniques :
Maîtrise des langages de programmation tels que Python ou R, et des bibliothèques de data science comme pandas, TensorFlow ou PyTorch ;
Expérience en Modélisation Statistique : Solide compréhension des techniques statistiques et de machine learning, avec une capacité à appliquer ces techniques pour résoudre des problèmes complexes ;
Gestion de Bases de Données : Expérience avec les bases de données SQL, NoSQL, Time Series, ainsi qu'avec les technologies de traitement de données en temps réel ;
Visualisation de Données : Compétence dans l'utilisation d'outils de visualisation de données tels que Tableau, Power BI, ou des bibliothèques Python de visualisation de données.
Show more
Show less","{'ProgLanguage': ['Python', 'R', 'Go'], 'DataBase': ['SQL', 'NoSQL'], 'DataAnalytics': ['Pandas', 'R'], 'BigData': [], 'MachingLearning': ['TensorFlow', 'PyTorch'], 'DataSerialization': [], 'DataVisualization': ['Tableau', 'Power BI'], 'Statistics': ['Statistiques', 'Statistiques Descriptives'], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Machine Learning', 'Statistiques'], 'FrSoftSkills': ['Communication'], 'EnSoftSkils': ['Communication']}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's', '5', '5', '5']}"
LinkedIn,Machine Learning Developer,MindPal,"Toulouse, Occitanie, France",https://fr.linkedin.com/jobs/view/machine-learning-developer-at-mindpal-3896992755?position=10&pageNum=7&refId=jSHCf8SJlBfpMeJ3wOWkYQ%3D%3D&trackingId=U51E83rZ34mXilrhQlk01g%3D%3D&trk=public_jobs_jserp-result_search-card,"We are looking for
Machine Learning Developer
Job Responsibilities
Working on machine learning projects
Analyzing and processing data to create machine learning models
Implementing and optimizing machine learning algorithms
Testing and evaluating models
Collaborating with the programming team and other departments within the company to develop innovative solutions
Requirements
Minimum 2 years of experience in the field of machine learning
Knowledge of machine learning algorithms and techniques
Ability to analyze and process data
Familiarity with machine learning tools and technologies
Proficient in English communication
Education in computer science
We Offer
B2B contract type
Full-time employment
Remote and flexible working hours
Show more
Show less","{'ProgLanguage': ['R', 'Go'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Machine Learning'], 'FrSoftSkills': ['Communication'], 'EnSoftSkils': ['Communication']}","{'JobDetail': ['Remote', 'Full'], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's']}"
LinkedIn,Senior Data Scientist (H/F),Technology & Strategy,"Paris, Île-de-France, France",https://fr.linkedin.com/jobs/view/senior-data-scientist-h-f-at-technology-strategy-3873419835?position=1&pageNum=10&refId=lUCpoL4OtWpdXIhZLSJ%2ByQ%3D%3D&trackingId=ecXMVmaYF654bCTCykdAeA%3D%3D&trk=public_jobs_jserp-result_search-card,"Découvrez Novencia
:
Expert en Data et Intelligence Artificielle, nous aidons nos clients à exploiter et à valoriser leurs données sous toutes ses formes en les accompagnant sur des projets de Data Analyse, Data Gourvernance, Data Architecture, Data Science, et Data Engineering…
Vous avez une solide expérience de minimum 4 ans dans la science des données et vous êtes à la recherche de nouveaux défis ? N'hésitez plus !
Type de contrat : CDI
Démarrage : Dès que possible
Lieu : Paris
En qualité de Senior Data Scientist (H/F), votre rôle sera :
Cadrer et challenger les besoins des utilisateurs, contribuer à la définition des Use Case
Traiter les données, structurées ou non structurées pour extraire des insights à valeur ajoutée
Contrôler la qualité des données, détecter des patterns, des outliers
Proposer et mettre en pratique les modèles statistiques (régressions…) ou de datascience (machine learning…) pour résoudre les problématiques métier
Mener le projet de la phase de POC à l’industrialisation, le plus souvent intégré au sein d’une Feature team
Restituer les résultats (rapports, présentations…)
Pré-requis :
Capacité de comprendre les besoins et enjeux métiers et de les reformuler sous forme d’une problématique Data
Capacité d’expliquer des idées complexes avec des mots simples, claires et précis
Bonne connaissance et maîtrise des algorithmes de Data Science et de Machine Learning
Très bonnes compétences en programmation sur Python avec une maîtrise des librairies python
Bonnes bases des outils de versioning comme git
Une maîtrise des librairies ou d'outils de data visualisation
Maîtrise d’autres langages (comme R et SAS) est un plus
Familier avec une plateforme cloud (AWS, GCP et Azure)
Compréhension des enjeux de mise en production
Compétences dans les technologies Big Data est un plus
Bon niveau d’anglais à l’oral comme à l’écrit
Notre objectif commun est de co-construire votre carrière en fonction de vos aspirations et de vos compétences.
Contactez-moi en message privé ou par mail à s.ziki@technologyandstrategy.com !
Let's make it possible #together
*Nos postes sont ouverts aux personnes bénéficiant d’une Reconnaissance de la Qualité de Travailleur Handicapé (RQTH). T&S Groupe encourage la diversité et l’égalité sur le lieu de travail. Tous les candidats qualifiés H/F/* sont pris en considération pour un emploi sur un même pied d'égalité.
Show more
Show less","{'ProgLanguage': ['Python', 'R', ' R ', 'Go'], 'DataBase': [], 'DataAnalytics': ['R', ' R '], 'BigData': [], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': ['Statistiques'], 'CloudComputing': ['AWS', 'Azure'], 'DevTools': ['Git'], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Big Data', 'Machine Learning', 'Statistiques', 'Cloud'], 'FrSoftSkills': [], 'EnSoftSkils': []}","{'JobDetail': ['Senior'], 'TypeContract': ['CDI'], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's', '4', '4', '4']}"
LinkedIn,Docteur en IA/ML/NLP – H/F,Novelis,"Paris, Île-de-France, France",https://fr.linkedin.com/jobs/view/docteur-en-ia-ml-nlp-%E2%80%93-h-f-at-novelis-3903772419?position=2&pageNum=10&refId=lUCpoL4OtWpdXIhZLSJ%2ByQ%3D%3D&trackingId=sKPdU8FAUJ4onEORMp6Uxg%3D%3D&trk=public_jobs_jserp-result_search-card,"Doctor in AI/ML/NLP
Novelis is a dynamic and agile organization that has chosen to focus on innovation and research. We strongly believe in investment as a tool for progress and a driver of growth; it's part of our DNA. With our Intelligent Automation division and our R&D laboratory, we assist our partners in developing innovative architectures and solutions that combine Data, Artificial Intelligence, and Smart Automation (RPA, OCR, Semantic Analysis).
We are looking for a PhD Doctor to strengthen our R&D Lab in the Paris region.
The Novelis Lab is our dedicated research and development structure. It is the nerve center of Novelis, whose objective is to implement our Innovation and Research strategy.
Your missions
Work on multidisciplinary topics that combine artificial intelligence (machine learning), natural language processing (NLP), and computer vision, reasoning
,
planification
and
optimization
tasks
,
process
automation.
Conduct research and stay up to date with the scientific state of the art related to our research work.
Design, develop, test, and document innovative solutions that meet the challenges of our R&D laboratory.
Contribute to the writing of scientific publications.
Required Profil
We are seeking a highly skilled and motivated individual to join our R&D laboratory as a Doctor of Artificial Intelligence. The successful candidate will have a PhD in artificial intelligence, machine learning, or a related field and will possess knowledge in NLP and/or machine vision and/or machine learning methods. Strong programming skills in Python (Java is a plus) and experience in software modeling, design (UML/Merise), and development are required.
In addition, excellent written and verbal communication skills, a creative mindset, scientific curiosity, and a passion for research are essential for this role. Fluency in English is required, and proficiency in French is a plus. If you are looking for an exciting opportunity to be part of a dynamic R&D team and contribute to cutting-edge research in the field of artificial intelligence, we encourage you to apply.
jobs@novelis.io
As part of its diversity policy, Novelis studies, with equal skills, all applications including those of people with disabilities.
Show more
Show less","{'ProgLanguage': ['Python', 'Java', 'R'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['ML', 'Machine Learning'], 'FrSoftSkills': ['Communication'], 'EnSoftSkils': ['Communication', 'Organization']}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's']}"
LinkedIn,Data Scientist,SMARTIUM Group,"Strasbourg, Grand Est, France",https://fr.linkedin.com/jobs/view/data-scientist-at-smartium-group-3835671392?position=3&pageNum=10&refId=lUCpoL4OtWpdXIhZLSJ%2ByQ%3D%3D&trackingId=RcYvV4bgCpIn5jNqakcapg%3D%3D&trk=public_jobs_jserp-result_search-card,"SMARTIUM Group est une jeune startup basée à Starsbourg qui propose des technologies de mesure des rayonnements ionisants dans les domaines de l'industrie, de la santé et de la sécurité. Dans le cadre de notre développement nous recherchons
un(e) Data Scientist
.
Nos solutions embarquées à forte valeur ajoutée permettent une analyse avancée des dnnées fournies par les systèmes de mesure et par la modélisation numérique (monte carlo).
Issue de la valorisation des travaux de recherche, SMARTIUM Group bénéficie d'un lien renforcé avec la recherche (CNRS) et les universités.
Vos missions
Vous êtes titulaire d'un Bac+5 et/ou doctorat en science de préférence, et vous avez pu développer des compétences en simulation Monte Carlo (Genat4, MCNP, ...) et/ou en science des données (analyse statistique, apprentissage automatique, intelligence artificielle). Vous souhaitez valoriser ces compétences dans un environnement professionnel dynamique d'une jeune startup Deeptech en lien direct avec la recherche.
Rattaché directement au CEO vous contriburez au développement de solutions innovantes variées pour des problématiques santés, industrielles et environnementales.
Votre implication et votre réussite feront de vous un élément clé du développement de l'entreprise. Des prerspectives d'encadrement d'équipe sont envisagées pour les profils faisant preuve de qualités managériales.
Vos compétences
Bac +5 en science/ physique nucléaire ; Intérêt fort pour la science des données ; une expérience/formation en simulation Monte Carlo serait un plus ; une apétence pour l'analyse des données ; des connaissance en Intelligence Artificielle serait un plus ;
Avantages
Ambiance startup - Equipe dynamique - Salaire suivant profil + avantages
Show more
Show less","{'ProgLanguage': ['R'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': [], 'FrSoftSkills': [], 'EnSoftSkils': []}","{'JobDetail': [], 'TypeContract': [], 'Salary': ['Salaire'], 'Level': ['Bac+5'], 'Experience': ['a', 'n', 's']}"
LinkedIn,"Ingénieur Machine Learning – Paris, France (H/F)",Astek,"Paris, Île-de-France, France",https://fr.linkedin.com/jobs/view/ing%C3%A9nieur-machine-learning-%E2%80%93-paris-france-h-f-at-astek-3882492554?position=4&pageNum=10&refId=lUCpoL4OtWpdXIhZLSJ%2ByQ%3D%3D&trackingId=gtmDKe%2FvjVPakexFswVVtA%3D%3D&trk=public_jobs_jserp-result_search-card,"CDI
Paris - France
Publiée il y a 1 mois
Le Groupe Astek
Ce Que Nous Allons Accomplir Ensemble :
Rejoignez nos équipes et intervenons ensemble sur les projets de nos partenaires autour des enheux d’innovation.
Votre Mission, Si Vous L’acceptez :
Cadrer techniquement les projets et accompagner les Data Scientists dans la construction des modèles en veillant à respecter les bonnes pratiques d’ingénierie logicielle.
Mettre en place la démarche ML OPS
Déployer les modèles en production en respectant des contraintes de coûts, précisions et performances techniques.
Implémenter les outils permettant de monitorer ces modèles en production
Vous ?
Vous êtes issu(e) d’une formation Bac+5 (École d’ingénieur, Université ou équivalent …) en informatique
Vous justifiez d’une expérience significative d’au moins 5 ans au sein d’une équipe dans un environnement Data à l’échelle du SI d’un grand groupe
Vous êtes un bon communiquant et disposez de capacités d’analyse et de synthèse éprouvées
Vous accordez de l’importance à la veille technologique
Compétences Techniques :
Expertise en SPARK et PySpark
Connaissance de Kubernetes
Connaissance de d’Apache Kafka
Une expérience sur un cloud provider public comme Azure (idéalement), AWS, ou GCP
Expertise de développement en Python
Expertise du ML OPS
Compétences Transverses :
Capacité à interagir avec des parties prenantes diverses : Data Scientists, Business analyst, Architectes, Métier
Forte expérience en mode de Delivery Agile (Scrum, Kanban, etc.…)
Etre expert dans les pratiques du Software Craftsmanship (Test Driven, Development, Behavior Driven Development, Clean Code, Code Reviews, etc.)
Et :
Des Connaissances sur Azure DevOps, Azure Pipeline, GIT
Maitrise des Traitements Big Data en mode Streaming
Maitrise des Bases de données relationnelles et NoSQL
Une expérience professionnelle avec des outils comme Azure Databricks, Azure, Machine Learning , Azure Data Lake Storage ou encore Azure Data Factory
Le Groupe Astek
Créé en France en 1988, Astek est un acteur mondial de l’ingénierie et du conseil en technologies. Fort de son expertise dans de nombreux secteurs industriels et tertiaires, Astek accompagne ses clients internationaux dans le déploiement intelligent de leurs produits et de leurs services, et dans la mise en œuvre de leur transformation digitale.
Depuis sa création, le Groupe a fondé son développement sur une forte culture d’entrepreneuriat et d’innovation, et sur l’accompagnement et la montée en compétence de
ses 7800 collaborateurs
qui s’engagent chaque jour à promouvoir la complémentarité entre les technologies numériques et l’ingénierie des systèmes complexes.
Rejoignez un Groupe en fort développement en France et à travers le monde ayant réalisé un chiffre d’affaires de 600 M€ en 2023.
Tous les détails sur le Groupe sur le site https://astekgroup.fr. Et vous pouvez aussi nous suivre sur notre blog : https://blog.groupeastek.com.
Rencontrons-nous
Notre projet commun vous plait ?
Postulez à cette annonce, et soyez transparent !
Notre Talent Acquisition Officer, vous contactera pour un premier échange téléphonique.
Puis vous rencontrerez votre futur manager, avec lequel vous échangerez autour d’Astek, de votre parcours, de vos attentes et de votre future mission .
Enfin, vous rencontrerez notre Directeur de département, avec lequel vous pourrez valider votre intérêt et adéquation pour le poste et finaliser les éléments contractuels.
Nos Plus
Astek est green et fait bénéficier ses salariés d’une indemnité kilométrique vélo
Une politique CARE sur-mesure déployée par nos équipes RH pour nos collaborateurs (https://astekgroup.fr/engagements)
Notre charte de la Diversité
Bienvenue dans la team ! Allez-y, maintenant c’est à vous de jouer !
Mots-clés :
ingénieur – ingénieure – consultant – consultante
Caractéristiques de l'emploi
Catégorie Chef de Projet
Job Industry Aérospatial / Défense / Sécurité, Distribution / Services Internet, Energie / Sciences de la Vie / Autres industries, Finance / Gouvernement, Télécom / Média, Transports Terrestres
Postuler en ligne
Nom *
Prénom *
Email *
Un email valide est requis.
Téléphone *
Un numéro de téléphone valide est requis.
Joindre un CV *
Mots-clés :
ingénieur – ingénieure – consultant – consultante
Show more
Show less","{'ProgLanguage': ['Python', 'R', 'Go'], 'DataBase': ['SQL', 'NoSQL'], 'DataAnalytics': ['R'], 'BigData': ['Spark', 'Databricks'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': ['AWS', 'Azure'], 'DevTools': ['Git'], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': ['Apache Kafka'], 'Automation': ['Kubernetes', 'Chef'], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': ['Kubernetes'], 'Collaboration': [], 'Other': ['DevOps', 'Big Data', 'ML', 'Machine Learning', 'Cloud'], 'FrSoftSkills': [], 'EnSoftSkils': []}","{'JobDetail': [], 'TypeContract': ['CDI'], 'Salary': [], 'Level': ['Bac+5'], 'Experience': ['a', 'n', 's', '5', '5', '5']}"
LinkedIn,ALTERNANCE - Data Scientist,Moët Hennessy,"Paris, Île-de-France, France",https://fr.linkedin.com/jobs/view/alternance-data-scientist-at-mo%C3%ABt-hennessy-3840470791?position=5&pageNum=10&refId=lUCpoL4OtWpdXIhZLSJ%2ByQ%3D%3D&trackingId=dOIqnzI%2BZWf9tXqV9o%2B%2F0Q%3D%3D&trk=public_jobs_jserp-result_search-card,"Moët Hennessy est à la recherche d'une personne motivée pour rejoindre son Centre d'Expertise (CoE) Data & AI en tant qu'alternant.e Data Scientist.
Dans ce rôle, vous aurez l'opportunité de contribuer au développement d'un ""compliance bridge"" visant à valider automatiquement la conformité aux différentes réglementations en vigueur du contenu produit par ou pour Moët Hennessy (texte, image, vidéo, etc.).
Cela nécessitera, notamment, de mettre en œuvre des compétences en Machine Learning (Object Detection, Object Segmentation, NLP, GenAI...).
En plus de cette mission principale, vous serez amené.e à travailler sur d'autres sujets selon les besoins (implémentation de démonstrateur IA, acculturation des métiers, veille technologique...).
Le CoE Data & AI est une équipe au sein du département Data & AI de la DSI de Moët Hennessy. Cette direction a pour mission d'accélérer la transformation de nos différents métiers, de la vigne jusqu'au verre.
Descriptif du poste
:
Participer au développement de la ""couche de conformité"" afin d'assurer la conformité du contenu avec les réglementations locales (par exemple, la Loi Evin) et les normes internes.
Participer aux phases d'idéation, d'étude de faisabilité et de lancement de projets IA
Participer pour ces projets aux phases de modélisation mathématique
Effectuer des analyses exploratoires des données
Contribuer aux activités de préparation des données (nettoyage de donnée, feature engineering, feature selection…)
Soutenir la conception et la mise en œuvre des modèles
Contribuer au design des pipelines de machine learning incluant notamment la mesure de performance des modèles et à leur monitoring
Contribuer à l'industrialisation des modèles tout en respectant les normes du groupe et les principes MLOps
Documenter les projets d'intelligence artificielle
Contribuer à la veille technologique du COE Data & AI
Nous recherchons une personne en alternance inscrite dans un programme master 1 ou master 2 en data science.
Rythme d'alternance souhaité :
15j / 15j de préférence (autres rythmes possibles).
Durée de l'alternance souhaitée :
1 an
Compétences recherchées :
Maitrise de Python
Bonne compréhension des bonnes pratiques de développement logiciel
Connaissance de Dataiku
Connaissance des services GCP (en particulier Cloud Run, Vertex AI
Anglais professionnel
Français courant
Autonomie et pro activité
Esprit de synthèse
Capacité de vulgarisation
Qualités relationnelles et rédactionnelles
Informations complémentaires :
Période : rentrée de septembre 2024
Localisation géographique de l'offre : PARIS
Déplacements occasionnels à prévoir en Champagne (Epernay)
Show more
Show less","{'ProgLanguage': ['Python', 'R'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['ML', 'Machine Learning', 'Cloud'], 'FrSoftSkills': [], 'EnSoftSkils': []}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's']}"
LinkedIn,DATA SCIENTIST - CDI - H/F,Pierre Fabre Group,"Lavaur, Occitanie, France",https://fr.linkedin.com/jobs/view/data-scientist-cdi-h-f-at-pierre-fabre-group-3908875712?position=6&pageNum=10&refId=lUCpoL4OtWpdXIhZLSJ%2ByQ%3D%3D&trackingId=%2FOn%2F%2FbnWQ8vwdot%2F6DMK1g%3D%3D&trk=public_jobs_jserp-result_search-card,"Qui sommes-nous ?
Pierre Fabre est le 2ème laboratoire dermo-cosmétique mondial, le 2ème groupe pharmaceutique privé français et le leader des produits vendus hors prescription dans les pharmacies en France.
Son portefeuille compte plusieurs franchises médicales et marques internationales dont Pierre Fabre Oncologie, Pierre Fabre Dermatologie, Eau Thermale Avène, Klorane, Ducray, René Furterer, A-Derma, Naturactive et Pierre Fabre Oral Care.
Implanté depuis toujours en région Occitanie, fabricant plus de 95% de ses produits en France, le groupe emploie près de 10 000 collaborateurs dans le monde et distribue ses produits dans quelque 130 pays. Pierre Fabre est détenu à 86% par la Fondation Pierre Fabre, une fondation reconnue d’utilité publique, et secondairement par ses collaborateurs à travers un plan d’actionnariat salarié.
En 2021, Ecocert Environnement a évalué la démarche de responsabilité sociétale et environnementale du Groupe selon la norme ISO 26000 du développement durable et lui a attribué le niveau « Excellence ».
Pierre Fabre est reconnu comme l’un des « Meilleurs Employeurs du Monde 2021 » par Forbes. Notre groupe est classé dans le Top 6 de l’industrie cosmétique et dans le Top 7 de l’industrie pharmaceutique dans le monde. Nous sommes convaincus que notre engagement et notre passion font préserver notre indépendance et vivre notre raison d'être.
Votre mission :
Les Laboratoires Pierre Fabre, engagés dans l'excellence et l'innovation, vous offrent la possibilité de mettre votre expertise en data science au service de projets novateurs et stratégiques.
En exploitant des techniques avancées d'IA (machine learning, IA Gen...), vous contribuerez à relever des défis commerciaux et opérationnels de prédiction et de prescription par la data.
Pour cela, nous recrutons notre futur(e) :
DATA SCIENTIST
– CDI-
H/F -
situé à
LAVAUR (81)
Au cœur du Data Office (rattaché à la Direction Générale), vous rejoindrez une équipe pluridisciplinaire de haut niveau. Dans un cadre agile et propice à la synergie, votre rôle sera pivot à chaque phase des projets :
Collaborer étroitement avec les départements opérationnels et exécutifs pour cerner leurs besoins et envisager des solutions data-driven.
Assurer l'intégrité des données via leur nettoyage, agrégation et analyse exploratoire.
Concevoir et déployer des modèles prédictifs en utilisant des algorithmes de pointe.
Piloter des tests en conditions réelles pour valider les solutions proposées.
Développer des interfaces de visualisation pour une interprétation intuitive des données.
Implémenter les solutions retenues, en assurer la maintenance et les améliorations continues.
Assurer une veille et tester les solutions d'IA Générative.
Encadrer et former les talents émergents en data science.
Ce poste est à pourvoir
au plus tôt selon votre disponibilité
dans le cadre d’un CDI.
Les ""plus"" du poste :
Votre intégration au sein de notre communauté d'experts en data science et ingénierie informatique (les data champions) vous permettra de participer à des séminaires, des ateliers et des forums de discussion, favorisant l'échange de connaissances et le partage d'expériences.
Qui êtes-vous ?
Vous êtes doté(e) d'une formation supérieure en informatique ou en mathématiques appliquées (Master ou expérience équivalente), vous possédez une solide maîtrise des algorithmes d'apprentissage statistique.
Vous justifiez d'au moins 5 ans d'expérience dans le domaine, avec une compétence reconnue à toutes les étapes du cycle de projet en data science, y compris la gestion de bases de données volumineuses.
Votre rigueur scientifique et votre capacité à vous adapter à de nouveaux challenges en science des données sont des atouts que vous avez su développer tout au long de votre parcours.
Vous êtes également en mesure de guider des data ingénieurs moins expérimentés et d'échanger efficacement avec des interlocuteurs variés.
Les enjeux opérationnels concrets, notamment ceux liés au secteur de la pharma et de la dermo- cosmétique, vous motivent.
Vous excellez dans la communication de concepts complexes à des audiences variées, grâce à vos qualités relationnelles et votre aisance à l'oral.
Votre expérience en développement collaboratif et votre attachement à la qualité et à la clarté du code sont essentiels.
Vous maîtrisez le français et l'anglais technique, et vous avez une expérience significative des
projets cloud et du développement agile
.
Atouts supplémentaires :
Nous valorisons votre expérience sur les plateformes cloud, en particulier Microsoft, et votre capacité à gérer d'importants volumes de données. Nous sommes attentifs à votre expertise en développement logiciel agile et à tout projet antérieur de mise en œuvre de solutions ML.
Environnement technique :
Nos outils incluent Python, SQL, Tableau, Alteryx, POSIT, Snowflake, JMP entre autres.
Package de rémunération :
Vous bénéficiez d’un package de rémunération complet et attractif : intéressement, participation, actionnariat salarié avec abondement, mutuelle, prévoyance, 16 jours de RTT, CE …
Nous sommes convaincus que la diversité est une source d’épanouissement, d’équilibre social et de complémentarité pour nos collaborateurs, nos offres sont donc ouvertes à toutes et tous sans restriction.
Show more
Show less","{'ProgLanguage': ['Python', 'R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': ['Tableau'], 'Statistics': [], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'DBMS': ['Snowflake', 'Snowflake'], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['ML', 'Machine Learning', 'Cloud'], 'FrSoftSkills': ['Communication'], 'EnSoftSkils': ['Communication']}","{'JobDetail': [], 'TypeContract': ['CDI'], 'Salary': ['16'], 'Level': [], 'Experience': ['a', 'n', 's', '5', '5', '5']}"
LinkedIn,Computer Vision - Deep Learning Engineer,Exotec,"Lille, Hauts-de-France, France",https://fr.linkedin.com/jobs/view/computer-vision-deep-learning-engineer-at-exotec-3918170653?position=7&pageNum=10&refId=lUCpoL4OtWpdXIhZLSJ%2ByQ%3D%3D&trackingId=edYin4dnueh%2FCTr3wpqAMg%3D%3D&trk=public_jobs_jserp-result_search-card,"Chez Exotec, nous mettons l'excellence technologique au service de la redéfinition des relations entre humains et robots. A travers le monde, nos solutions révolutionnent la façon dont nos clients délivrent leurs produits aux consommateurs finaux. Nous contribuons au succès des plus grandes marques du commerce et de l'industrie, tout en améliorant les conditions de travail de leurs salariés.
Par l'alliance de l'intelligence artificielle et d'un hardware performant, nos robots sont désormais déployés dans le monde entier et leur succès a fait de nous la première licorne industrielle française.
Rejoindre Exotec, c'est l'opportunité de donner du sens à vos compétences. Grandissez avec plus de 600 ExoPeople dans le monde entier pour faire de vos idées des réalités.
La révolution robotique portée par Exotec ne fait que commencer, vous en êtes ?
Vos missions :
Connaitre les dernières avancées dans le monde du Deep Learning et de la vision par ordinateur.
Identifier les angles d'améliorations des modèles et proposer de nouvelles solutions.
Collecter et manipuler les données nécessaires à l'entraînement et l'évaluation de modèles.
Implémenter et entrainer de nouveaux modèles.
Partager la connaissance avec votre équipe et consolider vos résultats sous la forme de code et de documentation de qualité.
Tester vos algorithmes en conditions réelles.
Contribuer à une intégration complète de vos solutions en collaborant avec les autres équipes.
Concevoir les méthodes de suivi des performances et d'identification de pistes d'améliorations.
Requirements
Vous êtes diplômé d'une grande école d'ingénieur ou détenteur d'un doctorat
Vous avez de l'expérience en Deep Learning et en Computer Vision et vous aimez la recherche
Vous aimer coder et vous êtes à l'aise en développement avec Python et utilisez des librairies comme PyTorch, TensorFlow et OpenCV
Vous avez des connaissances en C++ et en Robotique
Vous avez de l'expérience dans le déploiement et l'exploitation de modèles de Machine Learning en production
Vous savez prendre des initiatives et collaborer dans une ambiance décontractée au sein d'une équipe jeune et dynamique
Un niveau d'Anglais opérationnel, à l'oral comme à l'écrit, est nécessaire
Poste basé à Croix, à 15mn en métro du centre-ville de Lille, à 30mn de Bruxelles, 1h de Paris et 2h de Londres
Benefits
Couverture mutuelle et prévoyance santé compétitive
Primes collectives et attribution de BSPCE
Politique famille avantageuse
Programme de mobilité interne et internationale
Nombreuses opportunités de formation et de développement
Chez Exotec, nous garantissons l'égalité des chances dans notre processus de recrutement. L'ensemble des candidatures reçues sont étudiées indépendamment de l'âge, du genre, de l'origine, de la religion, de la couleur de peau, de la nationalité, du sexe, du handicap, de l'orientation sexuelle ou de toute autre distinction protégée par la loi. Nous mettons en place un environnement de travail inclusif et respectueux de toutes les différences. En rejoignant le Pacte Parité, Exotec s'engage pour un écosystème French Tech plus paritaire.
Show more
Show less","{'ProgLanguage': ['Python', 'C++', 'R', 'Go'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': ['TensorFlow', 'PyTorch'], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Machine Learning'], 'FrSoftSkills': [], 'EnSoftSkils': ['Initiative']}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's']}"
LinkedIn,Alternance - Data Scientist (H/F),Hermès,"Paris, Île-de-France, France",https://fr.linkedin.com/jobs/view/alternance-data-scientist-h-f-at-herm%C3%A8s-3890172447?position=8&pageNum=10&refId=lUCpoL4OtWpdXIhZLSJ%2ByQ%3D%3D&trackingId=kWxrs7B0%2FKNsohGsLL9Vww%3D%3D&trk=public_jobs_jserp-result_search-card,"Contexte
Alternance de 12 mois à pourvoir à partir de septembre.
Face au développement de la maison, la Direction des Activités Retail Groupe souhaite renforcer son expertise et développer son équipe Retail Data afin de répondre à de nouvelles ambitions concernant la gestion et l’analyse de la Data pour le Retail.
Missions
Vos principales missions seront :
ACCELERER LA MONTEE EN PUISSANCE DE LA DATA SCIENCE POUR LE RETAIL
Reprendre et améliorer les sujets IA existants au sein de l’équipe
Développer de nouveaux algorithmes de Machine Learning à destination de la relation client et du Retail
Promouvoir et animer l’utilisation de l’Intelligence Artificielle pour le retail en recensant et valorisant les cas d’usages de l’IA
MONITORER LA PERFORMANCE COMMERCIALE
Etudes Ad Hoc
Assister l’équipe Retail Data dans la réalisation des études AD HOC à destination des entités de production et de nos filiales de distribution
Reporting
Accompagner les Data Analysts dans la création de nouveaux reportings et leurs améliorations à destination des filiales de distribution et entités de production
ASSURER UNE VEILLE QUALITATIVE DES INNOVATIONS DATA SCIENCE APPLIQUEES AU RETAIL
Recenser et centraliser les nouvelles méthodologies d’algorithmie applicables à l’univers du Retail
Mettre à disposition cette veille aux membres de l’équipe
Profil recherché :
Etudiant(e) en Bac +4/5 en grande école ou grande université, en spécialité Statistiques/Data Science
Connaissance des Bases de données et à l’aise avec les langages de programmation (SQL, Python, etc.)
La connaissance de l’environnement AWS et ses composants (Sagemaker, etc.) est un plus
La connaissance de PowerBI est un plus
Langues : Anglais courant (écrit et oral)
Capacité d’analyse et esprit de synthèse
Curiosité et faculté d’adaptation
Show more
Show less","{'ProgLanguage': ['Python', 'R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': ['PowerBI'], 'Statistics': ['Statistiques'], 'CloudComputing': ['AWS'], 'DevTools': [], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Machine Learning', 'Statistiques'], 'FrSoftSkills': [], 'EnSoftSkils': []}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's']}"
LinkedIn,Data scientist pour la simulation de l'incendie et des explosions H/F,IRSN,"Saint-Paul-lez-Durance, Provence-Alpes-Côte d'Azur, France",https://fr.linkedin.com/jobs/view/data-scientist-pour-la-simulation-de-l-incendie-et-des-explosions-h-f-at-irsn-3909242968?position=9&pageNum=10&refId=lUCpoL4OtWpdXIhZLSJ%2ByQ%3D%3D&trackingId=oHFmObYU7gY4DVwRY3IQcg%3D%3D&trk=public_jobs_jserp-result_search-card,"Vous intégrez le Laboratoire de l'Incendie et des Explosions (LIE) du Service des Agressions Internes et risques Industriels (SA2I) rattaché au Pôle Sûreté des installations et des systèmes nucléaires à Cadarache.
Le SA2I réalise des expertises concernant la maîtrise des risques d'incendies, d'explosions et induits par l'activité humaine et des travaux de R&D dans ces mêmes domaines et plus généralement de la thermique et de la mécanique des fluides réactifs. Il initie, réalise ou suit des études et des recherches propres à répondre aux besoins de l'expertise dans son domaine de compétences.
Au sein du service, le LIE a pour objectif principal d'améliorer la connaissance sur les risques incendie et explosion en milieu confiné et ventilé et de développer les modélisations physiques associées. Cette connaissance est capitalisée par le développement de logiciels scientifiques à champ et à zones pour simuler les scénarios d'incendie et d'explosion en milieux représentatifs des installations
nucléaires. Il vient en soutien aux unités qui réalisent des expertises de sûreté et des programmes expérimentaux par l'utilisation de ces logiciels.
En tant que spécialiste en science des données, vous aurez quatre missions principales :
exploiter les informations contenues dans les bases expérimentales disponibles
et/ou générées par des simulations CFD par des méthodes de "" machine learning pour pouvoir extrapoler/interpoler les résultats physiques fournis par les logiciels (vitesses de flamme, température, écoulement...) et conforter leurs applications dans les études de sureté.
développer des modèles par assimilation de données issues de campagnes
expérimentales et de simulations CFD pour conforter leurs applications dans les études de sureté.
développer des métamodèles rapides en investiguant les solutions les plus
adaptées pour les problèmes physiques rencontrées en modélisation de l'incendie et des explosions. Ces modèles doivent permettre d'optimiser l'utilisation des logiciels développés au sein du service.
développer des méthodes d'analyse de sensibilité et de propagation des incertitudes pour l'identification des paramètres les plus influents des modèles numériques, en support à l'expertise et à l'orientation des recherches numériques et expérimentales.
Dans un environnement de travail où la compréhension et l'interprétation physique des phénomènes sont essentielles, vous devrez porter une attention particulière au niveau de confiance pouvant être accordé aux résultats obtenus par les métamodèles, ce qui pourrait notamment passer par le machine-learning informé par la physique, l'intelligence artificielle explicable et interprétable, les
méthodes de validation et de quantification des incertitudes avancées...
Vous aurez à collaborer avec les data scientists de différentes unités pour élaborer, partager et développer les méthodes à mettre en oeuvre pour les applications propres au SA2I. Vous devrez progressivement vous acculturer aux problématiques métiers du service, concernant les installations expérimentales et les outils de modélisation, afin de proposer des solutions répondant aux besoins des utilisateurs et s'intégrant dans les chaînes de calcul actuelles.
Vous aurez un rôle à jouer dans l'acculturation des ingénieurs-chercheurs au domaine des sciences des données.
Vous êtes titulaire d'un diplôme d'ingénieur ou de 3e cycle universitaire. Vous justifiez de 3 ans ou plus d'expérience professionnelle dans les sciences des données.
Des connaissances dans le domaine de la simulation numérique (CFD) seraient appréciées.
Vous maitrisez l'anglais.
Vous êtes rigoureux(se), force de proposition et disposez d'un esprit d'analyse et de synthèse ainsi que des capacités rédactionnelles.
Vous disposez de capacités de vulgarisation et d'écoute.
Vous avez un sens avéré du collectif.
20496836-55584
Show more
Show less","{'ProgLanguage': ['R', 'Go'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Machine Learning'], 'FrSoftSkills': [], 'EnSoftSkils': []}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's', '3', '3', '3']}"
LinkedIn,ML Engineer - CDI - F/H,Modjo,"Paris, Île-de-France, France",https://fr.linkedin.com/jobs/view/ml-engineer-cdi-f-h-at-modjo-3909458542?position=10&pageNum=10&refId=lUCpoL4OtWpdXIhZLSJ%2ByQ%3D%3D&trackingId=0Z5jp0PzvUT51yLEVmvL8Q%3D%3D&trk=public_jobs_jserp-result_search-card,"Modjo:
Modjo is the leader European AI Revenue Platform whose mission is to drive revenue teams productivity & performance with AI-extracted knowledge from customers interactions.
While AI is challenging how companies work across the world and all industries, Modjo brings these new capabilities to sales teams thanks to a platform that analyzes all interactions sales people have with their customers to improve sales teams productivity, drive strategy, and increase revenue.
We are a growing team of over 65 people, helping over 400 clients like BouyguesTelecom, Doctolib, Spendesk and Payfit in France and abroad. 🌎
Just like Slack, Zoom or Hubspot, Modjo is a product company. This means that our product is the core of what we are doing and how we are creating value to customers. Therefore, the success of the company relies on the capacity of its Tech & Product teams to deliver together the best product to its users.
Team organization :
The overall tech department is composed of 10 Software Engineers (2 squads), 2 ML Engineers, a Data Team (1 team lead + 1 analyst) and the CTO. You will be part of the Data Science team alongside the other ML Engineers.
Mission:
Modjo's core capabilities include capturing conversations between sales teams and their customers (video & audio recordings, emails..) and leveraging this data thanks to speech-to-text and various LLM-based processings to extract and structure data out of it.
As part of this, your main missions will be:
Collaborating with Product and Engineering to build features that require machine-learning expertise
Build, maintain and optimize our infrastructure for doing production machine learning including our speech-to-text stack (processing thousands of hours of audio every day) and our infrastructure for using LLMs
Design and implement processes, tools and pipelines in order to work efficiently with LLMs for our multiple use cases
Stay up to date with latest speech-to-text and LLM technologies in order to include them in the product and build the relevant technological asset for Modjo to differentiate from basic competition. This includes exploring model-finetuning models and RAGs
Your profile :
We think you would be a great fit if :
You have 3y+ experience in Machine Learning and Engineering
You have experience working with and knowledge about NLP, LLM and speech-to-text
You have experience with putting models in production, including monitoring and CI/CD
You are interested in solving real world use cases with LLMs and building the proper technology around it
You are eager to learn a lot in an autonomous way, both in Science and Engineering fields
You are willing to work in English (language of the team)
You want to join a company where the product you will be building is core to our strategy
You are looking for a challenging job, but also an environment where you can thrive and have fun on a day-to-day basis :)
We are looking for someone who will thrive and share our values:
😃 Pleasure
“If you Smile, things will work out” - Serena Williams
✅ Action
“Done is better than perfect” - Sheryl Sandberg
📚 Continuous Learning
“Amateurs call it Genius, masters call it practice” - Thierry Henry
🤲 Team Spirit
“Great things in business are never done by one person; they’re done by a team of people” - Steve Jobs
Show more
Show less","{'ProgLanguage': ['R'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': ['Slack', 'Teams'], 'Other': ['ML', 'Machine Learning', 'CI/CD'], 'FrSoftSkills': [], 'EnSoftSkils': ['Organization']}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's']}"
LinkedIn,Senior Data Scientist,Mirakl,France,https://fr.linkedin.com/jobs/view/senior-data-scientist-at-mirakl-3879684286?position=1&pageNum=12&refId=%2BSqq7I81JvLhh66Hu4n2TA%3D%3D&trackingId=mNNdDGXEHdQdszGAfOTmVA%3D%3D&trk=public_jobs_jserp-result_search-card,"Mirakl, leader et pionnier de l’économie de plateforme, propose aux entreprises une suite unique de solutions leur permettant de transformer significativement leur e-commerce afin d'accélérer de façon durable et rentable leur croissance. Depuis 2012, Mirakl accompagne les entreprises B2C et B2B avec la technologie la plus avancée, sécurisée et évolutive leur permettant de digitaliser leur activité et d'élargir leur offre via la marketplace ou le dropship, faciliter la gestion des catalogues et des paiements de leurs fournisseurs pour plus d'efficacité, offrir une expérience d'achat personnalisée à leurs clients, et augmenter leurs profits grâce au retail media. Basée à Paris et Boston, Mirakl est certifiée Great Place to Work.
A propos de Mirakl Labs
Nos équipes techniques et produits, nommées Mirakl Labs, sont principalement réparties entre nos 2 hubs situés à Paris et à Bordeaux. Elles collaborent au quotidien afin d'adresser les problématiques de nos clients et utilisateurs en répondant à différents challenges liés aux nouvelles fonctionnalités, à la scalabilité, la sécurité et l’ergonomie…
Elles opèrent en mode agile et s'organisent en Squads composées d'un Squad Lead, de 5 développeurs, d'un Product Manager et d'un QA. Chaque Squad est spécialisée sur un scope fonctionnel afin de concevoir et réaliser de nouvelles features, leurs évolutions et des APIs (avec un découpage en micro-services). Nos équipes Infrastructure, Architecture, Sécurité, Documentation, Product Design, Data et Support opèrent en transverse en apportant leur expertise et de la cohérence sur l’ensemble des produits.
Toutes les équipes sont responsables de leur périmètre et chacun des collaborateurs apporte son expérience et ses idées. Innovation, feedback et implication dans les prises de décision sont au cœur de notre philosophie.
Et pour favoriser ce partage avec d’autres passionnés, nous sommes sponsors, speakers, et hôtes de différents événements, meetups, et associations de la scène Tech en France. Au cours des dernières années, nous avons participé à des événements tels que Devoxx, ReactEurope, ProductConf et Flupa UX Days.
A propos du job
Intégré(e) dans notre équipe Data Science, votre principale mission sera de prototyper, itérer, et mettre en production des algorithmes en collaboration avec les équipes Produit, les Data Engineers et les équipes de développement. Les sujets que vous traiterez auront un vrai impact sur nos clients : l’ambition est d’exploiter au maximum nos données riches et variées afin de développer leur chiffre d'affaires, d’optimiser la gestion opérationnelle de leur marketplace et de garantir la sécurité des utilisateurs et des transactions.
A propos de l’équipe
Get to Know the Data Science Team That Powers the Mirakl Platform
Voici quelques sujets actuels & futurs :
Catégorisation de produits
Mappings de données produit
Extraction de caractéristiques produit à partir du texte et des images
Détection de comportements frauduleux
Estimation de la date de livraison d’une commande
Monitoring de la qualité de service des vendeurs
Recommandations de produits (upsell, cross-sell, retargeting, …)
Personnalisation des résultats de recherche
Personnalisation de l’affichage de contenu
Prédiction de produits tendance
Aide/Suggestion de réponses au customer service
Affichage de produits sponsorisés ou de publicités maximisant le taux de clic
Ce qu’il y a pour vous dans ce job
Implémenter des algorithmes qui auront un impact visible sur plus de 500 sites e-commerce/marketplaces dans 40 pays dont certains une volumétrie très importantes (millions de produits, de clients, de commandes par an)
Des techniques diverses et variées (Heuristiques, Deep Learning, NLP, Image Processing, Time Series, LLM, etc.)
Une vraie autonomie et responsabilité dans les projets dont vous avez l’ownership
La possibilité d'avoir un contrat freelance ou CDI
Notre stack et nos outils
Python, Tensorflow, Keras, Pytorch, Databricks, Spark, Aws (Amazon Redshift, s3, etc.), SQL, Airflow, Delta Lake
Au quotidien
, vous allez :
Analyser, préparer les données, prototyper des algorithmes
Les mettre en production en collaboration avec les Data Engineers et les équipes de développement
Faire des dashboards afin d’illustrer la pertinence des algorithmes et de monitorer la production
Présenter les résultats au weekly data science
Participer aux sessions de brainstorming de l’équipe
Échanger avec les autres équipes pour affiner les cas d’utilisation, l’expérience utilisateur et les modes d’intégration
Vous aimerez ce job si :
Vous avez 4 à 5 ans d'expérience minimum en tant que Data Scientist, avec une expérience significative en machine learning appliqué en entreprise
Vous avez déjà mis en production des algorithmes de Machine Learning
Vous avez une bonne connaissance des algorithmes de Deep Learning (image et/ou texte) et des architectures State-Of-the-Art - par exemple les Transformers
Vous maîtrisez Python, Tensorflow ou/et PyTorch
Vous avez une expérience en développement Spark
Vous êtes pragmatique, data-driven et orienté métier
Vous aimez avoir l’ownership de vos sujets
Vous êtes autonome et avez un très bon esprit d’équipe
Vous avez un esprit positif : respect et bienveillance font partie de vos valeurs
Vous aimez partager votre travail dans le cadre de présentations internes, dans des conférences ou en rédigeant des articles
Petit plus :
Vous avez une expérience en environnement e-commerce et sur des algorithmes de systèmes de recommandations
Mirakl est engagée en faveur de la diversité, de l’égalité des chances et de l’inclusion. Nous célébrons nos différences car nous sommes convaincus que les qualités visibles et invisibles de chaque Mirakl Worker sont une source de force et d’innovation. Dans le cadre de cet engagement, nous étudions toutes les candidatures sans distinction de : genre, ethnicité, religion, orientation sexuelle, handicap, âge ou toute autre caractéristique protégée par la loi.
Show more
Show less","{'ProgLanguage': ['Python', 'Scala', 'R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': ['Spark', 'Databricks'], 'MachingLearning': ['TensorFlow', 'Keras', 'PyTorch'], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': ['AWS'], 'DevTools': ['Git'], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': ['Airflow'], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Machine Learning'], 'FrSoftSkills': ['Collaboration'], 'EnSoftSkils': ['Collaboration']}","{'JobDetail': [], 'TypeContract': ['CDI'], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's', '5', '5', '5']}"
LinkedIn,Ingénieur Data Scientist (H/F) à Grenoble,Sully Group,"Grenoble, Auvergne-Rhône-Alpes, France",https://fr.linkedin.com/jobs/view/ing%C3%A9nieur-data-scientist-h-f-%C3%A0-grenoble-at-sully-group-3905268593?position=2&pageNum=12&refId=%2BSqq7I81JvLhh66Hu4n2TA%3D%3D&trackingId=P8Db1QOy4T6bBQS43vSVsw%3D%3D&trk=public_jobs_jserp-result_search-card,"Au sein d'une équipe de 6 personnes, vous intervenez en mission chez notre client basé à Grenoble comme Data Ingénieur.
Vous participerez à un nouveau projet orienté Intelligence Artificielle appliquée à la mobilité.
Vos missions
Collecter, transformer et nettoyer des données extraites
Création de tableaux de bord
Contribuer à l’effort d’animation technique, de veille technologique et d’innovation
Parlons de vous
Vous possédez une première expérience comme Data Scientist
Vous maitrisez Python
Vous avez l'esprit d'équipe
Show more
Show less","{'ProgLanguage': ['Python', 'R'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': ['Tableau'], 'Statistics': [], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': [], 'FrSoftSkills': [], 'EnSoftSkils': []}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's']}"
LinkedIn,Data Scientist H/F,Davidson consulting,"Nantes, Pays de la Loire, France",https://fr.linkedin.com/jobs/view/data-scientist-h-f-at-davidson-consulting-3913989716?position=3&pageNum=12&refId=%2BSqq7I81JvLhh66Hu4n2TA%3D%3D&trackingId=fpEQDidy%2B3idIFLcxMGygQ%3D%3D&trk=public_jobs_jserp-result_search-card,"Rejoindre Davidson, ce n'est pas seulement intégrer un groupe de 3000 consultants dans 8 pays et 3 continents, c'est intégrer LA société qui a été élue par ses salariés Great Place To Work France et Europe pendant 4 ans ainsi que la plus grande B Corp de France !
Les « B Corp » formant une communauté de sociétés qui ont décidé d'être non pas les meilleures du monde mais les meilleures POUR le monde.
Parce que notre développement repose sur des principes forts :
Un profond respect de l'ensemble de nos parties prenantes : consultants, clients et fournisseurs. Car si le travail ne fait pas le bonheur, il peut cependant faire le malheur. Nous nous engageons donc à écouter, agir avec honnêteté et promouvoir l'équité
Une empreinte environnementale minimale, et sociétale maximale. C'est pourquoi, au-delà des missions que vous réaliserez, vous pourrez également contribuer à des projets que Davidson soutient : missions de solidarité internationale (avec Planète Urgence), accompagnement d'étudiant(e)s issus de milieux peu favorisés (avec Article 1), investissement dans des startups développant des solutions innovantes !
Un Management adhocratique basé sur la mise en oeuvre des principes de l'entreprise horizontale et du management tribal.
Sur ce dernier point une précision d'importance : le bien-être au travail est un luxe qu'il faut pouvoir s'offrir en étant une entreprise solide. Ceci induit pour les davidsonien(ne)s d'allier prises d'initiative, engagement et professionnalisme. Car sans travail, le talent n'est qu'une sale manie. Et cela nous incite à chercher à recruter des éléments meilleurs que nous. Dans une organisation classico-hiérarchique, il peut être bénéfique d'avoir une armée de gens qui travaillent pour vous. Dans une adhocratie, ils causent des dégâts.
Dans le cadre de projets Data Science menés par Davidson pour ses clients dans des secteurs variés (Gaming, Luxe, Télécoms, Finance, etc.), tu interviendras en tant que spécialiste ML & DL. Ta mission consistera à accompagner des experts métiers sur des problématiques variées : traitement du langage naturel, reconnaissance d images, détection de la fraude, système de recommandation, agent conversationnel, etc.
À Ces Fins Tes Missions Consisteront à
Animer des ateliers d expression de besoins
Identifier, intégrer et croiser les sources de données (structurées ou non structurées)
Préparer et analyser des données
Créer, implémenter des mod��les
Prototyper et valider les algorithmes
Mesurer les gains obtenus
Communiquer et capitaliser sur les résultats
Réaliser une veille technologique ainsi que des études d opportunités
Compétences requises ou à acquérir
De formation ingénieur / Bac +5, tu as déjà réussi plusieurs projets dans le domaine de la Data Science. Avec au minimum 2 ans d expérience professionnelle (et c est vraiment un minimum hein)
Des compétences scripting sont nécessaires. Et mieux vaut être fort en maths !
Aptitudes / Savoir-être
Excellent relationnel
Capacité d analyse
Curiosité
Pédagogie
Anglais + SQL / Python bilingue
Show more
Show less","{'ProgLanguage': ['Python', 'R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['ML'], 'FrSoftSkills': ['Organisation'], 'EnSoftSkils': ['Initiative']}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's', '4', '4', '4']}"
LinkedIn,Data Scientist H/F,Davidson consulting,"Rennes, Brittany, France",https://fr.linkedin.com/jobs/view/data-scientist-h-f-at-davidson-consulting-3913988737?position=4&pageNum=12&refId=%2BSqq7I81JvLhh66Hu4n2TA%3D%3D&trackingId=M3VXBM3FYui5MlPlGZtuPQ%3D%3D&trk=public_jobs_jserp-result_search-card,"Rejoindre Davidson, ce n'est pas seulement intégrer un groupe de 3000 consultants dans 8 pays et 3 continents, c'est intégrer LA société qui a été élue par ses salariés Great Place To Work France et Europe pendant 4 ans ainsi que la plus grande B Corp de France !
Les « B Corp » formant une communauté de sociétés qui ont décidé d'être non pas les meilleures du monde mais les meilleures POUR le monde.
Parce que notre développement repose sur des principes forts :
Un profond respect de l'ensemble de nos parties prenantes : consultants, clients et fournisseurs. Car si le travail ne fait pas le bonheur, il peut cependant faire le malheur. Nous nous engageons donc à écouter, agir avec honnêteté et promouvoir l'équité
Une empreinte environnementale minimale, et sociétale maximale. C'est pourquoi, au-delà des missions que vous réaliserez, vous pourrez également contribuer à des projets que Davidson soutient : missions de solidarité internationale (avec Planète Urgence), accompagnement d'étudiant(e)s issus de milieux peu favorisés (avec Article 1), investissement dans des startups développant des solutions innovantes !
Un Management adhocratique basé sur la mise en oeuvre des principes de l'entreprise horizontale et du management tribal.
Sur ce dernier point une précision d'importance : le bien-être au travail est un luxe qu'il faut pouvoir s'offrir en étant une entreprise solide. Ceci induit pour les davidsonien(ne)s d'allier prises d'initiative, engagement et professionnalisme. Car sans travail, le talent n'est qu'une sale manie. Et cela nous incite à chercher à recruter des éléments meilleurs que nous. Dans une organisation classico-hiérarchique, il peut être bénéfique d'avoir une armée de gens qui travaillent pour vous. Dans une adhocratie, ils causent des dégâts.
Dans le cadre de projets Data Science menés par Davidson pour ses clients dans des secteurs variés (Gaming, Luxe, Télécoms, Finance, etc.), tu interviendras en tant que spécialiste ML & DL. Ta mission consistera à accompagner des experts métiers sur des problématiques variées : traitement du langage naturel, reconnaissance d images, détection de la fraude, système de recommandation, agent conversationnel, etc.
À Ces Fins Tes Missions Consisteront à
Animer des ateliers d expression de besoins
Identifier, intégrer et croiser les sources de données (structurées ou non structurées)
Préparer et analyser des données
Créer, implémenter des modèles
Prototyper et valider les algorithmes
Mesurer les gains obtenus
Communiquer et capitaliser sur les résultats
Réaliser une veille technologique ainsi que des études d opportunités
Compétences requises ou à acquérir
De formation ingénieur / Bac +5, tu as déjà réussi plusieurs projets dans le domaine de la Data Science. Avec au minimum 2 ans d expérience professionnelle (et c est vraiment un minimum hein)
Des compétences scripting sont nécessaires. Et mieux vaut être fort en maths !
Aptitudes / Savoir-être
Excellent relationnel
Capacité d analyse
Curiosité
Pédagogie
Anglais + SQL / Python bilingue
Show more
Show less","{'ProgLanguage': ['Python', 'R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['ML'], 'FrSoftSkills': ['Organisation'], 'EnSoftSkils': ['Initiative']}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's', '4', '4', '4']}"
LinkedIn,Data Scientist,Pictarine,"Labège, Occitanie, France",https://fr.linkedin.com/jobs/view/data-scientist-at-pictarine-3911762881?position=5&pageNum=12&refId=%2BSqq7I81JvLhh66Hu4n2TA%3D%3D&trackingId=heHC6icEiO9RWOdGLC%2Bu1g%3D%3D&trk=public_jobs_jserp-result_search-card,"Mission and challenges 🎯
Si tu es passionné par le développement d’outils en transformant des données brutes en informations claires et exploitables, le tout dans une startup en pleine croissance, c'est l'opportunité parfaite pour toi !
Ce sera l’occasion d’utiliser toute ta créativité pour fournir les bons outils aux équipes de Pictarine dans le but d’optimiser la prise de décisions.
Tu rejoindras l’équipe Engineering, composée des pôles dev et data 🤖 ! Tu travailleras en collaboration avec l’équipe tech (les data analyst, les data engineer, etc.), l’équipe produit (les PM, les user researchers, etc.), et bien d’autres équipes.
Ton Rôle Comprendra Les Aspects Suivants
Utiliser des techniques avancées d'analyse de données pour comprendre le comportement des clients, y compris l'analyse des feedbacks clients (NLP) et la segmentation des clients (clusterisation/segmentation)
Identifier les clients VIP et comprendre les facteurs qui contribuent à leur fidélité à Pictarine (rétention, etc.)
Analyser les données transactionnelles et comportementales pour détecter les corrélations entre les variables et identifier les tendances significatives
Développer et mettre en œuvre des modèles prédictifs pour anticiper le comportement d'achat des clients, en distinguant les returning clients des nouveaux clients
Collaborer avec les équipes marketing pour optimiser les campagnes de fidélisation, les programmes de récompenses et les stratégies de tarification en utilisant des analyses de données approfondies
Communiquer efficacement les résultats des analyses complexes aux parties prenantes non techniques et recommander des actions stratégiques basées sur les insights obtenus
Profil Recherché
About you 💎
Tu as au moins 5 ans d’expérience sur un poste de Data Scientist
Tu maîtrises des techniques d'analyse de données avancées, y compris l'apprentissage automatique, la modélisation statistique, l'analyse prédictive et la segmentation
Tu as d’excellentes compétences en programmation, notamment en Python, ainsi qu'une connaissance pratique des outils d'analyse de données (p. ex. pandas, scikit-learn, TensorFlow etc.)
Tu es familier avec le data warehouse suivant : BigQuery
Tu as des connaissances avec un ou plusieurs outils de data visualisation comme Looker Studio, Tableau, Power BI ou Dataiku
Tu es curieux de tester des nouvelles technologies et packages
Tu es doté d’excellentes qualités relationnelles, de communication et de vulgarisation
Tu es un team player et toujours à l'affût de nouvelles idées
Work @ Pictarine✨
Un environnement de travail agile, collaboratif, international et multiculturel
Des perspectives d’évolution rapides
Des locaux tout beaux à Labège avec du matériel dernier cri (mais aussi des snacks à profusion et un frigo à boissons toujours bien rempli)
Un apprentissage permanent : conférence, meet-up, Pictarine Academy, cours d’anglais.
Des events tous les mois : massage, pilates, TGIF, team building .
Un environnement de travail flexible : horaires, politique de remote hybride.
Un package de rémunération attractif : salaire compétitif, RTT, mutuelle& prévoyance 100% prise en charge, intéressement.
Des petits + : Développement de photos gratuit, subvention sport, 3 jours “entraide familiale”, jours de congés en plus avec l'ancienneté...🤫on ne te dévoile pas tout!
Recruitment process
⚙️
Tu souhaites nous rejoindre ? Viens rencontrer les gens avec qui tu vas bosser :
1er échange pour apprendre à se connaître avec Akram ou Marie (15’)
Entretien d’équipe RH/Manager avec Marie et des membres de l'équipe data (60-90’)
Test pratique afin de nous montrer tes talents 🙂 (durée selon test)
Entretien final avec 2 membres du CODIR (120’)
Welcome aboard !
Show more
Show less","{'ProgLanguage': ['Python', 'R', 'Go'], 'DataBase': [], 'DataAnalytics': ['Pandas', 'R'], 'BigData': [], 'MachingLearning': ['Scikit-Learn', 'TensorFlow'], 'DataSerialization': [], 'DataVisualization': ['Tableau', 'Power BI'], 'Statistics': [], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'DBMS': ['BigQuery'], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': [], 'FrSoftSkills': ['Communication', 'Créativité', 'Collaboration'], 'EnSoftSkils': ['Communication', 'Collaboration']}","{'JobDetail': ['Hybride', 'Remote'], 'TypeContract': [], 'Salary': ['100', '100'], 'Level': [], 'Experience': ['a', 'n', 's', '5', '5', '5']}"
LinkedIn,Data Scientist qui sauve des vies,Liberty Rider,"Toulouse, Occitanie, France",https://fr.linkedin.com/jobs/view/data-scientist-qui-sauve-des-vies-at-liberty-rider-3918799919?position=6&pageNum=12&refId=%2BSqq7I81JvLhh66Hu4n2TA%3D%3D&trackingId=EOLgfbCj3r66nVZ3UH4PDA%3D%3D&trk=public_jobs_jserp-result_search-card,"Environnement Technique
Des algorithmes de détection d'accident, de reconnaissance d’activité, de cartographie, ...
Machine learning (apprentissage supervisé, TensorFlow, ONNX)
Traitement du signal (filtrage, FFT, ...)
Des algorithmes temps-réel intégrés à des applications mobiles natives (Kotlin, Swift)
Un environnement d'expérimentation avec Python et NumPy
Des datasets riches, à améliorer constamment
Code reviews, intégration continue, releases automatisées
Tes Missions
Tu rejoindras l’équipe multidisciplinaire en charge des solutions de détection d’accident Liberty Rider.
Ta responsabilité sera l'amélioration de nos algorithmes et de nos datasets : surveillance des performances, investigation des défauts, recherche de solutions et d'innovations, expérimentation itérative, veille sur l'état de l'art, contribution à la stratégie R&D.
Comme nous sommes une petite équipe tu pourras contribuer sur d'autres sujets suivant tes goûts, ton niveau d'expérience, et les priorités du moment : implémentation dans les apps mobiles ou backend, roadmap technique globale, business intelligence...
Profil Recherché
Postule chez Liberty si :
tu as minimum 3 ans d'expérience professionnelle
tu veux avoir un vrai impact sur la vie des gens
tu fais du vélo ou de la moto
tu prends tes décisions en pensant à l’utilisateur final et aux enjeux de ton entreprise
tu aimes communiquer et travailler en équipe
Ce Que Nous T’offrons
un contrat en CDI, dès maintenant, et des tickets restaurant
des bureaux au coeur de Toulouse, du télétravail jusqu'à 80%
un salaire correspondant à ton profil (50-65k€)
Contact : jobs@liberty-rider.com
Show more
Show less","{'ProgLanguage': ['Python', 'R', 'Go', 'Kotlin'], 'DataBase': [], 'DataAnalytics': ['NumPy', 'R'], 'BigData': [], 'MachingLearning': ['TensorFlow'], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Machine Learning'], 'FrSoftSkills': [], 'EnSoftSkils': []}","{'JobDetail': [], 'TypeContract': ['CDI'], 'Salary': ['50'], 'Level': [], 'Experience': ['a', 'n', 's', '3', '3', '3']}"
LinkedIn,Data Scientist,ENGIE Global Energy Management & Sales,"Courbevoie, Île-de-France, France",https://fr.linkedin.com/jobs/view/data-scientist-at-engie-global-energy-management-sales-3779080378?position=7&pageNum=12&refId=%2BSqq7I81JvLhh66Hu4n2TA%3D%3D&trackingId=PIi2wJGsqM9MOwgNgjgAaA%3D%3D&trk=public_jobs_jserp-result_search-card,"About US (GEMS):
ENGIE Global Energy Management & Sales (GEMS) provides energy supply solutions and risk management services to support its clients through their decarbonization journey, while optimizing ENGIE’s assets and contributing to value creation.
ENGIE is a global reference in low-carbon energy and services with a leading energy management business, piloted by its entity ""Global Energy Management & Sales"" who built its savoir-faire managing the Group’s large and diverse asset portfolio over 20+ years.
3,300 employees around the world develop our solutions, through +20 international business platforms. We cover the full energy mix: renewable and thermal power, natural gas & LNG, biomass, environmental products. Our experts provide tailor made solutions based on a wide range of savoir-faire in energy management with a strong focus on decarbonation and decentralization.
Our +120,00 clients span the entire value chain: producers, asset developers, financial players, utilities, distributors and industrials. Our global reach and strong local presence enable us to offer these diverse clients tailor-made services and respond to rapid changes in mature or emerging markets alike.
Our 4 expertises:
Asset management
Energy transition services
Energy supply & global commodities
Risk management & market access
At GEMS we encourage breakthrough results, team spirit, curiosity and innovation while preserving the right work/life balance for you.
More info on GEMS Hub ( https://gems.engie.com ) or LinkedIn ( https://www.linkedin.com/company/engie-global-energy-management-solutions ).
Job Description
As Trading Data Scientist, you will be responsible for:
Designing and implementing new business use cases, going through rotations in the business divisions.
Acting as Data science expert for GEM (tools, methodology)
Ensuring Market intelligence on Data Science topics
Liaising with other Engie Data Science communities and projects
The Trading Data Scientist will be based in the transversal Data team located in Paris and will report to the Chief Data Officer.
Some of the initial use cases may include optimization of trading/hedging strategies, customer flow data and management of full supply contracts
Profile
Strong academic background, ideally from Engineering, Mathematics, Physics or Computing
Experience in a commodity trading environment is a plus
Power and gas markets fundamentals knowledge is a plus
Technical and professional skills
:
Excellent research and analytical skills, with the ability to synthesize analysis into concrete value creation
Excellent quantitative skills
Strong Programming skills: Python, C# is a plus
Data management skills
Team player
Soft skills and competencies
:
Ability to work under pressure in a fast-paced environment
Self-motivated and result driven with a high level of initiative and creative problem solving
Team player
Show more
Show less","{'ProgLanguage': ['Python', 'C#', 'R', 'Go'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': [], 'FrSoftSkills': [], 'EnSoftSkils': ['Problem Solving', 'Initiative']}","{'JobDetail': ['Full'], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's']}"
LinkedIn,Data Scientist - Automotive,Hashlist,Greater Paris Metropolitan Region,https://fr.linkedin.com/jobs/view/data-scientist-automotive-at-hashlist-3851788714?position=8&pageNum=12&refId=%2BSqq7I81JvLhh66Hu4n2TA%3D%3D&trackingId=0X3HUf%2Fn3KYYGjd1Z%2FNN2Q%3D%3D&trk=public_jobs_jserp-result_search-card,"Hashlist is a platform for tech positions & projects within the automotive sector.
We work with some of the largest OEMs, Tier1s, and Ecosystem Players developing for the automotive sector to help them fill on-demand tech talent gaps faster.
Are you ready to be a part of that journey? We are now looking for a Data Scientist in Paris, France.
Responsibilities:
Collect, process, and clean data from various automotive systems and sources, including vehicle telemetry, customer usage patterns, manufacturing processes, and external datasets, to prepare it for analysis.
Perform in-depth data analysis using statistical methods and data analytics tools to identify trends, patterns, and insights that can inform product development, operational improvements, and strategic decision-making.
Develop and maintain dashboards, reports, and visualizations to communicate findings and recommendations to both technical and non-technical stakeholders within Hashlist and its automotive partners.
Collaborate with cross-functional teams to define data analysis requirements and objectives, ensuring that data analysis projects align with business goals and contribute to the enhancement of automotive products and services.
Apply machine learning algorithms and predictive modeling techniques to forecast trends, optimize operations, and enhance vehicle performance and customer experiences.
Ensure data integrity and compliance with data protection regulations and best practices, managing data securely and ethically.
Provide analytical support for ad-hoc queries and projects, contributing to the overall data-driven culture within the organization.
Qualifications:
Bachelor’s or Master’s degree in Data Science, Statistics, Computer Science, or a related field, with a strong emphasis on quantitative analysis.
Proven experience in data analysis, with expertise in using statistical software and programming languages such as Python, R, SQL, or similar tools for data manipulation and analysis.
Strong knowledge of data visualization tools (e.g., Tableau, Power BI, Google Data Studio) and the ability to create impactful reports and dashboards.
Familiarity with machine learning techniques and tools, and experience applying these methods to real-world datasets to solve complex problems.
Excellent analytical and problem-solving skills, with the ability to interpret complex data sets and provide actionable insights.
Next steps:
Press ""Apply""
We will review your application
If qualified, you will be accepted into the network and can be considered for this and similar positions & projects.
Show more
Show less","{'ProgLanguage': ['Python', 'R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': ['Tableau', 'Power BI'], 'Statistics': ['Statistics'], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': ['Teams'], 'Other': ['Machine Learning'], 'FrSoftSkills': [], 'EnSoftSkils': ['Organization']}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's']}"
LinkedIn,Data Scientist F/H,VINCI Construction France,"Chevilly-Larue, Île-de-France, France",https://fr.linkedin.com/jobs/view/data-scientist-f-h-at-vinci-construction-france-3907122405?position=9&pageNum=12&refId=%2BSqq7I81JvLhh66Hu4n2TA%3D%3D&trackingId=c4ss6NnUK7FLuULm%2BXevUA%3D%3D&trk=public_jobs_jserp-result_search-card,"Au sein du Groupe VINCI, leader de la construction et des concessions, employant plus de 280 000 salariés à travers plus de 120 pays, l’équipe Synaps’Up spécialisée dans l’intelligence artificielle poursuit son développement.
L’ambition de cette activité innovante est de décupler la performance de VINCI Construction avec des solutions digitales et IA concrètes. Pour cela Synaps’Up regroupe des profils riches et complémentaires : ingénieurs génie civil, data scientists et développeurs. Tous travaillent ensemble à la création des nouveaux outils de la construction.
Issue de VINCI Construction en France et du programme d’intrapreneuriat de Léonard, la structure dédiée à l’innovation du Groupe VINCI, Synaps’Up vous permettra d’évoluer dans un environnement de type start-up tout en bénéficiant de l’écosystème d’un grand groupe du CAC40.
Description De La Mission
Vous travaillerez sur différents cas d’usage métier en équipe avec des ingénieurs Génie Civil et des développeurs pour mettre en œuvre les outils du futur de l’ingénierie de la construction ! Votre rôle sera de mettre au point et développer les solutions de Machine Learning répondant à des problématiques concrètes.
Pour cela vous travaillerez sur l’ensemble du cycle de vie des solutions :
En amont, vous participerez à l’analyse des besoins métiers et les traduirez sous l’aspect Machine Learning et optimisation
En développement, vous réaliserez les premiers prototypes jusqu’à la mise en œuvre d’une solution fonctionnelle et efficiente
Vous déploierez le modèle, l’industrialiserez et l’améliorerez
Nos solutions réunissent le meilleur des deux mondes de l’IT et de la Construction en mêlant optimisation et data science avec l’ingénierie de la construction. Les thématiques de travail et les technologies sont passionnantes, vous allez vous plaire chez nous !
BAC+5 diplômé d’une école d’ingénieur ou d’une Université en Mathématiques ou en Informatique
Curieux et autonome vous avez déjà une première expérience concluante de développement d’un projet d’optimisation ou de Machine Learning
Solides connaissances théoriques et pratiques des méthodes statistiques et de Machine Learning
Très bonne maîtrise des outils Python de Data-Science (pandas, numpy, scikit-learn, pytorch, tensorflow …)
Maîtrise des outils de développement collaboratifs (git)
Expérience en qualité logicielle, tests unitaires, programmation orientée objet
Une expérience en déploiement de modèles sur un Cloud (Azure ou autre) et en MLOps serait un plus
Pourquoi nous rejoindre ?
Plan épargne entreprise et prime d’intéressement
Equipe jeune, dynamique et surtout extrêmement sympathique !
Télétravail jusqu’à deux jours par semaine
Restaurant d’entreprise
Salle de sport d’entreprise dans les locaux + Piscine à moins de 500m
Show more
Show less","{'ProgLanguage': ['Python', 'R'], 'DataBase': [], 'DataAnalytics': ['Pandas', 'NumPy', 'R'], 'BigData': [], 'MachingLearning': ['Scikit-Learn', 'TensorFlow', 'PyTorch'], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': ['Statistiques'], 'CloudComputing': ['Azure'], 'DevTools': ['Git'], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['ML', 'Machine Learning', 'Statistiques', 'Cloud'], 'FrSoftSkills': [], 'EnSoftSkils': []}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': ['Bac+5'], 'Experience': ['a', 'n', 's']}"
LinkedIn,Senior Data Scientist,Mirakl,"Paris, Île-de-France, France",https://fr.linkedin.com/jobs/view/senior-data-scientist-at-mirakl-3767995717?position=1&pageNum=15&refId=wJnfW9FfV7ATob%2FRARlIng%3D%3D&trackingId=7%2FpbLUYDf14u2LOJaYegEg%3D%3D&trk=public_jobs_jserp-result_search-card,"Mirakl, leader et pionnier de l’économie de plateforme, propose aux entreprises une suite unique de solutions leur permettant de transformer significativement leur e-commerce afin d'accélérer de façon durable et rentable leur croissance. Depuis 2012, Mirakl accompagne les entreprises B2C et B2B avec la technologie la plus avancée, sécurisée et évolutive leur permettant de digitaliser leur activité et d'élargir leur offre via la marketplace ou le dropship, faciliter la gestion des catalogues et des paiements de leurs fournisseurs pour plus d'efficacité, offrir une expérience d'achat personnalisée à leurs clients, et augmenter leurs profits grâce au retail media. Basée à Paris et Boston, Mirakl est certifiée Great Place to Work.
A propos de Mirakl Labs
Nos équipes techniques et produits, nommées Mirakl Labs, sont principalement réparties entre nos 2 hubs situés à Paris et à Bordeaux. Elles collaborent au quotidien afin d'adresser les problématiques de nos clients et utilisateurs en répondant à différents challenges liés aux nouvelles fonctionnalités, à la scalabilité, la sécurité et l’ergonomie…
Elles opèrent en mode agile et s'organisent en Squads composées d'un Squad Lead, de 5 développeurs, d'un Product Manager et d'un QA. Chaque Squad est spécialisée sur un scope fonctionnel afin de concevoir et réaliser de nouvelles features, leurs évolutions et des APIs (avec un découpage en micro-services). Nos équipes Infrastructure, Architecture, Sécurité, Documentation, Product Design, Data et Support opèrent en transverse en apportant leur expertise et de la cohérence sur l’ensemble des produits.
Toutes les équipes sont responsables de leur périmètre et chacun des collaborateurs apporte son expérience et ses idées. Innovation, feedback et implication dans les prises de décision sont au cœur de notre philosophie.
Et pour favoriser ce partage avec d’autres passionnés, nous sommes sponsors, speakers, et hôtes de différents événements, meetups, et associations de la scène Tech en France. Au cours des dernières années, nous avons participé à des événements tels que Devoxx, ReactEurope, ProductConf et Flupa UX Days.
A propos du job
Intégré(e) dans notre équipe Data Science, votre principale mission sera de prototyper, itérer, et mettre en production des algorithmes en collaboration avec les équipes Produit, les Data Engineers et les équipes de développement. Les sujets que vous traiterez auront un vrai impact sur nos clients : l’ambition est d’exploiter au maximum nos données riches et variées afin de développer leur chiffre d'affaires, d’optimiser la gestion opérationnelle de leur marketplace et de garantir la sécurité des utilisateurs et des transactions.
A propos de l’équipe
Get to Know the Data Science Team That Powers the Mirakl Platform
Voici quelques sujets actuels & futurs :
Catégorisation de produits
Mappings de données produit
Extraction de caractéristiques produit à partir du texte et des images
Détection de comportements frauduleux
Estimation de la date de livraison d’une commande
Monitoring de la qualité de service des vendeurs
Recommandations de produits (upsell, cross-sell, retargeting, …)
Personnalisation des résultats de recherche
Personnalisation de l’affichage de contenu
Prédiction de produits tendance
Aide/Suggestion de réponses au customer service
Affichage de produits sponsorisés ou de publicités maximisant le taux de clic
Ce qu’il y a pour vous dans ce job
Implémenter des algorithmes qui auront un impact visible sur plus de 500 sites e-commerce/marketplaces dans 40 pays dont certains une volumétrie très importantes (millions de produits, de clients, de commandes par an)
Des techniques diverses et variées (Heuristiques, Deep Learning, NLP, Image Processing, Time Series, LLM, etc.)
Une vraie autonomie et responsabilité dans les projets dont vous avez l’ownership
La possibilité d'avoir un contrat freelance ou CDI
Notre stack et nos outils
Python, Tensorflow, Keras, Pytorch, Databricks, Spark, Aws (Amazon Redshift, s3, etc.), SQL, Airflow, Delta Lake
Au quotidien
, vous allez :
Analyser, préparer les données, prototyper des algorithmes
Les mettre en production en collaboration avec les Data Engineers et les équipes de développement
Faire des dashboards afin d’illustrer la pertinence des algorithmes et de monitorer la production
Présenter les résultats au weekly data science
Participer aux sessions de brainstorming de l’équipe
Échanger avec les autres équipes pour affiner les cas d’utilisation, l’expérience utilisateur et les modes d’intégration
Vous aimerez ce job si :
Vous avez 4 à 5 ans d'expérience minimum en tant que Data Scientist, avec une expérience significative en machine learning appliqué en entreprise
Vous avez déjà mis en production des algorithmes de Machine Learning
Vous avez une bonne connaissance des algorithmes de Deep Learning (image et/ou texte) et des architectures State-Of-the-Art - par exemple les Transformers
Vous maîtrisez Python, Tensorflow ou/et PyTorch
Vous avez une expérience en développement Spark
Vous êtes pragmatique, data-driven et orienté métier
Vous aimez avoir l’ownership de vos sujets
Vous êtes autonome et avez un très bon esprit d’équipe
Vous avez un esprit positif : respect et bienveillance font partie de vos valeurs
Vous aimez partager votre travail dans le cadre de présentations internes, dans des conférences ou en rédigeant des articles
Petit plus :
Vous avez une expérience en environnement e-commerce et sur des algorithmes de systèmes de recommandations
Mirakl est engagée en faveur de la diversité, de l’égalité des chances et de l’inclusion. Nous célébrons nos différences car nous sommes convaincus que les qualités visibles et invisibles de chaque Mirakl Worker sont une source de force et d’innovation. Dans le cadre de cet engagement, nous étudions toutes les candidatures sans distinction de : genre, ethnicité, religion, orientation sexuelle, handicap, âge ou toute autre caractéristique protégée par la loi.
Show more
Show less","{'ProgLanguage': ['Python', 'Scala', 'R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': ['Spark', 'Databricks'], 'MachingLearning': ['TensorFlow', 'Keras', 'PyTorch'], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': ['AWS'], 'DevTools': ['Git'], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': ['Airflow'], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Machine Learning'], 'FrSoftSkills': ['Collaboration'], 'EnSoftSkils': ['Collaboration']}","{'JobDetail': [], 'TypeContract': ['CDI'], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's', '5', '5', '5']}"
LinkedIn,P&C Data Scientist,JCW Group,"Paris, Île-de-France, France",https://fr.linkedin.com/jobs/view/p-c-data-scientist-at-jcw-group-3916695827?position=2&pageNum=15&refId=wJnfW9FfV7ATob%2FRARlIng%3D%3D&trackingId=aYDJ3zulLJknP7nBXRMY0Q%3D%3D&trk=public_jobs_jserp-result_search-card,"P&C Data Scientist – Paris
1. Purpose
Join a leading insurance company and be at the forefront of innovation as a P&C Data Scientist in Paris. This role combines actuarial expertise with data science to enhance risk assessment and support strategic decision-making through advanced analytics.
2. Key Result Areas and Deliverables:
Develop strong relationships with actuarial teams, underwriters, and stakeholders to drive innovation and leverage data insights.
Utilize statistical models, machine learning, and AI solutions to develop inference and predictive analytics, enhancing pricing strategies.
Analyze and incorporate external data sources to improve data-driven solutions and analytical models.
Enhance data collection, management, and transformation capabilities to support pricing optimization and product innovation.
Transform data into actionable insights, empowering business stakeholders to make informed decisions and drive growth.
3. Key Competencies:
Generic:
Good interpersonal skills
Creativity and curiosity
Attention to detail and analytical mindset
Proactive, flexible, and adaptable
Good communication skills in English and French
Job Specific:
Skilled in Python and SQL
Proficient in data analysis techniques
P&C insurance and Pricing knowledge
Familiarity with Large language Models (LLM)
Familiarity with Big Data technologies like Hadoop, Spark, or Kafka
Experience with R, SAS, and VBA is a plus
Show more
Show less","{'ProgLanguage': ['Python', 'R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': ['Hadoop', 'Spark'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': ['Teams'], 'Other': ['Big Data', 'Machine Learning'], 'FrSoftSkills': ['Communication'], 'EnSoftSkils': ['Communication', 'Creativity', 'Interpersonal Skills']}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's']}"
LinkedIn,Data Scientist - (H/F) - En alternance,OpenClassrooms,"Communay, Auvergne-Rhône-Alpes, France",https://fr.linkedin.com/jobs/view/data-scientist-h-f-en-alternance-at-openclassrooms-3919835926?position=3&pageNum=15&refId=wJnfW9FfV7ATob%2FRARlIng%3D%3D&trackingId=mrCKz5o59QNqdh031pWpNg%3D%3D&trk=public_jobs_jserp-result_search-card,"Description Du Poste
OpenClassrooms recherche un Data Scientist en contrat d’apprentissage pour un de nos partenaires du secteur de l'entreprise, pour préparer une de ses formations diplômantes reconnues par l’État.
Attention : cette offre ne s’adresse qu’aux candidats à l’alternance qui effectuent leur formation avec OpenClassrooms ou souhaitent s’inscrire chez OpenClassrooms pour leur alternance. Seules les candidatures répondant à ces critères seront étudiées. Apprenez un métier d’avenir en alternance avec OpenClassrooms. OpenClassrooms recherche un Data Scientist en contrat d’apprentissage pour un de nos partenaires du secteur de l'entreprise, pour préparer une de ses formations diplômantes reconnues par l’État.
Attention : cette offre ne s’adresse qu’aux candidats à l’alternance qui effectuent leur formation avec OpenClassrooms ou souhaitent s’inscrire chez OpenClassrooms pour leur alternance. Seules les candidatures répondant à ces critères seront étudiées.
Avec OpenClassrooms, vous apprendrez un métier avec une pédagogie mêlant 20% de théorie et 80% de pratique. Résultat : à l’issue de votre formation, vous êtes 100% prêt à l’emploi. Une fois votre diplôme en poche, nos équipes épaulent chaque profil dans la recherche d’un employeur, nous permettant d’afficher un taux d’insertion de nos étudiants en entreprise de plus de 80%. Si votre candidature est retenue, votre scolarité sera entièrement financée par votre employeur.
Vos missions en tant que Data Scientist en alternance :
Participer à l'analyse de données dans le but d'identifier des tendances et de formuler des recommandations pour améliorer les performances de l'entreprise
Contribuer à la création et à l'optimisation de modèles prédictifs pour anticiper les comportements des clients
Participer au développement d'algorithmes d'apprentissage automatique pour optimiser les campagnes de publicité en ligne
Collaborer avec les équipes techniques pour mettre en place des solutions basées sur les données
Poste basé à Paris (Île-de-France). Travail en hybride.
Rythme d’alternance et présence en entreprise Du lundi au vendredi Périodes de travail de 8 heures Repos le week-end Travail en journée
En entreprise : 4 jours par semaine (jours au choix) avec présence réduite à 3 jours 1 à 2 fois par mois
En formation : 1 jour par semaine + 1 jour supplémentaire 1 à 2 fois par mois
Profil recherché
Profil recherché
Formation en Data Science ou dans un domaine connexe
Maîtrise des techniques d'analyse de données et de modélisation statistique
Bonnes compétences en programmation (Python, R, etc.)
Capacité à travailler de manière autonome et en équipe
Bonnes capacités de communication et de présentation
Show more
Show less","{'ProgLanguage': ['Python', 'R', 'Go'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': [], 'FrSoftSkills': ['Communication'], 'EnSoftSkils': ['Communication']}","{'JobDetail': ['Hybride'], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's']}"
LinkedIn,Stage - Data Scientist (H/F),Equancy | Groupe EDG,"Paris, Île-de-France, France",https://fr.linkedin.com/jobs/view/stage-data-scientist-h-f-at-equancy-%C2%A0groupe-edg-3911741622?position=4&pageNum=15&refId=wJnfW9FfV7ATob%2FRARlIng%3D%3D&trackingId=onzFsT3EFkGmF%2BdRl37eMA%3D%3D&trk=public_jobs_jserp-result_search-card,"Equancy
est un cabinet de conseil international, basé à Paris et Dubaï, spécialisé dans la transformation data des entreprises.
Nous planifions, concevons et mettons en œuvre des solutions Big Data, Data Science et Intelligence Artificielle pour nos clients. Nos projets vont de la mise en œuvre d’infrastructures spécialisées dans le traitement de la donnée de nos clients, de lacs de données jusqu’au développement de systèmes opérationnels intégrant des algorithmes de
machine learning
ou de
deep learning
. Nous sommes experts dans l’industrialisation de ces plates-formes, en appliquant les principes du devops à nos infrastructures data.
Nos clients sont de grands groupes français et internationaux (LVMH, Picard, Chanel VINCI, Volkswagen). Ils nous font confiance autant dans l’accompagnement au cadrage de leurs besoins que dans la réalisation des solutions data innovantes
Afin d’accompagner la croissance de son activité, Equancy recherche un Stagiaire Data Scientist Junior (H/F) pour intégrer sa Practice data.
Dans ce cadre :
Vous participez à la compréhension du besoin métier et à la définition de l’approche de data science, encadré par un data scientist senior ou expert : données à utiliser, préparations nécessaires, approche algorithmique et de modélisation, évaluation des performances, optimisation des paramètres, itérations pour améliorer;
Vous réalisez les analyses nécessaires à une bonne prise en charge des données à disposition, contrôlez la cohérence, validez leur lecture;
Vous développez les traitements en Python (essentiellement) pour préparer les données, entraîner et optimiser les modèles de data science (statistiques, machine learning, deep learning), évaluer et valider leur performance;
Le cas échéant, en cas de fortes volumétries, vous travaillez en pyspark;
Vous pourriez avoir à développer des interfaces de visualisation et d’interaction avec les modèles développés (dash);
Vous participez à l’industrialisation (MLOps) des modèles qui sont mis en production et interagissez avec l’équipe de data engineering ; Vous évoluez dans des équipes fonctionnant en méthode Agile;
Vous documentez vos travaux et vos analyses;
Vous participez à la rédaction des restitutions et présentations des travaux réalisés auprès des commanditaires (internes ou clients).
Profil recherché:
De formation Bac+4/5 type Ecole d’ingénieur ou université en Informatique;
Vous maitrisez Python et ses modules de data science (pandas, sklearn, seaborn, dash);
Vous connaissez les techniques de préparation de données, création de features;
Vous connaissez les algorithmes de statistiques, machine learning et deep learning;
Vous vous intéressez particulièrement à l’industrialisation, au passage à l’échelle de modèles de data science, au-delà d’une approche expérimentale de la data science;
Vous avez envie de connaître les environnements cloud (Google Cloud, Amazon Web Services, MS Azure);
Vous aimez travailler en équipe;
Vous êtes réactif, avec le sens du service, vous justifiez de bonnes capacités d’écoute, d’un bon relationnel et d’une bonne gestion du stress;
Vous êtes curieux, autonome et proactif.
Equancy c'est aussi :
Un cadre de travail :
· Superbes locaux au cœur de Paris : Espace WeWork Jules Lefebvre, à coté de Saint Lazare, au sein d’un bâtiment historique, avec de grands espaces et vue panoramique sur tout Paris;
· Equilibre vie pro / vie perso;
· Une politique de télétravail de deux jours par semaine;
· Équipement pour travailler en remote + participation aux frais du télétravail (allocation mensuelle);
· Engagement environnemental;
· Des activités sportives proposées
· Une conciergerie proposée par We Work.
Environnement de travail stimulant, proximité forte avec les directeurs et les associés ;
Équipe dynamique, passionnée et internationale.
L’aventure vous tente ? Écrivez-nous !
Show more
Show less","{'ProgLanguage': ['Python', 'R', 'Go'], 'DataBase': [], 'DataAnalytics': ['Pandas', 'R'], 'BigData': ['Spark'], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': ['Seaborn'], 'Statistics': ['Statistiques'], 'CloudComputing': ['Azure'], 'DevTools': [], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['DevOps', 'Big Data', 'ML', 'Machine Learning', 'Statistiques', 'Cloud'], 'FrSoftSkills': ['Gestion du stress'], 'EnSoftSkils': []}","{'JobDetail': ['Remote', 'Junior', 'Senior'], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's']}"
LinkedIn,Data Scientist H/F,Assystem,"Courbevoie, Île-de-France, France",https://fr.linkedin.com/jobs/view/data-scientist-h-f-at-assystem-3902418016?position=5&pageNum=15&refId=wJnfW9FfV7ATob%2FRARlIng%3D%3D&trackingId=x5Iy%2BU0dhO1MrRGqlnQGDw%3D%3D&trk=public_jobs_jserp-result_search-card,"Trouver des solutions au dérèglement climatique est la priorité du 21ème siècle, et implique de switcher à
l’énergie bas-carbone
. Chez Assystem, on s’est donc donné pour mission
d’accélérer la transition énergétique
partout dans le monde. Et pour y parvenir,
nos 7000 Switchers
couplent leur expertise historique en
ingénierie et en management de projet
aux
technologies digitales
.
Présent dans 12 pays (Europe, Moyen-Orient, Asie), nous travaillons sur la
production et la distribution d'électricité bas-carbone
, à travers le
développement des énergies nucléaires
et
renouvelables
. Nous participons également à la
modernisation des réseaux électriques
et
l'électrification des usages
, à travers
l'hydrogène
pour décarboner les secteurs des transports et de l'industrie.
Description du poste
Votre Futur Equipe
Rejoignez l'équipe d'Alexandre et apportez votre expertise en tant que
Data Scientist (H/F)
pour contribuer activement à nos projets innovants dans le domaine du réseau électrique. Nous recherchons un(e) professionnel(le) passionné(e) et expérimenté(e) capable de créer et d'implémenter des algorithmes avancés pour optimiser nos opérations.
Mission :
En tant que Data Scientist (H/F), votre rôle sera crucial dans
le développement et l'optimisation de nos solutions data pour le réseau électrique.
Vous serez responsable de la
création d'algorithmes, de l'analyse de données et de la modélisation mathématique pour améliorer nos processus et nos décisions
.
Responsabilités principales :
Conception et développement d'algorithmes
avancés pour optimiser la conception et la régulation
du réseau électrique
.
Création d'une ontologie universelle
pour faciliter la recherche rapide des exigences de conception spécifiques aux différents pays.
Élaboration d'un cadre réglementaire de référence
pour identifier les régulations applicables dans les pays étrangers.
Analyse de conformité des designs originaux ou adaptés aux normes locales ou internationales du réseau électrique
.
Développement et mise en œuvre d'une application de sélection de sites pour les énergies renouvelables basée sur des facteurs géographiques et une cartographie binaire avec GIS.
Optimisation de la sélection des sites pour établir des installations hybrides à coût réduit en utilisant la modélisation déterministe et l'analyse du réseau.
Automatisation de l'analyse du réseau en utilisant Digsilent Powerfactory
et des scripts
Python
pour l'exécution parallèle des fonctions de calcul et les évaluations d'impact.
Pourquoi rejoindre la communauté des Switchers ?
Rejoignez la
communauté des Switchers
et faites partie d'une aventure digitale passionnante au cœur de
l'industrie nucléaire
!
💪 Plus de 55 ans d’expérience dans le nucléaire et positionné dans le top 3 des plus grandes entreprises d’ingénierie nucléaire.
🚀 Participer à des projets stimulants avec un véritableimpactsociétal.
📈 De nombreuses opportunités de carrière avec 70% de nos managers issus de la promotion interne.
Qualifications
Expérience significative de minimum 4 ansen tant que
Data Scientist,
idéalement dans le
domaine du réseau électrique ou secteur similaire
.
Maîtrise des modèles mathématiques
et capacité à les appliquer aux problématiques du réseau électrique.
Connaissance approfondie des entrepôts de données et maîtrise du requêtage.
Sensibilisation aux enjeux de la transition énergétique
et intérêt pour les énergies renouvelables.
Notions avancées en électrotechnique et connaissance des réseaux électriques.
Compétences en programmation avec Python
et
familiarité avec Digsilent Powerfactory.
Capacité à travailler en équipe, autonomie et rigueur.
Informations supplémentaires
Nous nous engageons au respect de l’égalité de traitement entre les candidats, et célébrons toutes les formes de diversité. Chez Assystem, seules les compétences comptent!Si vous souhaitez porter à la connaissance d’Assystem une quelconque situation ou des besoins spécifiques, n’hésitez pas vous serez accompagné(e)!
Show more
Show less","{'ProgLanguage': ['Python', 'R', 'Go'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git'], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': [], 'FrSoftSkills': [], 'EnSoftSkils': []}","{'JobDetail': ['Hybride'], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's', '55', '55', '55']}"
LinkedIn,Alternance – Data Scientist,METEOJOB by CleverConnect,"Aubervilliers, Île-de-France, France",https://fr.linkedin.com/jobs/view/alternance-%E2%80%93-data-scientist-at-meteojob-by-cleverconnect-3898720601?position=6&pageNum=15&refId=wJnfW9FfV7ATob%2FRARlIng%3D%3D&trackingId=vVffsTO1ZpX5Qw24My8nQw%3D%3D&trk=public_jobs_jserp-result_search-card,"Entreprise
MAKING THE WORLD A BETTER HOME
, faire du monde une maison commune, c'est la raison pour laquelle nous existons et c'est notre cap commun.
Présent dans 75 pays, Saint-Gobain est le leader mondial de la construction durable.
Notre métier ?
Nous concevons, produisons et distribuons des matériaux et des services pour les marchés de l'habitat et de l'industrie.
Nos solutions ?
Elles se trouvent partout dans notre vie quotidienne - bâtiments, transports, infrastructures - et apportent confort et durabilité.
Notre ambition ?
Où que vous soyez, laissez votre personnalité briller et nos valeurs vous guider chaque jour pour inventer un monde plus durable.
Saint-Gobain Glass conçoit, produit et distribue des matériaux et services pour les marchés de l'habitat et de l'industrie. Mus par une volonté permanente d'adapter nos produits verriers aux besoins et aux réalités actuels, nous innovons sans cesse. Nous développons ainsi des solutions intégrées pour la rénovation des bâtiments publics et privés, la construction légère. Par l'innovation, nous avons également à cœur de participer à la décarbonation du monde de la construction et de l'industrie avec des produits apportant durabilité et performance.
En France, Saint-Gobain Glass produit, transforme le verre plat et distribue des solutions verrières répondant à un large spectre d'applications pour l'habitat résidentiel et tertiaire.
En intégrant Saint-Gobain Glass France, vous rejoindrez la Direction Technologie et Performance Industrielle (DTI) établie à Aubervilliers, où vous serez au cœur des initiatives stratégiques pour optimiser les performances industrielles et environnementales.
Les missions principales de la DTI sont d'assurer un accompagnement des pays et métiers du Groupe sur les activités suivantes: feuilles de route industrielles (standards, benchmark, performance, énergie, CO2, savings, …), programmes R&D pour les métiers de la Construction, Investissements et Achats stratégiques, Allocation de capacité entre les pays et Programmes d'excellence opérationnelle avec les savings associés (World Class Manufacturing, World Class Supply Chain, 4.0, Applications digitales pour l'Industrie, …).
Description Du Poste
La Direction Technique Internationale est à la recherche d'un(e) alternant(e) - Data science.
Notre futur(e) alternant(e) collaborera avec les experts de divers domaines pour répondre à leurs besoins d'analyse et contribuera activement au développement du pôle ""Data Science"" chez Saint-Gobain Glass.
Il ou elle sera rattaché(e) à notre Ingénieurs Data Scientist
Les Missions Principales Incluront
Effectuer des analyses descriptives des données, telles que le Datamining, les Corrélations et les Segmentations.
Identifier et collecter les différentes données provenant des sources internes ou externes nécessaires aux études.
Manipuler et nettoyer de grandes quantités de données.
Mettre en place des algorithmes de prédiction, tels que la Régression, la Classification ou le Deep Learning.
Collaborer étroitement avec des experts techniques et des professionnels du domaine pour interpréter les résultats obtenus.
Créer des rapports et des tableaux de bord présentant divers indicateurs de performance, en utilisant des outils de business intelligence.
Formation
Description du profil :
Nous recherchons des candidat(e)s ayant un niveau d'expérience correspondant à un Master 1-2, issu(e)s d'une école d'ingénieur.
Compétences Techniques
Une maîtrise de Miscrosoft 365 est indispensable.
Capacité à effectuer des analyses de données sur R et/ou Python.
La maîtrise d'un outil de Business Intelligence est un atout.
Maîtrise du Français et de l'Anglais.
Compétences Relationnelles Et Qualités Requises
Un fort intérêt pour l'analyse de données.
Dynamisme et sens du service client.
Capacité à travailler de manière autonome et avec rigueur.
Ouverture d'esprit et curiosité.
Un intérêt marqué pour le secteur industriel et les nouvelles technologies.
Exigences Du Poste
Environnement multinational et multilingue.
Localisation à Aubervilliers
Cette offre est accessible à tous les talents ! Saint-Gobain s'engage quotidiennement pour l'égalité des chances. Nous apportons une attention particulière à l'inclusion et la diversité, https://www.saint-gobain.com/fr/news/agir-durablement
La culture Trust Empowerment and Collaboration (TEC) est le socle sur lequel se structure nos actions diversité et inclusion.
Show more
Show less","{'ProgLanguage': ['Python', 'R', ' R ', 'Go'], 'DataBase': [], 'DataAnalytics': ['R', ' R '], 'BigData': [], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': ['Tableau'], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git'], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': [], 'FrSoftSkills': ['Collaboration'], 'EnSoftSkils': ['Collaboration', 'Initiative']}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's']}"
LinkedIn,STAGE - Data Scientist (H/F),CHANEL,"Paris, Île-de-France, France",https://fr.linkedin.com/jobs/view/stage-data-scientist-h-f-at-chanel-3904548050?position=7&pageNum=15&refId=wJnfW9FfV7ATob%2FRARlIng%3D%3D&trackingId=Od8%2FZJ%2FBc19WHuPR%2BV2XhA%3D%3D&trk=public_jobs_jserp-result_search-card,"A propos du poste
La « Business Services Platform » se positionne en conseil interne, partenaire de tous nos départements fonctionnels, aux différents niveaux de l’organisation européenne : corporate, région, marchés et boutiques.
Elle se décompose en trois finalités opérationnelles complémentaires
Notre mission D&A, « Data Science & Advanced Analytics » est de définir et réaliser des cas d’usage pragmatiques et concrets via une approche projet itérative et courte.
En très forte collaboration avec les acteurs opérationnels, doté d’une expertise mathématique adaptée à nos besoins spécifiques, nous produisons du business consulting, des modèles mathématiques et algorithmiques performants et opérants.
En très forte collaboration avec les acteurs IT, nous construisons au fil des cas d’usage, nos plateformes européennes de donnée et d’algorithme, normalisées, industrialisées, orientées business et services.
Stage de 6 mois à pourvoir dès que possible.
Votre impact chez CHANEL
Dans une approche itérative, progressive et coconstruite avec l’expert opérationnel et les acteurs IT data-ops / dev-ops. Avec un temps de production court : 1 à 3 mois par cas d’usage, depuis la définition détaillée du besoin réel jusqu’au modèle opérant en production.
Dans une élaboration progressive, fonctionnelle et cohérente de la plateforme cible de données et d’algorithmes « as a service », vous serez un appui au service sur les sujets suivants :
Préparer et participer aux ateliers de définition détaillée, dans une approche produit / process cible, et couplée consulting métier / analyse exploratoire statistique de la donnée.
Produire les livrables formels et synthétiques de conception détaillée.
Aligner et modéliser la solution mathématique et algorithmique, dans le respect de nos normes internes (scripts, framework de packages, performance, exposition / -visualisation) et de la contrainte itérative.
Tester avec l’expert opérationnel : former et valider la solution de calcul avancé, sa restitution et son monitoring opérationnel.
Transmettre à l’IT les éléments et le support nécessaires d’industrialisation (mode batch - pipeline ou modèle conteneurisé).
Documenter et garantir l’auditabilité des modèles produits.
Contribuer au pilotage du projet : tenue des échéances, anticipation des risques, mise en production
Exemples de cas d’usage potentiels pendant le stage : optimisation de la distribution et de la répartition des stocks dans le réseau retail, optimisation de la planification des boutiques, prévisions commerciales, financières, des effectifs…
Ce que vous apporterez
Diplômé d’une école d’ingénieur, option mathématiques appliquées / data science
Expérience accomplie, avec des cas d’usage opérationnels et en production, sur des sujets de :
Séries temporelles
Modèles d’optimisation
Modèles de régression et de classification (machine & deep learning)
Maîtrise des frameworks classiques d’analyse statistique et de modélisation ; e.g. en Python :
numpy, pandas, matplotlib, statsmodel…
pmdarima, scikit-learn, scipy, tensorflow / keras, pytorch…
Maitrise du langage Python
Premier stage accompli de définition / validation du besoin métier, en approche couplée « business consulting » & analyse exploratoire et statistique des données. Si possible dans les fonctions finance et opérations.
Culture et savoir-faire en mode projet piloté de bout en bout, en double interface métier et IT
Curiosité, vivacité et agilité d’esprit
Influenceur, prescripteur et fort esprit de collaboration
Sens du résultat et du service au client, pédagogie opérationnelle
Anglais
Ce que CHANEL peut vous offrir
Chez CHANEL, nous nous attachons à créer une culture inclusive qui favorise l'épanouissement et le développement personnel tout en contribuant à la performance collective. Nous avons la conviction que la singularité de chaque personne contribue à renforcer la diversité, la complémentarité et l'efficacité de nos équipes. Nous encourageons vivement votre candidature, car nous accordons une grande importance à l'expérience et au potentiel que vous pourriez apporter à la Maison CHANEL.
Show more
Show less","{'ProgLanguage': ['Python', 'R', 'Go'], 'DataBase': [], 'DataAnalytics': ['Pandas', 'NumPy', 'R'], 'BigData': [], 'MachingLearning': ['Scikit-Learn', 'TensorFlow', 'Keras', 'PyTorch'], 'DataSerialization': [], 'DataVisualization': ['Matplotlib'], 'Statistics': [], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': [], 'FrSoftSkills': ['Collaboration', 'Organisation'], 'EnSoftSkils': ['Collaboration']}","{'JobDetail': [], 'TypeContract': [], 'Salary': ['Package'], 'Level': [], 'Experience': ['a', 'n', 's']}"
LinkedIn,"Data Scientist Traitement du Langage Naturel F/H - Système, réseaux, données (H/F)",Acelys Services Numériques,"Montpellier, Occitanie, France",https://fr.linkedin.com/jobs/view/data-scientist-traitement-du-langage-naturel-f-h-syst%C3%A8me-r%C3%A9seaux-donn%C3%A9es-h-f-at-acelys-services-num%C3%A9riques-3908665280?position=8&pageNum=15&refId=wJnfW9FfV7ATob%2FRARlIng%3D%3D&trackingId=T%2Fzawx6R49aHcZgK3juWmg%3D%3D&trk=public_jobs_jserp-result_search-card,"Cette offre d’emploi est fournie par Pôle emploi
Description
Descriptif du poste: Acelys recherche un.e Data Scientist expérimenté en IA et NLP pour rejoindre notre équipe dynamique au sein du pôle de R&D/IA d'une quinzaine de talents. Notre pôle R&D, expert dans le traitement du langage naturel (pôle Edition) mène depuis 10 ans des travaux en étroite collaboration avec des laboratoires de recherche sur des problématiques technologiques. Vous travaillerez en lien avec les chercheurs, ingénieurs et autres experts en utilisant des techniques d'apprentissage automatique et de traitement du langage naturel pour résoudre des problèmes complexes, tels que la recherche documentaire, la similarité sémantique, la classification... Profil recherché: - Vous êtes diplômé.e en informatique, en sciences des données ou dans un domaine connexe - Vous disposez de solides compétences en programmation (Python, TensorFlow, PyTorch, etc.) - Vous avez connaissance des techniques d'apprentissage automatique et du traitement automatique du langage naturel - Vous êtes expérimenté.e sur les pratiques CI/CD (intégration continue et déploiement continu) - Une expérience sur les Frameworks Python est appréciée : Langchain, Django/Flask,Transformers
PROFIL SOUHAITÉ
Expérience
Expérience exigée de 2 An(s)
Source: Pole emploi (https://www.pole-emploi.fr)
Show more
Show less","{'ProgLanguage': ['Python', 'R', 'Go'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': ['TensorFlow', 'PyTorch'], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['CI/CD'], 'FrSoftSkills': ['Collaboration'], 'EnSoftSkils': ['Collaboration']}","{'JobDetail': [], 'TypeContract': [], 'Salary': [], 'Level': [], 'Experience': ['a', 'n', 's', '10', '10', '10']}"
LinkedIn,"Lead Data Scientist – Bordeaux, France (H/F)",Astek,"Bordeaux, Nouvelle-Aquitaine, France",https://fr.linkedin.com/jobs/view/lead-data-scientist-%E2%80%93-bordeaux-france-h-f-at-astek-3882495203?position=9&pageNum=15&refId=wJnfW9FfV7ATob%2FRARlIng%3D%3D&trackingId=pL7LwHO8%2FzWbGzzjk%2BP3iw%3D%3D&trk=public_jobs_jserp-result_search-card,"CDI
Bordeaux - France
Publiée il y a 1 mois
Le Groupe Astek
Ce Que Nous Allons Accomplir Ensemble :
Afin d’accélérer la transformation IA de nos clients, la Division Consulting IA Astek vous propose d’integrer ses équipe en qualité de data scientist senior pour travailler sur le prototypage et la construction de solutions d’IA en étroite collaboration avec nos partenaires.
La Division Consulting IA a pour mission d’accélérer le développement de modèles et d’applications d’IA en itérant en étroite collaboration nos
équipes R&D internes et nos clients. Le projet nécessite à la fois des compétences techniques avancées, des aptitudes d’analyse et des compétences en communication.
Vous etes intéressé par l’innovation en IA et disposez d’une forte compétence technique et appréciez de travailler avec des équipes de
différentes fonctions? N’attendez plus, rejoignez nous.
Votre Mission, Si Vous L’acceptez :
Piloter les projets d’IA, proposer des solutions stratégiques et exposer les résultats aux dirigeants et aux partenaires commerciaux, tout en encadrant les scientifiques des données pour garantir la qualité de la livraison.
Participer à la transformation de l’IA dans l’entreprise, avec pour objectif de créer une valeur réelle et mesurable pour le Groupe.
Faciliter les projets en apportant des modèles, des pipelines de traitement de données, des analyses ou des modélisations de problèmes.
Contribuer aux activités de R&D en IA, notamment dans le cadre de nos partenariats avec Microsoft.
Accompagner nos clients dans la définition de leurs priorité et schémas directeurs.
Vous ?
Formation : Bac+5 ou doctorat issu d’une grande école d’ingénieurs ou d’université ; spécialisation en mathématiques, statistiques ou informatique.
Expérience : Entre 2 et 8 ans en tant que data scientist ou dans un poste comparable.
Compétences : Excellentes compétences en modélisation mathématique et en résolution de problèmes, avec une bonne maîtrise des statistiques, du machine learning et du deep learning ; La NLP est un atout.
Autonomie et adaptabilité ; Capacité à synthétiser et à communiquer efficacement.
Stack technique : Maîtrise de Python, SQL, Spark, avec une compétence supplémentaire dans le déploiement de modèles (Airflow, Gitlab, Docker) et/ou le deep learning (pyTorch, cuda).
Le Groupe Astek
Créé en France en 1988, Astek est un acteur mondial de l’ingénierie et du conseil en technologies. Fort de son expertise dans de nombreux secteurs industriels et tertiaires, Astek accompagne ses clients internationaux dans le déploiement intelligent de leurs produits et de leurs services, et dans la mise en œuvre de leur transformation digitale.
Depuis sa création, le Groupe a fondé son développement sur une forte culture d’entrepreneuriat et d’innovation, et sur l’accompagnement et la montée en compétence de
ses 7800 collaborateurs
qui s’engagent chaque jour à promouvoir la complémentarité entre les technologies numériques et l’ingénierie des systèmes complexes.
Rejoignez un Groupe en fort développement en France et à travers le monde ayant réalisé un chiffre d’affaires de 600 M€ en 2023.
Tous les détails sur le Groupe sur le site https://astekgroup.fr. Et vous pouvez aussi nous suivre sur notre blog : https://blog.groupeastek.com.
Rencontrons-nous
Notre projet commun vous plait ?
Postulez à cette annonce, et soyez transparent !
Notre Talent Acquisition Officer, vous contactera pour un premier échange téléphonique.
Puis vous rencontrerez votre futur manager, avec lequel vous échangerez autour d’Astek, de votre parcours, de vos attentes et de votre future mission .
Enfin, vous rencontrerez notre Directeur de département, avec lequel vous pourrez valider votre intérêt et adéquation pour le poste et finaliser les éléments contractuels.
Nos Plus
Astek est green et fait bénéficier ses salariés d’une indemnité kilométrique vélo
Une politique CARE sur-mesure déployée par nos équipes RH pour nos collaborateurs (https://astekgroup.fr/engagements)
Notre charte de la Diversité
Bienvenue dans la team ! Allez-y, maintenant c’est à vous de jouer !
Caractéristiques de l'emploi
Catégorie Ingénieur
Job Industry Aérospatial / Défense / Sécurité, Distribution / Services Internet, Energie / Sciences de la Vie / Autres industries, Finance / Gouvernement, Télécom / Média, Transports Terrestres
Postuler en ligne
Nom *
Prénom *
Email *
Un email valide est requis.
Téléphone *
Un numéro de téléphone valide est requis.
Joindre un CV *
Votre Mission, Si Vous L’acceptez :
Piloter les projets d’IA, proposer des solutions stratégiques et exposer les résultats aux dirigeants et aux partenaires commerciaux, tout en encadrant les scientifiques des données pour garantir la qualité de la livraison.
Participer à la transformation de l’IA dans l’entreprise, avec pour objectif de créer une valeur réelle et mesurable pour le Groupe.
Faciliter les projets en apportant des modèles, des pipelines de traitement de données, des analyses ou des modélisations de problèmes.
Contribuer aux activités de R&D en IA, notamment dans le cadre de nos partenariats avec Microsoft.
Accompagner nos clients dans la définition de leurs priorité et schémas directeurs.
Vous ?
Formation : Bac+5 ou doctorat issu d’une grande école d’ingénieurs ou d’université ; spécialisation en mathématiques, statistiques ou informatique.
Expérience : Entre 2 et 8 ans en tant que data scientist ou dans un poste comparable.
Compétences : Excellentes compétences en modélisation mathématique et en résolution de problèmes, avec une bonne maîtrise des statistiques, du machine learning et du deep learning ; La NLP est un atout.
Autonomie et adaptabilité ; Capacité à synthétiser et à communiquer efficacement.
Stack technique : Maîtrise de Python, SQL, Spark, avec une compétence supplémentaire dans le déploiement de modèles (Airflow, Gitlab, Docker) et/ou le deep learning (pyTorch, cuda).
Le Groupe Astek
Créé en France en 1988, Astek est un acteur mondial de l’ingénierie et du conseil en technologies. Fort de son expertise dans de nombreux secteurs industriels et tertiaires, Astek accompagne ses clients internationaux dans le déploiement intelligent de leurs produits et de leurs services, et dans la mise en œuvre de leur transformation digitale.
Depuis sa création, le Groupe a fondé son développement sur une forte culture d’entrepreneuriat et d’innovation, et sur l’accompagnement et la montée en compétence de
ses 7800 collaborateurs
qui s’engagent chaque jour à promouvoir la complémentarité entre les technologies numériques et l’ingénierie des systèmes complexes.
Rejoignez un Groupe en fort développement en France et à travers le monde ayant réalisé un chiffre d’affaires de 600 M€ en 2023.
Tous les détails sur le Groupe sur le site https://astekgroup.fr. Et vous pouvez aussi nous suivre sur notre blog : https://blog.groupeastek.com.
Rencontrons-nous
Notre projet commun vous plait ?
Postulez à cette annonce, et soyez transparent !
Notre Talent Acquisition Officer, vous contactera pour un premier échange téléphonique.
Puis vous rencontrerez votre futur manager, avec lequel vous échangerez autour d’Astek, de votre parcours, de vos attentes et de votre future mission .
Enfin, vous rencontrerez notre Directeur de département, avec lequel vous pourrez valider votre intérêt et adéquation pour le poste et finaliser les éléments contractuels.
Nos Plus
Astek est green et fait bénéficier ses salariés d’une indemnité kilométrique vélo
Une politique CARE sur-mesure déployée par nos équipes RH pour nos collaborateurs (https://astekgroup.fr/engagements)
Notre charte de la Diversité
Bienvenue dans la team ! Allez-y, maintenant c’est à vous de jouer !
Show more
Show less","{'ProgLanguage': ['Python', 'R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': ['Spark'], 'MachingLearning': ['PyTorch'], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': ['Statistiques'], 'CloudComputing': [], 'DevTools': ['Git', 'Docker'], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': ['Airflow'], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': ['Docker'], 'Collaboration': [], 'Other': ['Machine Learning', 'Statistiques'], 'FrSoftSkills': ['Communication', 'Adaptabilité', 'Résolution de problèmes', 'Collaboration'], 'EnSoftSkils': ['Communication', 'Collaboration']}","{'JobDetail': ['Senior'], 'TypeContract': ['CDI'], 'Salary': [], 'Level': ['Bac+5'], 'Experience': ['a', 'n', 's', '8', '8', '8']}"
LinkedIn,Data Scientist (CDI),LesJeudis,"Le Havre, Normandy, France",https://fr.linkedin.com/jobs/view/data-scientist-cdi-at-lesjeudis-3909984113?position=10&pageNum=15&refId=wJnfW9FfV7ATob%2FRARlIng%3D%3D&trackingId=mj1%2F5hu2Z0sN3fqfzwLf9A%3D%3D&trk=public_jobs_jserp-result_search-card,"Data Scientist H/F (CDI).
Mode de travail : hybride, 2 à 3 jours de présentiel.
Localisation : le Havre (76).
Profil : intermédiaire à confirmé.
Fourchette de salaire : 35k€ à 55k€ en fonction du profil et de l’expérience.
Date de démarrage : à partir de mai, si vous avez un préavis nous pouvons vous attendre.
L’
IT
chez ARTEMYS AGIL-IT combine
la technologie
et
l’humain
! Nous sommes convaincus que les compétences, le savoir-être et l’épanouissement de nos Talents sont les
clés de notre réussite
. Avant tout, nous recherchons chez
ARTEMYS AGIL-IT
des
personnalITés passionnées.
Alors, vous nous rejoignez ?!
Nous recherchons un.e Data Scientist talentueux.se pour rejoindre l’équipe dynamique de notre client. Dans ce rôle hybride, vous aurez l’opportunité de travailler sur un projet vitrine passionnant, impliquant la mise en place d’un kiosque data.
Les Missions
Concevoir, développer et mettre en œuvre des modèles de machine learning et des algorithmes d'analyse de données pour répondre aux besoins du projet.
Analyser et interpréter les données pour fournir des insights pertinents et des recommandations stratégiques.
Participer activement à l'amélioration continue des processus et des méthodologies liés à l'analyse de données.
Vous êtes titulaire d’un diplôme universitaire en informatique, statistiques, mathématiques appliquées ou domaine connexe.
Vous avez une
expérience
démontrée dans le développement et le déploiement de modèles de machine learning.
Vous
maîtrisez
des outils et des langages de programmation couramment utilisés en Data Science (Python, SQL…).
Votre esprit analytique et votre capacité à communiquer efficacement avec les parties prenantes ne sont plus à prouver.
Les Attendus Concernant Le Savoir-être
Autonomie, créativité et capacité à travailler dans un environnement collaboratif.
Vous avez un
super
état d’esprit
et êtes
ultra motivé.e
…
Vous vous reconnaissez ?
Alors, vous êtes fait.e pour nous rejoindre !
Vous êtes toujours là ? Top ! Voici ce qui vous attend :
Un premier échangepour faire connaissance
Un entretien RH avec Mathilde
Un entretien techniqueavec votre futur manager
Une proposition salariale
Alors, ça vous tente ?
C’est parti !
Bienvenue dans l’aventure ARTEMYS AGIL-IT
Show more
Show less","{'ProgLanguage': ['Python', 'R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataSerialization': [], 'DataVisualization': [], 'Statistics': ['Statistiques'], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'DBMS': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': [], 'Other': ['Machine Learning', 'Statistiques'], 'FrSoftSkills': ['Créativité'], 'EnSoftSkils': []}","{'JobDetail': ['Hybride', 'Confirmé'], 'TypeContract': ['CDI'], 'Salary': ['35k'], 'Level': [], 'Experience': ['a', 'n', 's']}"
