[
    {
        "source": "LinkedIn",
        "title": "Cloud Engineer",
        "company": "A2MAC1 - Decode the future",
        "location": "Boulogne-Billancourt, \u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/cloud-engineer-at-a2mac1-decode-the-future-3838857174?position=2&pageNum=0&refId=NuDbZkBPOnBALTaaBOYlpw%3D%3D&trackingId=BLMdFgmB%2FuSr15l9YXXUMg%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Under the direction of the IT Operations Manager, design & implement information systems architectures and evolutions for cloud environments.\nHe/she proposes a solution that meets the needs, evolutions and strategy of the company in terms of computer systems.\nIt defines and ensures the application of policies and good practices.\nTask and Activities :\nDesign, deploy, and manage cloud infrastructure and services using Azure technologies and best practices\nEnsure build/run of our cloud infrastructure in a devops method\nEnsure the application of A2MAC1 standards, processes, and IT policies\nMonitor and optimize cloud resources, costs, and performance using Azure tools and metrics\nApply and enforce security policy\nDefines and enforces the governance of our cloud solutions\nParticipate in IT infrastructure evolution projects, and take charge of the architecture\nEnsures the maintenance and evolution of technical architectures\nImplement and enforce cloud security policies and standards using Azure security features and services\nTroubleshoot and resolve cloud-related issues and incidents using Azure diagnostics and support tools\nCollaborate with other IT teams and stakeholders to ensure alignment and integration of cloud solutions and services, be the referent/contact point for cloud topics\nStay updated with the latest trends and developments in cloud technologies and Azure offerings\nRequirements\nProfessional Skills Required :\nProficient in Azure core services, such as Compute, Storage, Networking, Security, Identity, and Management\nFamiliar with Azure DevOps, PowerShell, CLI, and other scripting and automation tools\nKnowledge of cloud architecture patterns, principles, and best practices\nExcellent communication, collaboration, and problem-solving skills\n\"Team Player\" attitude\nCapacity to work with an agile methodology, Kanban approach\nGreat interpersonal, problem-solving, analytical, and research skills\nWriting of documentations and creation of architecture diagrams\nKnowledge Required :\nMUST-HAVES\nProfessional English\nExpertise in\nAzure PaaS, IaaS, network...\nAzure Active Directory & Office 365\nTerraform, Ansible\nPaaS web oriented : azure webapp, sql managed instances, frontdoor, nsg, app gw\nNetwork : switch, firewall, TCP/IP, DNS, DHCP\nCybersecurity\nSystem: Microsoft Server OS, Linux\nAzure CLI, Powershell scripting\nOn premise system infrastructure (hardware, virtualization, storage, backup...)\nGood knowledge of relevant ITIL / ITSM / ISO27001 / NIST best practice standards and IT technologies\nNICE-TO-HAVES\nKnowledge of various IT and business functions, software development process\nProfessional French or German or Chinese\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "R",
                "Go"
            ],
            "DataBase": [
                "SQL"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [],
            "MachineLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [
                "Azure"
            ],
            "DevTools": [],
            "Os": [
                "Linux"
            ],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [
                "Ansible"
            ],
            "InfrastructureAsCode": [
                "Terraform"
            ],
            "NetworkSecurty": [
                "Firewall"
            ],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [
                "Teams"
            ],
            "Other": [
                "DevOps",
                "Cloud"
            ],
            "FrSoftSkills": [
                "Communication",
                "Collaboration"
            ],
            "EnSoftSkils": [
                "Communication",
                "Collaboration"
            ]
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "title": "DevOps Engineer",
        "company": "Lengow",
        "location": "Nantes, Pays de la Loire, France",
        "link": "https://fr.linkedin.com/jobs/view/devops-engineer-at-lengow-3873989468?position=3&pageNum=0&refId=NuDbZkBPOnBALTaaBOYlpw%3D%3D&trackingId=aVRzrTek0bmAzca%2FSzCszg%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "\ud83e\udd13\nLengow, an intelligent and automated e-commerce platform :\nSince 2009, Lengow has been the indispensable e-commerce platform for multi-channel expansion in the European market: marketplaces, price comparison websites, affiliate marketing, display ad retargeting, social media, etc.\nAll jobs are open in Nantes/ Paris/ Barcelona.\nThe Infrastructure team manages the hosting provider for the production platform, and implements and maintains non-production environments, the CI/CD solution, and related tools.\nThe team also participates in the evaluation and deployment of new solutions (product evolution or custom projects)\nYour main goals: ensure the satisfaction of customers, as well as internal users. Ensure service continuity, propose and implement changes to achieve the objectives of reliability and scalability of the resources provided to developers.\n\u2328\ufe0f Your main tasks would be as follows :\nMission 1:\nYou will design, implement and maintain CI and CD pipelines\nYou will provide advice and expertise on the integration workflows to be implemented to achieve the continuous integration target\nMission 2:\nYou will ensure the deployment and maintenance of all our environments on AWS\nYou will check the resource requirements to ensure the efficiency, scalability, and reliability of our different environments\nYou will make sure that we control our expenses (FinOps) and that our platform is secure (SecOps)\nYou will help optimising our environments and move to managed resources when relevant (PostgreSQL to Aurora, for example)\n\ud83e\ude9c Hiring Process :\nPhone call with our HR\nInterview with Clement, Head of Infrastructure and Adrien DevOps\nCase study restitution with Marine, CTO at Lengow and Cl\u00e9ment\nReference check and offer letter\nRequirements\n\ud83c\udff9 We are looking for someone with the following experiences and skills:\nExperiences :\nAn experience in a similar position for at least 2 years\nAny experience as a developer could also be greatly appreciated.\nSkills & soft skills\nIn-depth AWS knowledge (Solution Architect Associate or SysOps Admin Associate)\nKubernetes, Terraform, Ansible\nAffinities with Python, PostgreSQL, async processes\nGCP knowledge a bonus\nAutonomy, responsibility, ownership and determination\nTeam-oriented and proactive\nBenefits\n\u2728\nJoining Lengow is also an opportunity to benefit from many advantages :\nTicket restaurant 8 euros by day\nMalakoff Humanis Private insurance & Prevoyance\nHybrid remote policy\nFlexible hours\nBike mileage allowances or 50% of transportation tickets\nRemote allowances\nProfessional events (Devoxx, Meetup ...) and regular internal events\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "Scala",
                "R",
                "Go"
            ],
            "DataBase": [
                "SQL"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [],
            "MachineLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [
                "AWS"
            ],
            "DevTools": [],
            "Os": [],
            "DBMS": [
                "PostgreSQL"
            ],
            "SoftBigDataProcessing": [],
            "Automation": [
                "Ansible",
                "Kubernetes"
            ],
            "InfrastructureAsCode": [
                "Terraform"
            ],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [
                "Kubernetes"
            ],
            "Collaboration": [],
            "Other": [
                "DevOps",
                "CI/CD"
            ],
            "FrSoftSkills": [],
            "EnSoftSkils": []
        },
        "details": {
            "JobDetail": [
                "Remote"
            ],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "title": "DevOps Engineer",
        "company": "Capgemini",
        "location": "Greater Paris Metropolitan Region",
        "link": "https://fr.linkedin.com/jobs/view/devops-engineer-at-capgemini-3402745877?position=4&pageNum=0&refId=NuDbZkBPOnBALTaaBOYlpw%3D%3D&trackingId=jWEPBWglKev4eyrn5DFeuw%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Tu commences \u00e0 faire le tour de ton poste et \u00e0 manquer de projection ?\nL\u2019heure est arriv\u00e9e d\u2019oser et donner un nouvel \u00e9lan \u00e0 ta carri\u00e8re : C&CA est faite pour toi !\nChez Capgemini,\nnous t\u2019aidons \u00e0 construire ta carri\u00e8re en mettant\nen place\ntout un accompagnement et un panel d\u2019outils, pour continuer \u00e0 te challenger au quotidien\n!\nQuelques raisons de nous croire\nCe que nous te proposons en tant que collaborateur Capgemini c\u2019est de rejoindre des \u00e9quipes d\u2019experts passionn\u00e9s par l\u2019innovation et les challenges. Tu auras l\u2019opportunit\u00e9s de travailler sur la mise en place de solutions innovantes de A \u00e0 Z pour r\u00e9pondre aux diff\u00e9rents enjeux de nos clients et d\u2019\u00e9voluer dans une communaut\u00e9 d\u2019expert \u00e0 l\u2019\u00e9coute ou le mot d\u2019ordre est le partage !\nEn projet ton r\u00f4le sera de\nParticiper au d\u00e9veloppement applicatif (en fonction de la taille du projet)\nConcevoir des pipelines DevOps (jobs Jenkins, t\u00e2ches Gradle/MAVEN \u2026)\nParticiper \u00e0 l\u2019automatisation des processus ou des cha\u00eenes de traitement\nParticiper et valider les architectures techniques cibles\nParticiper \u00e0 optimiser et automatiser les d\u00e9ploiements applicatifs (CI/CD)\nPr\u00e9parer les tests techniques pour les recettes techniques\nR\u00e9diger de la documentation technique\nLes domaines suivants t\u2019int\u00e9ressent\nAutomatisation / Industrialisation : Powershell, Bash, Perl, Git/ GitLab, VSTS, Jenkins, Ansible, Nexus\nCloud : AWS, Azure, GCP\u2026\nInfra As Code : Terraform, Cloudformation, Troposhpere, \u2026\nDocker / Kubernetess\nQui es-tu ?\nCe qui nous int\u00e9resse au-del\u00e0 des comp\u00e9tences que nous recherchons, c\u2019est ta personnalit\u00e9, ton d\u00e9sir d\u2019\u00e9voluer et de monter en comp\u00e9tences. La force de notre entreprise est de te donner l\u2019opportunit\u00e9 de construire ta trajectoire de carri\u00e8re en te fournissant un accompagnement sp\u00e9cifique pour que tu puisses atteindre tes objectifs (formations, certifications, accompagnement, \u00e9coute\u2026).\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "R",
                "Bash"
            ],
            "DataBase": [],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [],
            "MachineLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [
                "AWS",
                "Azure"
            ],
            "DevTools": [
                "Git",
                "Docker",
                "Jenkins"
            ],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [
                "Ansible",
                "Kubernetes"
            ],
            "InfrastructureAsCode": [
                "Terraform",
                "CloudFormation"
            ],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [
                "Docker",
                "Kubernetes"
            ],
            "Collaboration": [],
            "Other": [
                "DevOps",
                "Cloud",
                "CI/CD"
            ],
            "FrSoftSkills": [],
            "EnSoftSkils": []
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "title": "DevOps/Site Reliability Engineer",
        "company": "Foxintelligence",
        "location": "Paris, \u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/devops-site-reliability-engineer-at-foxintelligence-3876388754?position=5&pageNum=0&refId=NuDbZkBPOnBALTaaBOYlpw%3D%3D&trackingId=HdPJd%2FkFGx5d%2Fe1ZdsPoGw%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Chez Foxintelligence, nous sommes des amoureux de la data. \ud83e\udd13\nNotre mission est de rendre les consommateurs et les marques plus intelligents, gr\u00e2ce \u00e0 une donn\u00e9e de march\u00e9 r\u00e9volutionnaire issue de l'intelligence collective. Pour les consommateurs, Foxintelligence rend accessibles et utiles leurs donn\u00e9es transactionnelles issues de leurs bo\u00eetes mail ou comptes bancaires. En les anonymisant, nous cr\u00e9ons des statistiques uniques qui permettent aux marques de rester en phase avec les produits qui se vendent le mieux et les attentes des consommateurs.\nNous publions une application grand public aim\u00e9e par des millions de personnes (Cleanfox, 5m+ de t\u00e9l\u00e9chargements, 4.8/5 \ud83d\udc96 sur l'app store et le play store) et pr\u00e9parons le lancement d'une app de bilan carbone \u00e0 l'exp\u00e9rience radicalement nouvelle. Gr\u00e2ce \u00e0 notre plateforme data, elle va rendre possible une prise de conscience massive des enjeux du changement climatique \ud83c\udf0d et des actions individuelles possibles pour le combattre. Nous pensons que l'information est une force de changement puissante, lorsqu'elle s'appuie sur la data.\nUtilisant ces donn\u00e9es personnelles totalement anonymis\u00e9es, notre plateforme SaaS foxintelligence.io est devenue la r\u00e9f\u00e9rence de la market intelligence digitale en Europe avec des dizaines de grands groupes clients. Le point commun entre Deliveroo, Just Eat, Mano Mano, BackMarket ou The Boston Consulting Group ? Ils vont tr\u00e8s vite (on ne s'ennuie pas avec eux !) et ils nous font tous confiance !\nSoutenus par des investisseurs de premier plan (17m lev\u00e9s aupr\u00e8s de Daphni, Partech, GFC et eFounders) et r\u00e9cemment int\u00e9gr\u00e9 au groupe NielsenIQ nous sommes maintenant \u00e0 la conqu\u00eate de l'Europe et en phase d'hyper-croissance.\nSi notre FoxHQ reste \u00e0 Paris, notre \u00e9quipe de plus de 120 talents pluridisciplinaires (tech, data et business) travaille depuis partout en France et m\u00eame en dehors (ex. Turquie). Nous pensons que notre politique remote-first, notre culture forte (bienveillance, exigence, r\u00e9silience et data-first) et notre innovation permanente en termes de modes de travail (ex. grille de salaire transparente, formation au changement climatique, transparence sur la strat\u00e9gie) sont les cl\u00e9s de notre r\u00e9ussite collective.... et de ta r\u00e9ussite avec nous !\nJob Description\nFoxintelligence recherche\nun(une) DevOps/Site Reliability Engineer.\nTa mission consiste \u00e0 travailler avec le reste de l'\u00e9quipe DevOps / SRE et les \u00e9quipes de d\u00e9veloppement afin d'assurer disponibilit\u00e9, performance, efficacit\u00e9 et s\u00e9curit\u00e9 maximale des services applicatifs. Nous travaillons en collaboration rapproch\u00e9e avec le CTO et les d\u00e9veloppeurs et nos challenges en terme de gestion de la data feront de toi un expert en infrastructure r\u00e9siliente et performante ! Nos objectifs sont d'automatiser un maximum nos op\u00e9rations, nous tenons donc \u00e0 g\u00e9rer le maximum en Infra As Code (IaC), ce qui nous permet de gagner en r\u00e9silience et d'anticiper au mieux notre croissance internationale.\nVoici quelques chiffres de production pour donner une id\u00e9e des volumes que nous traitons :\n40 TB op\u00e9rationnels (noSQL et SQL) pour nos applications grand public et en entr\u00e9e de notre flux \"Big Data\"\n800 TB pour la partie analytique\n3000-6000 conteneurs en parall\u00e8le en fonction des pics de charge\n15 \u00e0 45 millions d'appels de fonctions serverless par jour\n1 millard de messages de logs chaque jour\nTes responsabilit\u00e9s au quotidien :\nAssurer le bon fonctionnement de notre infrastructure AWS (suivi du monitoring, cr\u00e9ation d'alertes, anticipations des probl\u00e8mes)\nD\u00e9ployer de nouvelles architectures AWS via Terraform, Helm, Ansible\nAdministration K8S / Karpenter\nAdministration des outils transverses fournis aux d\u00e9veloppeurs (Jenkins, Vault, Nexus, Grafana, ELK, etc..)\nMaitrise des co\u00fbts - S\u00e9curit\u00e9 - Support aux d\u00e9veloppeurs (1jour/semaine max)\nRequirements\nComp\u00e9tences n\u00e9cessaires (ce qu'il te faut pour r\u00e9ussir sur ce poste) :\nSoft Skills\nProactivit\u00e9\nRigueur\nR\u00e9activit\u00e9\nAisance relationnelle\nHard Skills\nBonne connaissance des briques techniques AWS (S3, EC2, ALB, API Gateway, Cloudfront, Lambda, etc)\nBonne connaissance de Terraform pour construire l'infrastructure AWS\nExp\u00e9rience avec Kubernetes + Helm - Connaissance de GCP / BigQuery\nMonitoring Prometheus/Grafana/AlertManager et/ou Cloudwatch\nMaitrise de Git\nMaitrise d'un langage de programmation et/ou de scripting (shell)\nComp\u00e9tences additionnelles\nAdministration de BDD\nExp\u00e9rience GCP avanc\u00e9e\nLadies\nLes \u00e9tudes montrent que les femmes ont moins tendance \u00e0 postuler \u00e0 une offre d'emploi quand elles n'ont pas toutes les qualifications requises. Ladies, ne vous mettez pas de barri\u00e8re et donnez-nous la chance de nous faire notre propre avis, nous serons toujours ravis d'\u00e9changer avec vous ! Si notre raison d'\u00eatre vous parle, postulez !\nSelf-made data lovers\nLes dipl\u00f4mes c'est bien, les skills c'est mieux et l'exp\u00e9rience t'en donne. Aucun dipl\u00f4me n'est requis chez nous, c'est les comp\u00e9tences et l'\u00e9nergie qui comptent !\nRecruitment process\nRound 0 : entretien (fit) avec notre Head of People\nRound 1 : entretiens (exp\u00e9rience et fit) avec notre \u00e9quipe DevOps\nRound 2 : Live coding\nDecision Round : Entretien (fit et vision) avec notre CTO\nBenefits\nAvantages/ce que nous offrons :\nSalaire et variable comp\u00e9titifs\nRemote friendly (+ budget am\u00e9nagement de l'espace de travail @Home)\nBonus Cooptation\nBonne assurance sant\u00e9 (Alan)\nTitres restaurants (swile) : pris en charge \u00e0 60% par Fox\nSyst\u00e8me de cr\u00e8che subventionn\u00e9 par Fox\nCulture forte et pratiques de management \u00e0 la pointe (strat\u00e9gie et r\u00e9sultats financiers transparents, feedback 360, grille de salaire innovante et transparente etc.)\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "R"
            ],
            "DataBase": [
                "SQL",
                "NoSQL"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [],
            "MachineLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [
                "Statistiques"
            ],
            "CloudComputing": [
                "AWS"
            ],
            "DevTools": [
                "Git",
                "Jenkins"
            ],
            "Os": [],
            "DBMS": [
                "BigQuery"
            ],
            "SoftBigDataProcessing": [],
            "Automation": [
                "Ansible",
                "Kubernetes"
            ],
            "InfrastructureAsCode": [
                "Terraform"
            ],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [
                "Kubernetes"
            ],
            "Collaboration": [],
            "Other": [
                "DevOps",
                "Big Data",
                "Statistiques",
                "Cloud"
            ],
            "FrSoftSkills": [
                "Collaboration"
            ],
            "EnSoftSkils": [
                "Collaboration"
            ]
        },
        "details": {
            "JobDetail": [
                "Remote"
            ],
            "TypeContract": [],
            "Salary": [
                "40"
            ],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "title": "DevOps Engineer",
        "company": "Orange Logic",
        "location": "\u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/devops-engineer-at-orange-logic-3916254305?position=6&pageNum=0&refId=NuDbZkBPOnBALTaaBOYlpw%3D%3D&trackingId=ysbkrTDSevxoFQWVICFFjg%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "For more than two decades, Orange Logic has empowered a wide range of clients with its digital asset management system, Cortex. We\u2019ve worked with almost every industry, from Finance to NGOs, Media giants to educational institutions; securing and organizing their assets. The DevOps Engineer introduces processes, tools, and methodologies to balance needs throughout the software development life cycle, from coding and deployment, to maintenance and updates.\nWhat you can expect in your role:\nInfrastructure provisioning, optimization and management.\nCloud architecture & system administration.\nManage and improve the observability stack (metrics, logs, traces, alerting, visualization).\nDealing with security requirements and automations proposing a good balance.\nActs as the DevOps advocate; helps evangelize and educate the DevOps way across the organization.\nDevelop new system and application plans to ensure operational reliability.\nAssist in managing and maintaining a network of hosted servers.\nEnforce / help about security good practices at dev level to prevent breaches.\nParticipate to optimize cloud costs.\nYou are:\nExperienced Infrastructure as Code with CloudFormation/Terraform.\nExperienced on containers approach with Docker (Linux and Windows).\nA Subject Matter Expert on cloud infrastructure (e.g. AWS, Google Cloud, Azure).\nExperience with CI/CD pipelines (Jenkins, TeamCity, Azure Pipelines) and ElasticSearch\nExperience with configuration management tools (e.g. Chef, Puppet or Ansible).\nExperience in cloud native approach and containers orchestration tools (e.g. Kubernetes).\nProficient with Windows/Linux systems using a terminal (e.g. Bash, Powershell).\nHands-on experience with developer toolset and practices such as using source control, giving and receiving code reviews, writing unit tests and familiarity with agile principles.\nStrong understanding of common system architecture, provisioning and automation.\nPerks of joining the team:\nCompetitive compensation & benefits package\nRemote work environment\nHow to get started:\nIf you\u2019re up for the challenge to be part of a growing DevOps team we\u2019d like to hear from you. Apply today!\nOrange Logic is an equal opportunity employer. We celebrate diversity and are committed to creating an inclusive environment for all our employees.\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "R",
                "Go",
                "Bash"
            ],
            "DataBase": [
                "Elasticsearch"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [],
            "MachineLearning": [
                "Orange"
            ],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [
                "AWS",
                "Azure"
            ],
            "DevTools": [
                "Git",
                "Docker",
                "Jenkins"
            ],
            "Os": [
                "Linux",
                "Windows"
            ],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [
                "Ansible",
                "Kubernetes",
                "Puppet",
                "Chef"
            ],
            "InfrastructureAsCode": [
                "Terraform",
                "CloudFormation"
            ],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [
                "Docker",
                "Kubernetes"
            ],
            "Collaboration": [],
            "Other": [
                "DevOps",
                "Cloud",
                "CI/CD"
            ],
            "FrSoftSkills": [],
            "EnSoftSkils": [
                "Organization"
            ]
        },
        "details": {
            "JobDetail": [
                "Remote"
            ],
            "TypeContract": [],
            "Salary": [
                "Package"
            ],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "title": "DevOps Engineer",
        "company": "Stakha",
        "location": "France",
        "link": "https://fr.linkedin.com/jobs/view/devops-engineer-at-stakha-3902900406?position=7&pageNum=0&refId=NuDbZkBPOnBALTaaBOYlpw%3D%3D&trackingId=sluMCbrXqSWnTEumjXBcRg%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Pour le compte de son client, Stakha est \u00e0 la recherche d\u2019un\u00b7e DevOps Engineer en full-remote (55/65k\u20ac\nbruts annuels\n) pour rejoindre une\nFintech\nde 20 collaborateurs dans le cadre d'une cr\u00e9ation de poste.\nLe profil recherch\u00e9 doit absolument avoir une exp\u00e9rience de plus de 4\nans\nen tant qu'Ing\u00e9nieur DevOps/SRE (Dev & Ops)\nAu sein de l'\u00e9quipe tech, vous participez \u00e0 l'am\u00e9lioration global du produit.\nLe poste en quelques mots :\n\ud83c\udf10Entreprise : Start-up - SaaS\n\ud83c\udfe2Localisation :\nFull Remote\n\ud83d\udcb0Salaire : 55k\u20ac \u00e0 65k\u20ac\n\ud83c\udfafPrincipales responsabilit\u00e9s :\nConcevoir et orchestrer l'infrastructure pour maximiser les performances (IaC)\nS\u00e9lectionner et int\u00e9grer les outils et services n\u00e9cessaires au product\nContribuer activement \u00e0 la s\u00e9curit\u00e9 globale du syst\u00e8me.\n\ud83d\ude80Tech Stack : Kube, Terraform, Docker, Cloud\n\u27a1\ufe0f amaury@stakha.io\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "R"
            ],
            "DataBase": [],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [],
            "MachineLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [],
            "DevTools": [
                "Docker"
            ],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [
                "Terraform"
            ],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [
                "Docker"
            ],
            "Collaboration": [],
            "Other": [
                "DevOps",
                "Cloud"
            ],
            "FrSoftSkills": [],
            "EnSoftSkils": []
        },
        "details": {
            "JobDetail": [
                "Remote",
                "Full"
            ],
            "TypeContract": [],
            "Salary": [
                "55k"
            ],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s",
                "4",
                "4",
                "4"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "title": "DevOps Engineer",
        "company": "IC Resources",
        "location": "Paris, \u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/devops-engineer-at-ic-resources-3866824508?position=8&pageNum=0&refId=NuDbZkBPOnBALTaaBOYlpw%3D%3D&trackingId=RdfTiX3VDyiaAlfmzT19Sg%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Global AudioVisual technology company is looking to hire an experienced DevOps Engineer to join their team in Paris.\nWorking closely with the SW engineering and validation teams, your role will involve the design, development and automation of development and validation infrastructures and processes, as they look to move their CI/CD processes forward.\nKey responsibilities:\nDefine / optimise continuous integration and deployment pipelines for their solutions\nAutomate infrastructure management processes\nSupport implementation of the CI/CD pipeline\nCollaborate with development teams to integrate DevSecOps best practices into their workflow\nInnovate and make the validation process of their products more efficient with new tools\nIntegrate third-party applications / modules into the CI/CD chain\nEnsure systems and data security at every stage of the software development lifecycle\nIdentify and resolve system performance, reliability and scalability issues\nKey skills/experience required:\nIn-depth knowledge of CI/CD principles and associated tools (Gitlab CI, Jenkins, etc.)\nExperience with Docker\nGit and Git-based workflow e.g. branching practices\nStrong scripting skills (Python, Bash, PowerShell, etc.)\nLinux environment (ideally Ubuntu, Debian, CentoS)\nAutomation tools and configuration management (Ansible type, Puppet, Chef, etc.)\nKnowledge of technologies related to virtualization, cloud\nAgile methodology\nCode quality tools (SonarQube type..)\nKnowledge of testing and validation within Hi-Tech engineering organisations\nExposure to embedded development technologies/environments\nIdeally, you will have worked in a similar DevOps role within a SW & HW tech company.\nThey are one of the world's leading companies in the design and manufacture of professional AV tech - this is your chance to join them as they continue to grow!\nThis is a hybrid role\nIf you are interested, please contact Matt Andrews at IC Resources for more information!\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "Scala",
                "R",
                "Bash"
            ],
            "DataBase": [],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [],
            "MachineLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [],
            "DevTools": [
                "Git",
                "Docker",
                "Jenkins"
            ],
            "Os": [
                "Linux"
            ],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [
                "Ansible",
                "Puppet",
                "Chef"
            ],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [
                "Docker"
            ],
            "Collaboration": [
                "Teams"
            ],
            "Other": [
                "DevOps",
                "Cloud",
                "CI/CD"
            ],
            "FrSoftSkills": [
                "Organisation"
            ],
            "EnSoftSkils": []
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "title": "DevOps Engineer",
        "company": "Madbox",
        "location": "Paris, \u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/devops-engineer-at-madbox-3897759681?position=9&pageNum=0&refId=NuDbZkBPOnBALTaaBOYlpw%3D%3D&trackingId=fL4u3ZMiax%2BkQAOuSqq5Jw%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Madbox is a fast-growing mobile gaming company with a very unique way of developing games. Everything has been made for teams to take as much\nownership\nas possible, unleash their\ncreativity\n, bring\nperformance\n, and have as much\nfun\nas possible.\nIn July 2022, we launched our\nPocket Champs\ngame worldwide which quickly became one of the top-grossing games in its category.\nThe game has been scaling a lot since the launch and is now supporting millions of monthly users. All these players are interactive with backend systems that we have developed internally and deployed based on our internal knowledge.\nBut the stakes are getting high and we cannot afford to have incidents on these services because it could damage the players experience. We are now looking for someone that has some expertise on deploying online applications that will be consumed by millions of players and would hold on under a heavy load.\nThis is where you come in:\ntake this DevOps / SRE position over and be a driving force of this new Chapter! \ud83d\udd25\nThe beginning of your journey at Madbox as an SRE Engineer:\n- Starts with meeting your team, discovering who is who and engaging with everyone involved (or not) in your missions.\n- Continues with getting familiar with our stack, discovering our environment, tools and processes.\n- You will of course play our games and learn more about how we are making them the \u201cMadbox way\u201d !\n- Everything will be made for you to get you up to speed, take ownership and be ready to tackle your missions.\nResponsibilities & Scope :\n- Design the backend infrastructure to host our Gaming Backend projects (APIs, Game Servers, Storage solutions\u2026).\n- Setup the monitoring services to allow tracking the health metrics of our backend applications.\n- Setup alerts and watch over the health of our backend applications to raise an alarm every time an issue occurs.\n- Alert the right team.\n- Give a clear criticality information to define how quickly the issue needs to be solved\n- Define SLA processes for each different level of criticality that can be followed to keep the service available.\n- Provide as much context as you can from the metrics and logs you see on the dashboards.\n- Setup our backend application to scale up & down automatically to optimize our cost.\n- Follow up and make sure that our services scale properly and be ready to operate the scaling up / down manually if necessary.\n- Identify bottlenecks in our backend applications and recommend optimization that the Gaming Backend Developers team could make to optimize the application.\n- Keep a vigil eye on the solutions available on the market.\nProfile\n- You have 3 years of hands-on experience in a DevOps / SRE position.\n- You are data-oriented, as you measure the impact of the solutions you implement.\n- You have proven experience at deploying applications that are accessible to millions of users.\n- You are fully proficient in English.\n- You\u2019re passionate about building systems that scale.\n- You focus on stability and availability.\n- You\u2019re a team player who can explain their work and share their knowledge with other technical people.\nHiring Process\n- A call with a recruiter\n- A call with the hiring manager\n- A home assignment\n- A review of the test with the hiring manager and someone from the automation team\n- A meet the team interview\nAll our offers are extended within 48 hours maximum\nPerks and benefits\nCompetitive compensation :\nour compensation grid is regularly reviewed based on the evolution on the market to ensure everyone at Madbox is fairly compensated and receives frequent updates.\nHybrid remote policy:\n3 days on site minimum per week + 15 additional working days fully remote per year\nCWS\n: Culture, Wellness & Sport,\nis a budget Madbox dedicated to each employee for them to self develop and take care of themselves\nHolidays\n: hyper-flexible 30 days off policy (take it when you need it)\nHealth of Our Madboxers is Essential:\nAlan Health Insurance (75% covered by Madbox)\nLunch coupons:\nTake advantage of the Swile card (60% covered by Madbox)\nTransport Fees :\n50% covered by Madbox\nAmazing Offices:\nCome and explore our offices in the heart of Paris (Bonne Nouvelle Station) and Barcelona (Diagonal Station)! From taking a nap in our \u201cjungle\u201d in Paris Office to soaking up the sun on the rooftop in Barcelona at lunch, we have thought of everything to make you feel right at home. \ud83e\uddd8\u200d\u2642\ufe0f\nBonus\n: Our fantastic Workplace Managers will make sure to provide you with the coffee/tea/snacks/drinks of your choice!\nHome office Expenses bonus\nTeam Macbook or Team PC?\n\ud83d\udda5 We provide all the necessary equipment\nEnglish Lessons\n: as our main langage in both studios is English, you can enjoy group lessons with your peers thanks to our private teacher\nMadgen :\nyearly company event\nContract and location\nLocation\n: This position is available in Paris, 19-21 Rue Poissonni\u00e8re \ud83c\uddeb\ud83c\uddf7\nor/and in Barcelona, Utopicus, Pla\u00e7a de Gal\u00b7la Plac\u00eddia, 1, 3, \ud83c\uddea\ud83c\uddf8\nContract\n: Permanent full-time contract\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "R",
                "Go"
            ],
            "DataBase": [],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [],
            "MachineLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [],
            "DevTools": [],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [
                "Teams"
            ],
            "Other": [
                "DevOps"
            ],
            "FrSoftSkills": [],
            "EnSoftSkils": [
                "Creativity"
            ]
        },
        "details": {
            "JobDetail": [
                "Remote",
                "Full"
            ],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "title": "Cloud Engineer",
        "company": "SELLIA",
        "location": "Paris, \u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/cloud-engineer-at-sellia-3902686769?position=10&pageNum=0&refId=NuDbZkBPOnBALTaaBOYlpw%3D%3D&trackingId=cTidfsCiFx1NWhlcZM8Uhw%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Nous recherchons un Ops Senior en environnement Kubernetes sur du cloud Azure pour prendre en charge l\u2019automatisation du d\u00e9ploiement de nos applications, le suivi de notre infrastructure et l\u2019optimisation des co\u00fbts des environnements.\nLes missions :\net d\u00e9ployer des infrastructures pour applications cloud (y compris sur les services de CI/CD)\nen place des outils de s\u00e9curisation, monitoring, backup, r\u00e9partition des charges, etc\nles processus et architectures\nau processus de certification ISO (documentation, tests, etc)\n\u00e0 la conception et au d\u00e9veloppement des architectures cloud en utilisant les meilleures pratiques et les services adapt\u00e9s (Azure).\nen place et g\u00e9rer des clusters Kubernetes pour le d\u00e9ploiement d'applications et de micro-services.\navec les \u00e9quipes de data science pour int\u00e9grer les donn\u00e9es et mod\u00e8les selon une approche MLOps.\nles bases de donn\u00e9es relationnelles (postgreSQL) et MongoDB dans les solutions architecturales, en tenant compte des exigences de performances et de disponibilit\u00e9.\nVotre profil :\nann\u00e9es d\u2019exp\u00e9riences minimum sur des projets similaires\ncertifications Azure MS devops engineer expert serait un plus\nmoins une exp\u00e9rience significative sur Kubernetes.\ndes bases de donn\u00e9es relationnelles et exp\u00e9rience avec MongoDB.\napprofondie des principes d'architecture logicielle, de la conception de syst\u00e8mes \u00e9volutifs et de la s\u00e9curit\u00e9 des applications.\n\u00e0 communiquer efficacement et \u00e0 travailler en \u00e9quipe, tout en faisant preuve d'autonomie.\ncompr\u00e9hension des m\u00e9thodologies Agile et des pratiques DevOps.\nLes technologies suivantes n\u2019ont pas de secret pour vous :\n: Windows, Linux (ubuntu, WSL2), r\u00e9seaux\n: JavaScript/TypeScript, Python, Shell\nde donn\u00e9es : postgreSQL , mongoDB\n: Docker/Podman, Kubernetes (AKS/EKS) : Helm, ISTIO,\n: Cloud functions\nGitOps, Serverless, Terraform, Helm, Ansible, Packer\nDeployment: Cloud CI/CD\n: Github, Consul, NGINX, WebPack, AWS Kinesis, Keycloak, Azure Devops\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "Java",
                "R",
                "Go",
                "JavaScript"
            ],
            "DataBase": [
                "SQL",
                " MongoDB"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [],
            "MachineLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [
                "AWS",
                "Azure"
            ],
            "DevTools": [
                "Git",
                "Docker"
            ],
            "Os": [
                "Linux",
                "Windows"
            ],
            "DBMS": [
                "PostgreSQL"
            ],
            "SoftBigDataProcessing": [],
            "Automation": [
                "Ansible",
                "Kubernetes"
            ],
            "InfrastructureAsCode": [
                "Terraform"
            ],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [
                "Docker",
                "Kubernetes"
            ],
            "Collaboration": [],
            "Other": [
                "DevOps",
                "ML",
                "Cloud",
                "CI/CD"
            ],
            "FrSoftSkills": [],
            "EnSoftSkils": []
        },
        "details": {
            "JobDetail": [
                "Senior"
            ],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "title": "DevOps/Cloud Engineer",
        "company": "Teolia",
        "location": "Paris, \u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/devops-cloud-engineer-at-teolia-3902427701?position=11&pageNum=0&refId=NuDbZkBPOnBALTaaBOYlpw%3D%3D&trackingId=8WUrSvcPSsF9X2U5dCb73w%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Pour toi, DevOps n\u2019est pas juste un ensemble de technologies\n, mais un moyen d\u2019accompagner efficacement un client dans ses probl\u00e9matiques m\u00e9tiers : r\u00e9duction du time-to-market, fiabilisation des produits et auto-r\u00e9silience, r\u00e9duction des co\u00fbts, s\u00e9curisation avec l\u2019approche shift-left (DevSecOps)\u2026\nAlors cette annonce devrait te plaire\n\ud83d\ude0a\nTes missions\nTu apporteras ton expertise DevOps aupr\u00e8s de nos clients dans leur projet de transformation digitale et performance op\u00e9rationnelle. Concr\u00e8tement, dans ton quotidien tu pourras \u00eatre amen\u00e9.e \u00e0 :\nTravailler aussi bien avec les \u00e9quipes de d\u00e9veloppement que les \u00e9quipes de production afin d\u2019automatiser et fluidifier le d\u00e9ploiement et le maintien des applicatifs (CI/CD).\nMettre en place une strat\u00e9gie de test adapt\u00e9e afin de r\u00e9duire au maximum les r\u00e9gressions et les bugs remont\u00e9es par les utilisateurs.\nD\u00e9ployer les ressources \u00e0 travers une technologie d\u2019IaC (Terraform like \u2013 ou Azure ARM/Blueprint/Bicep - ou AWS cloud formation)\nMettre en place l\u2019observabilit\u00e9 des applications et assurer leur niveau de disponibilit\u00e9 : monitoring / alerting, logging, anticipation des pics de charges\nOp\u00e9rer comme SRE : DRT, RTO et RPO\nContribuer comme Cloud architect + FinOps : design de solutions cloud native, architecture des solutions clouds, gestion du multicloud, mise en place de dashboard d\u2019analyse des co\u00fbts et proposition de r\u00e9duction\nOp\u00e9rer comme DevSecOps: mise en place d\u2019analyse et de correction de s\u00e9curit\u00e9 bout en bout, approche shift-left\u2026\nComment nous l\u2019op\u00e9rerons ensemble :\nEn \u00e9tant capable d\u2019identifier et d\u2019automatiser les traitements \u00e0 forte valeur ajout\u00e9e : quick-wins\nUn ADN de\nDoer\n: r\u00e9aliser des choses rapidement et en qualit\u00e9.\nUn ADN d\u2019\nEnabler\n: notre force vient du fait que nous formons o\u00f9 nous intervenons (nous croyons sinc\u00e8rement que la meilleure \u00e9quipe est celle o\u00f9 personne n\u2019est indispensable, tu en penses quoi ? \ud83d\ude09)\nEn nous rejoignant, ce qu\u2019on t\u2019apporte (attention liste non exhaustive)\n2 mantras chez Teolia : la FORMATION et le SUIVI.\nEn nous rejoignant, tu :\nB\u00e9n\u00e9ficieras d\u2019un\naccompagnement sur mesure\n(formations techniques, mise en pratique). Cette formation se base sur une analyse 360 de ton profil afin de te proposer une formation adapt\u00e9e en fonction de ce que tu dois apprendre et de ce que tu veux apprendre.\nTe formeras de mani\u00e8re continue : entre membres de l\u2019\u00e9quipe et via une plateforme d\u2019apprentissage\nValideras tes acquis via les\ncertifications\n(groupes de certifications pour plus d\u2019\u00e9mulation et financement par Teolia)\nSeras accompagn\u00e9.e en mission : par ton commercial et ton practice leader afin de t\u2019aider sur les \u00e9ventuelles probl\u00e9matiques techniques, d\u00e9tecter des besoins de formation/certifications, t\u2019aider \u00e0 prendre du recul sur les transformations \u00e0 op\u00e9rer\nEt cerise sur le cheesacake : Teolia c\u2019est aussi et avant tout une communaut\u00e9 aux petits oignons (des gens\npassionn\u00e9s et accueillants\n,\nune communaut\u00e9 qui ne laisse jamais quelqu\u2019un sur le c\u00f4t\u00e9\n).\nTon profil : si on parlait de toi?\nD'une formation sup\u00e9rieure en informatique minimum BAC+3, tu justifies id\u00e9alement de 2 ans d'exp\u00e9rience minimum sur un poste d\u2019ing\u00e9nieur DevOps (une belle alternance de 2/3 ans nous va aussi).\nSi on r\u00e9sume tes domaines de comp\u00e9tences/connaissances :\n\u00b7 Une base solide en Syst\u00e8me et r\u00e9seau\n\u00b7 Maitrise d\u2019un outil de Build et de packaging\n\u00b7 Est-il besoin de mentionner la Containerisation comme essentielle \ud83d\ude09\n\u00b7 Un outil de Deploy (ex : Kubernetes, Swarm, XLDeploy, \u2026)\n\u00b7 Un outil de CI/CD\n\u00b7 Un cloud provider\n\u00b7 Id\u00e9alement connaissance de l\u2019Infrastructure as Code et du Monitoring / Alerting (ex : Prometheus, Grafana, \u2026)\n\u00b7 A l\u2019aise dans des contextes anglophones (pas besoin de disserter sur la photo de famille retouch\u00e9e de Kate Middleton mais tu vois l\u2019id\u00e9e ).\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "R"
            ],
            "DataBase": [],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [],
            "MachineLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [
                "AWS",
                "Azure"
            ],
            "DevTools": [
                "Git"
            ],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [
                "Kubernetes"
            ],
            "InfrastructureAsCode": [
                "Terraform"
            ],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [
                "Kubernetes"
            ],
            "Collaboration": [],
            "Other": [
                "DevOps",
                "Cloud",
                "CI/CD"
            ],
            "FrSoftSkills": [],
            "EnSoftSkils": []
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [],
            "Salary": [],
            "Level": [
                "Bac+3"
            ],
            "Experience": [
                "a",
                "n",
                "s",
                "2",
                "2",
                "2"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "title": "Junior DevOps Engineer",
        "company": "Cronos Europa",
        "location": "Strasbourg, Grand Est, France",
        "link": "https://fr.linkedin.com/jobs/view/junior-devops-engineer-at-cronos-europa-3908284316?position=12&pageNum=0&refId=NuDbZkBPOnBALTaaBOYlpw%3D%3D&trackingId=TQmLRhcxdV%2FvqbGXvh75uA%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "We are currently looking for a Junior DevOps Engineer to strengthen the Cronos Europa team.\nResponsibilities\nDevelop tools and infrastructures to support Build & Deployment activities.\nManage, support, and enhance Build and Deployment pipelines for efficiency and reliability.\nImplement DevOps strategies and associated processes effectively to streamline operations and enhance collaboration.\nTechnical Skills\nThorough understanding of the Software Development Life Cycle (SDLC) and Agile methodologies.\nProficiency in automation tools for implementing continuous integration and continuous delivery.\nWorking knowledge of popular DevOps tools such as GIT, Jenkins, Ansible, Artifactory, SonarQube, and OpenShift.\nFamiliarity with scripting languages, such as Groovy, to streamline processes.\nBonus points for experience with mobile device technologies like React Native and Xcode, as well as familiarity with Android and iOS operating systems.\nProfile\n2 years' experience\nBachelor degree in IT\nMinimum B2 level of English proficiency. French language skills are a plus but not mandatory.\nGood reasoning and communication\nWhy Cronos Group? We'll propose you\nAn attractive salary package\nA good work-life balance environment\nThe assurance of working in cutting-edge technologies in an entrepreneurial spirit.\nThe opportunity to develop your skills thanks to tailor-made training courses according to your needs\nA good job in a friendly place\nIf you wish to integrate a dynamic structure on a human scale while working with the latest technologies, don't wait anymore and join Cronos!\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "R",
                "Go"
            ],
            "DataBase": [],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [],
            "MachineLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [],
            "DevTools": [
                "Git",
                "Jenkins"
            ],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [
                "Ansible"
            ],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [
                "OpenShift"
            ],
            "Collaboration": [],
            "Other": [
                "DevOps",
                "ML"
            ],
            "FrSoftSkills": [
                "Communication",
                "Collaboration"
            ],
            "EnSoftSkils": [
                "Communication",
                "Collaboration"
            ]
        },
        "details": {
            "JobDetail": [
                "Junior"
            ],
            "TypeContract": [],
            "Salary": [
                "Salary",
                "Package"
            ],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "title": "DevOps Engineer",
        "company": "Neosoft",
        "location": "Paris, \u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/devops-engineer-at-neosoft-3902390640?position=13&pageNum=0&refId=NuDbZkBPOnBALTaaBOYlpw%3D%3D&trackingId=QT044j2gDKahrIBitPLYIg%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Dans le cadre du renforcement de nos \u00e9quipes, nous recherchons un consultant DevOps (c\u00f4t\u00e9 Obs) confirm\u00e9 pour rejoindre le plus gros projet infrastructure du groupe N\u00e9o-Soft (Multi-Cloud, DevOps, Agile). Si vous \u00eates la bonne personne, c'est que vous aimez les probl\u00e9matiques li\u00e9es \u00e0 l'infrastructure, le travail d'\u00e9quipe, et plus largement le monde de l'IT. Vous \u00eates fier de votre travail et vous avez quelques beaux projets CI/CD \u00e0 votre actif.\nLes environnements techniques recherch\u00e9s ? : [Linux et Windows] ; [Jenkins ; Ansible ; GitLabCI ; Terraform ; Kubernetes] ; [AWS ; Azure ; GCP] ...\nLa cible ? Une offre de service infrastructure ainsi qu'un centre de comp\u00e9tences multisites qui tend \u00e0 industrialiser la m\u00e9thodologie DevOps au sein de ses \u00e9quipes ainsi qu'\u00e0 proposer un service cloud \u00e0 haute valeur ajout\u00e9e.\nLes pr\u00e9requis ? L'anglais, indispensable, l'aisance technique et la maitrise de l'outillage CI/CD.\nA vos CV ! :)\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "R"
            ],
            "DataBase": [],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [],
            "MachineLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [
                "AWS",
                "Azure"
            ],
            "DevTools": [
                "Git",
                "Jenkins"
            ],
            "Os": [
                "Linux",
                "Windows"
            ],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [
                "Ansible",
                "Kubernetes"
            ],
            "InfrastructureAsCode": [
                "Terraform"
            ],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [
                "Kubernetes"
            ],
            "Collaboration": [],
            "Other": [
                "DevOps",
                "Cloud",
                "CI/CD"
            ],
            "FrSoftSkills": [
                "Travail d'\u00e9quipe"
            ],
            "EnSoftSkils": []
        },
        "details": {
            "JobDetail": [
                "Confirm\u00e9"
            ],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "title": "DevOps Engineer",
        "company": "zefa",
        "location": "Strasbourg, Grand Est, France",
        "link": "https://fr.linkedin.com/jobs/view/devops-engineer-at-zefa-3901115060?position=14&pageNum=0&refId=NuDbZkBPOnBALTaaBOYlpw%3D%3D&trackingId=7Lqd8pCQXu2hvMEQe1EUEA%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "DevOps Engineer\nFreelance - 12 months\nFrance Strasburg\nProject experience:\n\u2022 Develop tools and infrastructures in order to support Build &\nDeployment activities;\n\u2022 Manage, support and improve Build and Deployment pipelines;\n\u2022 Effectively implement a DevOps strategy and associated\nprocesses\nKnowledge and Skills required:\n\u2022 Thorough understanding of the SDLC, and knowledge of Agile\nmethodologies;\n\u2022 Knowledge of automation tools used to implement continuous\nintegration and continuous delivery;\n\u2022 Working knowledge of known DevOps tools like Git, Jenkins,\nAnsible, Artifactory, Sonarqube, Openshift;\n\u2022 Knowledge of scripting languages (like Groovy);\n\u2022 Knowledge on mobile device technologies (React Native,\nxCode) and Operating systems (Android, iOS) would be\nadvantageous;\nThis is a 2 stage process, with an ideal start date in MAY.\nLet's connect and explore this project together!\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "R"
            ],
            "DataBase": [],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [],
            "MachineLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [],
            "DevTools": [
                "Git",
                "Jenkins"
            ],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [
                "Ansible"
            ],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [
                "OpenShift"
            ],
            "Collaboration": [],
            "Other": [
                "DevOps"
            ],
            "FrSoftSkills": [],
            "EnSoftSkils": []
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "title": "DevOps Engineer \u2013 Nice, France (H/F)",
        "company": "Astek",
        "location": "Nice, Provence-Alpes-C\u00f4te d'Azur, France",
        "link": "https://fr.linkedin.com/jobs/view/devops-engineer-%E2%80%93-nice-france-h-f-at-astek-3879635895?position=15&pageNum=0&refId=NuDbZkBPOnBALTaaBOYlpw%3D%3D&trackingId=hGj84aAdfHKHQ03YP%2FIeTQ%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "CDI\nNice - France\nPubli\u00e9e il y a 2 jours\nLe Groupe Astek\nCe Que Nous Allons Accomplir Ensemble :\nRejoindre une \u00e9quipe dans les domaines du transport et du tourisme sur des projets ambitieux dans lesquels la satisfaction clients et les solutions \u00e0 valeur ajout\u00e9e jouent un r\u00f4le crucial.\nVotre Mission, Si Vous L\u2019acceptez :\nComprendre les exigences du client ;\nEncourager et construire des processus automatis\u00e9s dans la mesure du possible\nContr\u00f4ler les processus tout au long du cycle de vie pour s\u2019assurer de leur respect\nD\u00e9finir et param\u00e9trer les processus de d\u00e9veloppement, de test, de mise en production, de mise \u00e0 jour et de support pour le fonctionnement DevOps.\nVotre Future \u00c9quipe :\nVenez rejoindre une \u00e9quibe ambitieuse et dynamique dans un environnement international\nVotre stack de jeu\nAnsible, Python, Jenkins, Docker et Kubernetes\nLes Petits Plus Du Projet :\nVous \u00e9voluerez au sein d\u2019une \u00e9quipe impliqu\u00e9e et r\u00e9active dans un environnement international et interviendrez sur des projets passionnants et enrichissants.\nVous ?\nDipl\u00f4m\u00e9(e) d\u2019une \u00e9cole d\u2019ing\u00e9nieur ou \u00e9quivalent de niveau Bac+5. Vous justifiez id\u00e9alement d\u2019une exp\u00e9rience sur un poste similaire ;\nVotre personnalit\u00e9, votre esprit d\u2019\u00e9quipe, votre autonomie, votre relationnel, votre rigueur, votre cr\u00e9ativit\u00e9 ainsi que votre curiosit\u00e9 seront des atouts essentiels pour mener \u00e0 bien vos missions sur le projet ;\nVous maitrisez les comp\u00e9tences techniques backend de base : Python, Kubernetes, Jenkins, Docker,\u2026\nAstek\nCr\u00e9\u00e9 en France en 1988, Astek est un acteur mondial de l\u2019ing\u00e9nierie et du conseil en technologies. Fort de son expertise dans de nombreux secteurs industriels et tertiaires, Astek accompagne ses clients internationaux dans le d\u00e9ploiement intelligent de leurs produits et de leurs services, et dans la mise en \u0153uvre de leur transformation digitale.\nDepuis sa cr\u00e9ation, le Groupe a fond\u00e9 son d\u00e9veloppement sur une forte culture d\u2019entrepreneuriat et d\u2019innovation, et sur l\u2019accompagnement et la mont\u00e9e en comp\u00e9tence de\nses 7800 collaborateurs\nqui s\u2019engagent chaque jour \u00e0 promouvoir la compl\u00e9mentarit\u00e9 entre les technologies num\u00e9riques et l\u2019ing\u00e9nierie des syst\u00e8mes complexes.\nRejoignez un Groupe en fort d\u00e9veloppement en France et \u00e0 travers le monde ayant r\u00e9alis\u00e9 un chiffre d\u2019affaires de 600 M\u20ac en 2023.\nTous les d\u00e9tails sur le Groupe sur le site https://astekgroup.fr. Et vous pouvez aussi nous suivre sur notre blog : https://blog.groupeastek.com.\nRencontrons-nous\nKillian, notre Talent Acquisition Officer, vous contactera afin de faire un point avec vous.\nEnsuite, Vous \u00c9changerez Avec :\nvotre futur manager (futur N+1) afin de discuter de ASTEK, votre parcours, vos attentes et la mission ;\nvotre directeur d\u2019agence pour valider votre int\u00e9r\u00eat pour le poste et vous pr\u00e9senter les \u00e9l\u00e9ments contractuels.\nNos Plus\nAstek est green et fait b\u00e9n\u00e9ficier ses salari\u00e9s d\u2019une indemnit\u00e9 kilom\u00e9trique v\u00e9lo\nUne politique CARE sur-mesure d\u00e9ploy\u00e9e par nos \u00e9quipes RH pour nos collaborateurs (https://astekgroup.fr/engagements)\nNotre charte de la Diversit\u00e9\nBienvenue dans la team ! Allez-y, maintenant c\u2019est \u00e0 vous de jouer !\nMots-cl\u00e9s :\ndevops \u2013 ing\u00e9nieur \u2013 ing\u00e9nieure \u2013 consultant \u2013 consultante \u2013 terraform \u2013 ansible \u2013 python\nCaract\u00e9ristiques de l'emploi\nCat\u00e9gorie Ing\u00e9nieur\nJob Industry Distribution / Services Internet, Transports Terrestres\nPostuler en ligne\nNom *\nPr\u00e9nom *\nEmail *\nUn email valide est requis.\nT\u00e9l\u00e9phone *\nUn num\u00e9ro de t\u00e9l\u00e9phone valide est requis.\nJoindre un CV *\nMots-cl\u00e9s :\ndevops \u2013 ing\u00e9nieur \u2013 ing\u00e9nieure \u2013 consultant \u2013 consultante \u2013 terraform \u2013 ansible \u2013 python\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "R",
                "Go"
            ],
            "DataBase": [],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [],
            "MachineLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [],
            "DevTools": [
                "Git",
                "Docker",
                "Jenkins"
            ],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [
                "Ansible",
                "Kubernetes"
            ],
            "InfrastructureAsCode": [
                "Terraform"
            ],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [
                "Docker",
                "Kubernetes"
            ],
            "Collaboration": [],
            "Other": [
                "DevOps"
            ],
            "FrSoftSkills": [
                "Cr\u00e9ativit\u00e9"
            ],
            "EnSoftSkils": []
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [
                "CDI"
            ],
            "Salary": [],
            "Level": [
                "Bac+5"
            ],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "title": "Data & Cloud Engineer (H/F)",
        "company": "fifty-five",
        "location": "Paris, \u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/data-cloud-engineer-h-f-at-fifty-five-3910028674?position=16&pageNum=0&refId=NuDbZkBPOnBALTaaBOYlpw%3D%3D&trackingId=8mWgqi050hRhEboDwNYoiA%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Data & Cloud Engineer\nfifty-five est une data-company d'un genre nouveau qui aide les marques \u00e0 exploiter les donn\u00e9es pour am\u00e9liorer le marketing, les m\u00e9dias et l'exp\u00e9rience client gr\u00e2ce \u00e0 une combinaison de services de conseil et de technologie sp\u00e9cialis\u00e9s.\nEn tant que pilier data et marketing du Brandtech Group, nous offrons des services qui combinent le conseil en strat\u00e9gie, les services de cloud, le conseil en m\u00e9dia et l'exp\u00e9rience client.\nfifty-five, c'est plus de 400 experts du num\u00e9rique. Des digital consultants, des sp\u00e9cialistes du tracking et du m\u00e9dia, des ing\u00e9nieurs et des data scientists, travaillent tous en \u00e9troite collaboration pour fournir des conseils marketing de haut niveau et une assistance technique aux marques, dans tout type d'industrie, partout dans le monde.\nPartenaire des annonceurs de la collecte \u00e0 l'activation et l'exploitation des donn\u00e9es, nous aidons les organisations \u00e0 devenir de v\u00e9ritables entit\u00e9s omnicanales ma\u00eetrisant l'efficacit\u00e9 de leur \u00e9cosyst\u00e8me digital et ses synergies avec le monde physique.\nBas\u00e9 \u00e0 Paris, nous op\u00e9rons sur 3 fuseaux horaires depuis nos 10 bureaux, situ\u00e9s \u00e0 Paris, Londres, Gen\u00e8ve, Milan, Shanghai, Hong Kong, Shenzhen, Taipei, Singapour et New York. fifty-five attache une importance particuli\u00e8re au bien-\u00eatre de ses collaborateurs, ce qui lui a permis de figurer dans le classement Best Workplaces France en 2018.\nContexte :\nL'\u00e9quipe d'ing\u00e9nierie d\u00e9veloppe et met en \u0153uvre les solutions techniques permettant la r\u00e9alisation de pipelines de donn\u00e9es et l'impl\u00e9mentation de data platform pour nos clients : r\u00e9cup\u00e9ration de datas sur de multiples sources de donn\u00e9es (APIs, files, etc.), data cleaning, data processing, automation et monitoring de l'ensemble. L'\u00e9quipe s'appuie sur des technologies r\u00e9centes (docker, kubernetes, terraform, notebooks, etc.) et met en place ses projets dans les diff\u00e9rents clouds du march\u00e9 (GCP, Azure, AWS...).\nMission :\nNous sommes \u00e0 la recherche d'une personne capable de r\u00e9aliser des projets techniques pour r\u00e9pondre aux besoins de nos clients (par exemple: syst\u00e8me de recommandations de produits, d\u00e9tection d'anomalies, ranking). Les activit\u00e9s vont du chiffrage et du sizing technique \u00e0 la mise en \u0153uvre des architectures, en passant par la revue des sp\u00e9cifications fonctionnelles et la production de code. Le Data & Cloud Engineer sera \u00e9paul\u00e9 par un Lead dans ses missions. Il sera \u00e9galement amen\u00e9 \u00e0 participer \u00e0 la R&D et \u00e0 accompagner les \u00e9quipes transverses dans la mise en place d'outils de travail internes (librairies pour les data scientists, environnement Notebooks pour les data analysts et data scientists, d\u00e9veloppement de frameworks sur diff\u00e9rents cloud providers, etc.).\nNous souhaitons trouver la bonne personne pour faire \u00e9voluer ou cr\u00e9er de nouvelles solutions dans ce cadre. Les missions comprennent aussi bien du prototypage rapide pour des d\u00e9monstrateurs, que de la production de code robuste qui tourne en production tous les jours.\nComp\u00e9tences et exp\u00e9riences :\n2 ans d'exp\u00e9rience en tant que Data Engineer\nMa\u00eetrise de Python, SQL\nMa\u00eetrise des environnements Cloud. Id\u00e9alement certifi\u00e9 GCP, Azure ou AWS\nBonne connaissance de Docker/Kubernetes\nBonne connaissance d'au moins un data warehouse (BigQuery, Snowflake, etc)\nConnaissance autour des Notebooks (Jupyter)\nA l'aise avec des concepts li\u00e9s aux APIs (OAuth, REST, etc.)\nA l'aise avec les notions d'Infrastructure as Code (Terraform)\nAu courant des pratiques GitOps et connaissances des concepts autour du CI/CD\nLa ma\u00eetrise d'un orchestrateur, comme Apache Airflow, est un plus\nEsprit d'\u00e9quipe (collaborer aux tests unitaires, revue de code, partage de code, sprints)\nBon niveau en fran\u00e7ais et en anglais\nA d\u00e9j\u00e0 travaill\u00e9 en mode projet avec des interlocuteurs vari\u00e9s (consultant, data analyst, data scientist)\nUne exp\u00e9rience en marketing digital est un plus\nNous proposons :\nun bureau au centre de Paris avec terrasse et jardin\nun environnement multiculturel avec des collaborateurs aux nationalit\u00e9s multiples (France, Royaume-Uni, Etats-Unis, Chine, Tunisie, Italie et plus)\ndes projets avec nos bureaux \u00e0 Londres, Hong Kong, New York, Shanghai, Gen\u00e8ve, Shenzhen et Taipei\ndes TGIF et supers soir\u00e9es\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "R"
            ],
            "DataBase": [
                "SQL"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [
                "Apache Airflow"
            ],
            "MachineLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [
                "AWS",
                "Azure"
            ],
            "DevTools": [
                "Git",
                "Docker"
            ],
            "Os": [],
            "DBMS": [
                "Snowflake",
                "Snowflake",
                "BigQuery"
            ],
            "SoftBigDataProcessing": [],
            "Automation": [
                "Kubernetes",
                "Airflow"
            ],
            "InfrastructureAsCode": [
                "Terraform"
            ],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [
                "Docker",
                "Kubernetes"
            ],
            "Collaboration": [],
            "Other": [
                "Cloud",
                "CI/CD"
            ],
            "FrSoftSkills": [
                "Collaboration",
                "Organisation"
            ],
            "EnSoftSkils": [
                "Collaboration"
            ]
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s",
                "2",
                "2",
                "2"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "title": "Cloud Engineer",
        "company": "PRIMA Partners Global",
        "location": "Greater Paris Metropolitan Region",
        "link": "https://fr.linkedin.com/jobs/view/cloud-engineer-at-prima-partners-global-3913218700?position=17&pageNum=0&refId=NuDbZkBPOnBALTaaBOYlpw%3D%3D&trackingId=I1tIcBd3aJ8SyZ0JhDhJXg%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Cloud Engineer | ESSENTIAL SKILL\n:\nFrench language skills (Written & Verbal)\nengineering experience, including Cloud Migrations\nto work across Amazon Web Services (AWS), Google Cloud Platform & Azure environments.\nin automation/scripting languages such as Python/Bash/PowerShell & CI/CD pipeline tools like GitLabCI/Jenkins\nof Infrastructure as code tools like Terraform/CloudFormation\nunderstanding of security best practices and hands-on experience with security tools\nanalytical and problem-solving abilities\n& End User Management experience\ncommunication skills (Written & Verbal)\nCloud Engineer | OVERVIEW\n:\nOur client require a Permanent In-House Cloud Engineer with strong project management skills to lead Cloud initiatives, collaborating closely with IT and Digital stakeholders.\nYour responsibilities will include designing, implementing, and maintaining Cloud infrastructures across AWS, GCP, and Azure platforms, optimizing performance, and deploying automation solutions. You willll oversee outsourced workstreams, monitor Cloud infrastructure performance, and stay updated on Cloud Computing and DevOps trends.\nProficiency in configuring CI/CD pipelines using tools like Jenkins, CircleCI, or TravisCI, and experience with containerization and orchestration technologies like Docker and Kubernetes is essential. Knowledge of infrastructure as code tools such as Terraform and CloudFormation is also required.\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "R",
                "Go",
                "Bash"
            ],
            "DataBase": [],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [],
            "MachineLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [
                "AWS",
                "Azure",
                "Google Cloud Platform"
            ],
            "DevTools": [
                "Git",
                "Docker",
                "Jenkins"
            ],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [
                "Kubernetes"
            ],
            "InfrastructureAsCode": [
                "Terraform",
                "CloudFormation"
            ],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [
                "Docker",
                "Kubernetes"
            ],
            "Collaboration": [],
            "Other": [
                "DevOps",
                "Cloud",
                "CI/CD"
            ],
            "FrSoftSkills": [
                "Communication"
            ],
            "EnSoftSkils": [
                "Communication",
                "Initiative"
            ]
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "title": "DevOps Engineer",
        "company": "AgileBio",
        "location": "Paris, \u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/devops-engineer-at-agilebio-3913553806?position=18&pageNum=0&refId=NuDbZkBPOnBALTaaBOYlpw%3D%3D&trackingId=uFdTNYDafKLTKCdkqxKOSw%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Company Description\nAgileBio is a scientific IT solutions company based in Paris. We specialize in providing biometric, RFID, and traceability solutions for laboratories, R&D, and the biotech and pharmaceutical industries. Our main product, LabCollector, is a full-web LIMS (Laboratory Information Management System) that offers easy deployment options, including on-site installations, unlike traditional SaaS solutions.\nRole Description\nThis is a full-time on-site role for a DevOps Engineer at AgileBio. As a DevOps Engineer, you will be responsible for tasks such as infrastructure as code (IaC) development, software development, continuous integration, system administration, and Linux management. You will work closely with cross-functional teams to support the deployment and maintenance of AgileBio's IT solutions.\nQualifications\nInfrastructure as code (IaC) development, software development, and continuous integration skills\nSystem administration and Linux management experience\nExperience with containerization technologies such as Docker and Kubernetes\nKnowledge of cloud platforms on AWS\nKnowledge on Jenkins\nExpert in Linux\nCompetence in IOT, TCP/IP and networks\nStrong problem-solving and troubleshooting abilities\nAbility to work effectively in a collaborative, agile environment\nExcellent communication and interpersonal skills\nRelevant certifications such as AWS Certified DevOps Engineer or Red Hat Certified Engineer (RHCE) are a plus\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "R"
            ],
            "DataBase": [],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [],
            "MachineLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [
                "AWS"
            ],
            "DevTools": [
                "Docker",
                "Jenkins"
            ],
            "Os": [
                "Linux"
            ],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [
                "Kubernetes"
            ],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [
                "Docker",
                "Kubernetes"
            ],
            "Collaboration": [
                "Teams"
            ],
            "Other": [
                "DevOps",
                "Cloud"
            ],
            "FrSoftSkills": [
                "Communication"
            ],
            "EnSoftSkils": [
                "Communication",
                "Interpersonal Skills"
            ]
        },
        "details": {
            "JobDetail": [
                "Full"
            ],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "title": "Cloud Engineer (H/F)",
        "company": "Thales Digital Identity and Security",
        "location": "La Ciotat, Provence-Alpes-C\u00f4te d'Azur, France",
        "link": "https://fr.linkedin.com/jobs/view/cloud-engineer-h-f-at-thales-digital-identity-and-security-3908299124?position=19&pageNum=0&refId=NuDbZkBPOnBALTaaBOYlpw%3D%3D&trackingId=Wvl5HMHyOwr3w90rfooKEQ%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "QUI ETES-VOUS ?\nVous poss\u00e9dez une premi\u00e8re exp\u00e9rience professionnelle sur ce m\u00e9tier.\nVos exp\u00e9rience et expertises vous permettent de conna\u00eetre :\nles approches DevSecOps de projets de d\u00e9veloppement logiciel ;\nle d\u00e9veloppement de pipelines GitlabCI ou Jenkins ;\nles outils de qualim\u00e9trie et de s\u00e9curit\u00e9, ainsi que leur automatisation dans les pipelines ;\nle d\u00e9veloppement de pipelines permettant le delivery d'applications ;\nle deploiment de services kubernetes.\ndes connaissances dans le Cloud\nVos comp\u00e9tences techniques :\nd\u00e9veloppement de pipelines (Gitlab CI, Jenkins) ;\nd\u00e9veloppement d\u2019\u00e9tapes types permettant d\u2019\u00eatre r\u00e9utilis\u00e9e au sein de pipeline (SAST, DAST, Code Quality\u2026)\nKubernetes setup, management and tools\nHelm v2 & v3\nConnaissance des infrastructures informatiques, r\u00e9seau, stockage et contain\u00e9risation Docker\nBonne connaissances des pratiques de Linux\nConnaissance des outils de gestion de configuration (Git)\nVos soft skills :\nAutonome, curieux et team player\nCapacit\u00e9 \u00e0 apprendre rapidement et \u00e0 s\u2019adapter \u00e0 de nouvelles technologies, aux outils et \u00e0 l'organisation\nCE QUE NOUS POUVONS ACCOMPLIR ENSEMBLE :\nVenez rejoindre le Digital Hub de l'Engineering Competence Center France (ECCF) de Thales, \u00e0 La Ciotat !\nSp\u00e9cialis\u00e9e dans les technologies de transformation digitale, cette \u00e9quipe dynamique et en pleine croissance s'int\u00e8gre dans les projets des diff\u00e9rentes unit\u00e9s de Thales : D\u00e9fense, Spatial, A\u00e9ronautique, Identit\u00e9 et S\u00e9curit\u00e9 Num\u00e9rique. Elle met en oeuvre, au sein des projets op\u00e9rationnels, ses comp\u00e9tences d'architecture et de d\u00e9veloppement de micro-services, de cloud design, de pipelines automatis\u00e9es, de devops et de cybers\u00e9curit\u00e9, pour acc\u00e9l\u00e9rer les transformations des logiciels vers ces technologies modernes.\nEn nous rejoignant sur ce poste, vous aurez le r\u00f4le d'Ing\u00e9nieur DevSecOps.\nVous int\u00e9grerez une squad agile en charge de la mise en place et du maintien en condition op\u00e9rationnelle des chaines d'int\u00e9gration et de delivery continues et automatis\u00e9es (CICD) d'un projet phare de nos activit\u00e9s spatiale.\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "R"
            ],
            "DataBase": [],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [],
            "MachineLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [],
            "DevTools": [
                "Git",
                "Docker",
                "Jenkins"
            ],
            "Os": [
                "Linux"
            ],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [
                "Kubernetes"
            ],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [
                "Docker",
                "Kubernetes"
            ],
            "Collaboration": [],
            "Other": [
                "DevOps",
                "Cloud"
            ],
            "FrSoftSkills": [
                "Organisation"
            ],
            "EnSoftSkils": []
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "title": "DevOps Engineer",
        "company": "zefa",
        "location": "Strasbourg, Grand Est, France",
        "link": "https://fr.linkedin.com/jobs/view/devops-engineer-at-zefa-3901115329?position=20&pageNum=0&refId=NuDbZkBPOnBALTaaBOYlpw%3D%3D&trackingId=JH5B1uQ3B012%2FtmyFc%2FUpw%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "\u2022Develop tools and infrastructures in order to support Build &\nDeployment activities;\n\u2022 Manage, support and improve Build and Deployment pipelines;\n\u2022 Effectively implement a DevOps strategy and associated\nprocesses\n\u2022Minimum 6 years of IT professional experience;\n\u2022 Minimum 3 years of relevant professional experience in a\nDevOps role, involved in maintaining DevOps tools & platform.\n\u2022Thorough understanding of the SDLC, and knowledge of Agile\nmethodologies;\n\u2022 Knowledge of automation tools used to implement continuous\nintegration and continuous delivery;\n\u2022 Working knowledge of known DevOps tools like Git, Jenkins,\nAnsible, Artifactory, Sonarqube, Openshift;\n\u2022 Knowledge of scripting languages (like Groovy);\n\u2022 Knowledge on mobile device technologies (React Native,\nxCode) and Operating systems (Android, iOS) would be\nadvantageous;\n\u2022 Technical writing skills would be an advantage\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "R"
            ],
            "DataBase": [],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [],
            "MachineLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [],
            "DevTools": [
                "Git",
                "Jenkins"
            ],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [
                "Ansible"
            ],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [
                "OpenShift"
            ],
            "Collaboration": [],
            "Other": [
                "DevOps"
            ],
            "FrSoftSkills": [],
            "EnSoftSkils": []
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "title": "DevOps Engineer",
        "company": "Coders Connect",
        "location": "Lyon, Auvergne-Rh\u00f4ne-Alpes, France",
        "link": "https://fr.linkedin.com/jobs/view/devops-engineer-at-coders-connect-3905662055?position=21&pageNum=0&refId=NuDbZkBPOnBALTaaBOYlpw%3D%3D&trackingId=aEsdbErO948rAtGcjIb0VA%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "This\nhybrid role\nis based in\nLyon\n, France, allowing you to split your time between working from home and our office in this culturally rich city. Proficiency in\nEnglish\nis essential, ensuring effective communication within our diverse and collaborative work environment. This arrangement supports a balanced lifestyle and fosters productivity.\nCoders Connect\nis thrilled to announce its partnership with a leading provider of innovative B2B SaaS solutions. This collaboration marks a pivotal moment in redefining the assessment of building materials, guiding decisions for sustainable transportation infrastructure. With a commitment to cutting-edge technology and unwavering core values of innovation, quality, collaboration, and customer satisfaction, our partner empowers stakeholders across the construction value chain in navigating the digital era and progressing towards net-zero objectives.\nPosition Overview:\nAs a\nDevOps Engineer,\nyou will hold a critical role in a dynamic, multicultural, and internationally diverse environment. With English as the working language, you will operate within an agile framework, primarily focused on Kanban. Your responsibilities will include automating cloud-native solutions on platforms such as AWS, managing deployments through Kubernetes, and spearheading efforts to boost infrastructure reliability and performance. By leading a skilled team of engineers and offering cross-functional technical guidance, you will ensure that our platform operates flawlessly and consistently stays ahead in technological innovation and efficiency.\nResponsibilities:\nCloud-Native Development and Automation:\nDesign, implement, and manage cloud-native solutions in line with architectural standards.\nUse Infrastructure as Code (IaC) tools such as AWS CDK, AWS CloudFormation, or Terraform to enhance deployment processes.\nAutomate CI/CD pipelines using tools like GitLab CI/CD and manage container orchestration with Kubernetes to improve service deployment and scalability.\nAdvanced Observability in Cloud-Native Environments:\nImplement and manage observability frameworks tailored for cloud-native applications.\nUtilize tools and standards like OpenSearch, Grafana, OpenTelemetry, and OpenTracing to enhance monitoring and application performance optimization.\nCreate and manage dashboards and alerts based on key performance metrics, using observability data to proactively address issues and guide architectural and operational improvements.\nSupport and Collaboration:\nAssist and guide a team of engineers in adhering to best practices, clarifying specifications, and fostering professional growth.\nWork closely with cross-functional teams to ensure that infrastructure and backend developments align with product and design requirements, contributing to the platform\u2019s strategy and innovation.\nContinuous Learning:\nStay updated on the latest trends and best practices in cloud architecture, DevOps, and observability.\nParticipate in internal training sessions, workshops, and code reviews.\nRequirements\nEssential:\nBachelor's degree in Computer Science or equivalent.\nAt least 3 years' experience in cloud architecture, cloud-native development, or operations, preferably with AWS.\nMinimum 2 years' experience with observability tools like OpenSearch and OpenTracing.\nExperience in building cloud-native platforms using Kubernetes on AWS.\nFamiliarity with agile development methodologies such as Kanban or SCRUM.\nProficiency in TypeScript or Python.\nStrong experience with GitLab CI/CD pipelines and AWS core services.\nNice to Have:\nUnderstanding of SaaS application development.\nKnowledge of database systems like PostgreSQL, MongoDB, Redis.\nExperience as a Full Stack Developer using Node.js, Java, or Python.\nExperience with workflow automation leveraging AI or LowCode solutions.\nImportant Soft Skills:\nExcellent communication skills for effective collaboration with external developers and explaining technical concepts to non-technical stakeholders.\nAbility to prioritise and delegate tasks efficiently.\nProficient in conducting code reviews and providing constructive feedback.\nSkilled in creating a positive and collaborative team environment.\nStrong organizational skills to manage multiple tasks and coordinate smoothly with external teams.\nCapable of handling project documentation thoroughly and accurately.\nProficient in presenting technical ideas to both technical and non-technical audiences.\nBenefits\nCompetitive salary and performance-based incentives.\nComprehensive benefits package.\nAccess to online learning platform.\nParticipation in tech conference.\nOpportunities for professional development and career growth within a dynamic and innovative company.\nA collaborative and inclusive work environment that values creativity and teamwork.\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "Java",
                "Scala",
                "R",
                "Go"
            ],
            "DataBase": [
                "SQL",
                " MongoDB"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [],
            "MachineLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [
                "AWS"
            ],
            "DevTools": [
                "Git"
            ],
            "Os": [],
            "DBMS": [
                "PostgreSQL"
            ],
            "SoftBigDataProcessing": [],
            "Automation": [
                "Kubernetes"
            ],
            "InfrastructureAsCode": [
                "Terraform",
                "CloudFormation"
            ],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [
                "Kubernetes"
            ],
            "Collaboration": [
                "Teams"
            ],
            "Other": [
                "DevOps",
                "Backend Development",
                "Cloud",
                "CI/CD"
            ],
            "FrSoftSkills": [
                "Communication",
                "Collaboration"
            ],
            "EnSoftSkils": [
                "Communication",
                "Teamwork",
                "Creativity",
                "Collaboration",
                "Organization"
            ]
        },
        "details": {
            "JobDetail": [
                "Full"
            ],
            "TypeContract": [],
            "Salary": [
                "Salary",
                "Package"
            ],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "title": "Infrastructure / Cloud Run Engineer",
        "company": "DataGalaxy",
        "location": "Lyon, Auvergne-Rh\u00f4ne-Alpes, France",
        "link": "https://fr.linkedin.com/jobs/view/infrastructure-cloud-run-engineer-at-datagalaxy-3877318102?position=22&pageNum=0&refId=NuDbZkBPOnBALTaaBOYlpw%3D%3D&trackingId=3fZ7p2gl1ebfzwXsEP8QJQ%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Who we are:\nFounded in Lyon, FR in 2015, DataGalaxy is the industry's first Data Knowledge Catalog helping organizations understand how their entire business runs on data. Our data management platform is dedicated to providing user-friendly metadata mapping, management, and knowledge sharing to support organizational data governance and literacy.\nDataGalaxy's Data Knowledge Catalog helps business users accelerate processes, reduce costs, and ensure regulatory compliance by providing an all-in-one data management and data governance platform. Our Data Catalog includes API to ease pre-existing data integration, AI services to automate data classification, and data lineage tracking to visualize data's entire lifecycle journey.\nFollowing our recent growth, DataGalaxy is blasting off to new heights! We've officially raised over $10M in funding and in 2023, DataGalaxy officially entered the American market. We're thrilled to continue expanding our active client base in the USA.\nOur mission:\nTo remain at the forefront of revolutionizing the modern business data catalog by empowering data professionals and business users through increasing data knowledge and providing an all-inclusive understanding of how businesses run on data. We're passionate about helping organizations facilitate rich collaboration, manage data as an asset, and derive powerful, data-driven decision-making.\nOur values: Be intentional. Be clear. Be bold. Be humble.\nAre you interested in joining an organization that values teamwork, ambition, enthusiasm, and collaboration? Each DataGalaxian brings unique knowledge, skills, and points of view that help us create a truly well-rounded crew! We encourage unique ideas, inventive thinking, and independent perspectives so that we can achieve out-of-this-world results together!\nWho we're looking for:\nWe're hiring someone who is:\n\ud83d\udcab Ready to join a growing team\n\ud83d\udcab Passionate about data\n\ud83d\udcab Up-to-date with the latest industry news and developments\n\ud83d\udcab Organized, autonomous, and a team player!\nWe are seeking a highly skilled and experienced Infrastructure / Cloud Run Engineer to join our dynamic team. This role focuses on maintaining the reliability, security, and cost efficiency of our cloud infrastructure, with a particular emphasis on Kubernetes and AWS ecosystems. The ideal candidate will have a strong background in cloud computing, containerization, and infrastructure management.\nKey Responsibilities\nMaintain Run Reliability: Ensure high availability and reliability of our cloud infrastructure, particularly Kubernetes clusters and AWS and Azure services. Proactively monitor system health, perform troubleshooting, and apply patches and updates as needed\nProduction Instance Management: Efficiently create and delete production instances, ensuring smooth deployments and minimal downtime. Work with development teams to understand requirements and deliver scalable solutions\nSecurity Management: Implement and maintain robust security measures for our cloud infrastructure. This includes managing access controls, network security configurations, and continuous monitoring for vulnerabilities. Managing compliance and security efforts on infrastructure\nCost Optimization: Monitor and optimize cloud resource usage to ensure cost efficiency. Implement cost-saving measures without compromising on performance or reliability\nTool and Technology Expertise: Utilize a range of tools and technologies to manage and improve our cloud infrastructure, with a focus on Kubernetes, AWS and Azure, and related technologies\nSkills and Qualifications\nMust-Have:\nPractical experience with Kubernetes for orchestration and management of containerized applications\nDeep understanding of AWS services, especially EKS. Experience in designing, deploying, and managing AWS-based infrastructure\nFamiliarity with IAM in AWS for managing access controls and permissions\nUnderstanding of VPC concepts to manage network configurations within AWS\nExperience on compliance and security best practices\nNice to Have:\nExperience with Helm, Docker, and secret management tools\nProficiency in GitOps tools such as Flux or Argo CD for continuous deployment\nKnowledge of security scanning tools like Trivy\nExperience with artifact registries and infrastructure as code tools (e.g., Cluster API, Terraform, OpenTofu, Crossplane)\nFamiliarity with monitoring and visualization tools such as Prometheus and Grafana\nFamiliarity with using powershell scripting\nExposure to other cloud providers like GCP and OVH is beneficial\nCloud Providers:\nAWS (must): Specifically, hands-on experience with EKS and knowledge of autoscaling\nAzure: Experience with azure infrastructure deployments is a must\nGCP and OVH (nice to have): Experience with this platform will be considered an advantage\nAdditional Requirements\nExcellent problem-solving skills and the ability to work independently or as part of a team\nStrong communication skills, both written and verbal, to effectively collaborate with cross-functional teams\nA commitment to continuous learning and staying updated with the latest trends and technologies in cloud computing and infrastructure management\nAbility to work in English and French\n\ud83d\ude80What can you expect:\nOffices in the heart of Lyon and Paris, 10-15 minutes from the train stations\nFlexible working hours (\"forfait jour\")\nA real opportunity to join a French start-up that is a pioneer in its market \ud83d\ude80\nA chance to create your own career path with autonomy in multiple projects\nAn attractive remuneration according to your performance and your potential\nRemote work at will & 2.50\u20ac net / day\ud83d\udd25\nHealth insurance Apicil\nMeal vouchers (Swile card of 9\u20ac/day)\nPublic transport 50% reimbursement\nDaily coffee and snacks\nQuarterly team events and seminars\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Scala",
                "R",
                "Go"
            ],
            "DataBase": [],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [],
            "MachineLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [
                "AWS",
                "Azure"
            ],
            "DevTools": [
                "Git",
                "Docker"
            ],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [
                "Kubernetes"
            ],
            "InfrastructureAsCode": [
                "Terraform"
            ],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [
                "Docker",
                "Kubernetes"
            ],
            "Collaboration": [
                "Teams"
            ],
            "Other": [
                "Cloud"
            ],
            "FrSoftSkills": [
                "Communication",
                "Collaboration"
            ],
            "EnSoftSkils": [
                "Communication",
                "Teamwork",
                "Collaboration",
                "Organization"
            ]
        },
        "details": {
            "JobDetail": [
                "Remote"
            ],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "title": "DevOps Engineer",
        "company": "ALTEN",
        "location": "Valbonne, Provence-Alpes-C\u00f4te d'Azur, France",
        "link": "https://fr.linkedin.com/jobs/view/devops-engineer-at-alten-3886545184?position=23&pageNum=0&refId=NuDbZkBPOnBALTaaBOYlpw%3D%3D&trackingId=PksGCVMyGo6XNGYbhn0KJw%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "The\ngoal\nof a Service Reliability Engineer (SRE) or DevOps will be to accelerate Application teams\u2019 ability\nto reliably and consistently deliver applications by developing standardized automation to control, build, and deploy managed services.\nThe main\nresponsibility\nis to participate in the successful delivery of the end to end services with agreed SLAs to our customers by leveraging, improving, designing and implementing services that automate application provisioning.\nYou will:\nparticipate to the building of tools and processes to support the infrastructure.\nleverage scripting to build required automation and tools on an ad-hoc basis.\nactively interface with software developers, system engineers, project management and database administrators on projects.\nOther responsibilities include ongoing issues such as capacity planning, change management, problem management, incident management, release management and performance improvement. You\u2019ll troubleshoot and resolve issues quickly and effectively.\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "R",
                "Go"
            ],
            "DataBase": [],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [],
            "MachineLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [],
            "DevTools": [],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [
                "Teams"
            ],
            "Other": [
                "DevOps"
            ],
            "FrSoftSkills": [],
            "EnSoftSkils": []
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "title": "Cloud Security Engineer",
        "company": "Teads",
        "location": "Paris, \u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/cloud-security-engineer-at-teads-3752360703?position=24&pageNum=0&refId=NuDbZkBPOnBALTaaBOYlpw%3D%3D&trackingId=y396HxC7rgTUUlLS5Rumug%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Teads has an engineering team that brings together\n200+ talented individuals\nin 3 main locations (\nMontpellier, Paris, and Bucharest\n). We are organized in agile and autonomous\nfeature teams\nand share technical knowledge within several\ncommunities of practice\n.\nWe promote diversity and are committed to creating an inclusive environment to enable all employees to feel valued and respected, which fosters creativity and innovation by allowing constructive collaboration and open exchange of ideas.\nOur organization offers the opportunity for hybrid work, allowing for two days in the office and the option to work remotely for the remainder of the week. Additionally, we provide relocation packages for those who prefer to relocate to one of our engineering offices.\n\ud83d\udc49 Join a team of passionate people who build quality and responsible advertising, at scale!\nOur main Engineering challenges at Teads\nWorking in a very high-traffic environment (1.9 billion users per month, 100 billion events per day) with low latency and high availability constraints (2 million requests per second, responses in less than 150 milliseconds).\nRich and diverse tech stack and system architecture to optimize for performance, scalability, resiliency, and cost efficiency. We use mostly Scala and TypeScript, among others.\nManagement of large datasets with milliseconds order of magnitude access time, to compute in a near real-time complex auction resolution algorithm (18 million predictions per second).\nBuild efficient and easy-to-use web products used by thousands of users working for the world's most premium publishers, advertisers, and agencies.\nA fast-changing environment where we continuously collaborate with Product teams and constantly adapt our Cloud infrastructure for new features and Products.\nBring a wide diversity of profiles to the same level of quality and knowledge.\nWhat will you do?\nAs a\nCloud Security Engineer\n, your mission will be to:\nProvide technical leadership and consultation for infrastructure engineers and developers to ensure the secure deployment of technology\nAs part of a team, ensure the adoption of security architecture and engineering initiatives in order to effectively and securely support the organization in meeting specific business technology needs\nDrive consideration of cybersecurity tools and datasets to enhance detective and preventative control sets\nUnderstand technical security issues and the implications to Teads businesses and be able to communicate them to management\nUnderstand emerging security technologies and determine the appropriate use within business applications\nMaintain and enforce Teads cybersecurity policies and secure design baselines\nExecute and improve Teads Security architecture review process and ensure compliance for all business initiatives\nArchitect global programs that deploy strong security patterns and controls across applications and computing environments, while addressing security, business resiliency, privacy and compliance frameworks\nIdentify security vulnerabilities and guide developers and engineers in addressing these issues\nImprove architectural adoption through automation and efficiently use security tools to solve challenges at scale\nValidate reference architectures for security best practices and recommend changes to enhance security and reduce risk\nCollaborate with the corporate functions including Finance, HR, Legal and Privacy to ensure that Teads maintains a strong cybersecurity posture\nWhat will you bring to the team?\nProven hands-on experience securing cloud infrastructure\nProven hands-on experience securing global multi-cloud architectures from both compute and network infrastructure perspective\nProven hands-on experience securing operating systems\nProven hands-on experience with application security topics such as the OWASP top 10 and technical remediations required\nDetailed technical experience supporting and implementing SIEM & logging tools (Splunk, Kibana, Qradar)\nAbility to extract actionable intelligence from large volume aggregated log storage\nThorough understanding of Network and Compute architectures and, specifically the security aspects\nThorough understanding of compliance and regulatory frameworks and how they affect architecture designs and reviews\nGood verbal and written communication skills, specifically the ability to communicate within the context of the intended audience, whether that be senior executives or highly technical engineering resources.\nDetailed understanding of the threats faced by advertising and digital platforms organizations\nWorking knowledge of at least one programming language (Python, Go, Terraform etc.)\nWhy work at Teads?\nAt Teads, Product and Engineering work hand in hand and are aligned towards the same goal: to\nscale our business\nwhile continuing to create\nnew and exciting products\n.\nWe value team spirit, pragmatism, listening and we encourage initiatives.\nWe promote end-to-end development: \u201cYou build it, you run it, you monitor it\u201d.\nWe share knowledge and support with each other beyond any organizational boundary.\nWe fix issues during a blameless postmortem and learn from it so that it doesn\u2019t happen twice.\nWe are working together to create great engineering, but we are also supportive to promote a great work-life balance.\nWe Care About You\nSecurity & Savings: Attractive package providing financial peace of mind, including competitive compensation, profit-sharing, daily meal vouchers (Swile), family health insurance (Alan), and a personalized relocation package (if needed).\nCareer Development: Continuous investment in our employees' skills: in-house and external training, tech conference opportunities, internal mobility (individual contributor or management career ladder).\nLife Balance: A well-balanced work-life for our employees is one of our top priorities: 35+ days off per year, hybrid work (2-3 days remote work per week, more is open to discussion), fully covered parental leave, and reserved daycare places.\nWellness: Prioritizing employee well-being through premium work equipment, enjoyable work environment (work-life balance, team building events, summits), remote work subsidy, promoting Diversity & Inclusion with internal & external initiatives (women speaking groups, dedicated school partnerships), dedicated charitable time and sustainability actions (Eco Tree, subsidy for eco-mobility).\nDiscover more about our culture and benefits on our Engineering website.\nWhat are our recruitment process steps?\nWe want to get to know you and we try to give you the insight you need to make an informed decision to join us. For that, you can find all the information in our Engineering hiring process article!\nAbout Teads\nTeads operates a leading, cloud-based, omnichannel platform that enables programmatic digital advertising across a global ecosystem of quality digital media.\nAs an end-to-end solution, Teads\u2019 modular platform allows partners to leverage buy-side, sell-side, creative, data and AI optimization technologies. For advertisers and their agencies, Teads offers a single access point to buy the inventory of many of the world\u2019s best publishers and content providers.\nThrough exclusive global media partnerships, Teads enables advertisers and agencies to reach billions of unique monthly users in brand safe, responsible advertising environments, while improving the effectiveness and efficiency of digital ad transactions.\nTeads partners with the leading marketers, agencies and publishers through a team of 1,200+ people in 50 offices across more than 30 countries.\nWe're committed to creating a dynamic work environment that values diversity and inclusion, and represents employees across a variety of skill sets. We embrace contributions from all ages, sexes, races, ethnicities, religions, sexual orientations and gender identities.\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "Scala",
                "R",
                "Go"
            ],
            "DataBase": [],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [],
            "MachineLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [],
            "DevTools": [
                "Git"
            ],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [
                "Terraform"
            ],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [
                "Teams"
            ],
            "Other": [
                "Cloud"
            ],
            "FrSoftSkills": [
                "Communication",
                "Leadership",
                "Collaboration"
            ],
            "EnSoftSkils": [
                "Communication",
                "Leadership",
                "Creativity",
                "Collaboration",
                "Organization",
                "Initiative"
            ]
        },
        "details": {
            "JobDetail": [
                "Remote",
                "Full",
                "Senior"
            ],
            "TypeContract": [],
            "Salary": [
                "1.9"
            ],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "title": "DevOps / Cloud Engineer",
        "company": "ASTRELYA",
        "location": "\u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/devops-cloud-engineer-at-astrelya-3902688494?position=25&pageNum=0&refId=NuDbZkBPOnBALTaaBOYlpw%3D%3D&trackingId=bO8PEaJLvLn4NRYju%2BAvHA%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "ASTRELYA est un groupe de conseil et d\u2019expertise IT fond\u00e9 en 2017, pr\u00e9sent en France (Paris et r\u00e9gions) et en Suisse (Gen\u00e8ve). Aujourd'hui plus de 280 collaborateurs accompagnent nos clients dans l\u2019acc\u00e9l\u00e9ration et la transformation de leurs organisations.\nDans le cadre de notre d\u00e9veloppement, nous recherchons un\nDevOps / Cloud Engineer F/H\n.\nVos r\u00f4les et responsabilit\u00e9s :\nAm\u00e9liorer et optimiser les outils li\u00e9s \u00e0 la cha\u00eene de production\nAutomatisation de process / t\u00e2ches\nGestion des configurations\nAdministration des serveurs et outils\nSupport aux \u00e9quipes de d\u00e9veloppement\nMa\u00eetrise des process d\u2019int\u00e9gration continue / d\u00e9ploiement\nProposer des nouvelles pratiques et de nouvelles solutions technologiques.\nStack technique :\nCI/CD\n: Jenkins, Sonar, Gitlab, GitLab CI, Ansible\nConteneurisation d\u2019application & Orchestration :\nDocker, Docker Swarm, Kubernetes\nAWS : EC2, S3, ELM, r\u00f4le IAM, Cognito, Lamba\u2026\nCI/CD : mise en \u0153uvre, d\u00e9finition d\u2019architecture, int\u00e9gration avec Jenkins, Ansible\u2026\nComp\u00e9tences Techniques :\nDe formation Ing\u00e9nieur ou \u00e9quivalent, vous justifiez d\u2019une exp\u00e9rience de 4 ans minimum en environnement DEVOPS / CLOUD sur la Stack ci-dessus.\nCI/CD : mise en \u0153uvre, d\u00e9finition d\u2019architecture, int\u00e9gration avec Jenkins, Ansible\u2026\nVous avez en plus une tr\u00e8s bonne connaissance de Linux Shell et d\u2019autres langages de programmation (Java, Python\u2026)\nConnaissance de l\u2019infrastructure as Code\nM\u00e9thodologie Agile / SAFE\nVous faites preuve de rigueur et d'esprit d'analyse, vous \u00eates force de proposition, vous \u00eates r\u00e9actif et avez le sens de l'\u00e9coute et du travail d'\u00e9quipe.\nPourquoi rejoindre ASTRELYA ?\nUne gestion de carri\u00e8re personnalis\u00e9e et un management de proximit\u00e9\nUne politique active de formations / certifications (technique, m\u00e9tier, leadership)\nUne offre vari\u00e9e de missions d\u2019expertise\nUn engagement RSE fort : Ecovadis Gold, Signataire de la charte pour la diversit\u00e9, du Pacte des Nations Unies et mise en place du M\u00e9c\u00e9nant de comp\u00e9tences\nUne campagne de cooptation attractive\nAfterwork et event r\u00e9guliers\nCette annonce vous correspond ? Postulez ! \ud83d\ude80\nTous nos postes sont ouverts aux personnes en situation de handicap.\nPour d\u00e9couvrir l\u2019ensemble de nos offres : ASTRELYA - Expertise en Transformation Digitale & IT\nCette annonce vous correspond ? Postulez ! \ud83d\ude80\nTous nos postes sont ouverts aux personnes en situation de handicap.\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "Java",
                "R",
                "Go"
            ],
            "DataBase": [],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [],
            "MachineLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [
                "AWS"
            ],
            "DevTools": [
                "Git",
                "Docker",
                "Jenkins"
            ],
            "Os": [
                "Linux"
            ],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [
                "Ansible",
                "Kubernetes"
            ],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [
                "Docker",
                "Kubernetes"
            ],
            "Collaboration": [],
            "Other": [
                "DevOps",
                "Cloud",
                "CI/CD"
            ],
            "FrSoftSkills": [
                "Travail d'\u00e9quipe",
                "Leadership",
                "Organisation"
            ],
            "EnSoftSkils": [
                "Leadership"
            ]
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s",
                "4",
                "4",
                "4"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "title": "DevOps/Cloud Engineer with IT Experience",
        "company": "WhiteLab Genomics",
        "location": "Paris, \u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/devops-cloud-engineer-with-it-experience-at-whitelab-genomics-3919802817?position=26&pageNum=0&refId=NuDbZkBPOnBALTaaBOYlpw%3D%3D&trackingId=UClWsukn%2FVCoeiLpwrD6Kg%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "WhiteLab Genomics\nwas founded with the belief that life-saving drugs should be accessible to all patients in need. United in our vision, we\u2019ve become a part of Y Combinator, French Tech 2030, Future 40 by Station F, and we\u2019ve been recognized by The Galien Foundation (\u201dBest Startup\u201d category), among other institutions at the forefront of technology. Today, we strive to become the leading expert in A.I. for genomic medicine, operating as the go-to partner for research and development.\nIn this critical and multifaceted role\n, you will lead the maintenance, development, and fortification of our AI/IT infrastructure for genomic medicine. We\u2019re in the process of setting up and scaling our Cloud infrastructure, and you\u2019ll play a valuable role in helping us scale up, leading the charge in optimizing our cloud services, streamlining workflows, and ensuring seamless integration with our DevOps practices and automation frameworks. To scale our current architecture to a higher level, you will help us identify our current bottlenecks, propose new Cloud based solutions, implement them, and help users to use them, allowing for enhanced efficiency. Fostering an atmosphere of productivity and teamwork, your expertise will drive our mission towards greater technological excellence and innovation.\nThis is an\nincredible opportunity\nto work on a diversity of engaging tasks in a hybrid role, forming the infrastructure of a vibrant start-up that seeks to make an impact on the future of healthcare \u2013- you'll play a crucial role in helping revolutionize genomic medicine with AI.\nOur Core Values:\nWe Believe that Care is Everything.\nWe Value our Collective Potential\nWe Cultivate Proactive Communication, Clarity and Respect\nWe Have a Can-Do Attitude\nWe Strive for Excellence\nWe\u2019re Eager to Meet You If\u2026\nProficiency in DevOps methodologies and tools, including proven experience in implementing robust continuous integration, continuous deployment (CI/CD) pipelines, infrastructure as code (IaC), and automated testing frameworks\nDemonstrated experience with coding (preferably Python) for automation tasks and infrastructure management and team interactions for orchestration tasks\nYou have expertise in cloud services (AWS, Azure, or Google Cloud), with a track record of designing, deploying, and managing scalable cloud-based infrastructure solutions tailored to business needs. Your comprehensive understanding of cloud services will enable seamless integration with DevOps practices and automation workflows\nYou have at least\n1 year of prior hands-on experience\nin managing IT equipment, tools, and issues at a tech company (preferably a tech start-up) and excel in administering SharePoint and email systems, ensuring smooth operations and user support\nYou possess great problem solving ability and can work autonomously\nYou have expertise in hardware, software, and network systems\nYou can manage pipelines, optimizing workflows for efficient deployment and delivery\nYour interpersonal skills allow you to collaborate effectively with cross-functional teams, including researchers, data scientists, business development professionals, and support functions\nYou can adapt to a dynamic and rapidly evolving industry, staying on top of the latest IT advancements\nYou have excellent verbal and written communication skills and have experience interfacing with stakeholders and users in English - French proficiency is a plus!\nYou\u2019re knowledgeable of standard practices for access control models, data protection regulations, IT security, and compliance protocols\nHere\u2019s How You\u2019ll Make an Impact\u2026\nYou\u2019ll provide strategic and technical leadership to all of our teams, guiding the development and implementation of innovative solutions towards orchestration, CI/CD and security standards\nYou\u2019ll set up and manage CI/CD pipelines to automate processes\nYou\u2019ll write automation scripts to automate routine orchestration tasks and manage our infrastructure efficiently\nYou\u2019ll design, deploy, and manage scalable cloud-based infrastructure solutions\nYou\u2019ll integrate cloud services with DevOps practices and automation workflows\nYou\u2019ll oversee the operation and maintenance of IT tools and infrastructure, ensuring reliability, performance, and security\nYou\u2019ll manage user roles, permissions, and access control for Cloud services, SharePoint, and email systems in compliance with data protection regulations\nYou\u2019ll administer and optimize SharePoint and other collaboration tools to enhance team productivity\nYou\u2019ll ensure all technology systems and platforms operate reliably and efficiently\nYou\u2019ll implement and maintain security policies and procedures, conducting regular audits to ensure compliance with industry standards\nYou\u2019ll provide technical support, resolving issues related to hardware, software, network problems, systems, and access permissions\nYou\u2019ll manage and maintain all IT equipment and tools, ensuring they\u2019re up to date and in good working condition\nYou\u2019ll lead Cloud and Helpdesk projects from inception to completion, ensuring projects are delivered on time, within budget, and meet quality standards\nYou\u2019ll implement best practices in IT operations and cybersecurity to safeguard company data and systems\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "Scala",
                "R",
                "Go"
            ],
            "DataBase": [],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [],
            "MachineLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [
                "AWS",
                "Azure"
            ],
            "DevTools": [],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [
                "Teams"
            ],
            "Other": [
                "DevOps",
                "ML",
                "Cloud",
                "CI/CD"
            ],
            "FrSoftSkills": [
                "Communication",
                "Leadership",
                "Collaboration"
            ],
            "EnSoftSkils": [
                "Communication",
                "Teamwork",
                "Problem Solving",
                "Leadership",
                "Collaboration",
                "Interpersonal Skills"
            ]
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "title": "Cloud Engineer",
        "company": "Equativ",
        "location": "Paris, \u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/cloud-engineer-at-equativ-3804533620?position=27&pageNum=0&refId=NuDbZkBPOnBALTaaBOYlpw%3D%3D&trackingId=GoeDZSf1GqxafEbArjRwwg%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "\ud83d\udc6b About the team\nAt Equativ, we\u2019re on a mission to develop advertising technologies that empower our customers to reach their digital business goals. This means that we rely on massively scalable, widely distributed, highly available, and efficient software systems; the platform deals with over 3 millions requests per second managed by 3,000 servers.\nOur innovation team based in Paris, Nantes, Limoges, Krakow and Berlin is composed of 100+ straightforward and energetic engineers working in an Agile environment and ready to tackle the most complex technical challenges.\nYour mission \ud83d\udc47\nWithin infra BU you will join the Platform department that strives to develop and deploy self-serve tooling to empower our RnD team.\nOur platform is gradually moving to a hybrid cloud platform. You will be joining as the second member of our cloud platform team:\nYou will help deliver a smooth transition of our RnD team to a hybrid cloud architecture.\nYou will be responsible for cloud governance and FinOps.\nYou will provide help to our engineering teams in order to optimize costs of our GCP components\nWhat you will do \u270f\ufe0f\nAs a Cloud engineer in our new cloud platform team your missions will be to:\nDesign and develop self-serve tooling for our engineering teams to transition and maintain their workloads to the cloud.\nDesign and instrumentalize Finops guidelines to manage the overall ROI of our cloud infrastructure.\nHelp design and develop our cost management framework to help teams optimize their operational ROI.\nPropagate best-practices and know-how on cloud services and architectural patterns.\nImplement terraform modules to support our IAC approach on the cloud.\nEvaluate the CO2 savings associated with optimizing our cloud infrastructure usage.\nAbout you \ud83d\udc4b\nMaster degree in Computer science or similar field of study.\n1+ years of System, Cloud or Software Engineering experience ideally in the web industry.\nAutonomous and innovative mindset.\nExperience in GCP cloud governance for production projects and collaboration within a 5+ engineering team.\nFluent with DevOps practices, specifically on Google Cloud Platform.\nInterested in the impact of technical decisions on business (finops approach) and environmental outcomes.\nWorking proficiency and communication skills in verbal and written English.\nNice to have:\nExperience in one or more of the following GCP topics: Finops, big data components for large datasets, Kubernetes administration.\nExperience working with IaC (Terraform or other).\nExperience in software development (Go, Python or equivalent).\nHow you'll grow \ud83d\ude80\nWithin 1 month:\nYou'll be just finishing your onboarding.\nYou'll probably have tackled a few small tasks with your peer.\nWithin 4 months:\nYou'll be trusted to review budget increases from development teams.\nYou'll be expected to propose small-scale optimisations on our cloud architecture.\nWithin 9 months:\nYou'll be in contact with most of the tech leads operating on GCP.\nYou'll be evolving our terraform architecture to deploy resources to the cloud.\nYou\u2019ll start getting a grasp on the AdTech business.\n\ud83d\udc4b About us\nEquativ is the new single name for Smart Adserver, DynAdmic, LiquidM and Nowtilus \u2014 four proven innovators in advertising technology. The vertically integrated company provides brand and privacy-safe solutions that empower its clients to achieve maximum impact while respecting the rights of consumers. The union combines client expertise and engineering excellence to serve the interests of both the supply- side and demand-side with equal professionalism and technical sophistication.\nHeadquartered in Paris and New York, Equativ operates globally with a team of more than 550 people in 20 offices. Equativ offers the market its own independent ad server, SSP, buyer tools, and media services to fulfill the promise of advertising technology. Learn more at Equativ.com.\nThe company is ranked on the Deloitte Technology Fast 500 EMEA and in the Financial Times\u2019 FT 1000: Europe\u2019s Fastest-Growing Companies.\nEquativ (formerly Smart AdServer) has been awarded the HappyIndex@Work label and is proud to be among the best companies in the ChooseMyCompany ranking, recognized for its flexible working environment.\nCome and lead the charge with us in building a transparent ecosystem based on quality!\n----------------------\nEquativ is an equal opportunity employer. Equal access to employment, services, and programs are available to everyone, regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity, or Veteran status. If you require reasonable accommodation throughout the application and/or interview process, please contact the recruitment team at ta-team@equativ.com\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "Scala",
                "R",
                "Go"
            ],
            "DataBase": [],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [],
            "MachineLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [
                "Google Cloud Platform"
            ],
            "DevTools": [
                "Git"
            ],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [
                "Kubernetes"
            ],
            "InfrastructureAsCode": [
                "Terraform"
            ],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [
                "Kubernetes"
            ],
            "Collaboration": [
                "Teams"
            ],
            "Other": [
                "DevOps",
                "Big Data",
                "Cloud"
            ],
            "FrSoftSkills": [
                "Communication",
                "Collaboration"
            ],
            "EnSoftSkils": [
                "Communication",
                "Collaboration"
            ]
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "title": "DevOps Engineer \u2013 Antibes, France (H/F)",
        "company": "Astek",
        "location": "Antibes, Provence-Alpes-C\u00f4te d'Azur, France",
        "link": "https://fr.linkedin.com/jobs/view/devops-engineer-%E2%80%93-antibes-france-h-f-at-astek-3829412893?position=28&pageNum=0&refId=NuDbZkBPOnBALTaaBOYlpw%3D%3D&trackingId=uEi9cPI%2BZkMctWvIAKSkig%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "CDI\nAntibes - France\nPubli\u00e9e il y a 2 jours\nLe Groupe Astek\nCe Que Nous Allons Accomplir Ensemble :\nRejoindre une \u00e9quipe dans les domaines du transport et du tourisme sur des projets ambitieux dans lesquels la satisfaction clients et les solutions \u00e0 valeur ajout\u00e9e jouent un r\u00f4le crucial.\nVotre Mission, Si Vous L\u2019acceptez :\nComprendre les exigences du client ;\nEncourager et construire des processus automatis\u00e9s dans la mesure du possible\nContr\u00f4ler les processus tout au long du cycle de vie pour s\u2019assurer de leur respect\nD\u00e9finir et param\u00e9trer les processus de d\u00e9veloppement, de test, de mise en production, de mise \u00e0 jour et de support pour le fonctionnement DevOps.\nVotre Future \u00c9quipe :\nVenez rejoindre une \u00e9quibe ambitieuse et dynamique dans un environnement international\nVotre stack de jeu\nAnsible, Python, Jenkins, Docker et Kubernetes\nLes Petits Plus Du Projet :\nVous \u00e9voluerez au sein d\u2019une \u00e9quipe impliqu\u00e9e et r\u00e9active dans un environnement international et interviendrez sur des projets passionnants et enrichissants.\nVous ?\nDipl\u00f4m\u00e9(e) d\u2019une \u00e9cole d\u2019ing\u00e9nieur ou \u00e9quivalent de niveau Bac+5. Vous justifiez id\u00e9alement d\u2019une exp\u00e9rience sur un poste similaire ;\nVotre personnalit\u00e9, votre esprit d\u2019\u00e9quipe, votre autonomie, votre relationnel, votre rigueur, votre cr\u00e9ativit\u00e9 ainsi que votre curiosit\u00e9 seront des atouts essentiels pour mener \u00e0 bien vos missions sur le projet ;\nVous maitrisez les comp\u00e9tences techniques backend de base : Python, Kubernetes, Jenkins, Docker,\u2026\nAstek\nCr\u00e9\u00e9 en France en 1988, Astek est un acteur mondial de l\u2019ing\u00e9nierie et du conseil en technologies. Fort de son expertise dans de nombreux secteurs industriels et tertiaires, Astek accompagne ses clients internationaux dans le d\u00e9ploiement intelligent de leurs produits et de leurs services, et dans la mise en \u0153uvre de leur transformation digitale.\nDepuis sa cr\u00e9ation, le Groupe a fond\u00e9 son d\u00e9veloppement sur une forte culture d\u2019entrepreneuriat et d\u2019innovation, et sur l\u2019accompagnement et la mont\u00e9e en comp\u00e9tence de\nses 7800 collaborateurs\nqui s\u2019engagent chaque jour \u00e0 promouvoir la compl\u00e9mentarit\u00e9 entre les technologies num\u00e9riques et l\u2019ing\u00e9nierie des syst\u00e8mes complexes.\nRejoignez un Groupe en fort d\u00e9veloppement en France et \u00e0 travers le monde ayant r\u00e9alis\u00e9 un chiffre d\u2019affaires de 600 M\u20ac en 2023.\nTous les d\u00e9tails sur le Groupe sur le site https://astekgroup.fr. Et vous pouvez aussi nous suivre sur notre blog : https://blog.groupeastek.com.\nRencontrons-nous\nKillian, notre Talent Acquisition Officer, vous contactera afin de faire un point avec vous.\nEnsuite, Vous \u00c9changerez Avec :\nvotre futur manager (futur N+1) afin de discuter de ASTEK, votre parcours, vos attentes et la mission ;\nvotre directeur d\u2019agence pour valider votre int\u00e9r\u00eat pour le poste et vous pr\u00e9senter les \u00e9l\u00e9ments contractuels.\nNos Plus\nAstek est green et fait b\u00e9n\u00e9ficier ses salari\u00e9s d\u2019une indemnit\u00e9 kilom\u00e9trique v\u00e9lo\nUne politique CARE sur-mesure d\u00e9ploy\u00e9e par nos \u00e9quipes RH pour nos collaborateurs (https://astekgroup.fr/engagements)\nNotre charte de la Diversit\u00e9\nBienvenue dans la team ! Allez-y, maintenant c\u2019est \u00e0 vous de jouer !\nMots-cl\u00e9s :\ndevops \u2013 ing\u00e9nieur \u2013 ing\u00e9nieure \u2013 consultant \u2013 consultante \u2013 terraform \u2013 ansible \u2013 python\nCaract\u00e9ristiques de l'emploi\nCat\u00e9gorie Ing\u00e9nieur\nJob Industry Distribution / Services Internet, Transports Terrestres\nPostuler en ligne\nNom *\nPr\u00e9nom *\nEmail *\nUn email valide est requis.\nT\u00e9l\u00e9phone *\nUn num\u00e9ro de t\u00e9l\u00e9phone valide est requis.\nJoindre un CV *\nMots-cl\u00e9s :\ndevops \u2013 ing\u00e9nieur \u2013 ing\u00e9nieure \u2013 consultant \u2013 consultante \u2013 terraform \u2013 ansible \u2013 python\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "R",
                "Go"
            ],
            "DataBase": [],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [],
            "MachineLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [],
            "DevTools": [
                "Git",
                "Docker",
                "Jenkins"
            ],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [
                "Ansible",
                "Kubernetes"
            ],
            "InfrastructureAsCode": [
                "Terraform"
            ],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [
                "Docker",
                "Kubernetes"
            ],
            "Collaboration": [],
            "Other": [
                "DevOps"
            ],
            "FrSoftSkills": [
                "Cr\u00e9ativit\u00e9"
            ],
            "EnSoftSkils": []
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [
                "CDI"
            ],
            "Salary": [],
            "Level": [
                "Bac+5"
            ],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "title": "Cloud Platform Engineer",
        "company": "Contemporary Amperex Technology Co., Limited",
        "location": "Paris, \u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/cloud-platform-engineer-at-contemporary-amperex-technology-co-limited-3888137773?position=29&pageNum=0&refId=NuDbZkBPOnBALTaaBOYlpw%3D%3D&trackingId=IVIKyTQ2n1ePTL3O87wMDQ%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "CATL invites you to continue our legend of green energy. CATL is a World Fortune 300 Company, a global leader who provides premier EV battery and energy storage battery for the world. CATL\u2019s EV battery consumption volume has ranked No.1 in the world for six consecutive years and global energy storage battery shipment has also ranked No.1 for two consecutive years.\nJob Responsibilities:\n1. Responsible for the operation of overseas big data platforms, formulate data access plans and programs, promote the implementation of data access programs, and realize data access of big data platforms;\n2. Responsible for customer docking, daily customer operation, demand communication and demand analysis of commercial vehicles, passenger cars and energy storage in Europe;\n3. Responsible for data management and data operation, coordinate internal and external resources, and form a normative docking process;\n4. Study the mechanism of battery products, collect data characteristics, and analyze data of specific business problems based on technical indicators;\n5. Responsible for the application and landing of the algorithm model, carry out data cleaning, prediction model establishment, training and optimization for the application scenario, and solve the problems of target recognition, classification, prediction, fault diagnosis and prediction in the scenario;\n6. Responsible for daily operation and maintenance of big data platform, such as operation and maintenance and algorithm deployment.\nJob requirements:\n1.Master degree or above, major in computer,software engineering, data science, vehicle engineering, management science and engineering, artificial intelligence, mathematical statistics and other science and engineering;\n2.\u2460 Familiar with commonly used machine learning and deep learning algorithms and models;\n\u2461 Familiar with mainstream cloud platform products (AWS, Azure, etc.) and understand the cloud native architecture system;\n\u2462 Familiar with Linux system principle and shell programming.\n3.\u2460 Have the understanding and mastery of Hadoop ecological technology stack, including but not limited to Spark, flink, storm, kafka, flume, HDFS, etc.;\n\u2461 Familiar with distributed storage and database technologies, including but not limited to ClickHouse, Greenplum, Redis, MonogoDB, ElasticSearch, etc., and skilled in using common data warehouse architectures;\n\u2462Master Java, Python, R and other programming languages, and skillfully use Python for data analysis;\n4. At least 2 years working experience in big data platform development or data analysis, experience in automobile industry, new energy or car networking industry is preferred;\n5. English as the working language, familiar with French is preferred;\n6. Strong communication and coordination skills, strong problem analysis and problem-solving skills, strong learning ability,business insight and data understanding ability, high sense of responsibility, and positive working attitude, cheerful personality, with certain pressure resistance.\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "Java",
                "R",
                " R ",
                "Go"
            ],
            "DataBase": [
                "Elasticsearch"
            ],
            "DataAnalytics": [
                "R",
                " R "
            ],
            "BigData": [
                "Hadoop",
                "Spark",
                "Flink"
            ],
            "MachineLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [
                "Statistics"
            ],
            "CloudComputing": [
                "AWS",
                "Azure"
            ],
            "DevTools": [],
            "Os": [
                "Linux"
            ],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [
                "Big Data",
                "Machine Learning",
                "Cloud"
            ],
            "FrSoftSkills": [
                "Communication"
            ],
            "EnSoftSkils": [
                "Communication"
            ]
        },
        "details": {
            "JobDetail": [
                "Full"
            ],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "title": "CLOUD ENGINEER",
        "company": "STATION F",
        "location": "Nantes, Pays de la Loire, France",
        "link": "https://fr.linkedin.com/jobs/view/cloud-engineer-at-station-f-3919657457?position=30&pageNum=0&refId=NuDbZkBPOnBALTaaBOYlpw%3D%3D&trackingId=CLBRBQk5MIiONyudToOm3w%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "About\nAB Tasty is a global leader in AI-powered experience optimization solutions empowering brands using personalization, experimentation, recommendations, and search to build better experiences on their websites and apps.\nIntegrated into a single platform, AB Tasty offers web and API-based solutions that provide companies with a unified approach to facilitating seamless experiences for customers.\nBrands use AB Tasty\u2019s platform to align digital, e-commerce, and product teams on revenue goals by maximizing digital impact.\nFounded in 2013, AB Tasty\u2019s customer roster includes world-leading brands such as Kering, McDonald\u2019s, Ulta Beauty, L\u2019Oreal, Disneyland Paris, and LVMH among others.\nAB Tasty has 12 offices across the globe : North America, Europe, Asia Pacific (Australia and Singapore).\nJob Description\nAB Tasty is a global leader in AI-powered experience optimization solutions empowering brands using personalization, experimentation, recommendations, and search to build better experiences on their websites and apps. Integrated into a single platform, AB Tasty offers web and API-based solutions that provide companies with a unified approach to creating seamless experiences for customers.\nBrands use AB Tasty\u2019s platform to align digital, e-commerce, and product teams on revenue goals by optimizing and innovating digital experiences.\nFounded in 2013, AB Tasty\u2019s customer roster includes world-leading brands such as Kering, McDonald\u2019s, Ulta Beauty, L\u2019Oreal, Disneyland Paris, and LVMH among others.\nAB Tasty has 12 offices across the globe: North America, Europe, Asia Pacific\nWe are seeking a motivated Cloud Engineer to become an integral part of our cloud infrastructure team.\nThe successful candidate will have practical experience working with cloud services (AWS or GCP) and a desire to develop their skills across a range of technologies and projects.\nThis role involves contributing to the development, optimization, and maintenance of our cloud-based infrastructures, ensuring they meet our standards for scalability, reliability, and security.\nContract & Location\nPermanent full-time contract\nParis or Nantes Office\nSmooth remote work policy (up to 3 days a week)\nWhat You Will Do\nAssist in the migration of applications and services from legacy cloud infrastructure to brand-new, well-architectured cloud infrastructures, ensuring a smooth and efficient transition.\nAssist development and product teams in utilizing cloud infrastructures effectively, providing support and guidance to maximize productivity and efficiency.\nSupport the design and implementation of cloud solutions, contributing to the overall architecture while also taking on specific tasks and projects.\nParticipate in the deployment and management of infrastructure as code, using tools such as Terraform.\nContribute to the development of automation scripts and tools to streamline operational processes using Python, Bash, or similar languages.\nWork closely with product and technical teams to understand requirements and ensure cloud solutions align with business goals.\nMonitor and maintain cloud environments to ensure optimal performance, cost-efficiency, and compliance with security standards.\nContinuously learn and stay up-to-date with emerging cloud technologies and practices.\nWhat We Offer\nHuge impact. AB Tasty is only as great as our team. By directly developing the publicly accessible SaaS platform used by all our clients, you\u2019ll have a direct impact on the company\u2019s success.\nThe opportunity to unleash your creativity. You\u2019ll be free to contribute to the processes, the tools and the organisation of the team, according the agile principles.\nNo micromanaging. Be the owner of your effort - you\u2019ll be one of the team and fully trusted to take responsibility for your tasks. You\u2019ll have every incentive to make a real impact.\nInternational reach. Our audience is wildly international, and our team is too. Although our HQ is located in France, our company language is English.\nContinuous education. We offer many opportunities for each employee to learn and grow from a mix of professional and non professional topics.\nUnique career opportunity. By joining a fast-growing company that\u2019s making waves in the tech industry, you\u2019ll have a wonderful chance to enhance your learning and advance in your career faster than you ever thought possible.\nLots. Of. Fun. Our incredible magic makers organize awesome events, such as team games, drinks, yoga classes, parties, and a company-wide retreat every year with employees from all countries gathering for 2 days of fun.\nRemote working, flexible schedule. This isn\u2019t a \u201cclock in, clock out\u201d company. We care about your productivity, not tracking every minute you\u2019re on site. It\u2019s up to you to always be responsible for your work, no matter where you are or what schedule you\u2019re keeping.\nTime for yourself. After a year within AB Tasty, we offer you a day off during which we simply ask you to think about your career expectations with us. It's not always easy to find time for introspection and to envision what path can lead us to a happy career so we offer a Retreat Day as an opportunity to reflect on that. We not only aim to succeed, but also to make you succeed.\nWhat We Are Looking For\n1+ years of experience in a cloud engineering role, or relevant experience in a cloud-focused project.\nFamiliarity with at least one major cloud provider (AWS, GCP) and its core services.\nExperience with infrastructure as code (Terraform) is a plus.\nExcellent communication skills, both written and verbal.\nAdditional Information\nContract Type: Full-Time\nLocation: Nantes\nPossible partial remote\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "Scala",
                "R",
                "Go",
                "Bash"
            ],
            "DataBase": [],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [],
            "MachineLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [
                "AWS"
            ],
            "DevTools": [
                "Git"
            ],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [
                "Terraform"
            ],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [
                "Teams"
            ],
            "Other": [
                "ML",
                "Cloud"
            ],
            "FrSoftSkills": [
                "Communication",
                "Organisation"
            ],
            "EnSoftSkils": [
                "Communication",
                "Creativity"
            ]
        },
        "details": {
            "JobDetail": [
                "Remote",
                "Full"
            ],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "title": "Cloud Security Engineer",
        "company": "Teads",
        "location": "Montpellier, Occitanie, France",
        "link": "https://fr.linkedin.com/jobs/view/cloud-security-engineer-at-teads-3757698693?position=31&pageNum=0&refId=NuDbZkBPOnBALTaaBOYlpw%3D%3D&trackingId=o%2BAqghG4UORpShFIGKCoAg%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Teads has an engineering team that brings together\n200+ talented individuals\nin 3 main locations (\nMontpellier, Paris, and Bucharest\n). We are organized in agile and autonomous\nfeature teams\nand share technical knowledge within several\ncommunities of practice\n.We promote diversity and are committed to creating an inclusive environment to enable all employees to feel valued and respected, which fosters creativity and innovation by allowing constructive collaboration and open exchange of ideas.\nOur organization offers the opportunity for hybrid work, allowing for two days in the office and the option to work remotely for the remainder of the week. Additionally, we provide relocation packages for those who prefer to relocate to one of our engineering offices.\n\ud83d\udc49 Join a team of passionate people who build quality and responsible advertising, at scale!\nOur main Engineering challenges at Teads\nWorking in a very high-traffic environment (1.9 billion users per month, 100 billion events per day) with low latency and high availability constraints (2 million requests per second, responses in less than 150 milliseconds).\nRich and diverse tech stack and system architecture to optimize for performance, scalability, resiliency, and cost efficiency. We use mostly Scala and TypeScript, among others.\nManagement of large datasets with milliseconds order of magnitude access time, to compute in a near real-time complex auction resolution algorithm (18 million predictions per second).\nBuild efficient and easy-to-use web products used by thousands of users working for the world's most premium publishers, advertisers, and agencies.\nA fast-changing environment where we continuously collaborate with Product teams and constantly adapt our Cloud infrastructure for new features and Products.\nBring a wide diversity of profiles to the same level of quality and knowledge.\nWhat will you do?\nAs a\nCloud Security Engineer\n, your mission will be to:\nProvide technical leadership and consultation for infrastructure engineers and developers to ensure the secure deployment of technology\nAs part of a team, ensure the adoption of security architecture and engineering initiatives in order to effectively and securely support the organization in meeting specific business technology needs\nDrive consideration of cybersecurity tools and datasets to enhance detective and preventative control sets\nUnderstand technical security issues and the implications to Teads businesses and be able to communicate them to management\nUnderstand emerging security technologies and determine the appropriate use within business applications\nMaintain and enforce Teads cybersecurity policies and secure design baselines\nExecute and improve Teads Security architecture review process and ensure compliance for all business initiatives\nArchitect global programs that deploy strong security patterns and controls across applications and computing environments, while addressing security, business resiliency, privacy and compliance frameworks\nIdentify security vulnerabilities and guide developers and engineers in addressing these issues\nImprove architectural adoption through automation and efficiently use security tools to solve challenges at scale\nValidate reference architectures for security best practices and recommend changes to enhance security and reduce risk\nCollaborate with the corporate functions including Finance, HR, Legal and Privacy to ensure that Teads maintains a strong cybersecurity posture\nWhat will you bring to the team?\nProven hands-on experience securing cloud infrastructure\nProven hands-on experience securing global multi-cloud architectures from both compute and network infrastructure perspective\nProven hands-on experience securing operating systems\nProven hands-on experience with application security topics such as the OWASP top 10 and technical remediations required\nDetailed technical experience supporting and implementing SIEM & logging tools (Splunk, Kibana, Qradar)\nAbility to extract actionable intelligence from large volume aggregated log storage\nThorough understanding of Network and Compute architectures and, specifically the security aspects\nThorough understanding of compliance and regulatory frameworks and how they affect architecture designs and reviews\nGood verbal and written communication skills, specifically the ability to communicate within the context of the intended audience, whether that be senior executives or highly technical engineering resources.\nDetailed understanding of the threats faced by advertising and digital platforms organizations\nWorking knowledge of at least one programming language (Python, Go, Terraform etc.)\nWhy work at Teads?\nAt Teads, Product and Engineering work hand in hand and are aligned towards the same goal: to\nscale our business\nwhile continuing to create\nnew and exciting products\n.\nWe value team spirit, pragmatism, listening and we encourage initiatives.\nWe promote end-to-end development: \u201cYou build it, you run it, you monitor it\u201d.\nWe share knowledge and support with each other beyond any organizational boundary.\nWe fix issues during a blameless postmortem and learn from it so that it doesn\u2019t happen twice.\nWe are working together to create great engineering, but we are also supportive to promote a great work-life balance.\nWe Care About You\nSecurity & Savings: Attractive package providing financial peace of mind, including competitive compensation, profit-sharing, daily meal vouchers (Swile), family health insurance (Alan), and a personalized relocation package (if needed).\nCareer Development: Continuous investment in our employees' skills: in-house and external training, tech conference opportunities, internal mobility (individual contributor or management career ladder).\nLife Balance: A well-balanced work-life for our employees is one of our top priorities: 35+ days off per year, hybrid work (2-3 days remote work per week, more is open to discussion), fully covered parental leave, and reserved daycare places.\nWellness: Prioritizing employee well-being through premium work equipment, enjoyable work environment (work-life balance, team building events, summits), remote work subsidy, promoting Diversity & Inclusion with internal & external initiatives (women speaking groups, dedicated school partnerships), dedicated charitable time and sustainability actions (Eco Tree, subsidy for eco-mobility).\nDiscover more about our culture and benefits on our Engineering website.\nWhat are our recruitment process steps?\nWe want to get to know you and we try to give you the insight you need to make an informed decision to join us. For that, you can find all the information in our Engineering hiring process article!\nAbout Teads\nTeads operates a leading, cloud-based, omnichannel platform that enables programmatic digital advertising across a global ecosystem of quality digital media.\nAs an end-to-end solution, Teads\u2019 modular platform allows partners to leverage buy-side, sell-side, creative, data and AI optimization technologies. For advertisers and their agencies, Teads offers a single access point to buy the inventory of many of the world\u2019s best publishers and content providers.\nThrough exclusive global media partnerships, Teads enables advertisers and agencies to reach billions of unique monthly users in brand safe, responsible advertising environments, while improving the effectiveness and efficiency of digital ad transactions.\nTeads partners with the leading marketers, agencies and publishers through a team of 1,200+ people in 50 offices across more than 30 countries.\nWe're committed to creating a dynamic work environment that values diversity and inclusion, and represents employees across a variety of skill sets. We embrace contributions from all ages, sexes, races, ethnicities, religions, sexual orientations and gender identities.\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "Scala",
                "R",
                "Go"
            ],
            "DataBase": [],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [],
            "MachineLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [],
            "DevTools": [
                "Git"
            ],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [
                "Terraform"
            ],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [
                "Teams"
            ],
            "Other": [
                "Cloud"
            ],
            "FrSoftSkills": [
                "Communication",
                "Leadership",
                "Collaboration"
            ],
            "EnSoftSkils": [
                "Communication",
                "Leadership",
                "Creativity",
                "Collaboration",
                "Organization",
                "Initiative"
            ]
        },
        "details": {
            "JobDetail": [
                "Remote",
                "Full",
                "Senior"
            ],
            "TypeContract": [],
            "Salary": [
                "1.9"
            ],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "title": "Senior Devops Engineer/SRE (H/F)",
        "company": "Sidetrade",
        "location": "Boulogne-Billancourt, \u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/senior-devops-engineer-sre-h-f-at-sidetrade-3919625910?position=32&pageNum=0&refId=NuDbZkBPOnBALTaaBOYlpw%3D%3D&trackingId=7byL7YdUvBYG7URWDllZRA%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Calling all tech enthusiasts! Are you a problem-solving, curious, and strategic DevOps SRE Engineer? Join us at Sidetrade, the leading global SaaS provider recognized by Gartner.(https://go.sidetrade.com/GartnerMagicQuadrant22.ht)\nIndulge your passion for high-availability software and performance enhancement as part of our dynamic team. Embrace the challenge, embrace the excitement - become a DevOps SRE Engineer and thrive! Shape the future of AI-powered Order-to-Cash at Sidetrade today. Join us in creating innovative solutions that redefine the industry!\nAbout Sidetrade\u202fand its amazing R&D team\nSidetrade is a fast-growing international software company that is transforming the Order-to-Cash process for global enterprises. Its AI-powered SaaS platform digitizes the financial customer journey, empowering CFOs to secure and accelerate cash flow generation. Recognized as a Leader in Gartner's Magic Quadrant for two consecutive years, Sidetrade fosters a culture of innovation, collaboration, and customer-centricity from its headquarters in Europe and North America.\nThe R&D team comprises experienced tech professionals who share a deep passion for technology. Together, they are dedicated to developing cutting-edge software solutions that drive the transformation of our customers' work processes. We provide comprehensive training, coaching, resources, and mentorship to empower every team member's growth and nurture their success.\nRequirements\nWhat you will love at Sidetrade:\nWe are seeking a passionate and knowledgeable DevOps SRE Engineer with a multifaceted skill set. Immerse yourself in the exhilarating world of AI and Data Science within our cutting-edge tech environment. Collaborate with like-minded individuals, embracing the latest tools, techniques, and technologies. Fuel your professional growth and innovation within our agile development ecosystem.\nAs a key member of our development team, you will deliver high-quality new features and product enhancements via our online platform. Collaborating with multi-disciplinary teams across the UK and France (with some travel required) will be your forte as you innovate to achieve goals and support the implementation of secure design principles according to policies and standards of Information Security. Explore latest tools and techniques, driving innovation within our R&D team.\nTake control of implementing cutting-edge solutions that optimize our processes. Level up your talent and ignite your development journey!\nWhy you should be working here:\nA strong and demonstrable passion for constantly learning and continuously improving in familiarity with industry leading DevOps/SRE best practices and technologies.\nYou have 5 years+ experience in :\nDeveloping or operating mission-critical systems\nSetup and use of IaC provisioning and deployment tools such as Docker, Terraform and Ansible\nScripting skills with Shell;\nGood knowledge of automation tools\nGood general knowledge of network security (Firewalling, application protection);\nGood knowledge of monitoring tools (Prometheus, grafana, etc.)\nGood knowledge of Linux and Windows systems\nGood knowledge about DNS, DHCP, IPAM, TCP/IP network architectures, HTTP/HTTPS and other Internet protocols.\nYou are aware of security constraints linked to our ISO27001 certification and attached to the roles and responsibilities of this position.\nA plus :\nConcepts and associated tools around containerised and virtualised environments such as Rancher / Kubernetes\nYou worked before with HyperV virtualization technology and Microsoft Azure\nYou speak English fluently, French a plus\nYour first 90 days:\nJoin our Immersive Bootcamp\nReview your onboarding plan with your manager and develop an action plan to achieve your goals\nCollaborate with the team and participate to the roadmap to optimize software performancebuild your internal network across all departments\nExpand your skill set, share your expertise and unlock your full potential\nAt Sidetrade, we cultivate a multicultural environment that fuels innovation. With over 22 nationalities represented, we strongly value diversity, gender equality, inclusivity, and fairness. As an equal opportunity employer, we reject all forms of discrimination and harassment. Your unique contributions are celebrated, driving collective success in our inclusive workplace.\nDiscover more on www.sidetrade.com\nAgencies\nOnly applications from invited agencies through the Workable portal will be accepted. Unsolicited CVs sent directly to managers or HR will not incur any fees.\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "R",
                "Go"
            ],
            "DataBase": [],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [],
            "MachineLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [
                "Azure"
            ],
            "DevTools": [
                "Git",
                "Docker"
            ],
            "Os": [
                "Linux",
                "Windows"
            ],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [
                "Ansible",
                "Kubernetes"
            ],
            "InfrastructureAsCode": [
                "Terraform"
            ],
            "NetworkSecurty": [
                "Firewall"
            ],
            "Virtualisation": [],
            "Containers": [
                "Docker",
                "Kubernetes"
            ],
            "Collaboration": [
                "Teams"
            ],
            "Other": [
                "DevOps"
            ],
            "FrSoftSkills": [
                "Collaboration"
            ],
            "EnSoftSkils": [
                "Collaboration"
            ]
        },
        "details": {
            "JobDetail": [
                "Full"
            ],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "title": "Cloud Engineer",
        "company": "MotorK",
        "location": "Paris, \u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/cloud-engineer-at-motork-3892286206?position=33&pageNum=0&refId=NuDbZkBPOnBALTaaBOYlpw%3D%3D&trackingId=NFsVPvQvl%2FY3aQMAdhdULg%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "MotorK is the leading sales and marketing technology company in Europe, specialising in the automotive sector. At MotorK, our mission is to empower manufacturers and dealerships to sell more with innovative, cloud-based products and services to offer the best digital customer experience.\nWe are on a fast and ambitious trajectory and serving 90% of the automotive manufacturers. To continue our growth, we are hiring new talents. If you want to spark the future of the automotive world, join us.\nWe're headquartered in Milan, Italy, where you'll find most of our employees but the teams you'll work with areas across Europe and the UK.\nYou will be the kubernetes expert inside a team of 5 cloud engineers; your role is key to make sure the existing clusters in MotorK are well managed. You will also be the drive for future improvements and implementation of best practices related to k8s and cloud native technologies in MotorK.\nThings you will do:\nIncrease the efficiency of our software development lifecycle thanks to best practices and infrastructure improvements\nBuild and provide tools to increase developer experience\nImprove and scale our cloud infrastructure, making sure governance, cost and security are under control\nDevelop and improve platform monitoring strategies\nPerform capacity management and load testing\nProvide cloud infrastructure support for the entire Research & Development department\nTechnologies you might work with include:\nOrchestration: Kubernetes, Docker\nCloud: AWS, GCP\nWeb: Nginx, Cloudflare\nData: Kafka, MySQL, Postgres, RabbitMQ, MongoDB\nMonitoring: Grafana, Loki, Prometheus\nCode: PHP, Java, Groovy, Python, Javascript\nRequirements\nStrong hands-on production experience on Kubernetes, at least 3 years\nExperience with at least one Cloud Provider, preferably AWS.\nGood to have\nUnderstanding of SRE and DevOps practices\nExperience with Infrastructure as Code (Ansible, Terraform)\nKnowledge of CI/CD\nRelevant experience with RDBMS (mysql, postgres), troubleshooting and optimization\nBackground in Linux environments as Administrator\nExperience on scripting (bash, python)\nPractical knowledge of networking, both cloud and bare-metal\nGood knowledge of monitoring and log collection tools (grafana, prometheus, loki)\nExperience with PHP or Java on k8s is a plus\nExperience with OSS CMS (WordPress, Joomla...) is a plus\nBenefits\nWork pattern and location\nPermanent contract\nHybrid Role\nWhat you can expect from the recruitment process:\nHR interview\nHiring Manager interview, Infrastructure Manager\nC-level interview, VP R&D\nMotorK is an Equal Opportunity Employer and Prohibits Discrimination and Harassment of Any kind. Our company is committed to the principle of equal employment opportunity for all employees and to providing employees with a work environment free of discrimination and harassment. All employment decisions at MotorK are based on business needs, job requirements, and individual qualifications, without regard to race, colour, religion or belief, age, family or parental status, or any other status protected by the laws or regulations in the locations where we operate.\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "Java",
                "R",
                "Go",
                "Bash",
                "JavaScript"
            ],
            "DataBase": [
                "SQL",
                " MongoDB"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [
                "Spark"
            ],
            "MachineLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [
                "AWS"
            ],
            "DevTools": [
                "Git",
                "Docker"
            ],
            "Os": [
                "Linux"
            ],
            "DBMS": [
                "MySQL"
            ],
            "SoftBigDataProcessing": [],
            "Automation": [
                "Ansible",
                "Kubernetes"
            ],
            "InfrastructureAsCode": [
                "Terraform"
            ],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [
                "Docker",
                "Kubernetes"
            ],
            "Collaboration": [
                "Teams"
            ],
            "Other": [
                "DevOps",
                "ML",
                "Cloud",
                "CI/CD"
            ],
            "FrSoftSkills": [],
            "EnSoftSkils": []
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "title": "DevOps Engineer (H/F)",
        "company": "MERITIS",
        "location": "Aix-en-Provence, Provence-Alpes-C\u00f4te d'Azur, France",
        "link": "https://fr.linkedin.com/jobs/view/devops-engineer-h-f-at-meritis-3815739629?position=34&pageNum=0&refId=NuDbZkBPOnBALTaaBOYlpw%3D%3D&trackingId=rmloD%2FcDTzBLKLjCa2iK8g%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Descriptif de l\u2019entreprise\n:\nMeritis est une soci\u00e9t\u00e9 de conseil sp\u00e9cialis\u00e9e en transformation digitale des organisations, fond\u00e9e en 2007 par S\u00e9bastien Videment.\nInstall\u00e9e initialement \u00e0 Paris, elle s\u2019est d\u00e9ploy\u00e9e en r\u00e9gions et assure d\u00e9sormais une pr\u00e9sence dans les plus grandes villes de France : Sophia-Antipolis, Montpellier, Nantes, Bordeaux, Lyon, Aix-en-Provence, Lille et m\u00eame \u00e0 Lisbonne au Portugal depuis 2023.\nNos experts accompagnent des clients de divers secteurs dans l\u2019int\u00e9gralit\u00e9 de leurs besoins de transformations num\u00e9riques \u00e0 travers de nombreux domaines d\u2019expertise : Finance, Software Engineering, Cloud & Infrastructure, Data, Transformation Digitale et Cybers\u00e9curit\u00e9.\nFort de ses valeurs d\u2019exigence, d\u2019humilit\u00e9, de bienveillance et de proximit\u00e9, le cabinet de +900 collaborateurs prim\u00e9 \u00e0 5 reprises au palmar\u00e8s Great Place To Work\u00ae connait une tr\u00e8s forte croissance et projette d\u2019atteindre 100M\u20ac de chiffre d\u2019affaires en 2024 et de d\u00e9passer la barre symbolique des 1000 collaborateurs.\nNous mettons un point d\u2019honneur \u00e0 \u00eatre proche de nos collaborateurs et \u00e0 les accompagner de mani\u00e8re individualis\u00e9e quelles que soient leurs fonctions dans l\u2019entreprise. Certifi\u00e9e Great Place To Work depuis 2013, notre conception du bien-\u00eatre au travail va bien au-del\u00e0 d'un simple label, ce sont nos collaborateurs qui en parlent le mieux : https://www.glassdoor.fr/Avis/Meritis-Avis-E1163008.htm\nDescriptif du poste :\nEn tant que\nIng\u00e9nieur DevOps (H/F),\nvous int\u00e9grerez une entreprise dynamique \u00e9voluant dans un contexte international et un environnement de travail agile. Vos missions seront :\nMettre en place et maintenir les chaines CI/CD de bout en bout\nContribuer aux travaux de fusion de pipelines en vue de rationaliser\nMigrer les pipelines obsol\u00e8tes vers des versions d'outils valid\u00e9es par la strat\u00e9gie entreprise\nD'accompagner les \u00e9quipes de d\u00e9veloppement \u00e0 l'appropriation de la m\u00e9thode Devops et des outils mis \u00e0 disposition\nParticiper aux r\u00e9flexions de veille sur le p\u00e9rim\u00e8tre du service\nQualification :\nVous avez un dipl\u00f4me d\u2019ing\u00e9nieur (Bac+5).\nVous disposez d'au moins 5 ans d'exp\u00e9rience dans un environnement DevOps\nVous \u00eates issu(e) d'une formation d'ing\u00e9nieur syst\u00e8me et/ou de d\u00e9veloppeur\nVous \u00eates dot\u00e9(e) d\u2019une grande capacit\u00e9 d\u2019adaptation.\nVous r\u00eavez de progresser entour\u00e9(e) de personnes de tous niveaux d\u2019expertise\nOutils / technologies\n:\nJenkins\nGit\nSonar\nCheckmarx\nAngular\nInformations compl\u00e9mentaires\n:\nDes parcours professionnels sur mesure (\u00e9volution de carri\u00e8re, formations adapt\u00e9es, mentoring\u2026) ;\u200b\nAvoir le choix de sa mission et un accompagnement personnalis\u00e9 tout au long de votre carri\u00e8re ;\u200b\nEvoluer dans un environnement o\u00f9 l\u2019apprentissage est favoris\u00e9 : formations certifiantes, e-learning, meetUp, concours de code, parcours d\u2019\u00e9volutions etc ;\u200b\nFaire partie de communaut\u00e9s d\u2019experts qui partagent leurs savoirs et exp\u00e9riences au sein de nos centres de comp\u00e9tences ;\u200b\nUn environnement convivial avec de nombreux \u00e9v\u00e9nements festifs (soir\u00e9e annuelle, s\u00e9minaires & teambuiding, d\u00e9jeuners et afterworks\u2026) ;\u200b\n\u200b\n\"Meritis est engag\u00e9e dans la Responsabilit\u00e9 Soci\u00e9tale des Entreprises. Nous valorisons notre impact positif sur la soci\u00e9t\u00e9 et l'environnement. Notre d\u00e9marche RSE guide chacune de nos actions pour promouvoir l'\u00e9quit\u00e9, la durabilit\u00e9 et le bien-\u00eatre de nos collaborateurs. Rejoignez-nous pour \u00eatre partie prenante de cette d\u00e9marche responsable, o\u00f9 chacun de nos talents contribue \u00e0 construire un avenir meilleur.\nNos diff\u00e9rences sont nos atouts. C\u2019est pourquoi Meritis s'implique en faveur de la diversit\u00e9 et de la non-discrimination. Tous nos m\u00e9tiers sont accessibles aux personnes en situation de handicap.\"\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "R"
            ],
            "DataBase": [],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [],
            "MachineLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [],
            "DevTools": [
                "Git",
                "Jenkins"
            ],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [
                "DevOps",
                "Cloud",
                "CI/CD"
            ],
            "FrSoftSkills": [
                "Organisation"
            ],
            "EnSoftSkils": []
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [],
            "Salary": [],
            "Level": [
                "Bac+5"
            ],
            "Experience": [
                "a",
                "n",
                "s",
                "5",
                "5",
                "5"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "title": "Lead Cloud & DevOps Engineer (H/F)",
        "company": "fifty-five",
        "location": "Paris, \u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/lead-cloud-devops-engineer-h-f-at-fifty-five-3883929582?position=35&pageNum=0&refId=NuDbZkBPOnBALTaaBOYlpw%3D%3D&trackingId=3LiXyHZ8fd%2Fxi6o%2FrCC9lQ%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Cloud & DevOps Lead\nfifty-five est une data-company d'un genre nouveau qui aide les marques \u00e0 exploiter les donn\u00e9es pour am\u00e9liorer le marketing, les m\u00e9dias et l'exp\u00e9rience client gr\u00e2ce \u00e0 une combinaison de services de conseil et de technologie sp\u00e9cialis\u00e9s.\nEn tant que pilier data et marketing du Brandtech Group, nous offrons des services qui combinent le conseil en strat\u00e9gie, les services de cloud, le conseil en m\u00e9dia et l'exp\u00e9rience client.\nfifty-five, c'est plus de 400 experts du num\u00e9rique. Des digital consultants, des sp\u00e9cialistes du tracking et du m\u00e9dia, des ing\u00e9nieurs et des data scientists, travaillent tous en \u00e9troite collaboration pour fournir des conseils marketing de haut niveau et une assistance technique aux marques, dans tout type d'industrie, partout dans le monde.\nPartenaire des annonceurs de la collecte \u00e0 l'activation et l'exploitation des donn\u00e9es, nous aidons les organisations \u00e0 devenir de v\u00e9ritables entit\u00e9s omnicanales ma\u00eetrisant l'efficacit\u00e9 de leur \u00e9cosyst\u00e8me digital et ses synergies avec le monde physique.\nBas\u00e9 \u00e0 Paris, nous op\u00e9rons sur 3 fuseaux horaires depuis nos 10 bureaux, situ\u00e9s \u00e0 Paris, Londres, Gen\u00e8ve, Milan, Shanghai, Hong Kong, Shenzhen, Taipei, Singapour et New York. fifty-five attache une importance particuli\u00e8re au bien-\u00eatre de ses collaborateurs, ce qui lui a permis de figurer dans le classement Best Workplaces France en 2018.\nContexte :\nfifty-five d\u00e9veloppe r\u00e9guli\u00e8rement des nouvelles solutions bas\u00e9es sur du data processing et dans certains cas du machine learning pour r\u00e9pondre aux besoins pr\u00e9cis de ses clients (par exemple: syst\u00e8me de recommandations de produits, d\u00e9tection d'anomalies, ranking).\nL'\u00e9quipe d'Ing\u00e9nierie adresse \u00e0 la fois les outils internes ainsi que les projets clients. L'\u00e9quipe Infrastructure au sein de l'\u00e9quipe Ing\u00e9nierie est responsable de l'infrastructure 55, des outils / scripts d'automation ainsi que des best practices Cloud & DevOps que le reste de l'\u00e9quipe est amen\u00e9 \u00e0 utiliser dans le cadre de leurs projets (internes ou clients). . L'infrastructure 55 recouvre de mani\u00e8re non exhaustive : les outils de d\u00e9veloppement et la stack DevOps (Gitlab, Jupyterhub, Terraform, Docker, Jenkins, etc.), l'h\u00e9bergement des outils d\u00e9velopp\u00e9s en interne (stack Spring Boot / Angular / MongoDB / Keycloak / Vault h\u00e9berg\u00e9 sur GKE), les outils de gouvernance cloud (alerting automatique, billing, etc.), les frameworks templatis\u00e9s que les autres membres de l'\u00e9quipe peuvent utiliser dans le cadre de leurs missions clients (architectures Clouds d\u00e9ployables via Terraform et templatis\u00e9es, sur les 3 cloud publics GCP / Azure / AWS). L'\u00e9quipe intervient \u00e9galement sur l'automatisation de diff\u00e9rents process internes : gestion du billing, ERP automations, etc. L'\u00e9quipe Infrastructure regroupe des Cloud Engineers, DevOps Engineers, Software Engineers (Python).\nMission :\nNous sommes \u00e0 la recherche de notre Cloud & DevOps Lead qui sera responsable de l'\u00e9quipe Infrastructure. Il aura en responsabilit\u00e9 \u00e0 la fois la stack technique interne utilis\u00e9 par l'Ing\u00e9nierie et son h\u00e9bergement, ainsi que les best practices et frameworks utilis\u00e9s par les autres ing\u00e9nieurs. Son r\u00f4le :\n\u00catre garant de la disponibilit\u00e9 et de la s\u00e9curit\u00e9 de l'infrastructure\nMettre en place et surveiller les best practices Infra : GitOps, gouvernance Cloud, FinOps\nS'assurer de la bonne r\u00e9utilisabilit\u00e9 des composants / frameworks / templates\nAccompagner son \u00e9quipe dans le suivi des t\u00e2ches, la mont\u00e9e en comp\u00e9tences et l'expertise au quotidien\nComp\u00e9tences et exp\u00e9riences :\nUne premi\u00e8re exp\u00e9rience sur un poste similaire et un minimum de 4 ans d'exp\u00e9rience.\nMa\u00eetrise des environnements Cloud. Id\u00e9alement certifi\u00e9 GCP, Azure et/ou AWS\nMa\u00eetrise de l'Infrastructure as Code (Terraform)\nMa\u00eetrise de Docker/Kubernetes\nMa\u00eetrise des pratiques GitOps et CI/CD\nMa\u00eetrise de Python, SQL et \u00e9ventuellement Java\nUne connaissance des activit\u00e9s IT est un plus (IDP, user management, device management, DNS management, network, etc.)\nEsprit d'\u00e9quipe (collaborer aux tests unitaires, revue de code, partage de code, sprints)\nBon niveau en fran\u00e7ais et en anglais\nNous proposons :\nun bureau au centre de Paris avec terrasse et jardin\nun environnement multiculturel avec des collaborateurs aux nationalit\u00e9s multiples (France, Royaume-Uni, Etats-Unis, Chine, Tunisie, Italie et plus)\ndes projets avec nos bureaux \u00e0 Londres, Hong Kong, New York, Shanghai, Gen\u00e8ve, Shenzhen et Taipei\ndes TGIF et supers soir\u00e9es\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "Java",
                "R",
                "Go"
            ],
            "DataBase": [
                "SQL",
                " MongoDB"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [],
            "MachineLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [
                "AWS",
                "Azure"
            ],
            "DevTools": [
                "Git",
                "Docker",
                "Jenkins"
            ],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [
                "Kubernetes"
            ],
            "InfrastructureAsCode": [
                "Terraform"
            ],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [
                "Docker",
                "Kubernetes"
            ],
            "Collaboration": [],
            "Other": [
                "DevOps",
                "Machine Learning",
                "Cloud",
                "CI/CD"
            ],
            "FrSoftSkills": [
                "Collaboration",
                "Organisation"
            ],
            "EnSoftSkils": [
                "Collaboration"
            ]
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s",
                "4",
                "4",
                "4"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "title": "SRE / DevOps Engineer",
        "company": "Equativ",
        "location": "Paris, \u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/sre-devops-engineer-at-equativ-3853475202?position=36&pageNum=0&refId=NuDbZkBPOnBALTaaBOYlpw%3D%3D&trackingId=i731NNFa%2B7m56h5tZQ9%2Fxg%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "\ud83d\udc6b About the team\nAt Equativ, we\u2019re on a mission to develop advertising technologies that empower our customers to reach their digital business goals. This means that we rely on massively scalable, widely distributed, highly available, and efficient software systems; the platform deals with over 3 millions requests per second managed by 3,000 servers.\nOur innovation team based in Paris, Nantes, Limoges, Krakow and Berlin is composed of 100+ straightforward and energetic engineers working in an Agile environment and ready to tackle the most complex technical challenges.\nYour mission \ud83d\udc47\nWithin infrastructure BU you will join the Platform department that strives to develop and deploy self-serve tooling to empower our RnD team.\nAs a member of our application SRE team, you will work closely with dev and platform teams to:\nAccelerate time to market and reliability of our backend services\nEnsure that our platform availability fulfills its SLA of 99.95%.\nWhat you will do \u270f\ufe0f\nAs a backend application SRE, your key responsibilities will be:\nCommunication Bridge:\nAct as the primary liaison between the R&D and Platform, DevSecOps and Ops teams\nAligning Best Practices:\nImplement and align DevOps mindset and best practices, including SLOs framework, monitoring, and alerting, across diverse applications.\nWork closely with dev teams to ensure adherence to industry standards and best practices, optimizing the efficiency and reliability of our platform.\nKnowledge Sharing:\nFacilitate knowledge transfer sessions to empower development teams with increased autonomy on DevOps matters and improved services reliability\nProduction awareness:\nAssist on identifying service errors, instability patterns and latency issues\nActively participate in production impediments (PIMPs), postmortems, and incident handling, contributing to a proactive production environment.\nProvide insights and recommendations for improving production processes and preventing future incidents.\nAbout you \ud83d\udc4b\nMaster degree in Computer science or similar field of study.\n2+ years of System or Software Engineering experience ideally in the web industry.\nFluent with DevOps practices.\nExperience in at least one of the following topics: CI/CD pipelines (gitlab, \u2026), Kubernetes administration (Rancher, argoCD, \u2026), Monitoring and alerting (prometheus, grafana stack, \u2026) with a focus on backend applications\nExperience working with IaC (Terraform, GitOps, \u2026).\nAutonomous and innovative mindset.\nWorking proficiency and communication skills in verbal and written English.\nNice to have:\nExperience with troubleshooting live incidents and incident management.\nExperience in software development (Go, Python or equivalent).\nHow you'll grow \ud83d\ude80\nWithin 1 month:\nYou'll be just finishing your onboarding.\nYou'll probably have tackled a few small tasks with your peers.\nWithin 4 months:\nYou'll be trusted to endorse weekly Green Lantern role to assist day to day BE requests.\nYou'll be assigned to minor tasks to ramp up on our stacks and processes.\nWithin 9 months:\nYou'll be leading critical projects (Priority 0).\nYou'll be evolving in our technical architecture discussion.\nYou\u2019ll start getting a grasp on the AdTech business.\n\ud83d\udc4b About us\nEquativ is the new single name for Smart Adserver, DynAdmic, LiquidM and Nowtilus \u2014 four proven innovators in advertising technology. The vertically integrated company provides brand and privacy-safe solutions that empower its clients to achieve maximum impact while respecting the rights of consumers. The union combines client expertise and engineering excellence to serve the interests of both the supply- side and demand-side with equal professionalism and technical sophistication.\nHeadquartered in Paris and New York, Equativ operates globally with a team of more than 550 people in 20 offices. Equativ offers the market its own independent ad server, SSP, buyer tools, and media services to fulfill the promise of advertising technology. Learn more at Equativ.com.\nThe company is ranked on the Deloitte Technology Fast 500 EMEA and in the Financial Times\u2019 FT 1000: Europe\u2019s Fastest-Growing Companies.\nEquativ (formerly Smart AdServer) has been awarded the HappyIndex@Work label and is proud to be among the best companies in the ChooseMyCompany ranking, recognized for its flexible working environment.\nCome and lead the charge with us in building a transparent ecosystem based on quality!\n----------------------\nEquativ is an equal opportunity employer. Equal access to employment, services, and programs are available to everyone, regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity, or Veteran status. If you require reasonable accommodation throughout the application and/or interview process, please contact the recruitment team at ta-team@equativ.com\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "Scala",
                "R",
                "Go"
            ],
            "DataBase": [],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [],
            "MachineLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [],
            "DevTools": [
                "Git"
            ],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [
                "Kubernetes"
            ],
            "InfrastructureAsCode": [
                "Terraform"
            ],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [
                "Kubernetes"
            ],
            "Collaboration": [
                "Teams"
            ],
            "Other": [
                "DevOps",
                "CI/CD"
            ],
            "FrSoftSkills": [
                "Communication"
            ],
            "EnSoftSkils": [
                "Communication"
            ]
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "title": "Senior Cloud Operations Engineer",
        "company": "Centric Software",
        "location": "Greater Paris Metropolitan Region",
        "link": "https://fr.linkedin.com/jobs/view/senior-cloud-operations-engineer-at-centric-software-3916228666?position=37&pageNum=0&refId=NuDbZkBPOnBALTaaBOYlpw%3D%3D&trackingId=uvh4gjHY%2BxzTCaRNevyqhA%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Centric Software provides a Digital Transformation Platform for the most prestigious names in fashion, retail, footwear, luxury, outdoor and consumer goods. Centric\u2019s flagship Product Lifecycle Management (PLM) platform, Centric 8, delivers enterprise-class merchandise planning, product development, sourcing, quality, and collection management functionality tailored for fast-moving consumer industries. Centric SMB provides innovative PLM technology and key industry learnings for emerging brands. Centric Visual Innovation Platform (VIP) offers a fully visual, transformative experience via large touchscreens and mobile devices, revolutionizing group decision-making and creative collaboration while dramatically condensing time to market and product innovation.\nJob Summary:\nThis role will be responsible for utilizing a diverse set of cloud technologies to support Centric Cloud Customers and to help build and maintain a scalable, robust, highly available platform for Centric\u2019s C8 cloud application.\nThis position will report to the Senior Director, Cloud Operations.\nLocation:\nThis is a Remote - Europe (UK and EU-based candidates only*)\nWorking Time:\nCentral European Working hours\nResponsibilities:\nManage and maintain cloud infrastructure on platforms such as AWS, Azure, or Google Cloud.\nMonitor cloud resources to ensure availability and scalability.\nMonitor and optimize cloud resource utilization.\nRespond to and resolve time-critical customer issues in the public cloud.\nTroubleshoot cloud-related infrastructure incidents and issues.\nPerform customer deployments, migrations, and upgrades in the cloud environment.\nSupport automation projects, writing infrastructure as code (IaC) for provisioning and scaling resources.\nAssist in ensuring security best practices for the cloud are followed and customer data is secured.\nPerform database operations such as backup and restores.\nCollaborate with development, devOps and support teams to deploy and manage cloud-based applications and resolve issues.\nCreate and maintain documentation for cloud infrastructure and processes.\nStay up-to-date with cloud technology trends and best practices.\nPropose and implement improvements to cloud operations processes.\nQualifications:\nBachelor\u2019s Degree Computer Science, MIS, or related technology field, or equivalent practical experience\n8+ years of experience in cloud operations and infrastructure management in AWS, Azure, or Google cloud\n5+ years in incident response and major incident management\nAdvanced Linux and Windows experience\nCertification in AWS, Azure or Google Cloud is a plus.\nSolid understanding of Cloud networking and security\nStrong scripting and automation skills (e.g., Python, Powershell)\nProficiency in infrastructure as code (IaC) and configuration management tools. (e.g, Terraform, Ansible)\nExpert knowledge in containerization and orchestration technologies (e.g., Docker Kubernetes, Rancher)\nExperience in version control, CI and automation tools such as Github/Bitbucket, Github Actions, Jenkins, Rundeck)\nExperience in deploying and troubleshooting Java based applications and microservices.\nExperience in deploying, configuring, and troubleshooting Database technologies like MSSQL, PostgreSQL and MongoDB\nExperience in monitoring and logging tools (e.g., Nagios, Prometheus, ELK stack)\nExperience with the following technologies: Virtualization, VPN, RDP, SSO, Kafka\nExperience working with Confluence/Jira\nWhat we offer:\nCompetitive salary and benefits\nA multifaceted job with a high degree of responsibility and a broad spectrum of opportunities\nOpportunity to work remotely with a dedicated and motivated team\nA remote work environment built on collaboration, flexibility, and respect\nVaried and challenging work to help you grow your technical skillset.\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "Java",
                "Scala",
                "R",
                "Go"
            ],
            "DataBase": [
                "SQL",
                " MongoDB"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [],
            "MachineLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [
                "AWS",
                "Azure"
            ],
            "DevTools": [
                "Git",
                "Docker",
                "Jenkins"
            ],
            "Os": [
                "Linux",
                "Windows"
            ],
            "DBMS": [
                "PostgreSQL"
            ],
            "SoftBigDataProcessing": [],
            "Automation": [
                "Ansible",
                "Kubernetes"
            ],
            "InfrastructureAsCode": [
                "Terraform"
            ],
            "NetworkSecurty": [
                "VPN"
            ],
            "Virtualisation": [],
            "Containers": [
                "Docker",
                "Kubernetes"
            ],
            "Collaboration": [
                "JIRA",
                "Confluence",
                "Teams"
            ],
            "Other": [
                "DevOps",
                "Cloud"
            ],
            "FrSoftSkills": [
                "Collaboration"
            ],
            "EnSoftSkils": [
                "Collaboration",
                "Flexibility"
            ]
        },
        "details": {
            "JobDetail": [
                "Remote",
                "Full",
                "Senior"
            ],
            "TypeContract": [],
            "Salary": [
                "Salary"
            ],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "title": "Junior DevOps Application Server Engineer",
        "company": "Euroclear",
        "location": "Paris, \u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/junior-devops-application-server-engineer-at-euroclear-3918734003?position=38&pageNum=0&refId=NuDbZkBPOnBALTaaBOYlpw%3D%3D&trackingId=gHtGV%2FK5QZdhl6oX9u6akA%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Location: Paris, France\nHeadquartered in Brussels and offices in more than 15 countries around the world, including Paris, Euroclear is the financial industry's leading provider of post-trade services globally. Our company ensures the settlement, custody and service of national and cross-border securities transactions, whether in bonds, shares, derivatives or investment funds. To put it simply, we are a bank for banks, and we are at the heart of the world financial system.\nEuroclear has an ambitious Group Strategy based on the following pillars:\nTransformation of the core business through smart process automation, analytics and value-added web-based user interface\nSetting up of a new Business line (i.e. Euroclear Information Services) aiming at monetizing the wealth of data acquired by Euroclear through its operations\nGeographical extension in emerging markets as well as partnerships in North America\nFurther streamlining of the post trade value chain leveraging off technologies such as Distributed Ledger Technologies\nAll the above requires amongst others:\nA rapid transformation of its IT towards Agile Software Development, DevOps, and the Cloud\nA collaborative platform managed jointly by Business and IT focused on driving innovation with staff and clients and delivering new digital products/services\nA highly automated IT that combines smartly resilience, security, speed and innovation\nIn this transformation context Group Technology Services (GTS) plans, builds and runs the global infrastructure of Euroclear, and is additionally responsible for the IT service management to the operating entities of the various Group markets. GTS operates its IT systems and IT services in such a way that, at an appropriate and benchmarked cost level, it can deliver the agreed levels of service to support the requirements of the business processes, for both normal operations and during disaster recovery.\nWe are looking for\nJunior DevOps Application Server Engineer\nto expand our division.\nYour role would be to\nDesign, implement and support Java Application Server based infrastructure solutions to support business opportunities in alignment with the enterprise architecture direction and standards\nAutomate the installing and maintaining of Java Application Server components on Linux and Windows operating systems within the datacentre using Ansible automation framework\nDevelop scripts to integrate Java Application Server components in the CI/CD pipeline (Infrastructure as code)\nEnsure business applications are successfully integrated and operated within the company\u2019s business environment and in compliance with the standards\nParticipate in, support and manage the deployment of applications within test, pre-production and production environments\nIntegrate Java application server components into private cloud based on Kubernetes technology\nYour profile\nBachelor or Master degree in Computer Science/ Information Technology/ Engineering or comparable qualification\nIdeally a first job/traineeship experience in IT\nFluent in French and in English\nAble to demonstrate your ability to learn ICT technologies\nAble to easily adapt to new circumstances / technologies / procedures\nStress resistant and constructive whatever the context\nAble to comply with existing standards and acting with attention to detail\nA true team player who demonstrates good interpersonal skills\nAble to summarize complex technical situations in simple terms\nSolution and client oriented\nWhat we offer\nWe offer an excellent opportunity to practice and develop your talents in a highly professional and motivated team, dealing with multi-domains and involved in some of the most strategic projects for the company\nYou will have the possibility to extend your IT skills and progressively evolve to one of the various possible career paths\nThis role gives you the opportunity to work with recent technologies that will require you to continuously develop your experience and skills\nYou will receive trainings to further evolve in the role\nNew ways of working\nAt Euroclear, we believe in an ideal balance between office and remote work toward business, team and individual needs, enhancing more flexibility, trust and individual accountability.\nAbout us\nThe Euroclear group is at the heart of the global capital markets providing post-trade and related services to 90% of the world\u2019s top banks. As a proven and resilient capital market infrastructure we have been offering vital financial services for over 50 years. Join us and help us serve our global customer franchise as we support their settlement and asset servicing of a variety of instruments, from domestic and international bonds to equities, investment funds and more.\nGreat Place to Work for All\nWe believe that our people are our strength. The diverse talents that our employees bring to the table, are directly linked to our global success. We are committed to creating an inclusive culture that celebrates diversity, and strive to be a Great Place to Work for All. All qualified applicants will be considered for employment, regardless of their race, religion, color, national origin, gender, sexual orientation, gender identity or expression, age, marital status, pregnancy, neuro-diversity, disability, or any other aspect that makes them unique. If you need any specific accommodation due to disability or any other reason, you can let the recruiter know during your application process.\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Java",
                "R",
                "Go"
            ],
            "DataBase": [],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [],
            "MachineLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [],
            "DevTools": [
                "Git"
            ],
            "Os": [
                "Linux",
                "Windows"
            ],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [
                "Ansible",
                "Kubernetes"
            ],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [
                "Kubernetes"
            ],
            "Collaboration": [],
            "Other": [
                "DevOps",
                "ML",
                "Cloud",
                "CI/CD"
            ],
            "FrSoftSkills": [],
            "EnSoftSkils": [
                "Flexibility",
                "Interpersonal Skills"
            ]
        },
        "details": {
            "JobDetail": [
                "Remote",
                "Full",
                "Junior"
            ],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "title": "Cloud Engineer - AWS F/H",
        "company": "StrangeBee",
        "location": "Paris, \u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/cloud-engineer-aws-f-h-at-strangebee-3870967050?position=39&pageNum=0&refId=NuDbZkBPOnBALTaaBOYlpw%3D%3D&trackingId=5lPJsvinH7sHk%2FggAg5mXw%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "StrangeBee\nest un\n\u00e9diteur de solutions de cybers\u00e9curit\u00e9\nd\u00e9di\u00e9es \u00e0 la\nR\u00e9ponse aux Incidents\n.\nEn 2018, Thomas, Nabil & J\u00e9r\u00f4me cr\u00e9ent la soci\u00e9t\u00e9 StrangeBee et poursuivent le d\u00e9veloppement et l'enrichissement des applications open source TheHive & Cortex, entam\u00e9s 4 ans auparavant.\nDevenue la r\u00e9f\u00e9rence, TheHive \u00e9paule aujourd'hui des milliers d'analystes \u00e0 travers le monde, \u00e0 d\u00e9fendre leur entreprise contre les cyberattaques quotidiennes.\nSes ambitions ? Renforcer son offre, r\u00e9pondre aux besoins grandissants, et s'imposer comme leader des plateformes de r\u00e9ponse aux incidents de cybers\u00e9curit\u00e9.\nVotre future \u00e9quipe\nL'\u00e9quipe des Produits Cloud supervise les offres IaaS et SaaS. Vous contribuerez directement au d\u00e9veloppement et aux op\u00e9rations de TheHive Cloud Platform, notre solution enti\u00e8rement g\u00e9r\u00e9e h\u00e9berg\u00e9e sur AWS. Vous serez \u00e9galement impliqu\u00e9 dans la mise \u00e0 jour r\u00e9guli\u00e8re et la publication de nos images IaaS sur AWS, Azure et Outscale.\nL'\u00e9quipe travaille principalement \u00e0 distance, nous recherchons donc quelqu'un capable de faire preuve d'un haut niveau d'ind\u00e9pendance et d'autonomie.\nDESCRIPTIF DE POSTE\nNotre \u00e9quipe est en croissance et recherche un nouveau\nCloud Engineer\n. Vous serez profond\u00e9ment impliqu\u00e9.e dans tous les aspects du cycle de vie des produits IaaS et SaaS :\nD\u00e9veloppement de nouveaux modules d'infra-as-code et am\u00e9lioration de ceux existants.\nConception et d\u00e9ploiement d'environnements techniques sur des infrastructures cloud.\nContribution \u00e0 la s\u00e9curit\u00e9 et aux op\u00e9rations quotidiennes de nos syst\u00e8mes de production bas\u00e9s sur le cloud. Ces syst\u00e8mes tournent 24/7 et n\u00e9cessitent des personnes disponibles et r\u00e9actives afin de r\u00e9pondre aux imp\u00e9ratifs de production (incidents, changements, maintenance, etc.).\n\u00c9valuation de la conformit\u00e9 de nos produits avec diff\u00e9rentes normes de s\u00e9curit\u00e9 et mise en place de nouvelles fonctionnalit\u00e9s de s\u00e9curit\u00e9.\nAm\u00e9lioration de la surveillance des SLA et des processus de QA.\nR\u00e9daction de documentation technique.\nD\u00e9veloppement et mise \u00e0 jour de mod\u00e8les d'infra-as-code pour nos clients IaaS.\nSupport aux clients IaaS et SaaS.\nPublication des mises \u00e0 jour des produits sur les places de march\u00e9 des fournisseurs de cloud.\nVous soutiendrez \u00e9galement d'autres membres de l'\u00e9quipe gr\u00e2ce \u00e0 votre expertise et pourriez occasionnellement encadrer des coll\u00e8gues moins exp\u00e9riment\u00e9s (juniors, apprentis, stagiaires).\nPROFIL RECHERCH\u00c9\nVous poss\u00e9dez une connaissance approfondie et prouv\u00e9e des services AWS (au moins deux ans d'exp\u00e9rience pratique quotidienne).\nTerraform et Packer n'ont aucun secret pour vous en ce qui concerne la gestion des infrastructures cloud.\nVous avez \u00e9crit et d\u00e9ploy\u00e9 des dizaines de r\u00f4les Ansible.\nLinux est le seul OS auquel vous faites confiance pour la production et vous vous d\u00e9brouillez bien avec Ubuntu. Vous pourriez secr\u00e8tement \u00eatre un f\u00e9tichiste de lignes de commande (c'est acceptable, nous n'avons pas besoin de le savoir).\nVotre console est en lecture seule; tout changement que vous apportez \u00e0 un syst\u00e8me de production provient de l'Infra-as-Code (le code \u00e9tant stock\u00e9 dans un VCS). Pour \u00eatre honn\u00eate, vous consid\u00e9rez en fait que tout ce qui a \u00e9t\u00e9 modifi\u00e9 manuellement est un d\u00e9chet contamin\u00e9 qui devrait \u00eatre imm\u00e9diatement d\u00e9truit et red\u00e9ploy\u00e9 \u00e0 partir d'une source propre et fiable.\nVous avez une grande exp\u00e9rience de l'exploitation et du support de syst\u00e8mes de production bas\u00e9s sur le cloud, id\u00e9alement sur AWS.\nTout votre code est dans Git, et uniquement dans Git.\nVous avez une certaine exp\u00e9rience de Hashicorp Vault.\nVous avez une certaine connaissance des meilleures pratiques en mati\u00e8re de s\u00e9curit\u00e9 de l'information (vous avez mis en \u0153uvre activement des fonctionnalit\u00e9s de s\u00e9curit\u00e9 sur des syst\u00e8mes de production par le pass\u00e9).\nVous \u00eates un grand fan de documentation. Vous documentez toujours votre code. Vous savez r\u00e9diger une documentation technique propre et structur\u00e9e ainsi que des proc\u00e9dures.\nCe que nous n'avons pas os\u00e9 demander mais appr\u00e9cierions vraiment\nExp\u00e9rience de publication sur les places de march\u00e9 des fournisseurs de cloud (AWS, Azure, GCP).\nExp\u00e9rience de Terraform Cloud : vous savez ce que sont les modules et les espaces de travail.\nFamiliarit\u00e9 avec certains pipelines CI/CD.\nExp\u00e9rience avec la stack Elastic.\nExp\u00e9rience de l'utilisation de TheHive et Cortex !\nPROCESS DE RECRUTEMENT\nCall d\u00e9couverte avec le service People (~30 min)\nTest de personnalit\u00e9 AssessFirst\nEntrevue technique avec ton futur manager (~1h)\nEntretien avec l\u2019un des fondateurs (~1h)\n\u00c9change avec la Head of People\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "R"
            ],
            "DataBase": [],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [],
            "MachineLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [
                "AWS",
                "Azure"
            ],
            "DevTools": [
                "Git"
            ],
            "Os": [
                "Linux"
            ],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [
                "Ansible"
            ],
            "InfrastructureAsCode": [
                "Terraform"
            ],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [
                "Cloud",
                "CI/CD"
            ],
            "FrSoftSkills": [],
            "EnSoftSkils": []
        },
        "details": {
            "JobDetail": [
                "Junior"
            ],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s",
                "4",
                "4",
                "4"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "title": "DevOps Engineer",
        "company": "Mistral AI",
        "location": "Paris, \u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/devops-engineer-at-mistral-ai-3878342741?position=40&pageNum=0&refId=NuDbZkBPOnBALTaaBOYlpw%3D%3D&trackingId=np7DJVrMqdOHDOOgpX4Xbw%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "We are seeking our first DevOps Engineer.\nResponsibilities\nCollaborate with AI/ML engineers and researchers to develop and implement a CI/CD that enables safe and reproducible experiments\nEnable seamless replication of work environment across several HPC clusters\nImplement and maintain monitoring, logging and alerting systems for both our large training runs and our client-facing APIs\nMake sure training environments are always available and ready on several clusters\nImprove development processes while finding the right balance between rigor, speed and flexibility for software development & research organization\nDevelop and own internal tooling\nCollaborate with our AI/ML engineers and data scientists to build and maintain a secure, scalable, and efficient infrastructure\nDevelop and implement CI/CD pipelines to streamline the evaluation and development of AI/ML models and other applications\nEnsure compliance with security best practices and industry standards\nWork closely with the development team to troubleshoot and resolve issues in production environments\nDevelop and maintain containerization and orchestration systems using tools like Docker and Kubernetes\nDocument processes and procedures to ensure consistency and knowledge sharing across the team\nAbout you:\nMaster\u2019s degree in Computer Science, Engineering, or a related field, or equivalent experience\n3+ years of experience in a DevOps role, preferably in an AI/ML-focused environment\nStrong experience with Kubernetes-based cloud computing\nProficiency in scripting languages such as Python, Bash, or PowerShell\nExperience with CI/CD tools like Jenkins, GitLab CI, or CircleCI\nExperience with containerization and orchestration technologies such as Docker and Kubernetes\nStrong knowledge of Python development good practices\nHaving worked with GPUs before is a + but not required\nFamiliarity with infrastructure-as-code tools like Terraform or CloudFormation\nKnowledge of monitoring, logging, and alerting tools like Prometheus, Grafana, ELK Stack, or Datadog\nYou ideally have an experience in Slurm\nStrong understanding of networking, security, and system administration concepts\nExcellent problem-solving and communication skills\nSelf-motivated and able to work well in a fast-paced startup environment\nWhat We Offer:\nAbility to shape the exciting journey of AI and be part of the very early days of one of Europe\u2019s hottest startup\nA fun, young, multicultural team and collaborative work environment \u2014 based in Paris and London\nCompetitive salary and bonus structure\nComprehensive benefits package\nOpportunities for professional growth and development\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "Scala",
                "R",
                "Go",
                "Bash"
            ],
            "DataBase": [],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [],
            "MachineLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [],
            "DevTools": [
                "Git",
                "Docker",
                "Jenkins"
            ],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [
                "Kubernetes"
            ],
            "InfrastructureAsCode": [
                "Terraform",
                "CloudFormation"
            ],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [
                "Docker",
                "Kubernetes"
            ],
            "Collaboration": [],
            "Other": [
                "DevOps",
                "ML",
                "Cloud",
                "CI/CD"
            ],
            "FrSoftSkills": [
                "Communication"
            ],
            "EnSoftSkils": [
                "Communication",
                "Organization",
                "Flexibility"
            ]
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [],
            "Salary": [
                "Salary",
                "Package"
            ],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "title": "\ud83d\ude80Cloud devops Engineer\ud83d\ude80",
        "company": "Devoteam G Cloud",
        "location": "\u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/%F0%9F%9A%80cloud-devops-engineer%F0%9F%9A%80-at-devoteam-g-cloud-3916035882?position=41&pageNum=0&refId=NuDbZkBPOnBALTaaBOYlpw%3D%3D&trackingId=xaQANSZsf5Yzo29P56Hw2w%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "\ud83d\ude80\ud83d\udcbb Devoteam GCloud cherche un(e) Ninja du Cloud DevOps GCP pour rejoindre notre \u00e9quipe de champions de l'innovation !\nSi vous \u00eates pr\u00eat(e) \u00e0 transformer le monde du cloud avec votre expertise, votre cr\u00e9ativit\u00e9 et votre \u00e9nergie, alors cette annonce est faite pour vous :\n\ud83d\udd0d\nVos Missions :\nD\u00e9ployer et maintenir des infrastructures cloud fiables et \u00e9volutives sur Google Cloud Platform (GCP)\nAutomatiser les processus de d\u00e9veloppement, d'int\u00e9gration et de d\u00e9ploiement pour acc\u00e9l\u00e9rer la livraison de logiciels\nCollaborer avec des \u00e9quipes multidisciplinaires pour concevoir des architectures cloud innovantes et r\u00e9silientes\nParticiper \u00e0 l'optimisation des co\u00fbts et des performances des solutions cloud\n\ud83d\udcaa\nCe que Vous Apportez :\nExp\u00e9rience solide dans le d\u00e9ploiement et la gestion d'infrastructures sur GCP\nMa\u00eetrise des outils de d\u00e9ploiement et d'orchestration (ex : Kubernetes, Terraform)\nComp\u00e9tences en scripting et automatisation (ex : Bash, Python)\nPassion pour la r\u00e9solution de probl\u00e8mes complexes et l'am\u00e9lioration continue\n\ud83c\udf89\nCe que Nous Offrons :\nL'opportunit\u00e9 de travailler avec des technologies de pointe dans un environnement agile et collaboratif\nDes formations et des opportunit\u00e9s de d\u00e9veloppement professionnel pour stimuler votre croissance\n\ud83d\ude80\nPr\u00eat(e) \u00e0 D\u00e9coller vers de Nouveaux Horizons ? Postulez d\u00e8s Maintenant !\nRejoignez-nous pour repousser les limites du cloud et faire de grandes choses ensemble chez Devoteam GCloud ! \ud83c\udf08\ud83d\ude80\nLe Groupe Devoteam oeuvre pour l'\u00e9galit\u00e9 des chances, pour la promotion de ses collaboratrices et de ses collaborateurs au m\u00e9rite et lutte activement contre toute forme de discrimination. Nous sommes persuad\u00e9s que la diversit\u00e9 contribue \u00e0 la cr\u00e9ativit\u00e9, au dynamisme et \u00e0 l'excellence de notre organisation.\nTous nos postes sont ouverts aux personnes en situation de handicap\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "R",
                "Go",
                "Bash"
            ],
            "DataBase": [],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [],
            "MachineLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [
                "Google Cloud Platform"
            ],
            "DevTools": [],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [
                "Kubernetes"
            ],
            "InfrastructureAsCode": [
                "Terraform"
            ],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [
                "Kubernetes"
            ],
            "Collaboration": [],
            "Other": [
                "DevOps",
                "Cloud"
            ],
            "FrSoftSkills": [
                "R\u00e9solution de probl\u00e8mes",
                "Cr\u00e9ativit\u00e9",
                "Organisation"
            ],
            "EnSoftSkils": []
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "title": "DevOps Engineer - CDI",
        "company": "Descartes Underwriting",
        "location": "Paris, \u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/devops-engineer-cdi-at-descartes-underwriting-3767096933?position=42&pageNum=0&refId=NuDbZkBPOnBALTaaBOYlpw%3D%3D&trackingId=DrgcVcpX%2FuFOTGZeeowtgg%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "About Descartes Underwriting\nDescartes was born out of the conviction that the ever-increasing complexity of risks faced by corporations, governments and vulnerable communities calls for a renewed approach in insurance. Our team brings together industry veterans from the most renowned institutions (AXA, SCOR, Swiss Re, Marsh, Aon, ...) and scientists on top of their field to bring underwriting excellence. After 5 years of existence, Descartes has secured a leading position in parametric insurance for weather and climate-related risks utilizing machine learning, real-time monitoring from satellite imagery & IoT. After a successful Series B raise of $120M USD, we launched Descartes Insurance, a 'full stack' insurer licensed to underwrite risk by the French regulator ACPR. With a growing corporate client base (350+ and counting), our diverse team is headquartered in Paris and operates out of our 13 global offices in North America, Europe, Australia, Singapore, Hong Kong and Japan. Descartes is trusted by a panel of A-rated (re)insurers to carry out its activities.\nAbout Your Role\nDue to our consistent growth, we are seeking to expand our Data, Software and DevOps team.\nAt the core of our company, as a\nDevOps Engineer\nyour main assignments will be to make direct contributions to the CI/CD and setup cloud resources to release, deploy, maintain and run our climate risk models. You will also have to provide support to data scientists and software engineers running and developing our models. Your secondary mission will be to connect the external tools to automate the flow of information between the tech and business side.\n\ud83d\udd14\nKEY MISSIONS\n\ud83d\udd14\nSetup, automate, maintain and update:\nCI/CD pipelines;\nData storage process;\nPackage versioning and releasing pipeline;\nDocker environment;\nModularization of code base.\nVM and compute instances:\nConnections to external and internal APIs;\nNotification process with chat tools;\nWebsite hosting;\nAssess and evaluate the cost and the security of software architecture and implementation.\nParticipate in:\nTech stack selection;\nDiscussions with tech partners;\nTraining of tech and underwriting teams;\nSupport and debug of internal users;\nManagement of IAM policies, groups and users.\nTECH STACK\n\ud83d\udda5\n\ufe0f\nCloud provider: GCP\nCode versioning tool: Git + Gitlab\nOS: Linux\nContainer: Docker\nContainer orchestrator: Kubernetes\nInfrastructure as code tool: terraform\nScripting: bash\nCode base: Python\nNotification tool: Slack\nAbout You\nEXPERIENCE & QUALIFICATIONS\n\u200d\n\ud83d\udcbb\n\u200d\n\ud83d\udcbb\n[Hard skills]\nKnowledge of the tech stack and demonstrated proficiency in production environments;\nExperience with Docker;\nExperience automating a CI/CD pipeline;\nFluent in English and in French;\n[Soft skills]\nDesire to train junior developers and explain CI/CD and cloud tool;\nContribute to a rigorous data engineering culture;\nExcellent communication skills, in both formal and informal settings, and in English and French.\n[Nice-to-have]\nExperience releasing python package;\nExperience working on data science projects or scientific code;\nExperience in HPC;\nContribution to an open source project.\nMINDSET\n\ud83d\udca5\nStrong interest in climate issues (it\u2019s not a hoax, many people suffer from it)\nBeing comfortable to work alongside corporate insurers (some still wear suits \ud83d\udc54)\nWillingness to help junior developers (remember how you were when you started \ud83d\udcac)\nStrong team spirit and ability to work (you\u2019ll have to review code and have your code reviewed)\nRigorous, creative and meticulous mind (we handle large insurance, we take our time)\nStrong desire to learn (there\u2019s no limitation to the tech used, we\u2019re happy to test and learn new tools)\nEagerness to work in a multi-cultural environment (policies and teams are from all around the world \ud83d\uddfa\ufe0f)\nWHY JOIN DESCARTES UNDERWRITING?\nOpportunity to work and learn with teams from the most prestigious schools and research labs in the world, allowing you to progress towards technical excellence;\nCommitment from Descartes to its staff of continued learning and development (think annual seminars, training etc.) ;\nWork in a collaborative & professional environment ;\nBe part of an international team, passionate about diversity ;\nJoin a company with a true purpose \u2013 help us help our clients be more resilient towards climate risks;\nA competitive salary, bonus and benefits;\nYou can benefit from a punctual home office days.\nAt Descartes Underwriting, we cherish value of diversity whatever it may be. We are committed to fighting against all forms of discrimination and for equal opportunities. We foster an inclusive work environment that respects all differences.\nWith equal skills, all our positions are open to people with disabilities.\nRECRUITMENT PROCESS\nStep 1: Call and HR Interview with our Talent Recruiter\nStep 2: Technical project submitted via GitHub\nStep 3: Technical interview\nStep 4: Manager interview\nStep 5: Final round interview with the team (Candidates can opt to have the manager interview before the technical project and interview)\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "R",
                "Go",
                "Bash"
            ],
            "DataBase": [],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [],
            "MachineLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [],
            "DevTools": [
                "Git",
                "Docker"
            ],
            "Os": [
                "Linux"
            ],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [
                "Kubernetes"
            ],
            "InfrastructureAsCode": [
                "Terraform"
            ],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [
                "Docker",
                "Kubernetes"
            ],
            "Collaboration": [
                "Slack",
                "Teams"
            ],
            "Other": [
                "DevOps",
                "Machine Learning",
                "Cloud",
                "CI/CD"
            ],
            "FrSoftSkills": [
                "Communication"
            ],
            "EnSoftSkils": [
                "Communication"
            ]
        },
        "details": {
            "JobDetail": [
                "Full",
                "Junior"
            ],
            "TypeContract": [],
            "Salary": [
                "1",
                "1"
            ],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "title": "DevOps Engineer (futur Head of Infra)",
        "company": "Mobiskill | WEFY Group",
        "location": "Paris, \u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/devops-engineer-futur-head-of-infra-at-mobiskill-wefy-group-3918169619?position=43&pageNum=0&refId=NuDbZkBPOnBALTaaBOYlpw%3D%3D&trackingId=Y%2FtTYtuBXVol6kfgyuP%2Fzw%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Context :\nTheir ambitions ? To develop a no-code tool for financial operators based on blockchain. The problems are diverse, and the project is less than two years old.\nYou'll be joining a team of 10 people and will be one of the company's first DevOps Engineer.\nAre you looking for a job with big challenges and prospects for rapid advancement to Head of Infra ? Then you'll want to read on !\nYour Responsibilities :\nAs the first DevOps Engineer you will be responsible for implementing the infrastructure and ensuring that the DevOps culture is respected internally\nScale our infrastructure globally (GCloud, K8S, postgresql, terraform)\nManage the relationship with providers in multiple countries\nBe responsible for the uptime of the platform\nRecruit and manage a team of SREs and backend developers\nArchitecture the monitoring and data stack\nContribute to the overall development of Metal Gear, regardless of roles and responsibilities\nYour profile :\nYou have at least 3 years' significant experience as a DevOps\nYou are sensitive to security issues, ideally you are interested in blockchain and/or have initial experience in the fintech sector\nYou are fluent in English (read, written and spoken), French is optional\nYou are autonomous and rigorous\nYou are quality-focused, with a perfectionist mindset\nYou are experienced with modern development concepts: CI/CD, automated testing, agile methodologies\nBonus point :\nYou have an appetite for blockchain-related issues, particularly security-related issues\nAn experience working on SaaS infrastructure products\nWhy should you join them ?\nThe opportunity to move up to Head of Infra and recruit your own team at term\nAn attractive package : fix + BSPCE)\nYou will be taking part in a project that makes sense, with the aim of making certain financial services accessible to everyone, even on the other side of the world.\nYou'll be working in an international environment\nYou'll be joining a young, dynamic company where you'll have a direct and significant impact on its development, as well as on the product itself.\nYou'll be joining a team of passionate people !\nOffices right in the centre of Paris (1 remote day per week)\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "R",
                "Go"
            ],
            "DataBase": [
                "SQL"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [],
            "MachineLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [],
            "DevTools": [],
            "Os": [],
            "DBMS": [
                "PostgreSQL"
            ],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [
                "Terraform"
            ],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [
                "DevOps",
                "Cloud",
                "CI/CD"
            ],
            "FrSoftSkills": [],
            "EnSoftSkils": []
        },
        "details": {
            "JobDetail": [
                "Remote"
            ],
            "TypeContract": [],
            "Salary": [
                "1"
            ],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "title": "Devops engineer",
        "company": "Harnham",
        "location": "Paris, \u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/devops-engineer-at-harnham-3869587731?position=44&pageNum=0&refId=NuDbZkBPOnBALTaaBOYlpw%3D%3D&trackingId=y7r4bNZgzTJNxoka97KD0g%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Devops engineer GCP\nMinimum 2 ans d'esp\u00e9rience\n2j TT\nParis\nUP to 55K\u20ac\nCDI\nNous recherchons pour l'un de nos clients, une startup dynamique en pleine croissance, sp\u00e9cialis\u00e9e dans le domaine de la technologie et de l'innovation.\nDescription du Poste :\nVous serez responsable de la mise en place et de la gestion de nos infrastructures cloud sur Google Cloud Platform (GCP), ainsi que du d\u00e9ploiement et de la maintenance de nos applications.\nResponsabilit\u00e9s :\nConcevoir, mettre en \u0153uvre et maintenir des pipelines CI/CD robustes.\nAutomatiser les t\u00e2ches de d\u00e9ploiement, de gestion et de surveillance des syst\u00e8mes.\nCollaborer avec les \u00e9quipes de d\u00e9veloppement pour garantir des environnements de d\u00e9veloppement, de test et de production efficaces.\nG\u00e9rer les incidents et garantir la disponibilit\u00e9 et la fiabilit\u00e9 des syst\u00e8mes.\nOptimiser les performances et la scalabilit\u00e9 de notre infrastructure.\nComp\u00e9tences Requises :\nExp\u00e9rience pratique dans un r\u00f4le de DevOps, avec au moins 2 ans d'exp\u00e9rience.\nMa\u00eetrise des services et des outils de Google Cloud Platform (GCP).\nSolides comp\u00e9tences en automatisation avec des outils tels que Terraform, Ansible ou \u00e9quivalents.\nBonne connaissance des pipelines CI/CD, des conteneurs (Docker) et des orchestrateurs (Kubernetes).\nExcellentes comp\u00e9tences en r\u00e9solution de probl\u00e8mes et en communication.\nAvantages :\nRejoignez une \u00e9quipe passionn\u00e9e dans un environnement stimulant et innovant.\nOpportunit\u00e9 de travailler sur des projets technologiquement avanc\u00e9s.\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Scala",
                "R",
                "Go"
            ],
            "DataBase": [],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [],
            "MachineLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [
                "Google Cloud Platform"
            ],
            "DevTools": [
                "Docker"
            ],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [
                "Ansible",
                "Kubernetes"
            ],
            "InfrastructureAsCode": [
                "Terraform"
            ],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [
                "Docker",
                "Kubernetes"
            ],
            "Collaboration": [],
            "Other": [
                "DevOps",
                "Cloud",
                "CI/CD"
            ],
            "FrSoftSkills": [
                "Communication",
                "R\u00e9solution de probl\u00e8mes"
            ],
            "EnSoftSkils": [
                "Communication"
            ]
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [
                "CDI"
            ],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s",
                "2",
                "2",
                "2"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "title": "DevOps Azure Platform Engineer",
        "company": "AXA Group Operations",
        "location": "Paris, \u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/devops-azure-platform-engineer-at-axa-group-operations-3887945584?position=45&pageNum=0&refId=NuDbZkBPOnBALTaaBOYlpw%3D%3D&trackingId=VkaNBVA%2B%2BZzpguP6Pq8ZKg%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Job purpose\nOur department is committed to offering to our customer entities cloud-based solutions that run with the expected performance and robustness, while being efficient and cost-effective.\nThe AXA GO product \u2018Risk Projection Engine - Sunrise\u2019 is an actuarial platform for dynamic financial analysis\n(DFA) based on models and using stochastic projections for predictions on Solvency 2, IFRS17, ALM and Internal Model Review and it\u2019s widely used at AXA.\nThe Risk Projection Engine - Sunrise Product runs in Azure Cloud environment and it\u2019s supported by a team of 6 specialists spread between France and Portugal GO offices. The purpose of this position is to lead the Azure Platform Engineers team and drive the cloud strategy for RPE Sunrise.\nMain mission\nYour responsibilities include:\nLead the Azure Platform Engineer team using Agile practices to ensure communication, work distributions and knowledge sharing.\nSupport the definition and implementation of RPE-Sunrise Azure strategy deploying scalable, reliable, and highly available infrastructure solutions in Azure.\nMonitor and optimize Azure performance and cost.\nWork with the security team to ensure that Azure resources are configured securely and are compliant with applicable AXA security standards and regulations.\nAutomate infrastructure deployment and configuration processes to increase efficiency, consistency, and reliability.\nTroubleshoot and resolve issues related to Azure infrastructure, working with other IT teams as Network and Cloud Broker to resolve issues quickly.\nExperience and Technical skills\nExpertise in using Azure DevOps and related tools such as Visual Studio, Git, Jenkins, and Docker.\nKnowledge of continuous integration (CI) and continuous delivery/deployment (CD) concepts and methodologies.\nExperience with Microsoft Azure cloud computing platforms.\nExperience on Azure managed services (SQL Server, PostgreSQL, Azure Storage Account, ...).\nExperience on Azure network and security components (build and run): VNet, Network Security Group, Monitoring of resources and the best practices surrounding them.\nMastery of Azure resource monitoring tool (OMS).\nExperience on best practices in terms of architecture design (AD, Storage, Managed services, etc.)\nExperience on the Kubernetes Ecosystem (Node, Pod, Ingress, ConfigMap, FleexVolume, Services, NetworkPolicy, CertManager, ...).\nExperience on automation of deployment of architectures and configurations (PowerShell, Python, JSON, ARM, YAML, HELM, Terraform).\nStrong understanding of software development processes, including Agile and DevOps methodologies.\nSolid understanding of software development lifecycles and Agile methodologies.\nA bachelor's or master's degree in computer science, information technology, or a related field.\nSoft skills / transversal skills\nProblem solving mindset\nStakeholder management\nCommunication and collaboration skills, adaptive to different levels of the organization, from executive forums to technical teams\nAutonomy and self-drive, but also teamwork and leadership\nAnalytical thinking, attention to detail, and problem-solving\nEnglish proficiency\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "Scala",
                "R",
                "Go"
            ],
            "DataBase": [
                "SQL"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [],
            "MachineLearning": [],
            "DataSerialization": [
                "Json"
            ],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [
                "Azure"
            ],
            "DevTools": [
                "Git",
                "Docker",
                "Jenkins"
            ],
            "Os": [],
            "DBMS": [
                "PostgreSQL",
                "SQL Server"
            ],
            "SoftBigDataProcessing": [],
            "Automation": [
                "Kubernetes"
            ],
            "InfrastructureAsCode": [
                "Terraform"
            ],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [
                "Docker",
                "Kubernetes"
            ],
            "Collaboration": [
                "Teams"
            ],
            "Other": [
                "DevOps",
                "ML",
                "Cloud"
            ],
            "FrSoftSkills": [
                "Communication",
                "Leadership",
                "Collaboration"
            ],
            "EnSoftSkils": [
                "Communication",
                "Teamwork",
                "Problem Solving",
                "Leadership",
                "Collaboration",
                "Organization"
            ]
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "title": "Data Engineer DevOps",
        "company": "ATLANSE",
        "location": "Issy-les-Moulineaux, \u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/data-engineer-devops-at-atlanse-3918368657?position=46&pageNum=0&refId=NuDbZkBPOnBALTaaBOYlpw%3D%3D&trackingId=rOXvbQkkw5nEHzGIwYBf2w%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Vous interviendrez au sein de l\u2019\u00e9quipe Analytics et contribuerez au d\u00e9veloppement de la plateforme DataHub, dans un environnement international.\nMissions :\nAnalyser les besoins aupr\u00e8s des utilisateurs de Datahub (m\u00e9tiers, \u00e9quipes IT, process...), formalisation des \u00e9changes, des process et d\u00e9veloppements \u00e0 effectuer\nActivit\u00e9s DevOps pour les applications Datahub :\nEffectuer les d\u00e9ploiements et mises \u00e0 jour d\u2019applications sur clusters Kubernetes\nAssurer la customisation et les param\u00e9trages avanc\u00e9s d\u2019applications open-sources\nParticiper \u00e0 l\u2019am\u00e9lioration continue de la stabilit\u00e9 des applications\nR\u00e9aliser le monitoring des applications\nVeiller \u00e0 la r\u00e9alisation et au suivi des sujets d\u2019architecture IT avec des sp\u00e9cialistes architecture IT (r\u00e9seau, cluster Kuberneters, bases de donn\u00e9es relationnelles, containers, usage des ressources de calculs)\nR\u00e9aliser les d\u00e9veloppements :\nAutomatisation de t\u00e2ches planifi\u00e9es (rafraichissements de donn\u00e9es, calculs de KPI, op\u00e9rations techniques\u2026) avec Python\nTraitement de donn\u00e9es Parquet (modifications des donn\u00e9es et sch\u00e9mas) avec pyArrow, pySpark ou polars\nRequ\u00eates Adhoc, qualit\u00e9 de donn\u00e9es, mod\u00e9lisation et r\u00e9alisation de d\u00e9veloppements SQL complexes (Ex : datasets pour rapports BI), performance tuning\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "R"
            ],
            "DataBase": [
                "SQL"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [
                "Spark"
            ],
            "MachineLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [],
            "DevTools": [],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [
                "Kubernetes"
            ],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [
                "Kubernetes"
            ],
            "Collaboration": [],
            "Other": [
                "DevOps"
            ],
            "FrSoftSkills": [],
            "EnSoftSkils": []
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "title": "DEVOPS/CLOUD ENGINEER WITH IT EXPERIENCE",
        "company": "STATION F",
        "location": "Paris, \u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/devops-cloud-engineer-with-it-experience-at-station-f-3918620381?position=47&pageNum=0&refId=NuDbZkBPOnBALTaaBOYlpw%3D%3D&trackingId=QpjU8S3H2TvNbfqnYakz3Q%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "About\nWhiteLab Genomics est une soci\u00e9t\u00e9 dynamique, en pleine croissance et engag\u00e9e pour acc\u00e9l\u00e9rer la d\u00e9couverte et le d\u00e9veloppement des th\u00e9rapies g\u00e9nomiques gr\u00e2ce \u00e0 l'intelligence artificielle en aidant nos partenaires \u00e0 gu\u00e9rir davantage de maladies \u00e0 un co\u00fbt abordable.\nIls d\u00e9veloppent et ils op\u00e8rent une plateforme d\u2019intelligence artificielle unique afin d\u2019acc\u00e9l\u00e9rer le d\u00e9veloppement des th\u00e9rapies g\u00e9nomiques, bas\u00e9es sur l\u2019ADN et/ou l\u2019ARN, une nouvelle g\u00e9n\u00e9ration de traitements adressant un large panel de pathologies allant des maladies neurod\u00e9g\u00e9n\u00e9ratives jusqu\u2019aux cancers. Les approches d\u2019IA associ\u00e9es \u00e0 de grands jeux de donn\u00e9es multi-omiques permettent de d\u00e9couvrir de nouvelles th\u00e9rapies et d\u2019en simuler les effets pour optimiser leur design.\nJob Description\nWhiteLab Genomics\nwas founded with the belief that life-saving drugs should be accessible to all patients in need. United in our vision, we\u2019ve become a part of Y Combinator, French Tech 2030, Future 40 by Station F, and we\u2019ve been recognized by The Galien Foundation (\u201dBest Startup\u201d category), among other institutions at the forefront of technology. Today, we strive to become the leading expert in A.I. for genomic medicine, operating as the go-to partner for research and development.\nIn this critical and multifaceted role\n, you will lead the maintenance, development, and fortification of our AI/IT infrastructure for genomic medicine. We\u2019re in the process of setting up and scaling our Cloud infrastructure, and you\u2019ll play a valuable role in helping us scale up, leading the charge in optimizing our cloud services, streamlining workflows, and ensuring seamless integration with our DevOps practices and automation frameworks. To scale our current architecture to a higher level, you will help us identify our current bottlenecks, propose new Cloud based solutions, implement them, and help users to use them, allowing for enhanced efficiency. Fostering an atmosphere of productivity and teamwork, your expertise will drive our mission towards greater technological excellence and innovation.\nThis is an\nincredible opportunity\nto work on a diversity of engaging tasks in a hybrid role, forming the infrastructure of a vibrant start-up that seeks to make an impact on the future of healthcare \u2013- you'll play a crucial role in helping revolutionize genomic medicine with AI.\nOur Core Values\nWe Believe that Care is Everything.\nWe Value our Collective Potential\nWe Cultivate Proactive Communication, Clarity and Respect\nWe Have a Can-Do Attitude\nWe Strive for Excellence\nPreferred Experience\nWe\u2019re Eager to Meet You If\u2026\nYou're proficient in DevOps methodologies and tools, including proven experience in implementing robust continuous integration, continuous deployment (CI/CD) pipelines, infrastructure as code (IaC), and automated testing frameworks\nYou have demonstrated experience with coding (preferably Python) for automation tasks and infrastructure management and team interactions for orchestration tasks\nYou have expertise in cloud services (AWS, Azure, or Google Cloud), with a track record of designing, deploying, and managing scalable cloud-based infrastructure solutions tailored to business needs. Your comprehensive understanding of cloud services will enable seamless integration with DevOps practices and automation workflows\nYou have at least 1 year of prior hands-on experience in managing IT equipment, tools, and issues at a tech company (preferably a tech start-up) and excel in administering SharePoint and email systems, ensuring smooth operations and user support\nYou possess great problem solving ability and can work autonomously\nYou have expertise in hardware, software, and network systems\nYou can manage pipelines, optimizing workflows for efficient deployment and delivery\nYour interpersonal skills allow you to collaborate effectively with cross-functional teams, including researchers, data scientists, business development professionals, and support functions\nYou can adapt to a dynamic and rapidly evolving industry, staying on top of the latest IT advancements\nYou have excellent verbal and written communication skills and have experience interfacing with stakeholders and users in English - French proficiency is a plus!\nYou\u2019re knowledgeable of standard practices for access control models, data protection regulations, IT security, and compliance protocols\nHere\u2019s How You\u2019ll Make An Impact\u2026\nYou\u2019ll provide strategic and technical leadership to all of our teams, guiding the development and implementation of innovative solutions towards orchestration, CI/CD and security standards\nYou\u2019ll set up and manage CI/CD pipelines to automate processes\nYou\u2019ll write automation scripts to automate routine orchestration tasks and manage our infrastructure efficiently\nYou\u2019ll design, deploy, and manage scalable cloud-based infrastructure solutions\nYou\u2019ll integrate cloud services with DevOps practices and automation workflows\nYou\u2019ll oversee the operation and maintenance of IT tools and infrastructure, ensuring reliability, performance, and security\nYou\u2019ll manage user roles, permissions, and access control for Cloud services, SharePoint, and email systems in compliance with data protection regulations\nYou\u2019ll administer and optimize SharePoint and other collaboration tools to enhance team productivity\nYou\u2019ll ensure all technology systems and platforms operate reliably and efficiently\nYou\u2019ll implement and maintain security policies and procedures, conducting regular audits to ensure compliance with industry standards\nYou\u2019ll provide technical support, resolving issues related to hardware, software, network problems, systems, and access permissions\nYou\u2019ll manage and maintain all IT equipment and tools, ensuring they\u2019re up to date and in good working condition\nYou\u2019ll lead Cloud and Helpdesk projects from inception to completion, ensuring projects are delivered on time, within budget, and meet quality standards\nYou\u2019ll implement best practices in IT operations and cybersecurity to safeguard company data and systems\nAdditional Information\nContract Type: Full-Time\nStart Date: 24 June 2024\nLocation: Paris\nExperience: > 1 year\nPossible partial remote\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "Scala",
                "R",
                "Go"
            ],
            "DataBase": [],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [],
            "MachineLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [
                "AWS",
                "Azure"
            ],
            "DevTools": [],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [
                "Teams"
            ],
            "Other": [
                "DevOps",
                "ML",
                "Cloud",
                "CI/CD"
            ],
            "FrSoftSkills": [
                "Communication",
                "Leadership",
                "Collaboration"
            ],
            "EnSoftSkils": [
                "Communication",
                "Teamwork",
                "Problem Solving",
                "Leadership",
                "Collaboration",
                "Interpersonal Skills"
            ]
        },
        "details": {
            "JobDetail": [
                "Remote",
                "Full"
            ],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "title": "Data Engineer DevOps H/F",
        "company": "Inetum",
        "location": "Courbevoie, \u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/data-engineer-devops-h-f-at-inetum-3843956952?position=48&pageNum=0&refId=NuDbZkBPOnBALTaaBOYlpw%3D%3D&trackingId=Sn4Hl2dBAtfOzY6bsphgkA%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "D\u00e9tail de l'offre\nInformations g\u00e9n\u00e9rales\nEntit\u00e9 de rattachement\nNous sommes une ESN agile, un groupe international certifi\u00e9 Top Employer Europe 2024.\nA l'\u00e8re de la post-transformation digitale, nous mettons tout en \u0153uvre pour que chacun de nos 28 000 athl\u00e8tes du digital puisse se renouveler perp\u00e9tuellement, en vivant positivement son propre flow digital.\nChacun de nos talents peut ainsi fa\u00e7onner son parcours de carri\u00e8re selon ses app\u00e9tences, entreprendre de mani\u00e8re pragmatique avec ses clients pour un monde \u00e0 impact positif, innover localement dans 27 pays et harmoniser son investissement professionnel et son bien-\u00eatre personnel.\nRejoignez Inetum. Live your positive digital flow.\nTous nos postes sont ouverts aux personnes en situation de handicap.\nDescription du poste\nM\u00e9tier\nConseil et Int\u00e9gration - Business Consulting\nIntitul\u00e9 du poste\nData Engineer DevOps H/F\nContrat\nCDI\nDescription De La Mission\nQui sommes-nous ?\nNous sommes une ESN agile et un groupe international. A l'\u00e8re de la post-transformation digitale, nous mettons tout en \u0153uvre pour que chacun de nos 27 000 collaborateurs puisse se renouveler perp\u00e9tuellement, en vivant positivement son propre flow digital. Chacun d'entre eux peut ainsi fa\u00e7onner son parcours de carri\u00e8re selon ses app\u00e9tences, entreprendre de mani\u00e8re pragmatique avec ses clients pour un monde plus positif, innover localement dans 26 pays et harmoniser son investissement professionnel et son bien-\u00eatre personnel.\nRejoignez\nCapital Market, entit\u00e9 Inetum en Finance de March\u00e9\n. Nous accompagnons les acteurs majeurs du secteur de la finance en France et \u00e0 l\u2019International.\nCultivant la double comp\u00e9tence technique et fonctionnelle, nous intervenons sur des projets innovants \u00e0 haute valeur ajout\u00e9e.\nQuelles sont nos valeurs ?\n\ud83c\udfc6 Excellence Notre culture de l\u2019excellence na\u00eet de notre audace.\n\ud83e\udd1d Engagement S\u2019associer et grandir ensemble !\n\ud83d\udef0 Innovation Nos FabLab au service de la transformation digitale de nos clients.\nMissions propos\u00e9es\nPour accompagner notre forte croissance, nous recherchons des\nData Engineer DevOps\npour le compte d\u2019un acteur majeur de la finance de march\u00e9 en Europe et dans le monde. Dans ce contexte international et exigeant, vous travaillez sur la conception de solutions Big Data afin de r\u00e9pondre aux besoins des op\u00e9rationnels m\u00e9tiers.\nPour mener \u00e0 bien ce projet, vous aurez pour responsabilit\u00e9s de\nComprendre les enjeux des \u00e9quipes Data et les accompagner. Faire le lien entre les environnements (datalake, datawarehouse et environnement de d\u00e9ploiement du mod\u00e8le) gr\u00e2ce \u00e0 des pipelines sophistiqu\u00e9s\n\u00catre r\u00e9f\u00e9rent et garant des bonnes pratiques pour le d\u00e9veloppement des langages utilis\u00e9s par l'\u00e9quipe. Accompagner les Data Scientists dans l'optimisation de leurs algorithmes\nAssurer la viabilit\u00e9 des solutions de datamining et de machine learning de l'\u00e9quipe Data et les mettre en production.Construire et optimiser des pipelines de donn\u00e9es complexes (ETL et ELT)\nCoordonner le d\u00e9veloppement et les op\u00e9rations gr\u00e2ce \u00e0 l\u2019automatisation des flux de travail, la cr\u00e9ation de services Web pr\u00e9dictifs.\nD\u00e9ployez ces mod\u00e8les en utilisant les derni\u00e8res techniques et pratiques (API REST, Docker, Tensorflow Serving, etc.)\nAnalyser et r\u00e9soudre les anomalies li\u00e9es aux performances et \u00e0 l\u2019\u00e9volutivit\u00e9 des solutions Cloud BI et Big Data\nProfil\nProfil souhait\u00e9\nDe formation Ing\u00e9nieur Grande Ecole ou \u00e9quivalent, vous poss\u00e9dez une premi\u00e8re exp\u00e9rience r\u00e9ussite de trois ans minimum sur un poste \u00e9quivalent id\u00e9alement en banque d\u2019investissement ou asset management.\nVous \u00eates familier avec l\u2019environnement Big Data (data grids, compute grids, REST based architectures, SGBDR, No-SQL Databases, GPUs)\nVous avez d\u00e9j\u00e0 travaill\u00e9 avec la m\u00e9thodologie Agile\nUne certaine aisance technique est \u00e9galement requise (Jenkins, Docker, Ansible, Git, Scala, Kubernetes, Python/Java, Maven)\nUne double comp\u00e9tence Cloud (AWS, Google Cloud, Azure) serait un v\u00e9ritable plus\nEvoluant dans un contexte international, la ma\u00eetrise de l'Anglais est n\u00e9cessaire.\nL\u2019aisance relationnelle, de l\u2019autonomie, la gestion des priorit\u00e9s, des capacit\u00e9s d\u2019analyse et de synth\u00e8se, \u2026 le savoir-\u00eatre est une composante importante dans notre processus de recrutement.\nTous nos postes sont ouverts aux personnes en situation de handicap.\nEt pourquoi Inetum Capital Market ?\n\ud83d\ude04 Des missions int\u00e9ressantes\n\ud83e\udd29 Des perspectives d'\u00e9volutions professionnelles et financi\u00e8res\n\ud83d\ude0e Les avantages d'un grand groupe international\n\ud83d\ude09 Un suivi r\u00e9gulier\n\u2708\ufe0f Une aide \u00e0 la mobilit\u00e9 g\u00e9ographique que vous soyez localis\u00e9 en France ou \u00e0 l'\u00e9tranger\n\ud83d\udc68\u200d\ud83c\udf93 Des formations certifiantes\n\ud83e\udd73 Des moments de FUN !\nLocalisation du poste\nLocalisation du poste\nFrance, Ile-de-France, 75 Paris\nVille\nCourbevoie\nCrit\u00e8res candidat\nNiveau d'\u00e9tudes min. requis\nBac+5\nNiveau d'exp\u00e9rience min. requis\nPlus de 2 ans\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "Java",
                "Scala",
                "R",
                "Go"
            ],
            "DataBase": [
                "SQL"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [],
            "MachineLearning": [
                "TensorFlow"
            ],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [
                "AWS",
                "Azure"
            ],
            "DevTools": [
                "Git",
                "Docker",
                "Jenkins"
            ],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [
                "Ansible",
                "Kubernetes"
            ],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [
                "Docker",
                "Kubernetes"
            ],
            "Collaboration": [],
            "Other": [
                "DevOps",
                "Big Data",
                "Machine Learning",
                "Cloud"
            ],
            "FrSoftSkills": [],
            "EnSoftSkils": []
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [
                "CDI"
            ],
            "Salary": [],
            "Level": [
                "Bac+5"
            ],
            "Experience": [
                "a",
                "n",
                "s",
                "2",
                "2",
                "2"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "title": "DevOps - Cloud Infrastructure Engineer @ start-up",
        "company": "Licorne Society",
        "location": "Paris, \u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/devops-cloud-infrastructure-engineer-%40-start-up-at-licorne-society-3918088091?position=49&pageNum=0&refId=NuDbZkBPOnBALTaaBOYlpw%3D%3D&trackingId=zBNVGytNUyFdX%2B0ViHpbzg%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Licorne Society est \u00e0 la recherche de DevOps - Cloud Infrastructure Engineer pour des startups innovantes, ne laisse pas passer ta chance !\nC\u2019est quoi Licorne Society ?\nLicorne Society est le seul outil qui te met en relation avec plus de 3000 startups recrutant en France, tous secteurs et m\u00e9tiers confondus. Qu\u2019elles soient en cr\u00e9ation ou en phase d\u2019hypercroissance, toutes les startups t\u2019attendent sur Licorne Society. Ah oui, et c\u2019est gratuit !\nNotre promesse : faire matcher ta recherche avec les meilleures opportunit\u00e9s et mettre en avant ton profil aupr\u00e8s des startups qui recrutent.\n>> www.licornesociety.com <<\nL'inscription Prend Moins De 10 Minutes. Tu Pourras Alors Acc\u00e9der \u00e0 L'ensemble Des Offres En Startup Du March\u00e9 Et \u00catre Contact\u00e9 Directement Par Les Recruteurs\n1 - Remplis ton profil et tes attentes.\n2 - Passe en revue les offres que nous te proposons en fonction de tes crit\u00e8res de recherche et re\u00e7ois une notification \u00e0 chaque nouvelle offre publi\u00e9e. Avec notre mode Tinder, tu n\u2019as qu\u2019\u00e0 swiper les offres. Matcher avec le job de tes r\u00eaves n\u2019a jamais \u00e9t\u00e9 aussi simple !\n3 - Re\u00e7ois des sollicitations directes pour des postes de DevOps - Cloud Infrastructure Engineer au sein de nos startups pr\u00e9f\u00e9r\u00e9es (pour ne citer que BackMarket, PlayPlay, Payfit, Trustpair ou encore Choco)\nProfil Recherch\u00e9\nTu as une premi\u00e8re exp\u00e9rience de DevOps - Cloud Infrastructure Engineer et tu es tr\u00e8s motiv\u00e9 pour rejoindre une start-up / scale-up ou tu es pr\u00eat \u00e0 d\u00e9crocher ton tout premier job\nTu as la fibre entrepreneuriale\nTu as soif de challenge et de nouveaux apprentissages\nTu es pr\u00eat \u00e0 cliquer sur le lien d\u2019inscription : www.licornesociety.com\nLes parcours particuli\u00e8rement valoris\u00e9s chez Licorne Society :\ndes exemples de prises d\u2019initiatives ou projets men\u00e9s avec l\u2019esprit entrepreneurial\ndes exp\u00e9riences dans des environnements particuli\u00e8rement exigeants\ndes exemples de r\u00e9alisations \u00e9difiants ou r\u00e9sultats chiffr\u00e9s\nOn se dit \u00e0 tout de suite sur la plateforme ?\n>> www.licornesociety.com <<\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "R"
            ],
            "DataBase": [],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [],
            "MachineLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [],
            "DevTools": [],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [
                "DevOps",
                "Cloud"
            ],
            "FrSoftSkills": [],
            "EnSoftSkils": [
                "Initiative"
            ]
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "title": "Ing\u00e9nieur DevOps/SRE F/H",
        "company": "Thales",
        "location": "V\u00e9lizy-Villacoublay, \u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/ing%C3%A9nieur-devops-sre-f-h-at-thales-3899044592?position=50&pageNum=0&refId=NuDbZkBPOnBALTaaBOYlpw%3D%3D&trackingId=ji3b0VY2ITNHhoK3uraI8A%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "QUI SOMMES-NOUS ?\nThales propose des syst\u00e8mes d\u2019information et de communication s\u00e9curis\u00e9s et interop\u00e9rables pour les forces arm\u00e9es, les forces de s\u00e9curit\u00e9 et les op\u00e9rateurs d\u2019importance vitale. Ces activit\u00e9s, qui regroupent radiocommunications, r\u00e9seaux, syst\u00e8mes de protection, syst\u00e8mes d\u2019information critiques et cybers\u00e9curit\u00e9, r\u00e9pondent aux besoins de march\u00e9s o\u00f9 l\u2019utilisation des nouvelles technologies num\u00e9riques est d\u00e9terminante. Thales intervient tout au long de la cha\u00eene de valeur, des \u00e9quipements aux syst\u00e8mes en passant par le soutien logistique et les services associ\u00e9s.\nPour r\u00e9pondre \u00e0 ces nouveaux enjeux et aux demandes croissantes de solutions innovantes et de technologies \u00e9mergentes, comp\u00e9titives, et souvent complexes ; nous nous sommes dot\u00e9s de collaborateurs qui vivent la culture Cloud et DevOps et sont form\u00e9s aux concepts X As Code (Infra As Code, Security As Code, Network As Code, \u2026) m\u00ealant une forte culture du d\u00e9veloppement logiciel aux probl\u00e9matiques de d\u00e9ploiement continu et aux contraintes de production.\nLe Centre de Comp\u00e9tence Software Factory & Cloud constitu\u00e9 de plus de 500 personnes est sp\u00e9cialis\u00e9 dans l\u2019int\u00e9gration et la s\u00e9curisation de logiciels OpenSource, le d\u00e9veloppement applicatif Cloud-natif, les architectures micro-services, la containerisation autour de Kubernetes, l\u2019int\u00e9gration et le d\u00e9ploiement continu (CI/CD) et l\u2019ing\u00e9nierie de fiabilit\u00e9 de site (SRE).\nQUI \u00caTES-VOUS ?\nIssu d\u2019une formation Bac +5\n(\u00e9cole d\u2019ing\u00e9nieur, Master ou \u00e9quivalent), Vous justifiez d\u2019une\nexp\u00e9rience de minimum 3 ans\nsur un poste similaire de\nConsultant\nDevops Cloud\n(H/F)\net vous ma\u00eetrisez les points suivants :\nde la plateforme Azure dans son ensemble et de l\u2019\u00e9cosyst\u00e8me associ\u00e9 : VNet/SubNet, VPN / ER, Azure FW, App Gateway, APIM, FD, AAD, etc\n(mod\u00e8le de d\u00e9ploiement Terraform et /ou ARM et/ou Bicep)\ndans Azure (Azure Policy, Azure Cost Management, etc)\net Exploitation Cloud Azure\ndu catalogue IaaS, PaaS sur Azure,\nPowerShell, Python\n(AZ-900, AZ-500, AZ-104, AZ-303, AZ-304) seraient un plus\nVous maitrisez l\u2019anglais\n\u00e0 l\u2019oral comme \u00e0 l\u2019\u00e9crit.\nVous avez une connaissance du secteur financier\net de ses m\u00e9tiers (banque, assurance ou mutuelle).\nCE QUE NOUS POUVONS FAIRE ENSEMBLE :\nRegroup\u00e9es en centres de comp\u00e9tences logiciel, nos \u00e9quipes participent \u00e0 des projets innovants et strat\u00e9giques pour nos clients Grand Comptes dans des secteurs d\u2019activit\u00e9s vari\u00e9s (la D\u00e9fense, de l\u2019Energie, de la Cybers\u00e9curit\u00e9 et de l\u2019A\u00e9ronautique). Notre \u00e9quipe du secteur\nBanque, Assurance, Mutuelle\nest \u00e0 la recherche d\u2019un\nIng\u00e9nieur DevOps/SRE\npour poursuivre leur croissance.\nActeurs majeurs bancaires en France, nos clients mettent en \u0153uvre des programmes de transformation dans tous les m\u00e9tiers bancaires afin d\u2019offrir une nouvelle exp\u00e9rience \u00e0 leurs clients et leurs collaborateurs, d\u2019acc\u00e9l\u00e9rer la digitalisation et \u00e0 am\u00e9liorer l\u2019efficacit\u00e9 op\u00e9rationnelle, et ceci de fa\u00e7on responsable.\nL\u2019utilisation de l\u2019IA, de la DATA, le d\u00e9veloppement du cloud, la convergence des plateformes technologiques et le d\u00e9ploiement de l\u2019APIsation du syst\u00e8me d\u2019information sont au c\u0153ur de leur mod\u00e8le et donc de nos missions. Vous interviendrez sur des projets de modernisation du SI, de mutualisation et d\u2019industrialisation de solutions num\u00e9riques innovantes.\nVos missions seront les suivantes :\nCr\u00e9ation d\u2019infrastructures sur le Cloud Azure\nen utilisant Terraform (Infra As Code)\nAccompagnement des \u00e9quipes de devs\nau quotidien dans une d\u00e9marche DevOps / GitOps\nR\u00e9soudre des incidents\nen investiguant sur les causes racines et en automatisant leur r\u00e9solution au sein de la squad SRE (Site Reliability Engineer).\nMigrations Cloud et Kubernetes\nMise en place et automatisation de la cha\u00eene de CI/CD\nProposer/participer \u00e0 des projets d\u2019innovation pour enrichir les offres cloud\nLe Poste requiert une forte app\u00e9tence technique. L\u2019accompagnement consiste \u00e9galement \u00e0 mettre en \u0153uvre les solutions pr\u00e9conis\u00e9es.\nLa perspective de rejoindre un Groupe innovant vous motive ? Alors rejoignez-nous en postulant \u00e0 cette offre !\nInnovation, passion, ambition : rejoignez Thales et cr\u00e9ez le monde de demain, d\u00e8s aujourd\u2019hui.\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "R"
            ],
            "DataBase": [],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [],
            "MachineLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [
                "Azure"
            ],
            "DevTools": [
                "Git"
            ],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [
                "Kubernetes"
            ],
            "InfrastructureAsCode": [
                "Terraform"
            ],
            "NetworkSecurty": [
                "VPN"
            ],
            "Virtualisation": [],
            "Containers": [
                "Kubernetes"
            ],
            "Collaboration": [],
            "Other": [
                "DevOps",
                "Cloud",
                "CI/CD"
            ],
            "FrSoftSkills": [
                "Communication"
            ],
            "EnSoftSkils": [
                "Communication"
            ]
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s",
                "3",
                "3",
                "3"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "title": "Data Engineer Devops H/F",
        "company": "Extia",
        "location": "Paris, \u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/data-engineer-devops-h-f-at-extia-3599185622?position=51&pageNum=0&refId=NuDbZkBPOnBALTaaBOYlpw%3D%3D&trackingId=bOBdBmlIQJrRbgF6oSqKNQ%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Vous souhaitez rejoindre une entreprise qui place l\u2019humain au c\u0153ur de ses pr\u00e9occupations ? On vous attend chez\nExtia\n!\nSoci\u00e9t\u00e9 de conseil sp\u00e9cialis\u00e9e dans les m\u00e9tiers de l\u2019IT, de l\u2019ing\u00e9nierie et du digital, Extia privil\u00e9gie depuis sa cr\u00e9ation en 2007 une approche qui allie performance et bien-\u00eatre au travail. Une vision de l\u2019entreprise partag\u00e9e aujourd\u2019hui par plus de 2 500 Extiens en France et \u00e0 l'international et r\u00e9compens\u00e9e par le label Great Place to Work\u00ae depuis 13 ans, notamment en\n2024 o\u00f9 les Extiens se hissent \u00e0 la premi\u00e8re place du palmar\u00e8s Best Workplaces France\n!\nChez Extia, c\u2019est \u00ab D\u2019abord qui, ensuite quoi \u00bb alors, allons-y !\nD'abord qui\nCurieux, vous adorez partager les derni\u00e8res id\u00e9es innovantes que vous avez d\u00e9couvertes\nRigoureux, vous ne laissez rien au hasard\nPers\u00e9v\u00e9rant, vous ne perdez jamais, soit vous gagnez, soit vous apprenez\nEnsuite quoi\nDans le cadre de votre mission, vos taches principales sont\n:\nL'impl\u00e9mentation de solutions techniques\nSens de l\u2019\u00e9change avec les diff\u00e9rents \u00e9quipiers, contributeurs de la division Data.\n\u00c9changes et pr\u00e9paration de demos avec les IT m\u00e9tiers.\nMaintien d'une veille technologique permanente.\nLes comp\u00e9tences techniques\n:\nAnalyse et d\u00e9veloppement\nD\u00e9veloppement en Java jusqu\u2019\u00e0 l\u2019int\u00e9gration avec les chaines CI/CD\nMaitrise des langages de programmation Java, Scala et Python\nMa\u00eetrise de Ansible, Terraform, Kubernetes...\nMa\u00eetrise de l\u2019\u00e9cosyst\u00e8me Hadoop, Spark, Kafka, ElasticSearch\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "Java",
                "Scala",
                "R",
                "Go"
            ],
            "DataBase": [
                "Elasticsearch"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [
                "Hadoop",
                "Spark"
            ],
            "MachineLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [],
            "DevTools": [
                "Git"
            ],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [
                "Ansible",
                "Kubernetes"
            ],
            "InfrastructureAsCode": [
                "Terraform"
            ],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [
                "Kubernetes"
            ],
            "Collaboration": [],
            "Other": [
                "CI/CD"
            ],
            "FrSoftSkills": [],
            "EnSoftSkils": []
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s",
                "13",
                "13",
                "13"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "title": "Cloud Security Engineer",
        "company": "Glocomms",
        "location": "France",
        "link": "https://fr.linkedin.com/jobs/view/cloud-security-engineer-at-glocomms-3910052052?position=52&pageNum=0&refId=NuDbZkBPOnBALTaaBOYlpw%3D%3D&trackingId=pRj5n9hfB0wpf%2B0fh03Zpg%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Senior ServiceNow Consultant\nOffice Location : Toulouse\nFully remote\nEnglish and French speaking project\nContract : 2 year project on a 6 month rolling contract\nStart date: Monday 3rd June\nWe are seeking a skilled and experienced Cloud Security Engineer to join our customer's team. The ideal candidate will be responsible for designing, implementing, and maintaining security measures to protect our cloud-based infrastructure and applications. The Cloud Security Engineer will work closely with our DevOps and IT teams to ensure that our cloud environments meet the highest standards of security and compliance.\nResponsibilities:\nDesign and implement security measures to protect cloud-based infrastructure and applications.\nConduct regular security assessments and audits of cloud environments.\nDevelop and maintain security policies, standards, and procedures for cloud environments.\nImplement access controls, encryption, and other security features to protect data in the cloud.\nMonitor cloud environments for security incidents and respond to incidents in a timely manner.\nWork closely with DevOps and IT teams to integrate security best practices into cloud deployment pipelines.\nStay up-to-date on the latest trends and developments in cloud security and recommend new security technologies and techniques.\nCollaborate with internal teams and external vendors to resolve security issues and implement security solutions.\nRequirements:\nBachelor's degree in Computer Science, Information Security, or a related field.\n5+ years of experience working in cloud security or a related field.\nIn-depth knowledge of cloud platforms such as AWS, Azure, or Google Cloud Platform.\nExperience with cloud security technologies and tools, such as IAM, WAF, and SIEM.\nStrong understanding of networking and network security principles.\nExperience with scripting languages such as Python, PowerShell, or Bash.\nCertifications such as Certified Cloud Security Professional (CCSP), Certified Information Systems Security Professional (CISSP), or AWS Certified Security Specialty are a plus.\nExcellent communication and collaboration skills.\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "R",
                "Go",
                "Bash"
            ],
            "DataBase": [],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [],
            "MachineLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [
                "AWS",
                "Azure",
                "Google Cloud Platform"
            ],
            "DevTools": [],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [
                "Teams"
            ],
            "Other": [
                "DevOps",
                "Cloud"
            ],
            "FrSoftSkills": [
                "Communication",
                "Collaboration"
            ],
            "EnSoftSkils": [
                "Communication",
                "Collaboration"
            ]
        },
        "details": {
            "JobDetail": [
                "Remote",
                "Full",
                "Senior"
            ],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "title": "DevOps Engineer Block Storage",
        "company": "Scaleway",
        "location": "France",
        "link": "https://fr.linkedin.com/jobs/view/devops-engineer-block-storage-at-scaleway-3918147786?position=53&pageNum=0&refId=NuDbZkBPOnBALTaaBOYlpw%3D%3D&trackingId=62wASrBEFl9kwKTkB5q1cw%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "About the job\nThe Storage Team is one of the pillars of Scaleway. This team not only develops the Scaleway Elements storage products (Block Storage), but also supports all the other Scaleway Elements products that rely on Block Storage (Instances, Database, Registry, Kubernetes, and more) for proper usage. In a challenging environment, and within a team that manages hundreds of storage servers across various regions, you will be responsible for developing, automating, and enhancing Scaleway\u2019s Block Storage solution.\nThis service launched by Scaleway offers resilient, redundant, and high-availability storage for its numerous clients. Your missions will require programming, automation, and architecture skills. On top of your daily activities within your team, you will need to interact with all of Scaleway\u2019s teams, especially Instances, Network, Hardware, and Platform.\nMinimum Qualifications\nExperienced System Engineer who is passionate about DevOps best practices and cloud architecture, ideally with over 5 years of experience\nExperience with (and love for) storage systems\nStrong system-level programming skills\nGood understanding of Golang.\nExperience with a continuous integration workflow, Gitlab, and Git\nStrong Linux knowledge\nDistributed systems (and debugging them)\nResponsibilities\nDeploying infrastructure in new Availability Zones\nImproving & bringing forward new ideas for our current infrastructure\nReacting to eventual failures in collaboration with other teams\nPresenting your work during tech meetings\nCoding, peer review, and deployment\nCustomer support in relation to your product\nDeploying your code\nPreferred qualifications\nSolid experience with Ceph in high capacity and/or performance environment\nGreat oral and written communication skills\nInfrastructure deployment with Ansible\nVery good command of English\nTechnical Stack\nCeph\nUbuntu/Debian\nAnsible\nGolang\nProtobuf\nPostgresql\nLocation\nThis position is based in our offices in Paris or Lille (France)\nRecruitment Process\nScreening call - 30 mins with the recruiter\nManager Interview - 45 mins\nTechnical Interviews\nHR Interview - 45 mins\nHead of Interview - 45 mins\nOffer sent - 48 hours\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "R",
                "Go"
            ],
            "DataBase": [
                "SQL"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [],
            "MachineLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [],
            "DevTools": [
                "Git"
            ],
            "Os": [
                "Linux"
            ],
            "DBMS": [
                "PostgreSQL"
            ],
            "SoftBigDataProcessing": [],
            "Automation": [
                "Ansible",
                "Kubernetes"
            ],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [
                "Kubernetes"
            ],
            "Collaboration": [
                "Teams"
            ],
            "Other": [
                "DevOps",
                "Cloud"
            ],
            "FrSoftSkills": [
                "Communication",
                "Collaboration"
            ],
            "EnSoftSkils": [
                "Communication",
                "Collaboration"
            ]
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "title": "Cloud Engineer Storage",
        "company": "Cloud Temple",
        "location": "\u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/cloud-engineer-storage-at-cloud-temple-3779352432?position=54&pageNum=0&refId=NuDbZkBPOnBALTaaBOYlpw%3D%3D&trackingId=SJlp%2BR9jCag6kk0bkGq1wA%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Afin de consolider notre \u00e9quipe Computing & Storage, Cloud Temple vous offre l'opportunit\u00e9 de nous rejoindre en tant que Cloud Engineer Storage F/H.\nMISSIONS :\nAu sein de l\u2019\u00e9quipe de Computing & Storage, vous \u00eates responsable du maintien et de l\u2019\u00e9volution de nos infrastructures compute et virtualisation ainsi que de la stabilit\u00e9 du service rendu au client. Vous travaillez sur des infrastructures certifi\u00e9es (SecNumCloud, HDS) avec de fortes contraintes de s\u00e9curit\u00e9 et de disponibilit\u00e9.\nEn tant que Cloud Engineer Storage , vous aurez comme mission :\nAssurer la gestion des \u00e9v\u00e8nements et incidents de production\nAssurer une r\u00e9solution rapide en cas d\u2019incident, identifier les causes racines et amener des correctifs\nMaintenir la conformit\u00e9 op\u00e9rationnelle et s\u00e9curitaire des services\nAssurer la gestion des changements en production en validant le niveau de risques en rapport avec les niveaux de service\nParticiper aux projets d\u2019\u00e9volution et de transformation des infrastructures et services\nAgr\u00e9menter et maintenir une base de connaissances techniques\nAssurer un suivi du traitement des incidents de bout en bout\nExigence du poste :\nNiveau de dipl\u00f4mes :\nBAC + 5\nComp\u00e9tences requises :\nConnaissance des outils Git, GitLab (CI/CD), Docker, Terraform, Ansible\nMaitrise des concepts ITIL\nConnaissance des produits VMware est un atout\nMaitrise d\u2019au moins un langage de programmation : Python, Bash, PHP, Golang, JAVA\nMa\u00eetrise des environnements UNIX (FeedBSD, Linux, Solaris) et r\u00e9seaux IP\nConnaissances linguistiques :\nAnglais : lu, parl\u00e9 et \u00e9crit\nExp\u00e9rience attendue\nAu moins 2 ans sur un poste similaire\nExp\u00e9rience en administration d\u2019infrastructure diverse et en gestion d\u2019environnement de production informatique certifi\u00e9s\nConnaissance des architectures des syst\u00e8mes d\u2019information\nMa\u00eetrise des protocoles et solutions de stockage standards\nCapacit\u00e9 \u00e0 automatiser des actions op\u00e9rationnelles au travers des scripts ou de programme\nMa\u00eetrise des solutions de supervision des services et leurs performances\nCapacit\u00e9 \u00e0 proposer et faire \u00e9voluer les process et outils de gestion de la production\nSavoir \u00eatre attendus\nSens de la qualit\u00e9 de service\nCapacit\u00e9 d\u2019adaptation et d\u2019automatisation dans un environnement en perp\u00e9tuelle \u00e9volution\nExcellentes comp\u00e9tences organisationnelles\nCapacit\u00e9 \u00e0 g\u00e9rer les situations de crise\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "Java",
                "R",
                "Go",
                "Bash"
            ],
            "DataBase": [],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [],
            "MachineLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [],
            "DevTools": [
                "Git",
                "Docker"
            ],
            "Os": [
                "Linux"
            ],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [
                "Ansible"
            ],
            "InfrastructureAsCode": [
                "Terraform"
            ],
            "NetworkSecurty": [],
            "Virtualisation": [
                "VMware"
            ],
            "Containers": [
                "Docker"
            ],
            "Collaboration": [],
            "Other": [
                "Cloud",
                "CI/CD"
            ],
            "FrSoftSkills": [
                "Organisation"
            ],
            "EnSoftSkils": []
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s",
                "2",
                "2",
                "2"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "title": "DevOps Engineer",
        "company": "Mazars",
        "location": "Paris, \u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/devops-engineer-at-mazars-3850005993?position=55&pageNum=0&refId=NuDbZkBPOnBALTaaBOYlpw%3D%3D&trackingId=ikPkXYPJBAlMpIHhKsp2jw%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Votre poste\nMazars is a leading international audit, tax and advisory firm, aspiring to build the economic foundations of a fair and prosperous world. Operating as a united partnership, Mazars works as one integrated team, leveraging expertise, scale and cultural understanding to deliver exceptional and tailored services in audit and accounting, as well as tax, financial advisory, consulting and legal services*.\nFounded in Europe, Mazars is present in over 95 countries and territories, with 47,000 professionals \u2013 30,000 in our integrated partnership, 17,000 via the Mazars North America Alliance \u2013 dedicated to helping clients make the most of business opportunities and operate with confidence.\n*where permitted under applicable country laws.\nVos principales missions\nThis is a permanent role reporting to Head of Platforms.\nTechnology & digital solutions (T&DS)\nMandated by Mazars Global Executive Board, the Technology & digital solutions team is leading Mazars digital transformation to unleash the next stage of Mazars growth. Specifically, the transformation will allow easier collaboration across geographies, quicker scalable service offering to clients in a safe, modern and sustainable way. As a result, Mazarians will enjoy a seamless experience and deliver more value to clients every day.\nTo reach these goals, Technology & digital solutions transformation programme aims at consolidating the IT operations from a multi-local model spread across 99+ countries into a global model. This includes the infrastructure and the operating model design needed to support Mazars business, people and clients now and in the future.\nThe success of this change relies on the great expertise and relentless engagement of every member of the team. This is a great moment to join the Technology & digital solutions organisation and be part of the delivery of this major transformation over the coming years!\nDevOps Engineer\nRole Purpose, Accountabilities, Experience, Knowledge, And Skills\nWe are looking for a DevOps Engineer to install, maintain, document, upgrade and optimise cloud & hybrid infrastructure while ensuring the reliability, security and availability of said platform, in close collaboration with the entire Global IT programme team.\nKey Responsibilities\nBuild\nManage the deployment of solutions, encompassing both applications and infrastructure, either through hands-on delivery or with third party support\nEnsure that deployments of new solutions comply with Global IT Enterprise Architectural standards\nOversee the handover of solutions into relevant service management teams via preparation of appropriate documentation and relevant training\nImagine, architect, develop, deploy, and evolve CI and CD systems for our cloud applications\nWrite Infrastructure as Code (IaC) using industry standard tools and services\nWrite application deployment automation using industry standard deployment and configuration tools\nRun\nProvide support and day to day administrator for deployed solutions\nOversee incident management activities related to global solutions and liaise with third party support partners through to resolution\nMonitor deployed solutions to ensure they are operating in an optimal manner\nManage patching, upgrades, service packs of compute components\nMaintain relevant documentation over the lifecycle of solutions ensuring they are kept up to date.\nVotre profil\nYou speak fluent English, and at least one other European language (French, Dutch, Spanish, ...)\nGood knowledge of IT best practices and design patterns.\nExcellent knowledge of (hybrid) cloud concepts and technologies, preferably utilizing Azure and Microsoft technologies. You are familiar with governance, monitoring, IAM, storage and server(less) infrastructure, and container concepts.\nCI/CD pipelines have no secrets for you anymore: you have a good experience in building a continuous delivery process: version management, automation, infrastructure as code\nKnowledge of Bicep.\nYou should be curious and fast at picking up new things with a sharp eye for details.\nYou should be eager to grow your skills and to embrace new challenges.\nPreferred Certifications\nAZ-104, AZ-900 preferred.\nAZ-400 highly desired\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Scala",
                "R",
                "Go"
            ],
            "DataBase": [],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [],
            "MachineLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [
                "AWS",
                "Azure"
            ],
            "DevTools": [
                "Git"
            ],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [
                "Teams"
            ],
            "Other": [
                "DevOps",
                "ML",
                "Cloud",
                "CI/CD"
            ],
            "FrSoftSkills": [
                "Collaboration",
                "Organisation"
            ],
            "EnSoftSkils": [
                "Collaboration"
            ]
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "title": "Senior Cloud DevOps Engineer (100% Remote -Europe)",
        "company": "Matomo",
        "location": "Paris, \u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/senior-cloud-devops-engineer-100%25-remote-europe-at-matomo-3883003015?position=56&pageNum=0&refId=NuDbZkBPOnBALTaaBOYlpw%3D%3D&trackingId=16d9rgitSoXgFNOAO479TQ%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Introduction\nWe\u2019re looking for an experienced DevOps engineer to work on our cloud hosted SaaS platform. We are the creators of Matomo, the leading open source web analytics solution that gives people full control of their data and built-in privacy. We have challenges to solve and need you!\nWe are fully remote and we collaborate online. We are a small, flexible team, and when you come onboard you will play an integral part in engineering. You\u2019ll help us to make our products better and deliver a great experience to our customers.\nKey Responsibilities\nBuild, manage and automate our SaaS web analytics platform on AWS\nEnsuring availability, performance, security, and scalability of the platform\nMaintain and improve CI/CD pipelines, Infrastructure as code, monitoring and alerting systems\nSupport software development, product and customer support teams to achieve business outcomes\nTake ownership of technical issues, and work with the team to resolve more advanced issues when necessary\nRespond to application and security incidents via a rotating On-Call schedule (two thirds of the time, including nights and weekends)\nMinimum Qualifications\n5+ years commercial experience working with the AWS cloud\nProficient with modern IaC tooling (e.g., Terraform, Cloud Formation, Pulumi)\nProficient in at least 1 popular scripting languages (e.g., Python, Typescript/Javascript)\nProficient in container technologies (e.g., Docker, Docker Compose, Kubernetes)\nProficient in Linux systems and shell scripting\nProficient in declarative modern CI/CD patterns (e.g., GitHub Action, Bitbucket Pipeline, GitLab CI/CD)\nProficient with modern software engineering workflows (e.g., Git, pull request, code review)\nUnderstanding of network topologies, high availability principles\nUnderstanding of monitoring concepts (e.g., metrics, dimensions, log analysis)\nStrong analytical skills and a passion for it to understand complex business logic\nGreat communication and collaboration skills\nAbility to work independently\nWilling to provide on-call support\nNice to have\nWorking knowledge of PHP\nMySQL server and SQL query optimisation\nLocation\n100% Remote work position ( Candidates must be willing to work a minimum of 4 hours overlapping with New Zealand per week)\nBenefits\nRemote work (save many hours on commute, and save money)\nCo-working space paid for and/or work from home\nAll home office equipment paid for (laptop, desk, chair, standing desk, lights, etc.)\nFlexible hours\n25 days of paid holidays per year plus your national public holidays\nSick leave\nHealth Insurance: Your Well-being, Our Priority\nA huge \u201cplayground\u201d to grow your skill set\nVolunteering Day: Empower Your Impact\nBereavement Leave for Pets: Compassion Beyond Boundaries\nTraining Opportunities\nMental Health Support Services\nOpportunity to work in a customer obsessed business, dedicated to building high-quality software with a strong mission of helping people grow their web projects while keeping full control of their data\nOpportunity to have an immediate impact on a product that is used by more than 1 million websites and almost 2% of the whole Internet\nAbout InnoCraft And Matomo Analytics\nAt InnoCraft, we offer analytics products and SaaS to enable our users to grow their business. We believe in openness, privacy and 100% data ownership. Our mission is to liberate analytics and we are passionate about measuring for success. That\u2019s why we created Matomo Analytics, the leading open source analytics platform used on more than 1 million websites and apps in over 150 countries, available in more than 50 languages. The Matomo platform collects, stores and processes a lot of information: hundreds of millions of data points each month. We create intuitive, simple and beautiful reports that delight our users.\nInnoCraft celebrates the things that make you, you! We are an inclusive employer and do not discriminate against any employee or applicant for employment because of race, color, religion, sex, sexual orientation, gender identity, national origin, age, marital status or disability. We actively seek diver\nsity in our workplace and embrace individuals with unique backgrounds, perspectives, and abilities!\nCome join our growing team that\u2019s helping ensure a safer, more privacy focused web/internet!\n#Hiring\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "Java",
                "Scala",
                "R",
                "JavaScript"
            ],
            "DataBase": [
                "SQL"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [],
            "MachineLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [
                "AWS"
            ],
            "DevTools": [
                "Git",
                "Docker"
            ],
            "Os": [
                "Linux"
            ],
            "DBMS": [
                "MySQL",
                "SQL Server"
            ],
            "SoftBigDataProcessing": [],
            "Automation": [
                "Kubernetes"
            ],
            "InfrastructureAsCode": [
                "Terraform"
            ],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [
                "Docker",
                "Kubernetes"
            ],
            "Collaboration": [
                "Teams"
            ],
            "Other": [
                "DevOps",
                "Cloud",
                "CI/CD"
            ],
            "FrSoftSkills": [
                "Communication",
                "Collaboration"
            ],
            "EnSoftSkils": [
                "Communication",
                "Collaboration"
            ]
        },
        "details": {
            "JobDetail": [
                "Remote",
                "Full"
            ],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "title": "DEVOPS CLOUD ENGINEER",
        "company": "STATION F",
        "location": "Paris, \u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/devops-cloud-engineer-at-station-f-3824854750?position=57&pageNum=0&refId=NuDbZkBPOnBALTaaBOYlpw%3D%3D&trackingId=WiKAqr%2Bd5xpJNB6dDqu10A%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "\u00c0 propos\nAllphins is the leading InsurTech company that provides risk management solutions for the insurance industry.\nAfter starting as a member of the Lloyd's Lab (reputable Insurtech accelerator in London) and being hosted at Station F (Paris), we now help 25+ clients cover all major commercial lines including Property, Energy, Political Risk, Trade Credit, Cyber, Casualty & Terrorism. Our goal is to help (re)insurers better analyse risks and make the right decisions.\nWith a strong international presence (UK & US) and self-financed growth (from 4 to 15 employees in 2 years), we seek to become the leading risk management platform for speciality risks.\nDescriptif du poste\nActivity\nAs a Cloud Devops at Allphins you will :\nImprove, maintain the current cloud infrastructure and helping the development team to scale the application\nApply site reliability engineering practices to a service (?)\nInsure the security of the app\nDevelop CI/CD for containerize application\nImplement infrastructure monitoring and optimize service performance\nEnsure the quality of the various release\nTechno\nCloud provider: GCP ( GKE, Network stack, Dataproc,...)\nContainerize app deploiment : Docker, Helm, kubernetes\nInfra as Code: Terraform\nCode versioning: Git\nDatabase technology: Postgresql, redis\nCode base: Python\nTechno Nice To Have\nKnowledge in big data architecture (using sprak, airflow etc\u2026)\nKnowledge in API development in python\nCode quality tools\nSoftskills\nExperience working with the scrum methodology\nProfil recherch\u00e9\nBackground : Master + 5 - Engineer\nExperience : 2 - 5 years\nSignificant experience as a devops engineering in a GCP environment.\nNice to have : you have already worked in a start up environment\nFluent in english\nWork at Allphins\n\u2600\ufe0f Key responsibilities: autonomy, impact & strong visibility\n\ud83c\udf0f Work in an international environment\n\ud83d\udcb8 Attractive remuneration (with benefits : Swile Card, Alan..)\n\ud83d\udcbb Hybrid working possible (2/3 days remote)\n\ud83d\ude80 Great career opportunities & solid learning\n\ud83c\udfe2 Offices in the center of Paris (WeWork Jules Lefebvre)\n\ud83e\uddbe High-end equipments (tools & technologies)\n\ud83c\udfd6\ufe0f One off-site per year\nProcess de recrutement\nInterview HR\nTech interview and case study\nInterview with Jean-Baptiste, CTO and co founder\nInformations compl\u00e9mentaires\nType de contrat : CDI\nLieu : Paris\nNiveau d'\u00e9tudes : Bac +5 / Master\nExp\u00e9rience : > 4 ans\nT\u00e9l\u00e9travail partiel possible\nSalaire : entre 49996\u20ac et 60000\u20ac / an\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "R",
                "Go"
            ],
            "DataBase": [
                "SQL"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [],
            "MachineLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [],
            "DevTools": [
                "Git",
                "Docker"
            ],
            "Os": [],
            "DBMS": [
                "PostgreSQL"
            ],
            "SoftBigDataProcessing": [],
            "Automation": [
                "Kubernetes",
                "Airflow"
            ],
            "InfrastructureAsCode": [
                "Terraform"
            ],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [
                "Docker",
                "Kubernetes"
            ],
            "Collaboration": [],
            "Other": [
                "DevOps",
                "Big Data",
                "Cloud",
                "CI/CD"
            ],
            "FrSoftSkills": [],
            "EnSoftSkils": []
        },
        "details": {
            "JobDetail": [
                "Remote"
            ],
            "TypeContract": [
                "CDI"
            ],
            "Salary": [
                "49996"
            ],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s",
                "4",
                "4",
                "4"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "title": "Cloud engineer Azure",
        "company": "Harnham",
        "location": "Paris, \u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/cloud-engineer-azure-at-harnham-3850370394?position=58&pageNum=0&refId=NuDbZkBPOnBALTaaBOYlpw%3D%3D&trackingId=YhfI68TMmLwFFOtDlPqW2g%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Cloud Engineer\nMinimum 1 an d'exp\u00e9rience en tant que Cloud engineer\nParis\n2jTT\nCDI\nNous sommes \u00e0 la recherche d'un(e) Cloud Engineer talentueux(se) pour rejoindre une \u00e9quipe dynamique dans le secteur du retail. En tant que Cloud Engineer, vous serez au c\u0153ur de notre transformation digitale, contribuant \u00e0 la conception, \u00e0 la mise en \u0153uvre et \u00e0 la maintenance de l'infrastructure cloud.\nStack technique : Azure, Powershell, ElasticSearch, Kibana, Grafana,\nResponsabilit\u00e9s Principales:\nConcevoir, d\u00e9ployer et g\u00e9rer notre infrastructure cloud sur Microsoft Azure, garantissant sa stabilit\u00e9, sa s\u00e9curit\u00e9 et sa performance.\nD\u00e9velopper des solutions d'automatisation pour le provisionnement, la configuration et la gestion des ressources cloud.\nCollaborer \u00e9troitement avec les \u00e9quipes techniques et m\u00e9tier pour comprendre les besoins et proposer des solutions cloud adapt\u00e9es.\nAssurer la conformit\u00e9 aux normes de s\u00e9curit\u00e9 et de gouvernance cloud.\nSurveiller et optimiser les performances des services cloud pour garantir une exp\u00e9rience utilisateur optimale.\nQualifications Recherch\u00e9es:\nDipl\u00f4me de Master en informatique ou dans un domaine connexe, ou exp\u00e9rience \u00e9quivalente avec au moins 1 an d'exp\u00e9rience dans un poste similaire.\nExp\u00e9rience av\u00e9r\u00e9e dans la conception, la mise en \u0153uvre et la gestion d'infrastructures cloud, de pr\u00e9f\u00e9rence sur\nMicrosoft Azure\n.\nMa\u00eetrise des outils et technologies DevOps, notamment\nAzure DevOps, PowerShell et Terraform\n.\nConnaissance approfondie des technologies de conteneurisation telles que\nKubernetes\n.\nExp\u00e9rience avec Elastic Search serait un atout.\nForte passion pour l'innovation et la r\u00e9solution de probl\u00e8mes, avec une orientation vers l'automatisation et l'am\u00e9lioration continue.\nCapacit\u00e9 \u00e0 travailler de mani\u00e8re proactive et autonome, avec un excellent esprit d'\u00e9quipe.\nMa\u00eetrise du fran\u00e7ais et de l'anglais est n\u00e9cessaire.\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "R",
                "Go"
            ],
            "DataBase": [
                "Elasticsearch"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [],
            "MachineLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [
                "Azure"
            ],
            "DevTools": [
                "Git"
            ],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [
                "Kubernetes"
            ],
            "InfrastructureAsCode": [
                "Terraform"
            ],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [
                "Kubernetes"
            ],
            "Collaboration": [],
            "Other": [
                "DevOps",
                "Cloud"
            ],
            "FrSoftSkills": [
                "R\u00e9solution de probl\u00e8mes"
            ],
            "EnSoftSkils": []
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [
                "CDI"
            ],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "title": "Cloud Architect (Azure) H/F",
        "company": "OPEN",
        "location": "Levallois-Perret, \u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/cloud-architect-azure-h-f-at-open-3720167006?position=59&pageNum=0&refId=NuDbZkBPOnBALTaaBOYlpw%3D%3D&trackingId=naa0VJmdk4499bQL4U2awQ%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Qui sommes-nous ?\nRejoindre la BU Cloud & DevOps, c\u2019est rejoindre La communaut\u00e9 d'experts techniques qui accompagne des sujets strat\u00e9giques et transverses pour Open France.\nVous serez en charge d'accompagner et conseiller nos clients autour des sujets Microsoft Cloud Azure depuis l\u2019expression et la collecte de leurs besoins fonctionnels.\nVos missions d\u00e9taill\u00e9es\nD\u00e9finir les architectures cibles Cloud et Hybride qui vont soutenir les briques du SI Client et capitaliser sur les projets pour d\u00e9finir nos standards d\u2019architecture.\nD\u00e9finir les chemins de migration et de transition des applications et des workloads clients vers Microsoft Azure,\nImpl\u00e9menter ou coordonner l\u2019int\u00e9gration des architectures et des solutions propos\u00e9es,\nAccompagner nos forces de vente dans les soutenances des dossiers de r\u00e9ponse complexes,\nParticiper activement \u00e0 la conception des nouvelles offres, en capitalisant sur les projets et les architectures d\u00e9j\u00e0 produites.\nVous\nDisposez d\u2019une premi\u00e8re exp\u00e9rience significative dans la conception d\u2019architecture de solutions et de services Cloud/SaaS privil\u00e9gi\u00e9s sur Microsoft Cloud Azure,\nMaitrisez sur le plan technique les concepts d\u2019architecture en Cloud Public : Microsoft Azure, IaaS/PaaS/SaaS, Azure Stack(s), solutions hybrides et multicloud, s\u00e9curit\u00e9 et gouvernance du Cloud, modernisation d\u2019applications et de donn\u00e9es,\nAimez travailler en \u00e9quipe et dans la bonne humeur,\nAvez le sens du service,\nAvez le go\u00fbt du challenge et la culture du r\u00e9sultat,\n\ud83e\udd1d Vous \u00eates mettre de votre carri\u00e8re : Comment ?\nInt\u00e9grer des projets transverses et strat\u00e9giques : outils interne, meetup, summit, formation, avant-ventes, chiffrage, veille, audit SI \u2026\nEvoluer vers votre r\u00f4le gr\u00e2ce \u00e0 un accompagnement personnalis\u00e9 et un parcours de formation et certifications adapt\u00e9.\nNotre process de recrutement\nBref \u00e9change t\u00e9l\u00e9phonique\nRencontre RH pour parler de vous, de vos aspirations professionnelles et vous pr\u00e9senter Open,\nEchange avec l\u2019un des experts\nTemps de partage avec votre futur manager.\n\u2705Apr\u00e8s vous avoir souhait\u00e9 la bienvenue vous b\u00e9n\u00e9ficiez d\u2019un parcours d\u2019int\u00e9gration sur-mesure.\nCODE REC : ACH23516\nQu\u2019attendez-vous pour \u00eatre Open ?\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "R",
                "Go"
            ],
            "DataBase": [],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [],
            "MachineLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [
                "Azure"
            ],
            "DevTools": [],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [
                "DevOps",
                "Cloud"
            ],
            "FrSoftSkills": [],
            "EnSoftSkils": []
        },
        "details": {
            "JobDetail": [
                "Hybride"
            ],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "title": "Senior Data & Cloud Engineer (H/F)",
        "company": "fifty-five",
        "location": "Paris, \u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/senior-data-cloud-engineer-h-f-at-fifty-five-3915044673?position=60&pageNum=0&refId=NuDbZkBPOnBALTaaBOYlpw%3D%3D&trackingId=3mDM8SFFfN23w70AQMCGNQ%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Senior Data & Cloud Engineer\nfifty-five est une data-company d'un genre nouveau qui aide les marques \u00e0 exploiter les donn\u00e9es pour am\u00e9liorer le marketing, les m\u00e9dias et l'exp\u00e9rience client gr\u00e2ce \u00e0 une combinaison de services de conseil et de technologie sp\u00e9cialis\u00e9s.\nEn tant que pilier data et marketing du Brandtech Group, nous offrons des services qui combinent le conseil en strat\u00e9gie, les services de cloud, le conseil en m\u00e9dia et l'exp\u00e9rience client.\nfifty-five, c'est plus de 400 experts du num\u00e9rique. Des digital consultants, des sp\u00e9cialistes du tracking et du m\u00e9dia, des ing\u00e9nieurs et des data scientists, travaillent tous en \u00e9troite collaboration pour fournir des conseils marketing de haut niveau et une assistance technique aux marques, dans tout type d'industrie, partout dans le monde.\nPartenaire des annonceurs de la collecte \u00e0 l'activation et l'exploitation des donn\u00e9es, nous aidons les organisations \u00e0 devenir de v\u00e9ritables entit\u00e9s omnicanales ma\u00eetrisant l'efficacit\u00e9 de leur \u00e9cosyst\u00e8me digital et ses synergies avec le monde physique.\nBas\u00e9 \u00e0 Paris, nous op\u00e9rons sur 3 fuseaux horaires depuis nos 10 bureaux, situ\u00e9s \u00e0 Paris, Londres, Gen\u00e8ve, Milan, Shanghai, Hong Kong, Shenzhen, Taipei, Singapour et New York. fifty-five attache une importance particuli\u00e8re au bien-\u00eatre de ses collaborateurs, ce qui lui a permis de figurer dans le classement Best Workplaces France en 2018.\nContexte :\nL'\u00e9quipe d'ing\u00e9nierie d\u00e9veloppe et met en \u0153uvre les solutions techniques permettant la r\u00e9alisation de pipelines de donn\u00e9es et l'impl\u00e9mentation de data platform pour nos clients : r\u00e9cup\u00e9ration de datas sur de multiples sources de donn\u00e9es (APIs, files, etc.), data cleaning, data processing, automation et monitoring de l'ensemble. L'\u00e9quipe s'appuie sur des technologies r\u00e9centes (docker, kubernetes, terraform, notebooks, etc.) et met en place ses projets dans les diff\u00e9rents clouds du march\u00e9 (GCP, Azure, AWS...).\nMission :\nNous sommes \u00e0 la recherche d'une personne capable de r\u00e9aliser des projets techniques pour r\u00e9pondre aux besoins de nos clients (par exemple: syst\u00e8me de recommandations de produits, d\u00e9tection d'anomalies, ranking). Les activit\u00e9s vont du chiffrage et du sizing technique \u00e0 la mise en \u0153uvre des architectures, en passant par la revue des sp\u00e9cifications fonctionnelles et la production de code. Le Data & Cloud Engineer sera \u00e9paul\u00e9 par un Lead dans ses missions. Il sera \u00e9galement amen\u00e9 \u00e0 participer \u00e0 la R&D et \u00e0 accompagner les \u00e9quipes transverses dans la mise en place d'outils de travail internes (librairies pour les data scientists, environnement Notebooks pour les data analysts et data scientists, d\u00e9veloppement de frameworks sur diff\u00e9rents cloud providers, etc.).\nNous souhaitons trouver la bonne personne pour faire \u00e9voluer ou cr\u00e9er de nouvelles solutions dans ce cadre. Les missions comprennent aussi bien du prototypage rapide pour des d\u00e9monstrateurs, que de la production de code robuste qui tourne en production tous les jours.\nComp\u00e9tences et exp\u00e9riences :\n4-5 ans d'exp\u00e9rience en tant que Data Engineer\nMa\u00eetrise de Python, SQL\nMa\u00eetrise des environnements Cloud. Id\u00e9alement certifi\u00e9 GCP, Azure ou AWS\nBonne connaissance de Docker/Kubernetes\nBonne connaissance d'au moins un data warehouse (BigQuery, Snowflake, etc)\nConnaissance autour des Notebooks (Jupyter)\nA l'aise avec des concepts li\u00e9s aux APIs (OAuth, REST, etc.)\nA l'aise avec les notions d'Infrastructure as Code (Terraform)\nAu courant des pratiques GitOps et connaissances des concepts autour du CI/CD\nLa ma\u00eetrise d'un orchestrateur, comme Apache Airflow, est un plus\nEsprit d'\u00e9quipe (collaborer aux tests unitaires, revue de code, partage de code, sprints)\nBon niveau en fran\u00e7ais et en anglais\nA d\u00e9j\u00e0 travaill\u00e9 en mode projet avec des interlocuteurs vari\u00e9s (consultant, data analyst, data scientist)\nUne exp\u00e9rience en marketing digital est un plus\nNous proposons :\nun bureau au centre de Paris avec terrasse et jardin\nun environnement multiculturel avec des collaborateurs aux nationalit\u00e9s multiples (France, Royaume-Uni, Etats-Unis, Chine, Tunisie, Italie et plus)\ndes projets avec nos bureaux \u00e0 Londres, Hong Kong, New York, Shanghai, Gen\u00e8ve, Shenzhen et Taipei\ndes TGIF et supers soir\u00e9es\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "R"
            ],
            "DataBase": [
                "SQL"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [
                "Apache Airflow"
            ],
            "MachineLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [
                "AWS",
                "Azure"
            ],
            "DevTools": [
                "Git",
                "Docker"
            ],
            "Os": [],
            "DBMS": [
                "Snowflake",
                "Snowflake",
                "BigQuery"
            ],
            "SoftBigDataProcessing": [],
            "Automation": [
                "Kubernetes",
                "Airflow"
            ],
            "InfrastructureAsCode": [
                "Terraform"
            ],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [
                "Docker",
                "Kubernetes"
            ],
            "Collaboration": [],
            "Other": [
                "Cloud",
                "CI/CD"
            ],
            "FrSoftSkills": [
                "Collaboration",
                "Organisation"
            ],
            "EnSoftSkils": [
                "Collaboration"
            ]
        },
        "details": {
            "JobDetail": [
                "Senior"
            ],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s",
                "5",
                "5",
                "5"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "title": "DevOps/Cloud Engineer with IT Experience",
        "company": "WhiteLab Genomics",
        "location": "Paris, \u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/devops-cloud-engineer-with-it-experience-at-whitelab-genomics-3919802817?position=1&pageNum=2&refId=UAjmJD%2Bo5LxF5kj2yfoeDg%3D%3D&trackingId=eHEToi0UkvdlfCNxArZA9w%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "WhiteLab Genomics\nwas founded with the belief that life-saving drugs should be accessible to all patients in need. United in our vision, we\u2019ve become a part of Y Combinator, French Tech 2030, Future 40 by Station F, and we\u2019ve been recognized by The Galien Foundation (\u201dBest Startup\u201d category), among other institutions at the forefront of technology. Today, we strive to become the leading expert in A.I. for genomic medicine, operating as the go-to partner for research and development.\nIn this critical and multifaceted role\n, you will lead the maintenance, development, and fortification of our AI/IT infrastructure for genomic medicine. We\u2019re in the process of setting up and scaling our Cloud infrastructure, and you\u2019ll play a valuable role in helping us scale up, leading the charge in optimizing our cloud services, streamlining workflows, and ensuring seamless integration with our DevOps practices and automation frameworks. To scale our current architecture to a higher level, you will help us identify our current bottlenecks, propose new Cloud based solutions, implement them, and help users to use them, allowing for enhanced efficiency. Fostering an atmosphere of productivity and teamwork, your expertise will drive our mission towards greater technological excellence and innovation.\nThis is an\nincredible opportunity\nto work on a diversity of engaging tasks in a hybrid role, forming the infrastructure of a vibrant start-up that seeks to make an impact on the future of healthcare \u2013- you'll play a crucial role in helping revolutionize genomic medicine with AI.\nOur Core Values:\nWe Believe that Care is Everything.\nWe Value our Collective Potential\nWe Cultivate Proactive Communication, Clarity and Respect\nWe Have a Can-Do Attitude\nWe Strive for Excellence\nWe\u2019re Eager to Meet You If\u2026\nProficiency in DevOps methodologies and tools, including proven experience in implementing robust continuous integration, continuous deployment (CI/CD) pipelines, infrastructure as code (IaC), and automated testing frameworks\nDemonstrated experience with coding (preferably Python) for automation tasks and infrastructure management and team interactions for orchestration tasks\nYou have expertise in cloud services (AWS, Azure, or Google Cloud), with a track record of designing, deploying, and managing scalable cloud-based infrastructure solutions tailored to business needs. Your comprehensive understanding of cloud services will enable seamless integration with DevOps practices and automation workflows\nYou have at least\n1 year of prior hands-on experience\nin managing IT equipment, tools, and issues at a tech company (preferably a tech start-up) and excel in administering SharePoint and email systems, ensuring smooth operations and user support\nYou possess great problem solving ability and can work autonomously\nYou have expertise in hardware, software, and network systems\nYou can manage pipelines, optimizing workflows for efficient deployment and delivery\nYour interpersonal skills allow you to collaborate effectively with cross-functional teams, including researchers, data scientists, business development professionals, and support functions\nYou can adapt to a dynamic and rapidly evolving industry, staying on top of the latest IT advancements\nYou have excellent verbal and written communication skills and have experience interfacing with stakeholders and users in English - French proficiency is a plus!\nYou\u2019re knowledgeable of standard practices for access control models, data protection regulations, IT security, and compliance protocols\nHere\u2019s How You\u2019ll Make an Impact\u2026\nYou\u2019ll provide strategic and technical leadership to all of our teams, guiding the development and implementation of innovative solutions towards orchestration, CI/CD and security standards\nYou\u2019ll set up and manage CI/CD pipelines to automate processes\nYou\u2019ll write automation scripts to automate routine orchestration tasks and manage our infrastructure efficiently\nYou\u2019ll design, deploy, and manage scalable cloud-based infrastructure solutions\nYou\u2019ll integrate cloud services with DevOps practices and automation workflows\nYou\u2019ll oversee the operation and maintenance of IT tools and infrastructure, ensuring reliability, performance, and security\nYou\u2019ll manage user roles, permissions, and access control for Cloud services, SharePoint, and email systems in compliance with data protection regulations\nYou\u2019ll administer and optimize SharePoint and other collaboration tools to enhance team productivity\nYou\u2019ll ensure all technology systems and platforms operate reliably and efficiently\nYou\u2019ll implement and maintain security policies and procedures, conducting regular audits to ensure compliance with industry standards\nYou\u2019ll provide technical support, resolving issues related to hardware, software, network problems, systems, and access permissions\nYou\u2019ll manage and maintain all IT equipment and tools, ensuring they\u2019re up to date and in good working condition\nYou\u2019ll lead Cloud and Helpdesk projects from inception to completion, ensuring projects are delivered on time, within budget, and meet quality standards\nYou\u2019ll implement best practices in IT operations and cybersecurity to safeguard company data and systems\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "Scala",
                "R",
                "Go"
            ],
            "DataBase": [],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [],
            "MachineLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [
                "AWS",
                "Azure"
            ],
            "DevTools": [],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [
                "Teams"
            ],
            "Other": [
                "DevOps",
                "ML",
                "Cloud",
                "CI/CD"
            ],
            "FrSoftSkills": [
                "Communication",
                "Leadership",
                "Collaboration"
            ],
            "EnSoftSkils": [
                "Communication",
                "Teamwork",
                "Problem Solving",
                "Leadership",
                "Collaboration",
                "Interpersonal Skills"
            ]
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "title": "Cloud Engineer",
        "company": "Equativ",
        "location": "Paris, \u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/cloud-engineer-at-equativ-3804533620?position=2&pageNum=2&refId=UAjmJD%2Bo5LxF5kj2yfoeDg%3D%3D&trackingId=lDzrBRhdea%2BAEXBS%2FUA16Q%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "\ud83d\udc6b About the team\nAt Equativ, we\u2019re on a mission to develop advertising technologies that empower our customers to reach their digital business goals. This means that we rely on massively scalable, widely distributed, highly available, and efficient software systems; the platform deals with over 3 millions requests per second managed by 3,000 servers.\nOur innovation team based in Paris, Nantes, Limoges, Krakow and Berlin is composed of 100+ straightforward and energetic engineers working in an Agile environment and ready to tackle the most complex technical challenges.\nYour mission \ud83d\udc47\nWithin infra BU you will join the Platform department that strives to develop and deploy self-serve tooling to empower our RnD team.\nOur platform is gradually moving to a hybrid cloud platform. You will be joining as the second member of our cloud platform team:\nYou will help deliver a smooth transition of our RnD team to a hybrid cloud architecture.\nYou will be responsible for cloud governance and FinOps.\nYou will provide help to our engineering teams in order to optimize costs of our GCP components\nWhat you will do \u270f\ufe0f\nAs a Cloud engineer in our new cloud platform team your missions will be to:\nDesign and develop self-serve tooling for our engineering teams to transition and maintain their workloads to the cloud.\nDesign and instrumentalize Finops guidelines to manage the overall ROI of our cloud infrastructure.\nHelp design and develop our cost management framework to help teams optimize their operational ROI.\nPropagate best-practices and know-how on cloud services and architectural patterns.\nImplement terraform modules to support our IAC approach on the cloud.\nEvaluate the CO2 savings associated with optimizing our cloud infrastructure usage.\nAbout you \ud83d\udc4b\nMaster degree in Computer science or similar field of study.\n1+ years of System, Cloud or Software Engineering experience ideally in the web industry.\nAutonomous and innovative mindset.\nExperience in GCP cloud governance for production projects and collaboration within a 5+ engineering team.\nFluent with DevOps practices, specifically on Google Cloud Platform.\nInterested in the impact of technical decisions on business (finops approach) and environmental outcomes.\nWorking proficiency and communication skills in verbal and written English.\nNice to have:\nExperience in one or more of the following GCP topics: Finops, big data components for large datasets, Kubernetes administration.\nExperience working with IaC (Terraform or other).\nExperience in software development (Go, Python or equivalent).\nHow you'll grow \ud83d\ude80\nWithin 1 month:\nYou'll be just finishing your onboarding.\nYou'll probably have tackled a few small tasks with your peer.\nWithin 4 months:\nYou'll be trusted to review budget increases from development teams.\nYou'll be expected to propose small-scale optimisations on our cloud architecture.\nWithin 9 months:\nYou'll be in contact with most of the tech leads operating on GCP.\nYou'll be evolving our terraform architecture to deploy resources to the cloud.\nYou\u2019ll start getting a grasp on the AdTech business.\n\ud83d\udc4b About us\nEquativ is the new single name for Smart Adserver, DynAdmic, LiquidM and Nowtilus \u2014 four proven innovators in advertising technology. The vertically integrated company provides brand and privacy-safe solutions that empower its clients to achieve maximum impact while respecting the rights of consumers. The union combines client expertise and engineering excellence to serve the interests of both the supply- side and demand-side with equal professionalism and technical sophistication.\nHeadquartered in Paris and New York, Equativ operates globally with a team of more than 550 people in 20 offices. Equativ offers the market its own independent ad server, SSP, buyer tools, and media services to fulfill the promise of advertising technology. Learn more at Equativ.com.\nThe company is ranked on the Deloitte Technology Fast 500 EMEA and in the Financial Times\u2019 FT 1000: Europe\u2019s Fastest-Growing Companies.\nEquativ (formerly Smart AdServer) has been awarded the HappyIndex@Work label and is proud to be among the best companies in the ChooseMyCompany ranking, recognized for its flexible working environment.\nCome and lead the charge with us in building a transparent ecosystem based on quality!\n----------------------\nEquativ is an equal opportunity employer. Equal access to employment, services, and programs are available to everyone, regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity, or Veteran status. If you require reasonable accommodation throughout the application and/or interview process, please contact the recruitment team at ta-team@equativ.com\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "Scala",
                "R",
                "Go"
            ],
            "DataBase": [],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [],
            "MachineLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [
                "Google Cloud Platform"
            ],
            "DevTools": [
                "Git"
            ],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [
                "Kubernetes"
            ],
            "InfrastructureAsCode": [
                "Terraform"
            ],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [
                "Kubernetes"
            ],
            "Collaboration": [
                "Teams"
            ],
            "Other": [
                "DevOps",
                "Big Data",
                "Cloud"
            ],
            "FrSoftSkills": [
                "Communication",
                "Collaboration"
            ],
            "EnSoftSkils": [
                "Communication",
                "Collaboration"
            ]
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "title": "DevOps Engineer \u2013 Antibes, France (H/F)",
        "company": "Astek",
        "location": "Antibes, Provence-Alpes-C\u00f4te d'Azur, France",
        "link": "https://fr.linkedin.com/jobs/view/devops-engineer-%E2%80%93-antibes-france-h-f-at-astek-3829412893?position=3&pageNum=2&refId=UAjmJD%2Bo5LxF5kj2yfoeDg%3D%3D&trackingId=FvyWkK7aw5uZBIQCKxvOfw%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "CDI\nAntibes - France\nPubli\u00e9e il y a 2 jours\nLe Groupe Astek\nCe Que Nous Allons Accomplir Ensemble :\nRejoindre une \u00e9quipe dans les domaines du transport et du tourisme sur des projets ambitieux dans lesquels la satisfaction clients et les solutions \u00e0 valeur ajout\u00e9e jouent un r\u00f4le crucial.\nVotre Mission, Si Vous L\u2019acceptez :\nComprendre les exigences du client ;\nEncourager et construire des processus automatis\u00e9s dans la mesure du possible\nContr\u00f4ler les processus tout au long du cycle de vie pour s\u2019assurer de leur respect\nD\u00e9finir et param\u00e9trer les processus de d\u00e9veloppement, de test, de mise en production, de mise \u00e0 jour et de support pour le fonctionnement DevOps.\nVotre Future \u00c9quipe :\nVenez rejoindre une \u00e9quibe ambitieuse et dynamique dans un environnement international\nVotre stack de jeu\nAnsible, Python, Jenkins, Docker et Kubernetes\nLes Petits Plus Du Projet :\nVous \u00e9voluerez au sein d\u2019une \u00e9quipe impliqu\u00e9e et r\u00e9active dans un environnement international et interviendrez sur des projets passionnants et enrichissants.\nVous ?\nDipl\u00f4m\u00e9(e) d\u2019une \u00e9cole d\u2019ing\u00e9nieur ou \u00e9quivalent de niveau Bac+5. Vous justifiez id\u00e9alement d\u2019une exp\u00e9rience sur un poste similaire ;\nVotre personnalit\u00e9, votre esprit d\u2019\u00e9quipe, votre autonomie, votre relationnel, votre rigueur, votre cr\u00e9ativit\u00e9 ainsi que votre curiosit\u00e9 seront des atouts essentiels pour mener \u00e0 bien vos missions sur le projet ;\nVous maitrisez les comp\u00e9tences techniques backend de base : Python, Kubernetes, Jenkins, Docker,\u2026\nAstek\nCr\u00e9\u00e9 en France en 1988, Astek est un acteur mondial de l\u2019ing\u00e9nierie et du conseil en technologies. Fort de son expertise dans de nombreux secteurs industriels et tertiaires, Astek accompagne ses clients internationaux dans le d\u00e9ploiement intelligent de leurs produits et de leurs services, et dans la mise en \u0153uvre de leur transformation digitale.\nDepuis sa cr\u00e9ation, le Groupe a fond\u00e9 son d\u00e9veloppement sur une forte culture d\u2019entrepreneuriat et d\u2019innovation, et sur l\u2019accompagnement et la mont\u00e9e en comp\u00e9tence de\nses 7800 collaborateurs\nqui s\u2019engagent chaque jour \u00e0 promouvoir la compl\u00e9mentarit\u00e9 entre les technologies num\u00e9riques et l\u2019ing\u00e9nierie des syst\u00e8mes complexes.\nRejoignez un Groupe en fort d\u00e9veloppement en France et \u00e0 travers le monde ayant r\u00e9alis\u00e9 un chiffre d\u2019affaires de 600 M\u20ac en 2023.\nTous les d\u00e9tails sur le Groupe sur le site https://astekgroup.fr. Et vous pouvez aussi nous suivre sur notre blog : https://blog.groupeastek.com.\nRencontrons-nous\nKillian, notre Talent Acquisition Officer, vous contactera afin de faire un point avec vous.\nEnsuite, Vous \u00c9changerez Avec :\nvotre futur manager (futur N+1) afin de discuter de ASTEK, votre parcours, vos attentes et la mission ;\nvotre directeur d\u2019agence pour valider votre int\u00e9r\u00eat pour le poste et vous pr\u00e9senter les \u00e9l\u00e9ments contractuels.\nNos Plus\nAstek est green et fait b\u00e9n\u00e9ficier ses salari\u00e9s d\u2019une indemnit\u00e9 kilom\u00e9trique v\u00e9lo\nUne politique CARE sur-mesure d\u00e9ploy\u00e9e par nos \u00e9quipes RH pour nos collaborateurs (https://astekgroup.fr/engagements)\nNotre charte de la Diversit\u00e9\nBienvenue dans la team ! Allez-y, maintenant c\u2019est \u00e0 vous de jouer !\nMots-cl\u00e9s :\ndevops \u2013 ing\u00e9nieur \u2013 ing\u00e9nieure \u2013 consultant \u2013 consultante \u2013 terraform \u2013 ansible \u2013 python\nCaract\u00e9ristiques de l'emploi\nCat\u00e9gorie Ing\u00e9nieur\nJob Industry Distribution / Services Internet, Transports Terrestres\nPostuler en ligne\nNom *\nPr\u00e9nom *\nEmail *\nUn email valide est requis.\nT\u00e9l\u00e9phone *\nUn num\u00e9ro de t\u00e9l\u00e9phone valide est requis.\nJoindre un CV *\nMots-cl\u00e9s :\ndevops \u2013 ing\u00e9nieur \u2013 ing\u00e9nieure \u2013 consultant \u2013 consultante \u2013 terraform \u2013 ansible \u2013 python\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "R",
                "Go"
            ],
            "DataBase": [],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [],
            "MachineLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [],
            "DevTools": [
                "Git",
                "Docker",
                "Jenkins"
            ],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [
                "Ansible",
                "Kubernetes"
            ],
            "InfrastructureAsCode": [
                "Terraform"
            ],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [
                "Docker",
                "Kubernetes"
            ],
            "Collaboration": [],
            "Other": [
                "DevOps"
            ],
            "FrSoftSkills": [
                "Cr\u00e9ativit\u00e9"
            ],
            "EnSoftSkils": []
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [
                "CDI"
            ],
            "Salary": [],
            "Level": [
                "Bac+5"
            ],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "title": "Cloud Platform Engineer",
        "company": "Contemporary Amperex Technology Co., Limited",
        "location": "Paris, \u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/cloud-platform-engineer-at-contemporary-amperex-technology-co-limited-3888137773?position=4&pageNum=2&refId=UAjmJD%2Bo5LxF5kj2yfoeDg%3D%3D&trackingId=VTzkp1FzC5uNkAZGjntn9Q%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "CATL invites you to continue our legend of green energy. CATL is a World Fortune 300 Company, a global leader who provides premier EV battery and energy storage battery for the world. CATL\u2019s EV battery consumption volume has ranked No.1 in the world for six consecutive years and global energy storage battery shipment has also ranked No.1 for two consecutive years.\nJob Responsibilities:\n1. Responsible for the operation of overseas big data platforms, formulate data access plans and programs, promote the implementation of data access programs, and realize data access of big data platforms;\n2. Responsible for customer docking, daily customer operation, demand communication and demand analysis of commercial vehicles, passenger cars and energy storage in Europe;\n3. Responsible for data management and data operation, coordinate internal and external resources, and form a normative docking process;\n4. Study the mechanism of battery products, collect data characteristics, and analyze data of specific business problems based on technical indicators;\n5. Responsible for the application and landing of the algorithm model, carry out data cleaning, prediction model establishment, training and optimization for the application scenario, and solve the problems of target recognition, classification, prediction, fault diagnosis and prediction in the scenario;\n6. Responsible for daily operation and maintenance of big data platform, such as operation and maintenance and algorithm deployment.\nJob requirements:\n1.Master degree or above, major in computer,software engineering, data science, vehicle engineering, management science and engineering, artificial intelligence, mathematical statistics and other science and engineering;\n2.\u2460 Familiar with commonly used machine learning and deep learning algorithms and models;\n\u2461 Familiar with mainstream cloud platform products (AWS, Azure, etc.) and understand the cloud native architecture system;\n\u2462 Familiar with Linux system principle and shell programming.\n3.\u2460 Have the understanding and mastery of Hadoop ecological technology stack, including but not limited to Spark, flink, storm, kafka, flume, HDFS, etc.;\n\u2461 Familiar with distributed storage and database technologies, including but not limited to ClickHouse, Greenplum, Redis, MonogoDB, ElasticSearch, etc., and skilled in using common data warehouse architectures;\n\u2462Master Java, Python, R and other programming languages, and skillfully use Python for data analysis;\n4. At least 2 years working experience in big data platform development or data analysis, experience in automobile industry, new energy or car networking industry is preferred;\n5. English as the working language, familiar with French is preferred;\n6. Strong communication and coordination skills, strong problem analysis and problem-solving skills, strong learning ability,business insight and data understanding ability, high sense of responsibility, and positive working attitude, cheerful personality, with certain pressure resistance.\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "Java",
                "R",
                " R ",
                "Go"
            ],
            "DataBase": [
                "Elasticsearch"
            ],
            "DataAnalytics": [
                "R",
                " R "
            ],
            "BigData": [
                "Hadoop",
                "Spark",
                "Flink"
            ],
            "MachineLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [
                "Statistics"
            ],
            "CloudComputing": [
                "AWS",
                "Azure"
            ],
            "DevTools": [],
            "Os": [
                "Linux"
            ],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [
                "Big Data",
                "Machine Learning",
                "Cloud"
            ],
            "FrSoftSkills": [
                "Communication"
            ],
            "EnSoftSkils": [
                "Communication"
            ]
        },
        "details": {
            "JobDetail": [
                "Full"
            ],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "title": "CLOUD ENGINEER",
        "company": "STATION F",
        "location": "Nantes, Pays de la Loire, France",
        "link": "https://fr.linkedin.com/jobs/view/cloud-engineer-at-station-f-3919657457?position=5&pageNum=2&refId=UAjmJD%2Bo5LxF5kj2yfoeDg%3D%3D&trackingId=buVObDFW7aLeNfEgOMCeUw%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "About\nAB Tasty is a global leader in AI-powered experience optimization solutions empowering brands using personalization, experimentation, recommendations, and search to build better experiences on their websites and apps.\nIntegrated into a single platform, AB Tasty offers web and API-based solutions that provide companies with a unified approach to facilitating seamless experiences for customers.\nBrands use AB Tasty\u2019s platform to align digital, e-commerce, and product teams on revenue goals by maximizing digital impact.\nFounded in 2013, AB Tasty\u2019s customer roster includes world-leading brands such as Kering, McDonald\u2019s, Ulta Beauty, L\u2019Oreal, Disneyland Paris, and LVMH among others.\nAB Tasty has 12 offices across the globe : North America, Europe, Asia Pacific (Australia and Singapore).\nJob Description\nAB Tasty is a global leader in AI-powered experience optimization solutions empowering brands using personalization, experimentation, recommendations, and search to build better experiences on their websites and apps. Integrated into a single platform, AB Tasty offers web and API-based solutions that provide companies with a unified approach to creating seamless experiences for customers.\nBrands use AB Tasty\u2019s platform to align digital, e-commerce, and product teams on revenue goals by optimizing and innovating digital experiences.\nFounded in 2013, AB Tasty\u2019s customer roster includes world-leading brands such as Kering, McDonald\u2019s, Ulta Beauty, L\u2019Oreal, Disneyland Paris, and LVMH among others.\nAB Tasty has 12 offices across the globe: North America, Europe, Asia Pacific\nWe are seeking a motivated Cloud Engineer to become an integral part of our cloud infrastructure team.\nThe successful candidate will have practical experience working with cloud services (AWS or GCP) and a desire to develop their skills across a range of technologies and projects.\nThis role involves contributing to the development, optimization, and maintenance of our cloud-based infrastructures, ensuring they meet our standards for scalability, reliability, and security.\nContract & Location\nPermanent full-time contract\nParis or Nantes Office\nSmooth remote work policy (up to 3 days a week)\nWhat You Will Do\nAssist in the migration of applications and services from legacy cloud infrastructure to brand-new, well-architectured cloud infrastructures, ensuring a smooth and efficient transition.\nAssist development and product teams in utilizing cloud infrastructures effectively, providing support and guidance to maximize productivity and efficiency.\nSupport the design and implementation of cloud solutions, contributing to the overall architecture while also taking on specific tasks and projects.\nParticipate in the deployment and management of infrastructure as code, using tools such as Terraform.\nContribute to the development of automation scripts and tools to streamline operational processes using Python, Bash, or similar languages.\nWork closely with product and technical teams to understand requirements and ensure cloud solutions align with business goals.\nMonitor and maintain cloud environments to ensure optimal performance, cost-efficiency, and compliance with security standards.\nContinuously learn and stay up-to-date with emerging cloud technologies and practices.\nWhat We Offer\nHuge impact. AB Tasty is only as great as our team. By directly developing the publicly accessible SaaS platform used by all our clients, you\u2019ll have a direct impact on the company\u2019s success.\nThe opportunity to unleash your creativity. You\u2019ll be free to contribute to the processes, the tools and the organisation of the team, according the agile principles.\nNo micromanaging. Be the owner of your effort - you\u2019ll be one of the team and fully trusted to take responsibility for your tasks. You\u2019ll have every incentive to make a real impact.\nInternational reach. Our audience is wildly international, and our team is too. Although our HQ is located in France, our company language is English.\nContinuous education. We offer many opportunities for each employee to learn and grow from a mix of professional and non professional topics.\nUnique career opportunity. By joining a fast-growing company that\u2019s making waves in the tech industry, you\u2019ll have a wonderful chance to enhance your learning and advance in your career faster than you ever thought possible.\nLots. Of. Fun. Our incredible magic makers organize awesome events, such as team games, drinks, yoga classes, parties, and a company-wide retreat every year with employees from all countries gathering for 2 days of fun.\nRemote working, flexible schedule. This isn\u2019t a \u201cclock in, clock out\u201d company. We care about your productivity, not tracking every minute you\u2019re on site. It\u2019s up to you to always be responsible for your work, no matter where you are or what schedule you\u2019re keeping.\nTime for yourself. After a year within AB Tasty, we offer you a day off during which we simply ask you to think about your career expectations with us. It's not always easy to find time for introspection and to envision what path can lead us to a happy career so we offer a Retreat Day as an opportunity to reflect on that. We not only aim to succeed, but also to make you succeed.\nWhat We Are Looking For\n1+ years of experience in a cloud engineering role, or relevant experience in a cloud-focused project.\nFamiliarity with at least one major cloud provider (AWS, GCP) and its core services.\nExperience with infrastructure as code (Terraform) is a plus.\nExcellent communication skills, both written and verbal.\nAdditional Information\nContract Type: Full-Time\nLocation: Nantes\nPossible partial remote\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "Scala",
                "R",
                "Go",
                "Bash"
            ],
            "DataBase": [],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [],
            "MachineLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [
                "AWS"
            ],
            "DevTools": [
                "Git"
            ],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [
                "Terraform"
            ],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [
                "Teams"
            ],
            "Other": [
                "ML",
                "Cloud"
            ],
            "FrSoftSkills": [
                "Communication",
                "Organisation"
            ],
            "EnSoftSkils": [
                "Communication",
                "Creativity"
            ]
        },
        "details": {
            "JobDetail": [
                "Remote",
                "Full"
            ],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "title": "Cloud Security Engineer",
        "company": "Teads",
        "location": "Montpellier, Occitanie, France",
        "link": "https://fr.linkedin.com/jobs/view/cloud-security-engineer-at-teads-3757698693?position=6&pageNum=2&refId=UAjmJD%2Bo5LxF5kj2yfoeDg%3D%3D&trackingId=GePTW1CixwCFJIm%2BFfb3ig%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Teads has an engineering team that brings together\n200+ talented individuals\nin 3 main locations (\nMontpellier, Paris, and Bucharest\n). We are organized in agile and autonomous\nfeature teams\nand share technical knowledge within several\ncommunities of practice\n.We promote diversity and are committed to creating an inclusive environment to enable all employees to feel valued and respected, which fosters creativity and innovation by allowing constructive collaboration and open exchange of ideas.\nOur organization offers the opportunity for hybrid work, allowing for two days in the office and the option to work remotely for the remainder of the week. Additionally, we provide relocation packages for those who prefer to relocate to one of our engineering offices.\n\ud83d\udc49 Join a team of passionate people who build quality and responsible advertising, at scale!\nOur main Engineering challenges at Teads\nWorking in a very high-traffic environment (1.9 billion users per month, 100 billion events per day) with low latency and high availability constraints (2 million requests per second, responses in less than 150 milliseconds).\nRich and diverse tech stack and system architecture to optimize for performance, scalability, resiliency, and cost efficiency. We use mostly Scala and TypeScript, among others.\nManagement of large datasets with milliseconds order of magnitude access time, to compute in a near real-time complex auction resolution algorithm (18 million predictions per second).\nBuild efficient and easy-to-use web products used by thousands of users working for the world's most premium publishers, advertisers, and agencies.\nA fast-changing environment where we continuously collaborate with Product teams and constantly adapt our Cloud infrastructure for new features and Products.\nBring a wide diversity of profiles to the same level of quality and knowledge.\nWhat will you do?\nAs a\nCloud Security Engineer\n, your mission will be to:\nProvide technical leadership and consultation for infrastructure engineers and developers to ensure the secure deployment of technology\nAs part of a team, ensure the adoption of security architecture and engineering initiatives in order to effectively and securely support the organization in meeting specific business technology needs\nDrive consideration of cybersecurity tools and datasets to enhance detective and preventative control sets\nUnderstand technical security issues and the implications to Teads businesses and be able to communicate them to management\nUnderstand emerging security technologies and determine the appropriate use within business applications\nMaintain and enforce Teads cybersecurity policies and secure design baselines\nExecute and improve Teads Security architecture review process and ensure compliance for all business initiatives\nArchitect global programs that deploy strong security patterns and controls across applications and computing environments, while addressing security, business resiliency, privacy and compliance frameworks\nIdentify security vulnerabilities and guide developers and engineers in addressing these issues\nImprove architectural adoption through automation and efficiently use security tools to solve challenges at scale\nValidate reference architectures for security best practices and recommend changes to enhance security and reduce risk\nCollaborate with the corporate functions including Finance, HR, Legal and Privacy to ensure that Teads maintains a strong cybersecurity posture\nWhat will you bring to the team?\nProven hands-on experience securing cloud infrastructure\nProven hands-on experience securing global multi-cloud architectures from both compute and network infrastructure perspective\nProven hands-on experience securing operating systems\nProven hands-on experience with application security topics such as the OWASP top 10 and technical remediations required\nDetailed technical experience supporting and implementing SIEM & logging tools (Splunk, Kibana, Qradar)\nAbility to extract actionable intelligence from large volume aggregated log storage\nThorough understanding of Network and Compute architectures and, specifically the security aspects\nThorough understanding of compliance and regulatory frameworks and how they affect architecture designs and reviews\nGood verbal and written communication skills, specifically the ability to communicate within the context of the intended audience, whether that be senior executives or highly technical engineering resources.\nDetailed understanding of the threats faced by advertising and digital platforms organizations\nWorking knowledge of at least one programming language (Python, Go, Terraform etc.)\nWhy work at Teads?\nAt Teads, Product and Engineering work hand in hand and are aligned towards the same goal: to\nscale our business\nwhile continuing to create\nnew and exciting products\n.\nWe value team spirit, pragmatism, listening and we encourage initiatives.\nWe promote end-to-end development: \u201cYou build it, you run it, you monitor it\u201d.\nWe share knowledge and support with each other beyond any organizational boundary.\nWe fix issues during a blameless postmortem and learn from it so that it doesn\u2019t happen twice.\nWe are working together to create great engineering, but we are also supportive to promote a great work-life balance.\nWe Care About You\nSecurity & Savings: Attractive package providing financial peace of mind, including competitive compensation, profit-sharing, daily meal vouchers (Swile), family health insurance (Alan), and a personalized relocation package (if needed).\nCareer Development: Continuous investment in our employees' skills: in-house and external training, tech conference opportunities, internal mobility (individual contributor or management career ladder).\nLife Balance: A well-balanced work-life for our employees is one of our top priorities: 35+ days off per year, hybrid work (2-3 days remote work per week, more is open to discussion), fully covered parental leave, and reserved daycare places.\nWellness: Prioritizing employee well-being through premium work equipment, enjoyable work environment (work-life balance, team building events, summits), remote work subsidy, promoting Diversity & Inclusion with internal & external initiatives (women speaking groups, dedicated school partnerships), dedicated charitable time and sustainability actions (Eco Tree, subsidy for eco-mobility).\nDiscover more about our culture and benefits on our Engineering website.\nWhat are our recruitment process steps?\nWe want to get to know you and we try to give you the insight you need to make an informed decision to join us. For that, you can find all the information in our Engineering hiring process article!\nAbout Teads\nTeads operates a leading, cloud-based, omnichannel platform that enables programmatic digital advertising across a global ecosystem of quality digital media.\nAs an end-to-end solution, Teads\u2019 modular platform allows partners to leverage buy-side, sell-side, creative, data and AI optimization technologies. For advertisers and their agencies, Teads offers a single access point to buy the inventory of many of the world\u2019s best publishers and content providers.\nThrough exclusive global media partnerships, Teads enables advertisers and agencies to reach billions of unique monthly users in brand safe, responsible advertising environments, while improving the effectiveness and efficiency of digital ad transactions.\nTeads partners with the leading marketers, agencies and publishers through a team of 1,200+ people in 50 offices across more than 30 countries.\nWe're committed to creating a dynamic work environment that values diversity and inclusion, and represents employees across a variety of skill sets. We embrace contributions from all ages, sexes, races, ethnicities, religions, sexual orientations and gender identities.\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "Scala",
                "R",
                "Go"
            ],
            "DataBase": [],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [],
            "MachineLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [],
            "DevTools": [
                "Git"
            ],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [
                "Terraform"
            ],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [
                "Teams"
            ],
            "Other": [
                "Cloud"
            ],
            "FrSoftSkills": [
                "Communication",
                "Leadership",
                "Collaboration"
            ],
            "EnSoftSkils": [
                "Communication",
                "Leadership",
                "Creativity",
                "Collaboration",
                "Organization",
                "Initiative"
            ]
        },
        "details": {
            "JobDetail": [
                "Remote",
                "Full",
                "Senior"
            ],
            "TypeContract": [],
            "Salary": [
                "1.9"
            ],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "title": "Senior Devops Engineer/SRE (H/F)",
        "company": "Sidetrade",
        "location": "Boulogne-Billancourt, \u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/senior-devops-engineer-sre-h-f-at-sidetrade-3919625910?position=7&pageNum=2&refId=UAjmJD%2Bo5LxF5kj2yfoeDg%3D%3D&trackingId=Gr9FaaLDS0aHGBD5YD2MFA%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Calling all tech enthusiasts! Are you a problem-solving, curious, and strategic DevOps SRE Engineer? Join us at Sidetrade, the leading global SaaS provider recognized by Gartner.(https://go.sidetrade.com/GartnerMagicQuadrant22.ht)\nIndulge your passion for high-availability software and performance enhancement as part of our dynamic team. Embrace the challenge, embrace the excitement - become a DevOps SRE Engineer and thrive! Shape the future of AI-powered Order-to-Cash at Sidetrade today. Join us in creating innovative solutions that redefine the industry!\nAbout Sidetrade\u202fand its amazing R&D team\nSidetrade is a fast-growing international software company that is transforming the Order-to-Cash process for global enterprises. Its AI-powered SaaS platform digitizes the financial customer journey, empowering CFOs to secure and accelerate cash flow generation. Recognized as a Leader in Gartner's Magic Quadrant for two consecutive years, Sidetrade fosters a culture of innovation, collaboration, and customer-centricity from its headquarters in Europe and North America.\nThe R&D team comprises experienced tech professionals who share a deep passion for technology. Together, they are dedicated to developing cutting-edge software solutions that drive the transformation of our customers' work processes. We provide comprehensive training, coaching, resources, and mentorship to empower every team member's growth and nurture their success.\nRequirements\nWhat you will love at Sidetrade:\nWe are seeking a passionate and knowledgeable DevOps SRE Engineer with a multifaceted skill set. Immerse yourself in the exhilarating world of AI and Data Science within our cutting-edge tech environment. Collaborate with like-minded individuals, embracing the latest tools, techniques, and technologies. Fuel your professional growth and innovation within our agile development ecosystem.\nAs a key member of our development team, you will deliver high-quality new features and product enhancements via our online platform. Collaborating with multi-disciplinary teams across the UK and France (with some travel required) will be your forte as you innovate to achieve goals and support the implementation of secure design principles according to policies and standards of Information Security. Explore latest tools and techniques, driving innovation within our R&D team.\nTake control of implementing cutting-edge solutions that optimize our processes. Level up your talent and ignite your development journey!\nWhy you should be working here:\nA strong and demonstrable passion for constantly learning and continuously improving in familiarity with industry leading DevOps/SRE best practices and technologies.\nYou have 5 years+ experience in :\nDeveloping or operating mission-critical systems\nSetup and use of IaC provisioning and deployment tools such as Docker, Terraform and Ansible\nScripting skills with Shell;\nGood knowledge of automation tools\nGood general knowledge of network security (Firewalling, application protection);\nGood knowledge of monitoring tools (Prometheus, grafana, etc.)\nGood knowledge of Linux and Windows systems\nGood knowledge about DNS, DHCP, IPAM, TCP/IP network architectures, HTTP/HTTPS and other Internet protocols.\nYou are aware of security constraints linked to our ISO27001 certification and attached to the roles and responsibilities of this position.\nA plus :\nConcepts and associated tools around containerised and virtualised environments such as Rancher / Kubernetes\nYou worked before with HyperV virtualization technology and Microsoft Azure\nYou speak English fluently, French a plus\nYour first 90 days:\nJoin our Immersive Bootcamp\nReview your onboarding plan with your manager and develop an action plan to achieve your goals\nCollaborate with the team and participate to the roadmap to optimize software performancebuild your internal network across all departments\nExpand your skill set, share your expertise and unlock your full potential\nAt Sidetrade, we cultivate a multicultural environment that fuels innovation. With over 22 nationalities represented, we strongly value diversity, gender equality, inclusivity, and fairness. As an equal opportunity employer, we reject all forms of discrimination and harassment. Your unique contributions are celebrated, driving collective success in our inclusive workplace.\nDiscover more on www.sidetrade.com\nAgencies\nOnly applications from invited agencies through the Workable portal will be accepted. Unsolicited CVs sent directly to managers or HR will not incur any fees.\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "R",
                "Go"
            ],
            "DataBase": [],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [],
            "MachineLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [
                "Azure"
            ],
            "DevTools": [
                "Git",
                "Docker"
            ],
            "Os": [
                "Linux",
                "Windows"
            ],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [
                "Ansible",
                "Kubernetes"
            ],
            "InfrastructureAsCode": [
                "Terraform"
            ],
            "NetworkSecurty": [
                "Firewall"
            ],
            "Virtualisation": [],
            "Containers": [
                "Docker",
                "Kubernetes"
            ],
            "Collaboration": [
                "Teams"
            ],
            "Other": [
                "DevOps"
            ],
            "FrSoftSkills": [
                "Collaboration"
            ],
            "EnSoftSkils": [
                "Collaboration"
            ]
        },
        "details": {
            "JobDetail": [
                "Full"
            ],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "title": "Cloud Engineer",
        "company": "MotorK",
        "location": "Paris, \u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/cloud-engineer-at-motork-3892286206?position=8&pageNum=2&refId=UAjmJD%2Bo5LxF5kj2yfoeDg%3D%3D&trackingId=PG5l3xk5UoWMoi2iWIFJtw%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "MotorK is the leading sales and marketing technology company in Europe, specialising in the automotive sector. At MotorK, our mission is to empower manufacturers and dealerships to sell more with innovative, cloud-based products and services to offer the best digital customer experience.\nWe are on a fast and ambitious trajectory and serving 90% of the automotive manufacturers. To continue our growth, we are hiring new talents. If you want to spark the future of the automotive world, join us.\nWe're headquartered in Milan, Italy, where you'll find most of our employees but the teams you'll work with areas across Europe and the UK.\nYou will be the kubernetes expert inside a team of 5 cloud engineers; your role is key to make sure the existing clusters in MotorK are well managed. You will also be the drive for future improvements and implementation of best practices related to k8s and cloud native technologies in MotorK.\nThings you will do:\nIncrease the efficiency of our software development lifecycle thanks to best practices and infrastructure improvements\nBuild and provide tools to increase developer experience\nImprove and scale our cloud infrastructure, making sure governance, cost and security are under control\nDevelop and improve platform monitoring strategies\nPerform capacity management and load testing\nProvide cloud infrastructure support for the entire Research & Development department\nTechnologies you might work with include:\nOrchestration: Kubernetes, Docker\nCloud: AWS, GCP\nWeb: Nginx, Cloudflare\nData: Kafka, MySQL, Postgres, RabbitMQ, MongoDB\nMonitoring: Grafana, Loki, Prometheus\nCode: PHP, Java, Groovy, Python, Javascript\nRequirements\nStrong hands-on production experience on Kubernetes, at least 3 years\nExperience with at least one Cloud Provider, preferably AWS.\nGood to have\nUnderstanding of SRE and DevOps practices\nExperience with Infrastructure as Code (Ansible, Terraform)\nKnowledge of CI/CD\nRelevant experience with RDBMS (mysql, postgres), troubleshooting and optimization\nBackground in Linux environments as Administrator\nExperience on scripting (bash, python)\nPractical knowledge of networking, both cloud and bare-metal\nGood knowledge of monitoring and log collection tools (grafana, prometheus, loki)\nExperience with PHP or Java on k8s is a plus\nExperience with OSS CMS (WordPress, Joomla...) is a plus\nBenefits\nWork pattern and location\nPermanent contract\nHybrid Role\nWhat you can expect from the recruitment process:\nHR interview\nHiring Manager interview, Infrastructure Manager\nC-level interview, VP R&D\nMotorK is an Equal Opportunity Employer and Prohibits Discrimination and Harassment of Any kind. Our company is committed to the principle of equal employment opportunity for all employees and to providing employees with a work environment free of discrimination and harassment. All employment decisions at MotorK are based on business needs, job requirements, and individual qualifications, without regard to race, colour, religion or belief, age, family or parental status, or any other status protected by the laws or regulations in the locations where we operate.\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "Java",
                "R",
                "Go",
                "Bash",
                "JavaScript"
            ],
            "DataBase": [
                "SQL",
                " MongoDB"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [
                "Spark"
            ],
            "MachineLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [
                "AWS"
            ],
            "DevTools": [
                "Git",
                "Docker"
            ],
            "Os": [
                "Linux"
            ],
            "DBMS": [
                "MySQL"
            ],
            "SoftBigDataProcessing": [],
            "Automation": [
                "Ansible",
                "Kubernetes"
            ],
            "InfrastructureAsCode": [
                "Terraform"
            ],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [
                "Docker",
                "Kubernetes"
            ],
            "Collaboration": [
                "Teams"
            ],
            "Other": [
                "DevOps",
                "ML",
                "Cloud",
                "CI/CD"
            ],
            "FrSoftSkills": [],
            "EnSoftSkils": []
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "title": "DevOps Engineer (H/F)",
        "company": "MERITIS",
        "location": "Aix-en-Provence, Provence-Alpes-C\u00f4te d'Azur, France",
        "link": "https://fr.linkedin.com/jobs/view/devops-engineer-h-f-at-meritis-3815739629?position=9&pageNum=2&refId=UAjmJD%2Bo5LxF5kj2yfoeDg%3D%3D&trackingId=gn8keAP0BuJPdtk6j6WIyQ%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Descriptif de l\u2019entreprise\n:\nMeritis est une soci\u00e9t\u00e9 de conseil sp\u00e9cialis\u00e9e en transformation digitale des organisations, fond\u00e9e en 2007 par S\u00e9bastien Videment.\nInstall\u00e9e initialement \u00e0 Paris, elle s\u2019est d\u00e9ploy\u00e9e en r\u00e9gions et assure d\u00e9sormais une pr\u00e9sence dans les plus grandes villes de France : Sophia-Antipolis, Montpellier, Nantes, Bordeaux, Lyon, Aix-en-Provence, Lille et m\u00eame \u00e0 Lisbonne au Portugal depuis 2023.\nNos experts accompagnent des clients de divers secteurs dans l\u2019int\u00e9gralit\u00e9 de leurs besoins de transformations num\u00e9riques \u00e0 travers de nombreux domaines d\u2019expertise : Finance, Software Engineering, Cloud & Infrastructure, Data, Transformation Digitale et Cybers\u00e9curit\u00e9.\nFort de ses valeurs d\u2019exigence, d\u2019humilit\u00e9, de bienveillance et de proximit\u00e9, le cabinet de +900 collaborateurs prim\u00e9 \u00e0 5 reprises au palmar\u00e8s Great Place To Work\u00ae connait une tr\u00e8s forte croissance et projette d\u2019atteindre 100M\u20ac de chiffre d\u2019affaires en 2024 et de d\u00e9passer la barre symbolique des 1000 collaborateurs.\nNous mettons un point d\u2019honneur \u00e0 \u00eatre proche de nos collaborateurs et \u00e0 les accompagner de mani\u00e8re individualis\u00e9e quelles que soient leurs fonctions dans l\u2019entreprise. Certifi\u00e9e Great Place To Work depuis 2013, notre conception du bien-\u00eatre au travail va bien au-del\u00e0 d'un simple label, ce sont nos collaborateurs qui en parlent le mieux : https://www.glassdoor.fr/Avis/Meritis-Avis-E1163008.htm\nDescriptif du poste :\nEn tant que\nIng\u00e9nieur DevOps (H/F),\nvous int\u00e9grerez une entreprise dynamique \u00e9voluant dans un contexte international et un environnement de travail agile. Vos missions seront :\nMettre en place et maintenir les chaines CI/CD de bout en bout\nContribuer aux travaux de fusion de pipelines en vue de rationaliser\nMigrer les pipelines obsol\u00e8tes vers des versions d'outils valid\u00e9es par la strat\u00e9gie entreprise\nD'accompagner les \u00e9quipes de d\u00e9veloppement \u00e0 l'appropriation de la m\u00e9thode Devops et des outils mis \u00e0 disposition\nParticiper aux r\u00e9flexions de veille sur le p\u00e9rim\u00e8tre du service\nQualification :\nVous avez un dipl\u00f4me d\u2019ing\u00e9nieur (Bac+5).\nVous disposez d'au moins 5 ans d'exp\u00e9rience dans un environnement DevOps\nVous \u00eates issu(e) d'une formation d'ing\u00e9nieur syst\u00e8me et/ou de d\u00e9veloppeur\nVous \u00eates dot\u00e9(e) d\u2019une grande capacit\u00e9 d\u2019adaptation.\nVous r\u00eavez de progresser entour\u00e9(e) de personnes de tous niveaux d\u2019expertise\nOutils / technologies\n:\nJenkins\nGit\nSonar\nCheckmarx\nAngular\nInformations compl\u00e9mentaires\n:\nDes parcours professionnels sur mesure (\u00e9volution de carri\u00e8re, formations adapt\u00e9es, mentoring\u2026) ;\u200b\nAvoir le choix de sa mission et un accompagnement personnalis\u00e9 tout au long de votre carri\u00e8re ;\u200b\nEvoluer dans un environnement o\u00f9 l\u2019apprentissage est favoris\u00e9 : formations certifiantes, e-learning, meetUp, concours de code, parcours d\u2019\u00e9volutions etc ;\u200b\nFaire partie de communaut\u00e9s d\u2019experts qui partagent leurs savoirs et exp\u00e9riences au sein de nos centres de comp\u00e9tences ;\u200b\nUn environnement convivial avec de nombreux \u00e9v\u00e9nements festifs (soir\u00e9e annuelle, s\u00e9minaires & teambuiding, d\u00e9jeuners et afterworks\u2026) ;\u200b\n\u200b\n\"Meritis est engag\u00e9e dans la Responsabilit\u00e9 Soci\u00e9tale des Entreprises. Nous valorisons notre impact positif sur la soci\u00e9t\u00e9 et l'environnement. Notre d\u00e9marche RSE guide chacune de nos actions pour promouvoir l'\u00e9quit\u00e9, la durabilit\u00e9 et le bien-\u00eatre de nos collaborateurs. Rejoignez-nous pour \u00eatre partie prenante de cette d\u00e9marche responsable, o\u00f9 chacun de nos talents contribue \u00e0 construire un avenir meilleur.\nNos diff\u00e9rences sont nos atouts. C\u2019est pourquoi Meritis s'implique en faveur de la diversit\u00e9 et de la non-discrimination. Tous nos m\u00e9tiers sont accessibles aux personnes en situation de handicap.\"\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "R"
            ],
            "DataBase": [],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [],
            "MachineLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [],
            "DevTools": [
                "Git",
                "Jenkins"
            ],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [
                "DevOps",
                "Cloud",
                "CI/CD"
            ],
            "FrSoftSkills": [
                "Organisation"
            ],
            "EnSoftSkils": []
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [],
            "Salary": [],
            "Level": [
                "Bac+5"
            ],
            "Experience": [
                "a",
                "n",
                "s",
                "5",
                "5",
                "5"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "title": "Lead Cloud & DevOps Engineer (H/F)",
        "company": "fifty-five",
        "location": "Paris, \u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/lead-cloud-devops-engineer-h-f-at-fifty-five-3883929582?position=10&pageNum=2&refId=UAjmJD%2Bo5LxF5kj2yfoeDg%3D%3D&trackingId=WE4cJ5Wyh6HJDn3VRJhi%2Fw%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Cloud & DevOps Lead\nfifty-five est une data-company d'un genre nouveau qui aide les marques \u00e0 exploiter les donn\u00e9es pour am\u00e9liorer le marketing, les m\u00e9dias et l'exp\u00e9rience client gr\u00e2ce \u00e0 une combinaison de services de conseil et de technologie sp\u00e9cialis\u00e9s.\nEn tant que pilier data et marketing du Brandtech Group, nous offrons des services qui combinent le conseil en strat\u00e9gie, les services de cloud, le conseil en m\u00e9dia et l'exp\u00e9rience client.\nfifty-five, c'est plus de 400 experts du num\u00e9rique. Des digital consultants, des sp\u00e9cialistes du tracking et du m\u00e9dia, des ing\u00e9nieurs et des data scientists, travaillent tous en \u00e9troite collaboration pour fournir des conseils marketing de haut niveau et une assistance technique aux marques, dans tout type d'industrie, partout dans le monde.\nPartenaire des annonceurs de la collecte \u00e0 l'activation et l'exploitation des donn\u00e9es, nous aidons les organisations \u00e0 devenir de v\u00e9ritables entit\u00e9s omnicanales ma\u00eetrisant l'efficacit\u00e9 de leur \u00e9cosyst\u00e8me digital et ses synergies avec le monde physique.\nBas\u00e9 \u00e0 Paris, nous op\u00e9rons sur 3 fuseaux horaires depuis nos 10 bureaux, situ\u00e9s \u00e0 Paris, Londres, Gen\u00e8ve, Milan, Shanghai, Hong Kong, Shenzhen, Taipei, Singapour et New York. fifty-five attache une importance particuli\u00e8re au bien-\u00eatre de ses collaborateurs, ce qui lui a permis de figurer dans le classement Best Workplaces France en 2018.\nContexte :\nfifty-five d\u00e9veloppe r\u00e9guli\u00e8rement des nouvelles solutions bas\u00e9es sur du data processing et dans certains cas du machine learning pour r\u00e9pondre aux besoins pr\u00e9cis de ses clients (par exemple: syst\u00e8me de recommandations de produits, d\u00e9tection d'anomalies, ranking).\nL'\u00e9quipe d'Ing\u00e9nierie adresse \u00e0 la fois les outils internes ainsi que les projets clients. L'\u00e9quipe Infrastructure au sein de l'\u00e9quipe Ing\u00e9nierie est responsable de l'infrastructure 55, des outils / scripts d'automation ainsi que des best practices Cloud & DevOps que le reste de l'\u00e9quipe est amen\u00e9 \u00e0 utiliser dans le cadre de leurs projets (internes ou clients). . L'infrastructure 55 recouvre de mani\u00e8re non exhaustive : les outils de d\u00e9veloppement et la stack DevOps (Gitlab, Jupyterhub, Terraform, Docker, Jenkins, etc.), l'h\u00e9bergement des outils d\u00e9velopp\u00e9s en interne (stack Spring Boot / Angular / MongoDB / Keycloak / Vault h\u00e9berg\u00e9 sur GKE), les outils de gouvernance cloud (alerting automatique, billing, etc.), les frameworks templatis\u00e9s que les autres membres de l'\u00e9quipe peuvent utiliser dans le cadre de leurs missions clients (architectures Clouds d\u00e9ployables via Terraform et templatis\u00e9es, sur les 3 cloud publics GCP / Azure / AWS). L'\u00e9quipe intervient \u00e9galement sur l'automatisation de diff\u00e9rents process internes : gestion du billing, ERP automations, etc. L'\u00e9quipe Infrastructure regroupe des Cloud Engineers, DevOps Engineers, Software Engineers (Python).\nMission :\nNous sommes \u00e0 la recherche de notre Cloud & DevOps Lead qui sera responsable de l'\u00e9quipe Infrastructure. Il aura en responsabilit\u00e9 \u00e0 la fois la stack technique interne utilis\u00e9 par l'Ing\u00e9nierie et son h\u00e9bergement, ainsi que les best practices et frameworks utilis\u00e9s par les autres ing\u00e9nieurs. Son r\u00f4le :\n\u00catre garant de la disponibilit\u00e9 et de la s\u00e9curit\u00e9 de l'infrastructure\nMettre en place et surveiller les best practices Infra : GitOps, gouvernance Cloud, FinOps\nS'assurer de la bonne r\u00e9utilisabilit\u00e9 des composants / frameworks / templates\nAccompagner son \u00e9quipe dans le suivi des t\u00e2ches, la mont\u00e9e en comp\u00e9tences et l'expertise au quotidien\nComp\u00e9tences et exp\u00e9riences :\nUne premi\u00e8re exp\u00e9rience sur un poste similaire et un minimum de 4 ans d'exp\u00e9rience.\nMa\u00eetrise des environnements Cloud. Id\u00e9alement certifi\u00e9 GCP, Azure et/ou AWS\nMa\u00eetrise de l'Infrastructure as Code (Terraform)\nMa\u00eetrise de Docker/Kubernetes\nMa\u00eetrise des pratiques GitOps et CI/CD\nMa\u00eetrise de Python, SQL et \u00e9ventuellement Java\nUne connaissance des activit\u00e9s IT est un plus (IDP, user management, device management, DNS management, network, etc.)\nEsprit d'\u00e9quipe (collaborer aux tests unitaires, revue de code, partage de code, sprints)\nBon niveau en fran\u00e7ais et en anglais\nNous proposons :\nun bureau au centre de Paris avec terrasse et jardin\nun environnement multiculturel avec des collaborateurs aux nationalit\u00e9s multiples (France, Royaume-Uni, Etats-Unis, Chine, Tunisie, Italie et plus)\ndes projets avec nos bureaux \u00e0 Londres, Hong Kong, New York, Shanghai, Gen\u00e8ve, Shenzhen et Taipei\ndes TGIF et supers soir\u00e9es\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "Java",
                "R",
                "Go"
            ],
            "DataBase": [
                "SQL",
                " MongoDB"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [],
            "MachineLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [
                "AWS",
                "Azure"
            ],
            "DevTools": [
                "Git",
                "Docker",
                "Jenkins"
            ],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [
                "Kubernetes"
            ],
            "InfrastructureAsCode": [
                "Terraform"
            ],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [
                "Docker",
                "Kubernetes"
            ],
            "Collaboration": [],
            "Other": [
                "DevOps",
                "Machine Learning",
                "Cloud",
                "CI/CD"
            ],
            "FrSoftSkills": [
                "Collaboration",
                "Organisation"
            ],
            "EnSoftSkils": [
                "Collaboration"
            ]
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s",
                "4",
                "4",
                "4"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "title": "Data Engineer Devops H/F",
        "company": "Extia",
        "location": "Paris, \u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/data-engineer-devops-h-f-at-extia-3599185622?position=1&pageNum=5&refId=HqnBGIsq%2F7%2BaI9g3tHePPw%3D%3D&trackingId=8vqLx3jIEu9QspJOWI2I1Q%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Vous souhaitez rejoindre une entreprise qui place l\u2019humain au c\u0153ur de ses pr\u00e9occupations ? On vous attend chez\nExtia\n!\nSoci\u00e9t\u00e9 de conseil sp\u00e9cialis\u00e9e dans les m\u00e9tiers de l\u2019IT, de l\u2019ing\u00e9nierie et du digital, Extia privil\u00e9gie depuis sa cr\u00e9ation en 2007 une approche qui allie performance et bien-\u00eatre au travail. Une vision de l\u2019entreprise partag\u00e9e aujourd\u2019hui par plus de 2 500 Extiens en France et \u00e0 l'international et r\u00e9compens\u00e9e par le label Great Place to Work\u00ae depuis 13 ans, notamment en\n2024 o\u00f9 les Extiens se hissent \u00e0 la premi\u00e8re place du palmar\u00e8s Best Workplaces France\n!\nChez Extia, c\u2019est \u00ab D\u2019abord qui, ensuite quoi \u00bb alors, allons-y !\nD'abord qui\nCurieux, vous adorez partager les derni\u00e8res id\u00e9es innovantes que vous avez d\u00e9couvertes\nRigoureux, vous ne laissez rien au hasard\nPers\u00e9v\u00e9rant, vous ne perdez jamais, soit vous gagnez, soit vous apprenez\nEnsuite quoi\nDans le cadre de votre mission, vos taches principales sont\n:\nL'impl\u00e9mentation de solutions techniques\nSens de l\u2019\u00e9change avec les diff\u00e9rents \u00e9quipiers, contributeurs de la division Data.\n\u00c9changes et pr\u00e9paration de demos avec les IT m\u00e9tiers.\nMaintien d'une veille technologique permanente.\nLes comp\u00e9tences techniques\n:\nAnalyse et d\u00e9veloppement\nD\u00e9veloppement en Java jusqu\u2019\u00e0 l\u2019int\u00e9gration avec les chaines CI/CD\nMaitrise des langages de programmation Java, Scala et Python\nMa\u00eetrise de Ansible, Terraform, Kubernetes...\nMa\u00eetrise de l\u2019\u00e9cosyst\u00e8me Hadoop, Spark, Kafka, ElasticSearch\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "Java",
                "Scala",
                "R",
                "Go"
            ],
            "DataBase": [
                "Elasticsearch"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [
                "Hadoop",
                "Spark"
            ],
            "MachineLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [],
            "DevTools": [
                "Git"
            ],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [
                "Ansible",
                "Kubernetes"
            ],
            "InfrastructureAsCode": [
                "Terraform"
            ],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [
                "Kubernetes"
            ],
            "Collaboration": [],
            "Other": [
                "CI/CD"
            ],
            "FrSoftSkills": [],
            "EnSoftSkils": []
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s",
                "13",
                "13",
                "13"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "title": "Cloud Security Engineer",
        "company": "Glocomms",
        "location": "France",
        "link": "https://fr.linkedin.com/jobs/view/cloud-security-engineer-at-glocomms-3910052052?position=2&pageNum=5&refId=HqnBGIsq%2F7%2BaI9g3tHePPw%3D%3D&trackingId=uVExhRYAD8wJwPNIWvMIKA%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Senior ServiceNow Consultant\nOffice Location : Toulouse\nFully remote\nEnglish and French speaking project\nContract : 2 year project on a 6 month rolling contract\nStart date: Monday 3rd June\nWe are seeking a skilled and experienced Cloud Security Engineer to join our customer's team. The ideal candidate will be responsible for designing, implementing, and maintaining security measures to protect our cloud-based infrastructure and applications. The Cloud Security Engineer will work closely with our DevOps and IT teams to ensure that our cloud environments meet the highest standards of security and compliance.\nResponsibilities:\nDesign and implement security measures to protect cloud-based infrastructure and applications.\nConduct regular security assessments and audits of cloud environments.\nDevelop and maintain security policies, standards, and procedures for cloud environments.\nImplement access controls, encryption, and other security features to protect data in the cloud.\nMonitor cloud environments for security incidents and respond to incidents in a timely manner.\nWork closely with DevOps and IT teams to integrate security best practices into cloud deployment pipelines.\nStay up-to-date on the latest trends and developments in cloud security and recommend new security technologies and techniques.\nCollaborate with internal teams and external vendors to resolve security issues and implement security solutions.\nRequirements:\nBachelor's degree in Computer Science, Information Security, or a related field.\n5+ years of experience working in cloud security or a related field.\nIn-depth knowledge of cloud platforms such as AWS, Azure, or Google Cloud Platform.\nExperience with cloud security technologies and tools, such as IAM, WAF, and SIEM.\nStrong understanding of networking and network security principles.\nExperience with scripting languages such as Python, PowerShell, or Bash.\nCertifications such as Certified Cloud Security Professional (CCSP), Certified Information Systems Security Professional (CISSP), or AWS Certified Security Specialty are a plus.\nExcellent communication and collaboration skills.\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "R",
                "Go",
                "Bash"
            ],
            "DataBase": [],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [],
            "MachineLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [
                "AWS",
                "Azure",
                "Google Cloud Platform"
            ],
            "DevTools": [],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [
                "Teams"
            ],
            "Other": [
                "DevOps",
                "Cloud"
            ],
            "FrSoftSkills": [
                "Communication",
                "Collaboration"
            ],
            "EnSoftSkils": [
                "Communication",
                "Collaboration"
            ]
        },
        "details": {
            "JobDetail": [
                "Remote",
                "Full",
                "Senior"
            ],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "title": "DevOps Engineer Block Storage",
        "company": "Scaleway",
        "location": "France",
        "link": "https://fr.linkedin.com/jobs/view/devops-engineer-block-storage-at-scaleway-3918147786?position=3&pageNum=5&refId=HqnBGIsq%2F7%2BaI9g3tHePPw%3D%3D&trackingId=FH0BUYlAO5FGSyD81OVxUA%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "About the job\nThe Storage Team is one of the pillars of Scaleway. This team not only develops the Scaleway Elements storage products (Block Storage), but also supports all the other Scaleway Elements products that rely on Block Storage (Instances, Database, Registry, Kubernetes, and more) for proper usage. In a challenging environment, and within a team that manages hundreds of storage servers across various regions, you will be responsible for developing, automating, and enhancing Scaleway\u2019s Block Storage solution.\nThis service launched by Scaleway offers resilient, redundant, and high-availability storage for its numerous clients. Your missions will require programming, automation, and architecture skills. On top of your daily activities within your team, you will need to interact with all of Scaleway\u2019s teams, especially Instances, Network, Hardware, and Platform.\nMinimum Qualifications\nExperienced System Engineer who is passionate about DevOps best practices and cloud architecture, ideally with over 5 years of experience\nExperience with (and love for) storage systems\nStrong system-level programming skills\nGood understanding of Golang.\nExperience with a continuous integration workflow, Gitlab, and Git\nStrong Linux knowledge\nDistributed systems (and debugging them)\nResponsibilities\nDeploying infrastructure in new Availability Zones\nImproving & bringing forward new ideas for our current infrastructure\nReacting to eventual failures in collaboration with other teams\nPresenting your work during tech meetings\nCoding, peer review, and deployment\nCustomer support in relation to your product\nDeploying your code\nPreferred qualifications\nSolid experience with Ceph in high capacity and/or performance environment\nGreat oral and written communication skills\nInfrastructure deployment with Ansible\nVery good command of English\nTechnical Stack\nCeph\nUbuntu/Debian\nAnsible\nGolang\nProtobuf\nPostgresql\nLocation\nThis position is based in our offices in Paris or Lille (France)\nRecruitment Process\nScreening call - 30 mins with the recruiter\nManager Interview - 45 mins\nTechnical Interviews\nHR Interview - 45 mins\nHead of Interview - 45 mins\nOffer sent - 48 hours\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "R",
                "Go"
            ],
            "DataBase": [
                "SQL"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [],
            "MachineLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [],
            "DevTools": [
                "Git"
            ],
            "Os": [
                "Linux"
            ],
            "DBMS": [
                "PostgreSQL"
            ],
            "SoftBigDataProcessing": [],
            "Automation": [
                "Ansible",
                "Kubernetes"
            ],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [
                "Kubernetes"
            ],
            "Collaboration": [
                "Teams"
            ],
            "Other": [
                "DevOps",
                "Cloud"
            ],
            "FrSoftSkills": [
                "Communication",
                "Collaboration"
            ],
            "EnSoftSkils": [
                "Communication",
                "Collaboration"
            ]
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "title": "Cloud Engineer Storage",
        "company": "Cloud Temple",
        "location": "\u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/cloud-engineer-storage-at-cloud-temple-3779352432?position=4&pageNum=5&refId=HqnBGIsq%2F7%2BaI9g3tHePPw%3D%3D&trackingId=Gw%2FoyNnClWoTKSlDWpBS7w%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Afin de consolider notre \u00e9quipe Computing & Storage, Cloud Temple vous offre l'opportunit\u00e9 de nous rejoindre en tant que Cloud Engineer Storage F/H.\nMISSIONS :\nAu sein de l\u2019\u00e9quipe de Computing & Storage, vous \u00eates responsable du maintien et de l\u2019\u00e9volution de nos infrastructures compute et virtualisation ainsi que de la stabilit\u00e9 du service rendu au client. Vous travaillez sur des infrastructures certifi\u00e9es (SecNumCloud, HDS) avec de fortes contraintes de s\u00e9curit\u00e9 et de disponibilit\u00e9.\nEn tant que Cloud Engineer Storage , vous aurez comme mission :\nAssurer la gestion des \u00e9v\u00e8nements et incidents de production\nAssurer une r\u00e9solution rapide en cas d\u2019incident, identifier les causes racines et amener des correctifs\nMaintenir la conformit\u00e9 op\u00e9rationnelle et s\u00e9curitaire des services\nAssurer la gestion des changements en production en validant le niveau de risques en rapport avec les niveaux de service\nParticiper aux projets d\u2019\u00e9volution et de transformation des infrastructures et services\nAgr\u00e9menter et maintenir une base de connaissances techniques\nAssurer un suivi du traitement des incidents de bout en bout\nExigence du poste :\nNiveau de dipl\u00f4mes :\nBAC + 5\nComp\u00e9tences requises :\nConnaissance des outils Git, GitLab (CI/CD), Docker, Terraform, Ansible\nMaitrise des concepts ITIL\nConnaissance des produits VMware est un atout\nMaitrise d\u2019au moins un langage de programmation : Python, Bash, PHP, Golang, JAVA\nMa\u00eetrise des environnements UNIX (FeedBSD, Linux, Solaris) et r\u00e9seaux IP\nConnaissances linguistiques :\nAnglais : lu, parl\u00e9 et \u00e9crit\nExp\u00e9rience attendue\nAu moins 2 ans sur un poste similaire\nExp\u00e9rience en administration d\u2019infrastructure diverse et en gestion d\u2019environnement de production informatique certifi\u00e9s\nConnaissance des architectures des syst\u00e8mes d\u2019information\nMa\u00eetrise des protocoles et solutions de stockage standards\nCapacit\u00e9 \u00e0 automatiser des actions op\u00e9rationnelles au travers des scripts ou de programme\nMa\u00eetrise des solutions de supervision des services et leurs performances\nCapacit\u00e9 \u00e0 proposer et faire \u00e9voluer les process et outils de gestion de la production\nSavoir \u00eatre attendus\nSens de la qualit\u00e9 de service\nCapacit\u00e9 d\u2019adaptation et d\u2019automatisation dans un environnement en perp\u00e9tuelle \u00e9volution\nExcellentes comp\u00e9tences organisationnelles\nCapacit\u00e9 \u00e0 g\u00e9rer les situations de crise\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "Java",
                "R",
                "Go",
                "Bash"
            ],
            "DataBase": [],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [],
            "MachineLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [],
            "DevTools": [
                "Git",
                "Docker"
            ],
            "Os": [
                "Linux"
            ],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [
                "Ansible"
            ],
            "InfrastructureAsCode": [
                "Terraform"
            ],
            "NetworkSecurty": [],
            "Virtualisation": [
                "VMware"
            ],
            "Containers": [
                "Docker"
            ],
            "Collaboration": [],
            "Other": [
                "Cloud",
                "CI/CD"
            ],
            "FrSoftSkills": [
                "Organisation"
            ],
            "EnSoftSkils": []
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s",
                "2",
                "2",
                "2"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "title": "DevOps Engineer",
        "company": "Mazars",
        "location": "Paris, \u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/devops-engineer-at-mazars-3850005993?position=5&pageNum=5&refId=HqnBGIsq%2F7%2BaI9g3tHePPw%3D%3D&trackingId=VzhP7OXvojAFknR1xckV3g%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Votre poste\nMazars is a leading international audit, tax and advisory firm, aspiring to build the economic foundations of a fair and prosperous world. Operating as a united partnership, Mazars works as one integrated team, leveraging expertise, scale and cultural understanding to deliver exceptional and tailored services in audit and accounting, as well as tax, financial advisory, consulting and legal services*.\nFounded in Europe, Mazars is present in over 95 countries and territories, with 47,000 professionals \u2013 30,000 in our integrated partnership, 17,000 via the Mazars North America Alliance \u2013 dedicated to helping clients make the most of business opportunities and operate with confidence.\n*where permitted under applicable country laws.\nVos principales missions\nThis is a permanent role reporting to Head of Platforms.\nTechnology & digital solutions (T&DS)\nMandated by Mazars Global Executive Board, the Technology & digital solutions team is leading Mazars digital transformation to unleash the next stage of Mazars growth. Specifically, the transformation will allow easier collaboration across geographies, quicker scalable service offering to clients in a safe, modern and sustainable way. As a result, Mazarians will enjoy a seamless experience and deliver more value to clients every day.\nTo reach these goals, Technology & digital solutions transformation programme aims at consolidating the IT operations from a multi-local model spread across 99+ countries into a global model. This includes the infrastructure and the operating model design needed to support Mazars business, people and clients now and in the future.\nThe success of this change relies on the great expertise and relentless engagement of every member of the team. This is a great moment to join the Technology & digital solutions organisation and be part of the delivery of this major transformation over the coming years!\nDevOps Engineer\nRole Purpose, Accountabilities, Experience, Knowledge, And Skills\nWe are looking for a DevOps Engineer to install, maintain, document, upgrade and optimise cloud & hybrid infrastructure while ensuring the reliability, security and availability of said platform, in close collaboration with the entire Global IT programme team.\nKey Responsibilities\nBuild\nManage the deployment of solutions, encompassing both applications and infrastructure, either through hands-on delivery or with third party support\nEnsure that deployments of new solutions comply with Global IT Enterprise Architectural standards\nOversee the handover of solutions into relevant service management teams via preparation of appropriate documentation and relevant training\nImagine, architect, develop, deploy, and evolve CI and CD systems for our cloud applications\nWrite Infrastructure as Code (IaC) using industry standard tools and services\nWrite application deployment automation using industry standard deployment and configuration tools\nRun\nProvide support and day to day administrator for deployed solutions\nOversee incident management activities related to global solutions and liaise with third party support partners through to resolution\nMonitor deployed solutions to ensure they are operating in an optimal manner\nManage patching, upgrades, service packs of compute components\nMaintain relevant documentation over the lifecycle of solutions ensuring they are kept up to date.\nVotre profil\nYou speak fluent English, and at least one other European language (French, Dutch, Spanish, ...)\nGood knowledge of IT best practices and design patterns.\nExcellent knowledge of (hybrid) cloud concepts and technologies, preferably utilizing Azure and Microsoft technologies. You are familiar with governance, monitoring, IAM, storage and server(less) infrastructure, and container concepts.\nCI/CD pipelines have no secrets for you anymore: you have a good experience in building a continuous delivery process: version management, automation, infrastructure as code\nKnowledge of Bicep.\nYou should be curious and fast at picking up new things with a sharp eye for details.\nYou should be eager to grow your skills and to embrace new challenges.\nPreferred Certifications\nAZ-104, AZ-900 preferred.\nAZ-400 highly desired\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Scala",
                "R",
                "Go"
            ],
            "DataBase": [],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [],
            "MachineLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [
                "AWS",
                "Azure"
            ],
            "DevTools": [
                "Git"
            ],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [
                "Teams"
            ],
            "Other": [
                "DevOps",
                "ML",
                "Cloud",
                "CI/CD"
            ],
            "FrSoftSkills": [
                "Collaboration",
                "Organisation"
            ],
            "EnSoftSkils": [
                "Collaboration"
            ]
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "title": "Senior Cloud DevOps Engineer (100% Remote -Europe)",
        "company": "Matomo",
        "location": "Paris, \u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/senior-cloud-devops-engineer-100%25-remote-europe-at-matomo-3883003015?position=6&pageNum=5&refId=HqnBGIsq%2F7%2BaI9g3tHePPw%3D%3D&trackingId=Kj%2FyEJBxdVKXnGaTrsZNmg%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Introduction\nWe\u2019re looking for an experienced DevOps engineer to work on our cloud hosted SaaS platform. We are the creators of Matomo, the leading open source web analytics solution that gives people full control of their data and built-in privacy. We have challenges to solve and need you!\nWe are fully remote and we collaborate online. We are a small, flexible team, and when you come onboard you will play an integral part in engineering. You\u2019ll help us to make our products better and deliver a great experience to our customers.\nKey Responsibilities\nBuild, manage and automate our SaaS web analytics platform on AWS\nEnsuring availability, performance, security, and scalability of the platform\nMaintain and improve CI/CD pipelines, Infrastructure as code, monitoring and alerting systems\nSupport software development, product and customer support teams to achieve business outcomes\nTake ownership of technical issues, and work with the team to resolve more advanced issues when necessary\nRespond to application and security incidents via a rotating On-Call schedule (two thirds of the time, including nights and weekends)\nMinimum Qualifications\n5+ years commercial experience working with the AWS cloud\nProficient with modern IaC tooling (e.g., Terraform, Cloud Formation, Pulumi)\nProficient in at least 1 popular scripting languages (e.g., Python, Typescript/Javascript)\nProficient in container technologies (e.g., Docker, Docker Compose, Kubernetes)\nProficient in Linux systems and shell scripting\nProficient in declarative modern CI/CD patterns (e.g., GitHub Action, Bitbucket Pipeline, GitLab CI/CD)\nProficient with modern software engineering workflows (e.g., Git, pull request, code review)\nUnderstanding of network topologies, high availability principles\nUnderstanding of monitoring concepts (e.g., metrics, dimensions, log analysis)\nStrong analytical skills and a passion for it to understand complex business logic\nGreat communication and collaboration skills\nAbility to work independently\nWilling to provide on-call support\nNice to have\nWorking knowledge of PHP\nMySQL server and SQL query optimisation\nLocation\n100% Remote work position ( Candidates must be willing to work a minimum of 4 hours overlapping with New Zealand per week)\nBenefits\nRemote work (save many hours on commute, and save money)\nCo-working space paid for and/or work from home\nAll home office equipment paid for (laptop, desk, chair, standing desk, lights, etc.)\nFlexible hours\n25 days of paid holidays per year plus your national public holidays\nSick leave\nHealth Insurance: Your Well-being, Our Priority\nA huge \u201cplayground\u201d to grow your skill set\nVolunteering Day: Empower Your Impact\nBereavement Leave for Pets: Compassion Beyond Boundaries\nTraining Opportunities\nMental Health Support Services\nOpportunity to work in a customer obsessed business, dedicated to building high-quality software with a strong mission of helping people grow their web projects while keeping full control of their data\nOpportunity to have an immediate impact on a product that is used by more than 1 million websites and almost 2% of the whole Internet\nAbout InnoCraft And Matomo Analytics\nAt InnoCraft, we offer analytics products and SaaS to enable our users to grow their business. We believe in openness, privacy and 100% data ownership. Our mission is to liberate analytics and we are passionate about measuring for success. That\u2019s why we created Matomo Analytics, the leading open source analytics platform used on more than 1 million websites and apps in over 150 countries, available in more than 50 languages. The Matomo platform collects, stores and processes a lot of information: hundreds of millions of data points each month. We create intuitive, simple and beautiful reports that delight our users.\nInnoCraft celebrates the things that make you, you! We are an inclusive employer and do not discriminate against any employee or applicant for employment because of race, color, religion, sex, sexual orientation, gender identity, national origin, age, marital status or disability. We actively seek diver\nsity in our workplace and embrace individuals with unique backgrounds, perspectives, and abilities!\nCome join our growing team that\u2019s helping ensure a safer, more privacy focused web/internet!\n#Hiring\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "Java",
                "Scala",
                "R",
                "JavaScript"
            ],
            "DataBase": [
                "SQL"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [],
            "MachineLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [
                "AWS"
            ],
            "DevTools": [
                "Git",
                "Docker"
            ],
            "Os": [
                "Linux"
            ],
            "DBMS": [
                "MySQL",
                "SQL Server"
            ],
            "SoftBigDataProcessing": [],
            "Automation": [
                "Kubernetes"
            ],
            "InfrastructureAsCode": [
                "Terraform"
            ],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [
                "Docker",
                "Kubernetes"
            ],
            "Collaboration": [
                "Teams"
            ],
            "Other": [
                "DevOps",
                "Cloud",
                "CI/CD"
            ],
            "FrSoftSkills": [
                "Communication",
                "Collaboration"
            ],
            "EnSoftSkils": [
                "Communication",
                "Collaboration"
            ]
        },
        "details": {
            "JobDetail": [
                "Remote",
                "Full"
            ],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "title": "DEVOPS CLOUD ENGINEER",
        "company": "STATION F",
        "location": "Paris, \u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/devops-cloud-engineer-at-station-f-3824854750?position=7&pageNum=5&refId=HqnBGIsq%2F7%2BaI9g3tHePPw%3D%3D&trackingId=Pw4vpsKQ6r4WBJqY6iKyAg%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "\u00c0 propos\nAllphins is the leading InsurTech company that provides risk management solutions for the insurance industry.\nAfter starting as a member of the Lloyd's Lab (reputable Insurtech accelerator in London) and being hosted at Station F (Paris), we now help 25+ clients cover all major commercial lines including Property, Energy, Political Risk, Trade Credit, Cyber, Casualty & Terrorism. Our goal is to help (re)insurers better analyse risks and make the right decisions.\nWith a strong international presence (UK & US) and self-financed growth (from 4 to 15 employees in 2 years), we seek to become the leading risk management platform for speciality risks.\nDescriptif du poste\nActivity\nAs a Cloud Devops at Allphins you will :\nImprove, maintain the current cloud infrastructure and helping the development team to scale the application\nApply site reliability engineering practices to a service (?)\nInsure the security of the app\nDevelop CI/CD for containerize application\nImplement infrastructure monitoring and optimize service performance\nEnsure the quality of the various release\nTechno\nCloud provider: GCP ( GKE, Network stack, Dataproc,...)\nContainerize app deploiment : Docker, Helm, kubernetes\nInfra as Code: Terraform\nCode versioning: Git\nDatabase technology: Postgresql, redis\nCode base: Python\nTechno Nice To Have\nKnowledge in big data architecture (using sprak, airflow etc\u2026)\nKnowledge in API development in python\nCode quality tools\nSoftskills\nExperience working with the scrum methodology\nProfil recherch\u00e9\nBackground : Master + 5 - Engineer\nExperience : 2 - 5 years\nSignificant experience as a devops engineering in a GCP environment.\nNice to have : you have already worked in a start up environment\nFluent in english\nWork at Allphins\n\u2600\ufe0f Key responsibilities: autonomy, impact & strong visibility\n\ud83c\udf0f Work in an international environment\n\ud83d\udcb8 Attractive remuneration (with benefits : Swile Card, Alan..)\n\ud83d\udcbb Hybrid working possible (2/3 days remote)\n\ud83d\ude80 Great career opportunities & solid learning\n\ud83c\udfe2 Offices in the center of Paris (WeWork Jules Lefebvre)\n\ud83e\uddbe High-end equipments (tools & technologies)\n\ud83c\udfd6\ufe0f One off-site per year\nProcess de recrutement\nInterview HR\nTech interview and case study\nInterview with Jean-Baptiste, CTO and co founder\nInformations compl\u00e9mentaires\nType de contrat : CDI\nLieu : Paris\nNiveau d'\u00e9tudes : Bac +5 / Master\nExp\u00e9rience : > 4 ans\nT\u00e9l\u00e9travail partiel possible\nSalaire : entre 49996\u20ac et 60000\u20ac / an\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "R",
                "Go"
            ],
            "DataBase": [
                "SQL"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [],
            "MachineLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [],
            "DevTools": [
                "Git",
                "Docker"
            ],
            "Os": [],
            "DBMS": [
                "PostgreSQL"
            ],
            "SoftBigDataProcessing": [],
            "Automation": [
                "Kubernetes",
                "Airflow"
            ],
            "InfrastructureAsCode": [
                "Terraform"
            ],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [
                "Docker",
                "Kubernetes"
            ],
            "Collaboration": [],
            "Other": [
                "DevOps",
                "Big Data",
                "Cloud",
                "CI/CD"
            ],
            "FrSoftSkills": [],
            "EnSoftSkils": []
        },
        "details": {
            "JobDetail": [
                "Remote"
            ],
            "TypeContract": [
                "CDI"
            ],
            "Salary": [
                "49996"
            ],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s",
                "4",
                "4",
                "4"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "title": "Cloud engineer Azure",
        "company": "Harnham",
        "location": "Paris, \u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/cloud-engineer-azure-at-harnham-3850370394?position=8&pageNum=5&refId=HqnBGIsq%2F7%2BaI9g3tHePPw%3D%3D&trackingId=xYNN2NVn%2F32kEONH7jx09A%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Cloud Engineer\nMinimum 1 an d'exp\u00e9rience en tant que Cloud engineer\nParis\n2jTT\nCDI\nNous sommes \u00e0 la recherche d'un(e) Cloud Engineer talentueux(se) pour rejoindre une \u00e9quipe dynamique dans le secteur du retail. En tant que Cloud Engineer, vous serez au c\u0153ur de notre transformation digitale, contribuant \u00e0 la conception, \u00e0 la mise en \u0153uvre et \u00e0 la maintenance de l'infrastructure cloud.\nStack technique : Azure, Powershell, ElasticSearch, Kibana, Grafana,\nResponsabilit\u00e9s Principales:\nConcevoir, d\u00e9ployer et g\u00e9rer notre infrastructure cloud sur Microsoft Azure, garantissant sa stabilit\u00e9, sa s\u00e9curit\u00e9 et sa performance.\nD\u00e9velopper des solutions d'automatisation pour le provisionnement, la configuration et la gestion des ressources cloud.\nCollaborer \u00e9troitement avec les \u00e9quipes techniques et m\u00e9tier pour comprendre les besoins et proposer des solutions cloud adapt\u00e9es.\nAssurer la conformit\u00e9 aux normes de s\u00e9curit\u00e9 et de gouvernance cloud.\nSurveiller et optimiser les performances des services cloud pour garantir une exp\u00e9rience utilisateur optimale.\nQualifications Recherch\u00e9es:\nDipl\u00f4me de Master en informatique ou dans un domaine connexe, ou exp\u00e9rience \u00e9quivalente avec au moins 1 an d'exp\u00e9rience dans un poste similaire.\nExp\u00e9rience av\u00e9r\u00e9e dans la conception, la mise en \u0153uvre et la gestion d'infrastructures cloud, de pr\u00e9f\u00e9rence sur\nMicrosoft Azure\n.\nMa\u00eetrise des outils et technologies DevOps, notamment\nAzure DevOps, PowerShell et Terraform\n.\nConnaissance approfondie des technologies de conteneurisation telles que\nKubernetes\n.\nExp\u00e9rience avec Elastic Search serait un atout.\nForte passion pour l'innovation et la r\u00e9solution de probl\u00e8mes, avec une orientation vers l'automatisation et l'am\u00e9lioration continue.\nCapacit\u00e9 \u00e0 travailler de mani\u00e8re proactive et autonome, avec un excellent esprit d'\u00e9quipe.\nMa\u00eetrise du fran\u00e7ais et de l'anglais est n\u00e9cessaire.\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "R",
                "Go"
            ],
            "DataBase": [
                "Elasticsearch"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [],
            "MachineLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [
                "Azure"
            ],
            "DevTools": [
                "Git"
            ],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [
                "Kubernetes"
            ],
            "InfrastructureAsCode": [
                "Terraform"
            ],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [
                "Kubernetes"
            ],
            "Collaboration": [],
            "Other": [
                "DevOps",
                "Cloud"
            ],
            "FrSoftSkills": [
                "R\u00e9solution de probl\u00e8mes"
            ],
            "EnSoftSkils": []
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [
                "CDI"
            ],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "title": "Cloud Architect (Azure) H/F",
        "company": "OPEN",
        "location": "Levallois-Perret, \u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/cloud-architect-azure-h-f-at-open-3720167006?position=9&pageNum=5&refId=HqnBGIsq%2F7%2BaI9g3tHePPw%3D%3D&trackingId=AGVc%2FDQYvXNEzb09Qzum5A%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Qui sommes-nous ?\nRejoindre la BU Cloud & DevOps, c\u2019est rejoindre La communaut\u00e9 d'experts techniques qui accompagne des sujets strat\u00e9giques et transverses pour Open France.\nVous serez en charge d'accompagner et conseiller nos clients autour des sujets Microsoft Cloud Azure depuis l\u2019expression et la collecte de leurs besoins fonctionnels.\nVos missions d\u00e9taill\u00e9es\nD\u00e9finir les architectures cibles Cloud et Hybride qui vont soutenir les briques du SI Client et capitaliser sur les projets pour d\u00e9finir nos standards d\u2019architecture.\nD\u00e9finir les chemins de migration et de transition des applications et des workloads clients vers Microsoft Azure,\nImpl\u00e9menter ou coordonner l\u2019int\u00e9gration des architectures et des solutions propos\u00e9es,\nAccompagner nos forces de vente dans les soutenances des dossiers de r\u00e9ponse complexes,\nParticiper activement \u00e0 la conception des nouvelles offres, en capitalisant sur les projets et les architectures d\u00e9j\u00e0 produites.\nVous\nDisposez d\u2019une premi\u00e8re exp\u00e9rience significative dans la conception d\u2019architecture de solutions et de services Cloud/SaaS privil\u00e9gi\u00e9s sur Microsoft Cloud Azure,\nMaitrisez sur le plan technique les concepts d\u2019architecture en Cloud Public : Microsoft Azure, IaaS/PaaS/SaaS, Azure Stack(s), solutions hybrides et multicloud, s\u00e9curit\u00e9 et gouvernance du Cloud, modernisation d\u2019applications et de donn\u00e9es,\nAimez travailler en \u00e9quipe et dans la bonne humeur,\nAvez le sens du service,\nAvez le go\u00fbt du challenge et la culture du r\u00e9sultat,\n\ud83e\udd1d Vous \u00eates mettre de votre carri\u00e8re : Comment ?\nInt\u00e9grer des projets transverses et strat\u00e9giques : outils interne, meetup, summit, formation, avant-ventes, chiffrage, veille, audit SI \u2026\nEvoluer vers votre r\u00f4le gr\u00e2ce \u00e0 un accompagnement personnalis\u00e9 et un parcours de formation et certifications adapt\u00e9.\nNotre process de recrutement\nBref \u00e9change t\u00e9l\u00e9phonique\nRencontre RH pour parler de vous, de vos aspirations professionnelles et vous pr\u00e9senter Open,\nEchange avec l\u2019un des experts\nTemps de partage avec votre futur manager.\n\u2705Apr\u00e8s vous avoir souhait\u00e9 la bienvenue vous b\u00e9n\u00e9ficiez d\u2019un parcours d\u2019int\u00e9gration sur-mesure.\nCODE REC : ACH23516\nQu\u2019attendez-vous pour \u00eatre Open ?\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "R",
                "Go"
            ],
            "DataBase": [],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [],
            "MachineLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [
                "Azure"
            ],
            "DevTools": [],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [
                "DevOps",
                "Cloud"
            ],
            "FrSoftSkills": [],
            "EnSoftSkils": []
        },
        "details": {
            "JobDetail": [
                "Hybride"
            ],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "title": "Senior Data & Cloud Engineer (H/F)",
        "company": "fifty-five",
        "location": "Paris, \u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/senior-data-cloud-engineer-h-f-at-fifty-five-3915044673?position=10&pageNum=5&refId=HqnBGIsq%2F7%2BaI9g3tHePPw%3D%3D&trackingId=7%2BtFXlpUGRyTUk0pTaMArg%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Senior Data & Cloud Engineer\nfifty-five est une data-company d'un genre nouveau qui aide les marques \u00e0 exploiter les donn\u00e9es pour am\u00e9liorer le marketing, les m\u00e9dias et l'exp\u00e9rience client gr\u00e2ce \u00e0 une combinaison de services de conseil et de technologie sp\u00e9cialis\u00e9s.\nEn tant que pilier data et marketing du Brandtech Group, nous offrons des services qui combinent le conseil en strat\u00e9gie, les services de cloud, le conseil en m\u00e9dia et l'exp\u00e9rience client.\nfifty-five, c'est plus de 400 experts du num\u00e9rique. Des digital consultants, des sp\u00e9cialistes du tracking et du m\u00e9dia, des ing\u00e9nieurs et des data scientists, travaillent tous en \u00e9troite collaboration pour fournir des conseils marketing de haut niveau et une assistance technique aux marques, dans tout type d'industrie, partout dans le monde.\nPartenaire des annonceurs de la collecte \u00e0 l'activation et l'exploitation des donn\u00e9es, nous aidons les organisations \u00e0 devenir de v\u00e9ritables entit\u00e9s omnicanales ma\u00eetrisant l'efficacit\u00e9 de leur \u00e9cosyst\u00e8me digital et ses synergies avec le monde physique.\nBas\u00e9 \u00e0 Paris, nous op\u00e9rons sur 3 fuseaux horaires depuis nos 10 bureaux, situ\u00e9s \u00e0 Paris, Londres, Gen\u00e8ve, Milan, Shanghai, Hong Kong, Shenzhen, Taipei, Singapour et New York. fifty-five attache une importance particuli\u00e8re au bien-\u00eatre de ses collaborateurs, ce qui lui a permis de figurer dans le classement Best Workplaces France en 2018.\nContexte :\nL'\u00e9quipe d'ing\u00e9nierie d\u00e9veloppe et met en \u0153uvre les solutions techniques permettant la r\u00e9alisation de pipelines de donn\u00e9es et l'impl\u00e9mentation de data platform pour nos clients : r\u00e9cup\u00e9ration de datas sur de multiples sources de donn\u00e9es (APIs, files, etc.), data cleaning, data processing, automation et monitoring de l'ensemble. L'\u00e9quipe s'appuie sur des technologies r\u00e9centes (docker, kubernetes, terraform, notebooks, etc.) et met en place ses projets dans les diff\u00e9rents clouds du march\u00e9 (GCP, Azure, AWS...).\nMission :\nNous sommes \u00e0 la recherche d'une personne capable de r\u00e9aliser des projets techniques pour r\u00e9pondre aux besoins de nos clients (par exemple: syst\u00e8me de recommandations de produits, d\u00e9tection d'anomalies, ranking). Les activit\u00e9s vont du chiffrage et du sizing technique \u00e0 la mise en \u0153uvre des architectures, en passant par la revue des sp\u00e9cifications fonctionnelles et la production de code. Le Data & Cloud Engineer sera \u00e9paul\u00e9 par un Lead dans ses missions. Il sera \u00e9galement amen\u00e9 \u00e0 participer \u00e0 la R&D et \u00e0 accompagner les \u00e9quipes transverses dans la mise en place d'outils de travail internes (librairies pour les data scientists, environnement Notebooks pour les data analysts et data scientists, d\u00e9veloppement de frameworks sur diff\u00e9rents cloud providers, etc.).\nNous souhaitons trouver la bonne personne pour faire \u00e9voluer ou cr\u00e9er de nouvelles solutions dans ce cadre. Les missions comprennent aussi bien du prototypage rapide pour des d\u00e9monstrateurs, que de la production de code robuste qui tourne en production tous les jours.\nComp\u00e9tences et exp\u00e9riences :\n4-5 ans d'exp\u00e9rience en tant que Data Engineer\nMa\u00eetrise de Python, SQL\nMa\u00eetrise des environnements Cloud. Id\u00e9alement certifi\u00e9 GCP, Azure ou AWS\nBonne connaissance de Docker/Kubernetes\nBonne connaissance d'au moins un data warehouse (BigQuery, Snowflake, etc)\nConnaissance autour des Notebooks (Jupyter)\nA l'aise avec des concepts li\u00e9s aux APIs (OAuth, REST, etc.)\nA l'aise avec les notions d'Infrastructure as Code (Terraform)\nAu courant des pratiques GitOps et connaissances des concepts autour du CI/CD\nLa ma\u00eetrise d'un orchestrateur, comme Apache Airflow, est un plus\nEsprit d'\u00e9quipe (collaborer aux tests unitaires, revue de code, partage de code, sprints)\nBon niveau en fran\u00e7ais et en anglais\nA d\u00e9j\u00e0 travaill\u00e9 en mode projet avec des interlocuteurs vari\u00e9s (consultant, data analyst, data scientist)\nUne exp\u00e9rience en marketing digital est un plus\nNous proposons :\nun bureau au centre de Paris avec terrasse et jardin\nun environnement multiculturel avec des collaborateurs aux nationalit\u00e9s multiples (France, Royaume-Uni, Etats-Unis, Chine, Tunisie, Italie et plus)\ndes projets avec nos bureaux \u00e0 Londres, Hong Kong, New York, Shanghai, Gen\u00e8ve, Shenzhen et Taipei\ndes TGIF et supers soir\u00e9es\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "R"
            ],
            "DataBase": [
                "SQL"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [
                "Apache Airflow"
            ],
            "MachineLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [
                "AWS",
                "Azure"
            ],
            "DevTools": [
                "Git",
                "Docker"
            ],
            "Os": [],
            "DBMS": [
                "Snowflake",
                "Snowflake",
                "BigQuery"
            ],
            "SoftBigDataProcessing": [],
            "Automation": [
                "Kubernetes",
                "Airflow"
            ],
            "InfrastructureAsCode": [
                "Terraform"
            ],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [
                "Docker",
                "Kubernetes"
            ],
            "Collaboration": [],
            "Other": [
                "Cloud",
                "CI/CD"
            ],
            "FrSoftSkills": [
                "Collaboration",
                "Organisation"
            ],
            "EnSoftSkils": [
                "Collaboration"
            ]
        },
        "details": {
            "JobDetail": [
                "Senior"
            ],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s",
                "5",
                "5",
                "5"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "title": "Site Reliability Engineer, AI Workbench",
        "company": "Renesas Electronics",
        "location": "Paris, \u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/site-reliability-engineer-ai-workbench-at-renesas-electronics-3897557499?position=1&pageNum=7&refId=AufKBH3ju6SkIv6PYkccnA%3D%3D&trackingId=QHi7IVm2AaSJ6sD8ezDFGg%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Company Description\nRenesas is one of the top global semiconductor companies in the world. We strive to develop a safer, healthier, greener, and smarter world, and our goal is to make every endpoint intelligent by offering product solutions in the automotive, industrial, infrastructure and IoT markets. Our robust product portfolio includes world-leading MCUs, SoCs, analog and power products, plus Winning Combination solutions that curate these complementary products. We are a key supplier to the world\u2019s leading manufacturers of electronics you rely on every day; you may not see our products, but they are all around you.\nRenesas employs roughly 21,000 people in more than 30 countries worldwide. As a global team, our employees actively embody the Renesas Culture, our guiding principles based on five key elements: Transparent, Agile, Global, Innovative, and Entrepreneurial. Renesas believes in, and has a commitment to, diversity and inclusion, with initiatives and a leadership team dedicated to its resources and values. At Renesas, we want to build a sustainable future where technology helps make our lives easier. Join us and build your future by being part of what\u2019s next in electronics and the world.\nOverview\nJob Description\nWe are seeking a skilled and experienced Site Reliability Engineer to join our team. In this role, you will be part of the AI & Cloud Engineering (ACE) Division and AI Workbench team. Our AI Workbench is a cloud-based environment to accelerate Automotive AI Software Development and Evaluation. The AI Workbench has 4 main functional blocks today, with one of those blocks providing access to both SILS (Software in the Loop Simulator) and HILS (Hardware in the Loop\u202fSimulator).\nAs a Site Reliability Engineer - ACE, you will be responsible for designing, building, and maintaining our infrastructure. You should have a strong background in cloud technologies and excellent problem-solving skills. You will work closely with multiple engineering teams (and cross-function teams) to support their infrastructure requirements.\nOur division\u2019s mission is to use the latest AI and cloud technologies to develop the best AI inference for advanced driver safety engineers building self-driving vehicles and other high performance compute products. Renesas is the leading automotive electronics supplier globally, and this is a rare opportunity to develop the infrastructure required to deploy our AI software to the billions of devices we ship to customers every year. You will join our newly formed AI & Cloud Engineering organization of around 100 software engineers. Due to strong demand for our AI-related products we are planning to triple in size in the next three years, so there is lots of room for you to help us grow the team together while remaining small. Our team\u2019s key locations are Tokyo, London, Paris, Dusseldorf, Beijing, Singapore, Ho Chi Minh City and other metropolitan areas, but you can also join fully remotely from other locations globally or get our support to relocate to our key hubs such as Tokyo.\nResponsibilities\nDesign, build, and maintain our division\u2019s infrastructure that supports our application development, with a focus on reliability, scalability, and performance.\nImplement and automate deployment, monitoring, and scaling processes to ensure the smooth operation of our systems and services.\nMonitor system performance and reliability metrics, troubleshoot issues, and implement solutions to prevent downtime and improve efficiency.\nCollaborate with our teams Engineers to design, develop, and deploy reliable and scalable applications.\nDevelop and maintain tools and scripts for automation, configuration management, and monitoring of our infrastructure and applications.\nRespond to incidents and emergencies to minimize downtime and ensure reliability of or systems.\nContinuously evaluate and improve our infrastructure, processes, and practises to enhance reliability, scalability, and efficiency.\nStay up-to-date with industry trends, best practises, and emerging technologies in site reliability engineering and cloud computing.\nQualifications\nBachelor\u2019s or Master\u2019s degree in Computer Science, Information Technology, or related field.\nExperience working as a Site Reliability Engineer or in a similar role.\nProgramming skills in languages such as Python, Java, or similar.\nHands-on experience with cloud platforms such as AWS, Azure, or GCP.\nExperience with containerization technologies such as Docker and container orchestration platforms such as Kubernetes.\nProficiency in Linux system administration, shell scripting, and network troubleshooting.\nExperience with infrastructure as code tools such as Terraform, Ansible, or similar.\nKnowledge of CI/CD pipelines and automated testing frameworks.\nStrong analytical and problem-solving.\nExcellent communication and collaboration skills.\nAdditional Information\nRenesas Electronics Corporation empowers a safer, smarter and more sustainable future where technology helps make our lives easier. The leading global provider of microcontrollers, Renesas combines our expertise in embedded processing, analog, power and connectivity to deliver complete semiconductor solutions. These Winning Combinations accelerate time to market for automotive, industrial, infrastructure and IoT applications, enabling billions of connected, intelligent devices that enhance the way people work and live. Learn more at www.renesas.com.\nRenesas\u2019 mission, To Make Our Lives Easier, is underpinned by our company culture, TAGIE. TAGIE stands for Transparent, Agile, Global, Innovative and Entrepreneurial. Our goal is to embed this unique culture in everything we do to succeed as a company and create trust with our diverse colleagues, customers and stakeholders.\nRenesas Electronics is an equal opportunity and affirmative action employer, committed to supporting diversity and fostering a work environment free of discrimination on the basis of sex, race, religion, national origin, gender, gender identity, gender expression, age, sexual orientation, military status, veteran status, or any other basis protected by law. For more information, please read our Diversity & Inclusion Statement.\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "Java",
                "Scala",
                "R",
                "Go"
            ],
            "DataBase": [],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [],
            "MachineLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [
                "AWS",
                "Azure"
            ],
            "DevTools": [
                "Docker"
            ],
            "Os": [
                "Linux"
            ],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [
                "Ansible",
                "Kubernetes"
            ],
            "InfrastructureAsCode": [
                "Terraform"
            ],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [
                "Docker",
                "Kubernetes"
            ],
            "Collaboration": [
                "Teams"
            ],
            "Other": [
                "Cloud",
                "CI/CD"
            ],
            "FrSoftSkills": [
                "Communication",
                "Leadership",
                "Collaboration"
            ],
            "EnSoftSkils": [
                "Communication",
                "Leadership",
                "Collaboration",
                "Organization",
                "Initiative"
            ]
        },
        "details": {
            "JobDetail": [
                "Remote",
                "Full"
            ],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "title": "Senior DevOps Engineer (Tech)",
        "company": "CoinMarketCap",
        "location": "France",
        "link": "https://fr.linkedin.com/jobs/view/senior-devops-engineer-tech-at-coinmarketcap-3885180166?position=2&pageNum=7&refId=AufKBH3ju6SkIv6PYkccnA%3D%3D&trackingId=oTeLOiEUH%2BDc3IH6Xb%2FN0g%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Company Description\nPOWERING CRYPTO WITH DATA\nCoinMarketCap is the world\u2019s most trusted and accurate source of data for cryptocurrencies. Used by millions of individuals, organizations, and exchanges, CoinMarketCap brings the most up-to-date market capitalizations, pricing, and cryptocurrency information to our users.\nPulling data from multiple exchanges and combining our robust research allows us to provide the most realistic representation of each cryptocurrency. As we grow, we will continue to provide access to our data wherever, whenever, and however is most helpful to our users.\nCREATING AN OPEN WORLD\nOur mission is to be the world\u2019s authority on cryptocurrency data. We believe in an open and Decentralized world, where we play a pivotal role in powering decisions and insights to drive greater understanding and adoption of cryptocurrencies. We want to achieve this mission with people who truly believe in the value and potential of empowering individuals.\nJob Description\nImprove the stability and availability of global infrastructure and services\nDevelop and maintain automation CI/CD solutions for the company's products and services\nProactively collaborate with other teams and collect feedback to improve existing solutions\nEvaluate new technology options and vendor products to improve the company's automation capabilities\nEngage in and improve the whole lifecycle of service, from inception and design, through to deployment, operation, and refinement\nDevelop and maintain tools, re-designing capacity planning infrastructure for greater scalability\nTroubleshooting, diagnosing, fixing software issues, and ensuring data security\nDefine architecture improvements, and push for changes that improve reliability\nQualifications\nAt least 6 years extensive experience with AWS in Blockchain/Fintech industry\nExperience in large-scale, distributed systems\nExperience with tools such as Kubernates, Docker, Ansible, Terraform, etc\nDemonstrated programming skills in NodeJS, Python, Golang, or similar\nFamiliarity with CI/CD tools such as K8s, GitHub Action, Prow, ArgoCD, etc\nExperience with full-stack development is a plus\nAdditional Information\nWorking at CoinMarketCap\nDo something meaningful; Be a part of the future of finance technology and the leading company in the industry\nFast moving, challenging and unique business problems\nInternational work environment, flat organization, flexible working hours\nGreat career development opportunities in a growing company\nPossibility for relocation and international transfers mid-career\nCompetitive salary\nBy submitting a job application, you confirm that you have read and agree to our Candidate Privacy Notice.\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "Scala",
                "R",
                "Go"
            ],
            "DataBase": [],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [],
            "MachineLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [
                "AWS"
            ],
            "DevTools": [
                "Git",
                "Docker"
            ],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [
                "Ansible"
            ],
            "InfrastructureAsCode": [
                "Terraform"
            ],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [
                "Docker"
            ],
            "Collaboration": [
                "Teams"
            ],
            "Other": [
                "CI/CD"
            ],
            "FrSoftSkills": [],
            "EnSoftSkils": [
                "Organization"
            ]
        },
        "details": {
            "JobDetail": [
                "Full"
            ],
            "TypeContract": [],
            "Salary": [
                "Salary"
            ],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "title": "Senior DevOps Engineer f/m",
        "company": "Ansys",
        "location": "Greater Lyon Area",
        "link": "https://fr.linkedin.com/jobs/view/senior-devops-engineer-f-m-at-ansys-3918759103?position=3&pageNum=7&refId=AufKBH3ju6SkIv6PYkccnA%3D%3D&trackingId=51WT2uSnMtMPyEJbMOkI5A%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Requisition #:\n14312\nOur Mission: Powering Innovation That Drives Human Advancement\nWhen visionary companies need to know how their world-changing ideas will perform, they close the gap between design and reality with Ansys simulation. For more than 50 years, Ansys software has enabled innovators across industries to push boundaries by using the predictive power of simulation. From sustainable transportation to advanced semiconductors, from satellite systems to life-saving medical devices, the next great leaps in human advancement will be powered by Ansys.\nInnovate With Ansys, Power Your Career.\nSummary / Role Purpose\nAnsys is seeking a Senior DevOps Engineer to be part of a rapidly growing team that\u2019s responsible for design, development, build and delivery of technology components that are consumed in different Ansys products. You will be working closely with Development and QA engineers, to deploy and manage GitHub, ADO pipelines, and with operations staff to ensure that systems are up and running smoothly.\nKey Duties And Responsibilities\nPerforms all DevOps activities, including the implementation, maintenance, monitoring, and verification of product builds and packaging to provide quality production builds\nUnderstands and employs best practices\nWorks closely with development to adjust builds and packaging to changing product requirements\nAnticipates future needs and technology evolution and proposes and participates in implementation of new solutions\nCreate sustainable systems and services through automation and uplifts\nDesign, build and maintain CI/CD pipelines in multiple environments and CSP\nMinimum Education/Certification Requirements And Experience\nBS in Engineering, Computer Science, or related field with 5 years\u2019 experience, MS with 3 years\u2019 experience, or PhD with 1 year experience in an Infrastructure/DevOps Engineering role\nExperience with CI/CD pipelines end-to-end, from code commits to production\nExperience with Azure DevOps (and Yaml)\nExperience with Conan, NuGet, wheel packages\nProficient in multiple scripting languages (e.g., Python, PowerShell, Bash)\nSource/version control (Git)\nGitHub actions\nExperience in installing, configuring and troubleshooting Windows & Linux based environments\nSelf-driven desire to continuously learn new technologies and skills, and solve tough problems\nAwareness of DevOps and Agile principles and the ability to apply them\nPreferred Qualifications And Skills\nExperience with Container technologies such as Docker\nExperience with secure development, coding, engineering practices\nExperience with Ansible, Terraform, etc.\nExperience with using monitoring and log analytics tools and creating dashboards\nExperience with C++ / .NET / JavaScript\nFamiliar with Platform as a Service (PaaS) technologies such as Kubernetes\nAt Ansys, we know that changing the world takes vision, skill, and each other. We fuel new ideas, build relationships, and help each other realize our greatest potential. We are ONE Ansys. We operate on three key components: the commitments to our stakeholders, the behaviors of how we work together, and the actions of how we deliver results.\nTogether as ONE Ansys, we are powering innovation that drives human advancement.\nOur Commitments\nAmaze with innovative products and solutions\nMake our customers incredibly successful\nAct with integrity\nEnsure employees thrive and shareholders prosper\nOur Values\nAdaptability: Be open, welcome what's next\nCourage: Be courageous, move forward passionately\nGenerosity: Be generous, share, listen, serve\nAuthenticity: Be you, make us stronger\nOur Actions\nWe commit to audacious goals\nWe work seamlessly as a team\nWe demonstrate mastery\nWe deliver outstanding results\nINCLUSION IS AT OUR CORE\nWe believe diverse thinking leads to better outcomes. We are committed to creating and nurturing a workplace that fuels this by welcoming people, no matter their background, identity, or experience, to a workplace where they are valued and where diversity, inclusion, equity, and belonging thrive.\nWelcome What\u2019s Next In Your Career At Ansys\nAt Ansys, you will find yourself among the sharpest minds and most visionary leaders across the globe. Collectively we strive to change the world with innovative technology and transformational solutions. With a prestigious reputation in working with well-known, world-class companies, standards at Ansys are high \u2014 met by those willing to rise to the occasion and meet those challenges head on. Our team is passionate about pushing the limits of world-class simulation technology, empowering our customers to turn their design concepts into successful, innovative products faster and at a lower cost.\nAt Ansys, it\u2019s about the learning, the discovery, and the collaboration. It\u2019s about the \u201cwhat\u2019s next\u201d as much as the \u201cmission accomplished.\u201d And it\u2019s about the melding of disciplined intellect with strategic direction and results that have, can, and do impact real people in real ways. All this is forged within a working environment built on respect, autonomy, and ethics.\nCREATING A PLACE WE\u2019RE PROUD TO BE\nAnsys is an S&P 500 company and a member of the NASDAQ-100. We are proud to have been recognized for the following more recent awards, although our list goes on: Newsweek\u2019s Most Loved Workplace globally and in the U.S., Gold Stevie Award Winner, America\u2019s Most Responsible Companies, Fast Company World Changing Ideas, Great Place to Work Certified (Belgium, China, Greece, France, India, Japan, Korea, Spain, Sweden, Taiwan, and U.K.).\nFor more information, please visit us at www.ansys.com\nAnsys is an Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, veteran status, and other protected characteristics.\nAnsys does not accept unsolicited referrals for vacancies, and any unsolicited referral will become the property of Ansys. Upon hire, no fee will be owed to the agency, person, or entity.\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "Java",
                "C++",
                "R",
                "Go",
                "Bash",
                "JavaScript"
            ],
            "DataBase": [],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [],
            "MachineLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [
                "Azure"
            ],
            "DevTools": [
                "Git",
                "Docker"
            ],
            "Os": [
                "Linux",
                "Windows"
            ],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [
                "Ansible",
                "Kubernetes"
            ],
            "InfrastructureAsCode": [
                "Terraform"
            ],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [
                "Docker",
                "Kubernetes"
            ],
            "Collaboration": [],
            "Other": [
                "DevOps",
                "ML",
                "CI/CD"
            ],
            "FrSoftSkills": [
                "Collaboration"
            ],
            "EnSoftSkils": [
                "Adaptability",
                "Collaboration"
            ]
        },
        "details": {
            "JobDetail": [
                "Senior"
            ],
            "TypeContract": [],
            "Salary": [
                "500"
            ],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "title": "Devops engineer Senior",
        "company": "Harnham",
        "location": "Greater Paris Metropolitan Region",
        "link": "https://fr.linkedin.com/jobs/view/devops-engineer-senior-at-harnham-3903596592?position=4&pageNum=7&refId=AufKBH3ju6SkIv6PYkccnA%3D%3D&trackingId=KJI2Ab0PNimSypUQiTn0eA%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "DevOps Engineer Senior (Paris Sportif)\n5 ans d'exp\u00e9rience minimum\n3j tt\nParis\nUp to 80k\u20ac\nCDI\nDescription du Poste :\nVous \u00eates un Expert DevOps \u00e0 la recherche d'une nouvelle opportunit\u00e9 dans le domaine passionnant des paris sportifs ? Nous avons le poste parfait pour vous ! Nous recrutons un DevOps exp\u00e9riment\u00e9 avec un minimum de 5 ans d'exp\u00e9rience pour rejoindre une \u00e9quipe dynamique dans le secteur des paris sportifs en ligne. En tant qu'Expert DevOps, vous serez responsable de concevoir, de d\u00e9velopper et de maintenir l'infrastructure cloud sur AWS, en mettant en \u0153uvre les meilleures pratiques DevOps pour garantir des performances optimales et une scalabilit\u00e9 maximale.\nResponsabilit\u00e9s :\nConception et d\u00e9veloppement de l'infrastructure cloud sur AWS.\nAutomatisation des processus de d\u00e9ploiement et de gestion des environnements.\nUtilisation de Terraform pour l'infrastructure as code.\nOptimisation des performances, de la s\u00e9curit\u00e9 et de la scalabilit\u00e9.\nCollaboration \u00e9troite avec les \u00e9quipes de d\u00e9veloppement pour am\u00e9liorer les pipelines CI/CD.\nSurveillance et r\u00e9solution des probl\u00e8mes li\u00e9s \u00e0 l'infrastructure et aux applications.\nContribution \u00e0 l'am\u00e9lioration continue des processus DevOps.\nExigences :\nMinimum de 5 ans d'exp\u00e9rience en tant que DevOps, id\u00e9alement dans le secteur des paris sportifs.\nExpertise avanc\u00e9e avec AWS et exp\u00e9rience significative avec Terraform.\nSolide compr\u00e9hension des concepts DevOps et des pratiques d'automatisation.\nComp\u00e9tences en scripting (Python, Shell) et en gestion des outils de monitoring.\nCapacit\u00e9 \u00e0 travailler de mani\u00e8re autonome et en \u00e9quipe dans un environnement agile.\nExcellentes comp\u00e9tences en communication et en r\u00e9solution de probl\u00e8mes.\nMa\u00eetrise de l'anglais, le fran\u00e7ais serait un atout.\nInt\u00e9ress\u00e9(e) ?\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "Scala",
                "R"
            ],
            "DataBase": [],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [],
            "MachineLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [
                "AWS"
            ],
            "DevTools": [],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [
                "Terraform"
            ],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [
                "DevOps",
                "Cloud",
                "CI/CD"
            ],
            "FrSoftSkills": [
                "Communication",
                "R\u00e9solution de probl\u00e8mes",
                "Collaboration"
            ],
            "EnSoftSkils": [
                "Communication",
                "Collaboration"
            ]
        },
        "details": {
            "JobDetail": [
                "Senior"
            ],
            "TypeContract": [
                "CDI"
            ],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s",
                "5",
                "5",
                "5"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "title": "DevOps Engineer (F/M/NB)",
        "company": "Ubisoft Bordeaux",
        "location": "Bordeaux, Nouvelle-Aquitaine, France",
        "link": "https://fr.linkedin.com/jobs/view/devops-engineer-f-m-nb-at-ubisoft-bordeaux-3910070709?position=5&pageNum=7&refId=AufKBH3ju6SkIv6PYkccnA%3D%3D&trackingId=J5XICMrjgGAvXESCrfAT5Q%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Company Description\nAbout Ubisoft\nUbisoft\u2019s 20,000 team members, working across more than 30 countries around the world, are bound by a common mission to enrich players\u2019 lives with original and memorable gaming experiences. Their commitment and talent have brought to life many acclaimed franchises such as Assassin\u2019s Creed, Far Cry, Watch Dogs, Just Dance, Rainbow Six, and many more to come. Ubisoft is an equal opportunity employer that believes diverse backgrounds and perspectives are key to creating worlds where both players and teams can thrive and express themselves. If you are excited about solving game-changing challenges, cutting edge technologies and pushing the boundaries of entertainment, we invite you to join our journey and help us create the unknown.\nUbisoft Bordeaux\nFounded in September 2017, Ubisoft Bordeaux works with passion on the biggest AAAA\u2019s game in order to offer the best gaming experiences to our players. Today, the studio has more than 400 talents, from 20 different nationalities, who work on licenses such as Assassin's Creed, Beyond Good & Evil 2, plus other unannounced free-to-play games. We are also working on exciting technologies with the Anvil team, Online services teams and with La Forge who seek to validate the value of technological innovations.\nHere is an opportunity to join a stimulating, international, ambitious but friendly studio and work in our new Game Streaming team.\nJob Description\nAs a DevOps Engineer of the Game Streaming team, you will be implementing CI/CD best practices for our interactive game streaming platform for internal and player-facing applications. You will contribute to the development of our infrastructure according to the needs of the team, working side by side with the Product and Development in a fast and creative atmosphere.\nOur team members are self-sufficient and have a problem-solving mindset. We are looking for people who are passionate about gaming and who are always one step ahead in development processes and release management.\nWe expect the candidate to be curious, open-minded, polyvalent, and comfortable exploring new architectures and solutions to deliver a brand-new platform.\nResponsibilities\nWork closely with teammates to design and build highly scalable, available, and reliable CI/CD processes using Ubisoft-recommended practices and tools\nOversee release management for cloud and native applications as well as related SDK\nApply site reliability engineering principles to our services; implement service monitoring strategies and optimize service performance\nManage individual priorities, deadlines, and deliverables\nContribute to engineering efforts from planning and organization to execution and delivery to solve complex engineering problems.\nQualifications\nMinimum Qualifications\nBA/BS in Computer Science, related technical field, or equivalent practical experience\n5 years of relevant work experience\nExperience with software development with one or more general programming languages (e.g. Go, Java, C/C++, Python, or JavaScript)\nPreferred Qualifications\nExperience with Gitlab and at least one additional CI/CD framework\nExperience with Container technology such as Kubernetes, or Docker\nExperience in automation, testing or monitoring framework development\nExperience with configuration management systems and cloud infrastructures such as OpenStack, AWS, Google, or Azure\nGo hands-on skills\nAbility to learn other coding languages as needed and contribute to the APIs integration on the client side\nDemonstrated ability to share knowledge via formal mentoring, reviewing code, reviewing design documents, providing technical talks, teaching classes, or as a consultant on projects\nAdditional Information\nThis job is open for a\npermanent contract.\nProcess:\nInterview with our Tech recruiter\nTechnical assesment\nInterview(s) with the team\nIf your application is not retained, you will receive a negative answer.\nAt Ubisoft, you can come as you are. We embrace diversity in all its forms. We\u2019re committed to fostering a work environment that is inclusive and respectful of all differences, we\nvalue diversity at our company and do not discriminate on the basis of race, ethnicity, religion, gender, sexual orientation, age or disability status. All personal informations will be treated as confidential according to the Employment Equity act.\nCheck out this guide to help you with your application, and learn about our actions to encourage more diversity and inclusion.\nConsultez ce guide qui a pour but de vous accompagner dans votre candidature, et d\u00e9couvrez nos actions pour encourager plus de diversit\u00e9 et d'inclusion.\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "Java",
                "C++",
                "Scala",
                "R",
                "Go",
                "JavaScript"
            ],
            "DataBase": [],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [],
            "MachineLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [
                "AWS",
                "Azure"
            ],
            "DevTools": [
                "Git",
                "Docker"
            ],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [
                "Kubernetes"
            ],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [
                "Docker",
                "Kubernetes"
            ],
            "Collaboration": [
                "Teams"
            ],
            "Other": [
                "DevOps",
                "Cloud",
                "CI/CD"
            ],
            "FrSoftSkills": [],
            "EnSoftSkils": [
                "Organization"
            ]
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "title": "Cloud Engineer - H/F",
        "company": "METEOJOB by CleverConnect",
        "location": "Paris, \u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/cloud-engineer-h-f-at-meteojob-by-cleverconnect-3917265563?position=6&pageNum=7&refId=AufKBH3ju6SkIv6PYkccnA%3D%3D&trackingId=vTlkef%2BsiStUJDKBLw7BAA%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Entreprise\nORIENTACTION EMPLOI est un cabinet de recrutement d\u00e9ploy\u00e9 au niveau national, dans de nombreux secteurs d'activit\u00e9s.\nNous accompagnons nos client.e.s partenaires dans la recherche de profils et conseillons nos candidat.e.s dans la concr\u00e9tisation de leur projet professionnel.\nCDI, CDD, Freelance, Franchis\u00e9,... Notre cabinet propose des aventures professionnelles adapt\u00e9es aux perspectives et aux ambitions de chacun.\nDescription Du Poste\nNous recrutons pour notre client, une entreprise propri\u00e9taire, d\u00e9veloppeur et op\u00e9rateur d'actifs immobiliers, un Cloud Engineer.\nVos Missions Principales Seront\nConcevoir, impl\u00e9menter et maintenir les infrastructures Cloud sur les plateformes AWS, GCP et Azure.\nCollaborer \u00e9troitement avec les \u00e9quipes de d\u00e9veloppement pour faciliter le d\u00e9ploiement des applications et services.\nPiloter efficacement le travail des infog\u00e9rants.\nMonitorer et optimiser les performances des infrastructures Cloud.\nD\u00e9velopper et mettre en \u0153uvre l'automatisation pour accro\u00eetre l'efficacit\u00e9 des environnements Cloud.\nRester constamment inform\u00e9 des derni\u00e8res tendances et bonnes pratiques du Cloud Computing et DevOps.\nConfigurer et superviser l'int\u00e9gration et le d\u00e9ploiement continus (CI/CD) \u00e0 l'aide d'outils tels que Jenkins, CircleCI ou TravisCI.\nImpl\u00e9menter avec expertise les technologies de containerisation et d'orchestration comme Docker et Kubernetes.\nUtiliser de mani\u00e8re efficace les outils d'infrastructure as code comme Terraform et CloudFormation.\nDescription Du Profil\nDipl\u00f4me d'ing\u00e9nieur ou \u00e9quivalent (BAC+5).\nMinimum 5 ans d'exp\u00e9rience dans des r\u00f4les d'ing\u00e9nierie Cloud, avec des r\u00e9alisations de projets de migration vers le Cloud. (Move to Cloud, Cloud to Cloud)\nMa\u00eetrise des environnements AWS, bonnes comp\u00e9tences sur GCP et Azure.\nExp\u00e9rience en automatisation et scripting avec des langages comme Python, Bash ou PowerShell.\nConnaissance des outils de pipeline CI/CD tels que GitLabCI, Jenkins, CircleCI ou TravisCI.\nExp\u00e9rience avec des outils d'infrastructure as code comme Terraform et CloudFormation.\nConnaissance d'outils de monitoring et de logs comme Prometheus et Elasticsearch\nBonne compr\u00e9hension des bonnes pratiques de s\u00e9curit\u00e9 et exp\u00e9rience dans l'impl\u00e9mentation d'outils de s\u00e9curisation.\nBonne compr\u00e9hension des protocoles et architectures r\u00e9seaux.\nCapacit\u00e9 d'analyse et de r\u00e9solution de probl\u00e8mes.\nDynamique, motiv\u00e9, pragmatique et dot\u00e9 d'un fort esprit d'\u00e9quipe.\nCapacit\u00e9 \u00e0 adapter le discours technique selon le niveau de compr\u00e9hension des interlocuteurs, en fran\u00e7ais et en anglais.\nUne exp\u00e9rience sur les infrastructures On Premise serait un atout.\nLe poste est bas\u00e9 \u00e0 Paris 16. Des d\u00e9placements professionnels sont \u00e0 pr\u00e9voir.\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "R",
                "Bash"
            ],
            "DataBase": [
                "Elasticsearch"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [],
            "MachineLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [
                "AWS",
                "Azure"
            ],
            "DevTools": [
                "Git",
                "Docker",
                "Jenkins"
            ],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [
                "Kubernetes"
            ],
            "InfrastructureAsCode": [
                "Terraform",
                "CloudFormation"
            ],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [
                "Docker",
                "Kubernetes"
            ],
            "Collaboration": [],
            "Other": [
                "DevOps",
                "Cloud",
                "CI/CD"
            ],
            "FrSoftSkills": [
                "R\u00e9solution de probl\u00e8mes"
            ],
            "EnSoftSkils": []
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [
                "CDI",
                "CDD"
            ],
            "Salary": [],
            "Level": [
                "Bac+5"
            ],
            "Experience": [
                "a",
                "n",
                "s",
                "5",
                "5",
                "5"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "title": "DevOps / SRE Engineer (H/F) - Paris",
        "company": "Madbox",
        "location": "Paris, \u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/devops-sre-engineer-h-f-paris-at-madbox-3843040454?position=7&pageNum=7&refId=AufKBH3ju6SkIv6PYkccnA%3D%3D&trackingId=%2BpirLj4CshcRVSIhXolXTg%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Madbox is a fast-growing mobile gaming company with a very unique way of developing games. Everything has been made for teams to take as much ownership as possible, unleash their creativity, bring performance, and have as much fun as possible.\nIn July 2022, we launched our Pocket Champs game worldwide which quickly became one of the top-grossing games in its category.\nThe game has been scaling a lot since the launch and is now supporting millions of monthly users. All these players are interactive with backend systems that we have developed internally and deployed based on our internal knowledge.\nBut the stakes are getting high and we cannot afford to have incidents on these services because it could damage the players experience. We are now looking for someone that has some expertise on deploying online applications that will be consumed by millions of players and would hold on under a heavy load.\nThis is where you come in: take this DevOps / SRE position over and be a driving force of this new Chapter! \ud83d\udd25\nAbout The Role\nThe beginning of your journey at Madbox as an SRE Engineer:\nStarts with meeting your team, discovering who is who and engaging with everyone involved (or not) in your missions\nContinues with getting familiar with our stack, discovering our environment, tools and processes\nYou will of course play our games and learn more about how we are making them the \u201cMadbox way\u201d !\nEverything will be made for you to get you up to speed, take ownership and be ready to tackle your missions\nResponsibilities & Scope :\nDesign the backend infrastructure to host our Gaming Backend projects (APIs, Game Servers, Storage solutions\u2026)\nSetup the monitoring services to allow tracking the health metrics of our backend applications\nSetup alerts and watch over the health of our backend applications to raise an alarm every time an issue occurs\nAlert the right team\nGive a clear criticality information to define how quickly the issue needs to be solved\nDefine SLA processes for each different level of criticality that can be followed to keep the service available\nProvide as much context as you can from the metrics and logs you see on the dashboards\nSetup our backend application to scale up & down automatically to optimize our cost\nFollow up and make sure that our services scale properly and be ready to operate the scaling up / down manually if necessary\nIdentify bottlenecks in our backend applications and recommend optimization that the Gaming Backend Developers team could make to optimize the application\nKeep a vigil eye on the solutions available on the market\nProfile\nYou have 3 years of hands-on experience in a DevOps / SRE position\nYou are data-oriented, as you measure the impact of the solutions you implement\nYou have proven experience at deploying applications that are accessible to millions of users\nYou are fully proficient in English\nYou\u2019re passionate about building systems that scale\nYou focus on stability and availability\nYou\u2019re a team player who can explain their work and share their knowledge with other technical people\nHiring Process\nA call with a recruiter\nA call with the hiring manager\nA home assignment\nA review of the test with the hiring manager and someone from the automation team\nA meet the team interview\nAll our offers are extended within 48 hours maximum\nPerks and benefits\nCompetitive compensation : our compensation grid is regularly reviewed based on the evolution on the market to ensure everyone at Madbox is fairly compensated and receives frequent updates.\nHybrid remote policy: 3 days on site minimum per week + 15 additional working days fully remote per year\nCWS : Culture, Wellness & Sport, is a budget Madbox dedicated to each employee for them to self develop and take care of themselves\nHolidays : hyper-flexible 30 days off policy (take it when you need it)\nHealth of Our Madboxers is Essential: Alan Health Insurance (75% covered by Madbox)\nLunch coupons: Take advantage of the Swile card (60% covered by Madbox)\nTransport Fees : 50% covered by Madbox\nAmazing Offices: Come and explore our offices in the heart of Paris (Bonne Nouvelle Station) and Barcelona (Diagonal Station)! From taking a nap in our \u201cjungle\u201d in Paris Office to soaking up the sun on the rooftop in Barcelona at lunch, we have thought of everything to make you feel right at home. \ud83e\uddd8\u200d\u2642\ufe0f Bonus: Our fantastic Workplace Managers will make sure to provide you with the coffee/tea/snacks/drinks of your choice!\nHome office Expenses bonus\nTeam Macbook or Team PC? \ud83d\udda5 We provide all the necessary equipment\nEnglish Lessons : as our main langage in both studios is English, you can enjoy group lessons with your peers thanks to our private teacher\nMadgen : yearly company event\nContract and location\nLocation : This position is available in Paris, 19-21 Rue Poissonni\u00e8re \ud83c\uddeb\ud83c\uddf7\nor/and in Barcelona, Utopicus, Pla\u00e7a de Gal\u00b7la Plac\u00eddia, 1, 3, \ud83c\uddea\ud83c\uddf8\nContract : Permanent full-time contract\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "R",
                "Go"
            ],
            "DataBase": [],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [],
            "MachineLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [],
            "DevTools": [],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [
                "Teams"
            ],
            "Other": [
                "DevOps"
            ],
            "FrSoftSkills": [],
            "EnSoftSkils": [
                "Creativity"
            ]
        },
        "details": {
            "JobDetail": [
                "Remote",
                "Full"
            ],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "title": "DevOps Engineer Block Storage",
        "company": "Scaleway",
        "location": "Paris, \u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/devops-engineer-block-storage-at-scaleway-3880171827?position=8&pageNum=7&refId=AufKBH3ju6SkIv6PYkccnA%3D%3D&trackingId=rpBDNCFbyh7YxUJPF6FnuQ%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "About The Job\nThe Storage Team is one of the pillars of Scaleway. This team not only develops the Scaleway Elements storage products (Block Storage), but also supports all the other Scaleway Elements products that rely on Block Storage (Instances, Database, Registry, Kubernetes, and more) for proper usage. In a challenging environment, and within a team that manages hundreds of storage servers across various regions, you will be responsible for developing, automating, and enhancing Scaleway\u2019s Block Storage solution.\nThis service launched by Scaleway offers resilient, redundant, and high-availability storage for its numerous clients. Your missions will require programming, automation, and architecture skills. On top of your daily activities within your team, you will need to interact with all of Scaleway\u2019s teams, especially Instances, Network, Hardware, and Platform.\nMinimum Qualifications\nExperienced System Engineer who is passionate about DevOps best practices and cloud architecture, ideally with over 5 years of experience\nExperience with (and love for) storage systems\nStrong system-level programming skills\nGood understanding of Golang\nExperience with a continuous integration workflow, Gitlab, and Git\nStrong Linux knowledge\nDistributed systems (and debugging them)\nResponsibilities\nDeploying infrastructure in new Availability Zones\nImproving & bringing forward new ideas for our current infrastructure\nReacting to eventual failures in collaboration with other teams\nPresenting your work during tech meetings\nCoding, peer review, and deployment\nCustomer support in relation to your product\nDeploying your code\nPreferred Qualifications\nSolid experience with Ceph in high capacity and/or performance environment\nGreat oral and written communication skills\nInfrastructure deployment with Ansible\nVery good command of English\nTechnical Stack\nCeph\nUbuntu/Debian\nAnsible\nGolang\nProtobuf\nPostgresql\nLocation\nThis position is based in our offices in Paris or Lille (France)\nRecruitment Process\nScreening call - 30 mins with the recruiter\nManager Interview - 45 mins\nTechnical Interviews\nHR Interview - 45 mins\nHead of Interview - 45 mins\nOffer sent\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "R",
                "Go"
            ],
            "DataBase": [
                "SQL"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [],
            "MachineLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [],
            "DevTools": [
                "Git"
            ],
            "Os": [
                "Linux"
            ],
            "DBMS": [
                "PostgreSQL"
            ],
            "SoftBigDataProcessing": [],
            "Automation": [
                "Ansible",
                "Kubernetes"
            ],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [
                "Kubernetes"
            ],
            "Collaboration": [
                "Teams"
            ],
            "Other": [
                "DevOps",
                "Cloud"
            ],
            "FrSoftSkills": [
                "Communication",
                "Collaboration"
            ],
            "EnSoftSkils": [
                "Communication",
                "Collaboration"
            ]
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "title": "Cloud Engineer",
        "company": "Equativ",
        "location": "Paris, \u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/cloud-engineer-at-equativ-3804563418?position=9&pageNum=7&refId=AufKBH3ju6SkIv6PYkccnA%3D%3D&trackingId=qvMMd6o0PeHkY%2BStgG0sug%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "\ud83d\udc6b About the team\nAt Equativ, we\u2019re on a mission to develop advertising technologies that empower our customers to reach their digital business goals. This means that we rely on massively scalable, widely distributed, highly available, and efficient software systems; the platform deals with over 3 millions requests per second managed by 3,000 servers.\nOur innovation team based in Paris, Nantes, Limoges, Krakow and Berlin is composed of 100+ straightforward and energetic engineers working in an Agile environment and ready to tackle the most complex technical challenges.\nYour mission \ud83d\udc47\nWithin infra BU you will join the Platform department that strives to develop and deploy self-serve tooling to empower our RnD team.\nOur platform is gradually moving to a hybrid cloud platform. You will be joining as the second member of our cloud platform team:\nYou will help deliver a smooth transition of our RnD team to a hybrid cloud architecture\nYou will be responsible for cloud governance and FinOps\nYou will provide help to our engineering teams in order to optimize costs of our GCP components\nWhat you will do \u270f\ufe0f\nAs a Cloud engineer in our new cloud platform team your missions will be to:\nDesign and develop self-serve tooling for our engineering teams to transition and maintain their workloads to the cloud\nDesign and instrumentalize Finops guidelines to manage the overall ROI of our cloud infrastructure\nHelp design and develop our cost management framework to help teams optimize their operational ROI\nPropagate best-practices and know-how on cloud services and architectural patterns\nImplement terraform modules to support our IAC approach on the cloud\nEvaluate the CO2 savings associated with optimizing our cloud infrastructure usage\nAbout You \ud83d\udc4b\nMaster degree in Computer science or similar field of study\n2+ years of System, Cloud or Software Engineering experience ideally in the web industry\nAutonomous and innovative mindset\nExperience in cloud governance (GCP preferred) for production projects and collaboration within a 5+ engineering team\nFluent with DevOps practices\nInterested in the impact of technical decisions on business (finops approach) and environmental outcomes\nWorking proficiency and communication skills in verbal and written English\nNice to have:\nExperience in one or more of the following topics: Finops, big data components for large datasets, Kubernetes administration\nExperience working with IaC (Terraform or other)\nExperience in software development (Go, Python or equivalent)\nHow you'll grow \ud83d\ude80\nWithin 1 month:\nYou'll be just finishing your onboarding\nYou'll probably have tackled a few small tasks with your peer\nWithin 4 months:\nYou'll be trusted to review budget increases from development teams\nYou'll be expected to propose small-scale optimisations on our cloud architecture\nWithin 9 months:\nYou'll be in contact with most of the tech leads operating on GCP\nYou'll be evolving our terraform architecture to deploy resources to the cloud\nYou\u2019ll start getting a grasp on the AdTech business\n\ud83d\udc4b About us\nEquativ is the new single name for Smart Adserver, DynAdmic, LiquidM and Nowtilus \u2014 four proven innovators in advertising technology. The vertically integrated company provides brand and privacy-safe solutions that empower its clients to achieve maximum impact while respecting the rights of consumers. The union combines client expertise and engineering excellence to serve the interests of both the supply- side and demand-side with equal professionalism and technical sophistication.\nHeadquartered in Paris and New York, Equativ operates globally with a team of more than 550 people in 20 offices. Equativ offers the market its own independent ad server, SSP, buyer tools, and media services to fulfill the promise of advertising technology. Learn more at Equativ.com.\nThe company is ranked on the Deloitte Technology Fast 500 EMEA and in the Financial Times\u2019 FT 1000: Europe\u2019s Fastest-Growing Companies.\nEquativ (formerly Smart AdServer) has been awarded the HappyIndex@Work label and is proud to be among the best companies in the ChooseMyCompany ranking, recognized for its flexible working environment.\nCome and lead the charge with us in building a transparent ecosystem based on quality!\nEquativ is an equal opportunity employer. Equal access to employment, services, and programs are available to everyone, regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity, or Veteran status. If you require reasonable accommodation throughout the application and/or interview process, please contact the recruitment team at ta-team@equativ.com\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "Scala",
                "R",
                "Go"
            ],
            "DataBase": [],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [],
            "MachineLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [],
            "DevTools": [
                "Git"
            ],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [
                "Kubernetes"
            ],
            "InfrastructureAsCode": [
                "Terraform"
            ],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [
                "Kubernetes"
            ],
            "Collaboration": [
                "Teams"
            ],
            "Other": [
                "DevOps",
                "Big Data",
                "Cloud"
            ],
            "FrSoftSkills": [
                "Communication",
                "Collaboration"
            ],
            "EnSoftSkils": [
                "Communication",
                "Collaboration"
            ]
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "title": "Cloud Support Engineer (H/F)",
        "company": "Cloud Temple",
        "location": "Greater Tours Area",
        "link": "https://fr.linkedin.com/jobs/view/cloud-support-engineer-h-f-at-cloud-temple-3885141496?position=10&pageNum=7&refId=AufKBH3ju6SkIv6PYkccnA%3D%3D&trackingId=km58dk4iXVl8bgvfZut%2Ffw%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Afin de consolider notre \u00e9quipe Computing & Storage, Cloud Temple vous offre l'opportunit\u00e9 de nous rejoindre en tant que\nCloud Support Engineer .\nAu sein de l\u2019\u00e9quipe de Trusted Cloud Support, vous avez la charge du maintien en conditions op\u00e9rationnelles de nos infrastructures compute et virtualisation, h\u00e9berg\u00e9es dans notre cloud priv\u00e9, ainsi que de la prise en charge des tickets de supports escalad\u00e9s par nos clients (internes ou externes). Vous travaillez sur des infrastructures certifi\u00e9es (SecNumCloud, HDS) avec de fortes contraintes de s\u00e9curit\u00e9 et de disponibilit\u00e9. L\u2019\u00e9quipe est au premier rang des demandes et incidents, les activit\u00e9s y sont par cons\u00e9quent vari\u00e9es et permettent rapidement de prendre du contexte et de mettre en \u0153uvre des comp\u00e9tences acquises, ainsi que d\u2019en d\u00e9velopper de nouvelles.\nMISSIONS :\nEn tant que\nCloud Support Engineer\n(F/H), vos responsabilit\u00e9s seront :\nVous \u00eates charg\u00e9 du maintien et de l'\u00e9volution de nos infrastructures, ainsi que de la stabilit\u00e9 du service rendu au client.\nContribuer \u00e0 l\u2019automatisation en \u00e9tant force de proposition\nCommuniquer avec nos clients et partenaires de l\u2019\u00e9tat d\u2019avancement des sujets escalad\u00e9s\nParticiper \u00e0 la livraison des Professional Services\nMaintenir la conformit\u00e9 op\u00e9rationnelle et s\u00e9curitaire des services\nParticiper aux projets d\u2019\u00e9volution et de transformation des infrastructures et services\nAgr\u00e9menter et maintenir une base de connaissances techniques\nExigence du poste :\nNiveau de dipl\u00f4mes :\nBAC + 5\nComp\u00e9tences requises :\nConnaissance des outils Git, GitLab (CI/CD), Docker, Terraform, Ansible\nMaitrise des concepts de conteneurisation (Docker, K8S) (des connaissances en OpenShift seraient un plus)\nMaitrise des concepts ITIL\nConnaissance des produits Cisco et IBM Storage\nConnaissances avanc\u00e9es des r\u00e9seaux LAN et WAN (VLAN, BGP)\nConnaissance des environnements UNIX (FreeBSD, Linux, Solaris)\nMaitrise d\u2019au moins un langage de programmation : Python, Bash, PHP, Golang, JAVA\nConnaissance des produits de virtualisation VMware\nFacilit\u00e9s r\u00e9dactionnelles\nSens de la relation client\nConnaissances linguistiques :\nAnglais : lu, parl\u00e9 et \u00e9crit\nExp\u00e9rience attendue\n:\nAu moins 2 ans sur un poste similaire\nExp\u00e9rience en administration d\u2019infrastructure diverses (une certification VMware serait un plus)\nConnaissance des diff\u00e9rentes architectures de stockage (SAN / vSAN)\nCapacit\u00e9 \u00e0 automatiser des actions op\u00e9rationnelles (scripts, dev)\nComp\u00e9tences sur les solutions de supervision des services et leurs performances\nSavoir \u00eatre attendus\nPassionn\u00e9 par les infrastructures et le cloud (priv\u00e9 et/ou public)\nSens de la qualit\u00e9 de service\nCapacit\u00e9 d\u2019adaptation et d\u2019automatisation dans un environnement en perp\u00e9tuelle \u00e9volution\nExcellentes comp\u00e9tences organisationnelles\nCapacit\u00e9 \u00e0 g\u00e9rer les situations de crise\nTravail en \u00e9quipe\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "Java",
                "Scala",
                "R",
                "Go",
                "Bash"
            ],
            "DataBase": [],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [],
            "MachineLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [],
            "DevTools": [
                "Git",
                "Docker"
            ],
            "Os": [
                "Linux"
            ],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [
                "Ansible"
            ],
            "InfrastructureAsCode": [
                "Terraform"
            ],
            "NetworkSecurty": [],
            "Virtualisation": [
                "VMware"
            ],
            "Containers": [
                "Docker",
                "OpenShift"
            ],
            "Collaboration": [],
            "Other": [
                "Cloud",
                "CI/CD"
            ],
            "FrSoftSkills": [
                "Organisation"
            ],
            "EnSoftSkils": []
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s",
                "2",
                "2",
                "2"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "title": "Solutions Engineer - France",
        "company": "Wiz",
        "location": "France",
        "link": "https://fr.linkedin.com/jobs/view/solutions-engineer-france-at-wiz-3867238861?position=1&pageNum=10&refId=bCEBNf%2BPt4%2BZw9jTJ1Np%2Fw%3D%3D&trackingId=LtwQaITDjiQQOwGf3H4%2BYQ%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Come join the company that is reinventing cloud security and empowering businesses to thrive in the cloud. As the fastest-growing startup ever, Wiz is on a mission to help organizations secure cloud environments that will accelerate their businesses. Trusted by security teams all over the world, we have a proven track record of success and a culture that values world-class talent.\nOur Wizards from over 13 countries work together to protect the infrastructure of our hundreds of customers, including over 40% of the Fortune 100, who trust us to scan and secure over 230 billion files daily. We\u2019re the leading player in a massive and growing market, but it\u2019s still early enough for you to make a significant impact. At Wiz, you\u2019ll have the freedom to think creatively, dream big, and use your full range of skills to contribute to our record growth. Come join our team and help us create secure cloud environments that allow the best companies to move faster.\nSummary\nAs a\nSolutions Engineer\n, you will be responsible for supporting our enterprise customers, reporting to the regional\nManager,\nSolutions Engineering\n. You will partner directly with regional account executives to help change our customers view and how they approach cloud security. You will be their trusted advisor for all matters related to cloud security across AWS, Azure, and GCP. We are passionate about technical sales and helping our customers achieve the maximum value from our solution.\nWhat You\u2019ll Do\nPartner with the sales team to provide technical leadership to our customers and prospective customers in conjunction with helping our team meet their quarterly sales targets.\nProvide presentations to our customers and prospective customers such as whiteboards, product demonstrations, slides, and proof of value outcomes.\nHelp our customers and prospective customers plan in-depth test plans for showing the value of the Wiz platform in their environment (proof of value).\nInvest time in learning new product features, industry related developments, and broadening your overall technical skillset.\nRepresent Wiz in technical forums such as trade shows, technical meet-ups, and industry events.\nWhat You\u2019ll Bring\nAbility to deliver world class demonstrations and training experience to our channel customers\nMastered the technical sales process\nThrive in a creative technical role assisting partners to build a technical business delivery model\nExperience in a sales engineering role delivering solutions to C-level executives at enterprise customers\nAbility to travel up to 50%\nCloud security experience\nAWS/Azure/GCP hands on experience\nNetwork engineering experience\nStrong operating system, virtual machine, and container knowledge\nKnowledge of risk-based security assessments and frameworks\nUnderstanding of cloud identity, access, certificates, and keys\nBONUS POINTS:\nExperience with traditional CSPM tools\nSaaS experience\nAwareness of the CI/CD process\nFamiliarity with Infrastructure as Code\nIf your experience is close but doesn\u2019t fulfill all requirements, please apply. Wiz is on a mission to build a special company. To achieve our goal, we are focused on hiring Wizards with different backgrounds, perspectives, and experiences.\nWiz is an equal opportunity employer. We do not discriminate based upon race, religion, color, national origin, sex (including pregnancy, childbirth, reproductive health decisions, or related medical conditions), sexual orientation, gender identity, gender expression, age, status as a protected veteran, status as an individual with a disability, genetic information, political views or activity, or other applicable legally protected characteristics. We also consider qualified applicants with criminal histories, consistent with applicable federal, state and local law.\nBy submitting your application, you acknowledge that Wiz will process your personal data in accordance with Wiz's Privacy Policy.\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "R",
                "Go"
            ],
            "DataBase": [],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [],
            "MachineLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [
                "AWS",
                "Azure"
            ],
            "DevTools": [],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [
                "Teams"
            ],
            "Other": [
                "Cloud",
                "CI/CD"
            ],
            "FrSoftSkills": [
                "Leadership"
            ],
            "EnSoftSkils": [
                "Leadership",
                "Organization"
            ]
        },
        "details": {
            "JobDetail": [
                "Full"
            ],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "title": "Devops Engineer MAHIN-JOB-34202",
        "company": "Keylent Inc",
        "location": "Us, \u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/devops-engineer-mahin-job-34202-at-keylent-inc-3916719541?position=2&pageNum=10&refId=bCEBNf%2BPt4%2BZw9jTJ1Np%2Fw%3D%3D&trackingId=KkEPgODRknR9CXuMYnVHAg%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Devops Engineer MAHIN-JOB-34202\nLocation: PHONEIX\nDeveloper experience in python, Ansible and pipeline construction Bash scripting Mid Level Python scripting Mid level Ci/CD experience required Terraform Mid level Packer Mid Level Vault Good to have AWS Experience Low Mid Level Azure Experience Low Mid Level\nResponsibilities\nDevelop and maintain automation scripts using Bash and Python to streamline deployment, configuration, and monitoring processes.\nDesign, implement, and manage CI/CD pipelines to enable continuous integration and delivery of software applications.\nCollaborate with development teams to ensure applications are designed for scalability, reliability, and performance.\nConfigure and manage cloud infrastructure on AWS or Azure, including EC2 instances, S3 buckets, VPCs, and more.\nMonitor system performance and troubleshoot issues, ensuring high availability and uptime for critical services.\nImplement security best practices and compliance standards across the infrastructure.\nParticipate in on-call rotations and respond to incidents in a timely manner.\nContinuously evaluate and implement new tools and technologies to improve efficiency and effectiveness.\nRequirements\nBachelor's degree in Computer Science, Engineering, or related field.\n3+ years of experience as a DevOps Engineer or similar role.\nProficiency in Bash scripting and Python scripting.\nHands-on experience with cloud platforms such as AWS or Azure.\nStrong understanding of CI/CD concepts and experience with tools like Jenkins, GitLab CI, or CircleCI.\nExperience with configuration management tools such as Ansible, Puppet, or Chef.\nFamiliarity with containerization technologies like Docker and orchestration tools like Kubernetes.\nExcellent problem-solving and communication skills.\nAbility to work effectively in a fast-paced, dynamic environment.\nPreferred Qualifications\nAWS or Azure certification (e.g., AWS Certified DevOps Engineer, Azure DevOps Engineer Expert).\nExperience with infrastructure as code tools such as Terraform or CloudFormation.\nKnowledge of monitoring and logging tools such as Prometheus, Grafana, ELK stack, or Splunk.\nUnderstanding of networking concepts and protocols.\nFamiliarity with Agile and DevOps methodologies.\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "Scala",
                "R",
                "Go",
                "Bash"
            ],
            "DataBase": [],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [],
            "MachineLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [
                "AWS",
                "Azure"
            ],
            "DevTools": [
                "Git",
                "Docker",
                "Jenkins"
            ],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [
                "Ansible",
                "Kubernetes",
                "Puppet",
                "Chef"
            ],
            "InfrastructureAsCode": [
                "Terraform",
                "CloudFormation"
            ],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [
                "Docker",
                "Kubernetes"
            ],
            "Collaboration": [
                "Teams"
            ],
            "Other": [
                "DevOps",
                "ML",
                "Cloud",
                "CI/CD"
            ],
            "FrSoftSkills": [
                "Communication"
            ],
            "EnSoftSkils": [
                "Communication"
            ]
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "title": "Data Engineer Cloud (F/H)",
        "company": "Apside",
        "location": "\u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/data-engineer-cloud-f-h-at-apside-3904088503?position=3&pageNum=10&refId=bCEBNf%2BPt4%2BZw9jTJ1Np%2Fw%3D%3D&trackingId=PtEgsBicH27fRvN6lxaa9g%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "\ud83d\udca5\nD\u00e9couvrez la Vie Apsidienne\n\ud83d\udcf9\net vous aussi, devenez Apsidien\nOn aurait pu demander \u00e0 Chat GPT de vous d\u00e9montrer en quoi\nApside est l\u2019ESN qu\u2019il vous faut,\nmais on pr\u00e9f\u00e8re que vous le d\u00e9couvriez vous-m\u00eames \ud83d\udc47\ud83d\ude0f\n\ud83d\udd25\nD\u00e9couvrez votre future mission\n\ud83d\udc49\nContexte\nRejoignez notre Practise Cloud/Data, afin d\u2019intervenir sur des sujets \u00e0 haute valeur ajout\u00e9e !\nNotre\nclient migre actuellement toutes ses applications vers le cloud AWS.\nDe plus, dans le cadre du d\u00e9veloppement d'un produit de restitution automatis\u00e9e de donn\u00e9es, ils recherchent actuellement d\u00e9veloppeur data ayant d\u00e9j\u00e0 travaill\u00e9 sur un projet similaire. La solution produit est techniquement con\u00e7ue en lien avec le Tech Lead validant l'architecture logicielle \u00e0 mettre en place sur le cloud AWS.\nSecteur\n: culture/m\u00e9dia\nM\u00e9thode de travail\n: Agile Safe\n\ud83d\ude0e Mission\nCapter les donn\u00e9es (structur\u00e9es et non structur\u00e9es) produites dans les diff\u00e9rentes applications\nInt\u00e9grer les \u00e9l\u00e9ments\nStructurer la donn\u00e9e (s\u00e9mantique, etc\u2026)\nCartographier les \u00e9l\u00e9ments \u00e0 disposition\nNettoyer la donn\u00e9e (\u00e9limination des doublons, etc\u2026)\nValider la donn\u00e9e\nCr\u00e9er les r\u00e9f\u00e9rentiels de donn\u00e9es\nEnvironnement technique\n:\nPython\nLambda\nStep Function\nAWS / AWS RDS\nPostegreSQL\nSnowflake\nSpark\n\ud83d\udccd\nLocalisation\nLa D\u00e9fense\n\ud83d\udcb0\nLe package salarial que nous vous proposons\nContrat :\nCDI\nAvantages groupe :\ncarte ticket restaurant Swile, prime de mobilit\u00e9, RTT, accord t\u00e9l\u00e9travail, Mutuelle, prime de cooptation, avantages CE, prise en charge de la mutuelle \u00e0 100% etc\u2026\nAvantages agence :\nCommunaut\u00e9 Cloud/Data, afterworks, communaut\u00e9 techlead\nFormation :\ncertifications techniques, cours particuliers d\u2019anglais en interne, acc\u00e8s \u00e0 un catalogue de formations gr\u00e2ce \u00e0 notre plateforme e-learning (\nAcademy by Apside\n) ou via nos organismes partenaires.\n\ud83d\udd2e\n\u00d4 vous futur Apsidien, qui \u00eates-vous ?\nAu moins 4 ans d'exp\u00e9rience en tant que Data Engineer\nMaitrise de l\u2019environnement cloud AWS\nForce de proposition, bon relationnel et autonome\n\ud83d\ude0f\nApside a suscit\u00e9 votre curiosit\u00e9 ?\nDans un environnement marqu\u00e9 par une acc\u00e9l\u00e9ration des \u00e9volutions technologiques, de transformations des usages et de disruptions majeures, Apside est un partenaire de confiance qui accompagne ses clients \u00e0 cr\u00e9er de la valeur et \u00e0 adresser leurs enjeux strat\u00e9giques en leur mettant \u00e0 disposition des expertises technologiques (\nData / IA, Cloud, Cyber\n) et une exp\u00e9rience sectorielle (\nIndustrie, Banque, Assurance, Service, Secteur Public\n). Pour un accompagnement global, le groupe propose des offres transverses autour du\nHandicap\n(Apsid\u2019EA), du\nDigital Learning\n, et du\nConseil\n.\n\ud83e\udd14\nEt votre place dans tout \u00e7a ?\n\ud83d\udc49 Notre volont\u00e9\nest de vous accompagner dans la construction et l\u2019\u00e9panouissement de votre carri\u00e8re\nen nous appuyant notamment\nsur 3 piliers :\nUne\nr\u00e9mun\u00e9ration\n\u00e0 hauteur de vos investissements et de vos comp\u00e9tences\nUne\ntrajectoire professionnelle\nstimulante sur mesure\nUn\nengagement\nautour des valeurs Apsidiennes : la qualit\u00e9 de vie et des conditions de travail au c\u0153ur de nos enjeux\nEngag\u00e9e pour\nun monde plus inclusif et plus responsable\n, Apside r\u00e9invente l\u2019ESN et propose l\u2019Engagement Soci\u00e9tal et Num\u00e9rique. D\u00e9couvrez notre d\u00e9marche RSE ainsi que notre vision de l\u2019Entreprise Engag\u00e9e.\nConvaincu ? A vous de jouer, envoyez-nous votre CV !\nRejoignez l\u2019aventure Apsidienne et d\u00e9couvrez notre vision d\u2019une ESN singuli\u00e8re et r\u00e9siliente\n\ud83d\ude80\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "R"
            ],
            "DataBase": [
                "SQL"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [
                "Spark"
            ],
            "MachineLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [
                "AWS"
            ],
            "DevTools": [
                "Git"
            ],
            "Os": [],
            "DBMS": [
                "Snowflake",
                "Snowflake"
            ],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [
                "Cloud"
            ],
            "FrSoftSkills": [],
            "EnSoftSkils": []
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [
                "CDI"
            ],
            "Salary": [
                "100"
            ],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s",
                "4",
                "4",
                "4"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "title": "Big Data Engineer Databricks Senior - H/F - CDI",
        "company": "Talan",
        "location": "Paris, \u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/big-data-engineer-databricks-senior-h-f-cdi-at-talan-3909664424?position=4&pageNum=10&refId=bCEBNf%2BPt4%2BZw9jTJ1Np%2Fw%3D%3D&trackingId=rBvicrMXCThyKq9glOYCNA%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Talan est un groupe international de conseil en transformation et en innovation par la technologie, cr\u00e9\u00e9 en 2002.\nNos 5000 consultantes et consultants partagent \u00e0 travers le monde l\u2019audace d\u2019innover, le go\u00fbt de l\u2019excellence, et l\u2019envie de relever les d\u00e9fis les plus complexes.\nNous accompagnons les entreprises dans des secteurs vari\u00e9s\u202f: \u00e9nergie, industrie, transport, finance, luxe\u2026 \u00e0 travers 3 grandes expertises\u202f:\nLe Conseil en Management et Innovation (320 Consultants en France)\nLa valorisation des donn\u00e9es, leurs structurations, et leurs usages (Data et Technologies)\nL\u2019int\u00e9gration de solutions logicielles (Cloud et Applications Services)\nNos valeurs\u202f: engagement, respect, partage, esprit d\u2019\u00e9quipe et optimisme.\nTalan est une entreprise responsable, reconnue par ses collaborateurs et attach\u00e9e \u00e0 la diversit\u00e9. Des am\u00e9nagements peuvent \u00eatre propos\u00e9s si vous \u00eates en situation de handicap.\nRetrouvez nos engagements RSEiciet nos actions en faveur de la diversit\u00e9ici\nJob Description\nNous sommes \u00e0 la recherche d\u2019un Big Data Engineer Databricks S\u00e9nior qui sera en charge de l\u2019int\u00e9gration des donn\u00e9es: acquisition, pr\u00e9paration, mod\u00e9lisation et stockage, exposition, . Vous devrez faire preuve d\u2019un \u00e9tat d\u2019esprit \u00e0 la fois innovant, m\u00e9thodique, orient\u00e9 solution (et non probl\u00e8me!), et communiquant.\nResponsabilit\u00e9s\nManager des Big Data Engineer et Cloud Engineer\nCoacher techniquement les membres de l\u2019\u00e9quipe: solution et code review sur site, recommandation sur les formations \u00e0 suivre, certifications \u00e0 r\u00e9aliser, \u2026\nAnalyse des besoins techniques m\u00e9tiers, d\u00e9finition de l\u2019architecture solution et logiciel, r\u00e9f\u00e9rent technique, d\u00e9veloppement et optimisation, code review, maintenir les pratiques Devops \u201cYou build IT, You run IT\u201d, support \u00e0 recette et mise en production, documentation, et parfois assumer le r\u00f4le de Scrum Master,\u2026\nBenchmark de solutions et conseil aupr\u00e8s de notre client sur les solutions technologiques \u00e0 adopter, en lien avec leurs besoins\nPartage de connaissances et formations interne\nQualifications\nIssu(e) d\u2019une formation sup\u00e9rieure (\u00e9cole d\u2019ing\u00e9nieur, master,\u2026)\nVous disposez d\u2019au moins 4 ann\u00e9es d\u2019exp\u00e9rience dans le domaine du Big Data (et particuli\u00e8rement sur le framework Spark), et au moins 6 ann\u00e9es d\u2019exp\u00e9rience dans le d\u00e9veloppement logiciel\nVous ma\u00eetrisez led\u00e9veloppement logiciel (Scala, Python \u2026), et vous disposez de solides exp\u00e9riences dans la mise en place de pipelines de donn\u00e9es\nVous ma\u00eetrisez leFramework Spark (id\u00e9alement sur Databricks) etson optimisation\nExp\u00e9rience sur une plateforme Cloud serait un plus et id\u00e9alement AWS\nExp\u00e9rience sur des flux temps r\u00e9elserait un plus : Kafka + Spark Streaming\nVous ma\u00eetrisez les bases de donn\u00e9es SQL et le langage SQL\nVous avez de l'exp\u00e9rience sur les m\u00e9thodes de stockage: HDFS, S3,,\u2026\nVous avez de bonnes connaissances en devOps : Jenkins, Gitlab, Maven, \u2026\nLa connaissance des concepts suivants serait un +: DataOps, DataVault, DataMesh..\nConnaissance de l\u2019Agilit\u00e9\nAutonome\nOrganis\u00e9(e)\nSens du partage\nBonne communication\nOrientation produit et solution\nAdditional Information\nAVANTAGES\n:\nPlan de formation pour accompagner votre carri\u00e8re (formations \u00e9diteurs, certifications) gr\u00e2ce \u00e0 nos partenariats nous accordant une position de partenaire privil\u00e9gi\u00e9, et management de proximit\u00e9 par des experts\nLocaux modernes en centre-ville\nTop 5 du Palmar\u00e8s Great Place to Work\nT\u00e9l\u00e9travail jusqu\u2019\u00e0 5 jours selon les missions, prime d\u2019\u00e9quipement de 100\u20ac\nMobilit\u00e9 en France et \u00e0 l\u2019\u00e9tranger\nTop 1% des entreprises \u00e9valu\u00e9es par Ecovadis dans le domaine social, environnemental et \u00e9thique\nTickets restaurant, prime vacances, 50% transport (abonnement transport public), mutuelle\nPermanence handicap (consultant d\u00e9di\u00e9 aux collaborateurs en situation de handicap et aux proches aidants)\nActionnariat salari\u00e9\nPrime de cooptations\nRTT\nPROCESS RECRUTEMENT\n:\nL\u2019\u00e9quipe recrutement s\u2019engage \u00e0 vous proposer un processus de recrutement rapide et fluide\n1 entretien RHpar Teams (45min)\n1 test technique\n1 entretien technique par Teams (1heure)\n1 entretien op\u00e9rationnel avec le responsable de domaine, au si\u00e8ge (1heure)\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "Scala",
                "R",
                "Go"
            ],
            "DataBase": [
                "SQL"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [
                "Spark",
                "Databricks"
            ],
            "MachineLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [
                "AWS"
            ],
            "DevTools": [
                "Git",
                "Jenkins"
            ],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [
                "Teams"
            ],
            "Other": [
                "DevOps",
                "Big Data",
                "Cloud"
            ],
            "FrSoftSkills": [
                "Communication"
            ],
            "EnSoftSkils": [
                "Communication"
            ]
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "title": "DevOps Engineer Block Storage",
        "company": "Scaleway",
        "location": "Lille, Hauts-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/devops-engineer-block-storage-at-scaleway-3880178183?position=5&pageNum=10&refId=bCEBNf%2BPt4%2BZw9jTJ1Np%2Fw%3D%3D&trackingId=LXvjALiiufQ6F5K2iaS%2BZA%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "About The Job\nThe Storage Team is one of the pillars of Scaleway. This team not only develops the Scaleway Elements storage products (Block Storage), but also supports all the other Scaleway Elements products that rely on Block Storage (Instances, Database, Registry, Kubernetes, and more) for proper usage. In a challenging environment, and within a team that manages hundreds of storage servers across various regions, you will be responsible for developing, automating, and enhancing Scaleway\u2019s Block Storage solution.\nThis service launched by Scaleway offers resilient, redundant, and high-availability storage for its numerous clients. Your missions will require programming, automation, and architecture skills. On top of your daily activities within your team, you will need to interact with all of Scaleway\u2019s teams, especially Instances, Network, Hardware, and Platform.\nMinimum Qualifications\nExperienced System Engineer who is passionate about DevOps best practices and cloud architecture, ideally with over 5 years of experience\nExperience with (and love for) storage systems\nStrong system-level programming skills\nGood understanding of Golang\nExperience with a continuous integration workflow, Gitlab, and Git\nStrong Linux knowledge\nDistributed systems (and debugging them)\nResponsibilities\nDeploying infrastructure in new Availability Zones\nImproving & bringing forward new ideas for our current infrastructure\nReacting to eventual failures in collaboration with other teams\nPresenting your work during tech meetings\nCoding, peer review, and deployment\nCustomer support in relation to your product\nDeploying your code\nPreferred Qualifications\nSolid experience with Ceph in high capacity and/or performance environment\nGreat oral and written communication skills\nInfrastructure deployment with Ansible\nVery good command of English\nTechnical Stack\nCeph\nUbuntu/Debian\nAnsible\nGolang\nProtobuf\nPostgresql\nLocation\nThis position is based in our offices in Paris or Lille (France)\nRecruitment Process\nScreening call - 30 mins with the recruiter\nManager Interview - 45 mins\nTechnical Interviews\nHR Interview - 45 mins\nHead of Interview - 45 mins\nOffer sent\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "R",
                "Go"
            ],
            "DataBase": [
                "SQL"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [],
            "MachineLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [],
            "DevTools": [
                "Git"
            ],
            "Os": [
                "Linux"
            ],
            "DBMS": [
                "PostgreSQL"
            ],
            "SoftBigDataProcessing": [],
            "Automation": [
                "Ansible",
                "Kubernetes"
            ],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [
                "Kubernetes"
            ],
            "Collaboration": [
                "Teams"
            ],
            "Other": [
                "DevOps",
                "Cloud"
            ],
            "FrSoftSkills": [
                "Communication",
                "Collaboration"
            ],
            "EnSoftSkils": [
                "Communication",
                "Collaboration"
            ]
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "title": "DevOps Engineer",
        "company": "Diverse Lynx",
        "location": "Us, \u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/devops-engineer-at-diverse-lynx-3869451140?position=6&pageNum=10&refId=bCEBNf%2BPt4%2BZw9jTJ1Np%2Fw%3D%3D&trackingId=wnXdcMQqAVjbbsqe7uECjg%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "8+ years of Very Strong with GitHub/Gitlab and deep understanding with Ansible.\nProficiency with any CI|CD tool example Jenkins, GitHub runners\nProficiency with developing pipelines\nGood understanding of Docker & Containerized applications\nGood knowledge on writing YAML\nOnsite Offshore Coordination\nOrganizing kick-offs for migrations of applications from On-Prem to Cloud (AZURE/AWS)\nAbility to follow standardized steps for migration factory\nAbility to work under pressure\nAbility to work well effectively with team-members with effective interpersonal, verbal and written communication skills\nDiverse Lynx LLC is an Equal Employment Opportunity employer. All qualified applicants will receive due consideration for employment without any discrimination. All applicants will be evaluated solely on the basis of their ability, competence and their proven capability to perform the functions outlined in the corresponding role. We promote and support a diverse workforce across all levels in the company.\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "R",
                "Go"
            ],
            "DataBase": [],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [],
            "MachineLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [
                "AWS",
                "Azure"
            ],
            "DevTools": [
                "Git",
                "Docker",
                "Jenkins"
            ],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [
                "Ansible"
            ],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [
                "Docker"
            ],
            "Collaboration": [],
            "Other": [
                "ML",
                "Cloud"
            ],
            "FrSoftSkills": [
                "Communication"
            ],
            "EnSoftSkils": [
                "Communication"
            ]
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "title": "Devops / Software Engineer",
        "company": "iPepperGroup",
        "location": "Valbonne, Provence-Alpes-C\u00f4te d'Azur, France",
        "link": "https://fr.linkedin.com/jobs/view/devops-software-engineer-at-ipeppergroup-3907530533?position=7&pageNum=10&refId=bCEBNf%2BPt4%2BZw9jTJ1Np%2Fw%3D%3D&trackingId=gQTYSvSamEgmw0m1aFv0XQ%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Nous sommes le partenaire technologique pr\u00e9f\u00e9r\u00e9 de ceux qui changent le monde !\niPepper c'est avant tout une fa\u00e7on de travailler ensemble : se faire du bien, faire du bien et prendre soin de ses clients, salari\u00e9s et partenaires !\nConsulting, Recrutement et Projets : une palette de services autour de la protection et la valorisation de la data.\nLe Poste\nNous recherchons pour l'un de nos clients un ing\u00e9nieur DevOps / Software Engineer (H/F) exp\u00e9riment\u00e9(e) et \u00e0 l'aise en anglais pour rejoindre notre \u00e9quipe dynamique et anglophone \u00e0 Sophia Antipolis.\nPossibilit\u00e9 de contrat : CDI / Portage salariale ou freelance.\nT\u00e9l\u00e9travail : 2 \u00e0 3 jours par semaine.\nMission longue.\nProjet\nLa mission combine \u00e0 la fois des aspects de DevOps et de d\u00e9veloppement logiciel.\nLe d\u00e9fi de l'ann\u00e9e \u00e0 venir consiste \u00e0 migrer les outils internes de l'h\u00e9bergement h\u00e9rit\u00e9 vers le Cloud Azure tout en adoptant les meilleures pratiques. En parall\u00e8le, faire \u00e9voluer un portail Django/React.\nLes autres outils utilis\u00e9s par l'\u00e9quipe sont en Java / Springboot / Angular.\nComme l'\u00e9quipe est relativement petite, le travail est organis\u00e9 selon une m\u00e9thodologie similaire \u00e0 Scrum avec un backlog Jira.\nLa mission principale est de construire une plateforme de bout en bout avec un environnement de premier ordre pour :\nAm\u00e9liorer la productivit\u00e9 des d\u00e9veloppeurs gr\u00e2ce \u00e0 des capacit\u00e9s d'int\u00e9gration et de d\u00e9ploiement automatis\u00e9es.\nD\u00e9velopper, innover et maintenir des plateformes technologiques qui atteignent une agilit\u00e9, une stabilit\u00e9 et des performances \u00e9lev\u00e9es.\nEnvisager, acc\u00e9l\u00e9rer les nouvelles versions et fournir des conseils sur la mani\u00e8re d'am\u00e9liorer les performances op\u00e9rationnelles.\nProfil\nQualifications requises :\nExp\u00e9rience significative en tant qu'Ing\u00e9nieur DevOps ou D\u00e9veloppeur Logiciel. (minimum 5 ans)\nSolides comp\u00e9tences en int\u00e9gration et d\u00e9ploiement continu.\nMa\u00eetrise des technologies de d\u00e9veloppement web, y compris Django, React, Java, Springboot et Angular.\nCapacit\u00e9 \u00e0 travailler dans un environnement agile et \u00e0 s'adapter rapidement aux changements.\nBonnes comp\u00e9tences en communication et capacit\u00e9 \u00e0 travailler efficacement en \u00e9quipe.\nAnglais courant obligatoire (conversation quotidienne en anglais / \u00e9quipe anglophone)\nSi vous \u00eates passionn\u00e9(e) par l'innovation technologique, que vous recherchez un environnement stimulant et que vous souhaitez contribuer au succ\u00e8s d'une \u00e9quipe dynamique, alors ce poste est fait pour vous !\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Java",
                "R",
                "Go"
            ],
            "DataBase": [],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [],
            "MachineLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [
                "Azure"
            ],
            "DevTools": [],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [
                "JIRA"
            ],
            "Other": [
                "DevOps",
                "Cloud"
            ],
            "FrSoftSkills": [
                "Communication"
            ],
            "EnSoftSkils": [
                "Communication"
            ]
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [
                "CDI"
            ],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s",
                "5",
                "5",
                "5"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "title": "Cloud Engineer / DevOps (F/H) - Nantes",
        "company": "SFEIR",
        "location": "Nantes, Pays de la Loire, France",
        "link": "https://fr.linkedin.com/jobs/view/cloud-engineer-devops-f-h-nantes-at-sfeir-3477973777?position=8&pageNum=10&refId=bCEBNf%2BPt4%2BZw9jTJ1Np%2Fw%3D%3D&trackingId=dLYGil6ucWg8fGmzjDyTpw%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "C'est quoi SFEIR ? \ud83e\udd14\nSFEIR, c'est avant tout une communaut\u00e9 de 900 techs en France, en Belgique et au Luxembourg.\nNous aidons nos clients \u00e0 :\n\ud83d\udd39 \u00catre compatible avec le futur en d\u00e9veloppant leurs architectures SI, Cloud et Data ;\n\ud83d\udd39 Donner de la valeur \u00e0 leurs donn\u00e9es, innover avec l'IA ;\n\ud83d\udd39Cr\u00e9ateur de valeur gr\u00e2ce aux API & microservices;\n\ud83d\udd39 D\u00e9velopper des applications web et mobiles pour am\u00e9liorer leur exp\u00e9rience client et se connecter partout.\nNotre culture d'entreprise est r\u00e9solument tourn\u00e9e vers l'expertise technologique, la transmission de connaissances et le respect de nos valeurs phares :\nbienveillance, inclusivit\u00e9, excellence, libert\u00e9, responsabilit\u00e9.\nEt Nantes dans tout \u00e7a ?\nSFEIR Nantes c'est :\n\ud83d\udd39 Une agence cr\u00e9e en 2018 par @Jean-Fran\u00e7ois Garreau , co-fondateur du DevFest Nantes\n\ud83d\udd39 Une trentaine de consultant(e)s qui se connaissent toutes et tous\n\ud83d\udd39 4 Managers qui sont aussi des consultants @Hoani , @Adrien , @Fr\u00e9d\u00e9ric , @Valentin\n\ud83d\udd39 Une dizaine de clients actifs en local et une centaine au niveau du groupe\n\ud83d\udd39 Des \u00e9v\u00e9nements en interne et en organis\u00e9s chaque mois (afterworks, meetup, formations)\n\ud83d\udd39 Une communaut\u00e9 active : une cinquantaine de conf\u00e9rences externes donn\u00e9es en 2022 (Devfest, Devoxx, communaut\u00e9 JS\u2026)\n\ud83d\udd39 Des locaux sur l'\u00eele de Nantes dans le b\u00e2timent totem du num\u00e9rique nantais.\nConcr\u00e8tement, quel sera mon job ?\nEn mission pour un client, ton r\u00f4le est d\u2019introduire des processus, des outils et des m\u00e9thodes pour \u00e9quilibrer les besoins tout au long du cycle de d\u00e9veloppement de logiciels, du codage et du d\u00e9ploiement, jusqu'\u00e0 la maintenance et \u00e0 la mise \u00e0 jour.\nTu es en charge du d\u00e9ploiement, du stockage, de la gestion et de la migration des donn\u00e9es sur des solutions Cloud (\nGCP, AWS, Azure\n\u2026).\n@Arthur et @Paul-Antoine , nos super commerciaux, seront \u00e0 ton \u00e9coute pour d\u00e9finir avec toi ta mission id\u00e9ale et tu pourras en changer lorsque tu en auras fait le tour.\nVoici des exemples de projets r\u00e9alis\u00e9s par des sfeiriens pour te donner une id\u00e9e :\n\ud83d\udd39\nGuillaume\na int\u00e9gr\u00e9 l\u2019\u00e9quipe SRE d\u2019un \u00e9diteur de logiciel. Son r\u00f4le est d\u2019assurer et d'am\u00e9liorer la fiabilit\u00e9 de l'infrastructure. Il automatise et industrialise des op\u00e9rations sur l'infrastructure et am\u00e9liore le monitoring de la plateforme.\n\ud83d\udd39\nJulien\nr\u00e9alise un projet dans l\u2019univers du luxe, de mise en place de fondations Cloud pour h\u00e9berger la future plateforme Data en utilisant des outils tel que Terraform et Cloud Build\nEt si je souhaite \u00e9voluer?\nNous proposons des possibilit\u00e9s d'\u00e9volution verticales et horizontales. Nous pourrons t'accompagner pour te certifier ou \u00e9valuer sur une autre sp\u00e9cialit\u00e9, ou encore devenir\nLead Tech\nou\narchitecte.\nTu auras \u00e9galement la possibilit\u00e9 de prendre des r\u00f4les en interne si tu le souhaites :\n\ud83d\udd39\n\u00c9valuateur(trice)\ndans le processus de recrutement\n\ud83d\udd39\nFormateur(trice)\naux Sfeir Schools ou au Sfeir Institute\n\ud83d\udd39\nSpeaker(euse)\nlors de conf\u00e9rences, meetups, talks internes, aupr\u00e8s des \u00e9coles\n\ud83d\udd39\nEngineering manager\nsi tu veux manager une \u00e9quipe tout en restant dans la technique\nEt si tu as d'autres envies, on en discute, chacun est diff\u00e9rent et on fait au cas par cas.\nJe suis int\u00e9ress\u00e9(e) \ud83d\ude42, comment vous rejoindre ?\nSi cette annonce a fourni ton attention, il ne te reste plus qu'\u00e0 postuler.\n@Justine se font un plaisir de t'en dire plus \ud83d\ude42. Tu pourras ensuite te frotter \u00e0 nos c\u00e9l\u00e8bres\nPlayOffs\n: 3 tests d'\u00e9valuation technique en pair-programming (algorithmie, langage, framework). Ne t'en fais pas, nos \u00e9valuateur(trice)s sont bienveillant(e)s !\nEnfin, tu \u00e9changeras avec Arthur et Paul-Antoine au commerce et Jean-Fran\u00e7ois et @Arnaud , nos directeurs.\nChez Sfeir, la confiance, la bonne humeur et l'inclusion font partie de notre ADN.\nEn rejoignant notre communaut\u00e9, tu deviendras un(e) Sfeirien(ne) bienveillant(e), libre et responsable.\n#L\u2019inclusionEstUneForce: Notre process de recrutement inclusif assure une \u00e9galit\u00e9 de traitement et de chance aux candidats de tous horizons.\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "R",
                "Go"
            ],
            "DataBase": [],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [],
            "MachineLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [
                "AWS",
                "Azure"
            ],
            "DevTools": [],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [
                "Terraform"
            ],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [
                "Cloud"
            ],
            "FrSoftSkills": [],
            "EnSoftSkils": []
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "title": "Software Integration Engineer",
        "company": "Quandela",
        "location": "Massy, \u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/software-integration-engineer-at-quandela-3759487196?position=9&pageNum=10&refId=bCEBNf%2BPt4%2BZw9jTJ1Np%2Fw%3D%3D&trackingId=3I8OY8dotTUg%2FmSA0J9MBw%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Quandela, a leader in the development and commercialization of Quantum Processing Units (QPU) based on the manipulation of single photons, is seeking a skilled and motivated Software Integration Engineer to join our team. As a Software Integration Engineer, you will play a crucial role in advancing our cutting-edge technology and contribute to shaping the future of quantum computing. At Quandela, we are committed to pushing the boundaries of what is possible in the world of quantum technology, and as a member of our team, you will have the opportunity to work on exciting and challenging projects that have the potential to revolutionize the field.\nResponsibilities\nParticipate in designing, developing and testing the software layers used to control and monitor the QPU\nCollaborate with a multidisciplinary team of engineers and scientists to integrate new features into the overall quantum computer architecture\nDeployment and control for system monitoring, diagnostics, and performance analysis\nParticipate in hardware and software testing procedures on QPUs or submodules\nWork closely with hardware engineers to develop hardware-software interfaces for efficient control and operation of quantum optical systems\nTroubleshoot and debug software issues that arise during integration and deployment\nDevelop and execute test plans to validate the performance and reliability of integrated systems\nRequirements\nProven experience in programming for hardware control\nStrong experience in Python, C++ optional but preferred\nKnowledge of Linux and Git required\nCurious and a fast learner\nExcellent problem-solving and analytical skills\nInterest in electronics, quantum optics and quantum computing\nStrong communication and collaboration abilities, with a proven track record of working effectively in a multidisciplinary team\nBenefits\nA diverse, dynamic, challenging, international team and environment.\nAll means necessary to carry-out high-impact projects\nStrong potential for fast career development within a rapidly growing company\nPart-time work-from-home\nEmployee profit-sharing scheme\nPrivate healthcare scheme\nMeal and transport subsidies\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "C++",
                "R"
            ],
            "DataBase": [],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [],
            "MachineLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [],
            "DevTools": [
                "Git"
            ],
            "Os": [
                "Linux"
            ],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [],
            "FrSoftSkills": [
                "Communication",
                "Collaboration"
            ],
            "EnSoftSkils": [
                "Communication",
                "Collaboration"
            ]
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "title": "Consultant\u00b7e Cloud Data Engineer GCP/Azure",
        "company": "Saegus",
        "location": "Paris, \u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/consultant%C2%B7e-cloud-data-engineer-gcp-azure-at-saegus-3769067736?position=10&pageNum=10&refId=bCEBNf%2BPt4%2BZw9jTJ1Np%2Fw%3D%3D&trackingId=RWYo0puums7LCzppOsY1KA%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Qui est Saegus ?\nSaegus est la\nConsulTech\nqui accompagne ses clients (grands groupes du CAC 40 / SBF 120) dans leur transition vers l'entreprise intelligente et responsable de demain, le\nSmart Shift\n.\nLe\nSmart Shift\nrepr\u00e9sente bien plus qu'une simple transition num\u00e9rique. C'est une vision strat\u00e9gique compl\u00e8te qui int\u00e8gre les technologies \u00e9mergentes, telles que l'intelligence artificielle et l'utilisation performante et raisonn\u00e9e de la Data, \u00e0 des changements culturels, organisationnels et de gouvernance.\nNous appliquons \u00e9galement l\u2019approche Smart Shift pour offrir \u00e0 nos consultants un environnement propice \u00e0 leur d\u00e9veloppement professionnel et \u00e0 leur \u00e9panouissement : The Best Place To Grow. Au-del\u00e0 de pouvoir vivre l'exp\u00e9rience d'un\nSmart Consultant\n(par l'IA), en rejoignant notre \u00e9quipe, vous b\u00e9n\u00e9ficierez d'une culture d'entreprise ax\u00e9e sur l'agilit\u00e9, l'innovation et l'adaptabilit\u00e9. Nous accompagnons nos Saegusien\u00b7ne\u00b7s \u00e0 d\u00e9velopper de nouvelles comp\u00e9tences, \u00e0 explorer les nouvelles technologies et \u00e0 cultiver un esprit entrepreneurial, le tout accompagn\u00e9 par une \u00e9cole du conseil (parcours de formation propre \u00e0 Saegus), un catalogue de formations et de certifications et un coach interne.\nSmart Shift. For Real.\nSaegus est incarn\u00e9 par ses\nquatre d\u00e9partements\n:\nShift Acceleration, pour acc\u00e9l\u00e9rer le passage d\u2019une id\u00e9e en un produit ou service au sein de grandes entreprises gr\u00e2ce \u00e0 des outils et m\u00e9thodologies agiles ;\nSmart Data, pour rendre compr\u00e9hensibles, exploitables et valorisables les donn\u00e9es des entreprises ;\nSmart Workplace, pour cr\u00e9er un environnement humain, physique et technologique optimal pour l\u2019ensemble des collaborateur\u00b7rice\u00b7s ;\nSmart Experience Factory, pour designer et d\u00e9velopper des applications sur-mesure gr\u00e2ce \u00e0 une m\u00e9thode centr\u00e9e utilisateurs.\nAinsi, nous recrutons un.e Consultant\u00b7e Cloud Data Engineer.\nConcr\u00e8tement, quelle sera la mission et les r\u00e9alisations attendues \u2753\nEn tant que\nConsultant\u00b7e Data Engineer\n, tu seras int\u00e9gr\u00e9\u00b7e \u00e0 l\u2019\u00e9quipe Smart Data dont la mission est d\u2019aider ses clients \u00e0 tirer profit des technologies les plus innovantes pour valoriser leurs donn\u00e9es. De l\u2019acquisition \u00e0 la restitution, tu interviens sur chaque \u00e9tape du processus d\u2019aide \u00e0 la d\u00e9cision.\nTu participeras aux missions de conseil et d\u2019expertise afin de contribuer \u00e0 l\u2019atteinte des objectifs majeurs de nos clients et contribueras \u00e0 la\nr\u00e9alisation de projets tels que\n:\n\u26a1\ufe0f Le design d\u2019une plateforme Azure Cloud et la mise en place de pipeline d\u2019ingestion et exposition de donn\u00e9es pour la mise \u00e0 disposition de donn\u00e9es m\u00e9tiers, rafra\u00eechies toutes les 30mn\n\u26a1\ufe0f La mise en place des bonnes pratiques et l\u2019initialisation du Datalab pour un grand groupe d\u2019assurance, et l\u2019accompagnement \u00e0 l\u2019industrialisation des algorithmes pour les usages m\u00e9tiers\n\u26a1\ufe0f L\u2019ensemble des traitements d\u2019ingestion et pr\u00e9paration des datasets afin d\u2019alimenter des Dashboard de monitoring de l\u2019activit\u00e9 digitale Worldwide d\u2019un grand groupe cosm\u00e9tique afin de mesurer l\u2019empreinte des marques sur les m\u00e9dias et r\u00e9seaux sociaux\n\u26a1\ufe0f L\u2019accompagnement \u00e0 la cr\u00e9ation et l\u2019activit\u00e9 d\u2019une Data Factory pour traiter l\u2019ensemble des donn\u00e9es d\u2019un grand groupe de distribution et mettre \u00e0 disposition des donn\u00e9es qualifi\u00e9es pour les diff\u00e9rents use cases m\u00e9tiers\nNous recherchons un.e passionn\u00e9.e poss\u00e9dant une envie de de f\u00e9d\u00e9rer et faire monter en valeur les consultants autour des th\u00e9matiques Data Engineering recouvrant la mise en place de Plateforme de donn\u00e9es, des bonnes pratiques de d\u00e9veloppements et des process DataOps, l\u2019industrialisation de pipeline de traitements de donn\u00e9es pouvant aller jusqu\u2019\u00e0 la Data Visualisation.\n\u279c Dans quel environnement ?\nEn fonction de tes missions et r\u00e9alisations projet, tu seras amen\u00e9\u00b7e \u00e0 int\u00e9grer des \u00e9quipes compos\u00e9es de Data Engineer, Data Scientist, Data Architects, organis\u00e9es en mode agile. Tes activit\u00e9s s\u2019appuieront sur les m\u00e9thodes et savoir-faire de Saegus et sur son catalogue d\u2019outils et technologies sur lesquels tu as une ma\u00eetrise sur plusieurs d\u2019entre eux :\n\u2705 Bonnes connaissances sur les architectures data et cloud (connaissance d\u2019un environnement Cloud) :\nAzure (Data Factory, Synapse, ADLS, Databricks)\nGoogle GCP (BigQuery, Composer, Data Studio)\n\u2705 SQL, Python\n\u2705 Spark, PySpark\n\u2705 Airflow, Kafka, Jenkins\n\u2705 Solides connaissances des processus collaboratifs et outils de d\u00e9veloppement (DevOps, Git, CI/CD\u2026)\nLes connaissances suivantes seraient un plus \u2935\ufe0f\nOpenShift, Docker, Kubernetes\nData visualisation\nBases NoSQL\nCertification Data Engineer (Azure Data Engineer, Google Professional Data Engineer ou Snowflake SnowPro)\nCe que nous t\u2019apportons\n\ud83d\udcab\nFORMATIONS ET D\u00c9VELOPPEMENT DE CARRI\u00c8RE\nUne journ\u00e9e de formation incluse dans ton parcours d\u2019onboarding lors de ton premier mois d\u2019arriv\u00e9e pour partager sur les fondamentaux et r\u00e9pondre \u00e0 tes questions\nAcc\u00e8s \u00e0 un coach interne et consultant comme toi pour t\u2019accompagner dans ton quotidien (questions en particulier, aide, mont\u00e9e en comp\u00e9tences)\nUn plan de formations et de certifications ambitieux (minimum 1 certification offerte par an)\n\u2b50\ufe0f\nAVANTAGES\nRemboursement de tes frais de transports (remboursement \u00e0 100% de ton pass navigo ou forfait mobilit\u00e9 durable jusqu\u2019\u00e0 700\u20ac par an pour l\u2019utilisation et l\u2019aide \u00e0 l\u2019achat de mat\u00e9riel de mobilit\u00e9 douce)\nTitres restaurant \u00e0 hauteur de 216\u20ac/mois pris en charge \u00e0 60% par Saegus (Carte Swile)\nPrime vacances (vers\u00e9e en juin)\nPrime t\u00e9l\u00e9phone 25\u20ac/mois\nPrime d\u2019int\u00e9ressement aux r\u00e9sultats de l\u2019entreprise\nPrise en charge par Saegus de la mutuelle \u00e0 la hauteur de 75%\n\ud83d\udc4b\nCOH\u00c9SION ET CONVIVIALIT\u00c9\nOrganisation de deux activit\u00e9s par mois (fun, solidaire ou excellence) par notre Team Anim\nUn s\u00e9minaire annuel pour favoriser la coh\u00e9sion entre Saegusiens\nAcc\u00e8s aux locaux de Saegus, tr\u00e8s accueillants dans le centre de Paris notamment lors de nos SaegUp mensuel\nProfil recherch\u00e9\n\ud83c\udfaf\nId\u00e9alement, en termes de comp\u00e9tences, nous recherchons\n:\nUn profil de formation sup\u00e9rieure (Bac + 5 minimum), ing\u00e9nieur ou \u00e9quivalent, avec une exp\u00e9rience d\u2019au moins 3 ou 4 ans minimum dans le domaine du Big Data.\nTu as d\u00e9j\u00e0 men\u00e9 avec succ\u00e8s plusieurs projets Big Data avec des r\u00e9f\u00e9rences significatives dans la mise en place de flux de donn\u00e9es et de traitement de l\u2019information.\nTu interviens en autonomie sur tes projets et as une premi\u00e8re exp\u00e9rience d\u2019encadrement technique.\nTu es motiv\u00e9.e pour int\u00e9grer une structure alliant l\u2019exigence d\u2019un cabinet de conseil et le dynamisme et l\u2019agilit\u00e9 d\u2019une start-up.\nTu es un\u00b7e tr\u00e8s bon\u00b7ne communiquant\u00b7e et as un fort esprit d\u2019initiative, un go\u00fbt prononc\u00e9 pour les nouvelles technologies et un bon esprit de synth\u00e8se.\nTon sens du service et ton \u00e9coute client te permettront de t\u2019inscrire parfaitement dans la culture de notre cabinet de conseil.\nLa\nma\u00eetrise de l\u2019anglais et du fran\u00e7ais\n\u00e0 l\u2019\u00e9crit et \u00e0 l\u2019oral est indispensable.\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "R",
                "Go"
            ],
            "DataBase": [
                "SQL",
                "NoSQL"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [
                "Spark",
                "Databricks"
            ],
            "MachineLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [
                "Azure"
            ],
            "DevTools": [
                "Git",
                "Docker",
                "Jenkins"
            ],
            "Os": [],
            "DBMS": [
                "Snowflake",
                "Snowflake",
                "BigQuery"
            ],
            "SoftBigDataProcessing": [],
            "Automation": [
                "Kubernetes",
                "Airflow"
            ],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [
                "Docker",
                "Kubernetes",
                "OpenShift"
            ],
            "Collaboration": [],
            "Other": [
                "DevOps",
                "Big Data",
                "Cloud",
                "CI/CD"
            ],
            "FrSoftSkills": [
                "Adaptabilit\u00e9",
                "Organisation"
            ],
            "EnSoftSkils": [
                "Initiative"
            ]
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s",
                "4",
                "4",
                "4"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "title": "Cloud Solution Architect - Paris / Bordeaux / Remote",
        "company": "Fieldbox",
        "location": "Bordeaux, Nouvelle-Aquitaine, France",
        "link": "https://fr.linkedin.com/jobs/view/cloud-solution-architect-paris-bordeaux-remote-at-fieldbox-3881559118?position=1&pageNum=12&refId=8y50RlLjosG8MBxznoHMvA%3D%3D&trackingId=5syFOTC0OKuhrSV5QAbVRw%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Our business:\nWe help industrial companies to accelerate their digital transformation and dramatically improve their operational efficiency and competitiveness with data, software and AI. Our clients include CAC 40 companies, as well as small and medium-sized companies on five continents and over 150 industrial sites.\nWhat makes us special:\nWe offer a complete range of services, combined with the use of latest technologies, covering the entire lifecycle of data-driven solutions, from ideation, business value assessment, industrialized solution development, to deployment, run and scale.\nOur positioning:\nWe seek long term partnership-relation with our clients. We can help them define their digital strategy and AI roadmap, build & run a solution, train, and transfer skills, set up and professionalize R&D or innovation units or digital & AI factories.\nOur teams:\nA virtuous combination of three areas of expertise:\nBusiness expertise: industrial operations & engineering.\nTechnical expertise: data science, software engineering & devops.\nDelivery management expertise: managing digital projects and setting digital factories.\nYour missions:\nAs a Cloud Architect,you will design and participate in the implementation of cloud solutions to support the digital transformation of our clients. You will work in agile mode, in an international context, on industrial projects.\nYour main missions :\nSupport pre-sales technical activities by translating client\u2019s requirements into state-of-the-art architectures, while guiding customers through their digital transformation journey in the cloud :\nLead workshops to study and define customer requirements\nImagine and define the architecture that would best meet the specifications provided while taking in account the financial and security constraints of the client.\nHandle and resolve technical questions and challenges encountered by clients during the first phases of their projects\nDefine deployment methodologies and integration of the solution into the existing client\u2019s ecosystem.\nParticipate in pre-sales meeting with clients to present the envisioned architectures\nLead end-to-end architecture projects (web applications, data engineering & processing pipelines) involving intensive use of industrial data, with a focus on performance, scalability and security issues\nSupervise the deployment and industrialization of the target architectures\nEnsure the security and reliability of deployed environments\nWork in collaboration with multidisciplinary teams, including DevOps, back-end, front-end, data, product and business skills to make every project a success.\nExperience and skills required:\nAt least 2 years' experience in Architect or tech lead full stack role\nYou have experience with the following technologies:\nCloud: Azure, Google Cloud, AWS, OVH\nDatabases & storage : PostgreSQL, TimeScaleDB, Redis, InfluxDB, S3 and alike\nProcessing and scheduling: Azure Data Factory, Azure Functions, Azure Synapse, Airflow, Argo, AWS Batch, AWS Step\nStreaming: Kafka, RabbitMQ, Kinesis, SQS\nDevops: Docker, Kubernetes\nMoreover :\nYou have proven experience in cloud or hybrid architectures\nYou love architecture diagrams ! (Excalidraw, Draw.io)\nYou demonstrate technical leadership and are able to communicate complex ideas effectively.\nYou know how to challenge customer requirements and Fieldbox objectives in order to optimize the proposed architecture.\nYou successfully manage the complex constraints of a production application through analysis and resolution.\nYou are customer and solution-oriented and have excellent interpersonal skills.\nFluency in English\nKnowledge of an industrial sector is a plus\nKnowledge in python is a plus\nAdvantage and benefits:\nFull remote possible (Metropolitan France only)\nWhat about our offices\nBordeaux: meet with your colleagues in a peaceful and calm space with an amazing view on \u201cLes bassins \u00e0 flots\u201d\nParis: enjoy a coworking space on the top of the Montparnasse tower with a 360 view of Paris\nWhat about our values :\nJoin a company which values care where everyone is in position to reach their full potential\nYou will work within an energetic team with a strong technical skill. Weekly engineering are organized every week to present and discuss technical topics\nCreate immediate impact on the company\nA quiz is sent every month in order to improve your comfort at work\nFun Activity:\nAfterwork every month with different theme ( bowling , board game , darts, beers bar, etc. )\nLunch break : outside lunchs, board game parties, and sport! (running, badminton, darts, yoga)\nCTFs\nTypical process includes 3 steps :\nHR interview\nInterview with operational team, aiming at testing your fit to the specific job,\nInterview with one or several founders to validate the application\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "Scala",
                "R",
                "Go"
            ],
            "DataBase": [
                "SQL"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [],
            "MachineLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [
                "AWS",
                "Azure"
            ],
            "DevTools": [
                "Git",
                "Docker"
            ],
            "Os": [],
            "DBMS": [
                "PostgreSQL"
            ],
            "SoftBigDataProcessing": [],
            "Automation": [
                "Kubernetes",
                "Airflow"
            ],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [
                "Docker",
                "Kubernetes"
            ],
            "Collaboration": [
                "Teams"
            ],
            "Other": [
                "DevOps",
                "Cloud"
            ],
            "FrSoftSkills": [
                "Leadership",
                "Collaboration"
            ],
            "EnSoftSkils": [
                "Leadership",
                "Collaboration",
                "Interpersonal Skills"
            ]
        },
        "details": {
            "JobDetail": [
                "Remote",
                "Full"
            ],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "title": "SRE / DevOps Engineer",
        "company": "Equativ",
        "location": "Paris, \u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/sre-devops-engineer-at-equativ-3853748999?position=2&pageNum=12&refId=8y50RlLjosG8MBxznoHMvA%3D%3D&trackingId=X5d%2B8oiaEXeGYEkw2mowpA%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "\ud83d\udc6b About the team\nAt Equativ, we\u2019re on a mission to develop advertising technologies that empower our customers to reach their digital business goals. This means that we rely on massively scalable, widely distributed, highly available, and efficient software systems; the platform deals with over 3 millions requests per second managed by 3,000 servers.\nOur innovation team based in Paris, Nantes, Limoges, Krakow and Berlin is composed of 100+ straightforward and energetic engineers working in an Agile environment and ready to tackle the most complex technical challenges.\nYour mission \ud83d\udc47\nWithin infrastructure BU you will join the Platform department that strives to develop and deploy self-serve tooling to empower our RnD team.\nAs a member of our application SRE team, you will work closely with dev and platform teams to:\nAccelerate time to market and reliability of our backend services\nEnsure that our platform availability fulfills its SLA of 99.95%\nWhat you will do \u270f\ufe0f\nAs a backend application SRE, your key responsibilities will be:\nCommunication Bridge:\nAct as the primary liaison between the R&D and Platform, DevSecOps and Ops teams\nAligning Best Practices:\nImplement and align DevOps mindset and best practices, including SLOs framework, monitoring, and alerting, across diverse applications\nWork closely with dev teams to ensure adherence to industry standards and best practices, optimizing the efficiency and reliability of our platform\nKnowledge Sharing:\nFacilitate knowledge transfer sessions to empower development teams with increased autonomy on DevOps matters and improved services reliability\nProduction awareness:\nAssist on identifying service errors, instability patterns and latency issues\nActively participate in production impediments (PIMPs), postmortems, and incident handling, contributing to a proactive production environment\nProvide insights and recommendations for improving production processes and preventing future incidents\nAbout You \ud83d\udc4b\nMaster degree in Computer science or similar field of study\n2+ years of System or Software Engineering experience ideally in the web industry\nFluent with DevOps practices\nExperience in at least one of the following topics: CI/CD pipelines (gitlab, \u2026), Kubernetes administration (Rancher, argoCD, \u2026), Monitoring and alerting (prometheus, grafana stack, \u2026) with a focus on backend applications\nExperience working with IaC (Terraform, GitOps, \u2026)\nAutonomous and innovative mindset\nWorking proficiency and communication skills in verbal and written English\nNice to have:\nExperience with troubleshooting live incidents and incident management\nExperience in software development (Go, Python or equivalent)\nHow you'll grow \ud83d\ude80\nWithin 1 month:\nYou'll be just finishing your onboarding\nYou'll probably have tackled a few small tasks with your peers\nWithin 4 months:\nYou'll be trusted to endorse weekly Green Lantern role to assist day to day BE requests\nYou'll be assigned to minor tasks to ramp up on our stacks and processes\nWithin 9 months:\nYou'll be leading critical projects (Priority 0)\nYou'll be evolving in our technical architecture discussion\nYou\u2019ll start getting a grasp on the AdTech business\n\ud83d\udc4b About us\nEquativ is the new single name for Smart Adserver, DynAdmic, LiquidM and Nowtilus \u2014 four proven innovators in advertising technology. The vertically integrated company provides brand and privacy-safe solutions that empower its clients to achieve maximum impact while respecting the rights of consumers. The union combines client expertise and engineering excellence to serve the interests of both the supply- side and demand-side with equal professionalism and technical sophistication.\nHeadquartered in Paris and New York, Equativ operates globally with a team of more than 550 people in 20 offices. Equativ offers the market its own independent ad server, SSP, buyer tools, and media services to fulfill the promise of advertising technology. Learn more at Equativ.com.\nThe company is ranked on the Deloitte Technology Fast 500 EMEA and in the Financial Times\u2019 FT 1000: Europe\u2019s Fastest-Growing Companies.\nEquativ (formerly Smart AdServer) has been awarded the HappyIndex@Work label and is proud to be among the best companies in the ChooseMyCompany ranking, recognized for its flexible working environment.\nCome and lead the charge with us in building a transparent ecosystem based on quality!\nEquativ is an equal opportunity employer. Equal access to employment, services, and programs are available to everyone, regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity, or Veteran status. If you require reasonable accommodation throughout the application and/or interview process, please contact the recruitment team at ta-team@equativ.com\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "Scala",
                "R",
                "Go"
            ],
            "DataBase": [],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [],
            "MachineLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [],
            "DevTools": [
                "Git"
            ],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [
                "Kubernetes"
            ],
            "InfrastructureAsCode": [
                "Terraform"
            ],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [
                "Kubernetes"
            ],
            "Collaboration": [
                "Teams"
            ],
            "Other": [
                "DevOps",
                "CI/CD"
            ],
            "FrSoftSkills": [
                "Communication"
            ],
            "EnSoftSkils": [
                "Communication"
            ]
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "title": "Ing\u00e9nieur Devops IA",
        "company": "Visian",
        "location": "Paris, \u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/ing%C3%A9nieur-devops-ia-at-visian-3894692222?position=3&pageNum=12&refId=8y50RlLjosG8MBxznoHMvA%3D%3D&trackingId=tDK9gJ87Tl%2FCiaK%2BDaCOYA%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Visian recherche pour son client grand compte bancaire un profil\nIng\u00e9nieur(e) DevOps IA\n.\nLe contexte :\nLe socle Data Cloud de notre client con\u00e7oit et op\u00e8re des plateformes \u00ab as a service \u00bb facilitant la mise en place d\u2019architectures modernes, distribu\u00e9es et hautement r\u00e9silientes pour l\u2019ensemble des entit\u00e9s du groupe.\nEn tant que\nData ops engineer\n, vous rejoindrez l\u2019\u00e9quipe data, actuellement constitu\u00e9e de 40 personnes et organis\u00e9e en 7 devs teams orient\u00e9es produit dont le p\u00e9rim\u00e8tre s\u2019\u00e9tend de la conception du service \u00e0 son maintien en condition op\u00e9rationnelle en production.\nEn tant que data ops engineer, vous \u00e9voluerez dans un environnement technique complexe, distribu\u00e9, s\u00e9curis\u00e9 et hautement disponible. Vous travaillerez au sein d\u2019une dev team affect\u00e9e \u00e0 un produit en particulier et serez sollicit\u00e9 en fonction de vos expertises pour accompagner les autres dev teams data.\nLes missions :\nEn qualit\u00e9 d'Ing\u00e9nieur(e) DevOps IA, vos principales missions seront les suivantes :\nMise en \u0153uvre op\u00e9rationnelle et techniques des produits Data :\nIndustrialiser et automatiser\nDocumenter les offres\nApporter une expertise technique\nMettre en production\nD\u00e9finir des architectures\nD\u00e9velopper des prototypes en lien avec les cas d\u2019usages des entit\u00e9s\nD\u00e9montrer la valeur des offres Data aupr\u00e8s des entit\u00e9s\nParticiper au Daily meeting anim\u00e9 par le Squad Lead\nParticiper aux r\u00e9unions de co-construction de la roadmap et de la mise en \u0153uvre de la roadmap sous la gestion du product owner Data et du responsable du Squad dont il d\u00e9pend\nPrendre des \u00e9l\u00e9ments de la backlog qui a \u00e9t\u00e9 formalis\u00e9 par le Squad Lead et met en \u0153uvre les \u00e9l\u00e9ments de la backlog\nRendre compte des difficult\u00e9s auxquelles il est confront\u00e9 et propose des solutions pour les r\u00e9soudre\nTravailler en \u00e9quipe avec son Squad\nEtre Lead sur un produit technique au sein du Squad\nParticiper \u00e0 l\u2019\u00e9laboration des formations, des pr\u00e9sentations aux r\u00e9f\u00e9rents Clusters et Entit\u00e9s qui consomment ou pourraient consommer les produits dont a g\u00e9r\u00e9 la mise en \u0153uvre\nParticiper aux d\u00e9monstrations de la plateforme\nParticiper \u00e0 l\u2019ensemble des rituels du Squad, de la plateforme et du socle\nPROFIL ATTENDU :\nTitulaire d'un dipl\u00f4me BAC+5 (\u00e9cole d'ing\u00e9nieur, \u00e9cole de commerce, universit\u00e9)\nVous justifiez d'une exp\u00e9rience minimum de 3 ans en qualit\u00e9 d'Ing\u00e9nieur Devops\nAnglais professionnel \u00e0 minima\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "R"
            ],
            "DataBase": [],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [],
            "MachineLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [],
            "DevTools": [],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [
                "Teams"
            ],
            "Other": [
                "DevOps",
                "Cloud"
            ],
            "FrSoftSkills": [],
            "EnSoftSkils": []
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [],
            "Salary": [],
            "Level": [
                "Bac+5"
            ],
            "Experience": [
                "a",
                "n",
                "s",
                "3",
                "3",
                "3"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "title": "Cloud Native Data Engineer",
        "company": "Stack Labs",
        "location": "Greater Paris Metropolitan Region",
        "link": "https://fr.linkedin.com/jobs/view/cloud-native-data-engineer-at-stack-labs-3918055497?position=4&pageNum=12&refId=8y50RlLjosG8MBxznoHMvA%3D%3D&trackingId=OuleBYg%2BjZAPnFR7S40zBw%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Pr\u00e9sentation de l\u2019entreprise :\nFond\u00e9e par des passionn\u00e9s de tech en 2017, Stack Labs est n\u00e9e d\u2019une conviction : privil\u00e9gier l\u2019excellence technique et le partage de connaissances pour adresser les enjeux du Cloud.\nDans un contexte o\u00f9 les entreprises doivent acc\u00e9l\u00e9rer leur transformation num\u00e9rique et s\u2019adapter aux challenges de la migration vers le Cloud, nous avons acquis notre cr\u00e9dibilit\u00e9 \u00e0 travers les projets strat\u00e9giques de nos clients mais surtout gr\u00e2ce \u00e0 notre rayonnement dans les diff\u00e9rentes communaut\u00e9s et conf\u00e9rences techniques dans le monde du Cloud (Devoxx, DevFest, GDG, etc.)\nPartenaire reconnu de Google (Partner of the year Google 2023 en France), et d\u2019AWS nous explorons toutes les nouvelles stacks techniques et les impl\u00e9mentons sur des projets dans le secteur du spatial, IoT, fintech, automobile, a\u00e9ronautique, etc.\nNotre devise : construire ensemble, partager nos connaissances et nos expertises au service de projets et produits ambitieux et innovants.\nEt concr\u00e8tement ? Les stackers sont des experts tech qui interviennent sur des projets impliquant des technologies li\u00e9es aux infrastructures \u00e9lastiques. L\u2019\u00e8re du Cloud exige un apprentissage continu : les stackers d\u00e9veloppent leur expertise \u00e0 travers de la veille et des codelabs sur du temps d\u00e9di\u00e9 (une demi-journ\u00e9e tous les 15 jours).\nNous recherchons avant tout des personnes engag\u00e9es, ayant envie d\u2019apprendre continuellement, qui portent nos valeurs de partage et de travail en \u00e9quipe.\nDescription du poste :\nPour renforcer notre \u00e9quipe data et accompagner notre croissance, nous recherchons actuellement un Data Engineer, avec une app\u00e9tence pour les solutions Cloud.\nDe part votre m\u00e9tier, vous serez amen\u00e9(e) \u00e0 intervenir d\u00e8s les phases amont de projets de migration cloud pour des clients \u00e0 forts enjeux de scalabilit\u00e9 sur du conseil technique et sur les fondamentaux du cloud public (infra as code & automatisation, s\u00e9curit\u00e9, observabilit\u00e9 ) jusqu\u2019\u00e0 la mise en service des solutions.\nReconnu(e) pour votre polyvalence au sein des \u00e9quipes, vous \u00eates orient\u00e9(e) aussi bien vers la sph\u00e8re technique que vers l\u2019Humain.\nNotre \u00e9cosyst\u00e8me technique (indicatif, variable en fonction des missions) :\nArchitecture Data : ETL, ELT, Dataflow, Spark, Airflow, GCP Workflows\nBig Data: BigQuery, Firestore, Redshift, Athena, MongoDB\nContainers & microservices : Docker, Kubernetes, Istio,...\nArchitectures orient\u00e9es messages : Kafka, PubSub,..\nAutomatisation & Infrastructure as Code (IaC) : Terraform, CloudFormation, Ansible, GitLab, GitHub,...\nPublic Cloud : AWS, GCP, ...\nLangages de d\u00e9veloppement : Python, Go, Java...\nProfil Recherch\u00e9 :\nVous disposez de plusieurs exp\u00e9riences en tant Data Engineer sur des plateforme cloud public, notamment dans la mise en place de pipelines et le traitement automatis\u00e9 des donn\u00e9es. Vous avez une vraie app\u00e9tence pour les technologies Cloud, et de l\u2019exp\u00e9rience sur au moins un fournisseur Cloud. Moteur au sein des \u00e9quipes, vous \u00eates naturellement tourn\u00e9(e) vers la proactivit\u00e9, le partage et la bienveillance. Plus qu\u2019un profil type, nous recherchons chez Stack Labs des personnes proches de notre ADN : passionn\u00e9es de tech, curieuses et disposant d\u2019une v\u00e9ritable \u201csoif d\u2019apprentissage\u201d.\n\u00c9voluer avec Stack Labs, c\u2019est ?\nS'\u00e9panouir, apprendre et transmettre, au sein d\u2019une v\u00e9ritable communaut\u00e9 d'experts techniques du cloud.\nTravailler et acqu\u00e9rir de l\u2019exp\u00e9rience sur des technologies \u00e0 fort potentiel strat\u00e9gique\n\u00catre form\u00e9(e)/certifi\u00e9(e) sur vos environnements de pr\u00e9dilection (GCP, AWS, K8S,..)\nDevenir ambassadeur/ambassadrice de l\u2019adoption des environnements Cloud\nAvoir la possibilit\u00e9 de r\u00e9diger des articles, de pitcher, de devenir formatrice/formateur\nLa possibilit\u00e9 d'\u00e9voluer vers un r\u00f4le de leader technique\nLes plus du Stacker :\n12 \u201cStack Day\u201d par an: une journ\u00e9e tous les mois \u00e0 l\u2019agence (Paris 9 ou Toulouse) consacr\u00e9e aux retours d\u2019exp\u00e9riences, \u00e0 la veille et \u00e0 l\u2019exploration de nouveaux sujets techniques\nDes conf\u00e9rences pour se former et pitcher\nUn pack de bienvenue avec du mat\u00e9riel de travail: choisissez votre propre configuration!\nLa flexibilit\u00e9: possibiliter de t\u00e9l\u00e9travail en fonction des contextes clients.\nParticiper \u00e0 des \u00e9v\u00e8nements: afterworks, manifestations internes (soir\u00e9es, team building, s\u00e9minaires, etc.)\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "Java",
                "Scala",
                "R",
                "Go"
            ],
            "DataBase": [
                " MongoDB"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [
                "Spark"
            ],
            "MachineLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [
                "AWS"
            ],
            "DevTools": [
                "Git",
                "Docker"
            ],
            "Os": [],
            "DBMS": [
                "BigQuery"
            ],
            "SoftBigDataProcessing": [],
            "Automation": [
                "Ansible",
                "Kubernetes",
                "Airflow"
            ],
            "InfrastructureAsCode": [
                "Terraform",
                "CloudFormation"
            ],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [
                "Docker",
                "Kubernetes"
            ],
            "Collaboration": [],
            "Other": [
                "Big Data",
                "Cloud"
            ],
            "FrSoftSkills": [
                "Flexibilit\u00e9"
            ],
            "EnSoftSkils": []
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "title": "Cloud Solutions Engineer",
        "company": "Amadeus",
        "location": "Sophia Antipolis, Provence-Alpes-C\u00f4te d'Azur, France",
        "link": "https://fr.linkedin.com/jobs/view/cloud-solutions-engineer-at-amadeus-3890146341?position=5&pageNum=12&refId=8y50RlLjosG8MBxznoHMvA%3D%3D&trackingId=LG6bM3k3qqDbRR8X8RTx5Q%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Job Title\nCloud Solutions Engineer\nSummary Of The Role\nAmadeus R&D's transversal unit within the TEC organization is dedicated to delivering cloud platform capabilities, middleware components, and services to all Amadeus applications, serving clients worldwide in various sectors such as airline, hospitality, and travel agencies. This team focuses on ensuring strong resiliency, scalability, security, and reusability of frameworks, resources, and services. As part of this forward-thinking department, you will analyse demands, develop comprehensive solutions, and provide cost estimations for future years, crucial for building business cases and determining investment decisions. Collaborating closely with stakeholders, including responding to customer RFPs and participating in solution design coordination, the team offers valuable expertise on requirements impacting the platforms.\nIn This Role You Will\nCollect and clarify the requirements from the requester (R&D, Business Units, finance Guardrails)\nCoordinate the design of the solution in collaboration with architects and/or technical product managers regarding the platform needs.\nAssess the cost of these solutions, evaluating several scenarios, in collaboration with R&D.\nExpose the solution with the corresponding cost to top management, focusing on specificities, assumptions, and forecasts.\nExplain the cost estimations related to assumptions, and how assumptions have been chosen.\nCommunicate with requester, sometime Amadeus customer or acquired companies.\nInteract with finance providing budget input, with the platform delivery teams to launch the execution, with Product managers to see what can be done, and possibly influence the platform evolution.\nPotentially influence the platform evolution backlog in line with the technical product managers.\nAbout The Ideal Candidate\nBachelor\u2019s degree in computing engineer or related field.\nExperience in a similar role\nExperience in computing, product management, and understanding of business cases.\nStrong notions in Architecture, Data Stores, network, computing.\nKnowledge in finance, business cases.\nFluent in English with excellent communication skills\nWhat We Can Offer You\nAdd your voice to a multicultural team of 16,000+ professionals.\nWork at one of the world\u2019s top 15 software companies.\nChallenge yourself to find solutions to complex problems.\nFlexible hybrid work from 1-2 days per week.\nCompetitive compensation and benefits package.\nApplication process\nCreate your candidate profile in our system and upload your recent resume! Once you have applied, you\u2019ll receive feedback within 15 days.\nAre you ready to leave your footprint? Be the power behind better journeys.\nDiversity & Inclusion\nWe are an Equal Opportunity Employer and seek to hire the best candidate regardless of age, beliefs, disability, ethnicity, gender or sexual orientation.\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Scala",
                "R"
            ],
            "DataBase": [],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [],
            "MachineLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [],
            "DevTools": [],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [
                "Teams"
            ],
            "Other": [
                "Cloud"
            ],
            "FrSoftSkills": [
                "Communication",
                "Collaboration"
            ],
            "EnSoftSkils": [
                "Communication",
                "Collaboration",
                "Organization"
            ]
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [],
            "Salary": [
                "15"
            ],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "title": "Ing\u00e9nieur Cloud/DevOps H/F",
        "company": "iPepperGroup",
        "location": "Alpes-de-Haute-Provence, Provence-Alpes-C\u00f4te d'Azur, France",
        "link": "https://fr.linkedin.com/jobs/view/ing%C3%A9nieur-cloud-devops-h-f-at-ipeppergroup-3914494594?position=6&pageNum=12&refId=8y50RlLjosG8MBxznoHMvA%3D%3D&trackingId=FDT%2BcDaYoC399sAYg%2Ffheg%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Nous sommes le partenaire technologique pr\u00e9f\u00e9r\u00e9 de ceux qui changent le monde ! iPepper c'est avant tout une fa\u00e7on de travailler ensemble : se faire du bien, faire du bien et prendre soin de ses clients, salari\u00e9s et partenaires ! Coaching, Recrutement et Conseil : une palette de services autour de la protection et la valorisation de la data.\nLe Poste\nNous recherchons plusieurs Cloud / DevOps Engineer talentueux(ses) pour rejoindre l'aventure iPepper sur Nantes et sa p\u00e9riph\u00e9rie. Responsabilit\u00e9s : - Concevoir, mettre en \u0153uvre et maintenir une infrastructure Cloud, en utilisant des services tels que AWS, Azure, ou Google Cloud Platform, - Automatiser les processus de d\u00e9ploiement et de gestion de l'infrastructure \u00e0 l'aide d'outils tels que Ansible ou Terraform, - Collaborer avec les \u00e9quipes de d\u00e9veloppement pour d\u00e9finir les meilleures pratiques en mati\u00e8re de d\u00e9veloppement et d'exploitation des syst\u00e8mes, - Mettre en place des pipelines d'int\u00e9gration continue et de d\u00e9ploiement continu, - Surveiller et analyser les performances du syst\u00e8me, et proposer des am\u00e9liorations, - Assurer la s\u00e9curit\u00e9 et la conformit\u00e9 des syst\u00e8mes et des donn\u00e9es, - G\u00e9rer les outils de surveillance tels que Prometheus, Grafana, et Datadog.\nProfil Recherch\u00e9\nNotre TOP profil poss\u00e8de : - Minimum de 4 ans d'exp\u00e9rience professionnelle en tant que Cloud / DevOps Engineer, - Une solide exp\u00e9rience dans la mise en place et la gestion d'infrastructures Cloud (AWS, Azure, GCP), - Une exp\u00e9rience pratique avec les outils de surveillance tels que Prometheus, Grafana et Datadog, - Une connaissance des outils de conteneurisation tels que Docker et Kubernetes, - Des comp\u00e9tences en scripting et en d\u00e9veloppement (Python, Shell, PowerShell, etc.), - De bonnes connaissances en r\u00e9seaux, - Une capacit\u00e9 \u00e0 travailler en \u00e9quipe et \u00e0 collaborer efficacement avec les d\u00e9veloppeurs, - D'excellentes comp\u00e9tences en r\u00e9solution de probl\u00e8mes et en d\u00e9pannage. Rejoignez nous !\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "R",
                "Go"
            ],
            "DataBase": [],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [],
            "MachineLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [
                "AWS",
                "Azure",
                "Google Cloud Platform"
            ],
            "DevTools": [
                "Docker"
            ],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [
                "Ansible",
                "Kubernetes"
            ],
            "InfrastructureAsCode": [
                "Terraform"
            ],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [
                "Docker",
                "Kubernetes"
            ],
            "Collaboration": [],
            "Other": [
                "DevOps",
                "Cloud"
            ],
            "FrSoftSkills": [
                "R\u00e9solution de probl\u00e8mes"
            ],
            "EnSoftSkils": []
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s",
                "4",
                "4",
                "4"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "title": "DevOps - Platform Engineer - Sre en Full-Remote H/F",
        "company": "Team.is",
        "location": "Bordeaux, Nouvelle-Aquitaine, France",
        "link": "https://fr.linkedin.com/jobs/view/devops-platform-engineer-sre-en-full-remote-h-f-at-team-is-3917051324?position=7&pageNum=12&refId=8y50RlLjosG8MBxznoHMvA%3D%3D&trackingId=r2USnfuOCwrDBxkPaXNa3A%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Lanc\u00e9 en 2021, Team.is est une start-up de recrutement sp\u00e9cialis\u00e9e dans la chasse et le recrutement de profils IT, Digital, Ing\u00e9nierie & Supply Chain.\nTeam.is c'est avant tout une entreprise \u00e0 taille humaine anim\u00e9e par la passion du recrutement !\nTeam.is poss\u00e8de l'expertise et l'\u00e9nergie pour s'attaquer \u00e0 n'importe quel d\u00e9fi. Mais nous ne sommes pas des robots du recrutement. Nous sommes des consultants qui vivent et respirent ce que nous faisons ! Nous sommes d\u00e9termin\u00e9s \u00e0 r\u00e9aliser le meilleur travail possible pour cultiver des relations durables avec nos candidats et nos clients.\nEn postulant \u00e0 cette offre, vous aurez l'opportunit\u00e9 de rejoindre une entreprise prometteuse avec une forte diversit\u00e9 de projets. Notre client est une soci\u00e9t\u00e9 de plate-forme de connectivit\u00e9 cellulaire offrant \u00e0 l'industrie automobile une nouvelle fa\u00e7on de permettre et d'am\u00e9liorer le fonctionnement de ses voitures connect\u00e9es \u00e0 l'\u00e9chelle mondiale.\nFond\u00e9e en 2021 par des entrepreneurs t\u00e9l\u00e9coms chevronn\u00e9s et d'anciens cadres d'acteurs des t\u00e9l\u00e9coms, de l'IOT, de la voiture connect\u00e9e et de la t\u00e9l\u00e9matique, l'entreprise recherche pour compl\u00e9ter son \u00e9quipe un Plateform Engineer H/F\nVos Missions Si Vous Les Acceptez\nAu sein de l'\u00e9quipe Platform Engineering, vous participerez \u00e0 la d\u00e9finition et \u00e0 l'\u00e9laboration des infrastructures Kubernetes n\u00e9cessaires au d\u00e9veloppement et \u00e0 l'op\u00e9ration de leurs solutions :\nCr\u00e9ation et administration avec ArgoCD et CrossPlane de clusters Kubernetes dans le cloud public (aujourd'hui AWS) et priv\u00e9\nMise en place et maintien de la haute disponibilit\u00e9, ainsi que des solutions de logs et de m\u00e9triques de l'infrastructure et des applicatifs\nInterconnections multi-clusters\nGestion des droits et de l'authentification, mise en place et maintien de la s\u00e9curit\u00e9 op\u00e9rationnelle\nD\u00e9ploiement de services transverses (DB, r\u00e9seau, etc.)\nD\u00e9veloppement de CRD et d'op\u00e9rateurs Kubernetes\nAutomatisation des proc\u00e9dures de d\u00e9ploiement et gestion des images Docker\nFormation des \u00e9quipes \u00e0 Kubernetes et \u00e0 l'IaC\nAvantages\nNotre client \u00e9tant organis\u00e9 en Holacratie, vous aurez toute libert\u00e9 de proposer le ou les roles que vous souhaiterez assumer afin de faire b\u00e9n\u00e9ficier au mieux l'\u00e9quipe de votre exp\u00e9rience. Vous pourrez \u00e9galement d\u00e9velopper de nouvelles comp\u00e9tences en choisissant d'autres roles.\nL'entreprise propose du 100% t\u00e9l\u00e9travail, vous pourrez travailler de n'importe o\u00f9 en France. Si vous \u00eates situ\u00e9 dans la r\u00e9gion toulousaine ou ni\u00e7oise, il y a \u00e9galement la possibilit\u00e9 de faire du co-working ponctuel.\nAutres Avantages\nEntre 8 et 11 jours de RTT par an\n3000\u20ac HT de budget d'installation pour vous \u00e9quiper - ce budget inclu votre laptop (Fame.work ou Macbook Pro)\n57.20 \u20ac / mois de prime t\u00e9l\u00e9travail\n2 rassemblements d'une semaine par an quelque part en France avec toute l'\u00e9quipe\nPossibilit\u00e9 de co-working\nEt vous ?\nVous avez une exp\u00e9rience comme Platform Engineer, DEVOPS ou SRE. Vous \u00eates autonomes et vous aidez vos coll\u00e8gues \u00e0 r\u00e9soudre leurs probl\u00e8mes gr\u00e2ce \u00e0 votre infrastructure. Vous parlez fran\u00e7ais et vous \u00eates \u00e0 l'aise en anglais. Bonus\nConnaissance r\u00e9seaux et T\u00e9l\u00e9com\nAdministration syst\u00e8me (gestion de data center)\nGestion de base de donn\u00e9es\nMise en oeuvre de pratiques agile\nLe cadre technique de leur solution\nCloud public : AWS et GCP\nCloud priv\u00e9 : Equinix\nCI sur GitHub Actions + ArgoCD\nKubernetes et CrossPlane\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "R",
                "Go"
            ],
            "DataBase": [],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [],
            "MachineLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [
                "AWS"
            ],
            "DevTools": [
                "Git",
                "Docker"
            ],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [
                "Kubernetes"
            ],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [
                "Docker",
                "Kubernetes"
            ],
            "Collaboration": [],
            "Other": [
                "DevOps",
                "Cloud"
            ],
            "FrSoftSkills": [],
            "EnSoftSkils": []
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "title": "Data engineer AWS S\u00e9nior",
        "company": "Apside",
        "location": "\u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/data-engineer-aws-s%C3%A9nior-at-apside-3825002635?position=8&pageNum=12&refId=8y50RlLjosG8MBxznoHMvA%3D%3D&trackingId=v3xp0zgIatvLsYT9k37s5Q%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "\ud83d\udca5\nD\u00e9couvrez la Vie Apsidienne\n\ud83d\udcf9\net vous aussi, devenez Apsidien\nOn aurait pu demander \u00e0 Chat GPT de vous d\u00e9montrer en quoi\nApside est l\u2019ESN qu\u2019il vous faut,\nmais on pr\u00e9f\u00e8re que vous le d\u00e9couvriez vous-m\u00eames \ud83d\udc47\ud83d\ude0f\n\ud83d\udd25\nD\u00e9couvrez votre future mission\n\ud83d\udc49\nContexte\nRejoignez notre Practise Cloud/Data, afin d\u2019intervenir sur des sujets \u00e0 haute valeur ajout\u00e9e !\nDans le cadre du renforcement de leur \u00e9quipe data, notre client recherche un data ing\u00e9nieur qui sera amen\u00e9 \u00e0 travailler sur la mise en \u0153uvre de plusieurs produits data visant \u00e0 l'exposition et la mise en qualit\u00e9 des donn\u00e9es de r\u00e9f\u00e9rences.\nL'environnement de travail est sur le cloud AWS avec terraform en infra as code\nSecteur\n: culture/m\u00e9dia\nM\u00e9thode de travail\n: Agile / Scrum\n\ud83d\ude0e Mission\nIngestion et traitement des sources de donn\u00e9es\nPr\u00e9paration des donn\u00e9es (transformation fonctionnelle et technique)\nElaboration de syst\u00e8me avanc\u00e9 de gestion de qualit\u00e9 de donn\u00e9es\nElaboration d'API/workflow\nExposition des donn\u00e9es (Elasticsearch, RDS) via des API pour les applications front\nPr\u00e9paration des package de livraison en Infra as code\nGestion du cycle de livraison en production\nMCO\nR\u00e9daction des documentations techniques\n\u2026\nEnvironnement technique\n:\nAWS (lambda, EMR, APIGateway, cognito ...)\nPython\nTerraForm\nGit CI/CD\nElasticsearch\nPySpark\nJSON\nSQL (PostgreSQL)\n\ud83d\udccd\nLocalisation\nLa D\u00e9fense\n\ud83d\udcb0\nLe package salarial que nous vous proposons\nContrat :\nCDI\nAvantages groupe :\ncarte ticket restaurant Swile, prime de mobilit\u00e9, RTT, accord t\u00e9l\u00e9travail, Mutuelle, prime de cooptation, avantages CE, prise en charge de la mutuelle \u00e0 100% etc\u2026\nAvantages agence :\nint\u00e9gration de la Practise Cloud/Data, afterworks, communaut\u00e9 techlead\nFormation :\ncertifications techniques, cours particuliers d\u2019anglais en interne, acc\u00e8s \u00e0 un catalogue de formations gr\u00e2ce \u00e0 notre plateforme e-learning (\nAcademy by Apside\n) ou via nos organismes partenaires.\n\ud83d\udd2e\n\u00d4 vous futur Apsidien, qui \u00eates-vous ?\nAu moins 5 ans d'exp\u00e9rience en tant que Data Engineer\nMaitrise de l\u2019environnement cloud AWS\nForce de proposition, bon relationnel et autonome\n\ud83d\ude0f\nApside a suscit\u00e9 votre curiosit\u00e9 ?\nDans un environnement marqu\u00e9 par une acc\u00e9l\u00e9ration des \u00e9volutions technologiques, de transformations des usages et de disruptions majeures, Apside est un partenaire de confiance qui accompagne ses clients \u00e0 cr\u00e9er de la valeur et \u00e0 adresser leurs enjeux strat\u00e9giques en leur mettant \u00e0 disposition des expertises technologiques (\nData / IA, Cloud, Cyber\n) et une exp\u00e9rience sectorielle (\nIndustrie, Banque, Assurance, Service, Secteur Public\n). Pour un accompagnement global, le groupe propose des offres transverses autour du\nHandicap\n(Apsid\u2019EA), du\nDigital Learning\n, et du\nConseil\n.\n\ud83e\udd14\nEt votre place dans tout \u00e7a ?\n\ud83d\udc49 Notre volont\u00e9\nest de vous accompagner dans la construction et l\u2019\u00e9panouissement de votre carri\u00e8re\nen nous appuyant notamment\nsur 3 piliers :\nUne\nr\u00e9mun\u00e9ration\n\u00e0 hauteur de vos investissements et de vos comp\u00e9tences\nUne\ntrajectoire professionnelle\nstimulante sur mesure\nUn\nengagement\nautour des valeurs Apsidiennes : la qualit\u00e9 de vie et des conditions de travail au c\u0153ur de nos enjeux\nEngag\u00e9e pour\nun monde plus inclusif et plus responsable\n, Apside r\u00e9invente l\u2019ESN et propose l\u2019Engagement Soci\u00e9tal et Num\u00e9rique. D\u00e9couvrez notre d\u00e9marche RSE ainsi que notre vision de l\u2019Entreprise Engag\u00e9e.\nConvaincu ? A vous de jouer, envoyez-nous votre CV !\nRejoignez l\u2019aventure Apsidienne et d\u00e9couvrez notre vision d\u2019une ESN singuli\u00e8re et r\u00e9siliente\n\ud83d\ude80\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "R"
            ],
            "DataBase": [
                "SQL",
                "Elasticsearch"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [
                "Spark"
            ],
            "MachineLearning": [],
            "DataSerialization": [
                "Json"
            ],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [
                "AWS"
            ],
            "DevTools": [
                "Git"
            ],
            "Os": [],
            "DBMS": [
                "PostgreSQL"
            ],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [
                "Terraform"
            ],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [
                "Cloud",
                "CI/CD"
            ],
            "FrSoftSkills": [],
            "EnSoftSkils": []
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [
                "CDI"
            ],
            "Salary": [
                "100"
            ],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s",
                "5",
                "5",
                "5"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "title": "Infrastructure Engineer",
        "company": "Density",
        "location": "Paris, \u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/infrastructure-engineer-at-density-3728504793?position=9&pageNum=12&refId=8y50RlLjosG8MBxznoHMvA%3D%3D&trackingId=uoVn7tIzShVVE0c6RFokAw%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "About Density\nDensity's mission is to measure and improve our footprint on the world.\nWe help companies understand how their workplaces are used. At Density, we build one of the most advanced people sensing systems in the world. Density can tell you how many people are in any room in near real-time, with very high degrees of accuracy and without invading privacy.\nWe translate that data into actionable, opinionated insights that help companies increase the financial and experiential performance of any workplace. Today, we work with companies ranging from Fortune 1000 to high growth such as Uber, Pinterest, Shopify and Okta, occupying more than a billion square feet worldwide.\nThe result: lower emissions, less waste, better access, safer buildings and better designed cities. It is a long term pursuit and one we could use your help achieving. That's where you come in.\nThe opportunity:\nWe're looking for talented Infrastructure Engineers to help us build one of the most advanced people sensing systems in the world. We're architecting infrastructure where annual, unscheduled downtime is measured in minutes. We're building intelligent redundancies so missed events are an oddity. The Infrastructure team is responsible for all of the cloud resources that power Density's business. We're a small group of engineers with broad experience and a passion for building reliable systems and thoughtful tools. Our positioning within Density is unique\u2014 our customers are other members of the engineering team. The products we build help application engineers deliver value to Density's customers quickly and effectively. As a Senior Infrastructure Engineer, you will help define, design, build, and manage the infrastructure that enables these products.\nIn this role you will:\nOwn, operate, and maintain production Kubernetes clusters running thousands of containers.\nBe a core contributor to our roadmap initiatives, namely our migration to Kubernetes and re-architecture of internal tooling. Since we are transitioning to Kubernetes, having knowledge of Nomad is not a requirement but a nice to have.\nLook for areas of improvement across our stack, design a solution, and see it through to production.\nEvangelize new designs and work with developer feedback to build a system that is robust, easy to use, and satisfies the use case.\nParticipate in 24/7 on call rotation for infrastructure issues. Participate in and coordinate incident response during production outages.\nFind satisfaction in working remotely from your home.\nThe ideal candidate will have:\n5+ years experience in an SRE, Infrastructure or DevOps role.\nBackground operating and maintaining container orchestration platforms like Kubernetes\nExperience with automation and configuration management tools like Terraform, Packer, Ansible, or equivalent\nStrong background in Linux/Unix fundamentals, including systemd, shell scripting, performance tuning\nAbility to design and manage CI / CD pipelines (ArgoCD, Helm, Sops, Github Actions .. )\nExperience with incident response processes and outage resolution\nStrong writing skills; ability to craft clear and concise documentation\nNice-To-Have:\nSignificant prior experience with observability and logging platforms such as DataDog and OpenSearch.\nSignificant prior experience operating and maintaining high performance logging and metrics pipelines using Vector, Fluentd, or similar.\nExperience using observability tools to tie metrics to application scaling.\nHave built metrics pipelines processing 100,000s or 1,000,000s of lines per minute.\nExperience operating APIs and web applications, like Go Gin/Connect-GO, Rust, Python Django/Flask,etc.\nA solid understanding of Linux security fundamentals.\nWe offer:\nA company full of fun, smart, talented and legitimately kind teammates. Our culture powers everything we do and we work hard to nurture it by bringing on the right humans.\nA team hailing from innovators like Apple, LinkedIn, Stripe, Meraki, Flexport, WeWork, NASA & beyond.\n$227M raised from investors including Kleiner Perkins, Founders Fund and Upfront Ventures.\nThe chance to change the built world as we know it.\nYou can read more about our values here.\nDensity provides equal employment opportunities to all employees and applicants for employment and prohibits discrimination and harassment of any type without regard to race, color, religion, age, sex, national origin, disability status, genetics, protected veteran status, sexual orientation, gender identity or expression, or any other characteristic protected by federal, state or local laws.\nThis policy applies to all terms and conditions of employment, including recruiting, hiring, placement, promotion, termination, layoff, recall, transfer, leaves of absence, compensation and training.\nJob Compensation Range:\nSalary Range: \u20ac60,000.00 - \u20ac90,000.00\nPreferred Primary Location: Paris, France\nAn important note on salary:\nThe annual pay range for this position is based on the preferred primary location of the role which is listed above. If you are applying to this role at a location that is not the preferred primary location, please keep in mind the salary range will vary and may fall outside of what is listed. Only in truly rare and exceptional circumstances, where an external candidate has experience, credentials or expertise that far exceed those required or expected for the position, would the Density consider paying a salary or rate near the higher end of the range. Equity may be provided as part of the compensation package, in addition to a full range of medical, financial, and/or other benefits, depending on the position offered.\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "R",
                "Go"
            ],
            "DataBase": [],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [],
            "MachineLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [
                "AWS"
            ],
            "DevTools": [
                "Git"
            ],
            "Os": [
                "Linux"
            ],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [
                "Ansible",
                "Kubernetes"
            ],
            "InfrastructureAsCode": [
                "Terraform"
            ],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [
                "Kubernetes"
            ],
            "Collaboration": [],
            "Other": [
                "DevOps",
                "Cloud",
                "CI / CD"
            ],
            "FrSoftSkills": [],
            "EnSoftSkils": [
                "Initiative"
            ]
        },
        "details": {
            "JobDetail": [
                "Remote",
                "Full",
                "Senior"
            ],
            "TypeContract": [],
            "Salary": [
                "60,000"
            ],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "title": "Software test engineer",
        "company": "CryptoNext Security",
        "location": "Paris, \u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/software-test-engineer-at-cryptonext-security-3900395021?position=10&pageNum=12&refId=8y50RlLjosG8MBxznoHMvA%3D%3D&trackingId=xXr22hyfsDyeykii9W0uxg%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "CryptoNext Security is seeking a highly motivated and skilled\nSoftware Test Engineer / ing\u00e9nieur de test et validation logiciels\nto join our R&D team focused on post-quantum cryptography. The ideal candidate will have a strong background in software development and cybersecurity solutions with a passion for pushing the boundaries of what is currently possible in the field.\nWorking within CryptoNext R&D, the Software Test Engineer plays a critical role in ensuring the quality and reliability of software products. He focus on testing procedures, identifying and reporting issues, and collaborating with development teams.\nPrincipal duties and responsibilities\nDesign and implementing testing strategies, testing procedures:\nDevelop testing procedures to evaluate the performance and validation of software.\nBuild software testing programs that automate testing processes.\nExecuting Testing Procedures:\nRun software testing procedures to assess the software\u2019s functionality\nDocument all testing procedures and report any identified bugs.\nMake recommendations to improve the software product.\nCollaboration:\nWork closely with other Test Engineers, Software Programmers, and team members.\nAttend meetings with the development team and clients.\nKnowledge, skills, abilities, degree\nEducation and experience:\nEngineering Degree.\nExperience at least 2 years of experience in software testing, preferably for cybersecurity products.\nTechnical skills:\nProficiency in testing tools,\nKnowledge of scripting languages and programming languages such as C/C++.\nLanguage: excellent French / English communication skills (both written and spoken).\nInterpersonal skills:\nStrong analytical and problem-solving abilities.\nEffective planning and organizational skills.\nAbility to work independently and as part of a team.\nTerms of employment\nBased in Paris, hybrid work.\nFull time position\nCDI (Contrat \u00e0 Dur\u00e9e Ind\u00e9termin\u00e9e), under French Law.\nSalary competitive and commensurate with experience.\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "C++",
                "R"
            ],
            "DataBase": [],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [],
            "MachineLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [],
            "DevTools": [],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [
                "Teams"
            ],
            "Other": [],
            "FrSoftSkills": [
                "Communication",
                "Collaboration"
            ],
            "EnSoftSkils": [
                "Communication",
                "Collaboration",
                "Organization",
                "Interpersonal Skills"
            ]
        },
        "details": {
            "JobDetail": [
                "Full"
            ],
            "TypeContract": [
                "CDI"
            ],
            "Salary": [
                "Salary"
            ],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "title": "Data Engineer / DevOps H/F",
        "company": "Seyos",
        "location": "St.-Maurice, \u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/data-engineer-devops-h-f-at-seyos-3786210667?position=1&pageNum=15&refId=OMURzinLd5E%2BW2XWlKoc1w%3D%3D&trackingId=I4wCQ10w4vfBbBurtFbRzA%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Description\nNotre client est un\ngrand groupe international\npr\u00e9sent dans plus de 50 pays et qui compte environ 180 000 collaborateurs.\nLeur m\u00e9tier est de concevoir et d\u00e9ployer des solutions qui favorisent le d\u00e9veloppement durable des pays et des entreprises (notamment dans les secteurs de la gestion de l\u2019eau, des d\u00e9chets et de l\u2019\u00e9nergie). L'objectif est de\ndevenir la soci\u00e9t\u00e9 de r\u00e9f\u00e9rence de la transformation \u00e9cologique.\nTr\u00e8s engag\u00e9s en faveur de la plan\u00e8te, avec l'objectif d'un futur meilleur et durable, la soci\u00e9t\u00e9 vous offre la possibilit\u00e9 de donner du sens \u00e0 votre activit\u00e9 professionnelle.\nNous recherchons, pour leur\nDigital Factory\n,\nun\nData Engineer / DevOps\npour rejoindre cette \u00e9quipe et garantir que les clients b\u00e9n\u00e9ficient de la meilleure exp\u00e9rience possible.\nLocalisation :\nSaint-Maurice (\u00cele-de-France)\nR\u00e9mun\u00e9ration :\nEntre 50K\u20ac et 70K\u20ac (selon le profil)\nStack :\nGit, Python ou R, CI/CD, Terraform, AWS SAM, NoSQL\nT\u00e9l\u00e9travail :\n2 jours / semaine\nVos missions :\nCollaborer avec des analystes de donn\u00e9es et des data scientists pour d\u00e9velopper des mod\ufffd\ufffdles de donn\u00e9es, des algorithmes et des pr\u00e9dictions.\nConcevoir, d\u00e9velopper et tester des infrastructures de pipelines de donn\u00e9es ainsi que des syst\u00e8mes de bases de donn\u00e9es.\nVeiller au respect des normes de l'industrie pour toutes les infrastructures et processus de donn\u00e9es actuels, en utilisant des technologies avanc\u00e9es en ing\u00e9nierie des donn\u00e9es.\nTravailler en collaboration avec diff\u00e9rentes \u00e9quipes, internes et externes, pour optimiser la qualit\u00e9 des donn\u00e9es, mettre en \u0153uvre des solutions \u00e9volutives et partager continuellement les connaissances au sein de l'\u00e9quipe.\nProfil recherch\u00e9\nProfil recherch\u00e9 :\nVous poss\u00e9dez une exp\u00e9rience d'au moins cinq ans dans un r\u00f4le de Data Engineer / DevOps.\nVous d\u00e9montrez des comp\u00e9tences avanc\u00e9es en bases de donn\u00e9es relationnelles et NoSQL.\nVous avez une connaissance approfondie des outils d'automatisation et d'infrastructure en tant que code (CI/CD, Terraform, AWS SAM).\nVous ma\u00eetrisez couramment l'anglais et le fran\u00e7ais.\nVous \u00eates familier avec la culture DevOps.\nLes avantages\nUne r\u00e9mun\u00e9ration attractive en fonction de votre exp\u00e9rience.\nTickets Restaurant, Mutuelle, Cong\u00e9s Pay\u00e9s, RTT.\nV\u00e9lo \u00e9lectrique de fonction.\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "R",
                "Go"
            ],
            "DataBase": [
                "SQL",
                "NoSQL"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [],
            "MachineLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [
                "AWS"
            ],
            "DevTools": [
                "Git"
            ],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [
                "Terraform"
            ],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [
                "DevOps",
                "CI/CD"
            ],
            "FrSoftSkills": [
                "Collaboration"
            ],
            "EnSoftSkils": [
                "Collaboration"
            ]
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "title": "Cloud Software Engineer",
        "company": "CIRCLE",
        "location": "Montbonnot-Saint-Martin, Auvergne-Rh\u00f4ne-Alpes, France",
        "link": "https://fr.linkedin.com/jobs/view/cloud-software-engineer-at-circle-3902063618?position=2&pageNum=15&refId=OMURzinLd5E%2BW2XWlKoc1w%3D%3D&trackingId=JL0bQrn8uLyv7qM9mIxbCw%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Circle Anatoscope Intuitive Design est une soci\u00e9t\u00e9 fond\u00e9e en 2016 par Biotech Dental - acteur majeur de l\u2019industrie dentaire en France - et Anatoscope - startup issue en 2015 du CNRS, de l\u2019INRIA et d\u2019universit\u00e9s - r\u00e9cemment rejoints par des g\u00e9ants internationaux du dentaire. Nous d\u00e9veloppons un service web radicalement novateur permettant aux dentistes et proth\u00e9sistes de produire des proth\u00e8ses dentaires de la plus haute qualit\u00e9 et au meilleur co\u00fbt, gr\u00e2ce \u00e0 une int\u00e9gration des flux de sp\u00e9cification, conception et fabrication. Notre application web permet au dentiste de sp\u00e9cifier un diagnostic, un traitement, et de pousser des fichiers d'imagerie issus de scanners 3D intra-oraux. Une proth\u00e8se est automatiquement mod\u00e9lis\u00e9e d\u2019apr\u00e8s l'imagerie du patient et les sp\u00e9cifications de l'appareil, puis le proth\u00e9siste peut la retoucher directement depuis le portail web avec nos outils maison de mod\u00e9lisation 3D. Une fois valid\u00e9e, la proth\u00e8se est export\u00e9e vers des machines de fabrication. Notre soci\u00e9t\u00e9 compte une quarantaine de salari\u00e9s r\u00e9partis dans nos locaux de Grenoble et Montpellier ainsi que divers lieux de t\u00e9l\u00e9travail. C\u2019est une entreprise \u00e0 taille humaine qui veut peser dans l\u2019univers m\u00e9dical, avec de bonnes conditions de travail et compos\u00e9e de gens tr\u00e8s talentueux. Nos valeurs principales sont l'int\u00e9grit\u00e9, la bienveillance et le plaisir.\nNous recherchons un Cloud Software Engineer en CDI.\nVotre p\u00e9rim\u00e8tre concerne notre service de calculs d\u00e9port\u00e9s et de streaming d\u2019applications 3D dans le cloud. Bien qu\u2019invisible des utilisateurs, c\u2019est une pi\u00e8ce centrale de notre solution SaaS permettant aux proth\u00e9sistes et dentistes de travailler sur des applications de CAO \u00e0 la pointe depuis un simple navigateur web sur un ordinateur standard.\n- Membre Dev(Sec)Ops d\u2019une nouvelle \u00e9quipe Cloud mixant d\u00e9veloppeurs et profils sp\u00e9cialis\u00e9s en infrastructure cloud. Cette \u00e9quipe est charg\u00e9e du d\u00e9veloppement et du maintien en condition op\u00e9rationnelle du service de calcul d\u00e9port\u00e9s et de streaming dans le cloud ayant vocation \u00e0 remplacer le syst\u00e8me actuel en production.\n- D\u00e9veloppement de modules et d\u2019API pour notre orchestrateur de conteneurs bas\u00e9 sur Kubernetes\n- D\u00e9veloppement du pipeline de test/versioning/packaging/d\u00e9ploiement\n- Participation au d\u00e9veloppement de notre technologie de streaming - Intervention en tant que support de niveau 3\nTechnologies:\n- Code : Go, Bash, YAML, Python\n- Orchestration : Docker, Kubernetes (k3s) - CI/CD : Gitlab\n- Cloud providers : AWS, GCP - IaC : Terraform, Packer, Ansible\n- OS : Linux (Debian, Ubuntu) - Supervision : Grafana, Loki, Prometheus\n- Streaming: TurboVNC\nProfil recherch\u00e9 :\n- Dipl\u00f4me bac+5\n- Environ 5 ans d\u2019exp\u00e9rience dans un poste similaire\n- Vous \u00eates rigoureux, pragmatique et avez une app\u00e9tence pour le travail bien fait.\n- Vous avez de bonnes capacit\u00e9s de communication et n\u2019h\u00e9sitez pas \u00e0 documenter et partager vos travaux.\nComp\u00e9tences techniques recherch\u00e9es :\n- D\u00e9veloppement dans un contexte web/cloud (back-end / API)\n- Bonnes pratiques de d\u00e9veloppement et de qualit\u00e9 de code (TDD, revues, KISS, linters, couverture)\n- Connaissance fonctionnelle de Kubernetes\n- Ma\u00eetrise de Git - Ma\u00eetrise d\u2019outils de CICD - Ma\u00eetrise de Docker\n- D\u00e9veloppement en Go\nEn plus :\n- D\u00e9veloppement dans Kubernetes (CRD, controllers, operators)\n- Connaissances sur la m\u00e9thodologie DevSecOps - Connaissances sur la supervision d\u2019applications\n- Connaissance en infrastructure cloud - Connaissances sur l\u2019Infrastructure-as-Code (Terraform)\n- Connaissances sur les outils des cloud providers GCP & AWS\n- D\u00e9veloppement en C\nLes conditions et avantages :\n- Lieu de travail : Grenoble (Montbonnot)\n- T\u00e9l\u00e9travail partiel possible\n- Tickets restaurant\n- Indemnit\u00e9 kilom\u00e9trique v\u00e9lo boost\u00e9e\n- Tr\u00e8s bonne compl\u00e9mentaire sant\u00e9 et pr\u00e9voyance\n- Compte Epargne Temps\n- Disponible d\u00e8s que possible\n- Salaire : selon exp\u00e9rience\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "R",
                "Go",
                "Bash"
            ],
            "DataBase": [],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [],
            "MachineLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [
                "AWS"
            ],
            "DevTools": [
                "Git",
                "Docker"
            ],
            "Os": [
                "Linux"
            ],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [
                "Ansible",
                "Kubernetes"
            ],
            "InfrastructureAsCode": [
                "Terraform"
            ],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [
                "Docker",
                "Kubernetes"
            ],
            "Collaboration": [],
            "Other": [
                "ML",
                "Cloud",
                "CI/CD"
            ],
            "FrSoftSkills": [
                "Communication"
            ],
            "EnSoftSkils": [
                "Communication"
            ]
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [
                "CDI"
            ],
            "Salary": [
                "Salaire"
            ],
            "Level": [
                "Bac+5"
            ],
            "Experience": [
                "a",
                "n",
                "s",
                "5",
                "5",
                "5"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "title": "DevOps Engineer Intern",
        "company": "myGwork - LGBTQ+ Business Community",
        "location": "Paris, \u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/devops-engineer-intern-at-mygwork-lgbtq%2B-business-community-3855495327?position=3&pageNum=15&refId=OMURzinLd5E%2BW2XWlKoc1w%3D%3D&trackingId=LE1Aln252qNKOHd1R9%2F2lw%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "This inclusive employer is a member of myGwork \u2013 the largest global platform for the LGBTQ+ business community.\nWhat You'll Do\nThe Platform teams keep one of the largest computing platforms in the AdTech world functioning like clockwork. They keep our products running using a broad selection of technologies, like large scale data compute & storage services (Hadoop, SQL & NoSQL), streaming (Kafka), platform as a service (Chef, Mesos), identity management (Kerberos) and analytics (Hive, Druid, Vertica), as well as an extensive monitoring/observability infrastructure.\nFor the Internship, you will be in a team of 5-7, working closely with your mentor to drive your project, design and ensure best practices are applied. You can ask questions and participate in all knowledge sharing sessions/workshops, etc. You are encouraged to actively voice your ideas whilst learning how to build and ship quality code into production which will likely affect millions of users instantly.\nSkills\nDuring your internship (6 months) and according to your choice, skills and interest, you can tackle one of the following subjects/ teams:\nObservability: Select, test and integegrate a reporting tool with the current stack: Prometheus / Graphite / Gafana / Elasticseach / Kibana. Migrate Grafana to containers and integrate with SSO. Build a log streaming interface\nData Processing: Be part of a team that builds our BigDataFlow platform and writes code to provide insight, give the platform users info about changes impacting their datasets (2) and even hint them about optimization opportunities.\nDistributed System SDKs: Smart cache invalidation in a distributed system.\nContinuous Deployment: Implement a mutation testing solution that is integrated into the Criteo CI/CD pipeline.\nProduct Reliability Engineering: Migrate admin handlers' UI to Angular and help develop a load testing pipeline.\nRivers: Create a Streaming Portal UI.\nData Development Cycle: Leverage the data that we scrape from all our data processing systems to provide automatic monitoring and alerting and in-depth analysis to data producers so that they can understand the sources of delays and make better decisions on the design of their pipeline dependencies.\nWho You Are\nYou are in your final year of study in System/Software Engineering or related fields.\nYou are interested in developing web-based applications and working on Linux environment.\nYou are experienced in Object Oriented Programming.\nYou are a problem solver, a fixer, and a creative technologist. We believe coding is a talent and a passion, not just a skill.\nYou are a strong communicator and a team player who can work efficiently with others.\nYou are fluent in English\nWe acknowledge that many candidates may not meet every single role requirement listed above. If your experience looks a little different from our requirements but you believe that you can still bring value to the role, we\u2019d love to see your application!\nWho We Are\nCriteo is the global commerce media company that enables marketers and media owners to deliver richer consumer experiences and drive better commerce outcomes through its industry leading Commerce Media Platform.\nAt Criteo, our culture is as unique as it is diverse. From our offices around the world or from home, our incredible team of 3,600 Criteos collaborates to develop an open and inclusive environment. We seek to ensure that all of our workers are treated equally, and we do not tolerate discrimination based on race, gender identity, gender, sexual orientation, color, national origin, religion, age, disability, political opinion, pregnancy, migrant status, ethnicity, marital or family status, or other protected characteristics at all stages of the employment lifecycle including how we attract and recruit, through promotions, pay decisions, benefits, career progression and development. We aim to ensure employment decisions and actions are based solely on business-related considerations and not on protected characteristics. As outlined in our Code of Business Conduct and Ethics, we strictly forbid any kind of discrimination, harassment, mistreatment or bullying towards colleagues, clients, suppliers, stakeholders, shareholders, or any visitors of Criteo. All of this supports us in our mission to power the world\u2019s marketers with trusted and impactful advertising encouraging discovery, innovation and choice in an open internet.\nWhy Join Us\nAt Criteo, we take pride in being a caring culture and are committed to providing our employees with valuable benefits that support their physical, emotional and financial wellbeing, their interests and the important life events. We aim to create a place where people can grow and learn from each other while having a meaningful impact. We want to set you up for success in your job, and an important part of that includes comprehensive perks & benefits. Benefits may vary depending on the country where you work and the nature of your employment with Criteo. When determining compensation, we carefully consider a wide range of job-related factors, including experience, knowledge, skills, education, and location. These factors can cause your compensation to vary.\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "R"
            ],
            "DataBase": [
                "SQL",
                "NoSQL"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [
                "Hadoop"
            ],
            "MachineLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [],
            "DevTools": [],
            "Os": [
                "Linux"
            ],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [
                "Chef"
            ],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [
                "Teams"
            ],
            "Other": [
                "CI/CD"
            ],
            "FrSoftSkills": [],
            "EnSoftSkils": []
        },
        "details": {
            "JobDetail": [
                "Full"
            ],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "title": "Site Reliability Engineer (SRE/Devops) M/F",
        "company": "Splio",
        "location": "Paris, \u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/site-reliability-engineer-sre-devops-m-f-at-splio-3826118662?position=4&pageNum=15&refId=OMURzinLd5E%2BW2XWlKoc1w%3D%3D&trackingId=suMq6aC%2Fsox4vPETJLCcAw%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "L'entreprise\nSplio est une scale-up du march\u00e9 des technologies marketing et digitales\ndont le si\u00e8ge est \u00e0 Paris (Op\u00e9ra). L\u2019entreprise compte plus de 250 collaborateurs et 4 bureaux en Europe et MEA.\nSplio \u00e9dite une plateforme marketing SaaS\nqui int\u00e8gre CDP et Marketing Automation ainsi que toutes les fonctionnalit\u00e9s essentielles du CRM (fid\u00e9lit\u00e9, Mobile Wallets), en une seule et m\u00eame plateforme boost\u00e9e \u00e0 l\u2019IA.\nLa plateforme permet aux \u00e9quipes CRM du retail, e-commerce, FMCG et des T\u00e9l\u00e9coms de communiquer et fid\u00e9liser leurs clients de fa\u00e7on personnalis\u00e9e sur tous les canaux (email, SMS, Push Wallet...)\nPlus de 500 entreprises du retail, e-commerce, FMCG et des T\u00e9l\u00e9coms, \u00e0 travers l\u2019Europe et le MEA utilisent Splio au quotidien, parmi lesquelles Nature et D\u00e9couvertes, Longchamp, Bazarchic, APC, The Kooples, Fnac-Darty, Micromania, Faguo, Cyrillus, Orange ou encore Samsung.\nLe poste\nL'\u00e9quipe SRE est responsable de la disponibilit\u00e9 de la plateforme, de son \u00e9volution et de sa s\u00e9curisation. En rejoignant l'\u00e9quipe SRE, tu seras rattach\u00e9(e) au SRE Manager et en charge de l'infrastructure de la plateforme Splio, qui est h\u00e9berg\u00e9e majoritairement sur AWS et GCP.\nTes objectifs sont d'automatiser le d\u00e9ploiement de la plateforme et d'aider \u00e0 maintenir l'\u00e9volution de la plateforme, la scalabilit\u00e9 et les faibles co\u00fbts d'infrastructure. Plus pr\u00e9cis\u00e9ment, tes principales missions seront les suivantes:\nCr\u00e9er et d\u00e9ployer de nouvelles solutions\nAssurer la disponibilit\u00e9 de la plateforme\nAutomatiser le d\u00e9ploiement de la plateforme\nTravailler avec les \u00e9quipes R&D et Product Management pour le d\u00e9ploiement de l'application en utilisant CI/CD\nG\u00e9rer l'astreinte toutes les 6 \u00e0 8 semaines (en alternance avec les autres membres de l'\u00e9quipe)\nAm\u00e9liorer continuellement la s\u00e9curit\u00e9 de la plateforme : maintenir les acc\u00e8s, appliquer les mises \u00e0 jour, cr\u00e9er une architecture s\u00e9curis\u00e9e.\nEnvironnement technique\nCloud: GCP et AWS\nTerraform /Terragrunt\nLinux (Debian) / Open Source ADN\nPuppet\nBigQuery / MySQL/ Clickhouse/ Redis / PostGresSQL would be a plus\nKafka / Pulsar\nKubernetes & Docker\nCI / CD: Gitlab EE.\nOpensearch / Prometheus / Grafana\nProfil recherch\u00e9\nAu moins 3 ans d'exp\u00e9rience en tant que DevOps/SRE.\nMa\u00eetrise de GCP: CloudRun, Composer, BigQuery, IAM.\nEnvie de se perfectionner sur AWS\n\u00catre curieux et autonome, aimer partager ses connaissances avec ses coll\u00e8gues\nExcellente capacit\u00e9 d'organisation et capacit\u00e9 \u00e0 travailler dans un environnement agile\nBonne communication orale et \u00e9crite en anglais et en fran\u00e7ais\nAvantages\n\ud83c\udf34 12 Splio days (jours off), en plus des 25 jours cong\u00e9s l\u00e9gaux\n\ud83d\udecb\ufe0f Politique de remote : 5 jours au bureau par mois dans l\u2019une des villes o\u00f9 Splio a un bureau (Paris, Barcelone, Tunis)\n\ud83d\ude0b Une carte swile pour les repas (\u00e0 raison de 10\u20ac par jour)\n\ud83d\udc68\u200d\ud83d\udc69\u200d\ufffd\ufffd\u200d\ud83d\udc66 Possibilit\u00e9 de se rendre ou de participer \u00e0 des conf\u00e9rence une ou deux fois par an\nInt\u00e9ress\u00e9(e) ? Rejoins-nous !\n45 minutes d'entretien en visio avec notre HRBP pour apprendre \u00e0 te conna\u00eetre et \u00e9changer sur tes exp\u00e9riences et motivations \u00e0 rejoindre Splio.\n45 minutes d'entretien en visio avec Yvan Leizour, SRE Manager et Romain Concaud, Devops Manager pour \u00e9changer plus en d\u00e9tail sur le r\u00f4le de SRE.\n1 heure de cas pratique dans notre bureau \u00e0 Paris avec une partie Q&A afin d'\u00e9valuer tes comp\u00e9tences techniques.\n30 minutes d'\u00e9change en visio avec notre CTO\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Scala",
                "R"
            ],
            "DataBase": [
                "SQL"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [],
            "MachineLearning": [
                "Orange"
            ],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [
                "AWS"
            ],
            "DevTools": [
                "Git",
                "Docker"
            ],
            "Os": [
                "Linux"
            ],
            "DBMS": [
                "MySQL",
                "BigQuery"
            ],
            "SoftBigDataProcessing": [],
            "Automation": [
                "Kubernetes",
                "Puppet"
            ],
            "InfrastructureAsCode": [
                "Terraform"
            ],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [
                "Docker",
                "Kubernetes"
            ],
            "Collaboration": [],
            "Other": [
                "DevOps",
                "Cloud",
                "CI/CD",
                "CI / CD"
            ],
            "FrSoftSkills": [
                "Communication",
                "Organisation"
            ],
            "EnSoftSkils": [
                "Communication"
            ]
        },
        "details": {
            "JobDetail": [
                "Remote"
            ],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s",
                "3",
                "3",
                "3"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "title": "Software Engineer",
        "company": "Orange Logic",
        "location": "France",
        "link": "https://fr.linkedin.com/jobs/view/software-engineer-at-orange-logic-3862540191?position=5&pageNum=15&refId=OMURzinLd5E%2BW2XWlKoc1w%3D%3D&trackingId=ahz1vwdhoO2r2BJgm85HLw%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "For more than two decades, Orange Logic has empowered a wide range of clients with its digital asset management system, Cortex. We\u2019ve worked with almost every industry, from Finance to NGOs, Media giants to educational institutions, securing and organizing their assets. The Software Engineer will enhance Orange Logic\u2019s software by participating in the design, development, maintenance and testing process.\nWhat you can expect in your role:\nTaking ownership of projects and having the opportunity to further your knowledge by exploring machine learning, security, DevOps, and more.\nDeveloping scalable new features for our software product that exceeds our customer\u2019s needs.\nBuilding architecture for our platform to ensure optimal performance.\nObtaining requirement feedback from internal teams/clients to maintain/support the product development.\nWrite the Unit Tests for robust development.\nPerforming code reviews on other team member\u2019s work.\nYou are:\nProficient with English (both verbal and written).\nHave 3+ years\u2019 practical experience on a web-based application.\nProficient with any backend programming languages (e.g. .NET, Java, Python, etc.).\nA strong fundamental understanding of software development.\nAn understanding of complex algorithms and data structures, as well as a passion for intellectual challenges.\nStrong self-discipline for delivering well-tested, complete features/modules under a tight schedule and the capability for rational thinking.\nExperience with the database management tool SQL is a plus, but not mandatory.\nObtained bachelor\u2019s degree in any relevant major (e.g. Information Technology, Computer Science, etc.).\nPerks of joining the team:\nCompetitive compensation & benefits package\nRemote Work Environment\nHow to get started:\nIf you\u2019re up for the challenge to be part of a growing engineering team we\u2019d like to hear from you. Apply today!\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "Java",
                "Scala",
                "R",
                "Go"
            ],
            "DataBase": [
                "SQL"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [],
            "MachineLearning": [
                "Orange"
            ],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [],
            "DevTools": [
                "Git"
            ],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [
                "Teams"
            ],
            "Other": [
                "DevOps",
                "Machine Learning"
            ],
            "FrSoftSkills": [],
            "EnSoftSkils": []
        },
        "details": {
            "JobDetail": [
                "Remote"
            ],
            "TypeContract": [],
            "Salary": [
                "Package"
            ],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "title": "Cloud & Data Engineer",
        "company": "SFEIR",
        "location": "Paris, \u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/cloud-data-engineer-at-sfeir-3634254863?position=6&pageNum=15&refId=OMURzinLd5E%2BW2XWlKoc1w%3D%3D&trackingId=WnHVbLlS8LX6FhUg7GWXdA%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "C'est quoi SFEIR ? \ud83e\udd14\nSFEIR, c'est avant tout une communaut\u00e9 de 900 Techs en France, en Belgique et au Luxembourg.\nNous aidons nos clients \u00e0 :\nD\u00e9velopper des applications web et mobiles pour am\u00e9liorer leur exp\u00e9rience client et se connecter partout ;\n\u00catre compatible avec le futur en d\u00e9veloppant leurs architectures SI, Cloud et Data\nDonner de la valeur \u00e0 leurs donn\u00e9es, innover avec l\u2019IA ;\nCr\u00e9er de la valeur gr\u00e2ce aux API & microservices.\nNotre culture d'entreprise est r\u00e9solument tourn\u00e9e vers l'expertise technologique, la transmission de connaissances et le respect de nos valeurs phares : bienveillance, inclusivit\u00e9, excellence, libert\u00e9, responsabilit\u00e9.\nSFEIR Paris c\u2019est aussi :\n\ud83d\udd39 Une agence co-dirig\u00e9e par Cyril Balit & Arnaud Waller\n\ud83d\udd39 400 Experts, dont 100 Sfeiriens sur l\u2019expertise Data\n\ud83d\udd39 70 clients actifs en Ile-de-France et 120 au niveau du Groupe\n\ud83d\udd39 41 Engineering Managers pour un suivi de proximit\u00e9\n\ud83d\udd39 370 certifications obtenues en 2022\n\ud83d\udd39 Des \u00e9v\u00e8nements en interne organis\u00e9s chaque mois (afterworks, meetups, formations)\n\ud83d\udd39 Une communaut\u00e9 active : une cinquantaine de conf\u00e9rences donn\u00e9es en 2022 (Devoxx \u2026)\nConcr\u00e8tement, quel sera mon job ?\nEn mission pour un client sur des stacks r\u00e9centes, vous concevez et vous d\u00e9veloppez des solutions logicielles en Python.\nChez nous, tu ne feras pas de TMA \u2026 Mais tu travailleras des projets de transformation ou de build de nouveaux produits \ud83d\ude09 .\nAu-del\u00e0 de ta ma\u00eetrise du python et de son \u00e9cosyst\u00e8me (ex : sql,terraform \u2026) tu es quelqu'un de curieux(se) et dans le partage !\nPar exemple :\n@Vincent, Data Engineer chez SFEIR, construit la plateforme de donn\u00e9es d'une soci\u00e9t\u00e9 historique de livraison et de suivi de colis, au sein d'un \u00e9cosyst\u00e8me Cloud. Cette plateforme a pour premi\u00e8re vocation d'aider au pilotage op\u00e9rationnel de l'activit\u00e9 et doit \u00eatre suffisamment \u00e9volutive pour accueillir les besoins qu'exprimeront les \u00e9quipes m\u00e9tiers. Je travaille sur la Stack suivante : Talend, Cloud Composer, BigQuery, DBT, Power BI\n@Thibaud intervient sur diff\u00e9rents projets ML en tant que Senior ML Engineer et ML Architect. Il va travailler sur la conception d'application ML et sur la mise en \u0153uvre d'algorithmes et d'outils ML appropri\u00e9s sur Google Cloud (Vertex IA, BigQUery, Storage,...) dans le secteur automotive.\nEt si je souhaite \u00e9voluer ?\nNous proposons des possibilit\u00e9s d'\u00e9volution verticales et horizontales.\nTu auras \u00e9galement la possibilit\u00e9 de prendre des r\u00f4les en interne si tu le souhaites :\n\ud83d\udd39 \u00c9valuateur\u00b7rice dans le process de recrutement\n\ud83d\udd39 Formateur\u00b7rice aux Sfeir Schools ou avec Sfeir Institute\n\ud83d\udd39 Speaker\u00b7euse lors de conf\u00e9rences, meetups, talks internes, aupr\u00e8s des \u00e9coles\n\ud83d\udd39 Engineering Manager si tu veux manager une \u00e9quipe tout en restant dans la technique\nEt si tu as d'autres envies, on en discute, chacun est diff\u00e9rent et on fait au cas par cas.\nA quelle r\u00e9mun\u00e9ration je peux pr\u00e9tendre chez SFEIR ?\nChez nous, pas de grille de salaire fig\u00e9e dans le marbre !\nSFEIR collecte vos donn\u00e9es \u00e0 caract\u00e8re personnel afin de traiter votre candidature. Pour en savoir plus sur la gestion de vos donn\u00e9es personnelles et pour exercer vos droits, nous vous invitons \u00e0 consulter notre Politique de confidentialit\u00e9 .\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "R",
                "Go"
            ],
            "DataBase": [
                "SQL"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [],
            "MachineLearning": [],
            "DataSerialization": [],
            "DataVisualization": [
                "Power BI"
            ],
            "Statistics": [],
            "CloudComputing": [],
            "DevTools": [],
            "Os": [],
            "DBMS": [
                "BigQuery"
            ],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [
                "Terraform"
            ],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [
                "ML",
                "Cloud"
            ],
            "FrSoftSkills": [],
            "EnSoftSkils": []
        },
        "details": {
            "JobDetail": [
                "Senior"
            ],
            "TypeContract": [],
            "Salary": [
                "Salaire"
            ],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "title": "Data Engineer (H/F)",
        "company": "Technology & Strategy",
        "location": "Lyon, Auvergne-Rh\u00f4ne-Alpes, France",
        "link": "https://fr.linkedin.com/jobs/view/data-engineer-h-f-at-technology-strategy-3881556102?position=7&pageNum=15&refId=OMURzinLd5E%2BW2XWlKoc1w%3D%3D&trackingId=D%2FbgsGCBYAQl67OwvcCsPQ%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "D\u00e9couvrez Novencia\n:\nExpert en Data et Intelligence Artificielle, nous aidons nos clients \u00e0 exploiter et \u00e0 valoriser leurs donn\u00e9es sous toutes ses formes en les accompagnant sur des projets de Data Analyse, Data Gourvernance, Data Architecture, Data Science, et Data Engineering\u2026\nVous avez une solide exp\u00e9rience de minimum 2 ans dans l'ing\u00e9nierie des donn\u00e9es et vous \u00eates \u00e0 la recherche de nouveaux d\u00e9fis ? Bouclez votre ceinture, la suite est pour vous !\nType de contrat : CDI\nLieu : Lyon\nEn qualit\u00e9 de Data Engineer (H/F), votre r\u00f4le sera :\nConcevoir et proposer les solutions de d\u00e9veloppement r\u00e9pondant aux besoins fonctionnels et techniques des projets big data.\nTu participes \u00e0 la conception de solutions permettant le traitement de volumes importants de pipelines donn\u00e9es.\nR\u00e9aliser ces solutions par l\u2019\u00e9criture de code, en respectant les m\u00e9thodes et proc\u00e9dures qualit\u00e9s d\u00e9finies au sein du d\u00e9partement Technique.\nMise \u00e0 disposition s\u00e9curis\u00e9 et lisible de la data.\nS\u2019assurer de la conformit\u00e9 fonctionnelle et technique de ces r\u00e9alisations en effectuant les tests automatis\u00e9s n\u00e9cessaire et la mise en place de monitoring (syst\u00e8me et qualit\u00e9).\nAssurer la maintenance des applicatifs / plateforme data science\nAssurer une veille technologique\nVous disposez des comp\u00e9tences suivantes :\nMaitrise des plateformes Cloud (AWS, GCP ou Azure), de Scala et de SQL.\nUn.e touche \u00e0 tout : poss\u00e9dant des comp\u00e9tences en langage Python/Spark, de bonnes capacit\u00e9s de mod\u00e9lisation, une forte app\u00e9tence pour le Big Data\nFin.e connaisseur.euse : Data Engineer convaincu, tr\u00e8s peu de secrets pour les clusters et pour les calculs parall\u00e8les\nExplorateur.trice : d\u00e9couvre de nouvelles technos gr\u00e2ce \u00e0 une veille r\u00e9guli\u00e8re\nD\u00e9brouillard.e : rel\u00e8ve de nouveaux d\u00e9fis\nNotre objectif commun est de co-construire votre carri\u00e8re en fonction de vos aspirations et de vos comp\u00e9tences.\nContactez-moi en message priv\u00e9 ou par mail \u00e0 s.ziki@technologyandstrategy.com !\nLet's make it possible #together\n*Nos postes sont ouverts aux personnes b\u00e9n\u00e9ficiant d\u2019une Reconnaissance de la Qualit\u00e9 de Travailleur Handicap\u00e9 (RQTH). T&S Groupe encourage la diversit\u00e9 et l\u2019\u00e9galit\u00e9 sur le lieu de travail. Tous les candidats qualifi\u00e9s H/F/* sont pris en consid\u00e9ration pour un emploi sur un m\u00eame pied d'\u00e9galit\u00e9.\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "Scala",
                "R",
                "Go"
            ],
            "DataBase": [
                "SQL"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [
                "Spark"
            ],
            "MachineLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [
                "AWS",
                "Azure"
            ],
            "DevTools": [],
            "Os": [],
            "DBMS": [],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [
                "Big Data",
                "Cloud"
            ],
            "FrSoftSkills": [],
            "EnSoftSkils": []
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [
                "CDI"
            ],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s",
                "2",
                "2",
                "2"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "title": "Data Engineer - Bordeaux",
        "company": "Capgemini",
        "location": "Bordeaux, Nouvelle-Aquitaine, France",
        "link": "https://fr.linkedin.com/jobs/view/data-engineer-bordeaux-at-capgemini-3889788624?position=8&pageNum=15&refId=OMURzinLd5E%2BW2XWlKoc1w%3D%3D&trackingId=ziv0UCdYzrS%2B%2FMwV51It7Q%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Choisir Capgemini, c'est choisir une entreprise o\u00f9 vous serez en mesure de fa\u00e7onner votre carri\u00e8re selon vos aspirations. Avec le soutien et l'inspiration d'une\ncommunaut\u00e9 d\u2019experts dans le monde entier, vous pourrez r\u00e9\u00e9crire votre futur. Rejoignez-nous pour red\u00e9finir les limites de ce qui est possible, contribuer \u00e0 lib\u00e9rer la\nvaleur de la technologie pour les plus grandes organisations et participer \u00e0 la construction d\u2019un monde plus durable et inclusif.\nVos missions :\nVous \u00eates passionn\u00e9 par le domaine de la Data, vous souhaitez prendre part \u00e0 des projets d'envergure, concevoir des solutions, les impl\u00e9menter et les faire \u00e9voluer?\nAlors rejoignez notre \u00e9quipe Data Engineering Services au sein de Capgemini Cloud Infrastructure Services en tant que Data Engineer.\nVous avez acquis une exp\u00e9rience solide dans le d\u00e9veloppement, la mise en \u0153uvre et l\u2019optimisation de solutions pour le traitement d'un grand volume de donn\u00e9es, vous \u00eates capable de cr\u00e9er des solutions qui r\u00e9pondent aux besoins m\u00e9tiers et IT, alors rejoignez notre \u00e9quipe d\u2019experts.\nEn qualit\u00e9 de Data engineer, vos missions sont les suivantes :\n\u25aa Concevoir et d\u00e9velopper des solutions Data/IA.\n\u25aa Accompagner les M\u00e9tier dans la compr\u00e9hension et la mise en \u0153uvre de solution orient\u00e9es donn\u00e9es.\n\u25aa Collaborer avec les Dev, les Ops, les experts infrastructures dans la construction de solutions et d\u2019infrastructures ax\u00e9es sur les donn\u00e9es.\n\u25aa G\u00e9rer un \u00e9cosyst\u00e8me de partenaires data et assurer un haut niveau d'expertise\n\u25aa Assurer un r\u00f4le de veille technologique sur tous les outils autours de la data, de l\u2019IA et de la BI.\nVotre profil :\nVous \u00eates issu d\u2019une formation ing\u00e9nieur ou \u00e9quivalent bac+5 informatique sp\u00e9cialis\u00e9e en DATA et vous justifiez d\u2019une exp\u00e9rience de 3 \u00e0 5 ans dans un r\u00f4le similaire. Expert dans une technologie de base de donn\u00e9es relationnelle (PostgreSQL, Oracle...)\nExpert dans une technologie de base NoSQL (MongoDB, Cassandra...)\nVous maitrisez un framework de manipulation de donn\u00e9es (Hadoop, Spark, Kafka...)\nVous maitrisez les concepts DevOps et avez de bonnes notions en scripting et d\u00e9veloppement\nVous avez une exp\u00e9rience des outils BI et de data visualisation (Kibana, PowerBI...)\nLa maitrise de l'anglais est n\u00e9cessaire.\n3 raisons de nous rejoindre :\nQualit\u00e9 de vie au travail :\naccord de t\u00e9l\u00e9travail en France et \u00e0 l\u2019international, accord sur l\u2019\u00e9galit\u00e9 professionnelle, la parentalit\u00e9, l\u2019\u00e9quilibre des temps et la mobilit\u00e9 durable.\nApprentissage en continu :\ncertifications et formations en libre acc\u00e8s, accompagnement sur mesure avec votre career manager, parcours d\u2019int\u00e9gration sur 9 mois.\nAvantages groupe & CSE :\nplan actionnariat, tarif pr\u00e9f\u00e9rentiels, remboursement partiel vacances, remboursement de votre abonnement sportif ou culture\nNos engagements et priorit\u00e9s :\nLe groupe Capgemini encourage une culture inclusive dans un cadre multiculturel et handi-accueillant. En nous rejoignant, vous int\u00e9grez un collectif qui valorise la diversit\u00e9, d\u00e9veloppe le potentiel de ses talents, s\u2019engage dans des initiatives solidaires avec ses partenaires, et se mobilise pour r\u00e9duire son impact environnemental sur tous ses sites et aupr\u00e8s de ses clients.\n\u00c0 propos de Capgemini :\nCapgemini est un leader mondial, responsable et multiculturel, regroupant pr\u00e8s de 350 000 personnes dans plus de 50 pays. Fort de 55 ans d\u2019exp\u00e9rience, nous sommes un partenaire strat\u00e9gique des entreprises pour la transformation de leurs activit\u00e9s en tirant profit de toute la puissance de la technologie et des innovations dans les domaines en perp\u00e9tuelle \u00e9volution tels que le cloud, la data, l\u2019Intelligence Artificielle, la connectivit\u00e9, les logiciels, l\u2019ing\u00e9nierie digitale ou les plateformes.\nGet The Future You Want* | www.capgemini.com/fr-fr\n*Capgemini, le futur que vous voulez\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "R",
                "Go"
            ],
            "DataBase": [
                "SQL",
                "NoSQL",
                "Cassandra"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [
                "Hadoop",
                "Spark"
            ],
            "MachineLearning": [],
            "DataSerialization": [],
            "DataVisualization": [
                "PowerBI"
            ],
            "Statistics": [],
            "CloudComputing": [],
            "DevTools": [
                "Git"
            ],
            "Os": [],
            "DBMS": [
                "PostgreSQL",
                "Oracle"
            ],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [
                "DevOps",
                "Cloud"
            ],
            "FrSoftSkills": [
                "Organisation"
            ],
            "EnSoftSkils": [
                "Initiative"
            ]
        },
        "details": {
            "JobDetail": [],
            "TypeContract": [],
            "Salary": [],
            "Level": [
                "Bac+5"
            ],
            "Experience": [
                "a",
                "n",
                "s",
                "5",
                "5",
                "5"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "title": "Ing\u00e9nieur Cloud (F/H)",
        "company": "Yooz",
        "location": "Montpellier, Occitanie, France",
        "link": "https://fr.linkedin.com/jobs/view/ing%C3%A9nieur-cloud-f-h-at-yooz-3903672660?position=9&pageNum=15&refId=OMURzinLd5E%2BW2XWlKoc1w%3D%3D&trackingId=7i8ltvEXzTU9kGz5RVtmhA%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Avec plus de 200 000 utilisateurs dans plus de 40 pays, nous recherchons des personnalit\u00e9s passionn\u00e9es et engag\u00e9es, pour continuer \u00e0 am\u00e9liorer la satisfaction de nos clients et renforcer notre position de leader sur le march\u00e9.\nCertifi\u00e9e Great Place To Work, notre entreprise offre des conditions de travail agr\u00e9ables, tant au niveau des locaux (\u00e0 Aimargues ou\u00a0Montpellier), du rythme (hybride, ouvert au t\u00e9l\u00e9travail) que des activit\u00e9s (foot, crossfit, boxe, piscine ext\u00e9rieure accessible librement) pour renforcer la coh\u00e9sion d\u2019\u00e9quipe.\nNotre division\nIT\nrecherche aujourd\u2019hui\nun(e) Cloud Operation Engineer, en CDI.\nA ce titre, vous serez en charge de :\nAssurer la maintenance et le suivi des plateformes Yooz Linux, avec Prometheus, Grafana, et autres.\nAssurer la maintenance des plateformes Yooz Windows.\nSuivre le maintien en condition op\u00e9rationnelle de nos databases et applications, des serveurs et r\u00e9soudre les incidents/anomalies potentiel(le)s.\nAccompagner nos \u00e9quipes sur leurs probl\u00e9matiques d'infrastructure.\nCollaborer avec le support Azure Cloud et utiliser les outils associ\u00e9s \u00e0 Microsoft Azure.\nVos atouts pour ce r\u00f4le :\nDe Formation Bac+3, ou \u00e9quivalent, vous disposez d'une exp\u00e9rience confirm\u00e9e sur des fonctions similaires.\nVous \u00eates rigoureux(se) et m\u00e9ticuleux(se).\nVous \u00eates \u00e0 l'aise dans des environnements Windows et Linux.\nVous disposez de connaissances solides en r\u00e9seau et s\u00e9curit\u00e9, en gestion de bases de donn\u00e9es (PostgreSQL).\nVous \u00eates \u00e0 l'aise avec l'utilisation de scripts Linux (Shell, Python), de Microsoft PowerShell et, id\u00e9alement, de Javascript.\nLa ma\u00eetrise de l\u2019anglais est souhait\u00e9e.\nPourquoi rejoindre Yooz ?\nYooz est une entreprise o\u00f9 plus de 95% des collaborateurs estiment qu\u2019il fait vraiment bon travailler.\nEquit\u00e9, respect, convivialit\u00e9, cr\u00e9dibilit\u00e9\nmais aussi\nfiert\u00e9\nsont autant de valeurs mises en avant par les 450 salari\u00e9s du groupe au travers de notre label Great Place to Work.\nNous veillons chaque jour \u00e0 cr\u00e9er un cadre de travail positif et \u00e9panouissant pour que chacun puisse \u00e9voluer dans les meilleures conditions.\nVous pensez correspondre \u00e0 nos valeurs et \u00e0 cette opportunit\u00e9 ? N\u2019h\u00e9sitez plus et adressez-nous votre candidature !\nYooz est une entreprise multiculturelle engag\u00e9e en mati\u00e8re d\u2019\u00e9galit\u00e9 professionnelle. Nous sommes convaincus que notre force r\u00e9side en la diversit\u00e9 de nos talents, et sommes fiers de garantir un acc\u00e8s \u00e9gal \u00e0 l\u2019emploi et aux promotions \u00e0 tous nos candidats et employ\u00e9s, quel que soit leur sexe, origine, orientation sexuelle, religion, handicap, \u00e2ge, ou tout autre statut prot\u00e9g\u00e9 par la loi. Yooz luttera toujours contre toute forme de discrimination et de harc\u00e8lement.\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "Java",
                "R",
                "Go",
                "JavaScript"
            ],
            "DataBase": [
                "SQL"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [],
            "MachineLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [
                "Azure"
            ],
            "DevTools": [],
            "Os": [
                "Linux",
                "Windows"
            ],
            "DBMS": [
                "PostgreSQL"
            ],
            "SoftBigDataProcessing": [],
            "Automation": [],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [],
            "Collaboration": [],
            "Other": [
                "Cloud"
            ],
            "FrSoftSkills": [],
            "EnSoftSkils": []
        },
        "details": {
            "JobDetail": [
                "Hybride",
                "Confirm\u00e9"
            ],
            "TypeContract": [
                "CDI"
            ],
            "Salary": [],
            "Level": [
                "Bac+3"
            ],
            "Experience": [
                "a",
                "n",
                "s"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "title": "Software Engineer (Crawling)",
        "company": "Wiser Solutions, Inc.",
        "location": "Paris, \u00cele-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/software-engineer-crawling-at-wiser-solutions-inc-3909448442?position=10&pageNum=15&refId=OMURzinLd5E%2BW2XWlKoc1w%3D%3D&trackingId=mYbGAMFcu1ogDwmgUp4Ojg%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Wiser Solutions is a suite of in-store and eCommerce intelligenceand execution tools. We're on a mission to enable brands, retailers, and retail channel partners to gather intelligence and automate actions to optimize in-store and online pricing, marketing, and operations initiatives. Our Commerce Execution Suite is available globally.\nJob Description\nLocation: Remote in France\nVeuillez soumettre votre curriculum vitae en anglais\nNous recherchons un Software Engineer (Crawling) hautement qualifi\u00e9 pour \u00eatre un contributeur essentiel au d\u00e9veloppement de notre suite de crawlers et d'extractions. Si vous aimez travailler sur des probl\u00e8mes complexes et \u00e9crire un code propre, vous allez adorerer ce r\u00f4le. Notre objectif est de r\u00e9soudre un probl\u00e8me complexe. Notre travail consiste \u00e0 collecter, cat\u00e9goriser et analyser des donn\u00e9es semi-structur\u00e9es provenant de diff\u00e9rentes sources (plus de 200 millions de produits provenant de plus de 100 sites Web dans notre catalogue de plus de 500 millions de produits). Nous aidons nos clients \u00e0 d\u00e9couvrir de nouveaux mod\u00e8les dans leurs donn\u00e9es pouvant \u00eatre exploit\u00e9s afin qu'ils deviennent plus comp\u00e9titifs et augmentent leurs revenus.\nFonctions essentielles:\nD\u00e9velopper et maintenir divers crawlers et composants c\u00f4t\u00e9 serveur.\nAssurer des performances optimales des diff\u00e9rentes bases de donn\u00e9es et une r\u00e9activit\u00e9 aux demandes frontend.\nD\u00e9velopper des applications haute performance en \u00e9crivant un code testable, r\u00e9utilisable et efficace.\nMettre en place des protocoles de s\u00e9curit\u00e9 efficaces, des mesures de protection des donn\u00e9es et des solutions de stockage.\nEffectuer des tests diagnostiques, r\u00e9parer les d\u00e9fauts et fournir un support technique.\nDocumenter les processus, y compris les sch\u00e9mas de base de donn\u00e9es, ainsi que pr\u00e9parer des rapports.\nRecommander et mettre en \u0153uvre des am\u00e9liorations aux processus et technologies.\nApporter de nouvelles id\u00e9es \u00e0 la table - certaines de nos meilleures innovations viennent de l'\u00e9quipe.\nTechnologies utilis\u00e9es:\nLangages : La ma\u00eetrise de Python, JavaScript (JS), HTML et SQL est essentielle.\nEnvironnement : Exp\u00e9rience avec la Google Cloud Platform (GCP), Kubernetes, les pratiques d'int\u00e9gration continue et de d\u00e9ploiement continu (CI/CD), GitHub etCircleCI.\nMariaDB, MySQL, MongoDB\nQualifications\nExp\u00e9rience : Un minimum de 3 ans dans un domaine pertinent est requis.\nProtocoles : Bonne compr\u00e9hension des protocoles TCP/IP et HTTP.\nConnaissance en s\u00e9curit\u00e9 Web : Familiarit\u00e9 avec les principes et pratiques de s\u00e9curit\u00e9 Web.\nSyst\u00e8mes : Comp\u00e9tent dans le travail avec les syst\u00e8mes d'exploitation bas\u00e9s sur Linux, notamment Debian et Ubuntu.\nM\u00e9thodologie : Les m\u00e9thodologies Agile et Scrum devraient \u00eatre naturelles.\nExcellentes comp\u00e9tences interpersonnelles, de communication et de collaboration.\nExpertise en d\u00e9veloppement back-end en utilisant Python.\nCompr\u00e9hension solide de la GCP, de Kubernetes et des concepts d'infrastructure.\nComp\u00e9tences en programmation RDBMS & SQL (l'exp\u00e9rience avec MYSQL, MariaDB & MongoDB est un plus).\nCe poste peut n\u00e9cessiter d\u2019\u00eatre sur appel pour r\u00e9soudre des probl\u00e8mes critiques li\u00e9s aux applications de production en dehors des heures normales de travail.\nFacultatif:\nConnaissance facultative de l'intelligence artificielle (IA) et de l'apprentissage automatique (ML), de l'analyse de donn\u00e9es et de AWS serait un plus.\nPoints bonus:\nExp\u00e9rience de travail sur des environnements de microservices ou de syst\u00e8mes distribu\u00e9s.\nExp\u00e9rience avec la conception orient\u00e9e domaine.\nExp\u00e9rience avec la mod\u00e9lisation C4.\nExp\u00e9rience de travail dans un environnement de vente au d\u00e9tail ou de commerce \u00e9lectronique\nAdditional Information\nEEO STATEMENT\nWiser Solutions, Inc. is an Equal Opportunity Employer and prohibits Discrimination, Harassment, and Retaliation of any kind. Wiser Solutions, Inc. is committed to the principle of equal employment opportunity for all employees and applicants, providing a work environment free of discrimination, harassment, and retaliation. All employment decisions at Wiser Solutions, Inc. are based on business needs, job requirements, and individual qualifications, without regard to race, color, religion, sex, national origin, family or parental status, disability, genetics, age, sexual orientation, veteran status, or any other status protected by the state, federal, or local law. Wiser Solutions, Inc. will not tolerate discrimination, harassment, or retaliation based on any of these characteristics.\nShow more\nShow less",
        "skills": {
            "ProgLanguage": [
                "Python",
                "Java",
                "R",
                "Go",
                "JavaScript",
                "HTML"
            ],
            "DataBase": [
                "SQL",
                " MongoDB"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [],
            "MachineLearning": [],
            "DataSerialization": [],
            "DataVisualization": [],
            "Statistics": [],
            "CloudComputing": [
                "AWS",
                "Google Cloud Platform"
            ],
            "DevTools": [
                "Git"
            ],
            "Os": [
                "Linux"
            ],
            "DBMS": [
                "MySQL"
            ],
            "SoftBigDataProcessing": [],
            "Automation": [
                "Kubernetes"
            ],
            "InfrastructureAsCode": [],
            "NetworkSecurty": [],
            "Virtualisation": [],
            "Containers": [
                "Kubernetes"
            ],
            "Collaboration": [],
            "Other": [
                "ML",
                "Cloud",
                "CI/CD"
            ],
            "FrSoftSkills": [
                "Communication",
                "Collaboration"
            ],
            "EnSoftSkils": [
                "Communication",
                "Collaboration",
                "Initiative"
            ]
        },
        "details": {
            "JobDetail": [
                "Remote"
            ],
            "TypeContract": [],
            "Salary": [],
            "Level": [],
            "Experience": [
                "a",
                "n",
                "s",
                "3",
                "3",
                "3"
            ]
        }
    }
]