[
    {
        "source": "LinkedIn",
        "company": "Cephalgo",
        "location": "France",
        "link": "https://fr.linkedin.com/jobs/view/data-scientist-ai-at-cephalgo-3817203204?position=2&pageNum=0&refId=SmRHYtKKcb%2BBbb%2BiSm10Sw%3D%3D&trackingId=bmnDaod1rkV77fBraMR3GA%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "The ideal candidate's favorite words are learning, data, scale, and agility. You will leverage your strong collaboration skills and ability to extract valuable insights from highly complex data sets to ask the right questions and find the right answers.\nResponsibilities\nCollect, process, and clean data from diverse sources to prepare it for analysis, ensuring consistency and reliability\nAnalyze raw data: assessing quality, cleansing, structuring for downstream processing and applying machine learning (ML) and deep learning (DL) techniques\nA focus on quantitative analytics and data modeling.\nDesign accurate and scalable prediction algorithms\nEnsuring scalable ML/DL pipeline construction\nImplementing data storage solutions that optimize for volume, velocity, and variety of EEG data\nCollaborate with the team to bring analytical prototypes to production\nStay up-to-date with the latest technologies and trends in data science and machine learning\nQualifications\nMaster's degree or equivalent experience in Computer Science\nAt least 2 years' of experience in DL, quantitative analytics and data modeling\nA strong statistical and programming background\nExperienced in MLOP pipeline construction and big data technologies like Spark, MLFlow, Snowflake, Hadoop for hosting the data\nDeep understanding of predictive modeling, machine-learning, clustering and classification techniques, and algorithms\nFluency in a programming language (Python, C,C++, Java, SQL)\nExcellent problem-solving skills and ability to work independently or as part of a team\nExperienced in working interdisciplinary tasks\nWe Offer\nCompetitive salary and benefits package\nA collaborative work environment with a supportive team\nOpportunities for professional growth and development\nAccess to the latest tools and technologies.\nFlexible working hours and remote work options\nCEPHALGO focuses on introducing technological innovations to assist medical professionals to provide better mental health care. Located in Strasbourg, extended beyond Europe, CEPHALGO‚Äôs patient monitoring technique using EEG and AI has been applied in psychiatry across Europe. Further information can be found at https://cephalgo.com.\nShow more\nShow less",
        "details": {
            "JobDetail": [
                "Remote"
            ],
            "TypeContract": "",
            "Salary": "Salary, Package",
            "Level": "",
            "Experience": null
        },
        "title": "data scientist",
        "skills": {
            "ProgLanguage": [
                "Java",
                "Python"
            ],
            "DataBase": [
                "SQL"
            ],
            "BigData": [
                "Hadoop",
                "Spark"
            ],
            "DBMS": [
                "Snowflake"
            ],
            "Other": [
                "ML",
                "Machine Learning",
                "Big Data"
            ],
            "EnSoftSkils": [
                "Collaboration"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "Akademija Oxford",
        "location": "Val-d'Oise, √éle-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/apprenti-e-data-scientist-at-akademija-oxford-3917868440?position=3&pageNum=0&refId=SmRHYtKKcb%2BBbb%2BiSm10Sw%3D%3D&trackingId=3gh8%2FgjuXi%2BOcjIC7KoOPA%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Un acteur majeur et en pleine croissance de la Biologie M√©dicale en Ile de France, recrute un.e Apprenti.e Data Scientist en alternance. Ce contrat d‚Äôapprentissage d‚Äôune dur√©e de 12 mois d√©bute en Octobre 2021.\nShow more\nShow less",
        "details": {
            "JobDetail": [],
            "TypeContract": "",
            "Salary": "",
            "Level": "",
            "Experience": null
        },
        "title": "data scientist",
        "skills": {}
    },
    {
        "source": "LinkedIn",
        "company": "Homa",
        "location": "Paris, √éle-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/machine-learning-engineer-at-homa-3904059928?position=4&pageNum=0&refId=SmRHYtKKcb%2BBbb%2BiSm10Sw%3D%3D&trackingId=OjpRIBsPX8vsbj5%2BZWBvWw%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Welcome to Homa, the gaming technology lab that is taking the industry by storm! Our team of over 200 people, hailing from more than 35 different countries, is dedicated to empowering mobile game creators worldwide to bring their creative ideas to the top charts.\nOur Homa Lab platform offers a comprehensive suite of cutting-edge tools that allow developers to stay on top of the latest trends, test new features in real-time, and easily distribute and monetize their games. Our success speaks for itself - our apps have been downloaded over 1 billion times!\nSince our inception, we have raised $165 million in total from prominent investors, including Headline, Northzone, Eurazeo, Singular, Quadrille Capital, Fabric Ventures, and Bpifrance. We have also received support from renowned business angels, such as the founders of King, Sorare and Spotify founders.\nBut what really makes Homa special is our team. We are a diverse group of artists, business developers, engineers, entrepreneurs, and former strategy consultants who all share the same passion for taking over the gaming industry. When you become part of Homa, you'll be joining a dedicated team that creates innovative and high-performing games that resonate with players worldwide.\nIf you're ready to take your career to the next level and make a real impact in the company, then Homa is the perfect place for you. Join us and let's create the future of gaming together!\nMeet the team\nüë©‚Äçüë©‚Äçüëß‚Äçüëß\nYou will join the Data department organized into:\nA Data Platform team with 5 Data Engineers responsible for ingesting large amounts of data from multiple different sources, creating and maintaining a core data model which aims at making data standardized, reliable and easily available\nA Data Science and ML Platform team with 6 Data Scientists / ML Engineer working on ML-driven data products: Autobidder for User Acquisition, N-Testing for experimentation\nAn Advanced Analytics & Data Science team with 6 Data Analysts and Scientists exploiting our data for:\nGame Analytics\nUser Acquisition and Marketing Analytics\nMarket Inteligence Analytics\nOps Analytics\nRole and Missions ‚Äî What you will do\nüöÄ\nWe are looking for a Machine Learning Engineer to join the team in order to scale and industrialize Machine Learning & AI at Homa. Under the responsibility of our Associate Director, your responsibilities will be the following:\nTake part in ML Projects: Spearhead development and implementation of ML models for Marketing Tech (User Acquisition, Monetization) and Game Tech (Bayesian A/B Testing, Segmentation)\nML Industrialization & Democratization: Enhance ML engineering processes, adopt ML Ops tools, and contribute to model interpretability and collaborative efforts\nImplement Scalable ML Solutions: Build Serving APIs for handling millions of requests daily with low latency\nCollaborative Innovation: Work closely with diverse teams, leveraging GenAI tools for productivity and product improvements\nStay Updated: Integrate latest ML technologies and advancements into our tech stack\nCurrent Tech Stack: AWS, Redshift, Databricks, Python, DBT, Spark, Airflow, Kafka, Kubernetes, LightGBM, MLFlow, Metabase\nRequirements\nIf you're creative, ambitious, and up for taking over the industry, we want you on our team! We are also looking for:\nFirst ML Experience: :2 years in implementing and deploying ML models to production\nKey Technology Proficiency: Experience in Neural Networks (TensorFlow / PyTorch), Gradient Boosting libraries (LightGBM / XGBoost), and at least one top Cloud provider (GCP, Azure, AWS)\nMLOps Skills: Knowledge of ML Ops tools like MLFlow\nAPI Development Expertise: Ability in building high-performance Serving APIs\nCollaborative Skills: Excellent communication and teamwork abilities\nInnovative Mindset: Passion for staying ahead in ML trends and technologies\nLanguage Skills: Fluency English is mandatory (interviews will be led in English)\nOur Culture‚ÄîWho we are\nü™ê\nAt Homa, we are building a community of brilliant talents. We believe that true innovation comes from diversity and collaboration, and that's why we prioritize brainpower and determination over formal education. So if you have the talent, energy and motivation, there is no obstacle to your success here.\nAs the creative experts behind the platform, we provide developers with the data they need to bring their ideas to life. Our team lives by three central values that guide everything we do:\n‚ú®\nAmbition\n: we're not afraid to tackle difficult challenges and set our goals extremely high. We're on a mission to revolutionize an industry dominated by well-established companies, and we won't stop until we succeed.\n‚ú®\nHumility\n: we leave our pride & ego aside. We are always ready to lend a helping hand, celebrate each other's successes, and learn from our failures. As Mr. Lamar said, \"Sit down. Be humble.\"\n‚ú®\nCuriosity\n: we keep our minds open and never stop learning. We believe that questioning everything is the best way to stay ahead of the curve, and we encourage all our team members to stay curious and never stop exploring new ideas.\nAt Homa, you'll be challenged, supported, and inspired every day, and we can't wait to see what you bring to the table.\nBenefits\nWhile success is its own reward, here are some of the benefits that come with working at Homa:\nWe offer essential benefits in France and specific locations, including health insurance, meal vouchers, public transport subsidies, childcare benefits, and life insurance\nIf you're interested in working from our newly renovated Paris HQ with a rooftop garden and WeWork amenities, we have a desk waiting for you\nYou will be working in English with our international team of top-tier talents from 35+ countries\nYou will have bi-annual reviews with your manager to reflect on your performance, celebrate wins, and receive constructive feedback\nYou will be able to attend diverse team events and Workations (the famous company-wide Homa trip)\nShow more\nShow less",
        "details": {
            "JobDetail": [],
            "TypeContract": "",
            "Salary": "",
            "Level": "",
            "Experience": null
        },
        "title": "machine learning engineer",
        "skills": {
            "ProgLanguage": [
                "Python"
            ],
            "BigData": [
                "Databricks",
                "Spark"
            ],
            "MachineLearning": [
                "PyTorch",
                "LightGBM",
                "TensorFlow",
                "XGBoost"
            ],
            "CloudComputing": [
                "GCP",
                "AWS",
                "Azure"
            ],
            "Automation": [
                "Airflow",
                "Kubernetes"
            ],
            "Containers": [
                "Kubernetes"
            ],
            "Collaboration": [
                "Teams"
            ],
            "Other": [
                "Machine Learning",
                "Cloud",
                "ML"
            ],
            "EnSoftSkils": [
                "Teamwork",
                "Communication",
                "Collaboration"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "Quack AI (YC S23)",
        "location": "Paris, √éle-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/ml-engineer-intern-at-quack-ai-yc-s23-3822705279?position=5&pageNum=0&refId=SmRHYtKKcb%2BBbb%2BiSm10Sw%3D%3D&trackingId=J%2BSk5BXc%2F7BjGPYHh4Il1g%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "You will be the first member of the ML team and will grow along with it. As such, your responsibilities will start in model improvement but grow with our internal team & open-source research. During your internship, you will: - establish a coherent way to evaluate our models on code-related tasks that are relevant for actual usage - fine-tune LLMs for code-related tasks (can't make promises about training from scratch) - integrate or create rich new datasets to feed into your training experiments - Work with other teammates to integrate the models you trained in Quack products\nAbout You\nAs an engineer, you have a disturbing obsession with making something useful, not something shiny. Your curious nature makes you excited about modern technologies and tools (e.g. ChatGPT and/or GitHub Copilot are in your daily toolset). Your peers describe you as humble, and you make sure to always learn new things however experienced you may be. This drives you not to shy away from community/user feedback, but instead to seek the hard truth and iterate.\nIn short, you will probably be a good fit if you: - have already founded or intend to found a startup at some point - spend more time on your favorite newsfeed (e.g. Twitter, GitHub) browsing the latest models and research papers. Although given the choice, you'd prefer to share your model checkpoint and your code publicly, rather than spending weeks writing the research paper for citations. - have experience with deep learning frameworks (PyTorch), NLP (Transformers, etc.) and GPUs (e.g. you've seem OOM & you know a few tricks to mitigate them). - you have already trained or finetuned deep learning models (computer vision or NLP) and you're also comfortable running inference with LLMs (not 3rd party API). - are comfortable using Python (more than Jupyter notebooks) and GitHub, you focus on results but you don't leave a mess behind. Open-source experience is big plus.\nPlease note we only consider internships onsite, for a period of 5-6 months! The internship is meant to lead to a full-time position.\nShow more\nShow less",
        "details": {
            "JobDetail": [
                "Full"
            ],
            "TypeContract": "",
            "Salary": "",
            "Level": "",
            "Experience": null
        },
        "title": "machine learning engineer",
        "skills": {
            "ProgLanguage": [
                "Python"
            ],
            "MachineLearning": [
                "PyTorch"
            ],
            "Other": [
                "ML"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "Checkout.com",
        "location": "Paris, √éle-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/data-scientist-payment-success-at-checkout-com-3903448233?position=6&pageNum=0&refId=SmRHYtKKcb%2BBbb%2BiSm10Sw%3D%3D&trackingId=bXKXbXAAEd8IFhkZRXaSsQ%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Company Description\nCheckout.com is one of the most exciting fintechs in the world. Our mission is to enable businesses and their communities to thrive in the digital economy. We‚Äôre the strategic payments partner for some of the best known fast-moving brands globally such as Wise, Hut Group, Sony Electronics, Homebase, Henkel, Klarna and many others. Purpose-built with performance and scalability in mind, our flexible cloud-based payments platform helps global enterprises launch new products and create experiences customers love. And it's not just what we build that makes us different. It's how.\nWe empower passionate problem-solvers to collaborate, innovate and do their best work. That‚Äôs why we‚Äôre on the Forbes Cloud 100 list and a Great Place to Work accredited company. And we‚Äôre just getting started. We‚Äôre building diverse and inclusive teams around the world ‚Äî because that‚Äôs how we create even better experiences for our merchants and our partners. And we need your help. Join us to build the digital economy of tomorrow.\nJob Description\nAbout the opportunity:\nWe empower businesses in the digital economy, and we know that every payment counts. Our Payment Performance team‚Äôs mission is to manage and optimise merchants‚Äô payment flow, to achieve optimal conversion, compliance and cost.\nCheckout.com is looking for a data scientist to automate research and investigations tailored for our Tier-1 merchants. This role encompasses the development of automation tools for monitoring, including dashboards and auto-generated presentations, as well as in-depth diagnostic solutions powered by machine learning and recommendation engines.\nYou will also work closely with Payment Performance Managers to ensure the delivery of a high level of service to our key merchants, underpinned by data-driven expertise. The ideal candidate must be a driven technologist with an affinity for problem solving and creating new tools.\nWhat you'll be doing:\nConduct deep-dive exploratory data analysis to uncover insights and anomalies\nDevelop cutting-edge automation tools aimed at monitoring and optimising merchants‚Äô performance\nCreate intuitive, real-time dashboards and reports to provide merchant performance visibility, enabling data-driven decision-making\nPropose enhancements of existing processes/tools by utilising statistical and machine learning techniques\nEffectively communicate research findings to both technical and non-technical stakeholders through reports and presentations\nQualifications\n2+ years experience as data scientist, working with large and diversified data sets\nBachelor‚Äôs degree, preferably in Mathematics / Statistics / Computer Science / Engineering, Finance or equivalent\nSQL/ Python knowledge to extract & analyse data from our Data Warehouse\nExperience with Git & Spark, Databricks, Retool, API\nAbility to find creative and effective solutions for business problems\nFlexible, adaptable and has a willingness to learn\nPayments or Fintech experience is a plus\nIf you don't meet all the requirements but think you might still be right for the role, please apply anyway. We're always keen to speak to people who connect with our mission and values\nIf possible, please submit CVs in English.\nAdditional Information\nApply without meeting all requirements statement\nIf you don't meet all the requirements but think you might still be right for the role, please apply anyway. We're always keen to speak to people who connect with our mission and values.\nWe believe in equal opportunities\nWe work as one team. Wherever you come from. However you identify. And whichever payment method you use.\nOur clients come from all over the world ‚Äî and so do we. Hiring hard-working people and giving them a community to thrive in is critical to our success.\nWhen you join our team, we‚Äôll empower you to unlock your potential so you can do your best work. We‚Äôd love to hear how you think you could make a difference here with us.\nWe want to set you up for success and make our process as accessible as possible. So let us know in your application, or tell your recruiter directly, if you need anything to make your experience or working environment more comfortable. We‚Äôll be happy to support you.\nTake a peek inside life at Checkout.com via\nOur Culture video https://youtu.be/BEwnpHuadSw\nOur careers page https://www.checkout.com/careers\nOur LinkedIn Life pages bit.ly/3OaoN1U\nOur Instagram https://www.instagram.com/checkout_com/\nApply Without Meeting All Requirements Statement\nIf you don't meet all the requirements but think you might still be right for the role, please apply anyway. We're always keen to speak to people who connect with our mission and values.\nWe believe in equal opportunities\nWe work as one team. Wherever you come from. However you identify. And whichever payment method you use.\nOur clients come from all over the world ‚Äî and so do we. Hiring hard-working people and giving them a community to thrive in is critical to our success.\nWhen you join our team, we‚Äôll empower you to unlock your potential so you can do your best work. We‚Äôd love to hear how you think you could make a difference here with us.\nWe want to set you up for success and make our process as accessible as possible. So let us know in your application, or tell your recruiter directly, if you need anything to make your experience or working environment more comfortable. We‚Äôll be happy to support you.\nTake a peek inside life at Checkout.com via\nOur Culture video https://youtu.be/BEwnpHuadSw\nOur careers page https://www.checkout.com/careers\nOur LinkedIn Life pages bit.ly/3OaoN1U\nOur Instagram https://www.instagram.com/checkout_com/\nShow more\nShow less",
        "details": {
            "JobDetail": [],
            "TypeContract": "",
            "Salary": "",
            "Level": "",
            "Experience": null
        },
        "title": "data scientist",
        "skills": {
            "ProgLanguage": [
                "Python"
            ],
            "DataBase": [
                "SQL"
            ],
            "BigData": [
                "Databricks",
                "Spark"
            ],
            "DevTools": [
                "Git"
            ],
            "Collaboration": [
                "Teams"
            ],
            "Other": [
                "Machine Learning",
                "Cloud"
            ],
            "EnSoftSkils": [
                "Problem Solving"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "NuMind (YC S22)",
        "location": "Paris, √éle-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/machine-learning-scientist-engineer-at-numind-yc-s22-3856851886?position=7&pageNum=0&refId=SmRHYtKKcb%2BBbb%2BiSm10Sw%3D%3D&trackingId=eqFY42eDw39uvPCyDG7Vyg%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "About Us\nNuMind (https://www.numind.ai/) is a software company developing a tool to create custom NLP models specialized in information extraction (see¬†https://www.youtube.com/watch?v=MQhYe5HXqss). We also develop open-source foundation models (https://huggingface.co/numind), and write research papers (see https://arxiv.org/abs/2402.15343).\nWe aim to become leader in the field of custom information extraction.\nWe are a team of 7: CEO, CTO, COO, 2 senior software engineers, and 2 machine learning scientists. Our CEO was head of ML at Wolfram Research and our CTO co-founded¬†Make.org.\nMost of the team are located in France (Paris).\nWe were part of YCombinator‚Äôs S22 batch, and raised a good seed round.\nJob Description\nNuMind is a tool to create NLP models (e.g. classifiers and entity recognizers). The user provides information about the task (e.g. by labeling documents), and the computer creates models automatically.\nYour job will be to make this happen in the most effective way. This will involve designing & testing various machine learning solutions, and implementing these solutions directly into NuMind.\nR&D topics include:\nTransfer learning, few-shot learning\nActive learning\nAutomatic machine learning\nPerformance measurements\nDistillation\nProbability calibration\nOut-of-domain robustness\nModel explanations\nThis position is for someone who has both a researcher and engineer mindset.\nResponsibilities\nTraining task-specific foundation models\nSetting up benchmarks to test ML solutions\nIdentifying & testing existing ML solutions\nDesigning & testing new ML solutions from scratch\nImplementing selected solutions into the product\nStaying up to date with relevant NLP research\nQualifications\nExpert-level understanding of machine learning.\nAbility to design, train, test deep learning models\nAbility to conduct machine learning research (e.g. conducting experiments, drawing conclusions, communicating results)\nAbility to develop production-grade code\nGood understanding of the following field: statistics, computer science (esp. data structures & algorithms), and numerical analysis\nShow more\nShow less",
        "details": {
            "JobDetail": [
                "Senior"
            ],
            "TypeContract": "",
            "Salary": "",
            "Level": "",
            "Experience": null
        },
        "title": "machine learning engineer",
        "skills": {
            "ProgLanguage": [
                "R"
            ],
            "DataAnalytics": [
                "R"
            ],
            "Other": [
                "Machine Learning",
                "ML"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "HackerPulse",
        "location": "France",
        "link": "https://fr.linkedin.com/jobs/view/machine-learning-engineer-at-hackerpulse-3917868826?position=8&pageNum=0&refId=SmRHYtKKcb%2BBbb%2BiSm10Sw%3D%3D&trackingId=sSvWEb7B28eiOhge%2BTov2Q%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Showcase your software engineering talents using ML-powered profiles. Loved by 11k+ engineers! Backed by Antler.\nThe Role\nYou Will Be Responsible For\nDeveloping scripts to process structured and unstructured data.\nRecommending, developing and implementing ways to improve data reliability, efficiency and quality.\nSupporting translation of data business needs into technical system requirements.\nWorking with stakeholders to understand needs in order with respect to data structure, availability, scalability and accessibility.\nDeveloping high-quality code to build and deploy machine learning models.\nIdeal Profile\nYou possess a degree in Computer Science, Applied Mathematics, Engineering or related field.\nYou have at least 1 year experience, ideally within a Data Engineer role.\nDemonstrated experience working with large and complex data sets as well as experience analyzing volumes of data.\nYou are a strong networker & relationship builder\nYou pay strong attention to detail and deliver work that is of a high standard\nYou are a self-starter and demonstrate a high level of resilience\nWhat's on Offer?\nGreat work environment\nExcellent career development opportunities\nLeadership Role\nShow more\nShow less",
        "details": {
            "JobDetail": [],
            "TypeContract": "",
            "Salary": "",
            "Level": "",
            "Experience": null
        },
        "title": "machine learning engineer",
        "skills": {
            "Other": [
                "Machine Learning",
                "ML"
            ],
            "EnSoftSkils": [
                "Leadership"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "AXA Group Operations",
        "location": "Paris, √éle-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/machine-learning-engineer-at-axa-group-operations-3856840119?position=9&pageNum=0&refId=SmRHYtKKcb%2BBbb%2BiSm10Sw%3D%3D&trackingId=hDyqNj86MKiMkQENRPVWmw%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Ready to shape the future? Join our team as a Machine Learning Engineer Extraordinaire!\nAbout the job\nBased in Paris or Barcelona, you will be part of the Artificial Intelligence Engineering team, in the Group Emerging Technologies and Data (GETD) division of AXA. This transversal team‚Äôs mission is both to build AI-powered initiatives (proofs of concept, proofs of value, pilots) with AXA entities & strategic partners and to define & implement MLOps best practices, tools, and collaboration models to be followed across the whole AXA Group. Our team is composed of 10 people, spread in 3 countries (France, Spain & Switzerland) and we work in hybrid mode (60% remote + 40% on-site).\nAXA is a global leader in insurance and asset management present in nearly 60 countries. We leverage Artificial Intelligence to protect our 100+ million customers, in every domain of core insurance (Property & Casualty, Life & Savings, Health, ‚Ä¶). As a responsible company, AXA defined and follows strong Responsible AI principles around robustness, interpretability, fairness, and sustainability.\nKey responsibilities\nIn this role, you will:\nBuild and improve reusable tools & modelling pipelines and support knowledge sharing across several teams.\nWork with Data Scientists to improve both technical and statistical performance of models.\nConvert the machine learning models into application program interfaces (APIs) so that other applications can use them in alignment with architecture & infrastructure standards.\nSecure and monitor ML processing, including safeguards, A/B testing, fault-tolerance, and failover.\nContribute to the definition and deployment of best practices in Machine Learning & MLOps,\nContribute to the sharing of knowledge and expertise through communities and working groups (internal and external).\nHelp the different actors of the organization (such as product managers and stakeholders) understand what results they gain from MLOps and best engineering practices in Data and AI.\nWhat is needed to succeed\nAs we want you to succeed in this role, here is a list of examples of key factors:\n4+ years of experience with DevOps: versioning (Git), containers (Docker/Kubernetes), CI/CD, Static analysis tools, ‚Ä¶\nProficiency in ML Ops and ML Engineering frameworks: experiment trackers (like mlFlow) & orchestrators (Airflow, Kubeflow, Sagemaker Pipeline)\nA practical knowledge in one of the popular ML Python libraries (TensorFlow, PyTorch, Keras, Scikit-Learn) and Open-Source libraries.\nA good understanding of Agile methodologies and a mindset of continuous improvement.\nAbility to articulate the results of your work for various audiences.\nGood communication in English and interpersonal skills for working in a multicultural work environment.\nPassion about solving challenging problems leveraging new technologies.\nNice to have\nHere are other elements we will consider:\n2+ years of experience in delivering and running ML models in production, using at least one of some of the main Big Data frameworks and platforms: Spark, Databricks, Snowflake, ‚Ä¶\nPractical knowledge in Infrastructure as code (Terraform, CloudFormation, ‚Ä¶).\nPractical knowledge of cloud services (Azure or Amazon Web Services).\nTheoretical knowledge in Event Driven Architecture (using Kafka, Event Hub, or Rabbit MQ).\nInsurance & Finance functional knowledge\nWhat we offer\nOn top of usual benefits, we also offer:\nHybrid working (60% remote + 40% on-site).\nGlobal communities of practice and 2 yearly global events gathering Engineers and Data Scientists.\nLearning and mentoring opportunities through partnerships with LinkedIn Learning and O‚ÄôReilly.\nAmong a strong Employee benefit program, mental health, and well-being platform to access personalised care.\nWe bring together the expertise, cultural diversity and creativity of over 8,000 employees worldwide. We‚Äôre committed to equal opportunities in all aspects of employment (gender, LGBT+, disabled persons, or people of different origins) and to promoting Diversity & Inclusion by creating a work environment where all employees are treated with dignity and respect, and where individual differences are valued.\nShow more\nShow less",
        "details": {
            "JobDetail": [
                "Remote"
            ],
            "TypeContract": "",
            "Salary": "",
            "Level": "",
            "Experience": null
        },
        "title": "machine learning engineer",
        "skills": {
            "ProgLanguage": [
                "Python"
            ],
            "BigData": [
                "Databricks",
                "Spark"
            ],
            "MachineLearning": [
                "Scikit-Learn",
                "PyTorch",
                "TensorFlow",
                "Keras"
            ],
            "CloudComputing": [
                "Azure"
            ],
            "DevTools": [
                "Git",
                "Docker"
            ],
            "DBMS": [
                "Snowflake"
            ],
            "Automation": [
                "Airflow",
                "Kubernetes"
            ],
            "InfrastructureAsCode": [
                "CloudFormation",
                "Terraform"
            ],
            "Containers": [
                "Docker",
                "Kubernetes"
            ],
            "Collaboration": [
                "Teams"
            ],
            "Other": [
                "CI/CD",
                "ML",
                "Big Data",
                "Machine Learning",
                "Cloud",
                "DevOps"
            ],
            "EnSoftSkils": [
                "Organization",
                "Collaboration",
                "Creativity",
                "Interpersonal Skills",
                "Communication"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "MindPal",
        "location": "Marseille, Provence-Alpes-C√¥te d'Azur, France",
        "link": "https://fr.linkedin.com/jobs/view/machine-learning-developer-at-mindpal-3911352774?position=10&pageNum=0&refId=SmRHYtKKcb%2BBbb%2BiSm10Sw%3D%3D&trackingId=0i01RXa%2B4A1umUlYRSOniA%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "We are looking for\nMachine Learning Developer\nJob Responsibilities\nWorking on machine learning projects\nAnalyzing and processing data to create machine learning models\nImplementing and optimizing machine learning algorithms\nTesting and evaluating models\nCollaborating with the programming team and other departments within the company to develop innovative solutions\nRequirements\nMinimum 2 years of experience in the field of machine learning\nKnowledge of machine learning algorithms and techniques\nAbility to analyze and process data\nFamiliarity with machine learning tools and technologies\nProficient in English communication\nEducation in computer science\nWe Offer\nB2B contract type\nFull-time employment\nRemote and flexible working hours\nShow more\nShow less",
        "details": {
            "JobDetail": [
                "Remote",
                "Full"
            ],
            "TypeContract": "",
            "Salary": "",
            "Level": "",
            "Experience": null
        },
        "title": "Other",
        "skills": {
            "Other": [
                "Machine Learning"
            ],
            "EnSoftSkils": [
                "Communication"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "EyeTech Solutions",
        "location": "Paris, √éle-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/data-scientist%E2%80%93-machine-learning-at-eyetech-solutions-3913336440?position=11&pageNum=0&refId=SmRHYtKKcb%2BBbb%2BiSm10Sw%3D%3D&trackingId=JgCq9myXNYIMM4eLr9FwjA%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Data Scientist‚Äì Machine Learning\nTravailler sur le d√©veloppement de mod√®le de machine learning pr√©dictif.\nPour une Solution SaaS de monitoring analytique, pr√©dictif et prescriptif en milieu industriel.\nData Scientist‚Äì Machine Learning\nFond√©e en 2016, notre soci√©t√© d√©veloppe une solution SAAS d√©di√©e au monitoring automatique des lignes de production.\nNotre √©quipe sp√©cialis√©e dans les donn√©es est responsable de la conception, du d√©veloppement et de la maintenance de la plateforme IA de notre solution, dont les principales fonctionnalit√©s incluent le monitoring analytique, pr√©dictif et prescriptif.\nCette m√™me √©quipe est √©galement charg√©e du d√©veloppement d'une nouvelle plateforme IA qui sera int√©gr√©e √† nos solutions existantes.\nNos solutions reposent sur une stack technologique moderne, utilisant des outils tels que Airflow, Mlflow, MongoDB, Kubernetes, CI/CD.\nData Scientist‚Äì Machine Learning\nTravaux sur le d√©veloppement de mod√®le de machine learning pr√©dictif\nCollaboration avec le Lead Data Scientist et le Lead Tech Senior pour d√©finir les orientations du produit et organiser les t√¢ches.\nContribution au d√©veloppement des fonctionnalit√©s li√©es aux donn√©es et √† l‚Äôintelligence artificielle.\nCommunication et pr√©sentation clients.\nVeille scientifique et travaux de recherche et d√©veloppement.\nData Scientist‚Äì Machine Learning\n3 ans d‚Äôexp√©rience minimum en tant que Data Scientist (IA, ML) dans l‚Äôindustrialisation d‚Äôun produit\nCapaciter √† vulgariser, comprendre et transformer les besoins\nDiplome universitaire\nData Scientist‚Äì Machine Learning\nLocaux √† Paris\nSalaire selon profil, entre 50K et 55K\nT√©l√©travail 2 jours / semaine\nShow more\nShow less",
        "details": {
            "JobDetail": [
                "Senior"
            ],
            "TypeContract": "",
            "Salary": "50K",
            "Level": "",
            "Experience": "3 an(s)"
        },
        "title": "data scientist",
        "skills": {
            "DataBase": [
                "MongoDB"
            ],
            "Automation": [
                "Airflow",
                "Kubernetes"
            ],
            "Containers": [
                "Kubernetes"
            ],
            "Other": [
                "Machine Learning",
                "ML",
                "CI/CD"
            ],
            "EnSoftSkils": [
                "Communication",
                "Collaboration"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "eXalt Value",
        "location": "√éle-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/data-scientist-ia-gen-at-exalt-value-3897781437?position=12&pageNum=0&refId=SmRHYtKKcb%2BBbb%2BiSm10Sw%3D%3D&trackingId=fdpaxaC4FJDSSjqxzsq45A%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "eXalt\nest un cabinet de conseil IT\nPure player Data\n& IA bas√© √† Paris (1er arrondissement).\nNotre offre s‚Äôarticule autour de 4 piliers r√©unis au sein d‚Äôune m√™me communaut√© pour un accompagnement √† 360¬∞ alliant une expertise technique et m√©thodologique √† une approche conseil m√©tier:\nData Gouvernance & Project\nData Engineering & Big Data\nData Performance & Analytics\nData Science & IA\nFiliale du groupe eXalt cr√©√© en 2018,\nregroupant plus de\n950 collaborateurs en France\n(Paris, Lyon, Bordeaux, Lille, Nantes, Marseille)\net √† l‚Äôinternational\n(Colombie, Etats-Unis, Espagne, Belgique),\neXalt Value\nd√©montre une\nexpertise approfondie\ndans le domaine de la Data & IA et conseille les entreprises dans le d√©ploiement de leurs strat√©gies data-driven.\nB√©n√©ficiant de la renomm√©e et des relations client du groupe eXalt\n(1er dans la cat√©gorie Conseil & Audit au classement des Champions de la Croissance 2024), eXalt Value\nest en pleine croissance et regroupe aujourd‚Äôhui une communaut√© d‚Äôexpertise de plus de 60 collaborateurs en r√©gion parisienne.\nNos consultants interviennent sur d\nes projets d‚Äôenvergure stimulants\ndans divers secteurs d‚Äôactivit√©, Banque & Assurance, M√©dias, Transports, Retail, Tourisme, etc.\nNous recherchons un\nData Scientist IA Gen H/F\npour rejoindre notre communaut√© sur le\npilier Data Science & IA.\nVos missions:\nIdentifier les besoins sp√©cifiques des diff√©rentes √©quipes, √† travers des ateliers d'id√©ation, et proposer des solutions algorithmiques innovantes et adapt√©es √† chaque situation.\nAnalyser les donn√©es disponibles pour s√©lectionner les mod√®les d'IA les plus pertinents face aux besoins identifi√©s, en tenant compte des particularit√©s de chaque cas d'usage.\nD√©velopper, tester et d√©ployer les algorithmes des mod√®les d'apprentissage automatique et des algorithmes avanc√©s pour r√©soudre des probl√®mes complexes gr√¢ce √† des m√©thodes statistiques, math√©matiques et de machine learning.\nCollaborer avec les Data Engineer afin d‚Äôint√©grer les solutions IA dans les produits et les applications existants.\nExploiter les derni√®res avanc√©es en mati√®re d'IA, notamment le Deep Learning, le Reinforcement Learning, le Traitement du Langage Naturel (NLP), la vision par ordinateur, etc., pour cr√©er des solutions innovantes.\nConseiller les clients tout au long du cycle de vie des projets sur les solutions techniques les plus adapt√©es √† leurs environnements.\nLes Pr√©requis :\nTitulaire d'un Bac+5, id√©alement Ecole d'Ing√©nieur\nCompr√©hension des enjeux business autours de\nl‚Äôexploitation des donn√©es et le d√©ploiement des solutions IA\nMa√Ætrise du\nMachine Learning et du Deep Learning,\ny compris des principaux frameworks (TensorFlow, PyTorch, Scikit-learn, Pandas, NumPy,) et des m√©thodes statistiques.\nSolides connaissances de\nPython\n(Java, Spark, Scala sont un plus).\nAisance avec l'ensemble du cycle de vie de d√©veloppement et de d√©ploiement de mod√®les d'IA (MLOps).\nExp√©rience de travail en\nm√©thode Agile\nCapacit√© √† travailler de mani√®re autonome et en √©quipe.\nExcellentes comp√©tences en communication et pr√©sentation.\nMa√Ætrise de l‚Äôanglais (oral & √©crit dans un contexte international professionnel).\nVotre environnement eXalt√©:\nRejoindre\neXalt Value\n, c‚Äôest √©galement :\nUn Lab IA\nau sein duquel vous pourrez exp√©rimenter les divers outils et techniques, autour de use cases internes et externes.\nUn environnement de travail Collaboratif\nfavorisant les initiatives et projets transverses √† la Practice Data & IA (Data Hub, etc ;)\nUn collectif de consultants passionn√©s,\ns‚Äôint√©ressant aux tendances innovantes du secteur\nUne Practice de proximit√©,\nprivil√©giant la mont√©e en comp√©tence de ses collaborateurs (formations, coachings, mentorats, etc.)\nUn suivi individualis√© et de proximit√©\npar un.e Data Sales Manager r√©f√©rent du compte client, un.e Charg√©.e RH et un.e Practice Manager\nUne √©quipe sympa et dynamique,\nqui privil√©gie des moments de partage (s√©minaires, eXaltemps, meet-ups, d√©jeuners d‚Äô√©quipe, etc.)\nNotre processus de recrutement :\nUn entretien RH avec Estelle,\n√† la suite duquel vous saurez tout (ou presque) d‚ÄôeXalt Value,\nUn entretien technique avec un Manager IA assorti d‚Äôun √©change technique,\nlors duquel vous aurez l‚Äôoccasion de d√©montrer vos talents et de challenger vos acquis.\nUn entretien final avec la Directrice Associ√©e ou le Directeur Op√©rationnel,\npour finir de vous convaincre de nous rejoindre üòä\nShow more\nShow less",
        "details": {
            "JobDetail": [],
            "TypeContract": "",
            "Salary": "",
            "Level": "Bac+5",
            "Experience": null
        },
        "title": "data scientist",
        "skills": {
            "ProgLanguage": [
                "Java",
                "Scala",
                "Python"
            ],
            "DataAnalytics": [
                "NumPy",
                "Pandas"
            ],
            "BigData": [
                "Spark"
            ],
            "MachineLearning": [
                "Scikit-Learn",
                "TensorFlow",
                "PyTorch"
            ],
            "Other": [
                "Statistiques",
                "Machine Learning",
                "Big Data"
            ],
            "EnSoftSkils": [
                "Communication"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "Doctolib",
        "location": "Paris, √éle-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/senior-data-scientist-deep-learning-x-f-m-ai-teams-at-doctolib-3778200205?position=13&pageNum=0&refId=SmRHYtKKcb%2BBbb%2BiSm10Sw%3D%3D&trackingId=1IWtNP0LvYMacU20uZOX%2BA%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "What You‚Äôll Do\nAt Doctolib, we're on a mission to transform the way healthcare is delivered by leveraging the power of AI. As a Data Scientist, you'll play a critical role in developing and implementing cutting-edge AI solutions that will enable us to create an AI medical assistant that will support the Healthcare Professionals in their day to day job.\nIn this role, you'll have the opportunity to work with a team of talented data scientists, software engineers, machine learning engineers and healthcare professionals to develop and deploy AI models that will have a real impact on people's lives.\nDoctolib is looking for a Senior Data Scientist to join our dedicated feature team in charge of shaping the new consultation experience powered by a medical assistant.\nLet‚Äôs make a direct impact of your work with easy access to final users (practitioners) or subject matter experts to empower our Clinical Product with AI.\nYour responsibilities include but are not limited to:\nCreate, find or adapt model architecture, annotation or validation strategies to improve our speech recognition, summarization and medical data structuration engines\nImplement your ideas and test them\nDeploy your algorithms in production guided by our ML platform team\nMeasure the uplift and continuously improve your approach\nWho You Are\nIf you don‚Äôt meet all the requirements below but believe this opportunity matches your expectations and experience, we still encourage you to apply!\nYou could be our next team mate if you:\nHave analytical skills, are result oriented and user first\nHave 3 years of experience in the domain or shorter but with significant contribution (papers, open source)\nAre proficient in Deep Learning framework: Pytorch or Tensorflow\nHave knowledge of the latest NLP architecture (Transformer, LLM) and methods (fine tuning, distillation‚Ä¶)\nNow, it would be fantastic if you:\nHave already launched large scale model training\nHave experience in collaborating with end users to refine your modeling approach\nWhat We Offer\nEmployee share plan for every Doctoliber (BSPCE)\nFree Health Insurance for you & your family\nQuarterly or monthly bonus (based on your position)\nUp to 14 days of RTT\nTransparent internal mobility opportunities you're welcome to apply for\nParental care program (1 month off in addition to the legal parental leave and 0,5 days off per child when the school starts)\nSolidarity Days (2 days per year to help health charities and create a positive social impact)\nWellbeing program (free mental health and coaching offer with our partner moka.care)\nA flexible workplace policy offering both hybrid and office-based mode\nFlexibility days allowing to work in EU countries and the UK 10 days per year\nLunch voucher with Swile card\nWork Council subsidy to refund part of sport club membership or creative class\nBicycle subsidy\nReimbursement of public transportation\nRelocation support for international mobilities\nSlean voucher for home-office furniture\nThe interview process\nHR Screen\nInterview with 2 members of the Data Science team\nCase Study & Case restitution\nFinal interview with the DS Director\nAt least one reference check\nCriminal background check\nJob details\nPermanent position\nFull Time\nWorkplace : Paris area\nStart date: asap\nRemuneration : fix + bonus on objectives (according to your profile)\nAt Doctolib, we believe in improving access to healthcare for everyone - regardless of where you come from, what you look like. This translates into our recruitment process: Doctolib is an equal opportunity employer. We don't just accept diversity at Doctolib, we respect and celebrate it!\nThe more diverse ideas are heard, the more our product will truly improve healthcare for all. You are welcome to apply to Doctolib, regardless of your gender, religion, age, sexual orientation, ethnicity, disability, or place of origin. If you have a disability, let us know if there's any way we can make the interview process smoother for you!\nAll the information transmitted via this form is processed by Doctolib for the purpose of managing applications. For more information on how Doctolib processes your application data, click\nhere\n.\nIf you wish to exercise your rights or if you have any questions about the processing of your data, you can write to us at\nhr.dataprivacy(at)doctolib.com\n.\nShow more\nShow less",
        "details": {
            "JobDetail": [
                "Full",
                "Senior"
            ],
            "TypeContract": "",
            "Salary": "",
            "Level": "",
            "Experience": null
        },
        "title": "data scientist",
        "skills": {
            "MachineLearning": [
                "PyTorch",
                "TensorFlow"
            ],
            "Other": [
                "Machine Learning",
                "ML"
            ],
            "EnSoftSkils": [
                "Flexibility"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "Valeuriad",
        "location": "Nantes, Pays de la Loire, France",
        "link": "https://fr.linkedin.com/jobs/view/data-scientist-h-f-at-valeuriad-3741220588?position=14&pageNum=0&refId=SmRHYtKKcb%2BBbb%2BiSm10Sw%3D%3D&trackingId=hSs1e27Th5%2FCN8GTo03Srw%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Rejoins la\nTeam Data\ncr√©√©e par\nNicolas Greffard,\nDocteur en Intelligence Artificielle\n, d√©j√† compos√©e de\n20\nData Scientists\net\nData Engineer\ntalentueux üòç\nNous recherchons de\nnouvelles p√©pites\npour rejoindre notre √©quipe de choc et r√©pondre aux\nmultiples probl√©matiques Data science\nde nos\nclients nantais\nmais √©galement\ncontribuer √† nos projets de R&D\net travailler sur des\nconf√©rences incroyables\n(DevFest, Salon de la Data)\nü§©\nTa future mission si tu l'acceptes\nüòâ\nNous te proposons d'intervenir au sein de nos\ngrandes DSI clientes\n, sur des sujets de\ncollecte\n, d\n'alimentation\net de\ntransformation de donn√©es\nautour de l‚Äôintelligence artificielle.\nLe job en d√©tail\nü§©\nToutes Les Missions Ne Sont Pas Identiques, Mais Voici Des Exemples De Choses Sur Lesquelles Nos Data Scientists Sont Intervenus\n√âchange avec les architectes, les PO et PPO, les d√©veloppeurs et la gouvernance de donn√©es ;\nDeep learning (RNN, LSTM, CNN, DQN) et Machine learning ;\nAnalyse de donn√©es : statistiques descriptives et exploratoires, Data Mining ;\nTraitement d‚Äôimages (pattern matching, extraction de descripteurs, tf-idf et classification, etc..) et traitement de texte.\nTraitement du langage / Text-Mining (Word2Vec, BoW, BERT, etc..) ;\nRestitutiondes r√©sultats : dataviz, indicateurs, dashboards (tableaux de bord), optimisation d‚Äôapplication streamlit ;\nMLOps : pour pour amener l'IA jusqu'√† la prod ;\nAm√©lioration de mod√®les : validation crois√©e, s√©lection de descripteurs, m√©triques d‚Äôerreurs ;\nAssurer la veille technologique sur les algorithmes et outils de Data Science.\nLangages : Principalement du Python, souvent du SQL et parfois du R ou m√™me du SAS ;\nFramework : ceux qui reviennent sans arr√™t : Tensorflow, PyTorch, Huggingface, SkLearn, Lime, Streamlit, √©cosyst√®me Hadoop ;\nInt√©gration continue : en fonction des contextes applicatifs : docker, docker-compose, Docker Swarm, GitHub actions, Jenkins, kubernetes, concourse.\nPourquoi choisir Valeuriad ?\nüòä\nEn plus d‚Äô√™tre aujourd‚Äôhui un acteur nantais reconnu de l‚Äôexpertise IT, nous nous inscrivons depuis notre cr√©ation dans une d√©marche d'entreprise\nOpale\net\nHolacratique\n, o√π l'ensemble de nos prises de d√©cisions et projets sont r√©alis√©s par et avec l'ensemble de nos\n120 co√©quipiers\nüí™\nRejoindre Valeuriad, c'est pouvoir s'investir dans la co-construction de l'entreprise :\nPar un r√¥le, avec une fiche de poste et un temps d√©di√© (gestionnaire des Ci‚Äôs, porteur des partenariats √©coles, organisateur d‚Äô√©v√©nements, PO des projets internes, gestion de l'Acad√©mie Valeuriad‚Ä¶).\nPar les projets strat√©giques (200 jours mis √† disposition pour les co√©quipiers chaque ann√©e) pour cr√©er et faire grandir des projets structurants (cr√©ation de nouveaux avantages √† l'anciennet√©, cr√©ation d'indicateurs mensuels pour √™tre toujours plus transparents, m√©c√©nat de comp√©tences pour des associations caritatives...).\nPar les projets cagnottes (150‚Ç¨ par co√©quipiers et par an) pour r√©aliser des projets collaboratifs qui te tiennent √† c≈ìur avec d'autres Valeurieux (d√©couverte du c√©cifoot, challenge √©cologique, challenges sportifs pour des dons √† des associations humanitaires, borne photo...).\nPar les ateliers collaboratifs, chaque mois des brainstorming et ateliers de travail sont propos√©s par les diff√©rents porteurs de projets et sont ouverts √† tous les volontaires.\nMais avant-tout nous sommes une\n√©quipe soud√©e\n, des coll√®gues qui appr√©cient passer du temps ensemble lors de nos soir√©es hebdomadaires et se cr√©er des\nsouvenirs inoubliables\nü§© C'est pour √ßa que chez Valeuriad, le plus important pour nous reste le savoir-√™tre : des passionn√©s, du dynamisme, des sourires, de l'√©coute et le sens de la f√™te üòâ\nShow more\nShow less",
        "details": {
            "JobDetail": [],
            "TypeContract": "",
            "Salary": "",
            "Level": "",
            "Experience": null
        },
        "title": "data scientist",
        "skills": {
            "ProgLanguage": [
                "R",
                "Python"
            ],
            "DataBase": [
                "SQL"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [
                "Hadoop"
            ],
            "MachineLearning": [
                "PyTorch",
                "TensorFlow"
            ],
            "Statistics": [
                "Statistiques Descriptives"
            ],
            "DevTools": [
                "Jenkins",
                "Docker"
            ],
            "Automation": [
                "Kubernetes"
            ],
            "Containers": [
                "Docker",
                "Kubernetes"
            ],
            "Other": [
                "Statistiques",
                "Machine Learning"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "Aether Energy (YC W24)",
        "location": "Paris, √éle-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/machine-learning-engineer-at-aether-energy-yc-w24-3911654324?position=15&pageNum=0&refId=SmRHYtKKcb%2BBbb%2BiSm10Sw%3D%3D&trackingId=l%2B8iCmLNN5jvGSlUZNHobA%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "We raised a $3M seed recently.\nWe encourage all applicants from the EU to apply.\nOverview\nAether is on a mission to develop a comprehensive AI-driven platform for the solar energy industry. Our founders have strong technical academic background from UC Berkeley, complemented by extensive technical experience gained at some of the most influential companies in the energy sector.\nAether is seeking a machine learning engineer with a strong background in software engineering.\nIdeal candidates should have backgrounds in Physics, Mechanical Engineering, Electrical Engineering, or Materials Science, coupled with expertise in Computational Mathematics. A Master's degree is essential for this role, while a PhD, though not mandatory, would be highly valuable.\nWe are proud of our recent success and invite you to check out our YCombinator launch at\nthis link\n.\nWe're Looking For Someone Who:\nGets things done. This is an emerging Y Combinator seed company, and we require you to make an impact from day one.\nYour growth potential here is unlimited.\nQualifications\nThis role will be 60% Machine Learning/Data Science focused, and 40% backend engineering focused. You will need to be comfortable writing production-level code.\nREQUIRED\nStrong proficiency in Python\nKnowledge of unsupervised and supervised machine learning techniques\nA deep understanding of Computer Vision models such as UNET, DeepLab, or HRNet (High-Resolution Network).\nInterested in developing foundational LLM models (our use-case is energy)\nProficiency in data exploration (using BigQuery, Jupyter notebooks, and SQL), model development, and the establishment of data/ML pipelines\nComfortable working with APIs and Databases.\nKnowledge of best practices in collaborative coding with tools like Git and CI/CD.\nStrong software engineering skills and an understanding of good design patterns.\nYou must be Fluent in English.\nPreferred -\nWe know you won‚Äôt know everything but having a good general breadth of the requirements below will set you apart.\nA keen interest in the intersection of physical systems and AI.\nKnowledge of the Django framework.\nFamiliarity with Python libraries, including Pandas, NumPy, scikit-learn, PyTorch/Tensorflow, PyTorch Lightning, and vector databases.\nCompetency in deploying data and code to cloud platforms (GCP/Digital Ocean).\nUnderstanding of energy related data: battery data, solar data, etc.\nIdeally, previous experience in high-growth start-ups.\nYour math has to be good. We will check for this.\nCompensation/Time Commitment/Location:\nYou will need to work US EST hours from Monday to Thursday. You must be in our Paris office 3x a week starting in August.\n1st 3 months will be on a contract basis to assess performance.\nShow more\nShow less",
        "details": {
            "JobDetail": [],
            "TypeContract": "",
            "Salary": "",
            "Level": "",
            "Experience": null
        },
        "title": "machine learning engineer",
        "skills": {
            "ProgLanguage": [
                "Python"
            ],
            "DataBase": [
                "SQL"
            ],
            "DataAnalytics": [
                "NumPy",
                "Pandas"
            ],
            "MachineLearning": [
                "Scikit-Learn",
                "TensorFlow",
                "PyTorch"
            ],
            "CloudComputing": [
                "GCP"
            ],
            "DevTools": [
                "Git"
            ],
            "DBMS": [
                "BigQuery"
            ],
            "Other": [
                "Machine Learning",
                "Cloud",
                "ML",
                "CI/CD"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "MindPal",
        "location": "Lyon, Auvergne-Rh√¥ne-Alpes, France",
        "link": "https://fr.linkedin.com/jobs/view/machine-learning-developer-at-mindpal-3910999113?position=16&pageNum=0&refId=SmRHYtKKcb%2BBbb%2BiSm10Sw%3D%3D&trackingId=63jUW77Dk9mBsKoAXM0lEQ%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "We are looking for\nMachine Learning Developer\nJob Responsibilities\nWorking on machine learning projects\nAnalyzing and processing data to create machine learning models\nImplementing and optimizing machine learning algorithms\nTesting and evaluating models\nCollaborating with the programming team and other departments within the company to develop innovative solutions\nRequirements\nMinimum 2 years of experience in the field of machine learning\nKnowledge of machine learning algorithms and techniques\nAbility to analyze and process data\nFamiliarity with machine learning tools and technologies\nProficient in English communication\nEducation in computer science\nWe Offer\nB2B contract type\nFull-time employment\nRemote and flexible working hours\nShow more\nShow less",
        "details": {
            "JobDetail": [
                "Remote",
                "Full"
            ],
            "TypeContract": "",
            "Salary": "",
            "Level": "",
            "Experience": null
        },
        "title": "Other",
        "skills": {
            "Other": [
                "Machine Learning"
            ],
            "EnSoftSkils": [
                "Communication"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "Mirakl",
        "location": "Paris, √éle-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/machine-learning-engineer-at-mirakl-3879686188?position=17&pageNum=0&refId=SmRHYtKKcb%2BBbb%2BiSm10Sw%3D%3D&trackingId=1IdrApveTqOLnADkOGXz2g%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Mirakl, leader et pionnier de l‚Äô√©conomie de plateforme, propose aux entreprises une suite unique de solutions leur permettant de transformer significativement leur e-commerce afin d'acc√©l√©rer de fa√ßon durable et rentable leur croissance. Depuis 2012, Mirakl accompagne les entreprises B2C et B2B avec la technologie la plus avanc√©e, s√©curis√©e et √©volutive leur permettant de digitaliser leur activit√© et d'√©largir leur offre via la marketplace ou le dropship, faciliter la gestion des catalogues et des paiements de leurs fournisseurs pour plus d'efficacit√©, offrir une exp√©rience d'achat personnalis√©e √† leurs clients, et augmenter leurs profits gr√¢ce au retail media. Bas√©e √† Paris et Boston, Mirakl est certifi√©e Great Place to Work.\nA propos de Mirakl Labs\nNos √©quipes techniques et produits, nomm√©es Mirakl Labs, sont principalement r√©parties entre nos 2 hubs situ√©s √† Paris et √† Bordeaux. Elles collaborent au quotidien afin d'adresser les probl√©matiques de nos clients et utilisateurs en r√©pondant √† diff√©rents challenges li√©s aux nouvelles fonctionnalit√©s, √† la scalabilit√©, la s√©curit√© et l‚Äôergonomie‚Ä¶\nElles op√®rent en mode agile et s'organisent en Squads compos√©es d'un Squad Lead, de 5 d√©veloppeurs, d'un Product Manager et d'un QA. Chaque Squad est sp√©cialis√©e sur un scope fonctionnel afin de concevoir et r√©aliser de nouvelles features, leurs √©volutions et des APIs (avec un d√©coupage en micro-services). Nos √©quipes Infrastructure, Architecture, S√©curit√©, Documentation, Product Design, Data et Support op√®rent en transverse en apportant leur expertise et de la coh√©rence sur l‚Äôensemble des produits.\nToutes les √©quipes sont responsables de leur p√©rim√®tre et chacun des collaborateurs apporte son exp√©rience et ses id√©es. Innovation, feedback et implication dans les prises de d√©cision sont au c≈ìur de notre philosophie.\nEt pour favoriser ce partage avec d‚Äôautres passionn√©s, nous sommes sponsors, speakers, et h√¥tes de diff√©rents √©v√©nements, meetups, et associations de la sc√®ne Tech en France. Au cours des derni√®res ann√©es, nous avons particip√© √† des √©v√©nements tels que Devoxx, ReactEurope, ProductConf et Flupa UX Days.\nA propos du job\nInt√©gr√©.e dans notre √©quipe Data Science, votre principale mission sera de prototyper, it√©rer, et mettre en production des algorithmes en collaboration avec les √©quipes Produit, les Data Engineers et les √©quipes de d√©veloppement. Les sujets que vous traiterez auront un vrai impact sur nos clients : l‚Äôambition est d‚Äôexploiter au maximum nos donn√©es riches et vari√©es afin de d√©velopper leur chiffre d'affaires, d‚Äôoptimiser la gestion op√©rationnelle de leur marketplace et de garantir la s√©curit√© des utilisateurs et des transactions.\nA propos de l‚Äô√©quipe\nGet to Know the Data Science Team That Powers the Mirakl Platform\nCe qu‚Äôil y a pour vous dans ce job\nImpl√©menter, optimiser et d√©ployer des algorithmes qui auront un impact visible sur plus de 500 sites e-commerce/marketplaces dans 40 pays dont certains une volum√©trie tr√®s importantes (millions de produits, de clients, de commandes par an)\nTraiter des sujets tr√®s divers et vari√©s d‚Äôun point de vue:\nBusiness\nMachine learning (NLP, Image processing, Time series, LLM, syst√®me de recommandation, etc.)\nInfrastructure (spark, model endpoints, etc.)\nUne plateforme Machine Learning et Data Platform state-of-the-art\nConcevoir et d√©ployer des infrastructures √† faible latence avec les Data Engineers\nUne vraie autonomie et responsabilit√© dans les projets dont vous avez l‚Äôownership\nLa possibilit√© d'avoir un contrat freelance ou CDI\nNotre stack et nos outils\nPython, Tensorflow, Pytorch, Databricks, Spark, Aws, Airflow, MLflow, Delta Lake, SQL\nAu quotidien\n,\nvous allez :\nDesigner, optimiser et mettre en production des mod√®les de machine learning de fa√ßon scalable (apprentissage et inf√©rence)\nRassembler et manipuler les donn√©es, prototyper des algorithmes de machine learning\nMettre en place et monitorer des serving endpoints\nParticiper √† l‚Äô√©volution de la plateforme Machine Learning de Mirakl\nContinuer √† mettre en place des best practices de programmation mais aussi de d√©ploiement\nEffectuer de la veille technologique sur les mod√®les state-of-the-art, ainsi que sur les stack machine learning\nPr√©senter les r√©sultats au weekly data science et aux sessions de brainstorming de l‚Äô√©quipe\n√âchanger avec les autres √©quipes pour affiner les cas d‚Äôutilisation, l‚Äôexp√©rience utilisateur et les modes d‚Äôint√©gration\nVous aimerez ce job si :\nVous avez minimum 3 ans d‚Äôexp√©rience en tant que Machine Learning Engineer (le poste est √©volutif selon votre s√©niorit√©)\nVous avez de solides comp√©tences en d√©veloppement Python\nVous aimez le software engineering et le machine learning\nVous avez une exp√©rience significative dans la mise en production, le scaling des mod√®les et des bests practices MLOps\nVous avez l‚Äôhabitude de chercher, manipuler et analyser des donn√©es √† forte volum√©trie, id√©alement avec Spark\nVous avez une bonne connaissance des algorithmes de Deep Learning (texte et/ou image), des architectures State-Of-the-Art - par exemple les Transformers\nVous avez de l‚Äôexp√©rience dans l‚Äôoptimisation de mod√®les de machine learning et de leur inf√©rence\nVous avez de l‚Äôexp√©rience dans la mise en place de serving de mod√®les\nVous aimez avoir l‚Äôownership de vos sujets et aimez partager votre travail dans le cadre de pr√©sentations internes, dans des conf√©rences ou en r√©digeant des articles\nPetit plus :\nVous avez une exp√©rience en environnement e-commerce, sur des algorithmes de syst√®mes de recommandations et/ou retail media\nVous avez une exp√©rience dans le serving de mod√®les √† faible latence\nVous √™tes sp√©cialiste NLP\nOptimisation de LLM\nMirakl est engag√©e en faveur de la diversit√©, de l‚Äô√©galit√© des chances et de l‚Äôinclusion. Nous c√©l√©brons nos diff√©rences car nous sommes convaincus que les qualit√©s visibles et invisibles de chaque Mirakl Worker sont une source de force et d‚Äôinnovation. Dans le cadre de cet engagement, nous √©tudions toutes les candidatures sans distinction de : genre, ethnicit√©, religion, orientation sexuelle, handicap, √¢ge ou toute autre caract√©ristique prot√©g√©e par la loi.\nShow more\nShow less",
        "details": {
            "JobDetail": [],
            "TypeContract": "CDI",
            "Salary": "",
            "Level": "",
            "Experience": "3 an(s)"
        },
        "title": "machine learning engineer",
        "skills": {
            "ProgLanguage": [
                "Python"
            ],
            "DataBase": [
                "SQL"
            ],
            "BigData": [
                "Databricks",
                "Spark"
            ],
            "MachineLearning": [
                "PyTorch",
                "TensorFlow"
            ],
            "CloudComputing": [
                "AWS"
            ],
            "Automation": [
                "Airflow"
            ],
            "Other": [
                "Machine Learning"
            ],
            "EnSoftSkils": [
                "Collaboration"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "Mirakl",
        "location": "Paris, √éle-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/machine-learning-engineer-at-mirakl-3879682593?position=18&pageNum=0&refId=SmRHYtKKcb%2BBbb%2BiSm10Sw%3D%3D&trackingId=D5L5uXrhFBGm5tiiQZQXYg%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Mirakl, leader et pionnier de l‚Äô√©conomie de plateforme, propose aux entreprises une suite unique de solutions leur permettant de transformer significativement leur e-commerce afin d'acc√©l√©rer de fa√ßon durable et rentable leur croissance. Depuis 2012, Mirakl accompagne les entreprises B2C et B2B avec la technologie la plus avanc√©e, s√©curis√©e et √©volutive leur permettant de digitaliser leur activit√© et d'√©largir leur offre via la marketplace ou le dropship, faciliter la gestion des catalogues et des paiements de leurs fournisseurs pour plus d'efficacit√©, offrir une exp√©rience d'achat personnalis√©e √† leurs clients, et augmenter leurs profits gr√¢ce au retail media. Bas√©e √† Paris et Boston, Mirakl est certifi√©e Great Place to Work.\nA propos de Mirakl Labs\nNos √©quipes techniques et produits, nomm√©es Mirakl Labs, sont principalement r√©parties entre nos 2 hubs situ√©s √† Paris et √† Bordeaux. Elles collaborent au quotidien afin d'adresser les probl√©matiques de nos clients et utilisateurs en r√©pondant √† diff√©rents challenges li√©s aux nouvelles fonctionnalit√©s, √† la scalabilit√©, la s√©curit√© et l‚Äôergonomie‚Ä¶\nElles op√®rent en mode agile et s'organisent en Squads compos√©es d'un Squad Lead, de 5 d√©veloppeurs, d'un Product Manager et d'un QA. Chaque Squad est sp√©cialis√©e sur un scope fonctionnel afin de concevoir et r√©aliser de nouvelles features, leurs √©volutions et des APIs (avec un d√©coupage en micro-services). Nos √©quipes Infrastructure, Architecture, S√©curit√©, Documentation, Product Design, Data et Support op√®rent en transverse en apportant leur expertise et de la coh√©rence sur l‚Äôensemble des produits.\nToutes les √©quipes sont responsables de leur p√©rim√®tre et chacun des collaborateurs apporte son exp√©rience et ses id√©es. Innovation, feedback et implication dans les prises de d√©cision sont au c≈ìur de notre philosophie.\nEt pour favoriser ce partage avec d‚Äôautres passionn√©s, nous sommes sponsors, speakers, et h√¥tes de diff√©rents √©v√©nements, meetups, et associations de la sc√®ne Tech en France. Au cours des derni√®res ann√©es, nous avons particip√© √† des √©v√©nements tels que Devoxx, ReactEurope, ProductConf et Flupa UX Days.\nA propos du job\nInt√©gr√©.e dans notre √©quipe Data Science, votre principale mission sera de prototyper, it√©rer, et mettre en production des algorithmes en collaboration avec les √©quipes Produit, les Data Engineers et les √©quipes de d√©veloppement. Les sujets que vous traiterez auront un vrai impact sur nos clients : l‚Äôambition est d‚Äôexploiter au maximum nos donn√©es riches et vari√©es afin de d√©velopper leur chiffre d'affaires, d‚Äôoptimiser la gestion op√©rationnelle de leur marketplace et de garantir la s√©curit√© des utilisateurs et des transactions.\nA propos de l‚Äô√©quipe\nGet to Know the Data Science Team That Powers the Mirakl Platform\nCe qu‚Äôil y a pour vous dans ce job\nImpl√©menter, optimiser et d√©ployer des algorithmes qui auront un impact visible sur plus de 500 sites e-commerce/marketplaces dans 40 pays dont certains une volum√©trie tr√®s importantes (millions de produits, de clients, de commandes par an)\nTraiter des sujets tr√®s divers et vari√©s d‚Äôun point de vue:\nBusiness\nMachine learning (NLP, Image processing, Time series, LLM, syst√®me de recommandation, etc.)\nInfrastructure (spark, model endpoints, etc.)\nUne plateforme Machine Learning et Data Platform state-of-the-art\nConcevoir et d√©ployer des infrastructures √† faible latence avec les Data Engineers\nUne vraie autonomie et responsabilit√© dans les projets dont vous avez l‚Äôownership\nLa possibilit√© d'avoir un contrat freelance ou CDI\nNotre stack et nos outils\nPython, Tensorflow, Pytorch, Databricks, Spark, Aws, Airflow, MLflow, Delta Lake, SQL\nAu quotidien\n,\nvous allez :\nDesigner, optimiser et mettre en production des mod√®les de machine learning de fa√ßon scalable (apprentissage et inf√©rence)\nRassembler et manipuler les donn√©es, prototyper des algorithmes de machine learning\nMettre en place et monitorer des serving endpoints\nParticiper √† l‚Äô√©volution de la plateforme Machine Learning de Mirakl\nContinuer √† mettre en place des best practices de programmation mais aussi de d√©ploiement\nEffectuer de la veille technologique sur les mod√®les state-of-the-art, ainsi que sur les stack machine learning\nPr√©senter les r√©sultats au weekly data science et aux sessions de brainstorming de l‚Äô√©quipe\n√âchanger avec les autres √©quipes pour affiner les cas d‚Äôutilisation, l‚Äôexp√©rience utilisateur et les modes d‚Äôint√©gration\nVous aimerez ce job si :\nVous avez minimum 3 ans d‚Äôexp√©rience en tant que Machine Learning Engineer (le poste est √©volutif selon votre s√©niorit√©)\nVous avez de solides comp√©tences en d√©veloppement Python\nVous aimez le software engineering et le machine learning\nVous avez une exp√©rience significative dans la mise en production, le scaling des mod√®les et des bests practices MLOps\nVous avez l‚Äôhabitude de chercher, manipuler et analyser des donn√©es √† forte volum√©trie, id√©alement avec Spark\nVous avez une bonne connaissance des algorithmes de Deep Learning (texte et/ou image), des architectures State-Of-the-Art - par exemple les Transformers\nVous avez de l‚Äôexp√©rience dans l‚Äôoptimisation de mod√®les de machine learning et de leur inf√©rence\nVous avez de l‚Äôexp√©rience dans la mise en place de serving de mod√®les\nVous aimez avoir l‚Äôownership de vos sujets et aimez partager votre travail dans le cadre de pr√©sentations internes, dans des conf√©rences ou en r√©digeant des articles\nPetit plus :\nVous avez une exp√©rience en environnement e-commerce, sur des algorithmes de syst√®mes de recommandations et/ou retail media*\nVous avez une exp√©rience dans le serving de mod√®les √† faible latence\nVous √™tes sp√©cialiste NLP\nOptimisation de LLM\nMirakl est engag√©e en faveur de la diversit√©, de l‚Äô√©galit√© des chances et de l‚Äôinclusion. Nous c√©l√©brons nos diff√©rences car nous sommes convaincus que les qualit√©s visibles et invisibles de chaque Mirakl Worker sont une source de force et d‚Äôinnovation. Dans le cadre de cet engagement, nous √©tudions toutes les candidatures sans distinction de : genre, ethnicit√©, religion, orientation sexuelle, handicap, √¢ge ou toute autre caract√©ristique prot√©g√©e par la loi.\nShow more\nShow less",
        "details": {
            "JobDetail": [],
            "TypeContract": "CDI",
            "Salary": "",
            "Level": "",
            "Experience": "3 an(s)"
        },
        "title": "machine learning engineer",
        "skills": {
            "ProgLanguage": [
                "Python"
            ],
            "DataBase": [
                "SQL"
            ],
            "BigData": [
                "Databricks",
                "Spark"
            ],
            "MachineLearning": [
                "PyTorch",
                "TensorFlow"
            ],
            "CloudComputing": [
                "AWS"
            ],
            "Automation": [
                "Airflow"
            ],
            "Other": [
                "Machine Learning"
            ],
            "EnSoftSkils": [
                "Collaboration"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "Capgemini",
        "location": "Toulouse, Occitanie, France",
        "link": "https://fr.linkedin.com/jobs/view/data-scientist-toulouse-at-capgemini-3913358664?position=19&pageNum=0&refId=SmRHYtKKcb%2BBbb%2BiSm10Sw%3D%3D&trackingId=%2F7xxP1SjvWCymZabufXsLA%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Capgemini en quelques mots\nChoisir Capgemini, c'est choisir une entreprise o√π vous serez en mesure de fa√ßonner votre carri√®re selon vos aspirations, o√π vous serez soutenu et inspir√© par une communaut√© d‚Äôexperts dans le monde entier, o√π vous pourrez r√©√©crire votre futur. Rejoignez-nous pour red√©finir les limites de ce qui est possible, contribuer √† lib√©rer la valeur de la technologie pour les plus grandes organisations et participez √† la construction d‚Äôun monde plus durable et inclusif.\nVos missions\nEn tant que\nLead Technique Data Science\nau sein de la practice Insights & Data, vous serez amener √† intervenir sur des projets data pour :\nId√©aliser les cas d‚Äôusages et cadrer le projet afin de r√©pondre aux exigences m√©tiers √† partir de solutions innovantes d‚ÄôIntelligence Artificielle\nPromouvoir les bonnes pratiques au sein de l‚Äô√©quipe avec le d√©veloppement d‚Äôune m√©thodologie de travail et d‚Äôam√©lioration continue appropri√©s\nParticiper aux propositions commerciales sur la partie Data\nConstruire une relation de confiance avec le client en tant qu‚Äôinterlocuteur privil√©gi√© et assurer la qualit√© des rendus finaux ainsi que le d√©veloppement de nouveaux enjeux business\nFaire parti des leaders de la communaut√© Data Science et influencer sur la strat√©gie Data d‚ÄôInsights & Data\nContinuer de vous former sur tous les aspects de votre m√©tier et assurer une veille technologique sur les innovations les plus pertinentes √† mettre en place\nVotre profil\nDe formation Bac + 5 en √©cole d‚Äôing√©nieur ou √©quivalent universitaire avec une sp√©cialisation Data Science\nA partir de 6 ans d‚Äôexp√©riences\nCompr√©hension fine des enjeux business et pilotage d'une √©quipe\nConnaissance de plusieurs langages de programmation (Python, Scala, Spark‚Ä¶) et Cloud (AWS, GCP, Azure, OVH)\nLe Machine Learning, le NLP et le Deep Learning n‚Äôont plus de secret pour vous\nBon niveau d'anglais\n3 raisons de nous rejoindre\nQualit√© de vie au travail :\naccord de t√©l√©travail en France et √† l‚Äôinternational, accord sur l‚Äô√©galit√©\nprofessionnelle, la parentalit√©, l‚Äô√©quilibre des temps et la mobilit√© durable.\nApprentissage en continu :\ncertifications et formations en libre acc√®s, accompagnement sur mesure avec\nvotre carreer manager, parcours d‚Äôint√©gration sur 9 mois.\nAvantages groupe & CSE :\nplan actionnariat, activit√©s √† tarifs pr√©f√©rentiels, remboursement partiel\nvacances, remboursement de votre abonnement sportif ou culturel\nNos engagements et priorit√©s\nLe groupe Capgemini encourage une\nculture inclusive dans un cadre multiculturel et handi-accueillant.\nEn nous rejoignant, vous int√©grez un collectif qui valorise la diversit√©, d√©veloppe le potentiel de ses talents, s‚Äôengage dans des\ninitiatives solidaires avec ses partenaires, et se mobilise pour r√©duire son impact environnemental sur tous ses sites et aupr√®s de ses clients.\nCapgemini\nest un\nleader mondial\n, responsable et multiculturel, regroupant pr√®s de 350 000 personnes dans plus de 50 pays. Fort de\n55 ans d‚Äôexp√©rience\n, nous sommes un partenaire strat√©gique des entreprises pour la transformation de leurs activit√©s en tirant profit de toute la puissance de la technologie et des innovations dans les domaines en perp√©tuelle √©volution tels que\nle cloud, la data, l‚ÄôIntelligence Artificielle, la connectivit√©, les logiciels, l‚Äôing√©nierie digitale ou les plateformes.\nGet The Future You Want* | www.capgemini.com/fr-fr\n*Capgemini, le futur que vous voulez\nShow more\nShow less",
        "details": {
            "JobDetail": [],
            "TypeContract": "",
            "Salary": "",
            "Level": "",
            "Experience": "6 an(s)"
        },
        "title": "data scientist",
        "skills": {
            "ProgLanguage": [
                "Scala",
                "Python"
            ],
            "BigData": [
                "Spark"
            ],
            "CloudComputing": [
                "GCP",
                "AWS",
                "Azure"
            ],
            "Other": [
                "Machine Learning",
                "Cloud"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "MindPal",
        "location": "Paris, √éle-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/machine-learning-developer-at-mindpal-3896993704?position=20&pageNum=0&refId=SmRHYtKKcb%2BBbb%2BiSm10Sw%3D%3D&trackingId=nGn9TarDKfgaojpLIy%2FYUQ%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "We are looking for\nMachine Learning Developer\nJob Responsibilities\nWorking on machine learning projects\nAnalyzing and processing data to create machine learning models\nImplementing and optimizing machine learning algorithms\nTesting and evaluating models\nCollaborating with the programming team and other departments within the company to develop innovative solutions\nRequirements\nMinimum 2 years of experience in the field of machine learning\nKnowledge of machine learning algorithms and techniques\nAbility to analyze and process data\nFamiliarity with machine learning tools and technologies\nProficient in English communication\nEducation in computer science\nWe Offer\nB2B contract type\nFull-time employment\nRemote and flexible working hours\nShow more\nShow less",
        "details": {
            "JobDetail": [
                "Remote",
                "Full"
            ],
            "TypeContract": "",
            "Salary": "",
            "Level": "",
            "Experience": null
        },
        "title": "Other",
        "skills": {
            "Other": [
                "Machine Learning"
            ],
            "EnSoftSkils": [
                "Communication"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "Manpower",
        "location": "Saint-√âtienne",
        "link": "https://fr.linkedin.com/jobs/view/data-scientist-h-f-at-manpower-3909184596?position=21&pageNum=0&refId=SmRHYtKKcb%2BBbb%2BiSm10Sw%3D%3D&trackingId=BySBcLKv4f0wHrIBzEA9BA%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Vous le saviez ?\n‚ÄãLe m√©tier de DATA SCIENTIST H/F a √©t√© √©lu le ¬´ m√©tier le plus sexy du XXIe si√®cle ¬ª, par le Harvard Business Review !\n‚Äã\nRejoignez donc une √©quipe passionn√©e et dynamique au sein d'une entreprise incontest√©e des syst√®mes automatis√©s et d'√©nergie, qui repousse constamment les limites de la technologie et en pleine croissance !\nLes missions\nEn tant que Data Scientist H/F, vous √™tes sensibilis√©s aux risques √©ventuels et vous pouvez envisager de mettre en place des mesures ad√©quates pour s√©curiser les donn√©es et les syst√®mes contre les menaces.\nVos missions seront donc :\nRassemblement, purification et manipulation d'ensembles de donn√©es massifs provenant de diverses sources telles que des bases de donn√©es internes et externes, des API et des donn√©es non structur√©es.\nConception et impl√©mentation de mod√®les pr√©dictifs et d'algorithmes d'apprentissage automatique pour r√©soudre des d√©fis commerciaux complexes.\nR√©alisation d'analyses statistiques approfondies afin d'identifier des tendances, des sch√©mas et des insights significatifs.\nCollaboration √©troite avec les √©quipes interfonctionnelles pour comprendre leurs besoins en donn√©es et proposer des solutions analytiques.\nCr√©ation de tableaux de bord interactifs, de visualisations de donn√©es et de rapports pour une communication efficace des r√©sultats d'analyse aux parties prenantes.\nVeille constante sur les avanc√©es technologiques en science des donn√©es et proposition d'am√©liorations continues pour les processus et m√©thodologies existants.\nLe profil\nEt si on parlait de vous...\n‚ÄãVous disposez de qualifications dans les domaines des sciences des donn√©es, de l'informatique, des math√©matiques, des statistiques, de l'√©conomie, de l'informatique, de la gestion, de l'ing√©nierie industrielle ou dans des domaines connexes.\nVous avez une exp√©rience pertinente dans ce domaine.\nVous √™tes familier avec les concepts de collecte, d'extraction et d'analyse de donn√©es.\nVous poss√©dez des comp√©tences analytiques et √™tes capable de travailler en √©quipe.\nVous √™tes capable de pr√©senter des informations complexes de mani√®re claire et compr√©hensible.\nVous maitrisez les langages de programmation courants tels que Python, R ou SQL ainsi que l'anglais professionnel.\nVous poss√©dez des comp√©tences avanc√©es en analyse statistique et en mod√©lisation pr√©dictive.\nVous √™tes dot√© d'une exp√©rience pratique avec les biblioth√®ques et les frameworks d'apprentissage automatique tels que TensorFlow, Scikit-Learn ou PyTorch.\nConditions & avantages :\nCDI Temps plein\nD√©placements √† pr√©voir en France et √† l'international (EMEA Germany, Italy, Spain, UK) selon besoin de l'activit√©\nSalaire ouvert fonction de vos pr√©tentions salariales, adaptable au profil !\nStatut cadre forfait jour\nRTT\nTickets restaurant\nParticipation et int√©ressement\nVous vous reconnaissez ?\nN'h√©sitez plus, postulez !!\nShow more\nShow less",
        "details": {
            "JobDetail": [
                "Temps plein"
            ],
            "TypeContract": "CDI",
            "Salary": "Salaire",
            "Level": "",
            "Experience": null
        },
        "title": "data scientist",
        "skills": {
            "ProgLanguage": [
                "R",
                "Python"
            ],
            "DataBase": [
                "SQL"
            ],
            "DataAnalytics": [
                "R"
            ],
            "MachineLearning": [
                "Scikit-Learn",
                "TensorFlow",
                "PyTorch"
            ],
            "Other": [
                "Statistiques"
            ],
            "EnSoftSkils": [
                "Communication",
                "Collaboration"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "Scaleway",
        "location": "Paris, √éle-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/ml-engineer-at-scaleway-3828501763?position=22&pageNum=0&refId=SmRHYtKKcb%2BBbb%2BiSm10Sw%3D%3D&trackingId=ypy1yg4PbYLPlrSSuhasqA%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "About The Job\nThe newly established Inference team at Scaleway is on a mission to revolutionize how Machine Learning (ML) is deployed and scaled in the cloud. We are seeking a talented ML Engineer to join us in developing and deploying Large Language Model (LLM) endpoints on both dedicated instances and serverless environments. As we plan to broaden our offerings to include various types of ML models later this year, this role offers a unique opportunity to be at the forefront of ML technology and its application in the cloud.\nReporting to our Manager, Gr√©goire de Turckheim, you will play a crucial role in building and optimizing ML model deployments, ensuring high performance, scalability, and reliability.\nMinimum Qualifications\nProficient in Python and familiar with other programming languages such as Go\nStrong background in Machine Learning, including experience with LLMs, NLP, or other ML model types\nExperience with ML frameworks (e.g., TensorFlow, PyTorch) and understanding of MLOps principles\nKnowledge of deploying ML models in cloud environments, including serverless architectures\nFamiliarity with container technologies (Docker, Kubernetes) and orchestration systems\nUnderstanding of REST and gRPC APIs for integrating ML models into applications\nExcellent command of English, both written and verbal\nPreferred Qualifications\nGood understanding of Linux system administration and cloud ecosystems\nResponsibilities\nOptimize ML models for high performance and low latency in cloud environments\nDesign, develop, and maintain scalable and efficient ML model deployments, focusing on LLMs initially and expanding to other models\nCollaborate with the Inference team to architect and implement serverless solutions for ML model hosting\nEnsure the reliability, availability, and security of ML model deployments\nStay abreast of the latest ML technologies and cloud trends to continuously improve our offerings\nTechnical Stack\nProgramming Languages: Python, Go\nML Frameworks: TensorFlow, PyTorch\nContainer Technologies: Kubernetes, Docker\nCloud and Serverless Technologies\nLinux Systems\nData Storage: S3, PostgreSQL, Redis\nVersion Control: Git\nLocation\nThis position is based in our offices in Paris or Lille (France)\nRecruitment Process\nScreening call - 30 mins with the recruiter\nManager Interview - 45 mins\nTechnical Interviews / or Home Assignment\nTeam Interview\nHR Interview - 45 mins\nOffer sent\nShow more\nShow less",
        "details": {
            "JobDetail": [],
            "TypeContract": "",
            "Salary": "",
            "Level": "",
            "Experience": null
        },
        "title": "machine learning engineer",
        "skills": {
            "ProgLanguage": [
                "Python"
            ],
            "MachineLearning": [
                "PyTorch",
                "TensorFlow"
            ],
            "DevTools": [
                "Git",
                "Docker"
            ],
            "OS": [
                "Linux"
            ],
            "DBMS": [
                "PostgreSQL"
            ],
            "Automation": [
                "Kubernetes"
            ],
            "Containers": [
                "Docker",
                "Kubernetes"
            ],
            "Other": [
                "Machine Learning",
                "Cloud",
                "ML"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "MERITIS",
        "location": "√éle-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/data-scientist-h-f-at-meritis-3869246366?position=23&pageNum=0&refId=SmRHYtKKcb%2BBbb%2BiSm10Sw%3D%3D&trackingId=0OPd9t4vgiPlMZYnYQp25w%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Nous recherchons un\nData Scientist\npour intervenir dans le cadre d'un\nprojet de d√©tection de document.\nVos missions :\nSujet de\nfraude documentaire:\nla probl√©matique est de d√©tecter si un document (RIB ou pi√®ce d‚Äôidentit√©) a √©t√© manipul√© (montage, remplacement de la photo d‚Äôidentit√©, changement du nom/pr√©nom, ou de l‚ÄôIBAN etc).\nLes technos connues utilis√©es:\nPython avec les libs/framework suivants : pytorch, jupyterlab, pandas\nMod√®les : layoutLM (techno √† priori assez r√©cente), yolo, resnet (classique), docTR (ocr)\nConnaitre les transformers\nAutre : Labelstudio\nCe poste est-il fait pour vous\n? :\nVous √™tes dipl√¥m√© d'un\nBac +5\net justifiez d'\nau moins 4 ans d'exp√©rience\nVous √™tes\nproactif et autonome ‚Äã\nVous aimez travailler\nau contact de plusieurs √©quipes m√©tiers\nConnaissance du secteur de l'assurance obligatoire\nDescriptif de l‚Äôentreprise :\n‚Äã\nMeritis est un cabinet de conseil, pilotage et d√©veloppement IT fond√© en 2007 pr√©sent √† Paris, Sophia-Antipolis, Aix-en-Provence, Montpellier, Toulouse, Nantes... Et bient√¥t sur de nouveaux territoires ! Notre mission ? Connecter les meilleurs talents aux entreprises pour leur donner un temps d‚Äôavance.‚Äã\nNous accompagnons nos clients dans l‚Äôint√©gralit√© de leurs besoins en transformation num√©rique √† travers de nombreux domaines d‚Äôexpertises : Software Engineering, Finance, Pilotage de projets, Devops, Data, Cloud, Cybers√©curit√© ou encore Agilit√©.‚Äã\nIntervenant aussi bien dans les secteurs de la Banque, de l'Assurance, des T√©l√©communications que de l'Industrie ou des Transports, aujourd'hui 40% des entreprises du CAC40 sont clientes Meritis.‚Äã\nFort de nos valeurs d‚Äôexigence, d‚Äôhumilit√©, de bienveillance et de proximit√©, nous comptons aujourd‚Äôhui plus de 900 collaborateurs.‚Äã\nNous mettons un point d‚Äôhonneur √† √™tre proche de nos collaborateurs et √† les accompagner de mani√®re individualis√©e quelles que soient leurs fonctions dans l‚Äôentreprise.\nCertifi√©e Great Place To Work depuis 2013, notre conception du bien-√™tre au travail va bien au-del√† d'un simple label, ce sont nos collaborateurs qui en parlent le mieux : https://www.glassdoor.fr/Avis/Meritis-Avis-E1163008.htm.‚Äã\nVos diff√©rences sont nos atouts. C‚Äôest pourquoi Meritis est engag√©e en faveur de la diversit√© et de la non-discrimination. Tous nos m√©tiers sont accessibles aux personnes en situation de handicap. Si vous avez une question ou pensez √™tre victime ou t√©moin d‚Äôune discrimination, vous pouvez contacter ethiquegroup@meritis.fr. ¬ª\nShow more\nShow less",
        "details": {
            "JobDetail": [],
            "TypeContract": "",
            "Salary": "",
            "Level": "",
            "Experience": "4 an(s)"
        },
        "title": "data scientist",
        "skills": {
            "ProgLanguage": [
                "Python"
            ],
            "DataAnalytics": [
                "Pandas"
            ],
            "MachineLearning": [
                "PyTorch"
            ],
            "Other": [
                "Cloud",
                "DevOps"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "Lincoln France",
        "location": "√éle-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/data-scientist-h-f-at-lincoln-france-3892490370?position=24&pageNum=0&refId=SmRHYtKKcb%2BBbb%2BiSm10Sw%3D%3D&trackingId=qFAnBCm28UeS6i2VeF1bcA%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "CDI\nüìä\n4 ans minimum\nChez Lincoln\n, nous formons une communaut√© d'innovateurs passionn√©s qui red√©finissent l'analyse de donn√©es depuis\nplus de 30 ans\n. En tant que\nPure Player Data\n, notre expertise est reconnue dans les domaines\nde la Modern BI, du Big Data et de la Science des donn√©es\n.\nNotre mission ?\nTransformer les donn√©es en solutions concr√®tes pour nos clients grands comptes dans divers secteurs tels que la banque, le retail, les t√©l√©coms, l'industrie, la sant√©, etc.\nDescription du poste\nNous recherchons un\nData Scientist H/F\npour accompagner nos clients dans leurs projets strat√©giques.\nVos missions\nCollecter, nettoyer et pr√©parer les donn√©es pour l'analyse.\nConcevoir, d√©velopper et mettre en ≈ìuvre des mod√®les pr√©dictifs et analytiques en utilisant des techniques avanc√©es d'apprentissage automatique et de science des donn√©es.\nAnalyser les r√©sultats des mod√®les et fournir des insights exploitables aux √©quipes clients.\nCollaborer avec les √©quipes interfonctionnelles pour comprendre les besoins commerciaux et recommander des solutions bas√©es sur les donn√©es.\nPr√©requis :\nSolides comp√©tences en programmation (\nPython, R, SQL, etc.)\net en manipulation de donn√©es.\nExp√©rience pratique avec des frameworks et des biblioth√®ques d'apprentissage automatique (\nTensorFlow, PyTorch, Scikit-learn\n,\netc\n.).\nMa√Ætrise des techniques avanc√©es d'analyse de donn√©es, y compris l'apprentissage automatique, l'apprentissage profond, la vision par ordinateur, le traitement du langage naturel, etc.\nExp√©rience de travail en\nm√©thode Agile\npour la gestion de projet et le d√©veloppement de solutions.\nCapacit√© √† travailler de mani√®re autonome et en √©quipe.\nExcellentes comp√©tences en communication et en pr√©sentation.\nLes plus du poste\nEnvironnement Collaboratif\n: projets innovants favorisant le partage des connaissances.\nAccompagnement individualis√© et de proximit√©\n: formations certifiantes, attribution d‚Äôun Career Manager pour vous orienter dans votre trajectoire professionnelle, opportunit√©s d‚Äô√©volution de carri√®re.\nFlexibilit√© du Travail\n: T√©l√©travail et horaires flexibles pour votre √©quilibre vie professionnelle-personnelle.\nR√©mun√©ration Comp√©titive\n: Salaire comp√©titif avec des avantages sociaux attrayants.\nMobilit√©\n: Possibilit√© de mobilit√© √† Lille, Lyon ou Aix-en-Provence offrant des exp√©riences diversifi√©es au sein de Lincoln.\nNotre processus de recrutement :\nUn entretien RH (1h) et entretien technique (1h)\nCette annonce n‚Äôest pas faite pour vous si :\nVous √™tes freelance et vous comptez le rester !\nToujours l√† ? Postulez et rejoignez nos\n400 experts en Data\nüòâ.\nShow more\nShow less",
        "details": {
            "JobDetail": [],
            "TypeContract": "CDI",
            "Salary": "400",
            "Level": "",
            "Experience": "4 an(s)"
        },
        "title": "data scientist",
        "skills": {
            "ProgLanguage": [
                "R",
                "Python"
            ],
            "DataBase": [
                "SQL"
            ],
            "DataAnalytics": [
                "R"
            ],
            "MachineLearning": [
                "Scikit-Learn",
                "TensorFlow",
                "PyTorch"
            ],
            "Other": [
                "Big Data"
            ],
            "EnSoftSkils": [
                "Communication"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "Mirakl",
        "location": "Bordeaux, Nouvelle-Aquitaine, France",
        "link": "https://fr.linkedin.com/jobs/view/machine-learning-engineer-at-mirakl-3879681732?position=25&pageNum=0&refId=SmRHYtKKcb%2BBbb%2BiSm10Sw%3D%3D&trackingId=pC%2Fm5oy%2B%2BtTLT0noRXJyHQ%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Mirakl, leader et pionnier de l‚Äô√©conomie de plateforme, propose aux entreprises une suite unique de solutions leur permettant de transformer significativement leur e-commerce afin d'acc√©l√©rer de fa√ßon durable et rentable leur croissance. Depuis 2012, Mirakl accompagne les entreprises B2C et B2B avec la technologie la plus avanc√©e, s√©curis√©e et √©volutive leur permettant de digitaliser leur activit√© et d'√©largir leur offre via la marketplace ou le dropship, faciliter la gestion des catalogues et des paiements de leurs fournisseurs pour plus d'efficacit√©, offrir une exp√©rience d'achat personnalis√©e √† leurs clients, et augmenter leurs profits gr√¢ce au retail media. Bas√©e √† Paris et Boston, Mirakl est certifi√©e Great Place to Work.\nA propos de Mirakl Labs\nNos √©quipes techniques et produits, nomm√©es Mirakl Labs, sont principalement r√©parties entre nos 2 hubs situ√©s √† Paris et √† Bordeaux. Elles collaborent au quotidien afin d'adresser les probl√©matiques de nos clients et utilisateurs en r√©pondant √† diff√©rents challenges li√©s aux nouvelles fonctionnalit√©s, √† la scalabilit√©, la s√©curit√© et l‚Äôergonomie‚Ä¶\nElles op√®rent en mode agile et s'organisent en Squads compos√©es d'un Squad Lead, de 5 d√©veloppeurs, d'un Product Manager et d'un QA. Chaque Squad est sp√©cialis√©e sur un scope fonctionnel afin de concevoir et r√©aliser de nouvelles features, leurs √©volutions et des APIs (avec un d√©coupage en micro-services). Nos √©quipes Infrastructure, Architecture, S√©curit√©, Documentation, Product Design, Data et Support op√®rent en transverse en apportant leur expertise et de la coh√©rence sur l‚Äôensemble des produits.\nToutes les √©quipes sont responsables de leur p√©rim√®tre et chacun des collaborateurs apporte son exp√©rience et ses id√©es. Innovation, feedback et implication dans les prises de d√©cision sont au c≈ìur de notre philosophie.\nEt pour favoriser ce partage avec d‚Äôautres passionn√©s, nous sommes sponsors, speakers, et h√¥tes de diff√©rents √©v√©nements, meetups, et associations de la sc√®ne Tech en France. Au cours des derni√®res ann√©es, nous avons particip√© √† des √©v√©nements tels que Devoxx, ReactEurope, ProductConf et Flupa UX Days.\nA propos du job\nInt√©gr√©.e dans notre √©quipe Data Science, votre principale mission sera de prototyper, it√©rer, et mettre en production des algorithmes en collaboration avec les √©quipes Produit, les Data Engineers et les √©quipes de d√©veloppement. Les sujets que vous traiterez auront un vrai impact sur nos clients : l‚Äôambition est d‚Äôexploiter au maximum nos donn√©es riches et vari√©es afin de d√©velopper leur chiffre d'affaires, d‚Äôoptimiser la gestion op√©rationnelle de leur marketplace et de garantir la s√©curit√© des utilisateurs et des transactions.\nA propos de l‚Äô√©quipe\nGet to Know the Data Science Team That Powers the Mirakl Platform\nCe qu‚Äôil y a pour vous dans ce job\nImpl√©menter, optimiser et d√©ployer des algorithmes qui auront un impact visible sur plus de 500 sites e-commerce/marketplaces dans 40 pays dont certains une volum√©trie tr√®s importantes (millions de produits, de clients, de commandes par an)\nTraiter des sujets tr√®s divers et vari√©s d‚Äôun point de vue:\nBusiness\nMachine learning (NLP, Image processing, Time series, LLM, syst√®me de recommandation, etc.)\nInfrastructure (spark, model endpoints, etc.)\nUne plateforme Machine Learning et Data Platform state-of-the-art\nConcevoir et d√©ployer des infrastructures √† faible latence avec les Data Engineers\nUne vraie autonomie et responsabilit√© dans les projets dont vous avez l‚Äôownership\nLa possibilit√© d'avoir un contrat freelance ou CDI\nNotre stack et nos outils\nPython, Tensorflow, Pytorch, Databricks, Spark, Aws, Airflow, MLflow, Delta Lake, SQL\nAu quotidien\n,\nvous allez :\nDesigner, optimiser et mettre en production des mod√®les de machine learning de fa√ßon scalable (apprentissage et inf√©rence)\nRassembler et manipuler les donn√©es, prototyper des algorithmes de machine learning\nMettre en place et monitorer des serving endpoints\nParticiper √† l‚Äô√©volution de la plateforme Machine Learning de Mirakl\nContinuer √† mettre en place des best practices de programmation mais aussi de d√©ploiement\nEffectuer de la veille technologique sur les mod√®les state-of-the-art, ainsi que sur les stack machine learning\nPr√©senter les r√©sultats au weekly data science et aux sessions de brainstorming de l‚Äô√©quipe\n√âchanger avec les autres √©quipes pour affiner les cas d‚Äôutilisation, l‚Äôexp√©rience utilisateur et les modes d‚Äôint√©gration\nVous aimerez ce job si :\nVous avez minimum 3 ans d‚Äôexp√©rience en tant que Machine Learning Engineer (le poste est √©volutif selon votre s√©niorit√©)\nVous avez de solides comp√©tences en d√©veloppement Python\nVous aimez le software engineering et le machine learning\nVous avez une exp√©rience significative dans la mise en production, le scaling des mod√®les et des bests practices MLOps\nVous avez l‚Äôhabitude de chercher, manipuler et analyser des donn√©es √† forte volum√©trie, id√©alement avec Spark\nVous avez une bonne connaissance des algorithmes de Deep Learning (texte et/ou image), des architectures State-Of-the-Art - par exemple les Transformers\nVous avez de l‚Äôexp√©rience dans l‚Äôoptimisation de mod√®les de machine learning et de leur inf√©rence\nVous avez de l‚Äôexp√©rience dans la mise en place de serving de mod√®les\nVous aimez avoir l‚Äôownership de vos sujets et aimez partager votre travail dans le cadre de pr√©sentations internes, dans des conf√©rences ou en r√©digeant des articles\nPetit plus :\nVous avez une exp√©rience en environnement e-commerce, sur des algorithmes de syst√®mes de recommandations et/ou retail media*\nVous avez une exp√©rience dans le serving de mod√®les √† faible latence\nVous √™tes sp√©cialiste NLP\nOptimisation de LLM\nMirakl est engag√©e en faveur de la diversit√©, de l‚Äô√©galit√© des chances et de l‚Äôinclusion. Nous c√©l√©brons nos diff√©rences car nous sommes convaincus que les qualit√©s visibles et invisibles de chaque Mirakl Worker sont une source de force et d‚Äôinnovation. Dans le cadre de cet engagement, nous √©tudions toutes les candidatures sans distinction de : genre, ethnicit√©, religion, orientation sexuelle, handicap, √¢ge ou toute autre caract√©ristique prot√©g√©e par la loi.\nShow more\nShow less",
        "details": {
            "JobDetail": [],
            "TypeContract": "CDI",
            "Salary": "",
            "Level": "",
            "Experience": "3 an(s)"
        },
        "title": "machine learning engineer",
        "skills": {
            "ProgLanguage": [
                "Python"
            ],
            "DataBase": [
                "SQL"
            ],
            "BigData": [
                "Databricks",
                "Spark"
            ],
            "MachineLearning": [
                "PyTorch",
                "TensorFlow"
            ],
            "CloudComputing": [
                "AWS"
            ],
            "Automation": [
                "Airflow"
            ],
            "Other": [
                "Machine Learning"
            ],
            "EnSoftSkils": [
                "Collaboration"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "VINCI Airports",
        "location": "Nanterre, √éle-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/data-scientist-f-m-at-vinci-airports-3888479165?position=26&pageNum=0&refId=SmRHYtKKcb%2BBbb%2BiSm10Sw%3D%3D&trackingId=fj6Yvs1%2FceyNOEErfKRB%2BA%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Premier op√©rateur a√©roportuaire priv√© au monde,\nVINCI Airports\ng√®re plus de 70 a√©roports dans 13 pays en Europe, en Asie et sur le continent am√©ricain. Gr√¢ce √† son expertise d‚Äôint√©grateur global, VINCI Airports d√©veloppe, finance, construit et exploite les a√©roports en apportant sa capacit√© d‚Äôinvestissement et son savoir-faire dans l‚Äôoptimisation de la performance op√©rationnelle, la modernisation des infrastructures et la conduite de leur transition environnementale.\nNous recherchons actuellement\nun(e) Data Scientist (F/M)\nen CDI.\nRattach√©(e) au D√©partement Data de la Direction financi√®re de VINCI Airports, vous participerez, en coordination avec les √©quipes m√©tiers et appuy√©(e) par l‚Äô√©quipe d‚Äôing√©nieurs Data (si√®ge VINCI Airports et Pays), √† la mise en ≈ìuvre du projet ¬´ SMART DATA HUB ¬ª, un projet strat√©gique et passionnant, qui a pour vocation de fournir √† l‚Äôensemble des a√©roports du groupe la capacit√© √† mieux piloter la performance de l‚Äôactivit√© autour de la Data.\nPour ce faire vous serez amen√©(e) √† d√©velopper des solutions avanc√©es en Data Science, Mod√®les de Machine Learning, avec un accent particulier sur le traitement du langage naturel (NLP) dans le d√©partement Data de VINCI Airports pour les besoins de digitalisation et d‚Äôam√©lioration des processus de VINCI Airports.\nMissions :\nMod√©lisation et pr√©vision : Concevoir, d√©velopper et mettre en ≈ìuvre des mod√®les statistiques et algorithmiques. Utiliser des m√©thodes d'apprentissage automatique et d'intelligence artificielle (IA) pour cr√©er des mod√®les pr√©dictifs.\nAnalyse des donn√©es : Collecter, nettoyer et pr√©parer les donn√©es brutes en vue de leur analyse. Utiliser des techniques de visualisation et des outils statistiques pour explorer et comprendre les ensembles de donn√©es.\nExploitation des donn√©es : Identifier les opportunit√©s d'am√©lioration des processus et des performances en utilisant les donn√©es disponibles. Travailler en √©troite collaboration avec les √©quipes op√©rationnelles pour comprendre leurs besoins et proposer des solutions bas√©es sur les donn√©es.\nCommunication des r√©sultats : Pr√©senter les r√©sultats de l'analyse de mani√®re claire et compr√©hensible √† des publics non techniques. Collaborer avec des √©quipes multidisciplinaires pour fournir des recommandations bas√©es sur les donn√©es pour la prise de d√©cision strat√©gique.\nTravailler sur des projets impliquant des mod√®les de langage comme GPT d√©velopp√©s par Open AI ou Google (ou autres nouvelles solutions sur le march√©).\nParticiper √† des formations et des ateliers avec les analystes de VINCI Airports pour d√©velopper leurs comp√©tences techniques et m√©thodologiques gr√¢ce aux solutions Data science/NLP.\nL‚Äôensemble de ces actions seront √† entreprendre sur l‚Äôensemble des domaines m√©tiers de VINCI Airports : Trafic, commercial, op√©rations...\nEffectuer une veille constante sur les derni√®res avanc√©es en Data Science, LLM et NLP pour proposer des solutions innovantes et les int√©grer aux mod√®les d√©velopp√©s par l‚Äô√©quipe Data.\nLe profil que nous recherchons √† ce poste :\nDipl√¥me universitaire (Bac+5) en statistiques, math√©matiques, informatique, science des donn√©es, Intelligence Artificielle ou un domaine connexe.\nExp√©rience pratique dans l'analyse de donn√©es et l'utilisation d'outils d'analyse tels que Python, R, SAS, SQL,‚Ä¶\nBonne connaissance des techniques d'apprentissage automatique (machine learning), des algorithmes statistiques et de l'analyse pr√©dictive.\nConnaissance approfondie des concepts de Machine Learning et des biblioth√®ques telles que TensorFlow, PyTorch, Scikit-Learn.\nMotivation pour la recherche et la r√©solution de probl√®mes complexes.\nInt√©r√™t et exp√©rience en traitement du langage naturel (NLP), y compris la familiarit√© avec les mod√®les de langage comme GPT.\nCapacit√© √† travailler de mani√®re autonome et √† g√©rer efficacement les projets, tout en respectant les d√©lais impartis.\nComp√©tences en communication orale et √©crite pour pr√©senter des r√©sultats complexes de mani√®re claire et concise.\nCuriosit√© intellectuelle et passion pour l'exploration des donn√©es afin de d√©couvrir des informations cach√©es et de g√©n√©rer des id√©es novatrices.\nTravail en √©quipe.\nVous √™tes capable de converser en Anglais.\nShow more\nShow less",
        "details": {
            "JobDetail": [],
            "TypeContract": "CDI",
            "Salary": "",
            "Level": "Bac+5",
            "Experience": null
        },
        "title": "data scientist",
        "skills": {
            "ProgLanguage": [
                "R",
                "Python"
            ],
            "DataBase": [
                "SQL"
            ],
            "DataAnalytics": [
                "R"
            ],
            "MachineLearning": [
                "Scikit-Learn",
                "TensorFlow",
                "PyTorch"
            ],
            "Other": [
                "Statistiques",
                "Machine Learning"
            ],
            "EnSoftSkils": [
                "Communication",
                "Collaboration"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "Pathway",
        "location": "Paris, √éle-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/data-scientist-python-mid-senior-senior-at-pathway-3887683294?position=27&pageNum=0&refId=SmRHYtKKcb%2BBbb%2BiSm10Sw%3D%3D&trackingId=ClUkqoBYZJmyRCS2LEgTiA%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "About Pathway\nDeeptech start-up, founded in March 2020.\nOur primary developer offering is an ultra-performant Data Processing Framework (unified streaming + batch) with a Python API, distributed Rust engine, and capabilities for data source integration & transformation at scale (Kafka, S3, databases/CDC,...)\nThe single-machine version is provided on a free-to-use license (`pip install pathway`)\nMajor data use cases are around event-stream data (including real-world data such as IoT), and graph data that changes over time\nOur enterprise offering is currently used by leaders of the logistics industry, such as DB Schenker or La Poste, and tested across multiple industries. Pathway has been featured in Gartner's market guide for Event Stream Processing\nLearn more at http://pathway.com/ and https://github.com/pathwaycom/\nPathway is VC-funded, with amazing BAs from the AI space and industry. We have operations across Europe and in the US. We are headquartered in Paris, with significant support from the French ecosystem (BPI, Agoranov, WILCO,...).\nThe Team\nPathway is built by and for overachievers. Its co-founders and employees have worked in the best AI labs in the world (Microsoft Research, Google Brain, ETH Zurich), worked at Google, and graduated from top universities (Polytechnique, ENSAE, Sciences Po, HEC Paris, PhD obtained at the age of 20, etc...). Pathway's CTO is a co-author with Goeff Hinton and Yoshua Bengio. The management team also includes the co-founder of Spoj.com (1M+ developer users) and NK.pl (13.5M+ users) and experienced growth leader who has scaled companies with multiple exits.\nThe opportunity\nWe are currently searching for\nData Scientists\nwith\nexperience in the Python stack\n, to help explore and discover the most pertinent insights in datasets on spatio-temporal event streams. In this job, statistical rigor and beauty of visualization meet on equal footing.\nYou Will\nbe working with spatiotemporal data with advanced schemas (time-changing graph models)/\nbe designing data cross-sections, proposing analytics metrics and KPI's in line with clients' objectives, selecting clustering algorithms, and preparing visualizations, to enable fast data exploration and insight discovery - all within our product\nbe designing dashboards in SQL with some Python elements/extensions\nbe directly helping us with Customer Conversion and Adoption within Customer organizations, by contributing to both deployment instances and \"demonstrators\" of our product, performed on client data sets\nwork directly with our Product Owner and CTO to propose and implement extensions to our product, based on repetitive client needs\ndepending on your seniority, implement machine learning algorithms on spatiotemporal event streams and other geospatial data\nThe results of your work will play a crucial role in proving how our technology can help with compelling industry use cases.\nRequirements\nYou Are\nReady for hands-on contribution to the product, helping to ensure the success of demonstrators for clients, and contribution to product codebase\nIntuitive, with good visual taste, and good common sense judgment\nCommitted to beautiful user-centered design: you know that stories are made for people, and you are willing to listen to what they have to say\nCurious at heart and thrilled to work with real-world data, especially spatio-temporal data\nLike trains, trucks, cranes, pythons, pandas, and other things that move\nNot afraid to switch between the roles of data scientist, data-vis magician, statistician, engineer, and detective, at a moment's notice\nHave 2 years+ experience in positions related to Data Science.\nHave a very good working knowledge of Python\nKnow SQL. Are able to work with tables and other data types (arrays, json,...)\nWould be able to implement the Transit Node Routing algorithm in Python just based on reading its Wikipedia article\nHave experience with git, build systems, and CI/CD\nHave at least basic undergrad textbook familiarity with graph algorithms, finite automata, and text (string) search algorithms\nUnderstand statistical concepts, such as correlated random variables, significance, and non-Gaussian noise\nPrepared to be quizzed & grilled by the datasets you encounter, everyday. Here are some questions you should be able to answer off the top of your head: what can \"-273.15\" signify; why \"65535\" is a suspicious integer value; how many months does it take a containership to go around the world; and, roughly what order of g-force is attained by an astronaut in a space rocket at liftoff?\nRespectful of others\nFluent in English\nBonus Points\nShowing a portfolio: code on github, visualization works, a research paper or a PhD thesis with an original statistical / probabilistic analysis or experiment design,..\nSuccessful track-record in Data Science or algorithms contests (Kaggle, Codeforces,...)\nExperience in topics linked to logistics/moving assets\nFamiliarity with some form of GIS software\nFamiliarity with Pandas, SciPy, NetworkX, and similar tools from the Python stack\nExperience in Data Visualization and UX\nSome knowledge of French, Polish, or German\nWhy You Should Apply\nJoin an intellectually stimulating work environment\nBe a pioneer: you get to work with a new type of data processing\nWork in one of the hottest data/AI startups in France\nUncover exciting career prospects\nMake significant contribution to our success\nJoin & co-create an inclusive workplace culture\nBenefits\nType of contract: Permanent employment contract\nPreferable joining date: February 2023. The positions (at least 2) are open until filled\nCompensation: annual salary of ‚Ç¨50K-‚Ç¨70K (mid) up to ‚Ç¨60K-‚Ç¨90K (senior, upper band negotiable) + Employee stock option plan\nLocation: Remote work from home. Possibility to work or meet with other team members in one of our offices:\nParis Area - Drahi X-Novation Center, Ecole Polytechnique, Palaiseau\nParis - Agoranov (where Doctolib, Alan, and Criteo were born) near Saint-Placide Metro (75006)\nWroclaw - University area\nPermanent residence will be required in France or Poland, exceptional candidates will be considered anywhere in the EU.\nIf you meet our broad requirements but are missing some experience, don't hesitate to reach out to us.\nNote\n: CS & engineering school students with exceptional profiles and/or strong motivation to join Pathway are invited to apply for Data Science internships. (Minimum duration: 5-6 months, remuneration level: ‚Ç¨1500 / month.)\nShow more\nShow less",
        "details": {
            "JobDetail": [
                "Remote",
                "Senior"
            ],
            "TypeContract": "",
            "Salary": "50K",
            "Level": "",
            "Experience": null
        },
        "title": "data scientist",
        "skills": {
            "ProgLanguage": [
                "Python"
            ],
            "DataBase": [
                "SQL"
            ],
            "DataAnalytics": [
                "Pandas"
            ],
            "DataSerialization": [
                "Json"
            ],
            "DevTools": [
                "Git"
            ],
            "Other": [
                "Machine Learning",
                "CI/CD"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "Unreal Staffing, Inc",
        "location": "Paris, √éle-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/data-scientist-at-unreal-staffing-inc-3913911173?position=28&pageNum=0&refId=SmRHYtKKcb%2BBbb%2BiSm10Sw%3D%3D&trackingId=nyYt4j5C5TOObVmbw5JDWg%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "About Us\nThe fashion industry contributes significantly to global greenhouse gas emissions. To address this, we developed a Carbon Management Platform tailored for the textile and fashion industry. We automate life-cycle assessment to help brands understand and reduce their environmental footprint.\nData At Our Company\nOur Data team manages customer data parsing and analytics. We clean and normalize customer data for accurate analysis and provide analytics on product-level environmental impacts.\nRequirements\nWhat You'll Be Working With\nInteresting data: Our data describes physical objects, such as shoes, t-shirts, and packaging boxes, enabling real insights into the environmental impact of products\nUnique opportunity: Apply your data science skills to reduce the environmental footprint of fashion companies\nWhat We're Looking For\nStrong communication skills\nExperience with heterogeneous data and basic NLP techniques\nProficiency in Python and SQL\nBasic software engineering skills\nBenefits\nRemote work in Europe\nCoworking space allowance up to ‚Ç¨300/month\nModern amenities including MacBook, headset, ChatGPT subscription, GitHub Copilot, etc\n100% health insurance coverage with Alan at the best coverage level\nOption to work from our office in Paris\nWork retreats organized 3 times a year\nTransparent compensation package with salary range ‚Ç¨60k - ‚Ç¨80k and significant equity\nOpportunities for promotion based on performance and impact on the company\nStrong belief in open-source software and contribution to the community\nShow more\nShow less",
        "details": {
            "JobDetail": [
                "Remote"
            ],
            "TypeContract": "",
            "Salary": "60k, 60k",
            "Level": "",
            "Experience": null
        },
        "title": "data scientist",
        "skills": {
            "ProgLanguage": [
                "Python"
            ],
            "DataBase": [
                "SQL"
            ],
            "EnSoftSkils": [
                "Communication"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "Astek",
        "location": "√éle-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/ing%C3%A9nieur-data-scientist-%E2%80%93intelligence-artificielle-idf-france-h-f-at-astek-3886897805?position=29&pageNum=0&refId=SmRHYtKKcb%2BBbb%2BiSm10Sw%3D%3D&trackingId=%2BqT0qPbSL5a%2FCJQwxypQmg%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Ce que nous allons accomplir ensemble :\nPour l‚Äôun de nos projets dans le domaine a√©ronautique, vous interviendrez en tant\nqu‚Äôing√©nieur Data scientist / Intelligence artificielle\nsur la mise en place de syst√®mes experts destin√©s aux avions civils et militaires.\nVotre future √©quipe :\nTeam IT de 12 personnes\nData scientist, ing√©nieurs syst√®mes, int√©grateurs, architectes\nVous travaillerez avec de v√©ritables passionn√©s !\nVotre mission (...si vous l‚Äôacceptez !) :\nVous participerez au d√©veloppement des fonctions d‚Äôanalyses multisyst√®mes. Pour cela vous assurerez l‚Äô√©tablissement d‚Äôune sp√©cification formelles sur les mod√®les d‚Äôanalyses.\nVous assurerez l‚Äôanalyse des donn√©es et la proposition de m√©thodes pour le traitement des signaux.\nVous d√©velopperez les outils capables de traiter de mani√®re automatique les donn√©es syst√®mes.\nVous assurerez la r√©alisation des sc√©narios, ainsi que les tests et simulations.\nVous r√©aliserez √©galement une activit√© de support.\nVotre stack de jeu :\nData scientist, python, principe de gestion de configuration, et tra√ßabilit√©, syst√®mes a√©ronautiques, intelligence artificielle\nLes petits plus du projet :\nVous √©voluerez au sein d‚Äô√©quipes agiles impliqu√©es et r√©actives.\nVous interviendrez de A √† Z sur des projets riches fonctionnellement et ambitieux techniquement :\nforte volum√©trie, haut niveau de performance, exigence maximale en termes d‚Äôintelligence artificielle et encore bien d'autres sujets captivants.\nVous ?\nDe formation Ing√©nieur, vous justifiez d‚Äôune exp√©rience significative en Data scientist et ou Intelligence artificielle.\nUne connaissance des m√©thodes d‚Äôanalyse de donn√©es serait un plus.\nId√©alement vous avez une connaissance des syst√®mes a√©ronautiques.\nDes postes √©galement ouverts aux d√©butants si stages significatifs.\nNous ?\nCr√©√© en France en 1988, Astek est un acteur mondial de l‚Äôing√©nierie et du conseil en technologies, pr√©sent sur les 5 continents. Fort de son expertise dans de nombreux secteurs industriels et tertiaires, Astek accompagne ses clients internationaux dans le d√©ploiement intelligent de leurs produits et de leurs services, et dans la mise en ≈ìuvre de leur transformation digitale.\nDepuis sa cr√©ation, le Groupe a fond√© son d√©veloppement sur une forte culture d‚Äôentrepreneuriat et d‚Äôinnovation, et sur l‚Äôaccompagnement et la mont√©e en comp√©tence de ses 5 200 collaborateurs qui s‚Äôengagent chaque jour √† promouvoir la compl√©mentarit√© entre les technologies num√©riques et l‚Äôing√©nierie des syst√®mes complexes.\nRejoignez un Groupe en fort d√©veloppement en France et √† travers le monde gr√¢ce √† une lev√©e de fonds de 200M‚Ç¨ r√©alis√©e en 2021. Ensemble ¬´ Let‚Äôs move forward! ¬ª\n‚ú® Tous les d√©tails sur le Groupe sur le site\nhttps://astekgroup.fr.\nEt vous pouvez aussi nous suivre sur\nnotre blog : https://blog.groupeastek.com\n.\nRencontrons-nous !\nVous vous √™tes reconnu sur l‚Äôannonce et Astek vous pla√Æt !\nPour en savoir plus sur vous, Franck , notre Talent Acquisition vous contacte. Puis, vous aurez 3 entretiens max, avec L√©onard (votre futur n+1), L√©onard notre Directeur !\nNos plus\nAstek est green et fait b√©n√©ficier ses salari√©s d‚Äôune indemnit√© kilom√©trique v√©lo\nUn programme CARE sur-mesure d√©ploy√© par nos √©quipes RH pour nos collaborateurs : https://astekgroup.fr/engagements\nNotre charte de la Diversit√©\nBienvenue dans la team ! Allez-y, maintenant c‚Äôest √† vous de jouer !\nShow more\nShow less",
        "details": {
            "JobDetail": [],
            "TypeContract": "",
            "Salary": "",
            "Level": "",
            "Experience": null
        },
        "title": "data engineer",
        "skills": {
            "ProgLanguage": [
                "Python"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "MP DATA",
        "location": "Clermont-Ferrand, Auvergne-Rh√¥ne-Alpes, France",
        "link": "https://fr.linkedin.com/jobs/view/data-scientist-h-f-at-mp-data-3904074177?position=30&pageNum=0&refId=SmRHYtKKcb%2BBbb%2BiSm10Sw%3D%3D&trackingId=%2Bgo0m%2Fw4fZLC7ewQE3cHEQ%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "MP DATA est une soci√©t√© sp√©cialis√©e dans l‚Äôacquisition, le traitement, et la valorisation des donn√©es. Depuis sa cr√©ation en 2015, MP DATA accompagne ses clients, majoritairement industriels, dans le management de leur performance et l‚Äôexploitation de leur donn√©e.\nLes collaborateurs, tous issus de grandes √©coles, incarnent au quotidien les valeurs d‚ÄôExcellence, de Partage et d‚ÄôEngagement. Ils associent savoir-faire technique, m√©thodologie et passion et mettent leurs comp√©tences au service de missions et projets au sein de grands groupes fran√ßais.\nMP DATA accompagne ses clients sur toute la chaine au travers de 3 p√¥les d‚Äôexpertise : Conseil et Strat√©gie, Infrastructure & CloudOPS, Data Science.\nNous recherchons un(e) Data Scientist passionn√©(e) pour rejoindre notre √©quipe dynamique.\nEn tant que membre cl√© du p√¥le Data Science de notre client, un grand acteur du secteur automobile, vous serez charg√©(e) d'analyser, interpr√©ter et exploiter les donn√©es pour fournir des solutions innovantes √† nos clients.\nConception et mise en ≈ìuvre de mod√®les pr√©dictifs et d'algorithmes avanc√©s.\nAnalyse approfondie des donn√©es pour identifier des tendances et des opportunit√©s.\nCollaboration √©troite avec les √©quipes clients pour comprendre leurs besoins et d√©finir des solutions sur mesure.\nParticipation active √† la veille technologique et √† l'am√©lioration continue de nos pratiques en Data Science.\nProfil :\nDipl√¥me\ning√©nieur Grande √âcole\nen Data Science, Statistiques, Informatique ou domaine connexe.\nExp√©rience pratique dans le d√©veloppement et l'application de mod√®les pr√©dictifs,\nMa√Ætrise des langages de programmation tels que Python,\nExcellentes comp√©tences analytiques et capacit√© √† traduire des r√©sultats complexes en recommandations claires,\nForte aptitude √† travailler en √©quipe et √† communiquer efficacement.\nShow more\nShow less",
        "details": {
            "JobDetail": [],
            "TypeContract": "",
            "Salary": "",
            "Level": "",
            "Experience": null
        },
        "title": "data scientist",
        "skills": {
            "ProgLanguage": [
                "Python"
            ],
            "Other": [
                "Statistiques"
            ],
            "EnSoftSkils": [
                "Collaboration"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "MindPal",
        "location": "Toulouse, Occitanie, France",
        "link": "https://fr.linkedin.com/jobs/view/machine-learning-developer-at-mindpal-3896992755?position=31&pageNum=0&refId=SmRHYtKKcb%2BBbb%2BiSm10Sw%3D%3D&trackingId=HvbH6vW7LisYhu48cENkNw%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "We are looking for\nMachine Learning Developer\nJob Responsibilities\nWorking on machine learning projects\nAnalyzing and processing data to create machine learning models\nImplementing and optimizing machine learning algorithms\nTesting and evaluating models\nCollaborating with the programming team and other departments within the company to develop innovative solutions\nRequirements\nMinimum 2 years of experience in the field of machine learning\nKnowledge of machine learning algorithms and techniques\nAbility to analyze and process data\nFamiliarity with machine learning tools and technologies\nProficient in English communication\nEducation in computer science\nWe Offer\nB2B contract type\nFull-time employment\nRemote and flexible working hours\nShow more\nShow less",
        "details": {
            "JobDetail": [
                "Remote",
                "Full"
            ],
            "TypeContract": "",
            "Salary": "",
            "Level": "",
            "Experience": null
        },
        "title": "Other",
        "skills": {
            "Other": [
                "Machine Learning"
            ],
            "EnSoftSkils": [
                "Communication"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "Enzo Tech Group",
        "location": "Paris, √éle-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/machine-learning-engineer-at-enzo-tech-group-3914687840?position=32&pageNum=0&refId=SmRHYtKKcb%2BBbb%2BiSm10Sw%3D%3D&trackingId=RY%2FMvBo6YLy9TmAdLUmwDQ%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Position:\nMachine Learning Engineer / MLOps Engineer / AI Engineer\nLocation:\nParis\nType:\nFreelance, Contract\nDuration:\n6 months\nSearching for a\nMLOps Engineer\nto lead the implementation of\nMLOps\npractices at scale with a focus on\nlarge language models\n(LLM)\n.\nRole:\nLead the implementation of\nMLOps\npractices at scale, focusing on industrialising AI solutions and ensuring their efficient deployment.\nCollaborate with software engineering teams to integrate machine learning models into production environments.\nManage and optimise\nAI infrastructure\non\nAzure\n, including\nDatabricks\nclusters and other relevant technologies.\nDevelop and maintain automation pipelines for model training, testing, monitoring, and retraining.\nRequirements\nProven experience as an MLOps Engineer or similar role, with expertise in large-scale AI deployments.\nDeep understanding of MLOps principles, including model versioning\nExpertise and support to data scientists and engineers working on AI initiatives.\nCVs: s.allenby@enzotechgroup.com\nShow more\nShow less",
        "details": {
            "JobDetail": [],
            "TypeContract": "",
            "Salary": "",
            "Level": "",
            "Experience": null
        },
        "title": "machine learning engineer",
        "skills": {
            "BigData": [
                "Databricks"
            ],
            "CloudComputing": [
                "Azure"
            ],
            "Collaboration": [
                "Teams"
            ],
            "Other": [
                "Machine Learning"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "Mines Paris",
        "location": "Valbonne, Provence-Alpes-C√¥te d'Azur, France",
        "link": "https://fr.linkedin.com/jobs/view/data-scientist-m-w-at-mines-paris-3908686193?position=33&pageNum=0&refId=SmRHYtKKcb%2BBbb%2BiSm10Sw%3D%3D&trackingId=IY%2BQALFGbSkFdOFKuI2VHg%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "√Ä propos de nous\nMines Paris est une des plus prestigieuses √©coles d'ing√©nieurs en France. Mines Paris est un √©tablissement public qui forme des ing√©nieurs g√©n√©ralistes via une exp√©rience p√©dagogique innovante et pluridisciplinaire (sciences de l'ing√©nieur et sciences humaines et sociales). Son appartenance √† l'Universit√© PSL, qui se positionne dans le top 50 des classements internationaux, constitue une v√©ritable opportunit√© d'enrichissement des parcours.\nMission\nYour Environment\nAs part of the scientific program of The Transition Institute 1.5 (TTI.5), which focuses on the conditions for the emergence of a transition to a low-carbon planet, taking into account technical, social, economic, political and geopolitical issues, Mines Paris - PSL has an opening for a Data Scientist.\nInsofar as these issues may represent obstacles to the transition, it is essential to understand their fundamentals and decipher the mechanisms that drive them. The TTI.5 scientific program has been designed to harmonize, enhance and extend the various research projects already on offer at Mines Paris - PSL. It is also intended to provide new impetus in areas that have been little addressed until now, but which are nonetheless essential to steering the transition, or to filling gaps such as that of a complete vision of the distribution of resources worldwide.\nYour Challenges And Responsabilities\nIn order to tackle the various transition strategies, it is essential to have a picture of the production of the various raw materials needed for today's and tomorrow's world. At the same time, the exploitation and circulation of different resources can be strongly impacted by geopolitical conditions and times of tension and conflict.\nThe aim of this project, with its high methodological stakes, is to develop and couple:\nglobal resource mapping for two critical \"identifiable\" resources (lithium and cobalt)\na mapping of armed tensions (conflicts, installation of military bases, etc.).\nTo achieve this, we will need to develop a tool for extracting data from a very large mass of information, to be identified, in a changing context that will need to be taken into account for the tool's sustainability.\nThe Development Prospects For This Work Could Include\na double cartography animated over time ;\nthe enrichment of military base and tension indicators, with an equal focus on cases of local armed non-tension around the resource\na scalable database that can be continuously updated\na tool that can be replicated for other resources in a rapidly changing world\nProfil\nLet's talk about you !...\nThe position is aimed at an engineer / master data scientist with a degree from a university or Grande Ecole. Additional skills in GIS would be a plus. He/she may receive in-house training on mining resource issues.\nThe candidate will be strongly encouraged to participate in TTI.5 activities, and may also take part in those of the referral centers. He/she must have demonstrated good teamwork skills.\nFluency in spoken and written English is imperative.\nKnowledge And Skills\nThe main skills required for this post are :\nMastery of algorithms and programming languages (ability to write efficient, scalable code)\nMastery of data management language and databases (ability to find, collect and analyze large volumes of data)\nMastery of data visualization tools\nSoft Skills\nSelf-motivated\nSpirit of initiative\nSense of teamwork\ncreativity\nFlexibility\nCommunication and teaching skills\nAnalytical skills\nThoroughness\n‚Ä¶And about us ! Working at Mines Paris also means :\nJoining a prestigious institution with a rich history\nPlaying a part in the digital transition and the transition to carbon neutrality to tackle the climate emergency\nBelonging to PSL University, ranked 41st in the Academic Ranking of World Universities\nJoin a dynamic, multidisciplinary team!\nA pleasant living environment in a pine forest, at the heart of the 1st technology cluster on the C√¥te d'Azur and 1st technology park in Europe!\nR√©f√©rence de l'offre : 6jpx490r88\nShow more\nShow less",
        "details": {
            "JobDetail": [],
            "TypeContract": "",
            "Salary": "",
            "Level": "",
            "Experience": null
        },
        "title": "data scientist",
        "skills": {
            "EnSoftSkils": [
                "Teamwork",
                "Flexibility",
                "Creativity",
                "Initiative",
                "Communication"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "TNP Consultants",
        "location": "Paris, √éle-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/data-scientist-h-f-%E2%80%93-digital-factory-at-tnp-consultants-3591227915?position=34&pageNum=0&refId=SmRHYtKKcb%2BBbb%2BiSm10Sw%3D%3D&trackingId=6%2Fn%2FJGCjttlJUDhmfFdmhQ%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Pr√©sentation de TNP Consultants\nFort de 450 collaborateurs, TNP est un cabinet de conseil ind√©pendant multi-sp√©cialiste et multisectoriel, pr√©sent en France, au Maroc, au Luxembourg, en Suisse et en Inde. Acc√©l√©rateur de performance, nous intervenons dans la mise en place de programmes de transformation sur les probl√©matiques r√©glementaires, excellence op√©rationnelle, digital et business solutions dans les secteurs banque, assurance & protection sociale, le secteur public et industrie & services.\nCette ann√©e, TNP recrute 200 collaborateurs ! Pour accompagner nos clients dans le cadre de leur transformation digitale, nous recherchons des consultants Data Scientists (H/F).\nVOTRE R√îLE AU SEIN DE L‚Äô√âQUIPE DATA SCIENTIST\nAu Sein De La DIGITAL FACTORY, Vous Participerez Au D√©veloppement Des Activit√©s Data Science. Vous Serez Notamment En Charge\nD‚Äôaider nos clients √† d√©finir les use cases m√©tiers et proposer des d√©marches d‚Äô√©tudes adapt√©es aux contextes et aux enjeux m√©tiers ;\nDe mod√©liser des ph√©nom√®nes et restituer des analyses √† l‚Äôusage des m√©tiers (Data Visualisation) ;\nDe prototyper des outils d‚Äôanalyse ou de pr√©diction utilisables par les m√©tiers ;\nDe former et accompagner les m√©tiers dans l‚Äôutilisation de ces outils ;\nAccompagner des mont√©es en comp√©tences d‚Äôautres Data Scientists.\nDe mettre en production les mod√®les et Dashboard d√©velopp√©s dans un outil de cloud.\nVOTRE PROFIL\nVous √™tes dipl√¥m√©s d‚Äôune √©cole d‚Äôing√©nieur ou d‚Äôun master 2 en Math√©matiques, informatiques et/ou statistiques. Vous justifiez d‚Äôau moins 4 ann√©es d‚Äôexp√©rience au sein d‚Äôun cabinet de conseil.\nComp√©tences techniques requises\nVous maitrisez la programmation en Python/R.\nVous avez un excellent niveau en statistique.\nVous avez des connaissances th√©oriques et pratiques dans la mod√©lisation en Machine Learning et Deep Learning (Mod√®les d‚Äôagr√©gation, R√©seaux de neurone)\nVous avez d√©j√† utilis√© au moins une solution cloud comme AWS /Azure.\nGestion des codes : Git, Bitbucket\nVous disposez d‚Äôun bon niveau d‚Äôanglais.\nSoft Skills\nPassionn√© par la data et l‚ÄôIA\nEsprit de synth√®se et d‚Äôanalyse\nRigoureux pour assurer une qualit√© de livrables et didactique pour pr√©senter les sujets aux m√©tiers\nSens de l‚Äô√©coute et de la communication\nSavoir travailler en √©quipe\nCurieux et cr√©atif\nUn √©tat d‚Äôesprit orient√© business et apport de valeur pour les √©quipes m√©tiers ;\nCoach√©(e) tout au long de votre carri√®re, vous b√©n√©ficierez d‚Äôune formation continue, pour enrichir votre expertise et accompagner votre d√©veloppement personnel. En √©troite collaboration avec les Associ√©s, vous √©voluerez dans un cabinet ind√©pendant en forte croissance et intervenant aupr√®s des grands comptes en France et √† l‚Äôinternational.\nShow more\nShow less",
        "details": {
            "JobDetail": [],
            "TypeContract": "",
            "Salary": "",
            "Level": "",
            "Experience": null
        },
        "title": "data scientist",
        "skills": {
            "ProgLanguage": [
                "R",
                "Python"
            ],
            "DataAnalytics": [
                "R"
            ],
            "CloudComputing": [
                "AWS",
                "Azure"
            ],
            "DevTools": [
                "Git"
            ],
            "Other": [
                "Statistiques",
                "Machine Learning",
                "Cloud"
            ],
            "EnSoftSkils": [
                "Communication",
                "Collaboration"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "Keley Consulting",
        "location": "Paris",
        "link": "https://fr.linkedin.com/jobs/view/data-scientist-at-keley-consulting-3908861590?position=35&pageNum=0&refId=SmRHYtKKcb%2BBbb%2BiSm10Sw%3D%3D&trackingId=xpu%2FJFSCphN553TAPIeh8g%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Data Scientist F/H\nDescription de l'offre d'emploi\nAu sein de la practice data, vous accompagnerez nos clients dans la gestion, l‚Äôanalyse et l‚Äôexploitation de leur donn√©es notamment gr√¢ce au d√©veloppement de mod√®les IA et la mise en production de ceux-ci.\nResponsabilit√©s\nVous interviendrez dans des secteurs vari√©s sur des probl√©matiques telles que :\nEvaluer les solutions technologiques li√©es √† la data en effectuant des benchmarks\nCollecter, traiter et analyser des donn√©es volumineuses\nCommuniquer efficacement les r√©sultats des analyses\nCr√©er de la valeur √† partir des donn√©es en utilisant l‚Äôintelligence artificielle et la Data Science\nTravailler en √©troite collaboration avec les m√©tiers afin de comprendre leurs besoins et les impliquer dans le d√©veloppement des outils IA\nD√©ployer les outils d√©velopp√©s en environnement de prod (MLOps)\nA titre d‚Äôexemple, nous avons r√©cemment men√© les missions suivantes :\nD√©veloppement d‚Äôoutils d‚Äôoptimisation des revenus pour le compte d‚Äôune compagnie a√©rienne\nEtude de l‚Äôimpact du traitement de plaintes sur la customer lifetime value\nIndustrialisation de proof-of-concepts (ML Ops)\nD√©veloppement de GPTMaker, un outil de cr√©ation de chatbot s‚Äôappuyant sur des LLM\nProfil recherch√©\nDipl√¥me Bac+5 type √©cole d‚Äôing√©nieur ou universit√© en Data Science / Statistiques\nExp√©rience de 2 √† 5 ans en Data, avec au moins 1 an en tant que Data Scientist / Engineer\nMa√Ætrise des m√©thodes statistiques et leurs applications op√©rationnelles, ainsi que Python/Spark\nForte capacit√© d‚Äôorganisation, d‚Äôanalyse, d‚Äô√©coute et de communication tout en √©tant force de conviction\nAnglais courant\nQualifications suppl√©mentaires (atouts) :\nExp√©rience avec les outils du cloud (GCP, Azure, AWS ‚Ä¶)\nExp√©rience dans le NLP (natural language processing)\nPourquoi rejoindre Keley ?\nKeley est un cabinet de conseil √† taille humaine.\nAcc√©l√©rateur de projet, nous accompagnons nos clients sur des programmes de transformation digitale & Data en apportant sens et performance. Autour de m√©thodologies produits issues du design et orient√©es r√©sultat, nous cocr√©ons avec nos clients en les accompagnant dans toutes les √©tapes de leurs projets, jusqu‚Äô√† l‚Äôautonomie.\nParce que les Humains sont au c≈ìur de la transformation digitale des entreprises, celle-ci est aussi culturelle : nous alignons strat√©gie produit, culture m√©tiers et mod√®les op√©rationnels pour concevoir avec nos clients des solutions qui leur ressemblent et qui font le succ√®s de leurs projets.\nNos valeurs\nPassionn√©s par notre m√©tier, nous sommes des consultants en transformation digitale avec un sens aigu de l‚Äôengagement et du partage.\nDans un esprit coop√©ratif et chaleureux, chaque collaborateur pourra trouver sa place, √©voluer au c≈ìur de nos m√©tiers et atteindre ses objectifs gr√¢ce √† des parcours de carri√®re √©volutifs, clairs et transparents.\nNous croyons en la valeur de la diversit√© et de l'inclusion et encourageons les candidats de tous horizons √† postuler.\nKeley vous propose une carri√®re passionnante dans un environnement stimulant, en vous permettant de travailler avec des grands comptes et sur des missions vari√©es.\nPour vous offrir le meilleur environnement de travail possible, nous vous proposons :\nUn parcours de carri√®re clair et partag√© pour √©voluer rapidement au sein du cabinet\nUne politique de r√©mun√©ration transparente et √©quitable\nUne charte de t√©l√©travail\nDes bureaux au c≈ìur de Paris dans le 8√®me arrondissement\nDes mentors et des buddys √† l‚Äô√©coute\nDes √©v√®nements de team building r√©guliers\nUne direction et un management toujours disponibles pour √©changer (organisation flat)\nUn programme de formation adapt√© √† vos besoins et incluant des formations externes certifiantes\nDes m√©thodes et outils de partage de connaissance pour vous nourrir mais aussi vous offrir une tribune : conf√©rences internes hebdomadaires, articles, livres blancs, enqu√™tes et contenus vid√©o\nUn MacBook car on aime les belles choses (surtout quand elles marchent bien)\nUne carte tickets restaurants\nUne prise en charge de la mutuelle √† 100%\nUne prime de vacances\nShow more\nShow less",
        "details": {
            "JobDetail": [],
            "TypeContract": "",
            "Salary": "",
            "Level": "Bac+5",
            "Experience": "5 an(s)"
        },
        "title": "data scientist",
        "skills": {
            "ProgLanguage": [
                "Python"
            ],
            "BigData": [
                "Spark"
            ],
            "CloudComputing": [
                "GCP",
                "AWS",
                "Azure"
            ],
            "Other": [
                "Statistiques",
                "Cloud",
                "ML"
            ],
            "EnSoftSkils": [
                "Communication",
                "Collaboration"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "Scaleway",
        "location": "Lille, Hauts-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/ml-engineer-at-scaleway-3828506145?position=36&pageNum=0&refId=SmRHYtKKcb%2BBbb%2BiSm10Sw%3D%3D&trackingId=55VD2KgY8r8VG0XoUYNTVg%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "About The Job\nThe newly established Inference team at Scaleway is on a mission to revolutionize how Machine Learning (ML) is deployed and scaled in the cloud. We are seeking a talented ML Engineer to join us in developing and deploying Large Language Model (LLM) endpoints on both dedicated instances and serverless environments. As we plan to broaden our offerings to include various types of ML models later this year, this role offers a unique opportunity to be at the forefront of ML technology and its application in the cloud.\nReporting to our Manager, Gr√©goire de Turckheim, you will play a crucial role in building and optimizing ML model deployments, ensuring high performance, scalability, and reliability.\nMinimum Qualifications\nProficient in Python and familiar with other programming languages such as Go\nStrong background in Machine Learning, including experience with LLMs, NLP, or other ML model types\nExperience with ML frameworks (e.g., TensorFlow, PyTorch) and understanding of MLOps principles\nKnowledge of deploying ML models in cloud environments, including serverless architectures\nFamiliarity with container technologies (Docker, Kubernetes) and orchestration systems\nUnderstanding of REST and gRPC APIs for integrating ML models into applications\nExcellent command of English, both written and verbal\nPreferred Qualifications\nGood understanding of Linux system administration and cloud ecosystems\nResponsibilities\nOptimize ML models for high performance and low latency in cloud environments\nDesign, develop, and maintain scalable and efficient ML model deployments, focusing on LLMs initially and expanding to other models\nCollaborate with the Inference team to architect and implement serverless solutions for ML model hosting\nEnsure the reliability, availability, and security of ML model deployments\nStay abreast of the latest ML technologies and cloud trends to continuously improve our offerings\nTechnical Stack\nProgramming Languages: Python, Go\nML Frameworks: TensorFlow, PyTorch\nContainer Technologies: Kubernetes, Docker\nCloud and Serverless Technologies\nLinux Systems\nData Storage: S3, PostgreSQL, Redis\nVersion Control: Git\nLocation\nThis position is based in our offices in Paris or Lille (France)\nRecruitment Process\nScreening call - 30 mins with the recruiter\nManager Interview - 45 mins\nTechnical Interviews / or Home Assignment\nTeam Interview\nHR Interview - 45 mins\nOffer sent\nShow more\nShow less",
        "details": {
            "JobDetail": [],
            "TypeContract": "",
            "Salary": "",
            "Level": "",
            "Experience": null
        },
        "title": "machine learning engineer",
        "skills": {
            "ProgLanguage": [
                "Python"
            ],
            "MachineLearning": [
                "PyTorch",
                "TensorFlow"
            ],
            "DevTools": [
                "Git",
                "Docker"
            ],
            "OS": [
                "Linux"
            ],
            "DBMS": [
                "PostgreSQL"
            ],
            "Automation": [
                "Kubernetes"
            ],
            "Containers": [
                "Docker",
                "Kubernetes"
            ],
            "Other": [
                "Machine Learning",
                "Cloud",
                "ML"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "Alki",
        "location": "Paris, √éle-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/machine-learning-engineer-at-alki-3916860370?position=37&pageNum=0&refId=SmRHYtKKcb%2BBbb%2BiSm10Sw%3D%3D&trackingId=hy8AovtbqWRpeMoSz2QFUw%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Full Stack Machine Learning Engineer (Time Series Forecasting)\nLocation:\nRemote or Paris\nJob Type\n: Full-Time\nCompany overview\n: At Alki, we‚Äôre leveraging cutting edge AI technologies to transform logistics warehouses and drive innovation. Our mission is to bridge the gap between Amazon and other logistics players. We are looking for a skilled full stack ML engineer with a strong focus on time series forecasting to industrialize and streamline our machine learning operations (MLOps) capabilities from R&D to production.\nResponsibilities:\nDesign & build robust data pipelines specifically tailored for time series data, ensuring efficient data ingestion, pre-processing & exploration to support ML models\nDesign, implement, and optimize sophisticated time series forecasting algorithms\nTranslate advanced statistical and machine learning models from R&D into scalable production solutions\nManage the deployment of machine learning systems, including setting up continuous integration and delivery pipelines (CI/CD) for automated model training and deployment\nMonitor and maintain operational ML models (thousands), quickly identifying and addressing performance degradation or shifts in model accuracy/data\nCollaborate with cross-functional teams, including CTO, AI researcher, software engineer, to ensure models effectively address business needs and enhance decision-making\nStay abreast of the latest developments in machine learning, artificial intelligence, and related technologies to continuously improve our MLOps practices and time series models\nQualifications\nMaster‚Äôs/PhD degree in Computer Science, Applied Maths, Statistics, or a related field\nStrong experience with a proven track record of deploying ML models to production\nStrong understanding of the challenges associated with deploying, monitoring, and maintaining thousands of ML models in a production environment\nStrong experience with AutoML, HPO, NAS\nProficient in Python, including extensive experience with ML libraries such as TensorFlow or PyTorch, and statistical modeling tools\nKnowledge of AWS cloud services related to machine learning and data processing, including Amazon S3, EC2, RDS, Lambda, and SageMaker\nFamiliarity with data orchestration tools\nExperience in building and maintaining CI/CD pipelines for automated model deployment\nExcellent analytical and problem-solving abilities, with a strong collaborative mindset\nExperience in time series analysis and forecasting is a plus\nBenefits:\nCompetitive salary\nStrong opportunities for professional development and career advancement\nFlexible working hours and remote work options\nDynamic and innovative work environment\nHow to apply:\nPlease submit your resume and any relevant project portfolio to tanguy@alki.io. We are excited to hear how you can contribute to our team at Alki!\nShow more\nShow less",
        "details": {
            "JobDetail": [
                "Remote",
                "Full"
            ],
            "TypeContract": "",
            "Salary": "Salary",
            "Level": "",
            "Experience": null
        },
        "title": "machine learning engineer",
        "skills": {
            "ProgLanguage": [
                "R",
                "Python"
            ],
            "DataAnalytics": [
                "R"
            ],
            "MachineLearning": [
                "PyTorch",
                "TensorFlow"
            ],
            "CloudComputing": [
                "AWS"
            ],
            "Collaboration": [
                "Teams"
            ],
            "Other": [
                "Machine Learning",
                "Cloud",
                "ML",
                "CI/CD"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "Homa",
        "location": "Paris, √éle-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/senior-machine-learning-engineer-at-homa-3911467922?position=38&pageNum=0&refId=SmRHYtKKcb%2BBbb%2BiSm10Sw%3D%3D&trackingId=GCTHWRYWx7RlHR4goAMYpA%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Welcome to Homa, the gaming technology lab that is taking the industry by storm! Our team of over 200 people, hailing from more than 35 different countries, is dedicated to empowering mobile game creators worldwide to bring their creative ideas to the top charts.\nOur Homa Lab platform offers a comprehensive suite of cutting-edge tools that allow developers to stay on top of the latest trends, test new features in real-time, and easily distribute and monetize their games. Our success speaks for itself - our apps have been downloaded over 1 billion times!\nSince our inception, we have raised $165 million in total from prominent investors, including Headline, Northzone, Eurazeo, Singular, Quadrille Capital, Fabric Ventures, and Bpifrance. We have also received support from renowned business angels, such as the founders of King, Sorare and Spotify founders.\nBut what really makes Homa special is our team. We are a diverse group of artists, business developers, engineers, entrepreneurs, and former strategy consultants who all share the same passion for taking over the gaming industry. When you become part of Homa, you'll be joining a dedicated team that creates innovative and high-performing games that resonate with players worldwide.\nIf you're ready to take your career to the next level and make a real impact in the company, then Homa is the perfect place for you. Join us and let's create the future of gaming together!\nMeet the team\nüë©‚Äçüë©‚Äçüëß‚Äçüëß\nYou will join the Data department organized into:\nA Data Platform team with 5 Data Engineers responsible for ingesting large amounts of data from multiple different sources, creating and maintaining a core data model which aims at making data standardized, reliable and easily available\nA Data Science and ML Platform team with 6 Data Scientists / ML Engineer working on ML-driven data products: Autobidder for User Acquisition, N-Testing for experimentation\nAn Advanced Analytics & Data Science team with 6 Data Analysts and Scientists exploiting our data for:\nGame Analytics\nUser Acquisition and Marketing Analytics\nMarket Inteligence Analytics\nOps Analytics\nRole and Missions ‚Äî What you will do\nüöÄ\nWe are looking for a Senior Machine Learning Engineer to join the team in order to scale and industrialize Machine Learning & AI at Homa. Under the responsibility of our Associate Director, your responsibilities will be the following:\nLead ML Projects: Spearhead development and implementation of ML models for Marketing Tech (User Acquisition, Monetization) and Game Tech (Bayesian A/B Testing, Segmentation)\nML Industrialization & Democratization: Enhance ML engineering processes, adopt ML Ops tools, and contribute to model interpretability and collaborative efforts\nImplement Scalable ML Solutions: Build Serving APIs for handling millions of requests daily with low latency\nCollaborative Innovation: Work closely with diverse teams, leveraging GenAI tools for productivity and product improvements\nStay Updated: Integrate latest ML technologies and advancements into our tech stack\nCurrent Tech Stack: AWS, Redshift, Databricks, Python, DBT, Spark, Airflow, Kafka, Kubernetes, LightGBM, MLFlow, Metabase\nRequirements\nIf you're creative, ambitious, and up for taking over the industry, we want you on our team! We are also looking for:\nExtensive ML Experience: 5+ years in implementing and deploying ML models to production\nKey Technology Proficiency: Expertise in Neural Networks (TensorFlow / PyTorch), Gradient Boosting libraries (LightGBM / XGBoost), and at least one top Cloud provider (GCP, Azure, AWS)\nMLOps Skills: Experience with ML Ops tools like MLFlow\nAPI Development Expertise: Proven ability in building high-performance Serving APIs\nCollaborative Skills: Excellent communication and teamwork abilities\nInnovative Mindset: Passion for staying ahead in ML trends and technologies\nLanguage Skills: Fluent English is mandatory (interviews will be led in English)\nOur Culture‚ÄîWho we are\nü™ê\nAt Homa, we are building a community of brilliant talents. We believe that true innovation comes from diversity and collaboration, and that's why we prioritize brainpower and determination over formal education. So if you have the talent, energy and motivation, there is no obstacle to your success here.\nAs the creative experts behind the platform, we provide developers with the data they need to bring their ideas to life. Our team lives by three central values that guide everything we do:\n‚ú®\nAmbition\n: we're not afraid to tackle difficult challenges and set our goals extremely high. We're on a mission to revolutionize an industry dominated by well-established companies, and we won't stop until we succeed.\n‚ú®\nHumility\n: we leave our pride & ego aside. We are always ready to lend a helping hand, celebrate each other's successes, and learn from our failures. As Mr. Lamar said, \"Sit down. Be humble.\"\n‚ú®\nCuriosity\n: we keep our minds open and never stop learning. We believe that questioning everything is the best way to stay ahead of the curve, and we encourage all our team members to stay curious and never stop exploring new ideas.\nAt Homa, you'll be challenged, supported, and inspired every day, and we can't wait to see what you bring to the table.\nBenefits\nWhile success is its own reward, here are some of the benefits that come with working at Homa:\nWe offer essential benefits in France and specific locations, including health insurance, meal vouchers, public transport subsidies, childcare benefits, and life insurance\nIf you're interested in working from our newly renovated Paris HQ with a rooftop garden and WeWork amenities, we have a desk waiting for you\nYou will be working in English with our international team of top-tier talents from 35+ countries\nYou will have bi-annual reviews with your manager to reflect on your performance, celebrate wins, and receive constructive feedback\nYou will be able to attend diverse team events and Workations (the famous company-wide Homa trip)\nShow more\nShow less",
        "details": {
            "JobDetail": [
                "Senior"
            ],
            "TypeContract": "",
            "Salary": "",
            "Level": "",
            "Experience": null
        },
        "title": "machine learning engineer",
        "skills": {
            "ProgLanguage": [
                "Python"
            ],
            "BigData": [
                "Databricks",
                "Spark"
            ],
            "MachineLearning": [
                "PyTorch",
                "LightGBM",
                "TensorFlow",
                "XGBoost"
            ],
            "CloudComputing": [
                "GCP",
                "AWS",
                "Azure"
            ],
            "Automation": [
                "Airflow",
                "Kubernetes"
            ],
            "Containers": [
                "Kubernetes"
            ],
            "Collaboration": [
                "Teams"
            ],
            "Other": [
                "Machine Learning",
                "Cloud",
                "ML"
            ],
            "EnSoftSkils": [
                "Teamwork",
                "Communication",
                "Collaboration"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "STATION F",
        "location": "Paris, √éle-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/ml-engineer-at-station-f-3852509522?position=39&pageNum=0&refId=SmRHYtKKcb%2BBbb%2BiSm10Sw%3D%3D&trackingId=eHx%2FAGBS%2BLB2nUuqSOvnuw%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "√Ä propos\nFond√©e par Flore, Christian et Tristan,\nVeeton\nambitionne de r√©volutionner la photographie commerciale.\nVeeton d√©veloppe une technologie de pointe permettant aux marques de mode de\ng√©n√©rer\nleur\nshooting e-commerce\nen\nun clic\n.\nLa recherche et le d√©veloppement tech sont au c≈ìur du projet. En quelques mois :\nNous avons d√©ploy√© avec succ√®s 2 versions de notre mod√®le pionnier\nNous sommes incub√©s √† Station F dans le programme Microsoft GenAI\nNotre travail R&D a √©t√© reconnu comme Deep Tech par Bpifrance\nNous collaborons avec une dizaine de marques et grands groupes reconnus\nDescriptif du poste\nEn Tant Que Membre De La Founder Team, Tu Seras Au C≈ìur De L'innovation Et De La Recherche Chez Veeton. Votre Mission Sera Polyvalente\nR√©solution de probl√®mes ML complexes : vous serez en premi√®re ligne pour manipuler et s'attaquer √† des notions en deep learning les plus complexes, avec par exemple, le conditionnement de mod√®les de diffusion. Une ambition : repousser les limites de ce qui est possible en computer vision.\nD√©ploiement de mod√®les : d√©ployez des mod√®le en production, √† la fois en interne et pour les clients, de la mani√®re la plus efficiente. Passez de la recherche au produit.\nApprentissage continu et impl√©mentation : lisez les derniers articles et mettez en ≈ìuvre les d√©couvertes dans les domaines de recherche pertinents (voir ci-dessus) pour tester leur int√©gration dans nos syst√®mes. Chez Veeton, int√©grer rapidement de nouvelles connaissances dans les projets est essentiel pour r√©ussir.\nEsprit Pionnier. Soyez adaptable, lead sur vos sujets, prenez des risques calcul√©s et adoptez une approche pratique pour r√©soudre les probl√®mes. Votre passion pour l'innovation et le produit aura un impact direct sur le succ√®s de Veeton.\nProfil recherch√©\nMaster en Math√©matiques Appliqu√©es / Informatique provenant des tops √©coles d'ing√©nieurs / universit√©s\nSolides comp√©tences en r√©solution de probl√®mes et autonomie\nUne exp√©rience pr√©alable dans la recherche en IA est recommand√©e\nProcess de recrutement\nPremi√®re rencontre avec un fondateur\nPremi√®re test : fit, √©valuation g√©n√©rale des math√©matiques et de la logique\n2e test: petite revue de litt√©rature\n3e test : informatique pratique et codage\nDernier appel avec les fondateurs\nInformations compl√©mentaires\nType de contrat : CDI\nLieu : Paris\nNiveau d'√©tudes : Bac +5 / Master\nT√©l√©travail ponctuel autoris√©\nShow more\nShow less",
        "details": {
            "JobDetail": [],
            "TypeContract": "CDI",
            "Salary": "",
            "Level": "",
            "Experience": null
        },
        "title": "machine learning engineer",
        "skills": {
            "ProgLanguage": [
                "R"
            ],
            "DataAnalytics": [
                "R"
            ],
            "Other": [
                "ML"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "La Javaness",
        "location": "Paris, √éle-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/stage-machine-learning-at-la-javaness-3829261041?position=40&pageNum=0&refId=SmRHYtKKcb%2BBbb%2BiSm10Sw%3D%3D&trackingId=sWiGJ%2BKfLcTPKzkx4OZjDw%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Descriptif du poste\nInt√©gr√©(e) √† notre Lab Data compos√© d'une vingtaine d'experts en Machine Learning, tes activit√©s s'orienteront autour de plusieurs grands axes :\nR√©aliser des missions avec de r√©elles donn√©es clients, o√π tu pourras tr√®s vite gagner en responsabilit√©\nEffectuer un travail de R&D autour de l'√©tat de l'art technologique et scientifique des m√©thodes de machine learning, dans le but de perfectionner les outils utilis√©s en interne\nParticiper aux data meeting hebdomadaires, au cours desquels chacun partage ses derni√®res avanc√©es et d√©couvertes\nCollaborer avec les autres m√©tiers (IT, Design, Business...), pour imaginer des solutions compl√®tes et innovantes r√©pondant aux besoins clients\nTravailler au plus pr√®s des clients, en les conseillant directement et en concevant le produit qui saura r√©pondre √† leurs attentes\nRequirements\nVenant d'une formation en Data Science, Computer Science, Math√©matiques, ou d'un parcours au cours duquel tu as acquis les comp√©tences recherch√©es, tu justifies de bonnes connaissances des algorithmes de Machine Learning. Tu dois √©galement √™tre curieux et effectuer une veille autour des derni√®res avanc√©es technologiques sur le sujet. Projets personnels et/ou participations √† des comp√©titions Kaggle sauront attester de cet int√©r√™t.\nDe solides connaissances en Python et une bonne ma√Ætrise de ses librairies de Machine Learning (pandas, scikit-learn, etc.) sont obligatoires. La ma√Ætrise d'un ou plusieurs frameworks de Deep Learning (Keras, Pytorch...) est un r√©el plus.\nComp√©tences obligatoires:\nPython\nMachine Learning / Deep Learning\nComp√©tences appr√©ci√©es:\nP√©dagogie, vulgarisation de concepts techniques\nEsprit de synth√®se\n√âcosyst√®me Big Data (Hadoop, Spark)\nProgrammation logiciel et web\nFormat: Stage de 4 √† 6 mois de pr√©f√©rence en fin d'√©tudes\nBenefits\nüç¥Une prime ¬´ paniers repas ¬ª vers√©e mensuellement √† hauteur de 98‚Ç¨ net\nüö≤ Au choix: La prise en charge int√©grale de ton pass Navigo, ou une prime mobilit√© durable de 500‚Ç¨/an vers√©e mensuellement\nü§∏ Des cours de sport en visio chaque semaine gratuits pour tous\nüè† Du t√©l√©travail flexible pour tous\nüìò Du partage de connaissance en interne : chaque vendredi apr√®s midi, ¬´ une s√©ance de pr√©sentation ¬ª est organis√©e par un collaborateur sur un sujet qu'il souhaite partager √† tous\nüíª Au choix: un ordinateur Mac, Linux, ou Windows selon tes pr√©f√©rences et comp√©tences\nüó∫Ô∏è Des locaux situ√©s dans le centre de Paris (10e), avec une super terrasse pour profiter de l'√©t√©\nüç∫ Des ap√©ros, s√©minaires, d√©jeuners en commun et autres r√©jouissances plusieurs fois par an\nShow more\nShow less",
        "details": {
            "JobDetail": [],
            "TypeContract": "",
            "Salary": "",
            "Level": "",
            "Experience": null
        },
        "title": "Other",
        "skills": {
            "ProgLanguage": [
                "R",
                "Python"
            ],
            "DataAnalytics": [
                "R",
                "Pandas"
            ],
            "BigData": [
                "Hadoop",
                "Spark"
            ],
            "MachineLearning": [
                "Scikit-Learn",
                "PyTorch",
                "Keras"
            ],
            "OS": [
                "Linux",
                "Windows"
            ],
            "Other": [
                "Machine Learning",
                "Big Data"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "Harmonie Mutuelle",
        "location": "Rennes, Brittany, France",
        "link": "https://fr.linkedin.com/jobs/view/data-scientist-h-f-at-harmonie-mutuelle-3903667706?position=41&pageNum=0&refId=SmRHYtKKcb%2BBbb%2BiSm10Sw%3D%3D&trackingId=IVmiF2ShwKWnofFmjh019A%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Vous √™tes en qu√™te d'une nouvelle aventure professionnelle collective et porteuse de sens ?\nVous voulez un parcours qui vous ressemble ? Vous avez envie d'√©voluer dans un\nenvironnement de travail √©panouissant fond√© sur la confiance, la diversit√© et l'√©galit√© des\nchances ?\nVous √™tes au bon endroit ! Ensemble, nous pouvons faire la diff√©rence.\nLe poste :\nNous op√©rons notre transformation digitale et renfor√ßons le besoin de pilotage de nos flux et activit√©s au sein de la Direction des Services et de la Satisfaction Clients. Dans ce cadre, nous recherchons un(e) Data Scientist pour renforcer l'√©quipe Pilotage et Analyse Data Science. Parmi nos sujets : analyser les activit√©s des centres de gestion, mesurer l'efficacit√© des actions de digitalisation, robotisation et d√©mat√©rialisation, analyser et d√©tecter les fraudes √† la mutuelle, mod√©liser des dimensionnements de flux et d'√©quipes...\nVos missions principales :\nVous participez au d√©veloppement de cette √©quipe avec pour mission principale la production op√©rationnelle d'algorithmes data science de d√©tection de fraude :\n- Ex√©cuter des algorithmes existants, monitorer, valider les productions\n- Maintenir ces mod√®les math√©matiques. Suivre leurs performances r√©elles\n- Collecter l'ensemble des informations (hypoth√®ses, roadmap, projet, nouvelles donn√©es) n√©cessaires √† l'am√©lioration continue des mod√®les et au d√©veloppement de nouveaux\n- Explorer et croiser les donn√©es, √† des fins d'investigation et de d√©tection unitaires de cas de fraudes\n- Interpr√©ter les donn√©es collect√©es, structurer et partager les r√©sultats\nEn compl√©ment de cette activit√©, vous interviendrez sur les missions suivantes :\n- Participer aux analyses de performances et de pilotage de cette activit√© globale de gestion de la fraude\n- Intervenir sur des projets transverses au sein de l'√©quipe et d'Harmonie Mutuelle (datalab, analyse d'impact...)\nLe profil recherch√© :\nIssu(e) d'une formation Bac +5 avec une sp√©cialisation en Statistiques / Econom√©trie / Analyse de donn√©es, vous avez au moins 2 ans d'exp√©rience en data science. Vous maitrisez les techniques de data mining, machine learning, mod√©lisations supervis√©es ou non et le pragmatisme.\nVous √™tes √† l'aise sous SAS, SQL, et Python.\nVous savez et aimez d√©velopper. Vous avez une app√©tence et exp√©rience sur les sujets d'investigation de fautes/fraudes √† impact directs sur notre soci√©t√©.\nVous √™tes curieux(se), rigoureux(se) et dot√©(e) d'un bon esprit d'analyse et de synth√®se. Vous √™tes force de proposition, autonome, dynamique, innovant, cr√©atif.\nVous aimez le travail en √©quipe.\nUne connaissance des m√©tiers de la mutuelle serait un plus.\nInfos compl√©mentaires :\n- 22, 5 jours de RTT par an\n- Des horaires flexibles pour la majorit√© des postes\n- Jusqu'√† 3 jours de t√©l√©travail par semaine (√† partir de 6 mois d'anciennet√©)\n- Carte d√©jeuner et CSE (enveloppes loisirs, culture, avantages vacances...)\n- Compte Epargne Temps\n- Forfait mobilit√© durable : jusqu'√† 300 ‚Ç¨ par an (cumulable avec le remboursement de l'abonnement aux transports en commun, dans la limite de 500 Euros au total)\n- Contrat collectif sant√© et pr√©voyance\n- PEE et Retraite\n- Prime d'int√©ressement\nShow more\nShow less",
        "details": {
            "JobDetail": [],
            "TypeContract": "",
            "Salary": "",
            "Level": "",
            "Experience": "2 an(s)"
        },
        "title": "data scientist",
        "skills": {
            "ProgLanguage": [
                "Python"
            ],
            "DataBase": [
                "SQL"
            ],
            "Other": [
                "Statistiques",
                "Machine Learning"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "OUTSCALE",
        "location": "St.-Cloud, √éle-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/data-scientist-f-h-at-outscale-3891855564?position=42&pageNum=0&refId=SmRHYtKKcb%2BBbb%2BiSm10Sw%3D%3D&trackingId=IsY7TAlUvSHVx5hTEiDKPA%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "OUTSCALE, marque de Dassault Syst√®mes, est un op√©rateur souverain et durable de l Exp√©rience en tant que Service qui offre √† ses clients des environnements technologiques de confiance.\nNous offrons des exp√©riences uniques gr√¢ce au savoir-faire de nos √©quipes passionn√©es, qui se refl√®te notamment par la cr√©ation de solutions de Business Exp√©riences, le d√©veloppement de notre propre orchestrateur Cloud, TINA OS, ou encore l obtention de la qualification SecNumCloud.\nNotre mission ? B√¢tir un monde num√©rique accessible et meilleur pour tous √† travers la cr√©ation du jumeau virtuel de l organisation.\nNous menons une politique RH engag√©e et inclusive favorisant le bien-√™tre de nos collaborateur¬∑rices : respect de l √©quilibre vie priv√©e/vie professionnelle, d√©veloppement personnel et des comp√©tences professionnelles, onboarding complet\nNous rejoindre, c est partager une passion pour l innovation, des valeurs communes et imaginer ensemble des solutions de confiance pour construire un monde meilleur et durable !\nNous recrutons\nun¬∑e\nData Scientist\nafin de renforcer notre √©quipe\nBusiness Experience\n.\nVos missions\nAnalyser des probl√©matiques et proposer des solutions.\nMod√©liser, impl√©menter et √©valuer des algorithmes.\nTraiter des donn√©es non structur√©es.\nOptimiser des mod√®les ML/DL pour la scalabilit√©, l'efficacit√© et les performances.\nIndustrialiser des algorithmes dans les services API.\nD√©ployer des services sur le cloud.\nParticiper √† la r√©daction de sp√©cifications et documentations techniques.\nParticiper √† des √©v√©nements et publications scientifiques.\nStack technique\nPython\nFrameworks ML/DL (Pytorch)\nArchitectures de r√©seaux neuronaux (LLMs)\nImpl√©mentation d‚Äôalgorithmes ML/DL (apprentissage supervis√©/non-supervis√©)\nVotre profil:\nDipl√¥m√©¬∑e d‚Äôun Master en Intelligence Artificielle, Machine Learning.\n3 ans d‚Äôexp√©rience minimum post-dipl√¥me dans le domaine de l‚ÄôIA, Data Science, Machine Learning, NLP, Computer Vision.\nVous ma√Ætrisez l‚Äôanalyse et la transformation des donn√©es.\nId√©alement, vous avez de l‚Äôexp√©rience dans le d√©ploiement des mod√®les ML/DL sur le cloud.\nMotiv√©¬∑e, organis√©¬∑e, curieux¬∑se, vous appr√©ciez travailler en √©quipe.\nLa Diversit√© d‚ÄôOUTSCALE trouve aussi son expression dans notre politique de recrutement qui privil√©gie l‚Äô√©galit√© des chances, la diversit√© des individus au sein de nos √©quipes.\nShow more\nShow less",
        "details": {
            "JobDetail": [],
            "TypeContract": "",
            "Salary": "",
            "Level": "",
            "Experience": "3 an(s)"
        },
        "title": "data scientist",
        "skills": {
            "ProgLanguage": [
                "Python"
            ],
            "MachineLearning": [
                "PyTorch"
            ],
            "Other": [
                "Machine Learning",
                "Cloud",
                "ML"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "Modjo",
        "location": "Paris, √éle-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/ml-engineer-cdi-f-h-at-modjo-3909458542?position=43&pageNum=0&refId=SmRHYtKKcb%2BBbb%2BiSm10Sw%3D%3D&trackingId=MKj9%2BnH1EQH6FMM7qkuGrA%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Modjo:\nModjo is the leader European AI Revenue Platform whose mission is to drive revenue teams productivity & performance with AI-extracted knowledge from customers interactions.\nWhile AI is challenging how companies work across the world and all industries, Modjo brings these new capabilities to sales teams thanks to a platform that analyzes all interactions sales people have with their customers to improve sales teams productivity, drive strategy, and increase revenue.\nWe are a growing team of over 65 people, helping over 400 clients like BouyguesTelecom, Doctolib, Spendesk and Payfit in France and abroad. üåé\nJust like Slack, Zoom or Hubspot, Modjo is a product company. This means that our product is the core of what we are doing and how we are creating value to customers. Therefore, the success of the company relies on the capacity of its Tech & Product teams to deliver together the best product to its users.\nTeam organization :\nThe overall tech department is composed of 10 Software Engineers (2 squads), 2 ML Engineers, a Data Team (1 team lead + 1 analyst) and the CTO. You will be part of the Data Science team alongside the other ML Engineers.\nMission:\nModjo's core capabilities include capturing conversations between sales teams and their customers (video & audio recordings, emails..) and leveraging this data thanks to speech-to-text and various LLM-based processings to extract and structure data out of it.\nAs part of this, your main missions will be:\nCollaborating with Product and Engineering to build features that require machine-learning expertise\nBuild, maintain and optimize our infrastructure for doing production machine learning including our speech-to-text stack (processing thousands of hours of audio every day) and our infrastructure for using LLMs\nDesign and implement processes, tools and pipelines in order to work efficiently with LLMs for our multiple use cases\nStay up to date with latest speech-to-text and LLM technologies in order to include them in the product and build the relevant technological asset for Modjo to differentiate from basic competition. This includes exploring model-finetuning models and RAGs\nYour profile :\nWe think you would be a great fit if :\nYou have 3y+ experience in Machine Learning and Engineering\nYou have experience working with and knowledge about NLP, LLM and speech-to-text\nYou have experience with putting models in production, including monitoring and CI/CD\nYou are interested in solving real world use cases with LLMs and building the proper technology around it\nYou are eager to learn a lot in an autonomous way, both in Science and Engineering fields\nYou are willing to work in English (language of the team)\nYou want to join a company where the product you will be building is core to our strategy\nYou are looking for a challenging job, but also an environment where you can thrive and have fun on a day-to-day basis :)\nWe are looking for someone who will thrive and share our values:\nüòÉ Pleasure\n‚ÄúIf you Smile, things will work out‚Äù - Serena Williams\n‚úÖ Action\n‚ÄúDone is better than perfect‚Äù - Sheryl Sandberg\nüìö Continuous Learning\n‚ÄúAmateurs call it Genius, masters call it practice‚Äù - Thierry Henry\nü§≤ Team Spirit\n‚ÄúGreat things in business are never done by one person; they‚Äôre done by a team of people‚Äù - Steve Jobs\nShow more\nShow less",
        "details": {
            "JobDetail": [],
            "TypeContract": "",
            "Salary": "",
            "Level": "",
            "Experience": null
        },
        "title": "machine learning engineer",
        "skills": {
            "Collaboration": [
                "Slack",
                "Teams"
            ],
            "Other": [
                "Machine Learning",
                "ML",
                "CI/CD"
            ],
            "EnSoftSkils": [
                "Organization"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "SoftwareOne",
        "location": "Levallois-Perret, √éle-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/data-scientist-flexible-working-at-softwareone-3872563771?position=44&pageNum=0&refId=SmRHYtKKcb%2BBbb%2BiSm10Sw%3D%3D&trackingId=Rxycml7kM7vjS1uChU%2BrfA%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Why SoftwareOne?\nSoftwareOne is a leading global software and cloud solutions provider that is redefining how companies build, buy and manage everything in the cloud. By helping clients to migrate and modernize their workloads and applications ‚Äì and in parallel, to navigate and optimize the resulting software and cloud changes ‚Äì SoftwareOne unlocks the value of technology. The company‚Äôs 8,900 employees are driven to deliver a portfolio of 7,500 software brands with sales and delivery capabilities in 90 countries. Headquartered in Switzerland, SoftwareOne is listed on the SIX Swiss Exchange under the ticker symbol SWON. Visit us at https://www.softwareone.com/en\nThe role\nDATA Scientist\nThe primary focus for a candidate will be in applying different techniques (data mining/statistical analysis/build prediction systems/recommendation systems) using large company data sets to find opportunities for services and products and using models to test the effectiveness of different courses of action. The Candidate must have strong experience using a variety of data mining/data analysis methods, using a variety of data tools, building and implementing models, using/creating algorithms and creating/running simulations.\nWork with business cases to identify opportunities for leveraging company data to drive business solutions.\nMine and analyze data from company databases to drive optimization and improvement of product development and sales techniques\nAssess the effectiveness and accuracy of new data sources and data gathering\nExtending company‚Äôs data with third party sources of information when needed\nUse predictive modeling to increase revenue generation, ad targeting and other business outcomes.\nWhat We Need To See From You\nCore:\nAnalyze business cases and identify data sources (internal/external) and data mining/analysis methods to use\nDevelop a normalization engine to execute cleansing/deduplication for a raw data through ETL process for data sources\nCreate, train and test predictive models to solve defined business cases\nDevelop algorithms to apply to data sets\nDesign data structure models for collected data\nFacilitate the build of a solution from PoC to production\nWork with business owners to gather additional information about business cases\nJob Specific:\nWork with Google Cloud data and AI tools\nBe ready to work in agile style (daily, sprint planning, sprint review, retrospective)\nWork in an environment that adapts quickly to creative change using agile principles\nActively work with different development groups inside of organization\nBe ready to adapt a new tool/library/technology/platform\nDesirable Skills:\nFluent in French and English\nAt least 4 years experience in Machine learning models creation\nMaster‚Äôs in Statistics, Mathematics, Computer Science preferred\nProfessional Machine learning engineering certification\nExperience with common data science toolkits and libraries, such as pandas, keras, scipy, scikit, tensorflow, NumPy etc\nKnowledge and interest in the following:\nprediction models, Vertex AI, Tenserflow, BigQuery ML, Python,\nnatural language processing, deep learning models, dataPROC, Hadoop, SQL\nExperience using statistical computer languages namely Python to manipulate data and draw insights from large data sets\nStrong knowledge and experience using SQL language\nExperience with C++/C# and Java as a plus\nBackground in technology or professional services preferably in one or more of the domains of GCP and Security,\nStrong understanding of consulting business\nStrong structural work methods, multitasking and time management skills\nSelf-driven independent work ethics that drives internal and external accountability\nMay require periodic travel for workshops\nJob Function\nSoftware & Cloud Services\nShow more\nShow less",
        "details": {
            "JobDetail": [],
            "TypeContract": "",
            "Salary": "",
            "Level": "",
            "Experience": null
        },
        "title": "data scientist",
        "skills": {
            "ProgLanguage": [
                "Java",
                "Python"
            ],
            "DataBase": [
                "SQL"
            ],
            "DataAnalytics": [
                "NumPy",
                "Pandas"
            ],
            "BigData": [
                "Hadoop"
            ],
            "MachineLearning": [
                "TensorFlow",
                "Keras"
            ],
            "CloudComputing": [
                "GCP"
            ],
            "DBMS": [
                "BigQuery"
            ],
            "Other": [
                "Machine Learning",
                "Cloud",
                "ML"
            ],
            "EnSoftSkils": [
                "Time Management",
                "Organization"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "Hugging Face",
        "location": "France",
        "link": "https://fr.linkedin.com/jobs/view/machine-learning-engineer-fast-optimized-inference-emea-remote-at-hugging-face-3848456024?position=46&pageNum=0&refId=SmRHYtKKcb%2BBbb%2BiSm10Sw%3D%3D&trackingId=W5x%2BCkV95mLlRtBtZSe2XA%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Here at Hugging Face, we're on a journey to advance good Machine Learning and make it more accessible. Along the way, we contribute to the development of technology for the better.\nWe have built the fastest-growing, open-source, library of pre-trained models in the world. With more than 1 Million+ models and 320K+ stars on GitHub, over 15.000 companies are using HF technology in production, including leading AI organizations such as Google, Elastic, Salesforce, Algolia, Grammarly and NASA.\nAbout the role:\nAs a Machine learning Engineer, you work mainly on creating great libraries highly focused on real world ML use cases. We're building on top of our open-source to create more specialized code with a focus on industrial level of usage.\nWe are searching for someone who brings fresh ideas, demonstrates a unique and informed viewpoint, and enjoys collaborating with a progressive, nimble and decentralized approach to develop real-world solutions and positive user experiences at every interaction.\nObjectives of this role:\nDevelop specialized software for specific machine learning (ML) use cases that have broad applications, similar to [text-generation-inference](https://github.com/huggingface/text-generation-inference).\nUtilize existing library frameworks to create scalable software solutions for industrial purposes.\nEnhance the reliability, quality, and time-to-market of our software suite. Measure and optimize system performance to stay ahead of customer needs and drive innovation.\nManage the production environment by monitoring availability and ensuring overall system health. We run our own tools\nAbout you:\nIf you are a passionate Machine Learning Engineer with a keen interest in AI and proficient with Python, Rust and specialized Cuda kernels Frameworks (transformers of course + Keras or PyTorch), we would love to hear from you. Join our team and contribute to the advancement of AI technologies while working alongside talented professionals in a collaborative and stimulating environment.\nMore about Hugging Face\nWe are actively working to build a culture that values diversity, equity, and inclusivity\n.\nWe are intentionally building a workplace where people feel respected and supported‚Äîregardless of who you are or where you come from. We believe this is foundational to building a great company and community. Hugging Face is an equal opportunity employer and we do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.\nWe value development.\nYou will work with some of the smartest people in our industry. We are an organization that has a bias for impact and is always challenging ourselves to continuously grow. We provide all employees with reimbursement for relevant conferences, training, and education.\nWe care about your well-being\n.\nWe offer flexible working hours and remote options. We offer health, dental, and vision benefits for employees and their dependents. We also offer flexible parental leave and paid time off.\nWe support our employees wherever they are\n.\nWhile we have office spaces in NYC and Paris, we're very distributed and all remote employees have the opportunity to visit our offices. If needed, we'll also outfit your workstation to ensure you succeed.\nWe want our teammates to be shareholders\n.\nAll employees have company equity as part of their compensation package. If we succeed in becoming a category-defining platform in machine learning and artificial intelligence, everyone enjoys the upside.\nWe support the community\n.\nWe believe major scientific advancements are the result of collaboration across the field. Join a community supporting the ML/AI community.\nShow more\nShow less",
        "details": {
            "JobDetail": [
                "Remote"
            ],
            "TypeContract": "",
            "Salary": "Package",
            "Level": "",
            "Experience": null
        },
        "title": "machine learning engineer",
        "skills": {
            "ProgLanguage": [
                "Python"
            ],
            "MachineLearning": [
                "PyTorch",
                "Keras"
            ],
            "Other": [
                "Machine Learning",
                "ML"
            ],
            "EnSoftSkils": [
                "Organization",
                "Collaboration"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "TEC Partners - Technical Recruitment Specialists",
        "location": "Paris, √éle-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/machine-learning-engineer-at-tec-partners-technical-recruitment-specialists-3890985195?position=47&pageNum=0&refId=SmRHYtKKcb%2BBbb%2BiSm10Sw%3D%3D&trackingId=6XOoKR65fV1HEvtRit3hgQ%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Role Overview:\nAs a Senior Machine Learning Engineer, you will play a crucial role in the development and deployment of AI models to enhance creativity processes for our users. From curating data to training and validating models, you will have end-to-end ownership of your work. You will collaborate closely with cross-functional teams, share your expertise on AI, and participate in strategic decisions concerning our tech stack.\nResponsibilities:\nDevelop and deploy machine learning models tailored to user needs.\nOwn the entire process from data preprocessing to model deployment (MLOps).\nCollaborate with cross-functional teams on strategic decisions regarding the tech stack.\nShare knowledge and expertise on AI with the team.\nWork closely with users to understand their needs and improve product features.\nRequirements:\n5+ years of experience in machine learning, ideally in an early-stage startup environment.\nProven experience in training and deploying machine learning models for products.\nFamiliarity with data preprocessing pipelines and MLOps.\nWillingness to work with new technologies and parts of the stack.\nAbility to thrive in a fast-paced environment.\nPhD in computer science, machine learning, or related field preferred.\nFluent in English; proficiency in French is a plus.\nShow more\nShow less",
        "details": {
            "JobDetail": [
                "Senior"
            ],
            "TypeContract": "",
            "Salary": "",
            "Level": "",
            "Experience": null
        },
        "title": "machine learning engineer",
        "skills": {
            "Collaboration": [
                "Teams"
            ],
            "Other": [
                "Machine Learning"
            ],
            "EnSoftSkils": [
                "Creativity"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "Hashlist",
        "location": "Paris",
        "link": "https://fr.linkedin.com/jobs/view/ai-ml-engineer-autonomous-driving-at-hashlist-3889037092?position=48&pageNum=0&refId=SmRHYtKKcb%2BBbb%2BiSm10Sw%3D%3D&trackingId=lQkMtR7nZo3cmnz8Fe72yA%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Hashlist is a platform for tech positions & projects within the automotive sector.\nWe work with some of the largest OEMs, Tier1s, and Ecosystem Players developing for the automotive sector to help them fill on-demand tech talent gaps faster.\nAre you ready to be a part of that journey? We are now looking for a AI/ML Engineer that can help our client develop autonomous vehicles in Paris, France.\nResponsibilities:\nDesign, develop, and implement machine learning models and algorithms to improve ADAS (advanced driver assistance systems) and full AD (autonomous driving).\nCollaborate with data engineers to design data collection strategies, preprocess data, and enhance data quality for training machine learning models.\nUtilize state-of-the-art machine learning frameworks (e.g., TensorFlow, PyTorch) to develop models that are efficient, scalable, and can be deployed in embedded automotive systems.\nConduct experiments and iterative testing to evaluate the performance of machine learning models, utilizing A/B testing and other statistical methods to validate improvements.\nIntegrate machine learning models into automotive software systems, working closely with software engineers to ensure seamless deployment and operation.\nDocument the machine learning development process, including model design, evaluation metrics, and deployment strategies, to ensure reproducibility and facilitate knowledge sharing within the team.\nQualifications\n:\nBachelor‚Äôs or Master‚Äôs degree in Computer Science, Artificial Intelligence, Data Science, or a related field, with a strong focus on machine learning.\nProven experience in designing and implementing machine learning models, with a portfolio of projects that demonstrates expertise in predictive modeling, classification, clustering, and deep learning.\nProficiency in programming languages such as Python, and experience with machine learning libraries and frameworks (TensorFlow, PyTorch).\nStrong understanding of data structures, data modeling, and software architecture principles relevant to machine learning and artificial intelligence applications.\nExperience with data preprocessing techniques, feature engineering, and understanding of the principles of dataset construction for machine learning.\nFamiliarity with automotive systems and applications where machine learning can be applied is a plus.\nExcellent problem-solving skills, with the ability to work independently and in cross-functional teams to deliver innovative solutions.\nStrong communication skills, with the capacity to articulate complex technical concepts to both technical and non-technical stakeholders.\nNext steps:\nPress \"Apply\"\nWe will review your application\nIf qualified, you will be accepted into the network and can be considered for this and similar positions & projects.\nShow more\nShow less",
        "details": {
            "JobDetail": [
                "Full"
            ],
            "TypeContract": "",
            "Salary": "",
            "Level": "",
            "Experience": null
        },
        "title": "machine learning engineer",
        "skills": {
            "ProgLanguage": [
                "Python"
            ],
            "MachineLearning": [
                "PyTorch",
                "TensorFlow"
            ],
            "Collaboration": [
                "Teams"
            ],
            "Other": [
                "Machine Learning",
                "ML"
            ],
            "EnSoftSkils": [
                "Communication"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "IT&M STATS",
        "location": "√éle-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/data-scientist-h-f-at-it-m-stats-3803674187?position=49&pageNum=0&refId=SmRHYtKKcb%2BBbb%2BiSm10Sw%3D%3D&trackingId=rbaTqUdqVnTdM8rY5l52Ig%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "IT&M Stats intervient dans le domaine des statistiques, de la programmation et de la data science, principalement dans les secteurs de l‚ÄôIndustrie Pharmaceutique, Cosm√©tique, dans la Sant√© et l‚ÄôAgro-alimentaire et aupr√®s des Banques et Assurances. IT&M Stats est une filiale du Groupe Astek, acteur mondial de l‚Äôing√©nierie et du conseil en technologies.\nNous basons notre relation sur :\nUn respect des collaborateurs et des clients, de leurs aspirations,\nUn suivi personnalis√© des collaborateurs et des clients,\nUne gestion r√©guli√®re des carri√®res des collaborateurs,\nDes √©changes transparents,\nUne r√©activit√©, une disponibilit√© et une √©coute permanentes.\nNous recherchons un\nData Scientist\npour intervenir dans le secteur\ncosm√©tique\n.\nCela vous int√©resse ? Voici la suite !\nüëá\nMaintenance et mise √† jour de dashboards de suivi de tests sous PowerBi\nAnalyser les donn√©es g√©n√©r√©es en interne et externe et r√©aliser des analyses crois√©es /meta analyse pour une meilleure compr√©hension de la performance de nos produits/services\nR√©aliser des analyses pr√©dictives de la performance cosm√©tique en fonction de la formulation\nR√©aliser des interfaces dynamiques sous R Shiny\nR√©-analyser et v√©rifier les analyses statistiques r√©alis√©es par les prestataires externes le cas √©ch√©ant\nContribuer √† la mise en place des √©tudes et aider le d√©partement √† l‚Äôam√©lioration des process (Plan d‚Äôexp√©rience, calcul du nombre de sujets n√©cessaires, etc‚Ä¶)\nVous pensez √™tre la perle rare ?\nVous √™tes titulaire d‚Äôun dipl√¥me de type Bac+5 (Master 2 ou √©cole d‚Äôing√©nieur) avec une sp√©cialisation en statistiques, math√©matiques ou data science\nVous justifiez d‚Äôune exp√©rience professionnelle de 2 √† 3 ans\nUne bonne maitrise de R (dont R Shiny) est attendue\nVous maitrisez PowerBI\nVous √™tes organis√©, rigoureux, autonome, flexible, vous aimez communiquer et travailler en √©quipe et vous avez un bon esprit de synth√®se et d‚Äôanalyse\nVous avez un bon niveau d‚Äôanglais\nüçÄ\nVoici ce que nous pouvons vous offrir‚Ä¶\nUn poste en CDI √† pourvoir d√®s que possible, de la bonne humeur, des formations, des soir√©es, de la bienveillance, un suivi personnalis√©, une gestion r√©guli√®re de votre carri√®re, des √©changes transparents et une √©coute permanente.\nSi vous √™tes convaincu que vous √™tes la perle rare, postulez ! Nous sommes impatients de vous rencontrer.\nShow more\nShow less",
        "details": {
            "JobDetail": [],
            "TypeContract": "CDI",
            "Salary": "",
            "Level": "Bac+5",
            "Experience": "3 an(s)"
        },
        "title": "data scientist",
        "skills": {
            "ProgLanguage": [
                "R"
            ],
            "DataAnalytics": [
                "R"
            ],
            "Other": [
                "Statistiques"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "Finegrain",
        "location": "Paris, √éle-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/machine-learning-researcher-at-finegrain-3773290571?position=50&pageNum=0&refId=SmRHYtKKcb%2BBbb%2BiSm10Sw%3D%3D&trackingId=s15%2BTMFAXUAG%2FRQ8A%2Bjl%2Fw%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "**Our mission**\nAt Finegrain, we believe the Internet deserves better images, and we're building the ultimate GenAI platform to make it happen - at massive scale.\n**Our unfair advantage**\nOur founders are repeat entrepreneurs who sold their first AI company to Google, and we are backed by a stellar and worldwide team of investors.\n**Meet Refiners**\nUnder the hoods, Finegrain relies on a breakthrough micro framework for foundation model adaptation called Refiners. We're building it in the open (MIT license), on top of our beloved PyTorch.\n**Your mission**\nJoin us as a Machine Learning Research Engineer to help extend the capabilities of the Refiners framework, and train breakthrough adapters with it!\n**Skills**\nWe're looking for folks who:\n1. love PyTorch\n2. know visual foundation models like Stable Diffusion, SAM, BLIP-2 inside out\n3. enjoy keeping track of the latest innovations on arXiv\n**Why join us?**\n1. You'll be part of our founding team.\n2. You'll work at Station F, the world's largest startup campus.\n3. You'll rub shoulders with some of the sharpest minds in AI.\n4. You'll help shape a product set to break new ground.\n5. You'll work on real, impactful AI. No fluff.\n**Process**\nIt all starts with taking a look at our bounty program: just pick one, and show us what you got. If you complete it, you'll get paid!\nShow more\nShow less",
        "details": {
            "JobDetail": [],
            "TypeContract": "",
            "Salary": "",
            "Level": "",
            "Experience": null
        },
        "title": "Other",
        "skills": {
            "MachineLearning": [
                "PyTorch"
            ],
            "Other": [
                "Machine Learning"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "Acelys Services Num√©riques",
        "location": "Montpellier, Occitanie, France",
        "link": "https://fr.linkedin.com/jobs/view/data-scientist-traitement-du-langage-naturel-h-f-h-f-at-acelys-services-num%C3%A9riques-3906686343?position=51&pageNum=0&refId=SmRHYtKKcb%2BBbb%2BiSm10Sw%3D%3D&trackingId=NpHw5ViyGb3srUNUED6tCA%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Cette offre d‚Äôemploi est fournie par P√¥le emploi\nDescription\nCr√©√©e en 1997, Acelys Services Num√©riques est la 1√®re DFS (Digital Factory Services) de la R√©gion qui propose √† ses clients des services industrialis√©s de d√©veloppement et d'int√©gration √† haute valeur ajout√©e de solutions num√©riques. En particulier sur les domaines : - Du d√©veloppement logiciel & mobile ; - De la Business Intelligence & la Data Science ; - De l'int√©gration des solutions de d√©mat√©rialisation ; - De la cybers√©curit√© et des infrastructures - De l'innovation R&D et l'√©dition de logiciels. Depuis 2017, Acelys confirme sa ma√Ætrise de la s√©curit√© de son syst√®me de management de la s√©curit√© de l'information avec la certification ISO 27001 ! Bas√© √† Montpellier, au sein du dynamique P√¥le Eureka, notre centre abrite pr√®s de 70% de nos collaborateurs. Notre histoire solide, notre ind√©pendance, et notre pr√©sence r√©gionale font de nous un pilier de l'innovation num√©rique ! Avec une √©quipe de plus de 200 professionnels passionn√©s, Acelys favorise la croissance et le d√©veloppement de chacun. Nous encourageons la promotion interne et offrons un environnement propice √† l'acquisition de nouvelles comp√©tences. Rejoignez-nous d√®s aujourd'hui pour faire partie d'une √©quipe dynamique et contribuer √† fa√ßonner l'avenir num√©rique avec nous ! Description du poste : Acelys recherche un.e Data Scientist exp√©riment√© en IA et NLP pour rejoindre notre √©quipe dynamique au sein du p√¥le de R&D/IA d'une quinzaine de talents. Notre p√¥le R&D, expert dans le traitement du langage naturel (p√¥le Edition) m√®ne depuis 10 ans des travaux en √©troite collaboration avec des laboratoires de recherche sur des probl√©matiques technologiques. Vous travaillerez en lien avec les chercheurs, ing√©nieurs et autres experts en utilisant des techniques d'apprentissage automatique et de traitement du langage naturel pour r√©soudre des probl√®mes complexes, tels que la recherche documentaire, la similarit√© s√©mantique, la classification... Profil recherch√© : - Vous √™tes dipl√¥m√©.e en informatique, en sciences des donn√©es ou dans un domaine connexe - Vous disposez de solides comp√©tences en programmation (Python, TensorFlow, PyTorch, etc.) - Vous avez connaissance des techniques d'apprentissage automatique et du traitement automatique du langage naturel - Vous √™tes exp√©riment√©.e sur les pratiques CI/CD (int√©gration continue et d√©ploiement continu) - Une exp√©rience sur les Frameworks Python est appr√©ci√©e : Langchain, Django/Flask,Transformers Avantages : - Salaire comp√©titif et avantages sociaux : Carte Swile, pr√©voyance Cadre, RTT, Plan Epargne Entreprise avec abondements, t√©l√©travail et un accord de participation tr√®s avantageux (1,5 mois de salaire ces derni√®res ann√©es en moyenne) - Environnement de travail collaboratif et stimulant - Contribution √† des projets innovants Acelys Services Num√©riques c'est plus de 25 ans d'histoire, √©crivons la suite ensemble !\nPROFIL SOUHAIT√â\nExp√©rience\n18 Mois\nSavoirs et savoir-faire\nAdapter les outils de traitement statistique de donn√©es\nD√©finir et faire √©voluer des proc√©d√©s de traitement de l'information\nPr√©senter et diffuser les r√©sultats des √©tudes r√©alis√©es\nR√©aliser une veille documentaire\nR√©diger l'information produite\nSavoir-√™tre professionnels\nFaire preuve de rigueur et de pr√©cision\nPrendre des initiatives et √™tre force de proposition\nTravailler en √©quipe\nSource: Pole emploi (https://www.pole-emploi.fr)\nShow more\nShow less",
        "details": {
            "JobDetail": [],
            "TypeContract": "",
            "Salary": "1,5",
            "Level": "",
            "Experience": "10 an(s)"
        },
        "title": "data scientist",
        "skills": {
            "ProgLanguage": [
                "R",
                "Python"
            ],
            "DataAnalytics": [
                "R"
            ],
            "MachineLearning": [
                "PyTorch",
                "TensorFlow"
            ],
            "Other": [
                "CI/CD"
            ],
            "EnSoftSkils": [
                "Collaboration"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "Talan",
        "location": "Paris, √éle-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/data-scientist-confirm%C3%A9-s%C3%A9nior-h-f-cdi-at-talan-3909648101?position=52&pageNum=0&refId=SmRHYtKKcb%2BBbb%2BiSm10Sw%3D%3D&trackingId=5tMjyzjS5yqn4uT0AUjdCA%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Talan est un groupe international de conseil en transformation et en innovation par la technologie, cr√©√© en 2002.\nNos 5000 consultantes et consultants partagent √† travers le monde l‚Äôaudace d‚Äôinnover, le go√ªt de l‚Äôexcellence, et l‚Äôenvie de relever les d√©fis les plus complexes.\nNous accompagnons les entreprises dans des secteurs vari√©s‚ÄØ: √©nergie, industrie, transport, finance, luxe‚Ä¶ √† travers 3 grandes expertises‚ÄØ:\nLe Conseil en Management et Innovation (320 Consultants en France)\nLa valorisation des donn√©es, leurs structurations, et leurs usages (Data et Technologies)\nL‚Äôint√©gration de solutions logicielles (Cloud et Applications Services)\nNos valeurs‚ÄØ: engagement, respect, partage, esprit d‚Äô√©quipe et optimisme.\nTalan est une entreprise responsable, reconnue par ses collaborateurs et attach√©e √† la diversit√©. Des am√©nagements peuvent √™tre propos√©s si vous √™tes en situation de handicap.\nRetrouvez nos engagements RSEiciet nos actions en faveur de la diversit√©ici\nJob Description\nNous sommes √† la recherche d‚Äôun Data Scientist capable de participer √† des projets techniques Data Science et IA. Vous devrez faire preuve d‚Äôun √©tat d‚Äôesprit √† la fois innovant, m√©thodique, orient√© solution (et non probl√®me!), et communiquant.\nVotre but ultime sera de garantir l‚Äôexcellence de vos solutions Data Science/IA, pi√®ces maitresses de la r√©alisation de projets disruptifs pour nos clients.\nVOTRE ROLE SUR NOS PROJETS\n:\nEn mission: analyse des besoins m√©tiers, d√©finition des principes et m√©thodes de collecte et de traitement des donn√©es, choix des mod√®les de Machine Learning ou de Deep Learning, mise en application des techniques de traitement et de visualisation de la data, restitution des analyses et r√©sultats obtenus aupr√®s des m√©tiers et des sponsors\nPartager techniquement les membres de l‚Äô√©quipe: solutions et code reviews, recommandations, certifications √† r√©aliser, ‚Ä¶\nParticipation √† des meet-up, coding dogo,‚Ä¶\nCommunication: √©criture d‚Äôarticles, retours d‚Äôexp√©rience‚Ä¶\nVOTRE ROLE CHEZ TALAN :\nBenchmark de solutions et conseil aupr√®s de nos clients sur les solutions technologiques √† adopter, en lien avec leurs besoins\nR√©alisation de POC (Proof Of Concept)\nParticipation √† des projets internes et partage de connaissances au sein de nos √©quipes.\nPartage de connaissances et formations interne\nQualifications\nVOTRE PROFIL:\nIssu d‚Äôune formation Grande √âcole d‚ÄôIng√©nieur/Doctorant, sp√©cialis√©e en Data Science ou Intelligence Artificielle\nVous disposez d‚Äôau moins 3 ann√©es d‚Äôexp√©rience dans le domaine\nMaitrise des techniques d‚Äôanalyses statistiques, de mod√©lisations pr√©dictives, de Machine Learning, de Deep Learning,...\nMaitrise des techniques de data management et de DataViz\nMaitrise de Python, R, RShiny, SQL‚Ä¶\nMaitrise de l‚Äôutilisation des outils DevOps: Git, Docker, Jenkins/Nexus,‚Ä¶\nBonnes connaissances Big Data: pySpark, Spark, NoSQL‚Ä¶\nConnaissance d‚Äôoutils tels que Dataiku, AWS SageMaker, Azure ML,‚Ä¶\nAutonomie, organisation, sens du partage\nExcellente communication\nOrientation m√©tier\nAdditional Information\nAVANTAGES\n:\nPlan de formation pour accompagner votre carri√®re (formations √©diteurs, certifications) gr√¢ce √† nos partenariats nous accordant une position de partenaire privil√©gi√©, et management de proximit√© par des experts\nLocaux modernes en centre-ville\nTop 5 du Palmar√®s Great Place to Work\nT√©l√©travail jusqu‚Äô√† 5 jours selon les missions, prime d‚Äô√©quipement de 100‚Ç¨\nMobilit√© en France et √† l‚Äô√©tranger\nTop 1% des entreprises √©valu√©es par Ecovadis dans le domaine social, environnemental et √©thique\nTickets restaurant, prime vacances, 50% transport (abonnement transport public), mutuelle\nPermanence handicap (consultant d√©di√© aux collaborateurs en situation de handicap et aux proches aidants)\nActionnariat salari√©\nPrime de cooptations\nRTT\nPROCESS RECRUTEMENT\n:\nL‚Äô√©quipe recrutement s‚Äôengage √† vous proposer un processus de recrutement rapide et fluide\n1 entretien RHpar Teams (45min)\n1 test technique\n1 entretien op√©rationnel avec le responsable de domaine, au si√®ge (1heure)\n1 entretien avec le directeur de p√¥le, au si√®ge(1heure)\nShow more\nShow less",
        "details": {
            "JobDetail": [],
            "TypeContract": "",
            "Salary": "",
            "Level": "",
            "Experience": null
        },
        "title": "data scientist",
        "skills": {
            "ProgLanguage": [
                "R",
                "Python"
            ],
            "DataBase": [
                "SQL",
                "NoSQL"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [
                "Spark"
            ],
            "CloudComputing": [
                "AWS",
                "Azure"
            ],
            "DevTools": [
                "Git",
                "Docker",
                "Jenkins"
            ],
            "Containers": [
                "Docker"
            ],
            "Collaboration": [
                "Teams"
            ],
            "Other": [
                "ML",
                "Big Data",
                "Statistiques",
                "Machine Learning",
                "Cloud",
                "DevOps"
            ],
            "EnSoftSkils": [
                "Communication"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "Astek",
        "location": "Bordeaux, Nouvelle-Aquitaine, France",
        "link": "https://fr.linkedin.com/jobs/view/ing%C3%A9nieur-machine-learning-%E2%80%93-bordeaux-france-h-f-at-astek-3882494346?position=53&pageNum=0&refId=SmRHYtKKcb%2BBbb%2BiSm10Sw%3D%3D&trackingId=2aHNqmFPtUAjz%2FJRRWjwcw%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "CDI\nBordeaux - France\nPubli√©e il y a 1 mois\nLe Groupe Astek\nCe Que Nous Allons Accomplir Ensemble :\nRejoignez nos √©quipes et intervenons ensemble sur les projets de nos partenaires autour des enheux d‚Äôinnovation.\nVotre Mission, Si Vous L‚Äôacceptez :\nCadrer techniquement les projets et accompagner les Data Scientists dans la construction des mod√®les en veillant √† respecter les bonnes pratiques d‚Äôing√©nierie logicielle.\nMettre en place la d√©marche ML OPS\nD√©ployer les mod√®les en production en respectant des contraintes de co√ªts, pr√©cisions et performances techniques.\nImpl√©menter les outils permettant de monitorer ces mod√®les en production\nVous ?\nVous √™tes issu(e) d‚Äôune formation Bac+5 (√âcole d‚Äôing√©nieur, Universit√© ou √©quivalent ‚Ä¶) en informatique\nVous justifiez d‚Äôune exp√©rience significative d‚Äôau moins 5 ans au sein d‚Äôune √©quipe dans un environnement Data √† l‚Äô√©chelle du SI d‚Äôun grand groupe\nVous √™tes un bon communiquant et disposez de capacit√©s d‚Äôanalyse et de synth√®se √©prouv√©es\nVous accordez de l‚Äôimportance √† la veille technologique\nComp√©tences Techniques :\nExpertise en SPARK et PySpark\nConnaissance de Kubernetes\nConnaissance de d‚ÄôApache Kafka\nUne exp√©rience sur un cloud provider public comme Azure (id√©alement), AWS, ou GCP\nExpertise de d√©veloppement en Python\nExpertise du ML OPS\nComp√©tences Transverses :\nCapacit√© √† interagir avec des parties prenantes diverses : Data Scientists, Business analyst, Architectes, M√©tier\nForte exp√©rience en mode de Delivery Agile (Scrum, Kanban, etc.‚Ä¶)\nEtre expert dans les pratiques du Software Craftsmanship (Test Driven, Development, Behavior Driven Development, Clean Code, Code Reviews, etc.)\nEt :\nDes Connaissances sur Azure DevOps, Azure Pipeline, GIT\nMaitrise des Traitements Big Data en mode Streaming\nMaitrise des Bases de donn√©es relationnelles et NoSQL\nUne exp√©rience professionnelle avec des outils comme Azure Databricks, Azure, Machine Learning , Azure Data Lake Storage ou encore Azure Data Factory\nLe Groupe Astek\nCr√©√© en France en 1988, Astek est un acteur mondial de l‚Äôing√©nierie et du conseil en technologies. Fort de son expertise dans de nombreux secteurs industriels et tertiaires, Astek accompagne ses clients internationaux dans le d√©ploiement intelligent de leurs produits et de leurs services, et dans la mise en ≈ìuvre de leur transformation digitale.\nDepuis sa cr√©ation, le Groupe a fond√© son d√©veloppement sur une forte culture d‚Äôentrepreneuriat et d‚Äôinnovation, et sur l‚Äôaccompagnement et la mont√©e en comp√©tence de\nses 7800 collaborateurs\nqui s‚Äôengagent chaque jour √† promouvoir la compl√©mentarit√© entre les technologies num√©riques et l‚Äôing√©nierie des syst√®mes complexes.\nRejoignez un Groupe en fort d√©veloppement en France et √† travers le monde ayant r√©alis√© un chiffre d‚Äôaffaires de 600 M‚Ç¨ en 2023.\nTous les d√©tails sur le Groupe sur le site https://astekgroup.fr. Et vous pouvez aussi nous suivre sur notre blog : https://blog.groupeastek.com.\nRencontrons-nous\nNotre projet commun vous plait ?\nPostulez √† cette annonce, et soyez transparent !\nNotre Talent Acquisition Officer, vous contactera pour un premier √©change t√©l√©phonique.\nPuis vous rencontrerez votre futur manager, avec lequel vous √©changerez autour d‚ÄôAstek, de votre parcours, de vos attentes et de votre future mission .\nEnfin, vous rencontrerez notre Directeur de d√©partement, avec lequel vous pourrez valider votre int√©r√™t et ad√©quation pour le poste et finaliser les √©l√©ments contractuels.\nNos Plus\nAstek est green et fait b√©n√©ficier ses salari√©s d‚Äôune indemnit√© kilom√©trique v√©lo\nUne politique CARE sur-mesure d√©ploy√©e par nos √©quipes RH pour nos collaborateurs (https://astekgroup.fr/engagements)\nNotre charte de la Diversit√©\nBienvenue dans la team ! Allez-y, maintenant c‚Äôest √† vous de jouer !\nMots-cl√©s :\ning√©nieur ‚Äì ing√©nieure ‚Äì consultant ‚Äì consultante\nCaract√©ristiques de l'emploi\nCat√©gorie Chef de Projet\nJob Industry A√©rospatial / D√©fense / S√©curit√©, Distribution / Services Internet, Energie / Sciences de la Vie / Autres industries, Finance / Gouvernement, T√©l√©com / M√©dia, Transports Terrestres\nPostuler en ligne\nNom *\nPr√©nom *\nEmail *\nUn email valide est requis.\nT√©l√©phone *\nUn num√©ro de t√©l√©phone valide est requis.\nJoindre un CV *\nMots-cl√©s :\ning√©nieur ‚Äì ing√©nieure ‚Äì consultant ‚Äì consultante\nShow more\nShow less",
        "details": {
            "JobDetail": [],
            "TypeContract": "CDI",
            "Salary": "",
            "Level": "Bac+5",
            "Experience": "5 an(s)"
        },
        "title": "Other",
        "skills": {
            "ProgLanguage": [
                "Python"
            ],
            "DataBase": [
                "NoSQL"
            ],
            "BigData": [
                "Databricks",
                "Spark"
            ],
            "CloudComputing": [
                "GCP",
                "AWS",
                "Azure"
            ],
            "DevTools": [
                "Git"
            ],
            "SoftBigDataProcessing": [
                "Apache Kafka"
            ],
            "Automation": [
                "Chef",
                "Kubernetes"
            ],
            "Containers": [
                "Kubernetes"
            ],
            "Other": [
                "ML",
                "Big Data",
                "Machine Learning",
                "Cloud",
                "DevOps"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "Licorne Society",
        "location": "Paris, √éle-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/front-end-software-engineer-at-licorne-society-3918084328?position=54&pageNum=0&refId=SmRHYtKKcb%2BBbb%2BiSm10Sw%3D%3D&trackingId=yryqI4Aq5lVU%2BEyOn5CyTA%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Licorne Society a √©t√© missionn√© par une startup en pleine croissance pour les aider √† trouver leur Front-End Software Engineer\nCONTEXTE\nNous recherchons un D√©veloppeur Fullstack √† dominante Front End pour rejoindre notre √©quipe ambitieuse sur un projet technique complexe : une plateforme No-code B2B qui r√©invente la gestion des op√©rations au sein des entreprises, gr√¢ce √† l'IA.\nLes entreprises s‚Äôappuient sur notre plateforme de gestion int√©gr√©e pour orchestrer leurs processus, automatiser les t√¢ches r√©currentes et, √† terme, accro√Ætre leur performance op√©rationnelle.\nNous Disposons D'un Premier Produit Stable Et Nous Renfor√ßons Notre √âquipe Tech Pour Acc√©l√©rer Le D√©veloppement Du Produit, Elle Est Pour L'instant Compos√©e De\nMatthieu (CTO)\nHugo (Dev Fullstack)\nMatthieu notre CTO a l'habitude des exp√©riences entrepreneuriales et a notamment co-fond√© Tessan.\nDescription Du Poste\nEn tant que Dev Fullstack √† dominante Front-end, tu seras amen√©¬∑e √† :\nTravailler sur les d√©veloppements front-end et √™tre force de proposition concernant l'UI et UX du produit,\nD√©velopper de nouvelles fonctionnalit√©s sur le projet,\nParticiper √† la conception et l'am√©lioration des bonnes pratiques de d√©veloppement,\nAvoir la possibilit√© de toucher au backend si cela t'int√©resse.\nStack globale du projet : TypeScript, Angular, React, Nest, Node.js, MongoDB, AWS...\nPACKAGE\nPossibilit√© de travailler 1 jour par semaine en remote\nMutuelle d'entreprise\nTitre de transport\nR√©mun√©ration attractive\nPROFIL RECHERCH√â\nAujourd'hui, nous recherchons un profil r√©pondant aux crit√®res suivants :\nTu as d√©j√† connu plusieurs ann√©es (au moins 2-3 ans) d'exp√©rience professionnelle en d√©veloppement frontend,\nTu es une personne curieuse, proactive et autonome,\nTu appr√©cies l'UI et l'UX.\nLES PLUS DU POSTE\nDevenir l'une des premi√®res recrues d'une startup early et ambitieuse\nPossibilit√© de vivre une aventure depuis quasi le d√©but\nRemote possible\nDes locaux neufs dans Paris centre (3√®me)\nShow more\nShow less",
        "details": {
            "JobDetail": [
                "Remote",
                "Full"
            ],
            "TypeContract": "",
            "Salary": "1",
            "Level": "",
            "Experience": "3 an(s)"
        },
        "title": "software engineer",
        "skills": {
            "DataBase": [
                "MongoDB"
            ],
            "CloudComputing": [
                "AWS"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "BrainChip",
        "location": "Toulouse, Occitanie, France",
        "link": "https://fr.linkedin.com/jobs/view/software-engineer-at-brainchip-3902556694?position=55&pageNum=0&refId=SmRHYtKKcb%2BBbb%2BiSm10Sw%3D%3D&trackingId=ta6xdF%2FQI99sFwyek1rCKg%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Brainchip is a leading technology company specializing in the design of electronics IP that accelerates AI on the edge. Our innovative solutions enable ultra-efficient and high-performance neural network processing for artificial intelligence applications. As part of our continuous growth, we are seeking a skilled Software Engineer with expertise in machine learning frameworks to join our team.\nResponsibilities:\nCollaborate with cross-functional teams to design, develop, and deploy machine learning models and algorithms for our products.\nImplement and optimize machine learning frameworks such as Tensorflow/Keras, PyTorch, and ONNX.\nDevelop software tools and infrastructure to support machine learning workflows, data preprocessing, model training, and evaluation.\nStay up-to-date with the latest advancements in machine learning and apply relevant techniques to enhance our products.\nConduct code reviews, provide constructive feedback, and maintain code quality and documentation.\nRequirements:\nBachelor's or Master's degree in Computer Science, Engineering, or a related field.\nStrong proficiency in machine learning frameworks such as Tensorflow/Keras, PyTorch, and ONNX.\nDemonstrated experience in developing and deploying machine learning models and algorithms.\nSolid understanding of deep learning concepts, neural networks, and related architectures.\nProficiency in programming languages such as Python, or C++.\nExperience with data preprocessing, feature engineering, and data visualization techniques.\nKnowledge of software engineering best practices, including version control, testing, and code documentation.\nStrong problem-solving skills and ability to work in a fast-paced, collaborative environment.\nExcellent communication skills and ability to effectively articulate technical concepts to both technical and non-technical team members.\nPreferred Qualifications:\nUnderstanding of computer vision or natural language processing (NLP) concepts and applications.\nExperience with deployment and optimization of machine learning models on edge devices.\nActive participation in the machine learning community, such as publications or open-source contributions.\nBenefits:\nCompetitive salary and comprehensive benefits package.\nOpportunities for professional growth and career advancement.\nCollaborative and inclusive work environment.\nFlexible work hours with the possibility to work remotely three days a week.\nAccess to cutting-edge technology and resources.\nShow more\nShow less",
        "details": {
            "JobDetail": [
                "Remote"
            ],
            "TypeContract": "",
            "Salary": "Salary, Package",
            "Level": "",
            "Experience": null
        },
        "title": "software engineer",
        "skills": {
            "ProgLanguage": [
                "Python"
            ],
            "MachineLearning": [
                "PyTorch",
                "TensorFlow",
                "Keras"
            ],
            "Collaboration": [
                "Teams"
            ],
            "Other": [
                "Machine Learning"
            ],
            "EnSoftSkils": [
                "Communication"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "EarthDaily Agro",
        "location": "Balma, Occitanie, France",
        "link": "https://fr.linkedin.com/jobs/view/geospatial-data-scientist-at-earthdaily-agro-3884744208?position=56&pageNum=0&refId=SmRHYtKKcb%2BBbb%2BiSm10Sw%3D%3D&trackingId=1u1srjZh101TrMC%2BiaXyRw%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "STRUCTURE D‚ÄôACCUEIL\nEarthDaily Agro fournit des donn√©es et des analyses de l'√®re spatiale aux organisations et aux personnes qui nourrissent la plan√®te !\nAvec 35 ans d'exp√©rience dans le secteur, EarthDaily Agro fournit √† ses clients les donn√©es, les analyses et les connaissances dont ils ont besoin pour prendre des d√©cisions plus efficaces. Les services B2B vont de la gestion globale des risques et du suivi des produits agricoles √† la commercialisation d'intrants et au conseil en agriculture de pr√©cision, en utilisant les derni√®res recherches en agronomie, en technologies de l'information et en t√©l√©d√©tection.\nEarthDaily Agro d√©veloppe √©galement des solutions commerciales hautement personnalis√©es pour les pr√™teurs agricoles, les assureurs, les fournisseurs d'intrants et les entreprises alimentaires, avec des analyses faciles √† utiliser, qui aident √† r√©duire les risques quotidiens de l'agriculture.\nEarthDaily Agro, dont le si√®ge social se trouve √† Minneapolis, MN, USA, et qui poss√®de des bureaux en France, au Br√©sil, en Australie et en Suisse, est une division de EarthDaily Analytics Corp.\nEarthDaily Analytics Corp, une soci√©t√© de traitement et d'analyse de donn√©es verticalement int√©gr√©e, lance une nouvelle constellation de satellites d'observation de la terre. La constellation de satellites EarthDaily am√©liorera consid√©rablement les capacit√©s d'analyse g√©ospatiale dans les secteurs de l'agriculture, de la sylviculture, de l'environnement, des services financiers et du renseignement, parmi de nombreux autres segments.\nRESPONSABILIT√âS\nVous serez en charge de r√©soudre des challenges li√©s √† l‚Äôagriculture en utilisant la t√©l√©d√©tection, en particulier les images de la future constellation EarthDaily, et des donn√©es m√©t√©o. Bas√© √† Balma, √† proximit√© de Toulouse, vous int√©grerez une √©quipe internationale avec des coll√®gues au Br√©sil et aux USA.\nVOS RESPONSABILIT√âS INCLURONT :\nL‚Äôagriculture fait face √† des challenges sans‚ÄØpr√©c√©dent‚ÄØ: le changement climatique induit des risques accrus, et les agriculteurs doivent maintenir voire am√©liorer leur productivit√© tout en r√©duisant leur impact environnemental. Avec la future constellation EarthDaily (jusqu‚Äô√† 5 m de r√©solution, revisite quotidienne avec 22 bandes spectrales du visible √† l‚Äôinfra-rouge thermique), EarthDaily Agro disposera d‚Äôune technologie clef pour r√©pondre √† ces probl√©matiques.‚ÄØRejoignez EarthDaily Agro pour contribuer √† minimiser ces risques avec la technologie.\nEarthDaily Agro est √† la recherche d‚Äôun.e‚ÄØData‚ÄØScientist en t√©l√©d√©tection pour rejoindre‚ÄØson √©quipe R&D et construire des analytiques √† valeur ajout√©e √† destination de ses clients dans le monde agricole.\nVous mettez en place des solutions inventives pour r√©pondre aux probl√©matiques des clients, demandant des comp√©tences fortes en analyse de donn√©es et‚ÄØen‚ÄØmachine‚ÄØlearning, dans un‚ÄØcontexte‚ÄØde larges volumes de donn√©es et d‚Äôune base existante de plus de 100 analytiques. Vous d√©veloppez des‚ÄØPOCs‚ÄØet prototypes, d√©finissez / testez / validez et sp√©cifiez les algorithmes appropri√©s. Vous √™tes activement‚ÄØimpliqu√©.e‚ÄØdans le design et la mise en place de la solution op√©rationnelle sur notre plateforme Cloud.\nVos missions‚ÄØ:\nComprendre les probl√©matiques m√©tier et les traduire en solution algorithmique bas√©e sur les donn√©es issues de la t√©l√©d√©tection.\nCr√©er et‚ÄØimpl√©menter‚ÄØdes mod√®les bas√©s sur l‚Äô√©tat de l‚Äôart, pour extraire l‚Äôinformation pertinente d‚Äôun large volume de donn√©es\nCollaborer au sein d‚Äôune √©quipe Agile pluridisciplinaire et internationale de Data Scientists, Data Engineers et experts m√©tiers dans toutes les phases du projet‚ÄØ: de l‚Äôid√©ation √† l‚Äôindustrialisation et d√©ploiement op√©rationnel\nR√©diger des supports de pr√©sentation des r√©sultats, conditions d‚Äôutilisation, et‚ÄØd√©fendre‚ÄØla solution propos√©e par une approche pragmatique\n√ätre‚ÄØproactif(ve)‚ÄØpour alimenter le pipeline d‚Äôinnovation avec des nouvelles id√©es, contribuer √† d√©finir la roadmap R&D\nEDUCATION, CONNAISSANCES ET CAPACIT√âS\nMaster ou doctorat en Machine Learning / Math√©matiques appliqu√©es, t√©l√©d√©tection,‚ÄØou domaine associ√©\nAu moins 3 ans d‚Äôexp√©rience professionnelle, exp√©rience dans un domaine associ√© √† l‚Äôagriculture et en entreprise priv√©e appr√©ci√©e\nEtat d‚Äôesprit orient√© r√©sultats et pragmatique pour √©voluer dans un contexte de plannings serr√©s\nMa√Ætrise‚ÄØde‚ÄØPython, connaissance en SIG (QGIS,‚ÄØGDAL/OGR),\nLa connaissance‚ÄØdes biblioth√®ques de‚ÄØMachine‚ÄØLearning /‚ÄØDeep‚ÄØLearning (Scikit-learn, Pytorch, Tensorflow‚Ä¶), des outils de MLOps (ZenML, MLFlow), des syst√®mes de‚ÄØgestion de‚ÄØversion (git), de Docker, Kubernetes et du fonctionnement des workflows sur AWS (et Azure)‚ÄØest appr√©ci√©e\nFacilit√©s de communication pour le travail en √©quipe dans un contexte international\nAnglais courant‚ÄØ(oral‚ÄØet √©crit)‚ÄØ:‚ÄØl‚Äô√©quipe d‚Äôaccueil est internationale, les r√©unions internes se d√©roulent‚ÄØprincipalement‚ÄØen anglais.\nVous √™tes curieux(se)‚ÄØet cr√©atif(ve), collaboratif(ve)‚ÄØet adaptable‚ÄØ?‚ÄØRejoignez-nous‚ÄØ!\nCONDITIONS\nEmploi en CDI, d√©marrage d√®s que possible\nPoste‚ÄØbas√©‚ÄØ√† Balma, premi√®re couronne‚ÄØde Toulouse‚ÄØaccessible en transports en commun.‚ÄØPossibilit√© de t√©l√©travail partiel.\nPowered by JazzHR\nm5SHCur65r\nShow more\nShow less",
        "details": {
            "JobDetail": [],
            "TypeContract": "CDI",
            "Salary": "",
            "Level": "",
            "Experience": "35 an(s)"
        },
        "title": "data scientist",
        "skills": {
            "ProgLanguage": [
                "R",
                "Python"
            ],
            "DataAnalytics": [
                "R"
            ],
            "MachineLearning": [
                "Scikit-Learn",
                "TensorFlow",
                "PyTorch"
            ],
            "CloudComputing": [
                "AWS",
                "Azure"
            ],
            "DevTools": [
                "Git",
                "Docker"
            ],
            "Automation": [
                "Kubernetes"
            ],
            "Containers": [
                "Docker",
                "Kubernetes"
            ],
            "Other": [
                "Machine Learning",
                "Cloud"
            ],
            "EnSoftSkils": [
                "Communication"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "Enzo Tech Group",
        "location": "√éle-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/data-scientist-at-enzo-tech-group-3914681877?position=57&pageNum=0&refId=SmRHYtKKcb%2BBbb%2BiSm10Sw%3D%3D&trackingId=1hj%2BoSKn7TZPJCxggJehuw%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Role:\nData Scientist\nLocation:\nParis (3 days) / Remote (2 days)\nSearching for a\nData Scientist\npartnering with a global customer who are searching for multiple Data Scientist's as they continue to invest in designing and building high-quality AI solutions.\nResponsibilities\nAnalyze raw data: assessing quality, cleansing, structuring for downstream processing\nDesign accurate and scalable prediction algorithms\nCollaborate with engineering team to bring analytical prototypes to production\nGenerate actionable insights for business improvements\nQualifications\nBachelor's degree or equivalent experience in quantative field (Statistics, Mathematics, Computer Science, Engineering, etc.)\nTech Stack: GenAI, Databricks, Azure\nAt least 1 - 2 years' of experience in quantitative analytics or data modelling\nDeep understanding of predictive modelling, machine-learning, clustering and classification techniques, and algorithms\nFluency in a programming language (Python, C,C++, Java, SQL)\nCVs:\nApply via job post or directly\n@\nk.downs@enzotechgroup.com\nShow more\nShow less",
        "details": {
            "JobDetail": [
                "Remote"
            ],
            "TypeContract": "",
            "Salary": "",
            "Level": "",
            "Experience": null
        },
        "title": "data scientist",
        "skills": {
            "ProgLanguage": [
                "Java",
                "Python"
            ],
            "DataBase": [
                "SQL"
            ],
            "BigData": [
                "Databricks"
            ],
            "CloudComputing": [
                "Azure"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "Dashlane",
        "location": "Paris, √éle-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/machine-learning-engineer-at-dashlane-3903118945?position=58&pageNum=0&refId=SmRHYtKKcb%2BBbb%2BiSm10Sw%3D%3D&trackingId=ArwQEmQnk73WUbT3diQpaw%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "About Dashlane\nDashlane's mission is to make security simple for millions of organizations and their people. We empower businesses of every size to protect company and employee data while helping everyone easily log in to the accounts they need‚Äîanytime, anywhere. Over 17 million users and 20,000 businesses in 180 countries use Dashlane for a faster, simpler, and more secure internet.\nOur global team is united by a strong sense of community and passion for improving the digital experience of our users. Learn more about how we work , how we hire , and the benefits of being a Dashlaner in our Life at Dashlane page.\nAt Dashlane, we see data as a true and reliable asset: data drives decisions based on timely insights and all teams are empowered to use data in their daily work.\nWe are hiring a Machine Learning Engineer to join our data & analytics team.\nHelping us to build & productionize impactful and actionable data models to be used in predictive and prescriptive analytics by our stakeholders and analysts teams.\nYou will play a pivotal role of managing data at rest and in motion along with governance controls empowering our business & technical users with trusted, timely and actionable data . You will be responsible for bringing robust, efficient, and integrated data models to life. You are expected to roll up your sleeves and deep dive into development on need basis. You should speak the language of business teams and technical teams, able to translate data insights and analysis needs into models.\nLocation:\nYou will be based in Paris, with English as your working language. We offer a hybrid work arrangement, with Tuesday being the company day, where we all collaborate in the office and have a company-sponsored meal, a department day for team bonding (will be Thursday for your department), and a third day at your choice. We offer relocation support (national and international).\nAbout Our Stack\nProgramming language: Python\nData Platform: AWS [ S3, EC2, ECS, Lambda, Kinesis, Glue & DMS], MySQL on RDS, Redis\nETL and ELT Tools: Airbyte and Hightouch\nData Modeling & Orchestration : DBT and Airflow\nRelease management and CI/CD: Gitlab\nBI Tools: Tableau\nInfrastructure provisioning and management: Terraform\nLogging and monitoring: ELK (ElasticSearch, Logstash, Kibana) & AWS Cloudwatch\nDocumentation and collaboration tooling: Confluence, Gitlab & Slack\nAt Dashlane You Will\nWork with batch and real-time operational and product usage data to build and improve ML models for Dashlane business.\nPrototype machine learning use cases and work with stakeholders to iterate on requirements.\nDevelop, productionize, and operate ML models and pipelines at scale.\nDrive end-2-end algorithm development of productionized models i.e. specifications, training data generation, testing , parameter and feature tuning.\nCollaborate with cross functional partners including data engineers, analysts , product managers and business stakeholders to identify opportunities impacting business.\nIdentify and articulate areas where data science can help grow company via business operations and product improvements.\nCommunicate exposition of proposed models to technical and functional stakeholders.\nAssist data science team to build MLops workflows and models for predictive modeling & analytics.\nRequirements\n3+ years experience in machine learning with an advanced degree in computer science or equivalent.\nProgramming experience in Python / Scala / Java or equivalent.\nWorking knowledge of machine learning best practices ( e.g. A/B test, feature engineering, feature/model selection), algorithms ( e.g. gradient boosted trees, deep learning / neural networks , optimization and NLP) and domains ( e.g. natural language processing, anomaly detection, personalization and recommendation).\nExperience in technologies such as TensorFlow or SageMaker.\nExperience in building end-2-end ML infrastructure and/or building and productionizing ML models.\nFluent in English: verbal and written.\nWe're Also Looking For\nSelf-motivated and self-managing, with organizational skills\nGreat communication: Regularly achieve consensus amongst technical and business teams\nDemonstrated capacity to communicate complex business activities, technical requirements, and recommendations clearly and concisely\nAbility to thrive in a distributed organization.\nHands-on experience in data engineering technologies such as Airflow, Kafka, Spark, Kubernetes and data warehouse ( Redshift/Snowflake).\nSaaS industry experience will be a huge plus.\nPhD in Computer Science , Machine Learning, Statistics or related field.\nWhat Dashlane Offers You\nEqual Parental leave - regardless of gender, up to 20 weeks fully paid leave to take care of their new baby, within the first year of birth or adoption\nHealth insurance covered by Dashlane\nMentorship program - select your mentor from our internal pool and continue your learning path!\nCommute allowance\nMeal Vouchers (Swile)\nMental health services through Spring Health for you and family members\n4 extra days off (one per quarter) to acknowledge the importance of your wellbeing\nSpot in daycare\nTime off saving account\nReimbursement of half of your commuting costs\nDonation matching program - give back to the community and support actions that lead to positive social impact under the historically marginalized communities. Every donation will be matched by Dashlane\nTeam buildings & seasonal social events\nWeekly lunch in the office and monthly happy hour\nand many more\nDiversity, Equity, Inclusion And Belonging At Dashlane\nAs a truly international company‚Äîfounded in France and distributed across France, US and Portugal‚ÄîDashlane thrives off diverse perspectives. We value all aspects of diversity: gender identity, sexual orientation, ability, ethnic origin, social background, age, lifestyle, and more. We are committed to hiring a diverse community and fostering a culture where everyone is heard and belongs. See more about this here .\nYour Interview Experience\nTo know what to expect once you‚Äôve sent your application, read about how we interview and hire at Dashlane . Feel free to browse our blog to find more information about our product and how we work.\nShow more\nShow less",
        "details": {
            "JobDetail": [
                "Full"
            ],
            "TypeContract": "",
            "Salary": "",
            "Level": "",
            "Experience": null
        },
        "title": "machine learning engineer",
        "skills": {
            "ProgLanguage": [
                "Java",
                "Scala",
                "Python"
            ],
            "DataBase": [
                "Elasticsearch"
            ],
            "BigData": [
                "Spark"
            ],
            "MachineLearning": [
                "TensorFlow"
            ],
            "DataVisualisation": [
                "Tableau"
            ],
            "CloudComputing": [
                "AWS"
            ],
            "DBMS": [
                "Snowflake",
                "MySQL"
            ],
            "Automation": [
                "Airflow",
                "Kubernetes"
            ],
            "InfrastructureAsCode": [
                "Terraform"
            ],
            "Containers": [
                "Kubernetes"
            ],
            "Collaboration": [
                "Slack",
                "Teams",
                "Confluence"
            ],
            "Other": [
                "Machine Learning",
                "ML",
                "CI/CD"
            ],
            "EnSoftSkils": [
                "Communication",
                "Organization",
                "Collaboration"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "PROXIAD",
        "location": "Nantes",
        "link": "https://fr.linkedin.com/jobs/view/ing%C3%A9nieur-machine-learning-at-proxiad-3862361161?position=59&pageNum=0&refId=SmRHYtKKcb%2BBbb%2BiSm10Sw%3D%3D&trackingId=e28JDxvPrvCJiUjmrRFPgg%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Proxiad Ouest est √† la recherche d‚Äôun\nnouveau talent\npour compl√©ter son √©quipe !\nQui sommes-nous ?\nAvec une √©coute attentive et un\nsuivi r√©gulier\nde ses collaborateurs, une\nbonne ambiance\net des\npetits d√©jeuner\n√† la cl√©, Proxiad est une ESN qui porte une attention toute particuli√®re au\nbien-√™tre\nde ses collaborateurs.\nSp√©cialis√© dans le Conseil et l‚ÄôExpertise aupr√®s de ses clients, le groupe Proxiad compte aujourd‚Äôhui plus de 1250 collaborateurs en France. Intervenant dans diff√©rents secteurs d‚Äôactivit√© : assurances, banques, sant√©, t√©l√©coms, industries, ‚Ä¶ Proxiad propose des projets innovant afin de d√©velopper au mieux les comp√©tences techniques de ses collaborateurs.\nQuelle sera votre mission ?\nSi vous l‚Äôacceptez, elle consistera √† occuper le r√¥le\nd'ing√©nieur machine learning (H/F)\npour l‚Äôun de nos clients. Le poste est bas√© √†\nNantes (44)\n.\nVos missions :\n- Pr√©parer les donn√©es mises √† disposition par les Data Engineers\n- Optimiser sur le plan informatique les mod√®les mis √† disposition par les Data Scientists\n- Concevoir la cha√Æne de traitement pour industrialiser des traitements\n- Assurer le maintien op√©rationnel et la p√©rennit√© des performances des mod√®les d√©ploy√©s\n- Produire la documentation (bonne pratiques, ‚Ä¶)\n- Proposer/D√©velopper des librairies internes\n- Participer aux expressions de besoins et qualification des produits et solutions mis √† disposition par les Data Architects\nEnvironnement technique\n: Python, VSCode, Jupyterlab, Docker/Kubernetes, SQL/Vertica, sklearn/xgboost/lightgbm‚Ä¶\nVotre profil :\nVous justifiez d‚Äôune exp√©rience minimum de 3 ans dans le domaine du machine learning et d√©veloppement python en production.\nVous avez des connaissances sur les frameworks de machine learning (comme scikit-learn, xgboost, lightgbm, pandas‚Ä¶).\nVous avez une exp√©rience en programmation avanc√©e / orient√©e objet avec Python.\nVous √™tes familier avec les outils de d√©veloppement Jupyter et IDE comme VSCode\nVous avez des comp√©tences en ing√©nierie logicielle (GIT, CI/CD‚Ä¶), et architecture applicative (design pattern‚Ä¶).\nShow more\nShow less",
        "details": {
            "JobDetail": [],
            "TypeContract": "",
            "Salary": "",
            "Level": "",
            "Experience": "3 an(s)"
        },
        "title": "Other",
        "skills": {
            "ProgLanguage": [
                "Python"
            ],
            "DataBase": [
                "SQL"
            ],
            "DataAnalytics": [
                "Pandas"
            ],
            "MachineLearning": [
                "Scikit-Learn",
                "LightGBM",
                "XGBoost"
            ],
            "DevTools": [
                "Git",
                "Docker"
            ],
            "Automation": [
                "Kubernetes"
            ],
            "Containers": [
                "Docker",
                "Kubernetes"
            ],
            "Other": [
                "Machine Learning",
                "CI/CD"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "Astek",
        "location": "Paris, √éle-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/ing%C3%A9nieur-machine-learning-%E2%80%93-paris-france-h-f-at-astek-3882492554?position=60&pageNum=0&refId=SmRHYtKKcb%2BBbb%2BiSm10Sw%3D%3D&trackingId=MrLSe%2FEDqyCRD28jFxFVBg%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "CDI\nParis - France\nPubli√©e il y a 1 mois\nLe Groupe Astek\nCe Que Nous Allons Accomplir Ensemble :\nRejoignez nos √©quipes et intervenons ensemble sur les projets de nos partenaires autour des enheux d‚Äôinnovation.\nVotre Mission, Si Vous L‚Äôacceptez :\nCadrer techniquement les projets et accompagner les Data Scientists dans la construction des mod√®les en veillant √† respecter les bonnes pratiques d‚Äôing√©nierie logicielle.\nMettre en place la d√©marche ML OPS\nD√©ployer les mod√®les en production en respectant des contraintes de co√ªts, pr√©cisions et performances techniques.\nImpl√©menter les outils permettant de monitorer ces mod√®les en production\nVous ?\nVous √™tes issu(e) d‚Äôune formation Bac+5 (√âcole d‚Äôing√©nieur, Universit√© ou √©quivalent ‚Ä¶) en informatique\nVous justifiez d‚Äôune exp√©rience significative d‚Äôau moins 5 ans au sein d‚Äôune √©quipe dans un environnement Data √† l‚Äô√©chelle du SI d‚Äôun grand groupe\nVous √™tes un bon communiquant et disposez de capacit√©s d‚Äôanalyse et de synth√®se √©prouv√©es\nVous accordez de l‚Äôimportance √† la veille technologique\nComp√©tences Techniques :\nExpertise en SPARK et PySpark\nConnaissance de Kubernetes\nConnaissance de d‚ÄôApache Kafka\nUne exp√©rience sur un cloud provider public comme Azure (id√©alement), AWS, ou GCP\nExpertise de d√©veloppement en Python\nExpertise du ML OPS\nComp√©tences Transverses :\nCapacit√© √† interagir avec des parties prenantes diverses : Data Scientists, Business analyst, Architectes, M√©tier\nForte exp√©rience en mode de Delivery Agile (Scrum, Kanban, etc.‚Ä¶)\nEtre expert dans les pratiques du Software Craftsmanship (Test Driven, Development, Behavior Driven Development, Clean Code, Code Reviews, etc.)\nEt :\nDes Connaissances sur Azure DevOps, Azure Pipeline, GIT\nMaitrise des Traitements Big Data en mode Streaming\nMaitrise des Bases de donn√©es relationnelles et NoSQL\nUne exp√©rience professionnelle avec des outils comme Azure Databricks, Azure, Machine Learning , Azure Data Lake Storage ou encore Azure Data Factory\nLe Groupe Astek\nCr√©√© en France en 1988, Astek est un acteur mondial de l‚Äôing√©nierie et du conseil en technologies. Fort de son expertise dans de nombreux secteurs industriels et tertiaires, Astek accompagne ses clients internationaux dans le d√©ploiement intelligent de leurs produits et de leurs services, et dans la mise en ≈ìuvre de leur transformation digitale.\nDepuis sa cr√©ation, le Groupe a fond√© son d√©veloppement sur une forte culture d‚Äôentrepreneuriat et d‚Äôinnovation, et sur l‚Äôaccompagnement et la mont√©e en comp√©tence de\nses 7800 collaborateurs\nqui s‚Äôengagent chaque jour √† promouvoir la compl√©mentarit√© entre les technologies num√©riques et l‚Äôing√©nierie des syst√®mes complexes.\nRejoignez un Groupe en fort d√©veloppement en France et √† travers le monde ayant r√©alis√© un chiffre d‚Äôaffaires de 600 M‚Ç¨ en 2023.\nTous les d√©tails sur le Groupe sur le site https://astekgroup.fr. Et vous pouvez aussi nous suivre sur notre blog : https://blog.groupeastek.com.\nRencontrons-nous\nNotre projet commun vous plait ?\nPostulez √† cette annonce, et soyez transparent !\nNotre Talent Acquisition Officer, vous contactera pour un premier √©change t√©l√©phonique.\nPuis vous rencontrerez votre futur manager, avec lequel vous √©changerez autour d‚ÄôAstek, de votre parcours, de vos attentes et de votre future mission .\nEnfin, vous rencontrerez notre Directeur de d√©partement, avec lequel vous pourrez valider votre int√©r√™t et ad√©quation pour le poste et finaliser les √©l√©ments contractuels.\nNos Plus\nAstek est green et fait b√©n√©ficier ses salari√©s d‚Äôune indemnit√© kilom√©trique v√©lo\nUne politique CARE sur-mesure d√©ploy√©e par nos √©quipes RH pour nos collaborateurs (https://astekgroup.fr/engagements)\nNotre charte de la Diversit√©\nBienvenue dans la team ! Allez-y, maintenant c‚Äôest √† vous de jouer !\nMots-cl√©s :\ning√©nieur ‚Äì ing√©nieure ‚Äì consultant ‚Äì consultante\nCaract√©ristiques de l'emploi\nCat√©gorie Chef de Projet\nJob Industry A√©rospatial / D√©fense / S√©curit√©, Distribution / Services Internet, Energie / Sciences de la Vie / Autres industries, Finance / Gouvernement, T√©l√©com / M√©dia, Transports Terrestres\nPostuler en ligne\nNom *\nPr√©nom *\nEmail *\nUn email valide est requis.\nT√©l√©phone *\nUn num√©ro de t√©l√©phone valide est requis.\nJoindre un CV *\nMots-cl√©s :\ning√©nieur ‚Äì ing√©nieure ‚Äì consultant ‚Äì consultante\nShow more\nShow less",
        "details": {
            "JobDetail": [],
            "TypeContract": "CDI",
            "Salary": "",
            "Level": "Bac+5",
            "Experience": "5 an(s)"
        },
        "title": "Other",
        "skills": {
            "ProgLanguage": [
                "Python"
            ],
            "DataBase": [
                "NoSQL"
            ],
            "BigData": [
                "Databricks",
                "Spark"
            ],
            "CloudComputing": [
                "GCP",
                "AWS",
                "Azure"
            ],
            "DevTools": [
                "Git"
            ],
            "SoftBigDataProcessing": [
                "Apache Kafka"
            ],
            "Automation": [
                "Chef",
                "Kubernetes"
            ],
            "Containers": [
                "Kubernetes"
            ],
            "Other": [
                "ML",
                "Big Data",
                "Machine Learning",
                "Cloud",
                "DevOps"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "VINCI Airports",
        "location": "Nanterre, √éle-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/data-scientist-f-m-at-vinci-airports-3888479165?position=1&pageNum=2&refId=EP75HsoD7J%2FCMwAPvjo3uA%3D%3D&trackingId=GIDan3Q6oj9tnUCI5Ovy5w%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Premier op√©rateur a√©roportuaire priv√© au monde,\nVINCI Airports\ng√®re plus de 70 a√©roports dans 13 pays en Europe, en Asie et sur le continent am√©ricain. Gr√¢ce √† son expertise d‚Äôint√©grateur global, VINCI Airports d√©veloppe, finance, construit et exploite les a√©roports en apportant sa capacit√© d‚Äôinvestissement et son savoir-faire dans l‚Äôoptimisation de la performance op√©rationnelle, la modernisation des infrastructures et la conduite de leur transition environnementale.\nNous recherchons actuellement\nun(e) Data Scientist (F/M)\nen CDI.\nRattach√©(e) au D√©partement Data de la Direction financi√®re de VINCI Airports, vous participerez, en coordination avec les √©quipes m√©tiers et appuy√©(e) par l‚Äô√©quipe d‚Äôing√©nieurs Data (si√®ge VINCI Airports et Pays), √† la mise en ≈ìuvre du projet ¬´ SMART DATA HUB ¬ª, un projet strat√©gique et passionnant, qui a pour vocation de fournir √† l‚Äôensemble des a√©roports du groupe la capacit√© √† mieux piloter la performance de l‚Äôactivit√© autour de la Data.\nPour ce faire vous serez amen√©(e) √† d√©velopper des solutions avanc√©es en Data Science, Mod√®les de Machine Learning, avec un accent particulier sur le traitement du langage naturel (NLP) dans le d√©partement Data de VINCI Airports pour les besoins de digitalisation et d‚Äôam√©lioration des processus de VINCI Airports.\nMissions :\nMod√©lisation et pr√©vision : Concevoir, d√©velopper et mettre en ≈ìuvre des mod√®les statistiques et algorithmiques. Utiliser des m√©thodes d'apprentissage automatique et d'intelligence artificielle (IA) pour cr√©er des mod√®les pr√©dictifs.\nAnalyse des donn√©es : Collecter, nettoyer et pr√©parer les donn√©es brutes en vue de leur analyse. Utiliser des techniques de visualisation et des outils statistiques pour explorer et comprendre les ensembles de donn√©es.\nExploitation des donn√©es : Identifier les opportunit√©s d'am√©lioration des processus et des performances en utilisant les donn√©es disponibles. Travailler en √©troite collaboration avec les √©quipes op√©rationnelles pour comprendre leurs besoins et proposer des solutions bas√©es sur les donn√©es.\nCommunication des r√©sultats : Pr√©senter les r√©sultats de l'analyse de mani√®re claire et compr√©hensible √† des publics non techniques. Collaborer avec des √©quipes multidisciplinaires pour fournir des recommandations bas√©es sur les donn√©es pour la prise de d√©cision strat√©gique.\nTravailler sur des projets impliquant des mod√®les de langage comme GPT d√©velopp√©s par Open AI ou Google (ou autres nouvelles solutions sur le march√©).\nParticiper √† des formations et des ateliers avec les analystes de VINCI Airports pour d√©velopper leurs comp√©tences techniques et m√©thodologiques gr√¢ce aux solutions Data science/NLP.\nL‚Äôensemble de ces actions seront √† entreprendre sur l‚Äôensemble des domaines m√©tiers de VINCI Airports : Trafic, commercial, op√©rations...\nEffectuer une veille constante sur les derni√®res avanc√©es en Data Science, LLM et NLP pour proposer des solutions innovantes et les int√©grer aux mod√®les d√©velopp√©s par l‚Äô√©quipe Data.\nLe profil que nous recherchons √† ce poste :\nDipl√¥me universitaire (Bac+5) en statistiques, math√©matiques, informatique, science des donn√©es, Intelligence Artificielle ou un domaine connexe.\nExp√©rience pratique dans l'analyse de donn√©es et l'utilisation d'outils d'analyse tels que Python, R, SAS, SQL,‚Ä¶\nBonne connaissance des techniques d'apprentissage automatique (machine learning), des algorithmes statistiques et de l'analyse pr√©dictive.\nConnaissance approfondie des concepts de Machine Learning et des biblioth√®ques telles que TensorFlow, PyTorch, Scikit-Learn.\nMotivation pour la recherche et la r√©solution de probl√®mes complexes.\nInt√©r√™t et exp√©rience en traitement du langage naturel (NLP), y compris la familiarit√© avec les mod√®les de langage comme GPT.\nCapacit√© √† travailler de mani√®re autonome et √† g√©rer efficacement les projets, tout en respectant les d√©lais impartis.\nComp√©tences en communication orale et √©crite pour pr√©senter des r√©sultats complexes de mani√®re claire et concise.\nCuriosit√© intellectuelle et passion pour l'exploration des donn√©es afin de d√©couvrir des informations cach√©es et de g√©n√©rer des id√©es novatrices.\nTravail en √©quipe.\nVous √™tes capable de converser en Anglais.\nShow more\nShow less",
        "details": {
            "JobDetail": [],
            "TypeContract": "CDI",
            "Salary": "",
            "Level": "Bac+5",
            "Experience": null
        },
        "title": "data scientist",
        "skills": {
            "ProgLanguage": [
                "R",
                "Python"
            ],
            "DataBase": [
                "SQL"
            ],
            "DataAnalytics": [
                "R"
            ],
            "MachineLearning": [
                "Scikit-Learn",
                "TensorFlow",
                "PyTorch"
            ],
            "Other": [
                "Statistiques",
                "Machine Learning"
            ],
            "EnSoftSkils": [
                "Communication",
                "Collaboration"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "Pathway",
        "location": "Paris, √éle-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/data-scientist-python-mid-senior-senior-at-pathway-3887683294?position=2&pageNum=2&refId=EP75HsoD7J%2FCMwAPvjo3uA%3D%3D&trackingId=JS8vijxhweKC0djTLhvQhQ%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "About Pathway\nDeeptech start-up, founded in March 2020.\nOur primary developer offering is an ultra-performant Data Processing Framework (unified streaming + batch) with a Python API, distributed Rust engine, and capabilities for data source integration & transformation at scale (Kafka, S3, databases/CDC,...)\nThe single-machine version is provided on a free-to-use license (`pip install pathway`)\nMajor data use cases are around event-stream data (including real-world data such as IoT), and graph data that changes over time\nOur enterprise offering is currently used by leaders of the logistics industry, such as DB Schenker or La Poste, and tested across multiple industries. Pathway has been featured in Gartner's market guide for Event Stream Processing\nLearn more at http://pathway.com/ and https://github.com/pathwaycom/\nPathway is VC-funded, with amazing BAs from the AI space and industry. We have operations across Europe and in the US. We are headquartered in Paris, with significant support from the French ecosystem (BPI, Agoranov, WILCO,...).\nThe Team\nPathway is built by and for overachievers. Its co-founders and employees have worked in the best AI labs in the world (Microsoft Research, Google Brain, ETH Zurich), worked at Google, and graduated from top universities (Polytechnique, ENSAE, Sciences Po, HEC Paris, PhD obtained at the age of 20, etc...). Pathway's CTO is a co-author with Goeff Hinton and Yoshua Bengio. The management team also includes the co-founder of Spoj.com (1M+ developer users) and NK.pl (13.5M+ users) and experienced growth leader who has scaled companies with multiple exits.\nThe opportunity\nWe are currently searching for\nData Scientists\nwith\nexperience in the Python stack\n, to help explore and discover the most pertinent insights in datasets on spatio-temporal event streams. In this job, statistical rigor and beauty of visualization meet on equal footing.\nYou Will\nbe working with spatiotemporal data with advanced schemas (time-changing graph models)/\nbe designing data cross-sections, proposing analytics metrics and KPI's in line with clients' objectives, selecting clustering algorithms, and preparing visualizations, to enable fast data exploration and insight discovery - all within our product\nbe designing dashboards in SQL with some Python elements/extensions\nbe directly helping us with Customer Conversion and Adoption within Customer organizations, by contributing to both deployment instances and \"demonstrators\" of our product, performed on client data sets\nwork directly with our Product Owner and CTO to propose and implement extensions to our product, based on repetitive client needs\ndepending on your seniority, implement machine learning algorithms on spatiotemporal event streams and other geospatial data\nThe results of your work will play a crucial role in proving how our technology can help with compelling industry use cases.\nRequirements\nYou Are\nReady for hands-on contribution to the product, helping to ensure the success of demonstrators for clients, and contribution to product codebase\nIntuitive, with good visual taste, and good common sense judgment\nCommitted to beautiful user-centered design: you know that stories are made for people, and you are willing to listen to what they have to say\nCurious at heart and thrilled to work with real-world data, especially spatio-temporal data\nLike trains, trucks, cranes, pythons, pandas, and other things that move\nNot afraid to switch between the roles of data scientist, data-vis magician, statistician, engineer, and detective, at a moment's notice\nHave 2 years+ experience in positions related to Data Science.\nHave a very good working knowledge of Python\nKnow SQL. Are able to work with tables and other data types (arrays, json,...)\nWould be able to implement the Transit Node Routing algorithm in Python just based on reading its Wikipedia article\nHave experience with git, build systems, and CI/CD\nHave at least basic undergrad textbook familiarity with graph algorithms, finite automata, and text (string) search algorithms\nUnderstand statistical concepts, such as correlated random variables, significance, and non-Gaussian noise\nPrepared to be quizzed & grilled by the datasets you encounter, everyday. Here are some questions you should be able to answer off the top of your head: what can \"-273.15\" signify; why \"65535\" is a suspicious integer value; how many months does it take a containership to go around the world; and, roughly what order of g-force is attained by an astronaut in a space rocket at liftoff?\nRespectful of others\nFluent in English\nBonus Points\nShowing a portfolio: code on github, visualization works, a research paper or a PhD thesis with an original statistical / probabilistic analysis or experiment design,..\nSuccessful track-record in Data Science or algorithms contests (Kaggle, Codeforces,...)\nExperience in topics linked to logistics/moving assets\nFamiliarity with some form of GIS software\nFamiliarity with Pandas, SciPy, NetworkX, and similar tools from the Python stack\nExperience in Data Visualization and UX\nSome knowledge of French, Polish, or German\nWhy You Should Apply\nJoin an intellectually stimulating work environment\nBe a pioneer: you get to work with a new type of data processing\nWork in one of the hottest data/AI startups in France\nUncover exciting career prospects\nMake significant contribution to our success\nJoin & co-create an inclusive workplace culture\nBenefits\nType of contract: Permanent employment contract\nPreferable joining date: February 2023. The positions (at least 2) are open until filled\nCompensation: annual salary of ‚Ç¨50K-‚Ç¨70K (mid) up to ‚Ç¨60K-‚Ç¨90K (senior, upper band negotiable) + Employee stock option plan\nLocation: Remote work from home. Possibility to work or meet with other team members in one of our offices:\nParis Area - Drahi X-Novation Center, Ecole Polytechnique, Palaiseau\nParis - Agoranov (where Doctolib, Alan, and Criteo were born) near Saint-Placide Metro (75006)\nWroclaw - University area\nPermanent residence will be required in France or Poland, exceptional candidates will be considered anywhere in the EU.\nIf you meet our broad requirements but are missing some experience, don't hesitate to reach out to us.\nNote\n: CS & engineering school students with exceptional profiles and/or strong motivation to join Pathway are invited to apply for Data Science internships. (Minimum duration: 5-6 months, remuneration level: ‚Ç¨1500 / month.)\nShow more\nShow less",
        "details": {
            "JobDetail": [
                "Remote",
                "Senior"
            ],
            "TypeContract": "",
            "Salary": "50K",
            "Level": "",
            "Experience": null
        },
        "title": "data scientist",
        "skills": {
            "ProgLanguage": [
                "Python"
            ],
            "DataBase": [
                "SQL"
            ],
            "DataAnalytics": [
                "Pandas"
            ],
            "DataSerialization": [
                "Json"
            ],
            "DevTools": [
                "Git"
            ],
            "Other": [
                "Machine Learning",
                "CI/CD"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "Unreal Staffing, Inc",
        "location": "Paris, √éle-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/data-scientist-at-unreal-staffing-inc-3913911173?position=3&pageNum=2&refId=EP75HsoD7J%2FCMwAPvjo3uA%3D%3D&trackingId=aN2ds7%2FHo9GQkvX15kCBxQ%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "About Us\nThe fashion industry contributes significantly to global greenhouse gas emissions. To address this, we developed a Carbon Management Platform tailored for the textile and fashion industry. We automate life-cycle assessment to help brands understand and reduce their environmental footprint.\nData At Our Company\nOur Data team manages customer data parsing and analytics. We clean and normalize customer data for accurate analysis and provide analytics on product-level environmental impacts.\nRequirements\nWhat You'll Be Working With\nInteresting data: Our data describes physical objects, such as shoes, t-shirts, and packaging boxes, enabling real insights into the environmental impact of products\nUnique opportunity: Apply your data science skills to reduce the environmental footprint of fashion companies\nWhat We're Looking For\nStrong communication skills\nExperience with heterogeneous data and basic NLP techniques\nProficiency in Python and SQL\nBasic software engineering skills\nBenefits\nRemote work in Europe\nCoworking space allowance up to ‚Ç¨300/month\nModern amenities including MacBook, headset, ChatGPT subscription, GitHub Copilot, etc\n100% health insurance coverage with Alan at the best coverage level\nOption to work from our office in Paris\nWork retreats organized 3 times a year\nTransparent compensation package with salary range ‚Ç¨60k - ‚Ç¨80k and significant equity\nOpportunities for promotion based on performance and impact on the company\nStrong belief in open-source software and contribution to the community\nShow more\nShow less",
        "details": {
            "JobDetail": [
                "Remote"
            ],
            "TypeContract": "",
            "Salary": "60k, 60k",
            "Level": "",
            "Experience": null
        },
        "title": "data scientist",
        "skills": {
            "ProgLanguage": [
                "Python"
            ],
            "DataBase": [
                "SQL"
            ],
            "EnSoftSkils": [
                "Communication"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "Astek",
        "location": "√éle-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/ing%C3%A9nieur-data-scientist-%E2%80%93intelligence-artificielle-idf-france-h-f-at-astek-3886897805?position=4&pageNum=2&refId=EP75HsoD7J%2FCMwAPvjo3uA%3D%3D&trackingId=T9CbOdjr1%2FTCt%2FANA%2F%2Bmvw%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Ce que nous allons accomplir ensemble :\nPour l‚Äôun de nos projets dans le domaine a√©ronautique, vous interviendrez en tant\nqu‚Äôing√©nieur Data scientist / Intelligence artificielle\nsur la mise en place de syst√®mes experts destin√©s aux avions civils et militaires.\nVotre future √©quipe :\nTeam IT de 12 personnes\nData scientist, ing√©nieurs syst√®mes, int√©grateurs, architectes\nVous travaillerez avec de v√©ritables passionn√©s !\nVotre mission (...si vous l‚Äôacceptez !) :\nVous participerez au d√©veloppement des fonctions d‚Äôanalyses multisyst√®mes. Pour cela vous assurerez l‚Äô√©tablissement d‚Äôune sp√©cification formelles sur les mod√®les d‚Äôanalyses.\nVous assurerez l‚Äôanalyse des donn√©es et la proposition de m√©thodes pour le traitement des signaux.\nVous d√©velopperez les outils capables de traiter de mani√®re automatique les donn√©es syst√®mes.\nVous assurerez la r√©alisation des sc√©narios, ainsi que les tests et simulations.\nVous r√©aliserez √©galement une activit√© de support.\nVotre stack de jeu :\nData scientist, python, principe de gestion de configuration, et tra√ßabilit√©, syst√®mes a√©ronautiques, intelligence artificielle\nLes petits plus du projet :\nVous √©voluerez au sein d‚Äô√©quipes agiles impliqu√©es et r√©actives.\nVous interviendrez de A √† Z sur des projets riches fonctionnellement et ambitieux techniquement :\nforte volum√©trie, haut niveau de performance, exigence maximale en termes d‚Äôintelligence artificielle et encore bien d'autres sujets captivants.\nVous ?\nDe formation Ing√©nieur, vous justifiez d‚Äôune exp√©rience significative en Data scientist et ou Intelligence artificielle.\nUne connaissance des m√©thodes d‚Äôanalyse de donn√©es serait un plus.\nId√©alement vous avez une connaissance des syst√®mes a√©ronautiques.\nDes postes √©galement ouverts aux d√©butants si stages significatifs.\nNous ?\nCr√©√© en France en 1988, Astek est un acteur mondial de l‚Äôing√©nierie et du conseil en technologies, pr√©sent sur les 5 continents. Fort de son expertise dans de nombreux secteurs industriels et tertiaires, Astek accompagne ses clients internationaux dans le d√©ploiement intelligent de leurs produits et de leurs services, et dans la mise en ≈ìuvre de leur transformation digitale.\nDepuis sa cr√©ation, le Groupe a fond√© son d√©veloppement sur une forte culture d‚Äôentrepreneuriat et d‚Äôinnovation, et sur l‚Äôaccompagnement et la mont√©e en comp√©tence de ses 5 200 collaborateurs qui s‚Äôengagent chaque jour √† promouvoir la compl√©mentarit√© entre les technologies num√©riques et l‚Äôing√©nierie des syst√®mes complexes.\nRejoignez un Groupe en fort d√©veloppement en France et √† travers le monde gr√¢ce √† une lev√©e de fonds de 200M‚Ç¨ r√©alis√©e en 2021. Ensemble ¬´ Let‚Äôs move forward! ¬ª\n‚ú® Tous les d√©tails sur le Groupe sur le site\nhttps://astekgroup.fr.\nEt vous pouvez aussi nous suivre sur\nnotre blog : https://blog.groupeastek.com\n.\nRencontrons-nous !\nVous vous √™tes reconnu sur l‚Äôannonce et Astek vous pla√Æt !\nPour en savoir plus sur vous, Franck , notre Talent Acquisition vous contacte. Puis, vous aurez 3 entretiens max, avec L√©onard (votre futur n+1), L√©onard notre Directeur !\nNos plus\nAstek est green et fait b√©n√©ficier ses salari√©s d‚Äôune indemnit√© kilom√©trique v√©lo\nUn programme CARE sur-mesure d√©ploy√© par nos √©quipes RH pour nos collaborateurs : https://astekgroup.fr/engagements\nNotre charte de la Diversit√©\nBienvenue dans la team ! Allez-y, maintenant c‚Äôest √† vous de jouer !\nShow more\nShow less",
        "details": {
            "JobDetail": [],
            "TypeContract": "",
            "Salary": "",
            "Level": "",
            "Experience": null
        },
        "title": "data engineer",
        "skills": {
            "ProgLanguage": [
                "Python"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "MP DATA",
        "location": "Clermont-Ferrand, Auvergne-Rh√¥ne-Alpes, France",
        "link": "https://fr.linkedin.com/jobs/view/data-scientist-h-f-at-mp-data-3904074177?position=5&pageNum=2&refId=EP75HsoD7J%2FCMwAPvjo3uA%3D%3D&trackingId=JmO80TlmFACnjldVL2r0%2Fg%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "MP DATA est une soci√©t√© sp√©cialis√©e dans l‚Äôacquisition, le traitement, et la valorisation des donn√©es. Depuis sa cr√©ation en 2015, MP DATA accompagne ses clients, majoritairement industriels, dans le management de leur performance et l‚Äôexploitation de leur donn√©e.\nLes collaborateurs, tous issus de grandes √©coles, incarnent au quotidien les valeurs d‚ÄôExcellence, de Partage et d‚ÄôEngagement. Ils associent savoir-faire technique, m√©thodologie et passion et mettent leurs comp√©tences au service de missions et projets au sein de grands groupes fran√ßais.\nMP DATA accompagne ses clients sur toute la chaine au travers de 3 p√¥les d‚Äôexpertise : Conseil et Strat√©gie, Infrastructure & CloudOPS, Data Science.\nNous recherchons un(e) Data Scientist passionn√©(e) pour rejoindre notre √©quipe dynamique.\nEn tant que membre cl√© du p√¥le Data Science de notre client, un grand acteur du secteur automobile, vous serez charg√©(e) d'analyser, interpr√©ter et exploiter les donn√©es pour fournir des solutions innovantes √† nos clients.\nConception et mise en ≈ìuvre de mod√®les pr√©dictifs et d'algorithmes avanc√©s.\nAnalyse approfondie des donn√©es pour identifier des tendances et des opportunit√©s.\nCollaboration √©troite avec les √©quipes clients pour comprendre leurs besoins et d√©finir des solutions sur mesure.\nParticipation active √† la veille technologique et √† l'am√©lioration continue de nos pratiques en Data Science.\nProfil :\nDipl√¥me\ning√©nieur Grande √âcole\nen Data Science, Statistiques, Informatique ou domaine connexe.\nExp√©rience pratique dans le d√©veloppement et l'application de mod√®les pr√©dictifs,\nMa√Ætrise des langages de programmation tels que Python,\nExcellentes comp√©tences analytiques et capacit√© √† traduire des r√©sultats complexes en recommandations claires,\nForte aptitude √† travailler en √©quipe et √† communiquer efficacement.\nShow more\nShow less",
        "details": {
            "JobDetail": [],
            "TypeContract": "",
            "Salary": "",
            "Level": "",
            "Experience": null
        },
        "title": "data scientist",
        "skills": {
            "ProgLanguage": [
                "Python"
            ],
            "Other": [
                "Statistiques"
            ],
            "EnSoftSkils": [
                "Collaboration"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "MindPal",
        "location": "Toulouse, Occitanie, France",
        "link": "https://fr.linkedin.com/jobs/view/machine-learning-developer-at-mindpal-3896992755?position=6&pageNum=2&refId=EP75HsoD7J%2FCMwAPvjo3uA%3D%3D&trackingId=dSuLbueg7nhVUePM1ioFmg%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "We are looking for\nMachine Learning Developer\nJob Responsibilities\nWorking on machine learning projects\nAnalyzing and processing data to create machine learning models\nImplementing and optimizing machine learning algorithms\nTesting and evaluating models\nCollaborating with the programming team and other departments within the company to develop innovative solutions\nRequirements\nMinimum 2 years of experience in the field of machine learning\nKnowledge of machine learning algorithms and techniques\nAbility to analyze and process data\nFamiliarity with machine learning tools and technologies\nProficient in English communication\nEducation in computer science\nWe Offer\nB2B contract type\nFull-time employment\nRemote and flexible working hours\nShow more\nShow less",
        "details": {
            "JobDetail": [
                "Remote",
                "Full"
            ],
            "TypeContract": "",
            "Salary": "",
            "Level": "",
            "Experience": null
        },
        "title": "Other",
        "skills": {
            "Other": [
                "Machine Learning"
            ],
            "EnSoftSkils": [
                "Communication"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "Enzo Tech Group",
        "location": "Paris, √éle-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/machine-learning-engineer-at-enzo-tech-group-3914687840?position=7&pageNum=2&refId=EP75HsoD7J%2FCMwAPvjo3uA%3D%3D&trackingId=taeGOOFAAyE6Y1yh6cUVsQ%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Position:\nMachine Learning Engineer / MLOps Engineer / AI Engineer\nLocation:\nParis\nType:\nFreelance, Contract\nDuration:\n6 months\nSearching for a\nMLOps Engineer\nto lead the implementation of\nMLOps\npractices at scale with a focus on\nlarge language models\n(LLM)\n.\nRole:\nLead the implementation of\nMLOps\npractices at scale, focusing on industrialising AI solutions and ensuring their efficient deployment.\nCollaborate with software engineering teams to integrate machine learning models into production environments.\nManage and optimise\nAI infrastructure\non\nAzure\n, including\nDatabricks\nclusters and other relevant technologies.\nDevelop and maintain automation pipelines for model training, testing, monitoring, and retraining.\nRequirements\nProven experience as an MLOps Engineer or similar role, with expertise in large-scale AI deployments.\nDeep understanding of MLOps principles, including model versioning\nExpertise and support to data scientists and engineers working on AI initiatives.\nCVs: s.allenby@enzotechgroup.com\nShow more\nShow less",
        "details": {
            "JobDetail": [],
            "TypeContract": "",
            "Salary": "",
            "Level": "",
            "Experience": null
        },
        "title": "machine learning engineer",
        "skills": {
            "BigData": [
                "Databricks"
            ],
            "CloudComputing": [
                "Azure"
            ],
            "Collaboration": [
                "Teams"
            ],
            "Other": [
                "Machine Learning"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "Mines Paris",
        "location": "Valbonne, Provence-Alpes-C√¥te d'Azur, France",
        "link": "https://fr.linkedin.com/jobs/view/data-scientist-m-w-at-mines-paris-3908686193?position=8&pageNum=2&refId=EP75HsoD7J%2FCMwAPvjo3uA%3D%3D&trackingId=3EHPfUaOaI4I96mXV%2FvRQQ%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "√Ä propos de nous\nMines Paris est une des plus prestigieuses √©coles d'ing√©nieurs en France. Mines Paris est un √©tablissement public qui forme des ing√©nieurs g√©n√©ralistes via une exp√©rience p√©dagogique innovante et pluridisciplinaire (sciences de l'ing√©nieur et sciences humaines et sociales). Son appartenance √† l'Universit√© PSL, qui se positionne dans le top 50 des classements internationaux, constitue une v√©ritable opportunit√© d'enrichissement des parcours.\nMission\nYour Environment\nAs part of the scientific program of The Transition Institute 1.5 (TTI.5), which focuses on the conditions for the emergence of a transition to a low-carbon planet, taking into account technical, social, economic, political and geopolitical issues, Mines Paris - PSL has an opening for a Data Scientist.\nInsofar as these issues may represent obstacles to the transition, it is essential to understand their fundamentals and decipher the mechanisms that drive them. The TTI.5 scientific program has been designed to harmonize, enhance and extend the various research projects already on offer at Mines Paris - PSL. It is also intended to provide new impetus in areas that have been little addressed until now, but which are nonetheless essential to steering the transition, or to filling gaps such as that of a complete vision of the distribution of resources worldwide.\nYour Challenges And Responsabilities\nIn order to tackle the various transition strategies, it is essential to have a picture of the production of the various raw materials needed for today's and tomorrow's world. At the same time, the exploitation and circulation of different resources can be strongly impacted by geopolitical conditions and times of tension and conflict.\nThe aim of this project, with its high methodological stakes, is to develop and couple:\nglobal resource mapping for two critical \"identifiable\" resources (lithium and cobalt)\na mapping of armed tensions (conflicts, installation of military bases, etc.).\nTo achieve this, we will need to develop a tool for extracting data from a very large mass of information, to be identified, in a changing context that will need to be taken into account for the tool's sustainability.\nThe Development Prospects For This Work Could Include\na double cartography animated over time ;\nthe enrichment of military base and tension indicators, with an equal focus on cases of local armed non-tension around the resource\na scalable database that can be continuously updated\na tool that can be replicated for other resources in a rapidly changing world\nProfil\nLet's talk about you !...\nThe position is aimed at an engineer / master data scientist with a degree from a university or Grande Ecole. Additional skills in GIS would be a plus. He/she may receive in-house training on mining resource issues.\nThe candidate will be strongly encouraged to participate in TTI.5 activities, and may also take part in those of the referral centers. He/she must have demonstrated good teamwork skills.\nFluency in spoken and written English is imperative.\nKnowledge And Skills\nThe main skills required for this post are :\nMastery of algorithms and programming languages (ability to write efficient, scalable code)\nMastery of data management language and databases (ability to find, collect and analyze large volumes of data)\nMastery of data visualization tools\nSoft Skills\nSelf-motivated\nSpirit of initiative\nSense of teamwork\ncreativity\nFlexibility\nCommunication and teaching skills\nAnalytical skills\nThoroughness\n‚Ä¶And about us ! Working at Mines Paris also means :\nJoining a prestigious institution with a rich history\nPlaying a part in the digital transition and the transition to carbon neutrality to tackle the climate emergency\nBelonging to PSL University, ranked 41st in the Academic Ranking of World Universities\nJoin a dynamic, multidisciplinary team!\nA pleasant living environment in a pine forest, at the heart of the 1st technology cluster on the C√¥te d'Azur and 1st technology park in Europe!\nR√©f√©rence de l'offre : 6jpx490r88\nShow more\nShow less",
        "details": {
            "JobDetail": [],
            "TypeContract": "",
            "Salary": "",
            "Level": "",
            "Experience": null
        },
        "title": "data scientist",
        "skills": {
            "EnSoftSkils": [
                "Teamwork",
                "Flexibility",
                "Creativity",
                "Initiative",
                "Communication"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "TNP Consultants",
        "location": "Paris, √éle-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/data-scientist-h-f-%E2%80%93-digital-factory-at-tnp-consultants-3591227915?position=9&pageNum=2&refId=EP75HsoD7J%2FCMwAPvjo3uA%3D%3D&trackingId=VJ57mM2q6YvdYXR84xw08A%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Pr√©sentation de TNP Consultants\nFort de 450 collaborateurs, TNP est un cabinet de conseil ind√©pendant multi-sp√©cialiste et multisectoriel, pr√©sent en France, au Maroc, au Luxembourg, en Suisse et en Inde. Acc√©l√©rateur de performance, nous intervenons dans la mise en place de programmes de transformation sur les probl√©matiques r√©glementaires, excellence op√©rationnelle, digital et business solutions dans les secteurs banque, assurance & protection sociale, le secteur public et industrie & services.\nCette ann√©e, TNP recrute 200 collaborateurs ! Pour accompagner nos clients dans le cadre de leur transformation digitale, nous recherchons des consultants Data Scientists (H/F).\nVOTRE R√îLE AU SEIN DE L‚Äô√âQUIPE DATA SCIENTIST\nAu Sein De La DIGITAL FACTORY, Vous Participerez Au D√©veloppement Des Activit√©s Data Science. Vous Serez Notamment En Charge\nD‚Äôaider nos clients √† d√©finir les use cases m√©tiers et proposer des d√©marches d‚Äô√©tudes adapt√©es aux contextes et aux enjeux m√©tiers ;\nDe mod√©liser des ph√©nom√®nes et restituer des analyses √† l‚Äôusage des m√©tiers (Data Visualisation) ;\nDe prototyper des outils d‚Äôanalyse ou de pr√©diction utilisables par les m√©tiers ;\nDe former et accompagner les m√©tiers dans l‚Äôutilisation de ces outils ;\nAccompagner des mont√©es en comp√©tences d‚Äôautres Data Scientists.\nDe mettre en production les mod√®les et Dashboard d√©velopp√©s dans un outil de cloud.\nVOTRE PROFIL\nVous √™tes dipl√¥m√©s d‚Äôune √©cole d‚Äôing√©nieur ou d‚Äôun master 2 en Math√©matiques, informatiques et/ou statistiques. Vous justifiez d‚Äôau moins 4 ann√©es d‚Äôexp√©rience au sein d‚Äôun cabinet de conseil.\nComp√©tences techniques requises\nVous maitrisez la programmation en Python/R.\nVous avez un excellent niveau en statistique.\nVous avez des connaissances th√©oriques et pratiques dans la mod√©lisation en Machine Learning et Deep Learning (Mod√®les d‚Äôagr√©gation, R√©seaux de neurone)\nVous avez d√©j√† utilis√© au moins une solution cloud comme AWS /Azure.\nGestion des codes : Git, Bitbucket\nVous disposez d‚Äôun bon niveau d‚Äôanglais.\nSoft Skills\nPassionn√© par la data et l‚ÄôIA\nEsprit de synth√®se et d‚Äôanalyse\nRigoureux pour assurer une qualit√© de livrables et didactique pour pr√©senter les sujets aux m√©tiers\nSens de l‚Äô√©coute et de la communication\nSavoir travailler en √©quipe\nCurieux et cr√©atif\nUn √©tat d‚Äôesprit orient√© business et apport de valeur pour les √©quipes m√©tiers ;\nCoach√©(e) tout au long de votre carri√®re, vous b√©n√©ficierez d‚Äôune formation continue, pour enrichir votre expertise et accompagner votre d√©veloppement personnel. En √©troite collaboration avec les Associ√©s, vous √©voluerez dans un cabinet ind√©pendant en forte croissance et intervenant aupr√®s des grands comptes en France et √† l‚Äôinternational.\nShow more\nShow less",
        "details": {
            "JobDetail": [],
            "TypeContract": "",
            "Salary": "",
            "Level": "",
            "Experience": null
        },
        "title": "data scientist",
        "skills": {
            "ProgLanguage": [
                "R",
                "Python"
            ],
            "DataAnalytics": [
                "R"
            ],
            "CloudComputing": [
                "AWS",
                "Azure"
            ],
            "DevTools": [
                "Git"
            ],
            "Other": [
                "Statistiques",
                "Machine Learning",
                "Cloud"
            ],
            "EnSoftSkils": [
                "Communication",
                "Collaboration"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "Keley Consulting",
        "location": "Paris",
        "link": "https://fr.linkedin.com/jobs/view/data-scientist-at-keley-consulting-3908861590?position=10&pageNum=2&refId=EP75HsoD7J%2FCMwAPvjo3uA%3D%3D&trackingId=NLxIpGcd8aJAnK0rclhdSQ%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Data Scientist F/H\nDescription de l'offre d'emploi\nAu sein de la practice data, vous accompagnerez nos clients dans la gestion, l‚Äôanalyse et l‚Äôexploitation de leur donn√©es notamment gr√¢ce au d√©veloppement de mod√®les IA et la mise en production de ceux-ci.\nResponsabilit√©s\nVous interviendrez dans des secteurs vari√©s sur des probl√©matiques telles que :\nEvaluer les solutions technologiques li√©es √† la data en effectuant des benchmarks\nCollecter, traiter et analyser des donn√©es volumineuses\nCommuniquer efficacement les r√©sultats des analyses\nCr√©er de la valeur √† partir des donn√©es en utilisant l‚Äôintelligence artificielle et la Data Science\nTravailler en √©troite collaboration avec les m√©tiers afin de comprendre leurs besoins et les impliquer dans le d√©veloppement des outils IA\nD√©ployer les outils d√©velopp√©s en environnement de prod (MLOps)\nA titre d‚Äôexemple, nous avons r√©cemment men√© les missions suivantes :\nD√©veloppement d‚Äôoutils d‚Äôoptimisation des revenus pour le compte d‚Äôune compagnie a√©rienne\nEtude de l‚Äôimpact du traitement de plaintes sur la customer lifetime value\nIndustrialisation de proof-of-concepts (ML Ops)\nD√©veloppement de GPTMaker, un outil de cr√©ation de chatbot s‚Äôappuyant sur des LLM\nProfil recherch√©\nDipl√¥me Bac+5 type √©cole d‚Äôing√©nieur ou universit√© en Data Science / Statistiques\nExp√©rience de 2 √† 5 ans en Data, avec au moins 1 an en tant que Data Scientist / Engineer\nMa√Ætrise des m√©thodes statistiques et leurs applications op√©rationnelles, ainsi que Python/Spark\nForte capacit√© d‚Äôorganisation, d‚Äôanalyse, d‚Äô√©coute et de communication tout en √©tant force de conviction\nAnglais courant\nQualifications suppl√©mentaires (atouts) :\nExp√©rience avec les outils du cloud (GCP, Azure, AWS ‚Ä¶)\nExp√©rience dans le NLP (natural language processing)\nPourquoi rejoindre Keley ?\nKeley est un cabinet de conseil √† taille humaine.\nAcc√©l√©rateur de projet, nous accompagnons nos clients sur des programmes de transformation digitale & Data en apportant sens et performance. Autour de m√©thodologies produits issues du design et orient√©es r√©sultat, nous cocr√©ons avec nos clients en les accompagnant dans toutes les √©tapes de leurs projets, jusqu‚Äô√† l‚Äôautonomie.\nParce que les Humains sont au c≈ìur de la transformation digitale des entreprises, celle-ci est aussi culturelle : nous alignons strat√©gie produit, culture m√©tiers et mod√®les op√©rationnels pour concevoir avec nos clients des solutions qui leur ressemblent et qui font le succ√®s de leurs projets.\nNos valeurs\nPassionn√©s par notre m√©tier, nous sommes des consultants en transformation digitale avec un sens aigu de l‚Äôengagement et du partage.\nDans un esprit coop√©ratif et chaleureux, chaque collaborateur pourra trouver sa place, √©voluer au c≈ìur de nos m√©tiers et atteindre ses objectifs gr√¢ce √† des parcours de carri√®re √©volutifs, clairs et transparents.\nNous croyons en la valeur de la diversit√© et de l'inclusion et encourageons les candidats de tous horizons √† postuler.\nKeley vous propose une carri√®re passionnante dans un environnement stimulant, en vous permettant de travailler avec des grands comptes et sur des missions vari√©es.\nPour vous offrir le meilleur environnement de travail possible, nous vous proposons :\nUn parcours de carri√®re clair et partag√© pour √©voluer rapidement au sein du cabinet\nUne politique de r√©mun√©ration transparente et √©quitable\nUne charte de t√©l√©travail\nDes bureaux au c≈ìur de Paris dans le 8√®me arrondissement\nDes mentors et des buddys √† l‚Äô√©coute\nDes √©v√®nements de team building r√©guliers\nUne direction et un management toujours disponibles pour √©changer (organisation flat)\nUn programme de formation adapt√© √† vos besoins et incluant des formations externes certifiantes\nDes m√©thodes et outils de partage de connaissance pour vous nourrir mais aussi vous offrir une tribune : conf√©rences internes hebdomadaires, articles, livres blancs, enqu√™tes et contenus vid√©o\nUn MacBook car on aime les belles choses (surtout quand elles marchent bien)\nUne carte tickets restaurants\nUne prise en charge de la mutuelle √† 100%\nUne prime de vacances\nShow more\nShow less",
        "details": {
            "JobDetail": [],
            "TypeContract": "",
            "Salary": "",
            "Level": "Bac+5",
            "Experience": "5 an(s)"
        },
        "title": "data scientist",
        "skills": {
            "ProgLanguage": [
                "Python"
            ],
            "BigData": [
                "Spark"
            ],
            "CloudComputing": [
                "GCP",
                "AWS",
                "Azure"
            ],
            "Other": [
                "Statistiques",
                "Cloud",
                "ML"
            ],
            "EnSoftSkils": [
                "Communication",
                "Collaboration"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "Acelys Services Num√©riques",
        "location": "Montpellier, Occitanie, France",
        "link": "https://fr.linkedin.com/jobs/view/data-scientist-traitement-du-langage-naturel-h-f-h-f-at-acelys-services-num%C3%A9riques-3906686343?position=1&pageNum=5&refId=JWyc74GSCq5ssJut%2FSE56g%3D%3D&trackingId=wed6ZTo9z%2BuZ9Ga87IfXPQ%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Cette offre d‚Äôemploi est fournie par P√¥le emploi\nDescription\nCr√©√©e en 1997, Acelys Services Num√©riques est la 1√®re DFS (Digital Factory Services) de la R√©gion qui propose √† ses clients des services industrialis√©s de d√©veloppement et d'int√©gration √† haute valeur ajout√©e de solutions num√©riques. En particulier sur les domaines : - Du d√©veloppement logiciel & mobile ; - De la Business Intelligence & la Data Science ; - De l'int√©gration des solutions de d√©mat√©rialisation ; - De la cybers√©curit√© et des infrastructures - De l'innovation R&D et l'√©dition de logiciels. Depuis 2017, Acelys confirme sa ma√Ætrise de la s√©curit√© de son syst√®me de management de la s√©curit√© de l'information avec la certification ISO 27001 ! Bas√© √† Montpellier, au sein du dynamique P√¥le Eureka, notre centre abrite pr√®s de 70% de nos collaborateurs. Notre histoire solide, notre ind√©pendance, et notre pr√©sence r√©gionale font de nous un pilier de l'innovation num√©rique ! Avec une √©quipe de plus de 200 professionnels passionn√©s, Acelys favorise la croissance et le d√©veloppement de chacun. Nous encourageons la promotion interne et offrons un environnement propice √† l'acquisition de nouvelles comp√©tences. Rejoignez-nous d√®s aujourd'hui pour faire partie d'une √©quipe dynamique et contribuer √† fa√ßonner l'avenir num√©rique avec nous ! Description du poste : Acelys recherche un.e Data Scientist exp√©riment√© en IA et NLP pour rejoindre notre √©quipe dynamique au sein du p√¥le de R&D/IA d'une quinzaine de talents. Notre p√¥le R&D, expert dans le traitement du langage naturel (p√¥le Edition) m√®ne depuis 10 ans des travaux en √©troite collaboration avec des laboratoires de recherche sur des probl√©matiques technologiques. Vous travaillerez en lien avec les chercheurs, ing√©nieurs et autres experts en utilisant des techniques d'apprentissage automatique et de traitement du langage naturel pour r√©soudre des probl√®mes complexes, tels que la recherche documentaire, la similarit√© s√©mantique, la classification... Profil recherch√© : - Vous √™tes dipl√¥m√©.e en informatique, en sciences des donn√©es ou dans un domaine connexe - Vous disposez de solides comp√©tences en programmation (Python, TensorFlow, PyTorch, etc.) - Vous avez connaissance des techniques d'apprentissage automatique et du traitement automatique du langage naturel - Vous √™tes exp√©riment√©.e sur les pratiques CI/CD (int√©gration continue et d√©ploiement continu) - Une exp√©rience sur les Frameworks Python est appr√©ci√©e : Langchain, Django/Flask,Transformers Avantages : - Salaire comp√©titif et avantages sociaux : Carte Swile, pr√©voyance Cadre, RTT, Plan Epargne Entreprise avec abondements, t√©l√©travail et un accord de participation tr√®s avantageux (1,5 mois de salaire ces derni√®res ann√©es en moyenne) - Environnement de travail collaboratif et stimulant - Contribution √† des projets innovants Acelys Services Num√©riques c'est plus de 25 ans d'histoire, √©crivons la suite ensemble !\nPROFIL SOUHAIT√â\nExp√©rience\n18 Mois\nSavoirs et savoir-faire\nAdapter les outils de traitement statistique de donn√©es\nD√©finir et faire √©voluer des proc√©d√©s de traitement de l'information\nPr√©senter et diffuser les r√©sultats des √©tudes r√©alis√©es\nR√©aliser une veille documentaire\nR√©diger l'information produite\nSavoir-√™tre professionnels\nFaire preuve de rigueur et de pr√©cision\nPrendre des initiatives et √™tre force de proposition\nTravailler en √©quipe\nSource: Pole emploi (https://www.pole-emploi.fr)\nShow more\nShow less",
        "details": {
            "JobDetail": [],
            "TypeContract": "",
            "Salary": "1,5",
            "Level": "",
            "Experience": "10 an(s)"
        },
        "title": "data scientist",
        "skills": {
            "ProgLanguage": [
                "R",
                "Python"
            ],
            "DataAnalytics": [
                "R"
            ],
            "MachineLearning": [
                "PyTorch",
                "TensorFlow"
            ],
            "Other": [
                "CI/CD"
            ],
            "EnSoftSkils": [
                "Collaboration"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "Talan",
        "location": "Paris, √éle-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/data-scientist-confirm%C3%A9-s%C3%A9nior-h-f-cdi-at-talan-3909648101?position=2&pageNum=5&refId=JWyc74GSCq5ssJut%2FSE56g%3D%3D&trackingId=%2B7%2Fgr3LvwNL9OuSOTOab3g%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Talan est un groupe international de conseil en transformation et en innovation par la technologie, cr√©√© en 2002.\nNos 5000 consultantes et consultants partagent √† travers le monde l‚Äôaudace d‚Äôinnover, le go√ªt de l‚Äôexcellence, et l‚Äôenvie de relever les d√©fis les plus complexes.\nNous accompagnons les entreprises dans des secteurs vari√©s‚ÄØ: √©nergie, industrie, transport, finance, luxe‚Ä¶ √† travers 3 grandes expertises‚ÄØ:\nLe Conseil en Management et Innovation (320 Consultants en France)\nLa valorisation des donn√©es, leurs structurations, et leurs usages (Data et Technologies)\nL‚Äôint√©gration de solutions logicielles (Cloud et Applications Services)\nNos valeurs‚ÄØ: engagement, respect, partage, esprit d‚Äô√©quipe et optimisme.\nTalan est une entreprise responsable, reconnue par ses collaborateurs et attach√©e √† la diversit√©. Des am√©nagements peuvent √™tre propos√©s si vous √™tes en situation de handicap.\nRetrouvez nos engagements RSEiciet nos actions en faveur de la diversit√©ici\nJob Description\nNous sommes √† la recherche d‚Äôun Data Scientist capable de participer √† des projets techniques Data Science et IA. Vous devrez faire preuve d‚Äôun √©tat d‚Äôesprit √† la fois innovant, m√©thodique, orient√© solution (et non probl√®me!), et communiquant.\nVotre but ultime sera de garantir l‚Äôexcellence de vos solutions Data Science/IA, pi√®ces maitresses de la r√©alisation de projets disruptifs pour nos clients.\nVOTRE ROLE SUR NOS PROJETS\n:\nEn mission: analyse des besoins m√©tiers, d√©finition des principes et m√©thodes de collecte et de traitement des donn√©es, choix des mod√®les de Machine Learning ou de Deep Learning, mise en application des techniques de traitement et de visualisation de la data, restitution des analyses et r√©sultats obtenus aupr√®s des m√©tiers et des sponsors\nPartager techniquement les membres de l‚Äô√©quipe: solutions et code reviews, recommandations, certifications √† r√©aliser, ‚Ä¶\nParticipation √† des meet-up, coding dogo,‚Ä¶\nCommunication: √©criture d‚Äôarticles, retours d‚Äôexp√©rience‚Ä¶\nVOTRE ROLE CHEZ TALAN :\nBenchmark de solutions et conseil aupr√®s de nos clients sur les solutions technologiques √† adopter, en lien avec leurs besoins\nR√©alisation de POC (Proof Of Concept)\nParticipation √† des projets internes et partage de connaissances au sein de nos √©quipes.\nPartage de connaissances et formations interne\nQualifications\nVOTRE PROFIL:\nIssu d‚Äôune formation Grande √âcole d‚ÄôIng√©nieur/Doctorant, sp√©cialis√©e en Data Science ou Intelligence Artificielle\nVous disposez d‚Äôau moins 3 ann√©es d‚Äôexp√©rience dans le domaine\nMaitrise des techniques d‚Äôanalyses statistiques, de mod√©lisations pr√©dictives, de Machine Learning, de Deep Learning,...\nMaitrise des techniques de data management et de DataViz\nMaitrise de Python, R, RShiny, SQL‚Ä¶\nMaitrise de l‚Äôutilisation des outils DevOps: Git, Docker, Jenkins/Nexus,‚Ä¶\nBonnes connaissances Big Data: pySpark, Spark, NoSQL‚Ä¶\nConnaissance d‚Äôoutils tels que Dataiku, AWS SageMaker, Azure ML,‚Ä¶\nAutonomie, organisation, sens du partage\nExcellente communication\nOrientation m√©tier\nAdditional Information\nAVANTAGES\n:\nPlan de formation pour accompagner votre carri√®re (formations √©diteurs, certifications) gr√¢ce √† nos partenariats nous accordant une position de partenaire privil√©gi√©, et management de proximit√© par des experts\nLocaux modernes en centre-ville\nTop 5 du Palmar√®s Great Place to Work\nT√©l√©travail jusqu‚Äô√† 5 jours selon les missions, prime d‚Äô√©quipement de 100‚Ç¨\nMobilit√© en France et √† l‚Äô√©tranger\nTop 1% des entreprises √©valu√©es par Ecovadis dans le domaine social, environnemental et √©thique\nTickets restaurant, prime vacances, 50% transport (abonnement transport public), mutuelle\nPermanence handicap (consultant d√©di√© aux collaborateurs en situation de handicap et aux proches aidants)\nActionnariat salari√©\nPrime de cooptations\nRTT\nPROCESS RECRUTEMENT\n:\nL‚Äô√©quipe recrutement s‚Äôengage √† vous proposer un processus de recrutement rapide et fluide\n1 entretien RHpar Teams (45min)\n1 test technique\n1 entretien op√©rationnel avec le responsable de domaine, au si√®ge (1heure)\n1 entretien avec le directeur de p√¥le, au si√®ge(1heure)\nShow more\nShow less",
        "details": {
            "JobDetail": [],
            "TypeContract": "",
            "Salary": "",
            "Level": "",
            "Experience": null
        },
        "title": "data scientist",
        "skills": {
            "ProgLanguage": [
                "R",
                "Python"
            ],
            "DataBase": [
                "SQL",
                "NoSQL"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [
                "Spark"
            ],
            "CloudComputing": [
                "AWS",
                "Azure"
            ],
            "DevTools": [
                "Git",
                "Docker",
                "Jenkins"
            ],
            "Containers": [
                "Docker"
            ],
            "Collaboration": [
                "Teams"
            ],
            "Other": [
                "ML",
                "Big Data",
                "Statistiques",
                "Machine Learning",
                "Cloud",
                "DevOps"
            ],
            "EnSoftSkils": [
                "Communication"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "Astek",
        "location": "Bordeaux, Nouvelle-Aquitaine, France",
        "link": "https://fr.linkedin.com/jobs/view/ing%C3%A9nieur-machine-learning-%E2%80%93-bordeaux-france-h-f-at-astek-3882494346?position=3&pageNum=5&refId=JWyc74GSCq5ssJut%2FSE56g%3D%3D&trackingId=a%2FYkkhioNa4Emmwch6rc2w%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "CDI\nBordeaux - France\nPubli√©e il y a 1 mois\nLe Groupe Astek\nCe Que Nous Allons Accomplir Ensemble :\nRejoignez nos √©quipes et intervenons ensemble sur les projets de nos partenaires autour des enheux d‚Äôinnovation.\nVotre Mission, Si Vous L‚Äôacceptez :\nCadrer techniquement les projets et accompagner les Data Scientists dans la construction des mod√®les en veillant √† respecter les bonnes pratiques d‚Äôing√©nierie logicielle.\nMettre en place la d√©marche ML OPS\nD√©ployer les mod√®les en production en respectant des contraintes de co√ªts, pr√©cisions et performances techniques.\nImpl√©menter les outils permettant de monitorer ces mod√®les en production\nVous ?\nVous √™tes issu(e) d‚Äôune formation Bac+5 (√âcole d‚Äôing√©nieur, Universit√© ou √©quivalent ‚Ä¶) en informatique\nVous justifiez d‚Äôune exp√©rience significative d‚Äôau moins 5 ans au sein d‚Äôune √©quipe dans un environnement Data √† l‚Äô√©chelle du SI d‚Äôun grand groupe\nVous √™tes un bon communiquant et disposez de capacit√©s d‚Äôanalyse et de synth√®se √©prouv√©es\nVous accordez de l‚Äôimportance √† la veille technologique\nComp√©tences Techniques :\nExpertise en SPARK et PySpark\nConnaissance de Kubernetes\nConnaissance de d‚ÄôApache Kafka\nUne exp√©rience sur un cloud provider public comme Azure (id√©alement), AWS, ou GCP\nExpertise de d√©veloppement en Python\nExpertise du ML OPS\nComp√©tences Transverses :\nCapacit√© √† interagir avec des parties prenantes diverses : Data Scientists, Business analyst, Architectes, M√©tier\nForte exp√©rience en mode de Delivery Agile (Scrum, Kanban, etc.‚Ä¶)\nEtre expert dans les pratiques du Software Craftsmanship (Test Driven, Development, Behavior Driven Development, Clean Code, Code Reviews, etc.)\nEt :\nDes Connaissances sur Azure DevOps, Azure Pipeline, GIT\nMaitrise des Traitements Big Data en mode Streaming\nMaitrise des Bases de donn√©es relationnelles et NoSQL\nUne exp√©rience professionnelle avec des outils comme Azure Databricks, Azure, Machine Learning , Azure Data Lake Storage ou encore Azure Data Factory\nLe Groupe Astek\nCr√©√© en France en 1988, Astek est un acteur mondial de l‚Äôing√©nierie et du conseil en technologies. Fort de son expertise dans de nombreux secteurs industriels et tertiaires, Astek accompagne ses clients internationaux dans le d√©ploiement intelligent de leurs produits et de leurs services, et dans la mise en ≈ìuvre de leur transformation digitale.\nDepuis sa cr√©ation, le Groupe a fond√© son d√©veloppement sur une forte culture d‚Äôentrepreneuriat et d‚Äôinnovation, et sur l‚Äôaccompagnement et la mont√©e en comp√©tence de\nses 7800 collaborateurs\nqui s‚Äôengagent chaque jour √† promouvoir la compl√©mentarit√© entre les technologies num√©riques et l‚Äôing√©nierie des syst√®mes complexes.\nRejoignez un Groupe en fort d√©veloppement en France et √† travers le monde ayant r√©alis√© un chiffre d‚Äôaffaires de 600 M‚Ç¨ en 2023.\nTous les d√©tails sur le Groupe sur le site https://astekgroup.fr. Et vous pouvez aussi nous suivre sur notre blog : https://blog.groupeastek.com.\nRencontrons-nous\nNotre projet commun vous plait ?\nPostulez √† cette annonce, et soyez transparent !\nNotre Talent Acquisition Officer, vous contactera pour un premier √©change t√©l√©phonique.\nPuis vous rencontrerez votre futur manager, avec lequel vous √©changerez autour d‚ÄôAstek, de votre parcours, de vos attentes et de votre future mission .\nEnfin, vous rencontrerez notre Directeur de d√©partement, avec lequel vous pourrez valider votre int√©r√™t et ad√©quation pour le poste et finaliser les √©l√©ments contractuels.\nNos Plus\nAstek est green et fait b√©n√©ficier ses salari√©s d‚Äôune indemnit√© kilom√©trique v√©lo\nUne politique CARE sur-mesure d√©ploy√©e par nos √©quipes RH pour nos collaborateurs (https://astekgroup.fr/engagements)\nNotre charte de la Diversit√©\nBienvenue dans la team ! Allez-y, maintenant c‚Äôest √† vous de jouer !\nMots-cl√©s :\ning√©nieur ‚Äì ing√©nieure ‚Äì consultant ‚Äì consultante\nCaract√©ristiques de l'emploi\nCat√©gorie Chef de Projet\nJob Industry A√©rospatial / D√©fense / S√©curit√©, Distribution / Services Internet, Energie / Sciences de la Vie / Autres industries, Finance / Gouvernement, T√©l√©com / M√©dia, Transports Terrestres\nPostuler en ligne\nNom *\nPr√©nom *\nEmail *\nUn email valide est requis.\nT√©l√©phone *\nUn num√©ro de t√©l√©phone valide est requis.\nJoindre un CV *\nMots-cl√©s :\ning√©nieur ‚Äì ing√©nieure ‚Äì consultant ‚Äì consultante\nShow more\nShow less",
        "details": {
            "JobDetail": [],
            "TypeContract": "CDI",
            "Salary": "",
            "Level": "Bac+5",
            "Experience": "5 an(s)"
        },
        "title": "Other",
        "skills": {
            "ProgLanguage": [
                "Python"
            ],
            "DataBase": [
                "NoSQL"
            ],
            "BigData": [
                "Databricks",
                "Spark"
            ],
            "CloudComputing": [
                "GCP",
                "AWS",
                "Azure"
            ],
            "DevTools": [
                "Git"
            ],
            "SoftBigDataProcessing": [
                "Apache Kafka"
            ],
            "Automation": [
                "Chef",
                "Kubernetes"
            ],
            "Containers": [
                "Kubernetes"
            ],
            "Other": [
                "ML",
                "Big Data",
                "Machine Learning",
                "Cloud",
                "DevOps"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "Licorne Society",
        "location": "Paris, √éle-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/front-end-software-engineer-at-licorne-society-3918084328?position=4&pageNum=5&refId=JWyc74GSCq5ssJut%2FSE56g%3D%3D&trackingId=XErRovUm3H2mMrCU%2FgjQfg%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Licorne Society a √©t√© missionn√© par une startup en pleine croissance pour les aider √† trouver leur Front-End Software Engineer\nCONTEXTE\nNous recherchons un D√©veloppeur Fullstack √† dominante Front End pour rejoindre notre √©quipe ambitieuse sur un projet technique complexe : une plateforme No-code B2B qui r√©invente la gestion des op√©rations au sein des entreprises, gr√¢ce √† l'IA.\nLes entreprises s‚Äôappuient sur notre plateforme de gestion int√©gr√©e pour orchestrer leurs processus, automatiser les t√¢ches r√©currentes et, √† terme, accro√Ætre leur performance op√©rationnelle.\nNous Disposons D'un Premier Produit Stable Et Nous Renfor√ßons Notre √âquipe Tech Pour Acc√©l√©rer Le D√©veloppement Du Produit, Elle Est Pour L'instant Compos√©e De\nMatthieu (CTO)\nHugo (Dev Fullstack)\nMatthieu notre CTO a l'habitude des exp√©riences entrepreneuriales et a notamment co-fond√© Tessan.\nDescription Du Poste\nEn tant que Dev Fullstack √† dominante Front-end, tu seras amen√©¬∑e √† :\nTravailler sur les d√©veloppements front-end et √™tre force de proposition concernant l'UI et UX du produit,\nD√©velopper de nouvelles fonctionnalit√©s sur le projet,\nParticiper √† la conception et l'am√©lioration des bonnes pratiques de d√©veloppement,\nAvoir la possibilit√© de toucher au backend si cela t'int√©resse.\nStack globale du projet : TypeScript, Angular, React, Nest, Node.js, MongoDB, AWS...\nPACKAGE\nPossibilit√© de travailler 1 jour par semaine en remote\nMutuelle d'entreprise\nTitre de transport\nR√©mun√©ration attractive\nPROFIL RECHERCH√â\nAujourd'hui, nous recherchons un profil r√©pondant aux crit√®res suivants :\nTu as d√©j√† connu plusieurs ann√©es (au moins 2-3 ans) d'exp√©rience professionnelle en d√©veloppement frontend,\nTu es une personne curieuse, proactive et autonome,\nTu appr√©cies l'UI et l'UX.\nLES PLUS DU POSTE\nDevenir l'une des premi√®res recrues d'une startup early et ambitieuse\nPossibilit√© de vivre une aventure depuis quasi le d√©but\nRemote possible\nDes locaux neufs dans Paris centre (3√®me)\nShow more\nShow less",
        "details": {
            "JobDetail": [
                "Remote",
                "Full"
            ],
            "TypeContract": "",
            "Salary": "1",
            "Level": "",
            "Experience": "3 an(s)"
        },
        "title": "software engineer",
        "skills": {
            "DataBase": [
                "MongoDB"
            ],
            "CloudComputing": [
                "AWS"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "BrainChip",
        "location": "Toulouse, Occitanie, France",
        "link": "https://fr.linkedin.com/jobs/view/software-engineer-at-brainchip-3902556694?position=5&pageNum=5&refId=JWyc74GSCq5ssJut%2FSE56g%3D%3D&trackingId=eW1k91WZlOSZ9ugdvNE7sg%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Brainchip is a leading technology company specializing in the design of electronics IP that accelerates AI on the edge. Our innovative solutions enable ultra-efficient and high-performance neural network processing for artificial intelligence applications. As part of our continuous growth, we are seeking a skilled Software Engineer with expertise in machine learning frameworks to join our team.\nResponsibilities:\nCollaborate with cross-functional teams to design, develop, and deploy machine learning models and algorithms for our products.\nImplement and optimize machine learning frameworks such as Tensorflow/Keras, PyTorch, and ONNX.\nDevelop software tools and infrastructure to support machine learning workflows, data preprocessing, model training, and evaluation.\nStay up-to-date with the latest advancements in machine learning and apply relevant techniques to enhance our products.\nConduct code reviews, provide constructive feedback, and maintain code quality and documentation.\nRequirements:\nBachelor's or Master's degree in Computer Science, Engineering, or a related field.\nStrong proficiency in machine learning frameworks such as Tensorflow/Keras, PyTorch, and ONNX.\nDemonstrated experience in developing and deploying machine learning models and algorithms.\nSolid understanding of deep learning concepts, neural networks, and related architectures.\nProficiency in programming languages such as Python, or C++.\nExperience with data preprocessing, feature engineering, and data visualization techniques.\nKnowledge of software engineering best practices, including version control, testing, and code documentation.\nStrong problem-solving skills and ability to work in a fast-paced, collaborative environment.\nExcellent communication skills and ability to effectively articulate technical concepts to both technical and non-technical team members.\nPreferred Qualifications:\nUnderstanding of computer vision or natural language processing (NLP) concepts and applications.\nExperience with deployment and optimization of machine learning models on edge devices.\nActive participation in the machine learning community, such as publications or open-source contributions.\nBenefits:\nCompetitive salary and comprehensive benefits package.\nOpportunities for professional growth and career advancement.\nCollaborative and inclusive work environment.\nFlexible work hours with the possibility to work remotely three days a week.\nAccess to cutting-edge technology and resources.\nShow more\nShow less",
        "details": {
            "JobDetail": [
                "Remote"
            ],
            "TypeContract": "",
            "Salary": "Salary, Package",
            "Level": "",
            "Experience": null
        },
        "title": "software engineer",
        "skills": {
            "ProgLanguage": [
                "Python"
            ],
            "MachineLearning": [
                "PyTorch",
                "TensorFlow",
                "Keras"
            ],
            "Collaboration": [
                "Teams"
            ],
            "Other": [
                "Machine Learning"
            ],
            "EnSoftSkils": [
                "Communication"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "EarthDaily Agro",
        "location": "Balma, Occitanie, France",
        "link": "https://fr.linkedin.com/jobs/view/geospatial-data-scientist-at-earthdaily-agro-3884744208?position=6&pageNum=5&refId=JWyc74GSCq5ssJut%2FSE56g%3D%3D&trackingId=r27RqGF2PKS2mcjCIit9sQ%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "STRUCTURE D‚ÄôACCUEIL\nEarthDaily Agro fournit des donn√©es et des analyses de l'√®re spatiale aux organisations et aux personnes qui nourrissent la plan√®te !\nAvec 35 ans d'exp√©rience dans le secteur, EarthDaily Agro fournit √† ses clients les donn√©es, les analyses et les connaissances dont ils ont besoin pour prendre des d√©cisions plus efficaces. Les services B2B vont de la gestion globale des risques et du suivi des produits agricoles √† la commercialisation d'intrants et au conseil en agriculture de pr√©cision, en utilisant les derni√®res recherches en agronomie, en technologies de l'information et en t√©l√©d√©tection.\nEarthDaily Agro d√©veloppe √©galement des solutions commerciales hautement personnalis√©es pour les pr√™teurs agricoles, les assureurs, les fournisseurs d'intrants et les entreprises alimentaires, avec des analyses faciles √† utiliser, qui aident √† r√©duire les risques quotidiens de l'agriculture.\nEarthDaily Agro, dont le si√®ge social se trouve √† Minneapolis, MN, USA, et qui poss√®de des bureaux en France, au Br√©sil, en Australie et en Suisse, est une division de EarthDaily Analytics Corp.\nEarthDaily Analytics Corp, une soci√©t√© de traitement et d'analyse de donn√©es verticalement int√©gr√©e, lance une nouvelle constellation de satellites d'observation de la terre. La constellation de satellites EarthDaily am√©liorera consid√©rablement les capacit√©s d'analyse g√©ospatiale dans les secteurs de l'agriculture, de la sylviculture, de l'environnement, des services financiers et du renseignement, parmi de nombreux autres segments.\nRESPONSABILIT√âS\nVous serez en charge de r√©soudre des challenges li√©s √† l‚Äôagriculture en utilisant la t√©l√©d√©tection, en particulier les images de la future constellation EarthDaily, et des donn√©es m√©t√©o. Bas√© √† Balma, √† proximit√© de Toulouse, vous int√©grerez une √©quipe internationale avec des coll√®gues au Br√©sil et aux USA.\nVOS RESPONSABILIT√âS INCLURONT :\nL‚Äôagriculture fait face √† des challenges sans‚ÄØpr√©c√©dent‚ÄØ: le changement climatique induit des risques accrus, et les agriculteurs doivent maintenir voire am√©liorer leur productivit√© tout en r√©duisant leur impact environnemental. Avec la future constellation EarthDaily (jusqu‚Äô√† 5 m de r√©solution, revisite quotidienne avec 22 bandes spectrales du visible √† l‚Äôinfra-rouge thermique), EarthDaily Agro disposera d‚Äôune technologie clef pour r√©pondre √† ces probl√©matiques.‚ÄØRejoignez EarthDaily Agro pour contribuer √† minimiser ces risques avec la technologie.\nEarthDaily Agro est √† la recherche d‚Äôun.e‚ÄØData‚ÄØScientist en t√©l√©d√©tection pour rejoindre‚ÄØson √©quipe R&D et construire des analytiques √† valeur ajout√©e √† destination de ses clients dans le monde agricole.\nVous mettez en place des solutions inventives pour r√©pondre aux probl√©matiques des clients, demandant des comp√©tences fortes en analyse de donn√©es et‚ÄØen‚ÄØmachine‚ÄØlearning, dans un‚ÄØcontexte‚ÄØde larges volumes de donn√©es et d‚Äôune base existante de plus de 100 analytiques. Vous d√©veloppez des‚ÄØPOCs‚ÄØet prototypes, d√©finissez / testez / validez et sp√©cifiez les algorithmes appropri√©s. Vous √™tes activement‚ÄØimpliqu√©.e‚ÄØdans le design et la mise en place de la solution op√©rationnelle sur notre plateforme Cloud.\nVos missions‚ÄØ:\nComprendre les probl√©matiques m√©tier et les traduire en solution algorithmique bas√©e sur les donn√©es issues de la t√©l√©d√©tection.\nCr√©er et‚ÄØimpl√©menter‚ÄØdes mod√®les bas√©s sur l‚Äô√©tat de l‚Äôart, pour extraire l‚Äôinformation pertinente d‚Äôun large volume de donn√©es\nCollaborer au sein d‚Äôune √©quipe Agile pluridisciplinaire et internationale de Data Scientists, Data Engineers et experts m√©tiers dans toutes les phases du projet‚ÄØ: de l‚Äôid√©ation √† l‚Äôindustrialisation et d√©ploiement op√©rationnel\nR√©diger des supports de pr√©sentation des r√©sultats, conditions d‚Äôutilisation, et‚ÄØd√©fendre‚ÄØla solution propos√©e par une approche pragmatique\n√ätre‚ÄØproactif(ve)‚ÄØpour alimenter le pipeline d‚Äôinnovation avec des nouvelles id√©es, contribuer √† d√©finir la roadmap R&D\nEDUCATION, CONNAISSANCES ET CAPACIT√âS\nMaster ou doctorat en Machine Learning / Math√©matiques appliqu√©es, t√©l√©d√©tection,‚ÄØou domaine associ√©\nAu moins 3 ans d‚Äôexp√©rience professionnelle, exp√©rience dans un domaine associ√© √† l‚Äôagriculture et en entreprise priv√©e appr√©ci√©e\nEtat d‚Äôesprit orient√© r√©sultats et pragmatique pour √©voluer dans un contexte de plannings serr√©s\nMa√Ætrise‚ÄØde‚ÄØPython, connaissance en SIG (QGIS,‚ÄØGDAL/OGR),\nLa connaissance‚ÄØdes biblioth√®ques de‚ÄØMachine‚ÄØLearning /‚ÄØDeep‚ÄØLearning (Scikit-learn, Pytorch, Tensorflow‚Ä¶), des outils de MLOps (ZenML, MLFlow), des syst√®mes de‚ÄØgestion de‚ÄØversion (git), de Docker, Kubernetes et du fonctionnement des workflows sur AWS (et Azure)‚ÄØest appr√©ci√©e\nFacilit√©s de communication pour le travail en √©quipe dans un contexte international\nAnglais courant‚ÄØ(oral‚ÄØet √©crit)‚ÄØ:‚ÄØl‚Äô√©quipe d‚Äôaccueil est internationale, les r√©unions internes se d√©roulent‚ÄØprincipalement‚ÄØen anglais.\nVous √™tes curieux(se)‚ÄØet cr√©atif(ve), collaboratif(ve)‚ÄØet adaptable‚ÄØ?‚ÄØRejoignez-nous‚ÄØ!\nCONDITIONS\nEmploi en CDI, d√©marrage d√®s que possible\nPoste‚ÄØbas√©‚ÄØ√† Balma, premi√®re couronne‚ÄØde Toulouse‚ÄØaccessible en transports en commun.‚ÄØPossibilit√© de t√©l√©travail partiel.\nPowered by JazzHR\nm5SHCur65r\nShow more\nShow less",
        "details": {
            "JobDetail": [],
            "TypeContract": "CDI",
            "Salary": "",
            "Level": "",
            "Experience": "35 an(s)"
        },
        "title": "data scientist",
        "skills": {
            "ProgLanguage": [
                "R",
                "Python"
            ],
            "DataAnalytics": [
                "R"
            ],
            "MachineLearning": [
                "Scikit-Learn",
                "TensorFlow",
                "PyTorch"
            ],
            "CloudComputing": [
                "AWS",
                "Azure"
            ],
            "DevTools": [
                "Git",
                "Docker"
            ],
            "Automation": [
                "Kubernetes"
            ],
            "Containers": [
                "Docker",
                "Kubernetes"
            ],
            "Other": [
                "Machine Learning",
                "Cloud"
            ],
            "EnSoftSkils": [
                "Communication"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "Enzo Tech Group",
        "location": "√éle-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/data-scientist-at-enzo-tech-group-3914681877?position=7&pageNum=5&refId=JWyc74GSCq5ssJut%2FSE56g%3D%3D&trackingId=o6k0uK%2BUxc%2Be7oyXo4ujew%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Role:\nData Scientist\nLocation:\nParis (3 days) / Remote (2 days)\nSearching for a\nData Scientist\npartnering with a global customer who are searching for multiple Data Scientist's as they continue to invest in designing and building high-quality AI solutions.\nResponsibilities\nAnalyze raw data: assessing quality, cleansing, structuring for downstream processing\nDesign accurate and scalable prediction algorithms\nCollaborate with engineering team to bring analytical prototypes to production\nGenerate actionable insights for business improvements\nQualifications\nBachelor's degree or equivalent experience in quantative field (Statistics, Mathematics, Computer Science, Engineering, etc.)\nTech Stack: GenAI, Databricks, Azure\nAt least 1 - 2 years' of experience in quantitative analytics or data modelling\nDeep understanding of predictive modelling, machine-learning, clustering and classification techniques, and algorithms\nFluency in a programming language (Python, C,C++, Java, SQL)\nCVs:\nApply via job post or directly\n@\nk.downs@enzotechgroup.com\nShow more\nShow less",
        "details": {
            "JobDetail": [
                "Remote"
            ],
            "TypeContract": "",
            "Salary": "",
            "Level": "",
            "Experience": null
        },
        "title": "data scientist",
        "skills": {
            "ProgLanguage": [
                "Java",
                "Python"
            ],
            "DataBase": [
                "SQL"
            ],
            "BigData": [
                "Databricks"
            ],
            "CloudComputing": [
                "Azure"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "Dashlane",
        "location": "Paris, √éle-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/machine-learning-engineer-at-dashlane-3903118945?position=8&pageNum=5&refId=JWyc74GSCq5ssJut%2FSE56g%3D%3D&trackingId=bNUuGfFjkEJL5DNVUQ2S%2Fg%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "About Dashlane\nDashlane's mission is to make security simple for millions of organizations and their people. We empower businesses of every size to protect company and employee data while helping everyone easily log in to the accounts they need‚Äîanytime, anywhere. Over 17 million users and 20,000 businesses in 180 countries use Dashlane for a faster, simpler, and more secure internet.\nOur global team is united by a strong sense of community and passion for improving the digital experience of our users. Learn more about how we work , how we hire , and the benefits of being a Dashlaner in our Life at Dashlane page.\nAt Dashlane, we see data as a true and reliable asset: data drives decisions based on timely insights and all teams are empowered to use data in their daily work.\nWe are hiring a Machine Learning Engineer to join our data & analytics team.\nHelping us to build & productionize impactful and actionable data models to be used in predictive and prescriptive analytics by our stakeholders and analysts teams.\nYou will play a pivotal role of managing data at rest and in motion along with governance controls empowering our business & technical users with trusted, timely and actionable data . You will be responsible for bringing robust, efficient, and integrated data models to life. You are expected to roll up your sleeves and deep dive into development on need basis. You should speak the language of business teams and technical teams, able to translate data insights and analysis needs into models.\nLocation:\nYou will be based in Paris, with English as your working language. We offer a hybrid work arrangement, with Tuesday being the company day, where we all collaborate in the office and have a company-sponsored meal, a department day for team bonding (will be Thursday for your department), and a third day at your choice. We offer relocation support (national and international).\nAbout Our Stack\nProgramming language: Python\nData Platform: AWS [ S3, EC2, ECS, Lambda, Kinesis, Glue & DMS], MySQL on RDS, Redis\nETL and ELT Tools: Airbyte and Hightouch\nData Modeling & Orchestration : DBT and Airflow\nRelease management and CI/CD: Gitlab\nBI Tools: Tableau\nInfrastructure provisioning and management: Terraform\nLogging and monitoring: ELK (ElasticSearch, Logstash, Kibana) & AWS Cloudwatch\nDocumentation and collaboration tooling: Confluence, Gitlab & Slack\nAt Dashlane You Will\nWork with batch and real-time operational and product usage data to build and improve ML models for Dashlane business.\nPrototype machine learning use cases and work with stakeholders to iterate on requirements.\nDevelop, productionize, and operate ML models and pipelines at scale.\nDrive end-2-end algorithm development of productionized models i.e. specifications, training data generation, testing , parameter and feature tuning.\nCollaborate with cross functional partners including data engineers, analysts , product managers and business stakeholders to identify opportunities impacting business.\nIdentify and articulate areas where data science can help grow company via business operations and product improvements.\nCommunicate exposition of proposed models to technical and functional stakeholders.\nAssist data science team to build MLops workflows and models for predictive modeling & analytics.\nRequirements\n3+ years experience in machine learning with an advanced degree in computer science or equivalent.\nProgramming experience in Python / Scala / Java or equivalent.\nWorking knowledge of machine learning best practices ( e.g. A/B test, feature engineering, feature/model selection), algorithms ( e.g. gradient boosted trees, deep learning / neural networks , optimization and NLP) and domains ( e.g. natural language processing, anomaly detection, personalization and recommendation).\nExperience in technologies such as TensorFlow or SageMaker.\nExperience in building end-2-end ML infrastructure and/or building and productionizing ML models.\nFluent in English: verbal and written.\nWe're Also Looking For\nSelf-motivated and self-managing, with organizational skills\nGreat communication: Regularly achieve consensus amongst technical and business teams\nDemonstrated capacity to communicate complex business activities, technical requirements, and recommendations clearly and concisely\nAbility to thrive in a distributed organization.\nHands-on experience in data engineering technologies such as Airflow, Kafka, Spark, Kubernetes and data warehouse ( Redshift/Snowflake).\nSaaS industry experience will be a huge plus.\nPhD in Computer Science , Machine Learning, Statistics or related field.\nWhat Dashlane Offers You\nEqual Parental leave - regardless of gender, up to 20 weeks fully paid leave to take care of their new baby, within the first year of birth or adoption\nHealth insurance covered by Dashlane\nMentorship program - select your mentor from our internal pool and continue your learning path!\nCommute allowance\nMeal Vouchers (Swile)\nMental health services through Spring Health for you and family members\n4 extra days off (one per quarter) to acknowledge the importance of your wellbeing\nSpot in daycare\nTime off saving account\nReimbursement of half of your commuting costs\nDonation matching program - give back to the community and support actions that lead to positive social impact under the historically marginalized communities. Every donation will be matched by Dashlane\nTeam buildings & seasonal social events\nWeekly lunch in the office and monthly happy hour\nand many more\nDiversity, Equity, Inclusion And Belonging At Dashlane\nAs a truly international company‚Äîfounded in France and distributed across France, US and Portugal‚ÄîDashlane thrives off diverse perspectives. We value all aspects of diversity: gender identity, sexual orientation, ability, ethnic origin, social background, age, lifestyle, and more. We are committed to hiring a diverse community and fostering a culture where everyone is heard and belongs. See more about this here .\nYour Interview Experience\nTo know what to expect once you‚Äôve sent your application, read about how we interview and hire at Dashlane . Feel free to browse our blog to find more information about our product and how we work.\nShow more\nShow less",
        "details": {
            "JobDetail": [
                "Full"
            ],
            "TypeContract": "",
            "Salary": "",
            "Level": "",
            "Experience": null
        },
        "title": "machine learning engineer",
        "skills": {
            "ProgLanguage": [
                "Java",
                "Scala",
                "Python"
            ],
            "DataBase": [
                "Elasticsearch"
            ],
            "BigData": [
                "Spark"
            ],
            "MachineLearning": [
                "TensorFlow"
            ],
            "DataVisualisation": [
                "Tableau"
            ],
            "CloudComputing": [
                "AWS"
            ],
            "DBMS": [
                "Snowflake",
                "MySQL"
            ],
            "Automation": [
                "Airflow",
                "Kubernetes"
            ],
            "InfrastructureAsCode": [
                "Terraform"
            ],
            "Containers": [
                "Kubernetes"
            ],
            "Collaboration": [
                "Slack",
                "Teams",
                "Confluence"
            ],
            "Other": [
                "Machine Learning",
                "ML",
                "CI/CD"
            ],
            "EnSoftSkils": [
                "Communication",
                "Organization",
                "Collaboration"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "PROXIAD",
        "location": "Nantes",
        "link": "https://fr.linkedin.com/jobs/view/ing%C3%A9nieur-machine-learning-at-proxiad-3862361161?position=9&pageNum=5&refId=JWyc74GSCq5ssJut%2FSE56g%3D%3D&trackingId=aG6oeQ3gyq40%2ByEDOX5QDw%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Proxiad Ouest est √† la recherche d‚Äôun\nnouveau talent\npour compl√©ter son √©quipe !\nQui sommes-nous ?\nAvec une √©coute attentive et un\nsuivi r√©gulier\nde ses collaborateurs, une\nbonne ambiance\net des\npetits d√©jeuner\n√† la cl√©, Proxiad est une ESN qui porte une attention toute particuli√®re au\nbien-√™tre\nde ses collaborateurs.\nSp√©cialis√© dans le Conseil et l‚ÄôExpertise aupr√®s de ses clients, le groupe Proxiad compte aujourd‚Äôhui plus de 1250 collaborateurs en France. Intervenant dans diff√©rents secteurs d‚Äôactivit√© : assurances, banques, sant√©, t√©l√©coms, industries, ‚Ä¶ Proxiad propose des projets innovant afin de d√©velopper au mieux les comp√©tences techniques de ses collaborateurs.\nQuelle sera votre mission ?\nSi vous l‚Äôacceptez, elle consistera √† occuper le r√¥le\nd'ing√©nieur machine learning (H/F)\npour l‚Äôun de nos clients. Le poste est bas√© √†\nNantes (44)\n.\nVos missions :\n- Pr√©parer les donn√©es mises √† disposition par les Data Engineers\n- Optimiser sur le plan informatique les mod√®les mis √† disposition par les Data Scientists\n- Concevoir la cha√Æne de traitement pour industrialiser des traitements\n- Assurer le maintien op√©rationnel et la p√©rennit√© des performances des mod√®les d√©ploy√©s\n- Produire la documentation (bonne pratiques, ‚Ä¶)\n- Proposer/D√©velopper des librairies internes\n- Participer aux expressions de besoins et qualification des produits et solutions mis √† disposition par les Data Architects\nEnvironnement technique\n: Python, VSCode, Jupyterlab, Docker/Kubernetes, SQL/Vertica, sklearn/xgboost/lightgbm‚Ä¶\nVotre profil :\nVous justifiez d‚Äôune exp√©rience minimum de 3 ans dans le domaine du machine learning et d√©veloppement python en production.\nVous avez des connaissances sur les frameworks de machine learning (comme scikit-learn, xgboost, lightgbm, pandas‚Ä¶).\nVous avez une exp√©rience en programmation avanc√©e / orient√©e objet avec Python.\nVous √™tes familier avec les outils de d√©veloppement Jupyter et IDE comme VSCode\nVous avez des comp√©tences en ing√©nierie logicielle (GIT, CI/CD‚Ä¶), et architecture applicative (design pattern‚Ä¶).\nShow more\nShow less",
        "details": {
            "JobDetail": [],
            "TypeContract": "",
            "Salary": "",
            "Level": "",
            "Experience": "3 an(s)"
        },
        "title": "Other",
        "skills": {
            "ProgLanguage": [
                "Python"
            ],
            "DataBase": [
                "SQL"
            ],
            "DataAnalytics": [
                "Pandas"
            ],
            "MachineLearning": [
                "Scikit-Learn",
                "LightGBM",
                "XGBoost"
            ],
            "DevTools": [
                "Git",
                "Docker"
            ],
            "Automation": [
                "Kubernetes"
            ],
            "Containers": [
                "Docker",
                "Kubernetes"
            ],
            "Other": [
                "Machine Learning",
                "CI/CD"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "Astek",
        "location": "Paris, √éle-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/ing%C3%A9nieur-machine-learning-%E2%80%93-paris-france-h-f-at-astek-3882492554?position=10&pageNum=5&refId=JWyc74GSCq5ssJut%2FSE56g%3D%3D&trackingId=bEl78%2BruEFeKVMFGIdqrfw%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "CDI\nParis - France\nPubli√©e il y a 1 mois\nLe Groupe Astek\nCe Que Nous Allons Accomplir Ensemble :\nRejoignez nos √©quipes et intervenons ensemble sur les projets de nos partenaires autour des enheux d‚Äôinnovation.\nVotre Mission, Si Vous L‚Äôacceptez :\nCadrer techniquement les projets et accompagner les Data Scientists dans la construction des mod√®les en veillant √† respecter les bonnes pratiques d‚Äôing√©nierie logicielle.\nMettre en place la d√©marche ML OPS\nD√©ployer les mod√®les en production en respectant des contraintes de co√ªts, pr√©cisions et performances techniques.\nImpl√©menter les outils permettant de monitorer ces mod√®les en production\nVous ?\nVous √™tes issu(e) d‚Äôune formation Bac+5 (√âcole d‚Äôing√©nieur, Universit√© ou √©quivalent ‚Ä¶) en informatique\nVous justifiez d‚Äôune exp√©rience significative d‚Äôau moins 5 ans au sein d‚Äôune √©quipe dans un environnement Data √† l‚Äô√©chelle du SI d‚Äôun grand groupe\nVous √™tes un bon communiquant et disposez de capacit√©s d‚Äôanalyse et de synth√®se √©prouv√©es\nVous accordez de l‚Äôimportance √† la veille technologique\nComp√©tences Techniques :\nExpertise en SPARK et PySpark\nConnaissance de Kubernetes\nConnaissance de d‚ÄôApache Kafka\nUne exp√©rience sur un cloud provider public comme Azure (id√©alement), AWS, ou GCP\nExpertise de d√©veloppement en Python\nExpertise du ML OPS\nComp√©tences Transverses :\nCapacit√© √† interagir avec des parties prenantes diverses : Data Scientists, Business analyst, Architectes, M√©tier\nForte exp√©rience en mode de Delivery Agile (Scrum, Kanban, etc.‚Ä¶)\nEtre expert dans les pratiques du Software Craftsmanship (Test Driven, Development, Behavior Driven Development, Clean Code, Code Reviews, etc.)\nEt :\nDes Connaissances sur Azure DevOps, Azure Pipeline, GIT\nMaitrise des Traitements Big Data en mode Streaming\nMaitrise des Bases de donn√©es relationnelles et NoSQL\nUne exp√©rience professionnelle avec des outils comme Azure Databricks, Azure, Machine Learning , Azure Data Lake Storage ou encore Azure Data Factory\nLe Groupe Astek\nCr√©√© en France en 1988, Astek est un acteur mondial de l‚Äôing√©nierie et du conseil en technologies. Fort de son expertise dans de nombreux secteurs industriels et tertiaires, Astek accompagne ses clients internationaux dans le d√©ploiement intelligent de leurs produits et de leurs services, et dans la mise en ≈ìuvre de leur transformation digitale.\nDepuis sa cr√©ation, le Groupe a fond√© son d√©veloppement sur une forte culture d‚Äôentrepreneuriat et d‚Äôinnovation, et sur l‚Äôaccompagnement et la mont√©e en comp√©tence de\nses 7800 collaborateurs\nqui s‚Äôengagent chaque jour √† promouvoir la compl√©mentarit√© entre les technologies num√©riques et l‚Äôing√©nierie des syst√®mes complexes.\nRejoignez un Groupe en fort d√©veloppement en France et √† travers le monde ayant r√©alis√© un chiffre d‚Äôaffaires de 600 M‚Ç¨ en 2023.\nTous les d√©tails sur le Groupe sur le site https://astekgroup.fr. Et vous pouvez aussi nous suivre sur notre blog : https://blog.groupeastek.com.\nRencontrons-nous\nNotre projet commun vous plait ?\nPostulez √† cette annonce, et soyez transparent !\nNotre Talent Acquisition Officer, vous contactera pour un premier √©change t√©l√©phonique.\nPuis vous rencontrerez votre futur manager, avec lequel vous √©changerez autour d‚ÄôAstek, de votre parcours, de vos attentes et de votre future mission .\nEnfin, vous rencontrerez notre Directeur de d√©partement, avec lequel vous pourrez valider votre int√©r√™t et ad√©quation pour le poste et finaliser les √©l√©ments contractuels.\nNos Plus\nAstek est green et fait b√©n√©ficier ses salari√©s d‚Äôune indemnit√© kilom√©trique v√©lo\nUne politique CARE sur-mesure d√©ploy√©e par nos √©quipes RH pour nos collaborateurs (https://astekgroup.fr/engagements)\nNotre charte de la Diversit√©\nBienvenue dans la team ! Allez-y, maintenant c‚Äôest √† vous de jouer !\nMots-cl√©s :\ning√©nieur ‚Äì ing√©nieure ‚Äì consultant ‚Äì consultante\nCaract√©ristiques de l'emploi\nCat√©gorie Chef de Projet\nJob Industry A√©rospatial / D√©fense / S√©curit√©, Distribution / Services Internet, Energie / Sciences de la Vie / Autres industries, Finance / Gouvernement, T√©l√©com / M√©dia, Transports Terrestres\nPostuler en ligne\nNom *\nPr√©nom *\nEmail *\nUn email valide est requis.\nT√©l√©phone *\nUn num√©ro de t√©l√©phone valide est requis.\nJoindre un CV *\nMots-cl√©s :\ning√©nieur ‚Äì ing√©nieure ‚Äì consultant ‚Äì consultante\nShow more\nShow less",
        "details": {
            "JobDetail": [],
            "TypeContract": "CDI",
            "Salary": "",
            "Level": "Bac+5",
            "Experience": "5 an(s)"
        },
        "title": "Other",
        "skills": {
            "ProgLanguage": [
                "Python"
            ],
            "DataBase": [
                "NoSQL"
            ],
            "BigData": [
                "Databricks",
                "Spark"
            ],
            "CloudComputing": [
                "GCP",
                "AWS",
                "Azure"
            ],
            "DevTools": [
                "Git"
            ],
            "SoftBigDataProcessing": [
                "Apache Kafka"
            ],
            "Automation": [
                "Chef",
                "Kubernetes"
            ],
            "Containers": [
                "Kubernetes"
            ],
            "Other": [
                "ML",
                "Big Data",
                "Machine Learning",
                "Cloud",
                "DevOps"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "ADHERENCE CONSULTING",
        "location": "Capinghem, Hauts-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/machine-learning-engineer-h-f-at-adherence-consulting-3913991636?position=1&pageNum=7&refId=RZQkDvxwhOz3zuBYk5I%2FIw%3D%3D&trackingId=SRALaks7NPQV6hy9oWH%2BGQ%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Adherence Consulting : Votre partenaire IT de choix !\nImplant√©s √† Paris, Lille et Marseille, nous sommes au coeur de l'innovation technologique et organisationnelle.\nNotre mission ? Booster votre performance et vous accompagner dans chaque √©tape de votre transformation digitale.\nSi vous √™tes pr√™t(e) pour une carri√®re qui d√©passe vos attentes, c'est le moment !\nhttps://www.adherence-consulting.fr/\nNous recherchons un ML Engineer qui rejoindra l'√©quipe MLOPS. Les missions de cette √©quipe sont :\nD'accompagner les Data Scientists sur toutes les parties techniquement complexes de leur projet (mise en production, entra√Ænement avec gros volumes de data)\nDe mettre √† disposition des Data Scientists tous les outils techniques permettant d'entra√Æner / r√©entra√Æner, de mettre en production des mod√®les de ML\nLe ML Engineer devra avoir des comp√©tences en Data Science (ie. comprendre les algorithmes de ML \"connus\") et avoir une bonne ma√Ætrise sur le build de pipeline ML.\nIl devra √©galement avoir une exp√©rience de mise en production / run de mod√®les de ML (exp√©rience indispensable)\nEn termes de technologies, l'√©cosyst√®me est constitu√© de :\nPython (avec tensorflow) et SQL\nBig Query, GCS, Data Flow, Vertex AI\nDocker, Github, Github Actions\nDatadog\nMLOPS\nData science\nPython\nCloud\nShow more\nShow less",
        "details": {
            "JobDetail": [],
            "TypeContract": "",
            "Salary": "",
            "Level": "",
            "Experience": null
        },
        "title": "machine learning engineer",
        "skills": {
            "ProgLanguage": [
                "Python"
            ],
            "DataBase": [
                "SQL"
            ],
            "MachineLearning": [
                "TensorFlow"
            ],
            "DevTools": [
                "Docker"
            ],
            "DBMS": [
                "Big Query"
            ],
            "Containers": [
                "Docker"
            ],
            "Other": [
                "Cloud",
                "ML"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "Sidetrade",
        "location": "Boulogne-Billancourt, √éle-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/data-scientist-at-sidetrade-3894699040?position=2&pageNum=7&refId=RZQkDvxwhOz3zuBYk5I%2FIw%3D%3D&trackingId=nWt6l7fevjur7yDlN1atgw%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Calling all tech enthusiasts! Are you a problem-solving, curious, and strategic Data Scientist ? Join us at Sidetrade, the leading global SaaS provider recognized by Gartner.(https://go.sidetrade.com/GartnerMagicQuadrant22.ht)\nIndulge your passion for high-availability software and performance enhancement as part of our dynamic team. Embrace the challenge, embrace the excitement - become a Data Scientist and thrive! Shape the future of AI-powered Order-to-Cash at Sidetrade today. Join us in creating innovative solutions that redefine the industry!\nAbout Sidetrade‚ÄØand its amazing R&D team\nSidetrade is a fast-growing international software company that is transforming the Order-to-Cash process for global enterprises. Its AI-powered SaaS platform digitizes the financial customer journey, empowering CFOs to secure and accelerate cash flow generation. Recognized as a Leader in Gartner's Magic Quadrant for two consecutive years, Sidetrade fosters a culture of innovation, collaboration, and customer-centricity from its headquarters in Europe and North America.\nThe R&D team comprises experienced tech professionals who share a deep passion for technology. Together, they are dedicated to developing cutting-edge software solutions that drive the transformation of our customers' work processes. We provide comprehensive training, coaching, resources, and mentorship to empower every team member's growth and nurture their success.\nWhat you will love at Sidetrade:\nWe are seeking a passionate and knowledgeable Data Scientist with a multifaceted skill set. Immerse yourself in the exhilarating world of AI and Data Science within our cutting-edge tech environment. Collaborate with like-minded individuals, embracing the latest tools, techniques, and technologies. Fuel your professional growth and innovation within our agile development ecosystem.\nYour missions :\nBuild solutions with AI, GenAI, LLM, Machine learning, Deep learning, Big Data for our products\nDefine the technical and functional orientations of the product in interaction with our Product, Marketing and Sales teams.\nParticipate in developing the architecture (LakeHouse, DataWareHouse, DataLake,¬†ETL, Search Engine, NoSQL, SQL) and designing scalable and smart algorithms\nEnhance your skills through constant discussions with specialists in their fields, and internal hackathons\nParticipate in data science guild projects: Exploratory research, Data mining, Data analysis, POC Machine learning,..\nYou will be involved in the entire development cycle: design, implementation, testing, release and maintenance.\nThrough your expertise, you will reinforce the continuous improvement of development processes.\nTechnical environment :\nLanguages : Python & SQL\nData Storage : Oracle, Postgres, Elasticsearch, Greenplum, MongoDB\nData Science framework : Dataiku, Jupyter Notebook, Metaflow\nDataviz : Tableau Server, PowerBI\nData processing : Talend, Python, DBT, Kafka\nSource control : Git\nD√©ployment: Bash, Ansible, Docker\nConfluence, Jira, Teams\nRequirements\nMaster degree\n2 to 5 years' experience in a similar position\nProven data science experience with production launch of Machine Learning models\nApplied knowledge of AI, GenAI and LLM\nSolid knowledge of Python and object-oriented programming\nGood knowledge of SQL and NoSQL databases\nFamiliarity with API Rest and Web development issues\nSensitivy to the performance of your algorithms, both in terms of relevance and hardware impact\nA taste for discovery and technology watch\nYou know how to grasp a rich technical stack (Scheduling/Message queuing/Front/API/Data Workflow / Distributed Computing Framework / Machine Learning / SQL & NoSQL databases) and challenge it\nFluent in English (written and spoken) is a must (most of the meeting are in English).\nBenefits\nJoin our Immersive Bootcamp\nReview your onboarding plan with your manager and develop an action plan to achieve your goals\nCollaborate with the team and participate to the roadmap to optimize software performancebuild your internal network across all departments\nExpand your skill set, share your expertise and unlock your full potential\nAt Sidetrade, we cultivate a multicultural environment that fuels innovation. With over 22 nationalities represented, we strongly value diversity, gender equality, inclusivity, and fairness. As an equal opportunity employer, we reject all forms of discrimination and harassment. Your unique contributions are celebrated, driving collective success in our inclusive workplace.\nDiscover more on¬†www.sidetrade.com\nAgencies\nOnly applications from invited agencies through the Workable portal will be accepted. Unsolicited CVs sent directly to managers or HR will not incur any fees.\nApply for this job\nShow more\nShow less",
        "details": {
            "JobDetail": [
                "Full"
            ],
            "TypeContract": "",
            "Salary": "",
            "Level": "",
            "Experience": null
        },
        "title": "data scientist",
        "skills": {
            "ProgLanguage": [
                "R",
                "Bash",
                "Python"
            ],
            "DataBase": [
                "Elasticsearch",
                "SQL",
                "MongoDB",
                "NoSQL"
            ],
            "DataAnalytics": [
                "R"
            ],
            "DataVisualisation": [
                "Tableau"
            ],
            "DevTools": [
                "Git",
                "Docker"
            ],
            "Automation": [
                "Ansible"
            ],
            "Containers": [
                "Docker"
            ],
            "Collaboration": [
                "Confluence",
                "Teams",
                "JIRA"
            ],
            "Other": [
                "Machine Learning",
                "Big Data"
            ],
            "EnSoftSkils": [
                "Collaboration"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "ADHERENCE CONSULTING",
        "location": "Lille, Hauts-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/data-scientist-h-f-at-adherence-consulting-3913991657?position=3&pageNum=7&refId=RZQkDvxwhOz3zuBYk5I%2FIw%3D%3D&trackingId=Oa3TChKIV0XEgTNO22LbAA%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Adherence Consulting : Votre partenaire IT de choix !\nImplant√©s √† Paris, Lille et Marseille, nous sommes au coeur de l'innovation technologique et organisationnelle.\nNotre mission ? Booster votre performance et vous accompagner dans chaque √©tape de votre transformation digitale.\nSi vous √™tes pr√™t(e) pour une carri√®re qui d√©passe vos attentes, c'est le moment !\nhttps://www.adherence-consulting.fr/\nImplant√©e au carrefour de l'innovation technologique et organisationnelle, notre entreprise se positionne comme un partenaire IT de premier plan. Situ√©s √† Paris, Lille, et Marseille, nous nous engageons √† booster la performance de nos clients √† travers une transformation digitale sur mesure. Rejoignez une √©quipe ambitieuse pour une carri√®re qui d√©passe vos attentes.\nDate de D√©but : Fin avril 2024 maximum.\nMission Principale : D√©velopper un syst√®me de recommandation destin√© aux utilisateurs pour am√©liorer le Diagnostique de Performance Energ√©tique de leur logement. Ce syst√®me √©voluera de recommandations bas√©es sur des r√®gles gouvernementales vers des suggestions personnalis√©es incluant des travaux et produits sp√©cifiques.\nResponsabilit√©s\nD√©velopper et maintenir le code backend en Python, participer √† la transcription de r√®gles DPE en code de calcul python\nAssurer la maintenance d'un syst√®me existant en Data Science.\nUtiliser des comp√©tences en Data Science, particuli√®rement dans les r√©seaux de neurones, pour am√©liorer et innover dans le syst√®me de recommandation.\nCollaborer √©troitement avec les √©quipes M√©tiers pour analyser, √©valuer et exploiter la richesse des donn√©es disponibles.\nG√©rer le cycle complet du d√©veloppement des projets Data Science, incluant la conception, le d√©ploiement, le monitoring, et la documentation.\nAttention, le poste est ouvert uniquement en CDI. Une exp√©rience de 5 √† 6 ans minimum est exig√©e.\nPour R√©ussir dans ce Poste : Vous √™tes un(e) passionn√©(e) de technologie et de data, capable de piloter des projets complexes avec une grande autonomie. Vous avez une excellente ma√Ætrise de la programmation en Python et une exp√©rience solide dans la mise en oeuvre de solutions de Data Science. Votre capacit√© √† communiquer et √† travailler en √©quipe vous permettra de vous int√©grer rapidement et de contribuer efficacement aux projets de l'entreprise.\nComp√©tences Techniques Requises\nMa√Ætrise avanc√©e de Python, avec une solide exp√©rience en d√©veloppement backend.\nConnaissance approfondie de FastAPI, Git, SQL, Docker, et Google Cloud Platform (GCP).\nExp√©rience significative en Data Science, notamment dans l'utilisation de r√©seaux de neurones.\nCapacit√© √† traduire les √©volutions du DPE en code de calcul scientifique.\nFamiliarit√© avec les technologies telles que TensorFlow pour le d√©veloppement de syst√®mes de recommandation.\nQualit√©s Professionnelles\nAutonomie dans la gestion de projets complexes.\nExcellente capacit√© de programmation et de r√©solution de probl√®mes.\nCommunication efficace avec les partenaires business.\nCapacit√© √† travailler en √©quipe et √† partager les connaissances et bonnes pratiques.\nModalit√©s De Travail\nPossibilit√© de t√©l√©travail\nInt√©gration dans une √©quipe projet dynamique avec des ambitions transversales fortes au sein du groupe.\nShow more\nShow less",
        "details": {
            "JobDetail": [],
            "TypeContract": "CDI",
            "Salary": "",
            "Level": "",
            "Experience": "6 an(s)"
        },
        "title": "data scientist",
        "skills": {
            "ProgLanguage": [
                "Python"
            ],
            "DataBase": [
                "SQL"
            ],
            "MachineLearning": [
                "TensorFlow"
            ],
            "CloudComputing": [
                "GCP",
                "Google Cloud Platform"
            ],
            "DevTools": [
                "Git",
                "Docker"
            ],
            "Containers": [
                "Docker"
            ],
            "Other": [
                "Cloud"
            ],
            "EnSoftSkils": [
                "Communication"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "METEOJOB by CleverConnect",
        "location": "Rennes, Brittany, France",
        "link": "https://fr.linkedin.com/jobs/view/data-scientist-h-f-at-meteojob-by-cleverconnect-3907968677?position=4&pageNum=7&refId=RZQkDvxwhOz3zuBYk5I%2FIw%3D%3D&trackingId=6WtZpQ6WnH9LON61QVJ1lA%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Entreprise\nQui sommes-nous ?\nNous sommes passionn√©s par les nouvelles technologies, et vous ?\nRejoindre Amiltone, c'est int√©grer des √©quipes dynamiques et soud√©es dans le cadre de projets novateurs et ambitieux. Nous relevons les challenges techniques de nos clients et les accompagnons dans leur transformation digitale.\nPourquoi choisir Amiltone‚ÄØ?\nAmiltone, plus qu'une entreprise, un √©tat d'esprit !\nNotre objectif ? Votre √©panouissement professionnel !\nNous Avons √† C≈ìur De\nVous accompagner au mieux au travers d'un suivi personnalis√©\nVous faire monter en comp√©tences en vous proposant des formations tout au long de votre carri√®re\nComprendre vos besoins et respecter nos engagements\nVous proposer des missions de qualit√© avec des technologies innovantes\nCultiver votre potentiel gr√¢ce √† notre programme de d√©veloppement personnel Addvise\nVotre bien-√™tre passe aussi par des activit√©s extraprofessionnelles, c'est pourquoi nous vous proposons des s√©ances sportives anim√©es par nos coachs, soir√©es pour se retrouver et animations (√† l'agence ou en visio), Gaming nights...\nDescription Du Poste\nVos missions ?\nInt√©gr√© √† notre √©quipe de 10 personnes, vous assurez les missions suivantes :\nR√©ceptionner et analyser la donn√©e brute\nTraiter la donn√©e en streaming ou en statique\nAdapter ou cr√©er des mod√®les de machine learning\nEvaluer la pr√©cision/robustesse d'un mod√®le\nOutils de monitoring et de visualisation\nD√©veloppement des mod√®les\nMaintenir et documenter les codes et les process\nLa stack Technique :\nOutils : MongoDB, PostgreSQL\nNLP (IA g√©n√©rative)\nQlik Sense\nDocker, Jenkins\nGitlab/Github\nDescription Du Profil\nAlors ? Pr√™t √† devenir Amiltonien ?\nN'h√©sitez Pas √† Postuler Si Vous Vous Reconnaissez\nDipl√¥m√© bac+5 (√©cole d'ing√©nieur ou master), vous avez au moins 2 ans d'exp√©rience en tant que Data Scientist.\nVous aimez d√©couvrir de nouveaux contextes fonctionnels et comprendre les objectifs des applications que vous d√©veloppez.\nA l'aise dans une organisation agile, vous faites preuve de rigueur et appliquez les standards de qualit√© Amiltone durant toute la dur√©e des d√©veloppements.\nOutre vos comp√©tences techniques, nous nous int√©ressons √©galement √† votre potentiel et votre motivation.\nNos postes sont ouverts aux personnes en situation de handicap.\nShow more\nShow less",
        "details": {
            "JobDetail": [],
            "TypeContract": "",
            "Salary": "",
            "Level": "Bac+5",
            "Experience": "2 an(s)"
        },
        "title": "data scientist",
        "skills": {
            "DataBase": [
                "MongoDB"
            ],
            "DevTools": [
                "Jenkins",
                "Docker"
            ],
            "DBMS": [
                "PostgreSQL"
            ],
            "Containers": [
                "Docker"
            ],
            "Other": [
                "Machine Learning"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "Withings",
        "location": "Paris, √éle-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/data-scientist-at-withings-3888804341?position=5&pageNum=7&refId=RZQkDvxwhOz3zuBYk5I%2FIw%3D%3D&trackingId=FHt2b7FmdSOCDylOxgumyA%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Vos missions\nL'√©quipe Machine Learning est responsable du d√©veloppement de tous les algorithmes de pr√©diction des produits Withings. Int√©gr√©.e en son sein, tu auras les responsabilit√©s suivantes:\nRecherche algorithmique pour analyser les donn√©es pertinentes et les partager avec l‚Äô√©quipe\nR√©alisation de prototypes par la mise en pratique des m√©thodes retenues\nImpl√©mentation de services sur la plateforme / produits Withings, en tenant compte des contraintes de ressources et de temps d‚Äôex√©cution\nMise en avant de nouvelles fonctionnalit√©s pour les applications et produits Withings\nMaintien du lien avec les √©quipes de Recherche Appliqu√©e et de D√©veloppement Produit pour comprendre et exploiter les donn√©es recueillies\nREQUIREMENTS\nFormation Bac+5 type grande √©cole d‚Äôing√©nieur ou √©quivalent\nUn\ndoctorat\ndans un domaine connexe est tr√®s appr√©ci√©\nUne premi√®re exp√©rience r√©ussie dans le domaine du Machine Learning, de l'algorithmie appliqu√© aux donn√©es de sant√© ou √† l'embarqu√© est fortement appr√©ci√©e\nFortes comp√©tences informatiques : calculs scientifiques, Python...\nRigueur, autonomie, prise d'initiatives, curiosit√©...\nConnaissances en traitement de signal, C/C++ appr√©ci√©es\nMa√Ætrise parfaite de la communication en fran√ßais et en anglais, aussi bien √† l‚Äô√©crit qu‚Äô√† l‚Äôoral\nRejoindre l‚Äôaventure Withings, c‚Äôest :\nInt√©grer un des pionniers et leaders mondiaux de la sant√© connect√©e, plusieurs fois prim√© au Consumer Electronic Show\nContribuer √† des projets innovants et ambitieux pour la sant√© de demain dans un environnement agile et en constante √©volution\nInt√©grer une entreprise internationale, membre de la FrenchTech 120, dont les √©quipes sont bas√©es √† Issy-les-Moulineaux, Boston, Hong-Kong et Shenzhen\nParticiper √† l‚Äôam√©lioration continue de nos produits et services en les b√™ta-testant avant leur sortie, notamment lors de nos nombreuses sessions sportives entre coll√®gues\nB√©n√©ficier de nombreux avantages : Stock Options, smartphone et ordinateur de votre choix, r√©ductions pour des activit√©s culturelles et sportives, restaurant d‚Äôentreprise, et bien plus encore\nParticiper √† la Withings Med Academy en assistant √† des conf√©rences de professionnels de sant√© afin de renforcer ses connaissances dans le domaine m√©dical\nCollaborer avec des coll√®gues passionn√©s et c√©l√©brer ensemble chacune de nos r√©ussites !\nToutes les candidatures re√ßues sont √©tudi√©es ind√©pendamment de l‚Äôorigine ethnique, des croyances, de la religion, du genre, de l‚Äôorientation sexuelle ou de la sant√© des candidats. Withings aspire √† offrir et garantir l‚Äô√©galit√© des chances aux candidats et seules les personnes habilit√©es (RH et Management) auront acc√®s aux informations concernant votre candidature.\nShow more\nShow less",
        "details": {
            "JobDetail": [],
            "TypeContract": "",
            "Salary": "",
            "Level": "Bac+5",
            "Experience": null
        },
        "title": "data scientist",
        "skills": {
            "ProgLanguage": [
                "Python"
            ],
            "Other": [
                "Machine Learning"
            ],
            "EnSoftSkils": [
                "Communication"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "FarmWise",
        "location": "Paris, √éle-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/senior-machine-learning-engineer-at-farmwise-3831137831?position=6&pageNum=7&refId=RZQkDvxwhOz3zuBYk5I%2FIw%3D%3D&trackingId=zgYKgbNkLJciuZWMhId4vQ%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Company Overview:\nAt FarmWise, we harness the power of AI to find solutions to combat food production challenges, and help growers thrive in this new farming era. We work hand in hand with growers to understand their constraints, address their priorities, and build products that are changing their lives for good. We‚Äôre a diverse team of analytical problem-solvers who are deeply motivated by challenges. We value open communication and a dedication to self-improvement. If you are interested in working on technology that will have a big impact on agriculture. Join us!\nJob Overview:\nAs a Sr. Machine Learning Engineer at FarmWise, you will play a pivotal role in leading and executing research and development initiatives. You will focus on advanced topics such as panoptic segmentation models for plant and weed detection, optimization of embedded models, 3D visual odometry, etc. You‚Äôll be part of a team of Data and Machine Learning engineers. This role encompasses the entire machine learning lifecycle, from defining state-of-the-art methodologies to deploying sophisticated solutions into production environments and maintaining automated and robust data pipelines.\nResponsibilities:\nLead and collaborate with cross-functional teams to identify and define complex machine learning challenges in agriculture.\nDesign, develop, and implement advanced machine learning algorithms, with a focus on automated diagnosis of mislabeled images and model robustness.\nConduct in-depth research to establish and integrate state-of-the-art approaches in machine learning domains.\nDesign and execute comprehensive experiments to evaluate and optimize machine learning models.\nCollaborate closely with the engineering team to successfully deploy advanced models into production environments.\nMentor and guide junior team members, fostering a culture of continuous learning and improvement.\nQualifications:\nExtensive experience in Python, PyTorch, and other relevant machine learning frameworks.\nProven track record of successfully leading and implementing machine learning projects, with a focus on computer vision and related domains.\nStrong problem-solving skills, analytical mindset, and ability to thrive in a fast-paced environment.\nExcellent communication skills, both technical and non-technical, and a commitment to mentorship.\nWhat We Offer:\nJoin a dynamic team of industry experts dedicated to making a positive impact on agriculture through technological innovation.\nWork with cutting-edge technologies and contribute to the development of groundbreaking solutions.\nEnjoy a hybrid-remote work policy, providing flexibility to accommodate your work preferences.\nHiring Process:\nHR Interview\nTechnical Interview\nTake-home challenge\nIn person interviews with various team members\nFarmWise is an equal opportunity employer, and we encourage applicants from all backgrounds to apply. If you are passionate about pushing the boundaries of technology in agriculture, we look forward to receiving your application!\nShow more\nShow less",
        "details": {
            "JobDetail": [
                "Remote",
                "Full",
                "Junior"
            ],
            "TypeContract": "",
            "Salary": "",
            "Level": "",
            "Experience": null
        },
        "title": "machine learning engineer",
        "skills": {
            "ProgLanguage": [
                "Python"
            ],
            "MachineLearning": [
                "PyTorch"
            ],
            "Collaboration": [
                "Teams"
            ],
            "Other": [
                "Machine Learning"
            ],
            "EnSoftSkils": [
                "Flexibility",
                "Communication"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "Liftoff Mobile",
        "location": "Paris, √éle-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/machine-learning-engineer-at-liftoff-mobile-3812712612?position=7&pageNum=7&refId=RZQkDvxwhOz3zuBYk5I%2FIw%3D%3D&trackingId=3Xt%2F63ZjZGkW8yIaVdjvyw%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Liftoff is the leading growth acceleration platform for the mobile industry, helping advertisers, publishers, game developers and DSPs scale revenue growth with solutions to market and monetize mobile apps.\nLiftoff‚Äôs solutions, including Accelerate, Direct, Influence, Monetize, Intelligence, and Vungle Exchange, support over 6,600 mobile businesses across 74 countries in sectors such as gaming, social, finance, ecommerce, and entertainment. Founded in 2012 and headquartered in Redwood City, CA, Liftoff has a diverse, global presence.\nAbout the team:\nThe Conversion ML team is responsible for improving and maintaining machine learning models that have a pivotal impact on the performance of Accelerate customers‚Äô advertising campaigns. The team collaborates closely with other ML-oriented teams at Liftoff. We use many modern ML frameworks and architectures, including Spark and PyTorch to build deep neural networks.\nLocation:\nThis role is located in Liftoff's Hub in Paris, France or can be in any of the following locations: England or Germany. ML Engineers located in Paris will be asked to come into the office once a week and once a month if located in one of the above countries.\nResponsibilities:\nOwn both the ML models and the underlying software tooling and infrastructure. Our ML Engineer role combines the classic \"ML Scientist\" and \"Data Engineer\" role at other companies.\nHave a closed feedback loop from hypothesis generation to live AB testing, with no cross-team friction and sub-day iteration cycles.\nTake on unique modeling challenges not covered in the scientific literature, like extreme positive sample sparsity and labeling delay.\nWork with modeling techniques at the state-of-the-art of probability prediction, as well as a multitude of other ML areas.\nBecome an expert in Clojure, Go, and the many other cutting-edge open source technologies that maximize our development velocity.\nJoin a nimble, consistently excellent, and experienced engineering team (former Google/LI/Ooyala/etc).\nRequirements:\nVery strong coding ability (experience in Go or Clojure is a plus).\n4+ years of industry experience applying Machine Learning to large scale problems.\nStrong core CS fundamentals (data structures, algorithms, architecting systems).\nA passion for quality and excellence, and the ability to temper it when necessary to ship.\nSets ego aside in pursuit of finding the best solution, no matter where it comes from.\nB.S. or higher in Computer Science. PhD a big plus.\n1\nWe use Covey as part of our hiring and / or promotional process for jobs in NYC and certain features may qualify it as an AEDT. As part of the evaluation process we provide Covey with job requirements and candidate submitted applications. We began using Covey Scout for Inbound on January 22, 2024.\nPlease see the independent bias audit report covering our use of Covey here.\nLiftoff is committed to providing and maintaining a work environment where all employees and candidates are treated with dignity and respect and that is free of bias, prejudice, and harassment. Liftoff is further committed to providing an equal employment opportunity for all employees and candidates for employment free from discrimination and harassment on the basis of sex, gender (including sexual harassment, gender harassment, and harassment due to pregnancy, childbirth, breastfeeding, and related conditions), sexual orientation, gender identity, gender expression, gender nonconformity, race, creed, religion, color, national origin, ancestry (including association, affiliation, or participation with persons or activities related to national origin, English-proficiency or accent, or immigration status), physical or mental disability, medical condition(s), genetic information of an individual or family member of the individual, marital or domestic partner status, age, veteran or military status, family care status, requesting or taking pregnancy, parental or disability leave, requesting an accommodation, or any other characteristic protected by federal, state, or local law, regulation, or ordinance. All such discrimination and harassment is unlawful and will not be tolerated. Liftoff maintains a continued commitment to equal employment opportunity and expects the full cooperation of all personnel.\nAgency and Third Party Recruiter Notice:\nLiftoff does not accept unsolicited resumes from individual recruiters or third-party recruiting agencies in response to job postings. No fee will be paid to third parties who submit unsolicited candidates directly to our hiring managers or Recruiting Team. All candidates must be submitted via our Applicant Tracking System by approved Liftoff vendors who have been expressly requested to make a submission by our Recruiting Team for a specific job opening. No placement fees will be paid to any firm unless such a request has been made by the Liftoff Recruiting Team and such a candidate was submitted to the Liftoff Recruiting Team via our Applicant Tracking System.\nShow more\nShow less",
        "details": {
            "JobDetail": [
                "Full"
            ],
            "TypeContract": "",
            "Salary": "",
            "Level": "",
            "Experience": null
        },
        "title": "machine learning engineer",
        "skills": {
            "BigData": [
                "Spark"
            ],
            "MachineLearning": [
                "PyTorch"
            ],
            "Collaboration": [
                "Teams"
            ],
            "Other": [
                "Machine Learning",
                "ML"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "ADHERENCE CONSULTING",
        "location": "Capinghem, Hauts-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/data-scientist-h-f-at-adherence-consulting-3913994542?position=8&pageNum=7&refId=RZQkDvxwhOz3zuBYk5I%2FIw%3D%3D&trackingId=MxldwosutwzoOpFE2lUW2A%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Adherence Consulting : Votre partenaire IT de choix !\nImplant√©s √† Paris, Lille et Marseille, nous sommes au coeur de l'innovation technologique et organisationnelle.\nNotre mission ? Booster votre performance et vous accompagner dans chaque √©tape de votre transformation digitale.\nSi vous √™tes pr√™t(e) pour une carri√®re qui d√©passe vos attentes, c'est le moment !\nhttps://www.adherence-consulting.fr/\nLes missions du poste\nContexte\nAdh√©rence Consulting est une ESN implant√© √† Paris, Lille et Marseille. Nous sommes au coeur de l'innovation technologique et organisationnelle.\nNotre mission ? Booster les performances et accompagner nos clients √† chaque √©tape de leur transformation digitale. Nous cherchons actuellement un Data Scientist (F/H) pour le projet de notre client.\nVous participerez √† la construction de nombreux projets tous aussi ambitieux les uns que les autres.\nQuelles sont vos missions au quotidien ?\nApplique des techniques (statistiques, text mining, comportementale, g√©olocalisation,) d'extraction et d'analyse d'informations, obtenues √† partir de gisements de donn√©es (Big Data)\nObtient des donn√©es ad√©quates, trouve les sources de donn√©es pertinentes, fait des recommandations sur les bases de donn√©es √† consolider, modifier, rapatrier, externaliser, internaliser, con√ßoit des datamarts, voire des entrep√¥ts de donn√©es (data warehouses).\n√âvalue la qualit√© et la richesse des donn√©es, les analyse et en restitue les r√©sultats pour ensuite les int√©grer dans le syst√®me d'information cible du M√©tier.\nAnalyse les donn√©es pour traduire une probl√©matique M√©tier en probl√®me math√©matiques/statistiques et r√©ciproquement.\nCompare et √©value diff√©rents mod√®les ou m√©thodes de calcul et anticipe les avantages et inconv√©nients dans un environnement M√©tier.\nIntervenant aupr√®s des M√©tiers, il exploite, analyse et √©value la richesse, de donn√©es structur√©es ou non, appartenant √† l'entreprise ou non, pour √©tablir des sc√©narios permettant de comprendre et d'anticiper de futurs levier M√©tiers ou op√©rationnels pour l'entreprise\nShow more\nShow less",
        "details": {
            "JobDetail": [],
            "TypeContract": "",
            "Salary": "",
            "Level": "",
            "Experience": null
        },
        "title": "data scientist",
        "skills": {
            "Other": [
                "Statistiques",
                "Big Data"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "Homa",
        "location": "Paris, √éle-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/game-data-analyst-scientist-live-games-at-homa-3890653582?position=9&pageNum=7&refId=RZQkDvxwhOz3zuBYk5I%2FIw%3D%3D&trackingId=jcnrH8BW8Rri9h0C9O2WrQ%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Welcome to Homa, the gaming technology lab that is taking the industry by storm! Our team of over 200 people, hailing from more than 35 different countries, is dedicated to empowering mobile game creators worldwide to bring their creative ideas to the top charts.\nOur Homa Lab platform offers a comprehensive suite of cutting-edge tools that allow developers to stay on top of the latest trends, test new features in real-time, and easily distribute and monetize their games. Our success speaks for itself - our apps have been downloaded over 1 billion times!\nSince our inception, we have raised $165 million in total from prominent investors, including Headline, Northzone, Eurazeo, Singular, Quadrille Capital, Fabric Ventures, and Bpifrance. We have also received support from renowned business angels, such as the founders of King, Sorare and Spotify founders.\nBut what really makes Homa special is our team. We are a diverse group of artists, business developers, engineers, entrepreneurs, and former strategy consultants who all share the same passion for taking over the gaming industry. When you become part of Homa, you'll be joining a dedicated team that creates innovative and high-performing games that resonate with players worldwide.\nIf you're ready to take your career to the next level and make a real impact in the company, then Homa is the perfect place for you. Join us and let's create the future of gaming together!\nMeet the team\nüë©‚Äçüë©‚Äçüëß‚Äçüëß\nYou will join the Data department organized into:\nA Data Platform team with 5 Data Engineers responsible for ingesting large amounts of data from multiple different sources, creating and maintaining a core data model which aims at making data standardized, reliable and easily available\nA Data Science and ML Platform team with 6 Data Scientists / ML Engineer working on ML-driven data products: Autobidder for User Acquisition, N-Testing for experimentation, etc.\nAn Advanced Analytics & Data Science team with 6 Data Analysts and Scientists exploiting our data for:\nGame Analytics\nUser Acquisition and Marketing Analytics\nMarket Inteligence Analytics\nOps Analytics\nRole and Missions ‚Äî What you will do\nüöÄ\nAs a\nData Analyst/Scientist\nin the\nGame Analytics team\n, you will push the analysis of our games portfolio (hypercasual, hybridcasual, casual) to offer a deeper user experience by adding more meta, live ops and segmentation.\nWorking under the responsibility of our Head of Data, your missions will be the following:\nPartnering with our Product Managers & Head of Studios to improve our live games portfolio by driving the roadmap through the analysis of player behaviors\nBeing the go-to-person for anything related to A/B Testing : planning, deciding on parameters, analyzing complex tests in depth to take statistically driven decision\nBuilding a standardized approach to improving our current Hybrid Games through the implementation of best in class process and standardized analysis\nRecommending segmentation to get closer to an adaptive gaming approach (gameplay & monetization)\nOur technical stack\n: SQL, Redshift, Python, Tableau, DBT, Gitflow\nRequirements\nHaving a strong experience in Data, you want to join a diverse team composed of mobile gaming enthusiasts. If you recognize yourself in the following description, you're the one!\nYou have a strong education background with an MSc. in Statistics / Maths / Computer Science / Economy or other quantitative fields from a top university\nPrior experience as a Data Analyst/Scientist - including at least 2-3 years in the gaming industry (mandatory)\nYou love playing mobile games and you are able to deconstruct them to define best-in-class practices\nYou demonstrate outstanding analytical skills and creative thinking\nYou own a classic technical toolkit for Machine Learning\nWe need a doer mindset as we are still a small team and need to do things outside of our job description when they can have an impact\nYou are absolutely fluent in English (interviews will be led in English)\nOur Culture‚ÄîWho we are\nü™ê\nAt Homa, we are building a community of brilliant talents. We believe that true innovation comes from diversity and collaboration, and that's why we prioritize brainpower and determination over formal education. So if you have the talent, energy and motivation, there is no obstacle to your success here.\nAs the creative experts behind the platform, we provide developers with the data they need to bring their ideas to life. Our team lives by three central values that guide everything we do:\n‚ú®\nAmbition\n: we're not afraid to tackle difficult challenges and set our goals extremely high. We're on a mission to revolutionize an industry dominated by well-established companies, and we won't stop until we succeed.\n‚ú®\nHumility\n: we leave our pride & ego aside. We are always ready to lend a helping hand, celebrate each other's successes, and learn from our failures. As Mr. Lamar said, \"Sit down. Be humble.\"\n‚ú®\nCuriosity\n: we keep our minds open and never stop learning. We believe that questioning everything is the best way to stay ahead of the curve, and we encourage all our team members to stay curious and never stop exploring new ideas.\nAt Homa, you'll be challenged, supported, and inspired every day, and we can't wait to see what you bring to the table.\nBenefits\nWhile success is its own reward, here are some of the benefits that come with working at Homa:\nWe offer essential benefits in France and specific locations, including health insurance, meal vouchers, public transport subsidies, childcare benefits, and life insurance\nIf you're interested in working from our newly renovated Paris HQ with a rooftop garden and WeWork amenities, we have a desk waiting for you\nYou will be working in English with our international team of top-tier talents from 35+ countries\nYou will have bi-annual reviews with your manager to reflect on your performance, celebrate wins, and receive constructive feedback\nYou will be able to attend diverse team events and Workations (the famous company-wide Homa trip)\nShow more\nShow less",
        "details": {
            "JobDetail": [],
            "TypeContract": "",
            "Salary": "",
            "Level": "",
            "Experience": null
        },
        "title": "data scientist",
        "skills": {
            "ProgLanguage": [
                "Python"
            ],
            "DataBase": [
                "SQL"
            ],
            "DataVisualisation": [
                "Tableau"
            ],
            "Other": [
                "Machine Learning",
                "ML"
            ],
            "EnSoftSkils": [
                "Collaboration"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "Social Clean",
        "location": "Paris, √éle-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/data-scientist-f-h-at-social-clean-3832562747?position=10&pageNum=7&refId=RZQkDvxwhOz3zuBYk5I%2FIw%3D%3D&trackingId=gQd72EDLMj4yvGW6SstBnA%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Social Clean, a √©t√© fond√©e avec une mission simple : aider les entreprises √† prendre des d√©cisions plus √©clair√©es en utilisant des donn√©es pertinentes et fiables. Nous sommes convaincus que l'analyse de donn√©es peut transformer la fa√ßon dont les entreprises fonctionnent et leur donner un avantage concurrentiel significatif.\nNotre √©quipe est compos√©e de professionnels de la data exp√©riment√©s, qui poss√®dent une expertise approfondie en mati√®re d'analyse de donn√©es, de visualisation et d'interpr√©tation. Nous avons travaill√© avec des entreprises de diff√©rentes tailles et de diff√©rents secteurs, ce qui nous permet de comprendre les d√©fis uniques auxquels sont confront√©es les entreprises dans diff√©rentes industries.\nNous offrons une gamme de services pour aider les entreprises √† tirer parti de leurs donn√©es, y compris la collecte et le nettoyage des donn√©es, l'analyse des donn√©es, la visualisation des donn√©es, et la mod√©lisation pr√©dictive. Nous sommes √©galement en mesure d'aider les entreprises √† mettre en place des syst√®mes de gestion de donn√©es efficaces pour assurer que leurs donn√©es sont stock√©es et organis√©es de mani√®re √† maximiser leur utilit√©.\nVos missions\nCollecter et nettoyer les donn√©es : Trouver, collecter et nettoyer les donn√©es n√©cessaires √† l'analyse en utilisant diff√©rentes sources telles que les bases de donn√©es, les API, les sites web, les fichiers Excel, etc.\nAnalyser les donn√©es : Utiliser des m√©thodes statistiques et des outils de visualisation pour explorer les donn√©es et identifier les tendances, les corr√©lations et les mod√®les.\nD√©velopper des mod√®les pr√©dictifs : Utiliser des techniques d'analyse statistique et de machine learning pour d√©velopper des mod√®les pr√©dictifs pour pr√©voir des r√©sultats futurs bas√©s sur les donn√©es existantes.\n√âvaluer les mod√®les pr√©dictifs : √âvaluer les performances des mod√®les pr√©dictifs et apporter des am√©liorations.\nCommuniquer les r√©sultats : Pr√©senter les r√©sultats d'analyse de donn√©es sous forme de rapports, de graphiques ou de tableaux pour aider √† prendre des d√©cisions √©clair√©es.\nCollaborer avec d'autres √©quipes : Travailler en √©troite collaboration avec des √©quipes interfonctionnelles pour comprendre les probl√®mes m√©tier et recommander des solutions bas√©es sur les donn√©es.\nUtiliser des outils de programmation : Utiliser des outils de programmation tels que Python, R et SQL pour analyser et manipuler les donn√©es.\nG√©rer les projets : G√©rer des projets de bout en bout, y compris la collecte de donn√©es, l'analyse, le d√©veloppement de mod√®les, l'√©valuation des performances et la communication des r√©sultats.\nRester √† jour sur les derni√®res tendances : Restez √† jour sur les derni√®res tendances et les nouvelles technologies pour am√©liorer les m√©thodes et les pratiques de l'entreprise.\nVos comp√©tences\nComp√©tences en programmation : Connaissance approfondie des langages de programmation couramment utilis√©s en science des donn√©es tels que Python, R, SQL, etc.\nComp√©tences en visualisation de donn√©es : Comp√©tences en visualisation de donn√©es pour cr√©er des graphiques et des tableaux clairs et concis pour pr√©senter les r√©sultats de l'analyse.\nComp√©tences en apprentissage automatique : Comprendre les concepts fondamentaux de l'apprentissage automatique, y compris les algorithmes d'apprentissage supervis√© et non supervis√©.\nComp√©tences en bases de donn√©es : Connaissance des bases de donn√©es relationnelles et non relationnelles, ainsi que des comp√©tences en gestion et en analyse des donn√©es.\nComp√©tences en gestion de projet : Capacit√© √† g√©rer des projets de bout en bout, y compris la collecte de donn√©es, l'analyse, la mod√©lisation et la pr√©sentation des r√©sultats.\nComp√©tences en communication : Capacit√© √† communiquer de mani√®re claire et concise les r√©sultats d'analyse de donn√©es aux parties prenantes et aux coll√®gues.\nComp√©tences en r√©solution de probl√®mes : Capacit√© √† identifier et √† r√©soudre les probl√®mes li√©s √† la collecte et √† l'analyse de donn√©es.\nComp√©tences en math√©matiques : Connaissance des math√©matiques appliqu√©es, y compris les statistiques et les probabilit√©s.\nComp√©tences en intelligence artificielle : Connaissance des concepts d'intelligence artificielle, y compris le traitement du langage naturel et la vision par ordinateur.\nComp√©tences en gestion des donn√©es : Capacit√© √† comprendre et √† g√©rer de grandes quantit√©s de donn√©es pour optimiser l'analyse et la prise de d√©cision.\nAvantages\nMutuelle Alan\nCarte Swile\nCong√©s pay√©s et RTT\nT√©l√©travail\nWelcome Kit\nEvents\nPerks\nNous sommes passionn√©s par ce que nous faisons et nous sommes convaincus que nous pouvons aider les entreprises √† transformer leur fa√ßon de travailler en utilisant des donn√©es. Si vous √™tes √† la recherche d'un partenaire fiable et exp√©riment√© pour vous aider √† relever vos d√©fis de donn√©es, nous sommes l√† pour vous aider.\nShow more\nShow less",
        "details": {
            "JobDetail": [],
            "TypeContract": "",
            "Salary": "",
            "Level": "",
            "Experience": null
        },
        "title": "data scientist",
        "skills": {
            "ProgLanguage": [
                "R",
                "Python"
            ],
            "DataBase": [
                "SQL"
            ],
            "DataAnalytics": [
                "R"
            ],
            "Other": [
                "Statistiques",
                "Machine Learning"
            ],
            "EnSoftSkils": [
                "Communication",
                "Collaboration"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "Saint-Gobain",
        "location": "Courbevoie, √éle-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/data-scientist-f-h-at-saint-gobain-3915274420?position=1&pageNum=10&refId=ROrjrJfuVI6x0QGlr%2BAc8w%3D%3D&trackingId=%2F2FvV7UgMcZfIHHeJLtYxA%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Why do we need you ?\nVous rejoindrez l‚Äô√©quipe ¬´ AI & Data Analytics ¬ª, int√©gr√©e au d√©partement ¬´Data & Analytics¬ª dans l‚Äôorganisation ¬´ Global Digital & IT¬ª. ¬´Data & Analytics¬ª regroupe les activit√©s suivantes :\nData Engineering, Data Capture & Delivery, BI & Visualization, Platform & Architecture, Data Governance and Data Engagement.\nAu Sein De L‚Äô√©quipe Data Science, Sous La Responsabilit√© Du Head Of AI & Data Analytics, Vous Aurez Le R√¥le De Data Scientist (H/F). En Tant Que Tel, Vous Aurez Les Responsabilit√©s Suivantes\nConstruire des mod√®les descriptifs et pr√©dictifs sur des sujets en constante √©volution ;\nMener des projets exploratoires faisant appel √† des techniques avanc√©es de Data Science (NLP, deep learning, Generative AI, apprentissage par renforcement ou par transfert), de fa√ßon autonome ou avec des partenaires externes ;\nAssurer une veille technologique permanente sur ces sujets ;\nParticiper √† l‚Äôindustrialisation des algorithmes en lien avec les √©quipes engineering bas√©e sur MLOps;\nAccompagner les √©quipes op√©rationnelles dans le d√©ploiement des algorithmes, notamment sur le volet analytics ;\nMener des ateliers d‚Äôid√©ation avec les √©quipes m√©tiers (industrie, marketing, ventes, logistique, e-commerce, finance, RH) pour identifier les opportunit√©s d‚Äôexploitation de la donn√©e et diffuser la culture data au sein de l‚Äôentreprise.\nSi vous recherchez des d√©fis passionnants, pouvant impacter des centaines de milliers de clients, et aimez travailler avec des outils √† la pointe de la technologie, venez et rejoignez-nous !\nVous participerez donc √† la mont√©e en puissance de l‚Äô√©quipe cr√©√©e r√©cemment, tout en intervenant sur un ou plusieurs cas d‚Äôutilisation.\nIs this job for you ?\nEn compl√©ment des missions √©voqu√©es, une r√©elle app√©tence pour la gestion et la facilitation de projet, avec une certaine aisance en termes de communication, seraient fortement appr√©ci√©es.\nNotre √©quipe ayant vocation √† travailler pour des clients internes pouvant √™tre bas√©s en France comme √† l‚Äô√©tranger, la maitrise de l‚Äôanglais (√©crite et orale) est obligatoire.\nProfil recherch√©\nIng√©nieur dipl√¥m√© d‚Äôune √©cole g√©n√©raliste (Centrale, X, Mines, ENS etc.) ayant au minimum 3 ann√©es d'exp√©rience apr√®s le dipl√¥me.\nGrande connaissance du Machine Learning, des statistiques et des probabilit√©s.\nSQL et Python, packages de ML: scikit, xgboost, keras\nExp√©rience de travail sur un cloud provider et savoir construire des data pipelines serait un plus\nGestion de code : Git, Gitlab, CI/CD\nMaitriser la mod√©lisation √† la fois pr√©dictive et descriptive\nSavoir impl√©menter des dashboards et autres outils de data viz\nPoss√©der de bonnes qualit√©s de communication : vous pouvez expliquer vos mod√®les clairement √† la fois √† des data analysts mais aussi √† des Directeurs G√©n√©raux ou des responsables op√©rationnels.\nEtre organis√©, structur√© et motiv√© par l‚Äôinnovation\nAimer le travail en √©quipe et savoir apprendre de chacun.\nUn √©tat d‚Äôesprit orient√© business et apport de valeur pour les √©quipes m√©tiers\nA Little More About Us\nSaint-Gobain est une entreprise fran√ßaise sp√©cialis√©e dans la production, la transformation et distribution de mat√©riaux.\nFond√©e en 1665 par Jean-Baptiste Colbert sous le nom de Manufacture royale des glaces, l'entreprise est pr√©sente dans soixante-sept pays et emploie en 2018 pr√®s de 180 000 personnes\nTo make sure nothing is forgotten\nD√©tails pratiques du r√¥le\nD√©but : D√®s que vous √™tes pr√™ts\nLocalisation : La Tour Saint-Gobain, La D√©fense\nContrat: CDI\nSaint-Gobain encourage la diversit√© des √©quipes et favorise notamment l‚Äôinclusion des personnes en situation de handicap.\nShow more\nShow less",
        "details": {
            "JobDetail": [],
            "TypeContract": "CDI",
            "Salary": "1665",
            "Level": "",
            "Experience": null
        },
        "title": "data scientist",
        "skills": {
            "ProgLanguage": [
                "Python"
            ],
            "DataBase": [
                "SQL"
            ],
            "MachineLearning": [
                "XGBoost",
                "Keras"
            ],
            "DevTools": [
                "Git"
            ],
            "Other": [
                "CI/CD",
                "ML",
                "Statistiques",
                "Machine Learning",
                "Cloud"
            ],
            "EnSoftSkils": [
                "Communication"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "Astek",
        "location": "Toulouse, Occitanie, France",
        "link": "https://fr.linkedin.com/jobs/view/ing%C3%A9nieur-machine-learning-%E2%80%93-toulouse-france-h-f-at-astek-3882495207?position=2&pageNum=10&refId=ROrjrJfuVI6x0QGlr%2BAc8w%3D%3D&trackingId=WRjL0Jtiuwpo%2FOQ1UEV%2FRg%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "CDI\nToulouse - France\nPubli√©e il y a 1 mois\nLe Groupe Astek\nCe Que Nous Allons Accomplir Ensemble :\nRejoignez nos √©quipes et intervenons ensemble sur les projets de nos partenaires autour des enheux d‚Äôinnovation.\nVotre Mission, Si Vous L‚Äôacceptez :\nCadrer techniquement les projets et accompagner les Data Scientists dans la construction des mod√®les en veillant √† respecter les bonnes pratiques d‚Äôing√©nierie logicielle.\nMettre en place la d√©marche ML OPS\nD√©ployer les mod√®les en production en respectant des contraintes de co√ªts, pr√©cisions et performances techniques.\nImpl√©menter les outils permettant de monitorer ces mod√®les en production\nVous ?\nVous √™tes issu(e) d‚Äôune formation Bac+5 (√âcole d‚Äôing√©nieur, Universit√© ou √©quivalent ‚Ä¶) en informatique\nVous justifiez d‚Äôune exp√©rience significative d‚Äôau moins 5 ans au sein d‚Äôune √©quipe dans un environnement Data √† l‚Äô√©chelle du SI d‚Äôun grand groupe\nVous √™tes un bon communiquant et disposez de capacit√©s d‚Äôanalyse et de synth√®se √©prouv√©es\nVous accordez de l‚Äôimportance √† la veille technologique\nComp√©tences Techniques :\nExpertise en SPARK et PySpark\nConnaissance de Kubernetes\nConnaissance de d‚ÄôApache Kafka\nUne exp√©rience sur un cloud provider public comme Azure (id√©alement), AWS, ou GCP\nExpertise de d√©veloppement en Python\nExpertise du ML OPS\nComp√©tences Transverses :\nCapacit√© √† interagir avec des parties prenantes diverses : Data Scientists, Business analyst, Architectes, M√©tier\nForte exp√©rience en mode de Delivery Agile (Scrum, Kanban, etc.‚Ä¶)\nEtre expert dans les pratiques du Software Craftsmanship (Test Driven, Development, Behavior Driven Development, Clean Code, Code Reviews, etc.)\nEt :\nDes Connaissances sur Azure DevOps, Azure Pipeline, GIT\nMaitrise des Traitements Big Data en mode Streaming\nMaitrise des Bases de donn√©es relationnelles et NoSQL\nUne exp√©rience professionnelle avec des outils comme Azure Databricks, Azure, Machine Learning , Azure Data Lake Storage ou encore Azure Data Factory\nLe Groupe Astek\nCr√©√© en France en 1988, Astek est un acteur mondial de l‚Äôing√©nierie et du conseil en technologies. Fort de son expertise dans de nombreux secteurs industriels et tertiaires, Astek accompagne ses clients internationaux dans le d√©ploiement intelligent de leurs produits et de leurs services, et dans la mise en ≈ìuvre de leur transformation digitale.\nDepuis sa cr√©ation, le Groupe a fond√© son d√©veloppement sur une forte culture d‚Äôentrepreneuriat et d‚Äôinnovation, et sur l‚Äôaccompagnement et la mont√©e en comp√©tence de\nses 7800 collaborateurs\nqui s‚Äôengagent chaque jour √† promouvoir la compl√©mentarit√© entre les technologies num√©riques et l‚Äôing√©nierie des syst√®mes complexes.\nRejoignez un Groupe en fort d√©veloppement en France et √† travers le monde ayant r√©alis√© un chiffre d‚Äôaffaires de 600 M‚Ç¨ en 2023.\nTous les d√©tails sur le Groupe sur le site https://astekgroup.fr. Et vous pouvez aussi nous suivre sur notre blog : https://blog.groupeastek.com.\nRencontrons-nous\nNotre projet commun vous plait ?\nPostulez √† cette annonce, et soyez transparent !\nNotre Talent Acquisition Officer, vous contactera pour un premier √©change t√©l√©phonique.\nPuis vous rencontrerez votre futur manager, avec lequel vous √©changerez autour d‚ÄôAstek, de votre parcours, de vos attentes et de votre future mission .\nEnfin, vous rencontrerez notre Directeur de d√©partement, avec lequel vous pourrez valider votre int√©r√™t et ad√©quation pour le poste et finaliser les √©l√©ments contractuels.\nNos Plus\nAstek est green et fait b√©n√©ficier ses salari√©s d‚Äôune indemnit√© kilom√©trique v√©lo\nUne politique CARE sur-mesure d√©ploy√©e par nos √©quipes RH pour nos collaborateurs (https://astekgroup.fr/engagements)\nNotre charte de la Diversit√©\nBienvenue dans la team ! Allez-y, maintenant c‚Äôest √† vous de jouer !\nMots-cl√©s :\ning√©nieur ‚Äì ing√©nieure ‚Äì consultant ‚Äì consultante\nCaract√©ristiques de l'emploi\nCat√©gorie Chef de Projet\nJob Industry A√©rospatial / D√©fense / S√©curit√©, Distribution / Services Internet, Energie / Sciences de la Vie / Autres industries, Finance / Gouvernement, T√©l√©com / M√©dia, Transports Terrestres\nPostuler en ligne\nNom *\nPr√©nom *\nEmail *\nUn email valide est requis.\nT√©l√©phone *\nUn num√©ro de t√©l√©phone valide est requis.\nJoindre un CV *\nMots-cl√©s :\ning√©nieur ‚Äì ing√©nieure ‚Äì consultant ‚Äì consultante\nShow more\nShow less",
        "details": {
            "JobDetail": [],
            "TypeContract": "CDI",
            "Salary": "",
            "Level": "Bac+5",
            "Experience": "5 an(s)"
        },
        "title": "Other",
        "skills": {
            "ProgLanguage": [
                "Python"
            ],
            "DataBase": [
                "NoSQL"
            ],
            "BigData": [
                "Databricks",
                "Spark"
            ],
            "CloudComputing": [
                "GCP",
                "AWS",
                "Azure"
            ],
            "DevTools": [
                "Git"
            ],
            "SoftBigDataProcessing": [
                "Apache Kafka"
            ],
            "Automation": [
                "Chef",
                "Kubernetes"
            ],
            "Containers": [
                "Kubernetes"
            ],
            "Other": [
                "ML",
                "Big Data",
                "Machine Learning",
                "Cloud",
                "DevOps"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "STATION F",
        "location": "Paris, √éle-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/data-scientist-en-alternance-f-h-at-station-f-3866142994?position=3&pageNum=10&refId=ROrjrJfuVI6x0QGlr%2BAc8w%3D%3D&trackingId=XRHu3V%2BdRnK1q%2ByA7U6m3A%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "√Ä propos\nWalter Learning con√ßoit, produit et diffuse des formations en ligne √† destination des professionnels, sous plusieurs marques :\nWalter Learning : formations g√©n√©ralistes (HACCP, bureautique, web & digital, etc.) et formations longues (CAP...)\nWalter Sant√© : formations sp√©cialis√©es pour les m√©decins, kin√©s, infirmiers, dentistes, sages-femmes...\nLe pari de Walter Learning, c‚Äôest de proposer un nouveau mod√®le de formation professionnelle, offrant la flexibilit√© et la cr√©ativit√© du e-learning, coupl√©es √† la rigueur et la justesse attendues par les professionnels.\nLeur Savoir-faire Se Situe Dans L‚Äôalliance Des Sciences De L‚Äô√©ducation, Du Digital Et De L‚Äôaudiovisuel. Walter Learning C‚Äôest\nDes formations denses, o√π chaque mot est pes√©,\nDes formateurs reconnus ;\nUne plateforme d‚Äôapprentissage cod√©e-maison, facile d‚Äôutilisation ;\nUn apprentissage souple, sans contraintes ;\nUn support apprenants aux petits soins.\nWalter Learning a commenc√© √† commercialiser son produit en mai 2019. Depuis, l‚Äôentreprise a d√©montr√© une croissance tr√®s forte, sur un march√© gigantesque, puisqu'elle a vendu plus de 80 000 formations √† fin 2023. Walter Learning est autofinanc√©e et rentable.\nDescriptif du poste\nWalter Learning recherche pour le compte des d√©partements IT de ses partenaires, des data scientists en alternance.\nLes Missions Sont Les Suivantes\nTraiter les donn√©es et construire et entra√Æner des algorithmes\nElaborer des mod√®les pr√©dictifs\nFournir des outils d'aide √† la d√©cision et recommendations strat√©giques aux √©quipes m√©tiers\nLes Comp√©tences Que Vous Allez D√©velopper\nCompr√©hension des enjeux business & marketing\nAisance avec les donn√©es chiffr√©es et la mod√©lisation de donn√©es\nLangages de programmation et de requ√™tage\nForte orientation business et use cases\nModalit√©s De L‚Äôalternance\nContrat de 12 mois\n1 jour par semaine en formation\nR√©mun√©ration en fonction de votre profil\nProfil recherch√©\nPas de dipl√¥me requis\nForte app√©tence pour les outils informatiques et les chiffres\nInformations compl√©mentaires\nType de contrat : Alternance (12 √† 12 mois)\nLieu : Paris\nNiveau d'√©tudes : Sans dipl√¥me\nExp√©rience :\nSalaire : entre 760‚Ç¨ et 1760‚Ç¨ / an\nShow more\nShow less",
        "details": {
            "JobDetail": [],
            "TypeContract": "",
            "Salary": "760",
            "Level": "",
            "Experience": null
        },
        "title": "data scientist",
        "skills": {}
    },
    {
        "source": "LinkedIn",
        "company": "Dataiku",
        "location": "Paris, √éle-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/data-scientist-france-paris-at-dataiku-3834882798?position=4&pageNum=10&refId=ROrjrJfuVI6x0QGlr%2BAc8w%3D%3D&trackingId=G6x%2FIbjWQ8tK0Jod1hOoxA%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "At Dataiku, we're not just adapting to the AI revolution, we're leading it. Since our beginning in Paris in 2013, we've been pioneering the future of AI with a platform that makes data actionable and accessible. With over 1,000 teammates across 25 countries and backed by a renowned set of investors, we're the architects of Everyday AI, enabling data experts and domain experts to work together to build AI into their daily operations, from advanced analytics to Generative AI.\nHeadquartered in New York City, Dataiku was founded in Paris in 2013 and achieved unicorn status in 2019. Now, more than 1,300 employees work across the globe in our offices and remotely. Backed by a renowned set of investors and partners including CapitalG, Tiger Global, and ICONIQ Growth, we‚Äôve set out to build the future of AI.\nThe role of a Data Scientist at Dataiku is unique. Our Data Scientists not only develop solutions to real-world problems but also participate in client-facing endeavors throughout the customer journey. This includes supporting their discovery of the platform, helping integrate Dataiku with other tools and technologies, providing user training, and co-developing data science projects from design to deployment.\nJust as the non-technical skills are important, so too are the technical. Our Data Scientists work on the Dataiku platform daily. Aside from the visual tools, our team uses mostly Python, with occasional work in other languages (e.g., R, SQL, Pyspark, JavaScript, etc.). An ideal candidate is excited to teach data science and how to use the Dataiku platform to customers, and learn about new technologies.\nHow you'll make an impact\nHelp users discover and master the Dataiku platform, via user training, office hours, demos, and ongoing consultative support.\nAnalyze and investigate various kinds of data and machine learning applications across industries and use cases.\nProvide strategic input to the customer and account teams that help make our customers successful.\nScope and co-develop production-level data science projects with our customers.\nMentor and help educate data scientists and other customer team members to aid in career development and growth.\nWhat you'll need to be successful\nCuriosity and a desire to learn new technical skills.\nEmpathy and an eagerness to share your knowledge with your colleagues, Dataiku‚Äôs customers, and the general public.\nAbility to clearly explain complex topics to technical as well as non-technical audiences.\nOver 3 years of experience with coding (Python, R, SQL).\nOver 3 years of experience building ML models.\nUnderstanding of underlying data systems and platform mechanics such as Cloud architectures, K8S, Spark, and SQL.\nWhat will make you stand out\nExperience with Consulting and/or Customer-facing Data Science roles.\nExperience with Data Engineering or MLOps.\nExperience developing WebApps in Javascript, RShiny, or Dash.\nExperience building APIs.\nExperience using enterprise data science tools.\nPassion for teaching or public speaking.\nBenefits\nExposure to a wide range of enterprise customers across industries. Examples of Dataiku‚Äôs hundreds of customers include GE, Unilever, Comcast, Ubisoft, OVH, Santander, and Capgemini.\nA wide diversity of projects.\nOpportunity to contribute to the core vision of our company and product: simplify and democratize the way people work with data and use Artificial Intelligence.\nExposure to the latest, open-source technologies that Dataiku integrates. See our release notes for our latest developments: https://doc.dataiku.com/dss/latest/release_notes/index.html\nOpportunity to work with a smart, passionate, and driven team in hypergrowth mode.\nDataiku has a strong culture based on key values: Transparency, Ambition, Excellence, Humility, and Empathy.\nWhat are you waiting for!\nAt Dataiku, you'll be part of a journey to shape the ever-evolving world of AI. We're not just building a product; we're crafting the future of AI. If you're ready to make a significant impact in a company that values innovation, collaboration, and your personal growth, we can't wait to welcome you to Dataiku! And if you‚Äôd like to learn even more about working here, you can visit our Dataiku LinkedIn page .\nOur practices are rooted in the idea that everyone should be treated with dignity, decency and fairness. Dataiku also believes that a diverse identity is a source of strength and allows us to optimize across the many dimensions that are needed for our success. Therefore, we are proud to be an equal opportunity employer. All employment practices are based on business needs, without regard to race, ethnicity, gender identity or expression, sexual orientation, religion, age, neurodiversity, disability status, citizenship, veteran status or any other aspect which makes an individual unique or protected by laws and regulations in the locations where we operate. This applies to all policies and procedures related to recruitment and hiring, compensation, benefits, performance, promotion and termination and all other conditions and terms of employment. If you need assistance or an accommodation, please contact us at: reasonable-accommodations@dataiku.com\nShow more\nShow less",
        "details": {
            "JobDetail": [
                "Remote"
            ],
            "TypeContract": "",
            "Salary": "",
            "Level": "",
            "Experience": null
        },
        "title": "data scientist",
        "skills": {
            "ProgLanguage": [
                "R",
                "Python"
            ],
            "DataBase": [
                "SQL"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [
                "Spark"
            ],
            "Collaboration": [
                "Teams"
            ],
            "Other": [
                "Machine Learning",
                "Cloud",
                "ML"
            ],
            "EnSoftSkils": [
                "Empathy",
                "Collaboration"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "DxO Labs",
        "location": "Boulogne-Billancourt, √éle-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/data-scientist-at-dxo-labs-3915441544?position=5&pageNum=10&refId=ROrjrJfuVI6x0QGlr%2BAc8w%3D%3D&trackingId=cVwmZ3kTveoq20zyIGTRzw%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "En 20 ans, DxO Labs s‚Äôest affirm√©e comme l‚Äôune des entreprises fran√ßaises les plus innovantes du secteur de la photographie num√©rique et du traitement d‚Äôimage.\nNous concevons et commercialisons des logiciels d‚Äô√©dition photo avanc√©e pour les photographes, amateurs ou experts. Nos solutions, issues de l‚Äôexcellence et du savoir-faire incomparable de nos √©quipes d‚Äôexperts internationales et multiculturelles, offrent les outils de correction et de traitement les plus performants.\nDxO Labs s‚Äôappuie depuis toujours sur l‚Äôexcellence et le savoir-faire incomparable de ses √©quipes d‚Äôexperts internationales et multiculturelles.\nSi vous souhaitez vous projeter et d√©couvrir nos produits; cliquez sur https://www.dxo.com/fr/\nAfin de renforcer notre √©quipe R&D, nous recrutons, dans le cadre d‚Äôun contrat en CDI plein temps un\nData Scientist\nBas√© √† notre si√®ge social de Boulogne-Billancourt et rapportant au Directeur Traitement Images.\nAu sein de notre √©quipe R&D Image et en √©troite collaboration avec nos √©quipes UX et produit, votre r√¥le sera de nous aider √† doter nos logiciels fonctionnalit√©s IA innovantes bas√©es sur l‚Äôanalyse d‚Äôune grande quantit√© de donn√©es.\nVos missions :\nAvec nos product managers et nos chercheurs en traitement d‚Äôimage, d√©finir de nouvelles fonctionnalit√©s utilisateur.\nConstituer les bases d‚Äôapprentissage n√©cessaires.\nConcevoir, impl√©menter et entrainer des mod√®les de deep learning.\nEvaluer ces mod√®les gr√¢ce √† des prototypes.\nAider nos experts logiciel √† int√©grer ces nouvelles fonctionnalit√©s utilisateur dans nos produits.\n√ätre au fait des derni√®res recherches et m√©thodes au croisement entre la data science, la vision par ordinateur et la retouche photo.\nVotre profil :\nAu moins 5 ans d'exp√©rience en tant que Data Scientist, de pr√©f√©rence dans le secteur technologique ou des logiciels\nDeep learning (connaissances √† jour par rapport √† l‚Äô√©tat de l‚Äôart en 2024)\nPython, PyTorch\nAu moins B2 en Anglais et Fran√ßais\nCapacit√© √† travailler de mani√®re autonome et en √©quipe, avec un esprit curieux et tourn√© innovation\nId√©alement\nConnaissance en Traitement d‚Äôimage (p.ex. analyse s√©mantique, g√©n√©ration d'images)\nTraitement de la langue (LLM)\nTensorFlow, AWS, WinML, CoreML, C++\nUn vrai + : Passionn√© de photographie\nSi vous vous retrouvez dans le descriptif candidat : Postulez sans attendre sur recruit@dxo.com\nNous verrons ensemble si vos comp√©tences et votre savoir-√™tre correspondent √† notre ADN\nLocalisation :\nBas√© √† Boulogne-Billancourt (M√©tro 9 station Billancourt ‚Äì Tramway T2 station Les Moulineaux),\nT√©l√©travail possible √† hauteur de 2j/semaine\nShow more\nShow less",
        "details": {
            "JobDetail": [],
            "TypeContract": "CDI",
            "Salary": "",
            "Level": "",
            "Experience": "20 an(s)"
        },
        "title": "data scientist",
        "skills": {
            "ProgLanguage": [
                "R",
                "Python"
            ],
            "DataAnalytics": [
                "R"
            ],
            "MachineLearning": [
                "PyTorch",
                "TensorFlow"
            ],
            "CloudComputing": [
                "AWS"
            ],
            "EnSoftSkils": [
                "Collaboration"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "Akademija Oxford",
        "location": "Paris, √éle-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/apprenti-data-engineer-h-f-at-akademija-oxford-3917872047?position=6&pageNum=10&refId=ROrjrJfuVI6x0QGlr%2BAc8w%3D%3D&trackingId=4gk%2BRvymD0ZVk4UUg9SAvQ%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Une de nos entreprises partenaires, ESN situ√©e √† Paris, recherche un Apprenti Data Engineer (H/F) pr√©parant un bac +4/+5 sp√©cialit√© Big Data pour la rentr√©e de Septembre 2021.\nShow more\nShow less",
        "details": {
            "JobDetail": [],
            "TypeContract": "",
            "Salary": "",
            "Level": "",
            "Experience": null
        },
        "title": "data engineer",
        "skills": {
            "Other": [
                "Big Data"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "Harry Hope.",
        "location": "Nancy, Grand Est, France",
        "link": "https://fr.linkedin.com/jobs/view/data-scientist-h-f-at-harry-hope-3917429026?position=7&pageNum=10&refId=ROrjrJfuVI6x0QGlr%2BAc8w%3D%3D&trackingId=jB%2B5Iyl6zoMF0wk8bs%2BmKQ%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Jean, consultant sp√©cialis√© sur les m√©tiers de l'IT sur la lorraine au sein du cabinet de recrutement Harry Hope accompagne les candidats dans leurs recherches d'une meilleure opportunit√© professionnelle sur leur secteur g√©ographique privil√©gi√©. Nous ne sommes pas une ESN, nous intervenons dans la mise en relation avec des clients finaux sur des postes en CDI. Notre client, une soci√©t√© en pleine croissance dans le secteur de l'IA, recherche un Data Scientist (H/F) pour compl√©ter son √©quipe d√©di√©e.\nInt√©gr√© √† une √©quipe technique compos√©e de Data scientist, de d√©veloppeurs et de chercheurs, vous aurez l'occasion d'intervenir dans la r√©cup√©ration, l'exploitation, la mod√©lisation, l'√©valuation et l'interpr√©tation de donn√©es stock√©es dans les bases de donn√©es de la structure permettant de les exploiter selon les besoins. En parall√®le de vos missions concernant les donn√©es propre √† l'activit√© principale de l'entreprise, vous intervenez √©galement dans l'exploitation et la structuration des datas r√©cup√©r√©es sur internet en lien avec l'IA en cours de d√©veloppement.\nDipl√¥m√© en informatique, vous disposez √† minima d'une premi√®re exp√©rience √† un poste similaire (alternance ou premier emploi). Techniquement, vous avez une grande expertise en statistiques et en math√©matiques appliqu√©es. Vous maitrisez les domaines du Big Data, du machine learning et de la programmation informatique (Python, Java, R, SQL). Humainement, vous √™tes reconnu pour votre dynamisme, votre flexibilit√© et votre engagement. Vous √™tes capable de vous impliquer √† fond dans les projets qui vous sont confi√©s et vous appr√©ciez le travail collaboratif. Passionn√© par la Data, vous assurez une veille constante sur les nouvelles technologies en lien avec votre activit√©. Enfin, vous maitrisez l'anglais √† l'oral comme √† l'√©crit.\nInformations compl√©mentaires : Salaire selon profil et exp√©riences (38/42kEUR), possibilit√© d'√©voluer rapidement, CDI √† pouvoir rapidement √† Nancy.\nSi cette opportunit√© correspond √† vos aspirations professionnelles alors faites-moi parvenir votre candidature. J'√©tudierai cette derni√®re et reviendrai vers vous dans les meilleurs d√©lais pour un suivi personnalis√© de votre profil !\nShow more\nShow less",
        "details": {
            "JobDetail": [],
            "TypeContract": "CDI",
            "Salary": "38",
            "Level": "",
            "Experience": null
        },
        "title": "data scientist",
        "skills": {
            "ProgLanguage": [
                "R",
                "Java",
                "Python"
            ],
            "DataBase": [
                "SQL"
            ],
            "DataAnalytics": [
                "R"
            ],
            "Other": [
                "Statistiques",
                "Machine Learning",
                "Big Data"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "METEOJOB by CleverConnect",
        "location": "Nantes, Pays de la Loire, France",
        "link": "https://fr.linkedin.com/jobs/view/data-scientist-h-f-at-meteojob-by-cleverconnect-3913467533?position=8&pageNum=10&refId=ROrjrJfuVI6x0QGlr%2BAc8w%3D%3D&trackingId=%2FUirevN8WueqM8NT%2F1oqpQ%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Entreprise\niziwork est une agence de recrutement d'int√©rim totalement digitalis√©e, s'appuyant sur l'innovation technologique pour am√©liorer radicalement l'acc√®s √† l'exp√©rience du travail pour tous. Elle offre aux travailleurs un acc√®s simple et instantan√© √† un grand choix de jobs mais aussi un accompagnement personnalis√© au fil des missions qui donne du sens au m√©rite individuel. En rupture avec les pratiques du march√©, iziwork offre une approche ¬´ worker centric ¬ª pour attirer et valoriser les personnes fiables et comp√©tentes en recherche d'emploi.\nDescription Du Poste\nIziwork est une agence de recrutement digital qui s√©lectionne les meilleures missions et offres d'emploi pour les centaines de milliers d'int√©rimaires et candidats qu'elle a d√©j√† s√©duits. Postulez en quelques minutes, g√©rez votre contrat en un clin d'oeil depuis notre app et b√©n√©ficiez du suivi personnalis√© de votre recruteur au quotidien.\n√Ä propos de la mission\nOrganiser et conduire les ateliers de construction des mod√®les de donn√©es pour chaque r√©f√©rentiel groupe\nAccompagner les m√©tiers √† la d√©finition des r√®gles d'archivage, de gestion et de contr√¥le qualit√©\nAssurer les contr√¥les pr√©liminaires de coh√©rence des donn√©es\nAccompagner l'administrateur des donn√©es au transcodage des r√®gles de contr√¥le qualit√© dans Talend\nAssurer les contr√¥les pr√©liminaires de coh√©rence des donn√©es\nParticiper au processus de migration des donn√©es dans l'ERP cible en accompagnant les m√©tiers √† l'identification des √©carts et √† la mise en conformit√© des data dans la/les solutions cible\nIdentifier les incoh√©rences avec l'architecture et participer √† la synchronisation de l'int√©grit√© des flux\nAssurer la supervision et l'int√©gration des donn√©es de diverses natures et v√©rifier la qualit√© des donn√©es qui entrent dans le Data Lake\nStructurer le cycle de vie de la donn√©e dans le respect des r√©glementations RGPD & ISO24143\nR√©mun√©ration & Avantages\nR√©mun√©ration : 40‚ÄØ000 ‚Ç¨ - 50‚ÄØ000 ‚Ç¨ par an\nProfil recherch√©\nIssu(e) d'une formation en Informatique de niveau BAC+2/+3, vous disposez d'une exp√©rience similaire de 2 √† 3 ans id√©alement en milieu industriel ou SSI.\nVous poss√©dez une premi√®re exp√©rience de gestion de projet informatique, vous savez animer des ateliers.\nTr√®s organis√©(e), rigoureux(se), r√©actif(ve), vous savez g√©rer les priorit√©s.\nVotre sens du service et votre aisance relationnelle vous permettent d'instaurer un climat de confiance avec vos diff√©rents interlocuteurs.\nVous maitrisez les langages informatiques suivants : Java, Python, SQL. Connaissances souhait√©es d'un outil MDM (Talend, Tibco) et d'un ETL.\nVous b√©n√©ficiez d'une bonne ma√Ætrise d'Excel.\nNotre environnement international requiert la ma√Ætrise de l'anglais √† un niveau B2 minimum (interm√©diaire - avanc√©).\nExp√©rience : Entre 24 mois et 5 ans\nCertificats requis\nAucun certificat requis\nShow more\nShow less",
        "details": {
            "JobDetail": [],
            "TypeContract": "",
            "Salary": "",
            "Level": "",
            "Experience": "3 an(s)"
        },
        "title": "data scientist",
        "skills": {
            "ProgLanguage": [
                "Java",
                "Python"
            ],
            "DataBase": [
                "SQL"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "Thales",
        "location": "Lyon, Auvergne-Rh√¥ne-Alpes, France",
        "link": "https://fr.linkedin.com/jobs/view/data-engineer-h-f-at-thales-3903089036?position=9&pageNum=10&refId=ROrjrJfuVI6x0QGlr%2BAc8w%3D%3D&trackingId=mivaVROT2FYn%2Bm2U%2B3mpHg%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "üì¢ Nous recherchons un(e) Data Engineer, bas√©(e) √† Lyon\nüëâQuelques mots sur les activit√©s num√©riques de Thales Lyon :\nLes activit√©s num√©riques repr√©sentent une entit√© rattach√©e au groupe Thales, sp√©cialis√©e dans l‚ÄôIT et pr√©sente au national.\nL‚Äôagence de Lyon adresse divers sujets d‚Äôexpertise : ing√©nierie logiciels, cybers√©curit√©, infog√©rance des infrastructures et transformation digitale.\nüéØ\nVotre r√¥le et missions\nEn nous rejoignant, vous int√©grerez le centre de comp√©tences\nAugmented data\n,\nsp√©cialis√© dans la conception, le d√©veloppement et l‚Äô√©volution d‚Äôapplications data centr√©es. Vous y boosterez votre carri√®re en travaillant sur des technologies telles que\nSpark, Elasticsearch, Kube ...\nle plus souvent dans un environnement\nAgile\n.\nDans le cadre des projets que nous op√©rons aujourd‚Äôhui :\n- Vous contribuerez √† la conception, au maintien, √† la scalabilit√© des plateformes d‚Äôanalyse de donn√©es au travers de votre expertise sur les sujets data (base de donn√©es, gestion de flux, ETL ‚Ä¶)\n- Vous contribuerez √† la conception et √† la mise en production des pipelines d‚Äôanalyses et de transformations de donn√©es en veillant √† leur bonne adaptation aux besoins m√©tiers et aux contraintes techniques du client\n- Vous pourrez intervenir sur des sujets de visualisations, dans le but de notamment accompagn√©es nos clients sur la conception de Dashboard m√©tier intelligent ‚Ä¶\n- Vous serez √©galement amen√©es √† √©changer directement avec des DevOps/Datascientist pour la mise en place, l‚Äôint√©gration des pipelines et l‚Äô√©laboration des algorithmes de traitements de donn√©es.\n- A l‚Äô√©chelle du d√©partement, Vous serez un acteur majeur du d√©veloppement de notre activit√© et du lancement de nouveaux projets de valorisation de donn√©es.\nüôã‚Äç‚ôÄÔ∏è üôã‚Äç‚ôÇÔ∏è\nVotre profil\nDe formation Bac +5 en informatique (√©cole d‚Äôing√©nieur, Master ou √©quivalent), vous justifiez d‚Äôune premi√®re exp√©rience r√©ussie sur un projet data ? Vous souhaitez participer √† la conception et intervenir sur des solutions de r√©cup√©ration et d‚Äôexploitation de donn√©es m√©tiers dans des contextes critiques et hautement s√©curis√©s ?\nAutonome, dynamique, organis√©(e) et proactif(ve), vous souhaitez √©voluer au sein d‚Äô√©quipes passionn√©es par l‚Äôexploration et l‚Äôint√©gration des technologies nouvelles au service des m√©tiers de nos clients ?\nVous avez des comp√©tences qui couvrent les domaines suivants :\nMise en place et gestion de base de donn√©es (SQL, Elasticsearch, Clickhouse ...)\nLangages de programmations (Java, Python)\nGestion de flux (Kafka, flink, logstash ‚Ä¶)\nEnvironnements big Data (Spark/hadoop )\nPrincipes et outils de type ETL\nVous √™tes de plus int√©ress√©(e):\nPar les environnements containeris√©s (docker, kubernetes, helm ...)\nLes concepts DevOps (Ansible, CI/CD...)\nLes sujets de Datavisualisation (Vega, Kibana, python librairies...)\nVous aimez travailler en √©quipe ? Vous √™tes reconnu(e) pour vos qualit√©s relationnelles et vos capacit√©s de vulgarisation ?\nAlors notre poste d‚ÄôIng√©nieur(e) Data(H/F) est fait pour vous !\nüôå\nVotre carri√®re chez Thales\nDiff√©rentes opportunit√©s vous permettront de d√©couvrir d'autres domaines ou sites. Vous pourrez √©voluer et d√©velopper vos comp√©tences dans diff√©rents domaines.\nExplorez un espace attentif au d√©veloppement personnel.\nD√©veloppez vos talents dans un autre domaine du groupe Thales, en d√©couvrant de nouveaux produits, de nouveaux clients, un nouveau pays ou en vous orientant vers une solution plus complexe.\nChoisissez entre une expertise technique ou un parcours de leadership.\nVous travaillerez dans une entreprise r√©solument humaine avec des valeurs fortes comme la s√©curit√© au travail, l‚Äô√©galit√© Homme/Femme et l‚Äô√©quilibre vie personnelle/professionnelle (Accord T√©l√©travail).\nRattach√©(e) √† la Convention m√©tallurgie, vous b√©n√©ficierez aussi de ses multiples avantages (‚Ä¶)\nVous souhaitez en savoir plus ?\nN‚Äôh√©sitez pas √† contacter notre √©quipe de recrutement ou nos √©quipes directement.\nShow more\nShow less",
        "details": {
            "JobDetail": [],
            "TypeContract": "",
            "Salary": "",
            "Level": "",
            "Experience": null
        },
        "title": "data engineer",
        "skills": {
            "ProgLanguage": [
                "Java",
                "Python"
            ],
            "DataBase": [
                "Elasticsearch",
                "SQL"
            ],
            "BigData": [
                "Hadoop",
                "Flink",
                "Spark"
            ],
            "DevTools": [
                "Docker"
            ],
            "Automation": [
                "Kubernetes",
                "Ansible"
            ],
            "Containers": [
                "Docker",
                "Kubernetes"
            ],
            "Other": [
                "Big Data",
                "DevOps",
                "CI/CD"
            ],
            "EnSoftSkils": [
                "Leadership"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "Viveris",
        "location": "Strasbourg, Grand Est, France",
        "link": "https://fr.linkedin.com/jobs/view/data-scientist-h-f-at-viveris-3916481860?position=10&pageNum=10&refId=ROrjrJfuVI6x0QGlr%2BAc8w%3D%3D&trackingId=5wOoX6oqT1kpAJ%2FWD8aPEw%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Viveris est un groupe de conseil et d'ing√©nierie sp√©cialis√© dans la conduite et la r√©alisation de projets dans les domaines de l'informatique et de l'√©lectronique.\nS'engager avec Viveris, c'est l'assurance de relever des d√©fis techniques et humains tout en travaillant sur des projets innovants dans un environnement collaboratif et solidaire.\nNotre client, entreprise du secteur a√©ronautique recherche un Data Scientist pour rejoindre son √©quipe.\nResponsabilit√©s :\nComprendre les probl√®mes commerciaux et concevoir des cas d'analyse de bout en bout;\nD√©velopper des mod√®les et des algorithmes complexes qui stimulent l'innovation dans toute l'organisation. Cela peut inclure l'am√©lioration de la ponctualit√©, la maximisation des profits, etc;\nEffectuer des analyses statistiques avanc√©es pour fournir des informations exploitables, identifier les tendances et mesurer les performances;\nGuider les efforts d'ing√©nierie des donn√©es pour assurer l'alignement avec les futurs besoins en science des donn√©es;\nCollaborer avec les ing√©nieurs pour mettre en oeuvre et d√©ployer des solutions √©volutives.\nProfil recherch√© :\nDe formation Bac+5 √† Bac+8 en informatique, statistiques, √©conomie ou math√©matiques, vous avez 1 √† 4 ans d'exp√©rience dans un r√¥le similaire (ou 5 √† 10 ans pour un poste senior).\nComp√©tences techniques :\nConnaissance approfondie de l'apprentissage automatique, des statistiques, de l'optimisation ou d'un domaine connexe;\nExp√©rience avec Python, SQL, Spark, Pandas, Numpy, SciPy, Statsmodels, Stan, pymc3, Caret, Scikit-learn, Keras, TensorFlow, Pytorch;\nUne exp√©rience en programmation en C, C++, Java est un atout;\nExp√©rience avec MLOps et travail avec de grands ensembles de donn√©es, notamment (Map/Reduce, Hadoop, Hive, Spark,).\nUn bon niveau d'anglais est n√©cessaire.\nNos avantages :\nR√©mun√©ration attractive et √©volutive, mutuelle familiale √† garantie haute;\nTickets restaurant pris en charge √† 60%, 100% titre de transport urbain rembours√©;\nPrimes d'int√©ressement, de participation et de cooptation;\n2 jours de t√©l√©travail par semaine;\nFormation continue avec LinkedIn Learning et nos communaut√©s techniques.\n20620401-55584\nShow more\nShow less",
        "details": {
            "JobDetail": [
                "Senior"
            ],
            "TypeContract": "",
            "Salary": "",
            "Level": "Bac+5",
            "Experience": "4 an(s)"
        },
        "title": "data scientist",
        "skills": {
            "ProgLanguage": [
                "Java",
                "Python"
            ],
            "DataBase": [
                "SQL"
            ],
            "DataAnalytics": [
                "NumPy",
                "Pandas"
            ],
            "BigData": [
                "Hadoop",
                "Spark"
            ],
            "MachineLearning": [
                "Scikit-Learn",
                "PyTorch",
                "TensorFlow",
                "Keras"
            ],
            "Other": [
                "Statistiques"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "Air France",
        "location": "Provence-Alpes-C√¥te d'Azur, France",
        "link": "https://fr.linkedin.com/jobs/view/data-engineer-d%C3%A9veloppeur-big-data-%23-h-f-at-air-france-3900080172?position=1&pageNum=12&refId=g33qv%2BeUV9twrCN4MQzIIw%3D%3D&trackingId=%2FMLTUCYHAAbvlOAcpCN1%2Fw%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Description du poste\nIntitul√© du poste\nData Engineer / D√©veloppeur Big Data # H/F\nM√©tier\nSyst√®mes d'informations - D√©veloppement\nCat√©gorie socio-professionnelle\nCadre\nPr√©sentation du contexte\nVous avez peut-√™tre d√©j√† voyag√© avec nous, mais que connaissez-vous de nos m√©tiers et de la richesse des donn√©es qu‚Äôils g√©n√®rent au quotidien ? Comment le traitement et l‚Äôexploitation de ces donn√©es peut contribuer √† notre strat√©gie de Revenue Management, ou encore aux multiples op√©rations √† r√©aliser pour permettre √† un vol de partir √† l‚Äôheure ?\nAir France-KLM fait r√™ver 104 millions de passagers par an, en les emmenant vers plus de 250 destinations, gr√¢ce √† une flotte de plus de 500 appareils. Le Groupe emploie 80 000 collaborateurs partout dans le monde :les opportunit√©s sont vastes pour mettre √† profit ses comp√©tences, apprendre et se d√©velopper !\nLe d√©partement de d√©veloppement DATA, OR & AI d‚ÄôAir France, au sein de la direction des Syst√®mes d‚ÄôInformation, intervient dans toute la cha√Æne de captation et de traitement des donn√©es du groupe pour d√©livrer √† nos m√©tiers des solutions applicatives cl√©s en main.\nLe d√©partement est √©galement en charge de l‚Äôensemble des outils techniques (ETL, DataLakes, DataWarehouses, Data visualisation) et du d√©veloppement des talents et comp√©tences de Data Engineering.\nNotre mission ? Transformer la donn√©e brute en d√©cision intelligente, pour mieux optimiser les m√©tiers d‚ÄôAir France ‚Äì KLM !\nPour cela, nous avons chacun un r√¥le essentiel √† jouer, pourquoi le v√¥tre ne serait pas celui de Data Engineer et de d√©veloppeur Big Data ?\nDescription de la mission\nAu sein de notre d√©partement, vous travaillerez main dans la main avec d‚Äôautres Data Engineers et d√©veloppeurs Big Data ainsi qu‚Äôavec des sp√©cialistes des m√©tiers.\nInt√©gr√© au sein d‚Äôune product team agile passionn√©e et dynamique :\nVous participez √† l‚Äôanalyse des besoins m√©tiers du commercial, des op√©rations a√©riennes, de l‚Äôexploitation sol en a√©roport, de la maintenance a√©ronautique ou encore du Cargo.\nVous contribuez √† la d√©finition, au d√©veloppement, √† l‚Äôindustrialisation et √† la maintenance d‚Äôapplications Big Data ou en Business Intelligence\nVous pr√©sentez la restitution de vos travaux et accompagnez les utilisateurs d‚Äôun point de vue fonctionnel ou m√©thodologique\nVous serez en contact avec les directions m√©tier du groupe Air France KLM.\nNous attachons beaucoup d'importance au d√©veloppement des comp√©tences de nos collaborateurs ainsi qu‚Äô√† leur offrir des conditions de travail favorables √† l‚Äôautonomie et aux missions √† forte valeur ajout√©e. L'ouverture, le respect, la bienveillance et le partage sont des valeurs humaines port√©es par l'entreprise.\nProfil recherch√©\nVous √™tes dipl√¥m√© de niveau Master ou Ing√©nieur dans les domaines informatiques, vous avez acquis une exp√©rience professionnelle dans le d√©veloppement d‚Äôapplications.\nVous disposez d‚Äôune exp√©rience du d√©veloppement indispensable en Backend / Java\nVous ma√Ætrisez les bases de donn√©es relationnelles et le langage SQL\nEn Compl√©ment, Vous Avez Une Connaissance Ou Une Exp√©rience Dans Tout Ou Partie Des Concepts Ou Outils Suivants\nEnvironnement Big Data (Spark, Hadoop, Elasticsearch, Kafka, ...)\nBase de donn√©es noSQL (MongoDB, HBase, REDIS) ou Data Warehouse Teradata\nOutil de Datavisualisation (Spotfire, PowerBI, Qlik ou Kibana)\nSolutions de Cloud (GCP) et hybride (GCP / AZURE)\n(Ces comp√©tences compl√©mentaires ou manquantes pouvant aussi s'acqu√©rir √† travers un parcours de reskilling et de formations aux outils du data engineering dispens√© en interne).\nVous avez particip√© √† des projets organis√©s en Scrum ou Kanban, et avez peut-√™tre m√™me ≈ìuvr√© comme Scrum-Master, ce qui vous permettra de vous int√©grer ais√©ment au sein d‚Äôune Product Team. Votre esprit de synth√®se, votre force de conviction et votre ma√Ætrise de la communication facilitent les d√©cisions avec l‚Äôensemble des collaborateurs de l‚Äô√©quipe, √©ventuellement en langue anglaise, √† l‚Äô√©crit comme √† l‚Äôoral.\nVous √™tes autonome, rigoureux(se), responsable et curieux(se), vous aimez travailler en √©quipe. Vous poss√©dez de bonnes capacit√©s d'√©coute, d'analyse, de synth√®se et de communication.\nEt bien s√ªr, vous √™tes passionn√©(e), enthousiaste et ing√©nieux(se)\nCe que nous vous offrons\nDe la cr√©ation de valeur pour l‚Äôensemble des m√©tiers d‚ÄôAir France KLM\nDes challenges et probl√©matiques complexes √† r√©soudre\nL‚Äôopportunit√© de d√©ployer des solutions Data industrielles √† l‚Äô√©chelle !\nUne grande part de responsabilit√© dans une structure hi√©rarchique horizontale\nUn important degr√© de libert√© pour apprendre et d√©velopper son expertise au sein de l‚Äô√©quipe\nOn vous attend le plus rapidement possible ! Et pour une dur√©e ind√©termin√©e ;)\nType de contrat\nCDI\nTemps partiel possible\nNon\nType d'horaires\nAdministratif\nProfil candidat\nNiveau d'√©tudes min. requis\nBac + 5 et plus\nLangue\nAnglais (4 - Confirm√© / C1)\nLocalisation du poste\nLocalisation du poste\nFrance, Provence-Alpes-C√¥te d'Azur, Alpes Maritimes (06)\nSite\nValbonne\nShow more\nShow less",
        "details": {
            "JobDetail": [
                "Hybride",
                "Confirm√©"
            ],
            "TypeContract": "CDI",
            "Salary": "",
            "Level": "",
            "Experience": null
        },
        "title": "data engineer",
        "skills": {
            "ProgLanguage": [
                "Java"
            ],
            "DataBase": [
                "MongoDB",
                "HBase",
                "Elasticsearch",
                "SQL",
                "NoSQL"
            ],
            "BigData": [
                "Hadoop",
                "Spark"
            ],
            "CloudComputing": [
                "GCP",
                "Azure"
            ],
            "SoftBigDataProcessing": [
                "HBase"
            ],
            "Other": [
                "Cloud",
                "Big Data"
            ],
            "EnSoftSkils": [
                "Communication"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "GROUPE ALLIANCE",
        "location": "√éle-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/datascientist-at-groupe-alliance-3916080098?position=2&pageNum=12&refId=g33qv%2BeUV9twrCN4MQzIIw%3D%3D&trackingId=jexPXnm3q%2BSl8Z0B2oRfvg%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "SI LA GESTION DES DONNEES EST TON DADA, TU PEUX GAGNER LA COURSE EN LISANT CETTE ANNONCE ‚Ä¶\nCe que tu recherches :\nau sein d‚Äôune √©quipe dynamique\n√† des projets innovants d‚Äôenvergure\ndes d√©fis\nun nouveau souffle √† ta carri√®re\nAlors nous avons la mission id√©ale pour toi.\nAu sein d‚Äôacteurs majeurs du secteur Bancaire, tu participeras des projets d‚Äôenvergure sur des √©volutions majeures √† mettre en ≈ìuvre dans le SI du client :\ndes besoins, tu feras\ntechniques, tu r√©digeras\net/ou socle technique, tu d√©finiras\npratiques, tu instaureras\nnouvelles fonctionnalit√©s, tu d√©velopperas\nbug, tu laisseras\n√©quipe, tu accompagneras\ninstances de pilotage, tu participeras\nQui tu es :\nde la formation qui va bien\nou d√¥t√©(e) d‚Äôune exp√©rience de 3 ans minimum\nde la Stack technique machine learning et python\navec les Frameworks et Outils : Ttensorflow, pytorch,scikit-learn, numpy, pandas\nAu-del√† des comp√©tences techniques, tu es :\n: tu n‚Äôaimes pas rester les deux pieds dans le m√™me sabot\n: un guide du Routard te suffira\nde synth√®se : tu sais aller √† l‚Äôessentiel\nd‚Äôadaptation : tu es un vrai cam√©l√©on\nde la communication : les mots n‚Äôont pas de secret pour toi\nde proposition : tu es l‚ÄôAladdin de l‚Äôinformatique\nd‚Äô√©quipe : un pour tous et tous pour un !\nShow more\nShow less",
        "details": {
            "JobDetail": [],
            "TypeContract": "",
            "Salary": "",
            "Level": "",
            "Experience": "3 an(s)"
        },
        "title": "data scientist",
        "skills": {
            "ProgLanguage": [
                "Python"
            ],
            "DataAnalytics": [
                "NumPy",
                "Pandas"
            ],
            "MachineLearning": [
                "Scikit-Learn",
                "PyTorch"
            ],
            "Other": [
                "Machine Learning"
            ],
            "EnSoftSkils": [
                "Communication"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "Cr√©dit Agricole Assurances",
        "location": "Paris, √éle-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/data-scientist-ia-h-f-at-cr%C3%A9dit-agricole-assurances-3915760690?position=3&pageNum=12&refId=g33qv%2BeUV9twrCN4MQzIIw%3D%3D&trackingId=kzD4LFkt2UmUyjYy%2FanK8w%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Premier assureur en France et premier bancassureur en Europe, nous voulons aller plus loin en devenant l'assureur digital de r√©f√©rence et le n¬∞1 de la satisfaction client. La Direction de la Transformation accompagne notre Groupe pour mener √† bien cette transformation digitale. Pour vous, c‚Äôest l‚Äôopportunit√© de vivre une riche aventure humaine, dans une structure en pleine transformation, avec de nombreuses possibilit√©s d'√©volution.\nAu sein de le Direction de la Transformation CAA, vous serez rattach√© √† l‚Äô√©quipe AI Factory (√©quipe compos√©e de data scientist, ing√©nieurs IT IA et pilotes de projets IA). Cette √©quipe a en charge le d√©veloppement de moteurs d‚Äôintelligence artificielle int√©gr√©s au c≈ìur des processus de production.\nConcr√®tement, de quoi s'agit-il sur le terrain ?\nPr√©diction des anomalies dans l‚Äôinfocentre avec de l‚ÄôIA (XGB / r√©seaux de neurones).\nAnalyse de texte libre (IA G√©n√©rative, Topic Modeling, TFIDF, etc.)\nTraitement automatiques des documents (IA G√©n√©rative, OCR, Computer Vision, NLP)\nClassification de document\nLecture d‚Äôinformation dans les documents (ex. factures, carte grise, etc.)\nIdentification d‚Äôintention des clients\nSurveillance des comportements clients \"anormaux\" (RNNS, XGB)\nD√©tection de Fraude √† l‚Äôassurance\n√Ä ces missions s'ajoutent des missions plus g√©n√©rales :\n- Interagir avec l‚Äôensemble des filiales du groupe Cr√©dit Agricole\nMener des d√©veloppements R&D au sein des projets, qui sont ensuite partag√©s dans l'√©quipe\nParticiper √† la vie de la communaut√© Data Science dans le groupe Cr√©dit Agricole Assurances\nParticiper √† la veille technologique en Data Science et √©changer avec le DataLab groupe CASA Voici la description des avantages et de la r√©mun√©ration qui sera publi√©e √† la suite des missions.\nLors de votre prise de poste, vous serez bien entendu accompagn√© par l‚Äô√©quipe dans la prise en main de vos missions.\nVos avantages\n- Un mod√®le manag√©rial bienveillant favorisant la mise en responsabilit√©.\nDes opportunit√©s professionnelles dans l‚Äôensemble du Groupe Cr√©dit Agricole.\nT√©l√©travail : forfait de 82 jours √† poser de fa√ßon flexible, soit 40 % d‚Äôun temps plein annuel.\n34 CP + 12 RTT.\nR√©mun√©rations fixe et variable individuelle.\nInt√©ressement et √©pargne salariale avec abondement.\nAvantages bancaires, avantages CSE, compte √©pargne temps.\nMutuelle prise en charge √† 75 %, forfait mobilit√© durable...\nPython (et les librairies type PyTorch, Keras, Seaborn, etc.)\nPlateforme IA AWS\nUn premier niveau de connaissance des assets de MLOps type Docker\nGitlab\nBac+5\nShow more\nShow less",
        "details": {
            "JobDetail": [
                "Temps plein"
            ],
            "TypeContract": "",
            "Salary": "",
            "Level": "Bac+5",
            "Experience": null
        },
        "title": "data scientist",
        "skills": {
            "ProgLanguage": [
                "R",
                "Python"
            ],
            "DataAnalytics": [
                "R"
            ],
            "MachineLearning": [
                "PyTorch",
                "Keras"
            ],
            "DataVisualisation": [
                "Seaborn"
            ],
            "CloudComputing": [
                "AWS"
            ],
            "DevTools": [
                "Docker"
            ],
            "Containers": [
                "Docker"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "Groupe Caisse des D√©p√¥ts",
        "location": "Paris, √éle-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/ing%C3%A9nieur-quantitatif-data-scientist-confirm%C3%A9-h-f-1-0007595-at-groupe-caisse-des-d%C3%A9p%C3%B4ts-3907546129?position=4&pageNum=12&refId=g33qv%2BeUV9twrCN4MQzIIw%3D%3D&trackingId=nLFss3rxX7UXpR%2FkKFS52Q%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "La Direction des risques Groupe (DRG) pilote le dispositif de ma√Ætrise des risques du Groupe. Elle veille √† sa coh√©rence et √† son efficacit√©. Au titre de sa fonction d'animation, de coordination et de supervision de la fili√®re ¬´ Risques ¬ª du Groupe, ou ¬´ fonction de gestion des risques ¬ª au sens des nouveaux textes bancaires en vigueur, elle assure un suivi des risques du Groupe adapt√© √† l'environnement √©conomique, financier et r√©glementaire, qui contribue au dispositif de pilotage global du Groupe. Rattach√©e au Directeur g√©n√©ral et √† vocation transversale, elle compte 170 collaborateurs. La Directrice des risques est membre du Comex.\nLa Direction est en charge :\n- du pilotage transverse des risques : analyse et avis sur les risques de bilan, validation des mod√®les, reporting, pilotage des risques des filiales, r√®glementation prudentielle\n- du suivi des risques financiers : analyse financi√®re ing√©nierie financi√®re\n- du suivi des engagements : investisseur, bancaire, pr√™teur\n- du pilotage des risques dans les directions r√©gionales\n- du pilotage des comit√©s d'engagements\n- de la s√©curit√© des SI.\nMissions et activit√©s principales\nDescription d√©taill√©e du poste\nRATTACHEMENT\nLe poste est rattach√© au responsable du Service Mod√©lisation des risques de cr√©dit de la Direction des Risques du Groupe (DRG).\nLe service est charg√© de l‚Äô√©valuation de la qualit√© de cr√©dit des contreparties de pr√™ts (organismes de logements sociaux et collectivit√©s locales notamment) et des contreparties de portefeuilles financiers (grandes banques, groupes industriels et commerciaux, Etats, titrisations) qui √©mettent sur les march√©s de taux. A ce titre, le service est charg√© de la conception et du management des outils de notation interne et de calibrage des probabilit√©s de d√©fauts et probabilit√©s de recouvrement.\nDESCRIPTION DU POSTE\nAu sein de son service Mod√©lisation des risques de cr√©dit, le service recherche un mod√©lisateur du risque de cr√©dit, dont les principales missions porteront sur :\nLe d√©veloppement de mod√®les de notation bas√©s sur les fondamentaux de l‚Äôanalyse financi√®re, et le management des mod√®les existants (backtestings annuels, maintenance applicative, etc.) ;\nLe d√©veloppement de mod√®les de probabilit√©s de d√©fauts et de recouvrement (param√®tres b√¢lois et IFRS9) et le management des mod√®les existants : PD, LGD et CCF ;\nLe d√©veloppement d‚Äôoutils de scoring, notation et/ou probabilit√©s de d√©faut pour des √©metteurs non conventionnels (Fonds) ;\nL‚Äôadaptation des processus de mod√©lisation aux recommandations r√®glementaires ;\nLa mise en place et/ou la maintenance d‚Äôune infrastructure s√©curis√©e et automatis√©e (formalisation et maintenance des bases de donn√©es, travaux statistiques sous SAS et Python) ;\nLa repr√©sentation du service dans le cadre du stress testing transversal, sur le volet cr√©dit ;\nLa diffusion des connaissances r√©glementaires aupr√®s des interlocuteurs de la Direction des Risques du Groupe ;\nLa participation √† la refonte des syst√®mes d‚Äôinformation et projets transversaux ;\nLa maintenance des outils informatiques : analyse des besoins, √©laboration de cahiers des charges, suivi des r√©alisations informatiques (projets & maintenance) ;\nUne veille scientifique sur les techniques candidates, en lien avec les technologies big bata et machine learning.\nProfil attendu\nLe recrutement √† la Caisse des D√©p√¥ts est fond√© sur les comp√©tences, sans distinction d'origine, d'√¢ge, ni de genre. Tous nos postes sont ouverts aux personnes en situation de handicap.\nA partir de 5 ans d'exp√©rience sur un poste similaire\nBAC+5 de formation math√©matique,\nExp√©rience significative en mod√©lisation statistique, en particulier du risque de cr√©dit,\nBonne ma√Ætrise d‚Äôau moins un des langages de programmation : Python, SAS, R\nConnaissance de la r√©glementation b√¢loise,\nExcellent niveau r√©dactionnel,\nRigueur et capacit√© de synth√®se,\nMotivation, autonomie, esprit d‚Äô√©quipe, disponibilit√©.\nVos connaissances financi√®res et votre exp√©rience vous ont permis d'acqu√©rir un bon esprit d'analyse et de synth√®se ainsi que de bonnes qualit√©s r√©dactionnelles. Ouvert(e), vous avez un bon relationnel qui vous permet de vous adapter facilement √† des environnements divers et exigeants.\nConditions de travail\nPoste √©ligible au t√©l√©travail.\nSitu√© rue de Lille, Paris 7.\nShow more\nShow less",
        "details": {
            "JobDetail": [],
            "TypeContract": "",
            "Salary": "",
            "Level": "Bac+5",
            "Experience": "5 an(s)"
        },
        "title": "data engineer",
        "skills": {
            "ProgLanguage": [
                "R",
                "Python"
            ],
            "DataAnalytics": [
                "R"
            ],
            "Other": [
                "Statistiques",
                "Machine Learning"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "METEOJOB by CleverConnect",
        "location": "Aubervilliers, √éle-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/alternance-%E2%80%93-data-scientist-at-meteojob-by-cleverconnect-3898720601?position=5&pageNum=12&refId=g33qv%2BeUV9twrCN4MQzIIw%3D%3D&trackingId=tCIfrrucKBYAr74%2F%2Fon5gQ%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Entreprise\nMAKING THE WORLD A BETTER HOME\n, faire du monde une maison commune, c'est la raison pour laquelle nous existons et c'est notre cap commun.\nPr√©sent dans 75 pays, Saint-Gobain est le leader mondial de la construction durable.\nNotre m√©tier ?\nNous concevons, produisons et distribuons des mat√©riaux et des services pour les march√©s de l'habitat et de l'industrie.\nNos solutions ?\nElles se trouvent partout dans notre vie quotidienne - b√¢timents, transports, infrastructures - et apportent confort et durabilit√©.\nNotre ambition ?\nO√π que vous soyez, laissez votre personnalit√© briller et nos valeurs vous guider chaque jour pour inventer un monde plus durable.\nSaint-Gobain Glass con√ßoit, produit et distribue des mat√©riaux et services pour les march√©s de l'habitat et de l'industrie. Mus par une volont√© permanente d'adapter nos produits verriers aux besoins et aux r√©alit√©s actuels, nous innovons sans cesse. Nous d√©veloppons ainsi des solutions int√©gr√©es pour la r√©novation des b√¢timents publics et priv√©s, la construction l√©g√®re. Par l'innovation, nous avons √©galement √† c≈ìur de participer √† la d√©carbonation du monde de la construction et de l'industrie avec des produits apportant durabilit√© et performance.\nEn France, Saint-Gobain Glass produit, transforme le verre plat et distribue des solutions verri√®res r√©pondant √† un large spectre d'applications pour l'habitat r√©sidentiel et tertiaire.\nEn int√©grant Saint-Gobain Glass France, vous rejoindrez la Direction Technologie et Performance Industrielle (DTI) √©tablie √† Aubervilliers, o√π vous serez au c≈ìur des initiatives strat√©giques pour optimiser les performances industrielles et environnementales.\nLes missions principales de la DTI sont d'assurer un accompagnement des pays et m√©tiers du Groupe sur les activit√©s suivantes: feuilles de route industrielles (standards, benchmark, performance, √©nergie, CO2, savings, ‚Ä¶), programmes R&D pour les m√©tiers de la Construction, Investissements et Achats strat√©giques, Allocation de capacit√© entre les pays et Programmes d'excellence op√©rationnelle avec les savings associ√©s (World Class Manufacturing, World Class Supply Chain, 4.0, Applications digitales pour l'Industrie, ‚Ä¶).\nDescription Du Poste\nLa Direction Technique Internationale est √† la recherche d'un(e) alternant(e) - Data science.\nNotre futur(e) alternant(e) collaborera avec les experts de divers domaines pour r√©pondre √† leurs besoins d'analyse et contribuera activement au d√©veloppement du p√¥le \"Data Science\" chez Saint-Gobain Glass.\nIl ou elle sera rattach√©(e) √† notre Ing√©nieurs Data Scientist\nLes Missions Principales Incluront\nEffectuer des analyses descriptives des donn√©es, telles que le Datamining, les Corr√©lations et les Segmentations.\nIdentifier et collecter les diff√©rentes donn√©es provenant des sources internes ou externes n√©cessaires aux √©tudes.\nManipuler et nettoyer de grandes quantit√©s de donn√©es.\nMettre en place des algorithmes de pr√©diction, tels que la R√©gression, la Classification ou le Deep Learning.\nCollaborer √©troitement avec des experts techniques et des professionnels du domaine pour interpr√©ter les r√©sultats obtenus.\nCr√©er des rapports et des tableaux de bord pr√©sentant divers indicateurs de performance, en utilisant des outils de business intelligence.\nFormation\nDescription du profil :\nNous recherchons des candidat(e)s ayant un niveau d'exp√©rience correspondant √† un Master 1-2, issu(e)s d'une √©cole d'ing√©nieur.\nComp√©tences Techniques\nUne ma√Ætrise de Miscrosoft 365 est indispensable.\nCapacit√© √† effectuer des analyses de donn√©es sur R et/ou Python.\nLa ma√Ætrise d'un outil de Business Intelligence est un atout.\nMa√Ætrise du Fran√ßais et de l'Anglais.\nComp√©tences Relationnelles Et Qualit√©s Requises\nUn fort int√©r√™t pour l'analyse de donn√©es.\nDynamisme et sens du service client.\nCapacit√© √† travailler de mani√®re autonome et avec rigueur.\nOuverture d'esprit et curiosit√©.\nUn int√©r√™t marqu√© pour le secteur industriel et les nouvelles technologies.\nExigences Du Poste\nEnvironnement multinational et multilingue.\nLocalisation √† Aubervilliers\nCette offre est accessible √† tous les talents ! Saint-Gobain s'engage quotidiennement pour l'√©galit√© des chances. Nous apportons une attention particuli√®re √† l'inclusion et la diversit√©, https://www.saint-gobain.com/fr/news/agir-durablement\nLa culture Trust Empowerment and Collaboration (TEC) est le socle sur lequel se structure nos actions diversit√© et inclusion.\nShow more\nShow less",
        "details": {
            "JobDetail": [],
            "TypeContract": "",
            "Salary": "",
            "Level": "",
            "Experience": null
        },
        "title": "data scientist",
        "skills": {
            "ProgLanguage": [
                "R",
                "Python"
            ],
            "DataAnalytics": [
                "R"
            ],
            "EnSoftSkils": [
                "Collaboration"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "Mailinblack",
        "location": "Marseille, Provence-Alpes-C√¥te d'Azur, France",
        "link": "https://fr.linkedin.com/jobs/view/data-scientist-h-f-at-mailinblack-3910201495?position=6&pageNum=12&refId=g33qv%2BeUV9twrCN4MQzIIw%3D%3D&trackingId=iOZssRF0uLF5Z713PkkywA%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Cette offre d‚Äôemploi est fournie par P√¥le emploi\nDescription\nRESPONSABILIT√âS : Ton job ? Rattach√©(e) √† l'√©quipe Lab R&D, tu travailleras en √©troite collaboration avec les √©quipes techniques et produit. Ton r√¥le sera d'am√©liorer la d√©tection des menaces provenant de multiples vecteurs d'attaques (emails, pages web malveillantes) et d'apporter ton expertise en Machine Learning lors du d√©veloppement de nouveaux produits. Tes missions ? - D√©velopper des mod√®les pr√©dictifs afin d'am√©liorer la d√©tection et la pr√©vention des menaces cyber ; - Collaborer avec les √©quipes pour int√©grer les mod√®les et les algorithmes dans les solutions de Mailinblack ; - Concevoir des services de surveillance des r√©sultats des analyses et des pr√©dictions ; - Imaginer et proposer de nouvelles id√©es pour am√©liorer les produits de Mailinblack ou en cr√©er de nouveaux ; - Participer √† la veille technologique ; Environnement technique : Python, Golang, Scala, Spark, Databricks, Azure (VM, ADLS, Event Hubs, Service Bus, DevOps pipeline), MySQL, Git, Jenkins, Docker, Kubernetes, ELK, API REST, SMTP. PROFIL RECHERCH√â : Ton profil¬ø? ¬ø Tr√®s bonne connaissance des algorithmes de Machine Learning : Ma√Ætrise des techniques de r√©gression, de classification et de clustering, ainsi que des Frameworks courants. Capacit√© √† optimiser les mod√®les, √† √©valuer leur performance et √† interpr√©ter leurs r√©sultats. ¬ø Comp√©tences en d√©veloppement : Ma√Ætrise des biblioth√®ques de Python pour la data science. Exp√©rience avec Apache Spark. ¬ø Bases en traitement automatique de langage naturel (NLP) ¬ø Connaissance des syst√®mes de base de donn√©es : Exp√©rience avec les bases de donn√©es relationnelles (SQL) et les bases de donn√©es NoSQL. üåü Bonus¬ø:¬ø - Connaissances dans les domaines de la messagerie (protocole SMTP et m√©thodes de filtrage) et web. - Connaissance des environnements de micro-services (Docker, Kubernetes), compr√©hension des enjeux d'int√©gration de d√©ploiement continu - Exp√©rience en apprentissage non-supervis√© et/ou end-to-end et/ou analyse d'image - Comp√©tences en traitement √† grande √©chelle (Big Data) D√©roulement des entretiens ¬ø¬ø üì± Premier √©change de 20 minutes par t√©l√©phone avec Alexandre, notre Talent Acquisition üí¨ Entretien en visio avec Achraf, Manager de l'√©quipe IA/Data, et Alexandre¬ø üíª Test technique ¬ø üëÄ Rencontre avec l'√©quipe¬øData R√©mun√©ration : 40k √† 50k annuel brut Les + chez Mailinblack : - Des bureaux sympas en plein centre de Marseille, au soleil et √† deux pas du Vieux Port et des Calanques ¬ø¬ø ¬ø¬ø - 7 jours de cong√©s pay√©s suppl√©mentaires - 2 √† 3 jours par semaine en t√©l√©travail - Une culture d'entreprise qui pr√¥ne l'autonomie, la responsabilit√© et la bienveillance - Un plan de d√©veloppement de comp√©tences Et aussi : des ch√®ques vacances, des paniers de fruits dans la cuisine, des repas d'√©quipes, des journ√©es massage sur site et des √©v√©nements canons ! Et bien s√ªr une bonne mutuelle (Malakoff), une √©pargne salariale, une participation aux transports en commun (50%) Impatient(e) d'int√©grer une √©quipe soud√©e et une entreprise en pleine √©volution ?\nPROFIL SOUHAIT√â\nExp√©rience\nD√©butant accept√©\nSource: Pole emploi (https://www.pole-emploi.fr)\nShow more\nShow less",
        "details": {
            "JobDetail": [],
            "TypeContract": "",
            "Salary": "",
            "Level": "",
            "Experience": null
        },
        "title": "data scientist",
        "skills": {
            "ProgLanguage": [
                "R",
                "Scala",
                "Python"
            ],
            "DataBase": [
                "SQL",
                "NoSQL"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [
                "Databricks",
                "Spark"
            ],
            "CloudComputing": [
                "Azure"
            ],
            "DevTools": [
                "Git",
                "Docker",
                "Jenkins"
            ],
            "DBMS": [
                "MySQL"
            ],
            "Automation": [
                "Kubernetes"
            ],
            "Containers": [
                "Docker",
                "Kubernetes"
            ],
            "Other": [
                "Machine Learning",
                "Big Data",
                "DevOps"
            ],
            "EnSoftSkils": [
                "Collaboration"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "Talent-R",
        "location": "Paris",
        "link": "https://fr.linkedin.com/jobs/view/data-engineer-ml-engineer-up-to-75k-boulogne-at-talent-r-3904965048?position=7&pageNum=12&refId=g33qv%2BeUV9twrCN4MQzIIw%3D%3D&trackingId=lHByyxECDT17nmxP0LE1zQ%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "üìç\nLocalisation\n: R√©gion Parisienne & Remote Flexible (60%) - CDI\nüîç\nSeniorit√©\n: Mid/Senior (>4/5 years of Data)\nüí∞\nSalaire\n: Up to 75K‚Ç¨ fixe + Prime de participation, prime vacances et bonus...\nL'entreprise\nüíº\nLe groupe entre dans une nouvelle √®re gr√¢ce √† la strat√©gie qui place\nL‚ÄôIA\nau c≈ìur du business. Acteur incontournable de ce nouveau cycle ils participent activement √† relever les challenges des\nnouvelles mobilit√©s et de l‚Äôindustrie 4.0.\nP√¥le Architecture et Data :\nL'objectif est de mettre en place les bases de\nla plateforme IA\nafin de r√©pondre aux nouveaux besoins m√©tiers.\nLes missions\n‚öôÔ∏è\nDans ce r√¥le, vous travaillerez en √©troite collaboration avec les √©quipes m√©tiers et les autres membres du P√¥le Architecture & Data (Data Analysts, Scientists, architectes, etc.), en exploitant des quantit√©s massives de donn√©es (flux d'√©v√©nements en continu, traitements par lots et en temps r√©el, ainsi que les appels aux APIs).\nL'objectif est notamment d'alimenter des mod√®les d'apprentissage automatique pour des t√¢ches telles que la segmentation des clients et la d√©tection automatique des pannes des v√©hicules.\nLes avantages\nüòç\nVariable de 6% (Objectifs individuels / Performance du groupe)\nPrime int√©ressement (√† peu pr√®s un mois de salaire)\nPrime vacances (1% de salaire annuel)\nTarif pr√©f√©rentiels achats de v√©hicules\nAvantage CE (200 - 400‚Ç¨ de ch√®ques cadeaux)\nT√©l√© travail : 3 jours / semaine\nMat√©riel IT + participation frais d‚Äôinternet\n10 jours de RTT\nLe stack technique\nüëâüèª\nGoogle Cloud Platform (BigQuery, PubSub, Dataflow, Vertex AI)\nAirflow\nTerraform\nPython\nLooker\nDataiku\nKubernetes, SQL, Git\nPostulez si et seulement si\nVous disposez d'au moins\n5\nans\nd‚Äôexp√©rience en data\nVous disposez d‚Äôune solide exp√©rience en d√©veloppement\nPython\net\nframework ML\n(Vertex, Tensorflow, Scikit, PyTorch‚Ä¶)\nVous poss√©dez une exp√©rience de d√©veloppement et orchestration de chaines ETL complexes via\nAirflow\nou √©quivalent\nVous savez utiliser des services cloud (pr√©f√©rablement\nGCP\n)\nVous √™tes capable d‚Äô√©changer en\nanglais\ntechnique √©crit et oral\nShow more\nShow less",
        "details": {
            "JobDetail": [
                "Remote",
                "Senior"
            ],
            "TypeContract": "CDI",
            "Salary": "75K",
            "Level": "",
            "Experience": "5 an(s)"
        },
        "title": "data engineer",
        "skills": {
            "ProgLanguage": [
                "Python"
            ],
            "DataBase": [
                "SQL"
            ],
            "MachineLearning": [
                "PyTorch",
                "TensorFlow"
            ],
            "CloudComputing": [
                "GCP",
                "Google Cloud Platform"
            ],
            "DevTools": [
                "Git"
            ],
            "DBMS": [
                "BigQuery"
            ],
            "Automation": [
                "Airflow",
                "Kubernetes"
            ],
            "InfrastructureAsCode": [
                "Terraform"
            ],
            "Containers": [
                "Kubernetes"
            ],
            "Other": [
                "Cloud",
                "ML"
            ],
            "EnSoftSkils": [
                "Collaboration"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "IRSN",
        "location": "Saint-Paul-lez-Durance, Provence-Alpes-C√¥te d'Azur, France",
        "link": "https://fr.linkedin.com/jobs/view/data-scientist-pour-la-simulation-de-l-incendie-et-des-explosions-h-f-at-irsn-3909242968?position=8&pageNum=12&refId=g33qv%2BeUV9twrCN4MQzIIw%3D%3D&trackingId=R70ZBJBn1ofMTrC0EXW62Q%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Vous int√©grez le Laboratoire de l'Incendie et des Explosions (LIE) du Service des Agressions Internes et risques Industriels (SA2I) rattach√© au P√¥le S√ªret√© des installations et des syst√®mes nucl√©aires √† Cadarache.\nLe SA2I r√©alise des expertises concernant la ma√Ætrise des risques d'incendies, d'explosions et induits par l'activit√© humaine et des travaux de R&D dans ces m√™mes domaines et plus g√©n√©ralement de la thermique et de la m√©canique des fluides r√©actifs. Il initie, r√©alise ou suit des √©tudes et des recherches propres √† r√©pondre aux besoins de l'expertise dans son domaine de comp√©tences.\nAu sein du service, le LIE a pour objectif principal d'am√©liorer la connaissance sur les risques incendie et explosion en milieu confin√© et ventil√© et de d√©velopper les mod√©lisations physiques associ√©es. Cette connaissance est capitalis√©e par le d√©veloppement de logiciels scientifiques √† champ et √† zones pour simuler les sc√©narios d'incendie et d'explosion en milieux repr√©sentatifs des installations\nnucl√©aires. Il vient en soutien aux unit√©s qui r√©alisent des expertises de s√ªret√© et des programmes exp√©rimentaux par l'utilisation de ces logiciels.\nEn tant que sp√©cialiste en science des donn√©es, vous aurez quatre missions principales :\nexploiter les informations contenues dans les bases exp√©rimentales disponibles\net/ou g√©n√©r√©es par des simulations CFD par des m√©thodes de \" machine learning pour pouvoir extrapoler/interpoler les r√©sultats physiques fournis par les logiciels (vitesses de flamme, temp√©rature, √©coulement...) et conforter leurs applications dans les √©tudes de suret√©.\nd√©velopper des mod√®les par assimilation de donn√©es issues de campagnes\nexp√©rimentales et de simulations CFD pour conforter leurs applications dans les √©tudes de suret√©.\nd√©velopper des m√©tamod√®les rapides en investiguant les solutions les plus\nadapt√©es pour les probl√®mes physiques rencontr√©es en mod√©lisation de l'incendie et des explosions. Ces mod√®les doivent permettre d'optimiser l'utilisation des logiciels d√©velopp√©s au sein du service.\nd√©velopper des m√©thodes d'analyse de sensibilit√© et de propagation des incertitudes pour l'identification des param√®tres les plus influents des mod√®les num√©riques, en support √† l'expertise et √† l'orientation des recherches num√©riques et exp√©rimentales.\nDans un environnement de travail o√π la compr√©hension et l'interpr√©tation physique des ph√©nom√®nes sont essentielles, vous devrez porter une attention particuli√®re au niveau de confiance pouvant √™tre accord√© aux r√©sultats obtenus par les m√©tamod√®les, ce qui pourrait notamment passer par le machine-learning inform√© par la physique, l'intelligence artificielle explicable et interpr√©table, les\nm√©thodes de validation et de quantification des incertitudes avanc√©es...\nVous aurez √† collaborer avec les data scientists de diff√©rentes unit√©s pour √©laborer, partager et d√©velopper les m√©thodes √† mettre en oeuvre pour les applications propres au SA2I. Vous devrez progressivement vous acculturer aux probl√©matiques m√©tiers du service, concernant les installations exp√©rimentales et les outils de mod√©lisation, afin de proposer des solutions r√©pondant aux besoins des utilisateurs et s'int√©grant dans les cha√Ænes de calcul actuelles.\nVous aurez un r√¥le √† jouer dans l'acculturation des ing√©nieurs-chercheurs au domaine des sciences des donn√©es.\nVous √™tes titulaire d'un dipl√¥me d'ing√©nieur ou de 3e cycle universitaire. Vous justifiez de 3 ans ou plus d'exp√©rience professionnelle dans les sciences des donn√©es.\nDes connaissances dans le domaine de la simulation num√©rique (CFD) seraient appr√©ci√©es.\nVous maitrisez l'anglais.\nVous √™tes rigoureux(se), force de proposition et disposez d'un esprit d'analyse et de synth√®se ainsi que des capacit√©s r√©dactionnelles.\nVous disposez de capacit√©s de vulgarisation et d'√©coute.\nVous avez un sens av√©r√© du collectif.\n20496836-55584\nShow more\nShow less",
        "details": {
            "JobDetail": [],
            "TypeContract": "",
            "Salary": "",
            "Level": "",
            "Experience": "3 an(s)"
        },
        "title": "data scientist",
        "skills": {
            "ProgLanguage": [
                "R"
            ],
            "DataAnalytics": [
                "R"
            ],
            "Other": [
                "Machine Learning"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "GE HealthCare",
        "location": "Buc, √éle-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/data-scientist-h-f-at-ge-healthcare-3910073642?position=9&pageNum=12&refId=g33qv%2BeUV9twrCN4MQzIIw%3D%3D&trackingId=TIxaMW7hQH4w9HBBs2u%2BIA%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Job Description Summary\nAu sein du service AV (Advanced Vizualization) engineering, vous travaillerez au d√©veloppement d‚Äôalgorithmes d‚Äôintelligence artificielle utilis√©s dans des logiciels de post-traitement d‚Äôimages m√©dicales.\nCes logiciels s‚Äôadressent aux radiologues, cardiologues et chirurgiens. Ils sont destin√©s √† am√©liorer la fiabilit√© et la rapidit√© du diagnostic gr√¢ce √† des outils d‚Äôaide √† la d√©cision en imagerie m√©dicale.\n(https://www.gehealthcare.com/products/advanced-visualization)\nEn tant que Data Scientist au sein de notre √©quipe R&D, vous interviendrez sur ces projets en √©troite collaboration avec les chefs de projet, les sp√©cialistes d‚Äôapplication et les d√©veloppeurs pour r√©pondre √† des probl√©matiques cliniques concr√®tes.\nVos r√©sultats devront prendre en compte les contraintes de temps de calcul, de fiabilit√©, et de simplicit√© n√©cessaires √† une utilisation en routine m√©dicale. Votre mission devra s‚Äôeffectuer dans le respect du Syst√®me Qualit√© de GEHC.\nJob Description\nR√¥les et responsabilit√©s\nD√©velopper des algorithmes en traitement de l‚Äôimage dans le domaine de l‚Äôimagerie m√©dicale.\nInteragir et travailler avec des sp√©cialistes cliniques et des m√©decins pour proposer des solutions innovantes √† leurs probl√®mes.\nContribuer √† la progression m√©thodologique des √©quipes dans la conception d‚Äôalgorithmes et d‚Äôapplications m√©dicales\nD√©finir et ex√©cuter la strat√©gie de validation des algorithmes et fournir les √©l√©ments documentaires pour le d√©veloppement et la certification du produit (documents de conception et de qualification de l‚Äôalgorithme).\nParticiper √† la veille scientifique et technique dans le domaine du traitement de l‚Äôimage et de ses applications.\nProfil Et Qualifications\nDoctorat et/ou dipl√¥me d‚Äôune grande √©cole d‚Äôing√©nieur avec sp√©cialisation en science de la donn√©e ou informatique ou math√©matiques appliqu√©es\nConnaissances approfondies dans le domaine de l‚Äôapprentissage automatique (en particulier deep learning) et ses applications en traitement de l‚Äôimage.\nMa√Ætrise du langage Python\nExp√©riences avec les frameworks de machine learning tels que TensorFlow ou PyTorch\nMa√Ætrise de l‚Äôenvironnement Linux.\nMa√Ætrise de l‚Äôanglais √©crit et parl√©\nRigueur, curiosit√©, cr√©ativit√© et esprit d‚Äô√©quipe\nPassionn√©(e) par l‚Äôinnovation et les technologies de la sant√©\nInclusion et diversit√©\nGE HealthCare est un employeur offrant l'√©galit√© des chances o√π l'inclusion compte. Les d√©cisions relatives √† l'emploi sont prises sans tenir compte de l‚Äôorigine nationale ou ethnique, de la religion, du sexe, de l'orientation sexuelle, de l'identit√© ou de l'expression de genre, de l'√¢ge, du handicap, du statut d'ancien combattant prot√©g√© ou d'autres caract√©ristiques prot√©g√©es par la loi.\nNos r√©mun√©rations totales sont con√ßues pour lib√©rer votre ambition en vous donnant la motivation et la flexibilit√© dont vous avez besoin pour transformer vos id√©es en r√©alit√©s qui changent le monde. Nos salaires et nos avantages sociaux correspondent √† tout ce que vous attendez d‚Äôune organisation ayant une dimension internationale, avec des possibilit√©s de d√©veloppement de carri√®re, dans une culture qui favorise la collaboration et le soutien.\nA propos de nous\nGE HealthCare est l'un des leaders mondiaux dans le domaine des technologies m√©dicales et des solutions num√©riques. Il permet aux cliniciens de prendre des d√©cisions plus rapides et plus pertinentes √† travers des √©quipements intelligents, des analyses de donn√©es, des applications et des services. Avec plus de 100 ans d'exp√©rience dans le secteur de la sant√© et environ 47 000 employ√©s dans le monde, la soci√©t√© est au centre d'un √©cosyst√®me qui travaille pour une m√©decine de pr√©cision.\nPr√©sent en France depuis 1987 avec aujourd‚Äôhui 2 800 collaborateurs, c‚Äôest un acteur solidement ancr√© dans l‚Äôhexagone √† travers son empreinte industrielle, son centre de R&D et de production √† Buc dans les Yvelines et des partenariats de recherche avec des entreprises et des centres de recherche fran√ßais. www.gehealthcare.com\nAdditional Information\nRelocation Assistance Provided:\nNo\nShow more\nShow less",
        "details": {
            "JobDetail": [],
            "TypeContract": "",
            "Salary": "100",
            "Level": "",
            "Experience": "100 an(s)"
        },
        "title": "data scientist",
        "skills": {
            "ProgLanguage": [
                "R",
                "Python"
            ],
            "DataAnalytics": [
                "R"
            ],
            "MachineLearning": [
                "PyTorch",
                "TensorFlow"
            ],
            "OS": [
                "Linux"
            ],
            "Other": [
                "Machine Learning"
            ],
            "EnSoftSkils": [
                "Collaboration"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "Niji",
        "location": "Rennes, Brittany, France",
        "link": "https://fr.linkedin.com/jobs/view/ml-engineer-f-h-at-niji-3864183545?position=10&pageNum=12&refId=g33qv%2BeUV9twrCN4MQzIIw%3D%3D&trackingId=kL4yyxuffiZgpTcsptvUuQ%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Nous sommes plus qu‚Äôun simple cabinet de conseil, qu'une agence de design et qu'une soci√©t√© de mise en ≈ìuvre technologique. Nous sommes le partenaire de la transformation digitale de nos clients grands-comptes et ETI, que nous accompagnons de l‚Äôid√©e √† la r√©alit√©.\nNous associons, dans une m√™me cha√Æne de valeur, conseil en strat√©gie, design de service et design √©motionnel, management et valorisation de la donn√©e, ing√©nierie et conseil technologique, r√©alisation logicielle et expertise en cybers√©curit√©.\nNotre singularit√© repose sur les talents pluriels de nos √©quipes, au service de la satisfaction et de la performance de nos clients.\nLe P√¥le Data De Niji C'est Avant Tout Une √âquipe √† Taille Humaine Et Pluridisciplinaire, Compos√©e De Consultants Et Experts Qui Conseillent Et Appuient Nos Clients Sur Toutes Les √âtapes Du Cycle Des Donn√©es\nde la collecte √† la valorisation dans des services innovants,\nen passant par les architectures de stockage et de services.\nNos consultants sont bas√©s en Ile-de-France et en r√©gions (Nantes, Rennes, Lille, Lyon et Bordeaux).\nNos 3 directeurs : experts confirm√©s de la gouvernance des donn√©es, de la data science de l'IA et des m√©thodologies d'industrialisation de l'IA (MLOps, DataOps), recherchent de nouveaux talents tous compl√©mentaires avec plusieurs niveaux de qualification et s√©niorit√©, qui travailleront en synergie avec la large palette de comp√©tences de Niji en d√©veloppement, communication, cybers√©curit√© et en conseil.\nInt√©grer le P√¥le Data de Niji c'est avoir l'assurance d'√™tre accompagn√© dans sa progression et le d√©veloppement rapide de ses comp√©tences ,vous suivez un\nparcours de formation\nriche et diversifi√©, visant √† vous faire rapidement monter en expertise et √† vous certifier.\nEn tant que\nML Engineer\n, vos principales missions seront les suivantes :\nD√©velopper et mettre en ≈ìuvre des mod√®les d'apprentissage automatique pour r√©soudre des probl√®mes complexes dans divers domaines, en utilisant des techniques telles que le deep learning, le reinforcement learning, etc.\nCollaborer avec les √©quipes de Data Science et les Data Engineers pour collecter, pr√©traiter et analyser les donn√©es n√©cessaires √† la cr√©ation de mod√®les efficaces.\nExploiter et optimiser les architectures informatiques et les infrastructures cloud pour garantir des performances optimales des mod√®les ML en production.\nAssurer la mise en place de processus de validation et de tests pour √©valuer la qualit√© et la fiabilit√© des mod√®les ML.\nParticiper au maintien de la documentation technique, les bonnes pratiques et les standards de d√©veloppement au sein de l'√©quipe.\nProfil recherch√©\nSi Vous\nAvez obtenu un dipl√¥me en universit√©, √©cole de commerce ou √©quivalent type bac +5\nMa√Ætrisez l'anglais √† l'√©crit comme √† l'oral\nAvez de solides compr√©hension des concepts ML, des outils et des frameworks tels que TensorFlow, PyTorch, Scikit-Learn, etc\nMa√Ætrisez les outils d‚Äôindustrialisation des pipelines data tel que Docker, Kubernetes, Dataiku, Jenkins‚Ä¶\nAvez une exp√©rience avec les langages de programmation utilis√©s dans le domaine des donn√©es, tels que : Python,R, Scala, SQL, etc.\nAvez une exp√©rience dans la conception et la mise en ≈ìuvre de pipelines de donn√©es\nAlors‚Ä¶ Venez participer au dynamisme de notre site en rejoignant notre Team Data Niji !\nL'aventure Niji\nProcess de recrutement : premier contact RH puis rencontre avec nos op√©rationnels.\nRejoindre l'exp√©rience Niji c'est avoir l'assurance de participer √† une aventure humaine dans un environnement de travail motivant, challengeant et innovant.\nNijiU: notre plateforme de formation digital learning contenant pr√®s de 3 000 modules en acc√®s libre.\nNos valeurs : Audace - Bienveillance - Performance ‚Äì Talent.\nSi ces mots vous parlent, venez faire la diff√©rence chez Niji !\nEn rejoignant Niji, vous int√©grez une entreprise dont la politique RSE contribue √† la promotion de la diversit√© et de l‚Äô√©galit√© des chances, notamment pour les personnes en situation de handicap.\nShow more\nShow less",
        "details": {
            "JobDetail": [
                "Confirm√©"
            ],
            "TypeContract": "",
            "Salary": "",
            "Level": "",
            "Experience": null
        },
        "title": "machine learning engineer",
        "skills": {
            "ProgLanguage": [
                "R",
                "Scala",
                "Python"
            ],
            "DataBase": [
                "SQL"
            ],
            "DataAnalytics": [
                "R"
            ],
            "MachineLearning": [
                "Scikit-Learn",
                "TensorFlow",
                "PyTorch"
            ],
            "DevTools": [
                "Jenkins",
                "Docker"
            ],
            "Automation": [
                "Kubernetes"
            ],
            "Containers": [
                "Docker",
                "Kubernetes"
            ],
            "Other": [
                "Cloud",
                "ML"
            ],
            "EnSoftSkils": [
                "Communication"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "SMARTIUM Group",
        "location": "Strasbourg, Grand Est, France",
        "link": "https://fr.linkedin.com/jobs/view/data-scientist-at-smartium-group-3835671392?position=1&pageNum=15&refId=YTnH3q6QeTQMMDDgtJs6iw%3D%3D&trackingId=yVAGS2vH8Aa8o0qMIJaNvw%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "SMARTIUM Group est une jeune startup bas√©e √† Starsbourg qui propose des technologies de mesure des rayonnements ionisants dans les domaines de l'industrie, de la sant√© et de la s√©curit√©. Dans le cadre de notre d√©veloppement nous recherchons\nun(e) Data Scientist\n.\nNos solutions embarqu√©es √† forte valeur ajout√©e permettent une analyse avanc√©e des dnn√©es fournies par les syst√®mes de mesure et par la mod√©lisation num√©rique (monte carlo).\nIssue de la valorisation des travaux de recherche, SMARTIUM Group b√©n√©ficie d'un lien renforc√© avec la recherche (CNRS) et les universit√©s.\nVos missions\nVous √™tes titulaire d'un Bac+5 et/ou doctorat en science de pr√©f√©rence, et vous avez pu d√©velopper des comp√©tences en simulation Monte Carlo (Genat4, MCNP, ...) et/ou en science des donn√©es (analyse statistique, apprentissage automatique, intelligence artificielle). Vous souhaitez valoriser ces comp√©tences dans un environnement professionnel dynamique d'une jeune startup Deeptech en lien direct avec la recherche.\nRattach√© directement au CEO vous contriburez au d√©veloppement de solutions innovantes vari√©es pour des probl√©matiques sant√©s, industrielles et environnementales.\nVotre implication et votre r√©ussite feront de vous un √©l√©ment cl√© du d√©veloppement de l'entreprise. Des prerspectives d'encadrement d'√©quipe sont envisag√©es pour les profils faisant preuve de qualit√©s manag√©riales.\nVos comp√©tences\nBac +5 en science/ physique nucl√©aire ; Int√©r√™t fort pour la science des donn√©es ; une exp√©rience/formation en simulation Monte Carlo serait un plus ; une ap√©tence pour l'analyse des donn√©es ; des connaissance en Intelligence Artificielle serait un plus ;\nAvantages\nAmbiance startup - Equipe dynamique - Salaire suivant profil + avantages\nShow more\nShow less",
        "details": {
            "JobDetail": [],
            "TypeContract": "",
            "Salary": "Salaire",
            "Level": "Bac+5",
            "Experience": null
        },
        "title": "data scientist",
        "skills": {}
    },
    {
        "source": "LinkedIn",
        "company": "G√©rard Perrier Industrie",
        "location": "Serres-Castet, Nouvelle-Aquitaine, France",
        "link": "https://fr.linkedin.com/jobs/view/stage-ing%C3%A9nieur-machine-learning-pour-tomographie-h-f-at-g%C3%A9rard-perrier-industrie-3767314230?position=2&pageNum=15&refId=YTnH3q6QeTQMMDDgtJs6iw%3D%3D&trackingId=HlJg%2BfQmKPe8gSGzuBLHqw%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Nous recherchons\nun(e) stagiaire Ing√©nieur Machine Learning pour Tomographie H/F\nqui rejoindra nos √©quipes bas√©es √† Serres-Castet (64) pour son stage d'√©cole d'ing√©nieur.\nNous avons d√©velopp√© un logiciel de traitement d'images en Python. Ce logiciel se base sur un algorithme et g√©n√®re un rapport de r√©sultats.\nRattach√©(e) au bureau d'√©tude R&D, vous aurez pour sujet l'optimisation d'une proc√©dure de contr√¥le tomographique et l'√©tude de nouvelles proc√©dures de d√©tection d'anomalie notamment en utilisant le machine learning.\nDans le cadre de vos missions vous serez emmen√© √† :\nPrendre en main le logiciel et comprendre son fonctionnement\nProposer des algorithmes de traitement d'image classique alternatifs √† l'algorithme actuel\nTester quels mod√®les seraient adapt√©s √† notre probl√©matique : classification supervis√©e, non-supervis√©e, deep learning\n√âtudier quelles seraient les caract√©ristiques √† extraire des images pour g√©n√©rer le mod√®le\nSi le temps le permet, d√©velopper les mod√®les et les √©valuer\nVotre Profil\nVous √™tes en formation Ing√©nieur et souhaitez r√©aliser votre stage dans les domaines du traitement d'image/traitement du signal, programmation et machine learning\nVous disposez de notion en programmation python et des notions de machine Learning\nVous avez des premi√®res connaissance sur le traitement d'images et/ou traitement du signal\nVous √™tes reconnu(e) pour votre rigueur et votre autonomie\nDynamique, vous √™tes reconnu(e) pour √™tre force de proposition et pour vos capacit√©s √† remettre en cause et approfondir les sujets\nCe Que Nous Vous Proposons\nUn stage dans une entreprise dynamique et √† taille humaine situ√©e √† Serres Castet (64) avec toutes les commodit√©s √† proximit√©\nUne gratification de stage\nDes titres restaurant et l'acc√®s au restaurant Inter-Entreprises\nVous vous √™tes reconnu dans notre annonce ?\nPostulez et venez rejoindre nos √©quipes !\nLocalisation du poste: Serres-Castet (64)\nType de contrat: Stage\nR√©mun√©ration : Gratification\nShow more\nShow less",
        "details": {
            "JobDetail": [],
            "TypeContract": "",
            "Salary": "",
            "Level": "",
            "Experience": null
        },
        "title": "Other",
        "skills": {
            "ProgLanguage": [
                "R",
                "Python"
            ],
            "DataAnalytics": [
                "R"
            ],
            "Other": [
                "Machine Learning"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "Pernod Ricard",
        "location": "Paris, √éle-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/machine-learning-engineer-at-pernod-ricard-3896432442?position=3&pageNum=15&refId=YTnH3q6QeTQMMDDgtJs6iw%3D%3D&trackingId=C%2BWUjH%2FfQ5N1Q%2BR35Mkb2A%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Want to join a fast-moving company, work among convivial teams and take part in the global growth strategy of one of the most prestigious and comprehensive portfolios in the wine & spirits industry?\nWe are looking for our Machine Learning Engineers‚Äã!\nYou will be based at The Island, our office in central Paris.\nIn this role, you‚Äôll have the chance to roll up your sleeves to make the date science models operational.\nYour key missions:\nReport directly to the manager of team Machine Learning Engineers and Research Scientists, you will join our cross-functional team of machine learning engineers, research scientists, data scientists and data engineers to contribute to the KEY DIGITAL PROGRAMS:\n¬∑ You will contribute to the MLOps process implementation to maintain ML models in production.\n¬∑ You will collaborate with the team to deploy or improve scalable and efficient ML pipelines using best MLOps practices.\n¬∑ You will collaborate with the team on production-quality service development with Unit & Integration testing, CI/CD & devOps for these services.\n¬∑ You will identify new opportunities to improve go-to-production, MLOps processes.\n¬∑ You will apply software development practices and standards to enhance and ensure the code quality of our applications.\n¬∑ You will maintain an active role in every part of the software development life cycle.\n¬∑ You will actively contribute to Data platform community.\nIf you recognize yourself in the description below, don‚Äôt wait to apply!\nYour profile:\n¬∑ You have a master diploma (or equivalent) in Computer Science, Computer Engineering, or quantitative science fields, a PhD is a plus.\n¬∑ You have more than 2 years implementation experience with high-level languages, such as Python, Scala, Java, C/C++.\n¬∑ You have knowledge and experience with cloud and deployment technologies. Knowing Microsoft Azure is a plus.\n¬∑ You have experience in building or improving CI/CD pipelines.\n¬∑ You have knowledge and experience with container tools such as Docker.\n¬∑ You are familiar with MLOps practices (Azure ML Studio, Mlfow)\n¬∑ You have knowledge and experience in designing and building APIs with Python\n¬∑ You have first experiences in data science and applying machine learning algorithms and libraries (Pandas, Scikit-learn, Pytorch ...)\n¬∑ You are fluent in English, speaking French is a plus.\nWe will appreciate if you are familiar with:\n¬∑ Microservices architecture\nYour soft skills:\n¬∑ You have very good oral and written communication skills\n¬∑ You have an analytic reasoning and problem-solving skills.\n¬∑ You are service-oriented, flexible and a team player.\n¬∑ You have a real attention to detail and a technical intuition.\n¬∑ You are driven by passion and willingness to learn and explorer.\nIf you don‚Äôt fill 100% of the criteria below don‚Äôt panic, we expect you to learn with us in this position.\nWait, there‚Äôs more‚Ä¶\nWe offer you an outstanding and collaborative workplace that embodies our sharing & conviviality culture, the possibility to work from home (2 days a week), a very complete health insurance, an attractive compensation including profit-sharing, train daily, employee events‚Ä¶\nPernod Ricard values diversity and solidarity within its organization and in its relations with stakeholders. Our recruitment methods focus on skills, and we welcome all types of talents.\nShow more\nShow less",
        "details": {
            "JobDetail": [],
            "TypeContract": "",
            "Salary": "",
            "Level": "",
            "Experience": null
        },
        "title": "machine learning engineer",
        "skills": {
            "ProgLanguage": [
                "Java",
                "Scala",
                "Python"
            ],
            "DataAnalytics": [
                "Pandas"
            ],
            "MachineLearning": [
                "Scikit-Learn",
                "PyTorch"
            ],
            "CloudComputing": [
                "Azure"
            ],
            "DevTools": [
                "Docker"
            ],
            "Containers": [
                "Docker"
            ],
            "Collaboration": [
                "Teams"
            ],
            "Other": [
                "CI/CD",
                "ML",
                "Machine Learning",
                "Cloud",
                "DevOps"
            ],
            "EnSoftSkils": [
                "Communication",
                "Organization"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "eekem group",
        "location": "Biot, Provence-Alpes-C√¥te d'Azur, France",
        "link": "https://fr.linkedin.com/jobs/view/python-software-engineer-h-f-at-eekem-group-3902428372?position=4&pageNum=15&refId=YTnH3q6QeTQMMDDgtJs6iw%3D%3D&trackingId=yXXc5Sv5zD7hOM1patGHOA%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Pr√©sentation de l‚Äôentreprise :\nActeur des services du num√©rique, notre soci√©t√© s‚Äôengage √† satisfaire l‚Äôambition de ses clients dans leurs projets digitaux en France et √† l‚Äôinternational. Nous nous engageons sur des projets √† forte valeur ajout√©e pour nos ing√©nieurs et mettant en ≈ìuvre les derni√®res briques technologiques aussi bien aupr√®s de startups ambitieuses que chez des grands comptes.\nSe challenger, se d√©velopper et viser l‚Äôexcellence sont des notions inscrites dans notre ADN. EEKEM construit ses √©quipes avec exigence et bienveillance. Nos collaborateurs sont autant acteurs de leur carri√®re qu‚Äôambassadeurs de notre soci√©t√©, et nous sommes fiers de leur expertise et de leur potentiel. Avec eux, nous privil√©gions l‚Äô√©coute, la disponibilit√©, et le suivi personnalis√©. Faire une seule et m√™me √©quipe avec nos collaborateurs et cr√©er des moments de rassemblement fait partie int√©grante de notre culture.\nD√©tails du poste :\nEn relation √©troite avec la ma√Ætrise d‚Äôouvrage notre\nD√©veloppeur Python\ndevra accompagner un √©diteur de logiciel sur des applications de pricing supportant des dizaines de milliers de transactions par seconde et incluant des centaines de fonctionnalit√©s bas√©es sur des algorithmes complexes.\nLa mission\nCollaboration avec les √©quipes m√©tier et AMOA pour la d√©finition des besoins utilisateurs pour le d√©veloppement des nouvelles solutions logicielles\nConception, d√©veloppement et mise en production de nouvelles fonctionnalit√©s en environnement Agile.\nConduite de tests unitaires, de tests d'int√©gration et de tests de performance.\nAnalyse de performance et optimisation.\nParticipation √† l'innovation et √† la veille technologique.\nProduction de la documentation logiciel n√©cessaire au maintien de l‚Äôapplicatif.\nNotre ing√©nieur sera confront√© √† des probl√©matiques de scalabilit√©, de robustesse, de latence et de performance, dans le cadre de processus temps r√©el et √©voluera dans un environnement technique diversifi√©, avec de multiples technologies, syst√®mes d'exploitation et bases de donn√©es.\nIl devra aussi savoir √©voluer dans un contexte o√π des m√©thodes pouss√©es de s√©curit√© sont appliqu√©es, o√π le traitement de volumes de donn√©es massives est une priorit√© et o√π l'adaptation des architectures vers le cloud requiert √† la fois int√©grit√© et pr√©cision.\nLe profil :\nDipl√¥m√©(e) d'une √©cole d'ing√©nieur ou d'une formation sup√©rieure universitaire √©quivalente vous avez une premi√®re exp√©rience significative en d√©veloppement Python. Vous poss√©dez une solide connaissance des principes de\nla programmation OO\net des mod√®les de conception et √™tes capable d‚Äôappr√©hender des architectures complexes et vous souhaitez participer √† l‚Äôensemble du cycle de d√©veloppement\nMotiv√©, dynamique, sociable, vous √™tes capable de vous int√©grer dans des √©quipes multiculturelles et anglophones et sur des projets d'envergure internationale si besoin.\nShow more\nShow less",
        "details": {
            "JobDetail": [],
            "TypeContract": "",
            "Salary": "",
            "Level": "",
            "Experience": null
        },
        "title": "software engineer",
        "skills": {
            "ProgLanguage": [
                "Python"
            ],
            "Other": [
                "Cloud"
            ],
            "EnSoftSkils": [
                "Collaboration"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "Fnac Darty",
        "location": "Ivry-sur-Seine, √éle-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/data-scientist-f-h-at-fnac-darty-3805367610?position=5&pageNum=15&refId=YTnH3q6QeTQMMDDgtJs6iw%3D%3D&trackingId=DAUq1yjuYdJxWusDpByglg%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Fnac Darty, un leader europ√©en de la distribution omnicanal. Acteur omnicanal et europ√©en, sp√©cialis√© dans la distribution de produits techniques et d'√©lectrom√©nager, de biens culturels et de loisirs, et leader du service apr√®s-vente : 975 magasins dans le monde, 27 Millions de visiteurs uniques cumul√©s par mois sur nos sites marchands. Nos 25 000 collaborateurs sont notre meilleur atout. Ils font vivre la raison d'√™tre du Groupe au quotidien, qui consiste √† ¬´ s'engager pour un choix √©clair√© et une consommation durable ¬ª, aupr√®s de nos clients. Fnac Darty recrute partout en France des talents aux profils, formations et exp√©riences tr√®s diverses, que ce soit pour ses magasins, mais aussi dans les domaines de la logistique, de la r√©paration et service apr√®s-vente, de la livraison, de la relation client ou encore pour ses fonctions support. Votre prochain emploi vous attend chez Fnac Darty !\nLe groupe Fnac-Darty acc√©l√®re sa trajectoire dans la data et l‚ÄôIA.\nVous souhaitez mettre en oeuvre et d√©velopper vos comp√©tences en data science sur des projets √† fort impact dans un march√© en √©volution rapide ? Vous voulez travailler dans une √©quipe dynamique aussi passionn√©e que comp√©tente et d√©velopper votre carri√®re ? Alors n‚Äôh√©sitez plus et rejoignez-nous au sein du groupe Fnac-Darty !\nVous rejoindrez la direction de la Transformation Data & IA du Groupe au sein du d√©partement Strat√©gie et Transformation et travaillerez sur des sujets-cl√©s visant impact et transformation de nos m√©tiers dans l‚Äôensemble des activit√©s du groupe. Sujets parmi lesquels peuvent figurer par exemple l‚Äôam√©lioration de l‚Äôexp√©rience client et de l‚Äôefficience de nos interactions (service apr√®s-vente,‚Ä¶), l‚Äôoptimisation de nos budgets promotionnels, le scoring d‚Äôapp√©tence des utilisateurs, le churn, l‚Äôactivation d‚Äôaudiences, la personnalisation des parcours, la d√©tection d‚Äôanomalies, etc‚Ä¶\nForts d‚Äôune implantation particuli√®rement forte en France et √† l‚Äôinternational tant via Internet que via nos magasins, experts reconnus et marques appr√©ci√©es, nous agissons sur une gamme de produits, de services et d‚Äô√©v√©nements extr√™mement large aupr√®s d‚Äôune large partie des populations de ces pays. Vous travaillerez donc sur des donn√©es tr√®s riches dans un environnement technologique √† la pointe.\nVotre profil\nEcole d‚Äôing√©nieurs (Centrale, ENS, Mines, Ecole Polytechnique, etc‚Ä¶) en formation initiale, avec sp√©cialisation en math√©matiques / data science / machine learning\nVous connaissez les math√©matiques derri√®re les algorithmes et √™tes capable de r√©fl√©chir un algorithme d√©di√© si besoin et de le mettre en oeuvre\nVous √™tes exp√©riment√© sur le cloud, Google Cloud appr√©ci√© (dont en particulier BigQuery, Compute Engine, Cloud Storage) et vous ma√Ætrisez les librairies d√©di√©es (command-line + Python) ainsi que les outils de versioning tel git\nBash, SQL et Python sont des langages que vous ma√Ætrisez √† un niveau avanc√©\nVous √™tes capables d‚Äôint√©grer les flux de donn√©es n√©cessaires de mani√®re automatique et p√©renne\nVous savez passer vos algorithmes √† l‚Äô√©chelle et mettre en oeuvre un ensemble robuste et stable sur de grosses volum√©tries pour d√©ploiement en production ; mieux, vous pensez le passage √† l‚Äô√©chelle et l‚Äôindustrialisation d√®s le d√©but du projet\nVous √™tes capables de construire les analyses et algorithmes pertinents avec une palette large et compl√®te d‚Äôoutils (librairies Python d√©di√©es ; features GCP exploitables ; BigQuery ; ‚Ä¶), mais aussi de construire des visualisations\nShow more\nShow less",
        "details": {
            "JobDetail": [],
            "TypeContract": "",
            "Salary": "",
            "Level": "",
            "Experience": null
        },
        "title": "data scientist",
        "skills": {
            "ProgLanguage": [
                "Bash",
                "Python"
            ],
            "DataBase": [
                "SQL"
            ],
            "CloudComputing": [
                "GCP"
            ],
            "DevTools": [
                "Git"
            ],
            "DBMS": [
                "BigQuery"
            ],
            "Other": [
                "Machine Learning",
                "Cloud"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "CHANEL",
        "location": "Paris, √éle-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/stage-data-scientist-h-f-at-chanel-3904548050?position=6&pageNum=15&refId=YTnH3q6QeTQMMDDgtJs6iw%3D%3D&trackingId=4m9xE%2Fe2V%2BFqcBtMkubwig%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "A propos du poste\nLa ¬´ Business Services Platform ¬ª se positionne en conseil interne, partenaire de tous nos d√©partements fonctionnels, aux diff√©rents niveaux de l‚Äôorganisation europ√©enne : corporate, r√©gion, march√©s et boutiques.\nElle se d√©compose en trois finalit√©s op√©rationnelles compl√©mentaires\nNotre mission D&A, ¬´ Data Science & Advanced Analytics ¬ª est de d√©finir et r√©aliser des cas d‚Äôusage pragmatiques et concrets via une approche projet it√©rative et courte.\nEn tr√®s forte collaboration avec les acteurs op√©rationnels, dot√© d‚Äôune expertise math√©matique adapt√©e √† nos besoins sp√©cifiques, nous produisons du business consulting, des mod√®les math√©matiques et algorithmiques performants et op√©rants.\nEn tr√®s forte collaboration avec les acteurs IT, nous construisons au fil des cas d‚Äôusage, nos plateformes europ√©ennes de donn√©e et d‚Äôalgorithme, normalis√©es, industrialis√©es, orient√©es business et services.\nStage de 6 mois √† pourvoir d√®s que possible.\nVotre impact chez CHANEL\nDans une approche it√©rative, progressive et coconstruite avec l‚Äôexpert op√©rationnel et les acteurs IT data-ops / dev-ops. Avec un temps de production court : 1 √† 3 mois par cas d‚Äôusage, depuis la d√©finition d√©taill√©e du besoin r√©el jusqu‚Äôau mod√®le op√©rant en production.\nDans une √©laboration progressive, fonctionnelle et coh√©rente de la plateforme cible de donn√©es et d‚Äôalgorithmes ¬´ as a service ¬ª, vous serez un appui au service sur les sujets suivants :\nPr√©parer et participer aux ateliers de d√©finition d√©taill√©e, dans une approche produit / process cible, et coupl√©e consulting m√©tier / analyse exploratoire statistique de la donn√©e.\nProduire les livrables formels et synth√©tiques de conception d√©taill√©e.\nAligner et mod√©liser la solution math√©matique et algorithmique, dans le respect de nos normes internes (scripts, framework de packages, performance, exposition / -visualisation) et de la contrainte it√©rative.\nTester avec l‚Äôexpert op√©rationnel : former et valider la solution de calcul avanc√©, sa restitution et son monitoring op√©rationnel.\nTransmettre √† l‚ÄôIT les √©l√©ments et le support n√©cessaires d‚Äôindustrialisation (mode batch - pipeline ou mod√®le conteneuris√©).\nDocumenter et garantir l‚Äôauditabilit√© des mod√®les produits.\nContribuer au pilotage du projet : tenue des √©ch√©ances, anticipation des risques, mise en production\nExemples de cas d‚Äôusage potentiels pendant le stage : optimisation de la distribution et de la r√©partition des stocks dans le r√©seau retail, optimisation de la planification des boutiques, pr√©visions commerciales, financi√®res, des effectifs‚Ä¶\nCe que vous apporterez\nDipl√¥m√© d‚Äôune √©cole d‚Äôing√©nieur, option math√©matiques appliqu√©es / data science\nExp√©rience accomplie, avec des cas d‚Äôusage op√©rationnels et en production, sur des sujets de :\nS√©ries temporelles\nMod√®les d‚Äôoptimisation\nMod√®les de r√©gression et de classification (machine & deep learning)\nMa√Ætrise des frameworks classiques d‚Äôanalyse statistique et de mod√©lisation ; e.g. en Python :\nnumpy, pandas, matplotlib, statsmodel‚Ä¶\npmdarima, scikit-learn, scipy, tensorflow / keras, pytorch‚Ä¶\nMaitrise du langage Python\nPremier stage accompli de d√©finition / validation du besoin m√©tier, en approche coupl√©e ¬´ business consulting ¬ª & analyse exploratoire et statistique des donn√©es. Si possible dans les fonctions finance et op√©rations.\nCulture et savoir-faire en mode projet pilot√© de bout en bout, en double interface m√©tier et IT\nCuriosit√©, vivacit√© et agilit√© d‚Äôesprit\nInfluenceur, prescripteur et fort esprit de collaboration\nSens du r√©sultat et du service au client, p√©dagogie op√©rationnelle\nAnglais\nCe que CHANEL peut vous offrir\nChez CHANEL, nous nous attachons √† cr√©er une culture inclusive qui favorise l'√©panouissement et le d√©veloppement personnel tout en contribuant √† la performance collective. Nous avons la conviction que la singularit√© de chaque personne contribue √† renforcer la diversit√©, la compl√©mentarit√© et l'efficacit√© de nos √©quipes. Nous encourageons vivement votre candidature, car nous accordons une grande importance √† l'exp√©rience et au potentiel que vous pourriez apporter √† la Maison CHANEL.\nShow more\nShow less",
        "details": {
            "JobDetail": [],
            "TypeContract": "",
            "Salary": "Package",
            "Level": "",
            "Experience": null
        },
        "title": "data scientist",
        "skills": {
            "ProgLanguage": [
                "Python"
            ],
            "DataAnalytics": [
                "NumPy",
                "Pandas"
            ],
            "MachineLearning": [
                "Scikit-Learn",
                "PyTorch",
                "TensorFlow",
                "Keras"
            ],
            "DataVisualisation": [
                "Matplotlib"
            ],
            "EnSoftSkils": [
                "Collaboration"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "Oliver James",
        "location": "Paris, √éle-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/machine-learning-engineer-at-oliver-james-3917497308?position=7&pageNum=15&refId=YTnH3q6QeTQMMDDgtJs6iw%3D%3D&trackingId=ecF33rOE7Z%2FKf46tNZEUcg%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Oliver James Paris accompagne un de leurs clients, un groupe industriel fran√ßais pr√©sent √† l'international, dans le recrutement urgent d'un ing√©nieur machine learning exp√©riment√© (au moins 5 ans d'exp√©rience en production/industrialisation de mod√®les ML). La mission est √† pourvoir urgemment.\nVous √©voluerez dans un environnement particuli√®rement innovant dans l'intelligence artificielle dans une √©quipe passionn√©e. Cette mission peut s'effectuer en t√©l√©travail complet si d√©sir√©, bien que les locaux se situent dans Paris intramuros si vous souhaitez vous y rendre. Vous disposerez d'une forte autonomie sur ce poste en tant qu'expert machine learning. La mission est √©galement renouvelable au-del√† de la p√©riode de 6 mois.\nLe candidat id√©al dispose d'au moins 5 ans d'exp√©rience en cr√©ation/industrialisation de mod√®les ML, et id√©alement √©galement sur la partie MLOps. Vous maitrisez parfaitement Databricks et Kubernetes, √©galement les outils de configuration de machines virtuelles.\nSi vous √™tes int√©ress√©, merci de nous contacter au plus vite.\nShow more\nShow less",
        "details": {
            "JobDetail": [],
            "TypeContract": "",
            "Salary": "",
            "Level": "",
            "Experience": "5 an(s)"
        },
        "title": "machine learning engineer",
        "skills": {
            "BigData": [
                "Databricks"
            ],
            "Automation": [
                "Kubernetes"
            ],
            "Containers": [
                "Kubernetes"
            ],
            "Other": [
                "Machine Learning",
                "ML"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "DataScientest.com",
        "location": "Puteaux, √éle-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/data-scientist-h-f-stage-at-datascientest-com-3887999540?position=9&pageNum=15&refId=YTnH3q6QeTQMMDDgtJs6iw%3D%3D&trackingId=1ACZxshffCsL3E1f14UnJg%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Data Scientist (H/F) | Stage\nPuteaux\nStage\nPostuler\nRetour\nDatascientest Is Hiring!\nData Scientist (H/F) | Stage\n√Ä propos\nü§ùüèªDataScientest ?\nDataScientest, est le leader de la formation aux m√©tiers de la Data, en Europe\nLa pluralit√© des formations propos√©es et la disponibilit√© de ses √©quipes talentueuses permet √† tous les apprenants (B2B, B2C), quels que soient leurs besoins (reconversion professionnelle, d√©veloppement de comp√©tences, professionnalisation), et leur niveau, de se perfectionner, de progresser, d‚Äô√™tre coach√©s et de booster leur carri√®re dans le monde de la Tech.\nDe plus, DataScientest propose des formations adapt√©es aux objectifs de ses entreprises partenaires, notamment √† travers son √©troite collaboration avec p√¥le emploi, mais √©galement des particuliers qui b√©n√©ficient d‚Äôun accompagnement personnalis√© (√©quipes career & customer care).\nEnfin, DataScientest ≈ìuvre pour l‚Äôemployabilit√© et le d√©veloppement des comp√©tences de ses apprenants, notamment √† travers les dispositifs de POEI et l‚Äôouverture de son centre de formation en apprentissage (CFA).\nüìàEn Quelques Chiffres\nPlus de 7000 apprenants inscrits et satisfaits,\n70 groupes partenaires, dont 30 du CAC40,\n2 partenaires acad√©miques prestigieux : Mines Paris Executive Education et l'Universit√© Panth√©on La Sorbonne,\nDes partenaires √©diteurs majeurs : AWS, Microsoft Azure\nüèÜSes Ambitions\nD‚Äôici 3 ans, DataScientest a pour objectif de devenir un champion mondial en continuant √† proposer des produits de formation qui r√©pondent aux besoins du march√© et en poursuivant son expansion g√©ographique,\nAfin d‚Äôappuyer son statut de leader, DataScientest continue de se d√©velopper √† l‚Äôinternational et de cr√©er ses propres √©coles en Cybers√©curit√© et DevOps adapt√©es aux besoins du march√© (CyberUniversity, DevUniversity) !\nComment ? Avec un format p√©dgogique hybride unique, un studio R&D et surtout les √©quipes de DataScientest qui donnent le meilleur d'eux m√™me au quotidien pour d√©livrer des formations de qualit√© !\nDescriptif du poste\nAu sein de l‚Äô√©quipe data-science, votre r√¥le s‚Äôarticule autour des axes suivants :\nContribution active au d√©veloppement d‚Äôun produit de formation √† venir. C‚Äôest l‚Äôoccasion r√™v√©e pour acqu√©rir les comp√©tences de demain‚Ä¶ avant tout le monde üöÄ.\nMentorat et accompagnement sur des produits existants\n(Si souhait√©) Participation √† la strat√©gie R&D du d√©partement Tech\nProfil recherch√©\nChez Datascientest, nous valorisons la diversit√© des profils et sommes convaincus par la force du collectif. Cette offre d'emploi est ouverte √† tous, quel que soit votre niveau d‚Äôexp√©rience.\nI\nssu(e) d‚Äôune formation orient√©e data-science vous √™tes :\nCapable de g√©rer des charges de travail parfois √©lev√©es.\nBonne ma√Ætrise de Python.\nLa ma√Ætrise de la programmation orient√© objet et/ou du cloud computing est un plus.\nBonne culture data-science et attrait pour l‚Äôactualit√© relative aux machine learning au sens large.\nBon niveau r√©dactionnel et oral en fran√ßais/anglais.\nPr√™t √† √©norm√©ment apprendre et √† vivre une exp√©rience unique dans un environnement start-up.\nAttrait pour la polyvalence et capacit√© √† g√©rer plusieurs projets de front.\nProcess de recrutement\nChez DataScientest, nous avons √† c≈ìur d'offrir la meilleure exp√©rience candidat. Nous utilisons donc la plateforme Avoda√Ø pour r√©f√©rencer les candidats qui passent plusieurs √©tapes dans nos process de recrutement, aupr√®s de nos entreprises partenaires.\nInformations compl√©mentaires\nType de contrat : Stage (6 √† 6 mois)\nDate de d√©but : 01 septembre 2023\nLieu : Puteaux\nT√©l√©travail ponctuel autoris√©\nVous √™tes int√©ress√© par cette offre ?\nPostuler\nShow more\nShow less",
        "details": {
            "JobDetail": [
                "Hybride"
            ],
            "TypeContract": "",
            "Salary": "",
            "Level": "",
            "Experience": "3 an(s)"
        },
        "title": "data scientist",
        "skills": {
            "ProgLanguage": [
                "R",
                "Python"
            ],
            "DataAnalytics": [
                "R"
            ],
            "CloudComputing": [
                "AWS",
                "Azure"
            ],
            "Other": [
                "Machine Learning",
                "Cloud",
                "DevOps"
            ],
            "EnSoftSkils": [
                "Collaboration"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "Equativ",
        "location": "Nantes, Pays de la Loire, France",
        "link": "https://fr.linkedin.com/jobs/view/junior-software-engineer-at-equativ-3909983597?position=10&pageNum=15&refId=YTnH3q6QeTQMMDDgtJs6iw%3D%3D&trackingId=mXJ6FwOrvXC%2BfA8AK1enHQ%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "üë´ About the team\nAt Equativ, we‚Äôre on a mission to develop advertising technologies that empower our customers to reach their digital business goals. This means that we rely on massively scalable, widely distributed, highly available, and efficient software systems; the platform deals with over 3 millions requests per second managed by 3,000 servers.\nOur innovation team based in Paris, Nantes, Limoges, Krakow and Berlin is composed of 100+ straightforward and energetic engineers working in an Agile environment and ready to tackle the most complex technical challenges.\nYour mission üëá\nInside a team of 4, you will work closely with all R&D teams (and even with other divisions!) to improve each step of the development cycle amongst Equativ. You will develop tools and implement automation to accelerate development, improve build reliability & stability and improve the overall productivity of each Equativ employee. You will challenge existing processes to reinforce the quality of our products.\nWhat you'll do ‚úèÔ∏è\nEngineering internal systems and tools to support both build and verification of our products, as well as automate work process\nEnforce software development best practices\nIdentify, collaborate and implement process improvement opportunities\nDetect impediments and advocate for their resolution\nShow our technical skills outside Equativ by going open source on key projects\nSome examples of the projects we are working on :\nOnboarding/Offboarding automation (account creation for newcomers or deactivation when someone leave) through APIs\nThe Timeline, an internal tool developed from scratch showing a state of the art of our product deployments, customer activations, infra interventions\nDeployment of test environments on-the-fly, just by moving a Jira\nAbout You üí™\nYou have a master‚Äôs degree in Computer Science or a similar technical field of study\nYou have 1+ years experience (apprenticeship accepted) in software development\nYou have a programming experience in C# or JavaScript/Typescript (Angular) and SQL\nYou are also interested in agile development methodologies, in continuous integration and its tools like GitLab, Sonarcloud, Jira‚Ä¶\nYou are self-driven and a team player with a solid work ethic\nYou are a hands-on problem-solver\nFluent English is required\nüëã About us\nEquativ is the new single name for Smart Adserver, DynAdmic, LiquidM and Nowtilus ‚Äî four proven innovators in advertising technology. The vertically integrated company provides brand and privacy-safe solutions that empower its clients to achieve maximum impact while respecting the rights of consumers. The union combines client expertise and engineering excellence to serve the interests of both the supply- side and demand-side with equal professionalism and technical sophistication.\nHeadquartered in Paris and New York, Equativ operates globally with a team of more than 550 people in 20 offices. Equativ offers the market its own independent ad server, SSP, buyer tools, and media services to fulfill the promise of advertising technology. Learn more at Equativ.com.\nThe company is ranked on the Deloitte Technology Fast 500 EMEA and in the Financial Times‚Äô FT 1000: Europe‚Äôs Fastest-Growing Companies.\nEquativ (formerly Smart AdServer) has been awarded the HappyIndex@Work label and is proud to be among the best companies in the ChooseMyCompany ranking, recognized for its flexible working environment.\nCome and lead the charge with us in building a transparent ecosystem based on quality!\nEquativ is an equal opportunity employer. Equal access to employment, services, and programs are available to everyone, regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity, or Veteran status. If you require reasonable accommodation throughout the application and/or interview process, please contact the recruitment team at ta-team@equativ.com\nShow more\nShow less",
        "details": {
            "JobDetail": [],
            "TypeContract": "",
            "Salary": "",
            "Level": "",
            "Experience": null
        },
        "title": "software engineer",
        "skills": {
            "ProgLanguage": [
                "R"
            ],
            "DataBase": [
                "SQL"
            ],
            "DataAnalytics": [
                "R"
            ],
            "Collaboration": [
                "Teams",
                "JIRA"
            ]
        }
    }
]