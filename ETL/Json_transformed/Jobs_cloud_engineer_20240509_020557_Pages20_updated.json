[
    {
        "source": "LinkedIn",
        "company": "A2MAC1 - Decode the future",
        "location": "Boulogne-Billancourt, √éle-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/cloud-engineer-at-a2mac1-decode-the-future-3838857174?position=2&pageNum=0&refId=NuDbZkBPOnBALTaaBOYlpw%3D%3D&trackingId=BLMdFgmB%2FuSr15l9YXXUMg%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Under the direction of the IT Operations Manager, design & implement information systems architectures and evolutions for cloud environments.\nHe/she proposes a solution that meets the needs, evolutions and strategy of the company in terms of computer systems.\nIt defines and ensures the application of policies and good practices.\nTask and Activities :\nDesign, deploy, and manage cloud infrastructure and services using Azure technologies and best practices\nEnsure build/run of our cloud infrastructure in a devops method\nEnsure the application of A2MAC1 standards, processes, and IT policies\nMonitor and optimize cloud resources, costs, and performance using Azure tools and metrics\nApply and enforce security policy\nDefines and enforces the governance of our cloud solutions\nParticipate in IT infrastructure evolution projects, and take charge of the architecture\nEnsures the maintenance and evolution of technical architectures\nImplement and enforce cloud security policies and standards using Azure security features and services\nTroubleshoot and resolve cloud-related issues and incidents using Azure diagnostics and support tools\nCollaborate with other IT teams and stakeholders to ensure alignment and integration of cloud solutions and services, be the referent/contact point for cloud topics\nStay updated with the latest trends and developments in cloud technologies and Azure offerings\nRequirements\nProfessional Skills Required :\nProficient in Azure core services, such as Compute, Storage, Networking, Security, Identity, and Management\nFamiliar with Azure DevOps, PowerShell, CLI, and other scripting and automation tools\nKnowledge of cloud architecture patterns, principles, and best practices\nExcellent communication, collaboration, and problem-solving skills\n\"Team Player\" attitude\nCapacity to work with an agile methodology, Kanban approach\nGreat interpersonal, problem-solving, analytical, and research skills\nWriting of documentations and creation of architecture diagrams\nKnowledge Required :\nMUST-HAVES\nProfessional English\nExpertise in\nAzure PaaS, IaaS, network...\nAzure Active Directory & Office 365\nTerraform, Ansible\nPaaS web oriented : azure webapp, sql managed instances, frontdoor, nsg, app gw\nNetwork : switch, firewall, TCP/IP, DNS, DHCP\nCybersecurity\nSystem: Microsoft Server OS, Linux\nAzure CLI, Powershell scripting\nOn premise system infrastructure (hardware, virtualization, storage, backup...)\nGood knowledge of relevant ITIL / ITSM / ISO27001 / NIST best practice standards and IT technologies\nNICE-TO-HAVES\nKnowledge of various IT and business functions, software development process\nProfessional French or German or Chinese\nShow more\nShow less",
        "details": {
            "JobDetail": [],
            "TypeContract": "",
            "Salary": "",
            "Level": "",
            "Experience": null
        },
        "title": "cloud architect /engineer ",
        "skills": {
            "DataBase": [
                "SQL"
            ],
            "CloudComputing": [
                "Azure"
            ],
            "OS": [
                "Linux"
            ],
            "Automation": [
                "Ansible"
            ],
            "InfrastructureAsCode": [
                "Terraform"
            ],
            "NetworkSecurty": [
                "Firewall"
            ],
            "Collaboration": [
                "Teams"
            ],
            "Other": [
                "Cloud",
                "DevOps"
            ],
            "EnSoftSkils": [
                "Communication",
                "Collaboration"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "Lengow",
        "location": "Nantes, Pays de la Loire, France",
        "link": "https://fr.linkedin.com/jobs/view/devops-engineer-at-lengow-3873989468?position=3&pageNum=0&refId=NuDbZkBPOnBALTaaBOYlpw%3D%3D&trackingId=aVRzrTek0bmAzca%2FSzCszg%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "ü§ì\nLengow, an intelligent and automated e-commerce platform :\nSince 2009, Lengow has been the indispensable e-commerce platform for multi-channel expansion in the European market: marketplaces, price comparison websites, affiliate marketing, display ad retargeting, social media, etc.\nAll jobs are open in Nantes/ Paris/ Barcelona.\nThe Infrastructure team manages the hosting provider for the production platform, and implements and maintains non-production environments, the CI/CD solution, and related tools.\nThe team also participates in the evaluation and deployment of new solutions (product evolution or custom projects)\nYour main goals: ensure the satisfaction of customers, as well as internal users. Ensure service continuity, propose and implement changes to achieve the objectives of reliability and scalability of the resources provided to developers.\n‚å®Ô∏è Your main tasks would be as follows :\nMission 1:\nYou will design, implement and maintain CI and CD pipelines\nYou will provide advice and expertise on the integration workflows to be implemented to achieve the continuous integration target\nMission 2:\nYou will ensure the deployment and maintenance of all our environments on AWS\nYou will check the resource requirements to ensure the efficiency, scalability, and reliability of our different environments\nYou will make sure that we control our expenses (FinOps) and that our platform is secure (SecOps)\nYou will help optimising our environments and move to managed resources when relevant (PostgreSQL to Aurora, for example)\nü™ú Hiring Process :\nPhone call with our HR\nInterview with Clement, Head of Infrastructure and Adrien DevOps\nCase study restitution with Marine, CTO at Lengow and Cl√©ment\nReference check and offer letter\nRequirements\nüèπ We are looking for someone with the following experiences and skills:\nExperiences :\nAn experience in a similar position for at least 2 years\nAny experience as a developer could also be greatly appreciated.\nSkills & soft skills\nIn-depth AWS knowledge (Solution Architect Associate or SysOps Admin Associate)\nKubernetes, Terraform, Ansible\nAffinities with Python, PostgreSQL, async processes\nGCP knowledge a bonus\nAutonomy, responsibility, ownership and determination\nTeam-oriented and proactive\nBenefits\n‚ú®\nJoining Lengow is also an opportunity to benefit from many advantages :\nTicket restaurant 8 euros by day\nMalakoff Humanis Private insurance & Prevoyance\nHybrid remote policy\nFlexible hours\nBike mileage allowances or 50% of transportation tickets\nRemote allowances\nProfessional events (Devoxx, Meetup ...) and regular internal events\nShow more\nShow less",
        "details": {
            "JobDetail": [
                "Remote"
            ],
            "TypeContract": "",
            "Salary": "",
            "Level": "",
            "Experience": null
        },
        "title": "devops",
        "skills": {
            "ProgLanguage": [
                "Python"
            ],
            "CloudComputing": [
                "GCP",
                "AWS"
            ],
            "DBMS": [
                "PostgreSQL"
            ],
            "Automation": [
                "Kubernetes",
                "Ansible"
            ],
            "InfrastructureAsCode": [
                "Terraform"
            ],
            "Containers": [
                "Kubernetes"
            ],
            "Other": [
                "DevOps",
                "CI/CD"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "Capgemini",
        "location": "Paris",
        "link": "https://fr.linkedin.com/jobs/view/devops-engineer-at-capgemini-3402745877?position=4&pageNum=0&refId=NuDbZkBPOnBALTaaBOYlpw%3D%3D&trackingId=jWEPBWglKev4eyrn5DFeuw%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Tu commences √† faire le tour de ton poste et √† manquer de projection ?\nL‚Äôheure est arriv√©e d‚Äôoser et donner un nouvel √©lan √† ta carri√®re : C&CA est faite pour toi !\nChez Capgemini,\nnous t‚Äôaidons √† construire ta carri√®re en mettant\nen place\ntout un accompagnement et un panel d‚Äôoutils, pour continuer √† te challenger au quotidien\n!\nQuelques raisons de nous croire\nCe que nous te proposons en tant que collaborateur Capgemini c‚Äôest de rejoindre des √©quipes d‚Äôexperts passionn√©s par l‚Äôinnovation et les challenges. Tu auras l‚Äôopportunit√©s de travailler sur la mise en place de solutions innovantes de A √† Z pour r√©pondre aux diff√©rents enjeux de nos clients et d‚Äô√©voluer dans une communaut√© d‚Äôexpert √† l‚Äô√©coute ou le mot d‚Äôordre est le partage !\nEn projet ton r√¥le sera de\nParticiper au d√©veloppement applicatif (en fonction de la taille du projet)\nConcevoir des pipelines DevOps (jobs Jenkins, t√¢ches Gradle/MAVEN ‚Ä¶)\nParticiper √† l‚Äôautomatisation des processus ou des cha√Ænes de traitement\nParticiper et valider les architectures techniques cibles\nParticiper √† optimiser et automatiser les d√©ploiements applicatifs (CI/CD)\nPr√©parer les tests techniques pour les recettes techniques\nR√©diger de la documentation technique\nLes domaines suivants t‚Äôint√©ressent\nAutomatisation / Industrialisation : Powershell, Bash, Perl, Git/ GitLab, VSTS, Jenkins, Ansible, Nexus\nCloud : AWS, Azure, GCP‚Ä¶\nInfra As Code : Terraform, Cloudformation, Troposhpere, ‚Ä¶\nDocker / Kubernetess\nQui es-tu ?\nCe qui nous int√©resse au-del√† des comp√©tences que nous recherchons, c‚Äôest ta personnalit√©, ton d√©sir d‚Äô√©voluer et de monter en comp√©tences. La force de notre entreprise est de te donner l‚Äôopportunit√© de construire ta trajectoire de carri√®re en te fournissant un accompagnement sp√©cifique pour que tu puisses atteindre tes objectifs (formations, certifications, accompagnement, √©coute‚Ä¶).\nShow more\nShow less",
        "details": {
            "JobDetail": [],
            "TypeContract": "",
            "Salary": "",
            "Level": "",
            "Experience": null
        },
        "title": "devops",
        "skills": {
            "ProgLanguage": [
                "Bash"
            ],
            "CloudComputing": [
                "GCP",
                "AWS",
                "Azure"
            ],
            "DevTools": [
                "Git",
                "Docker",
                "Jenkins"
            ],
            "Automation": [
                "Ansible"
            ],
            "InfrastructureAsCode": [
                "CloudFormation",
                "Terraform"
            ],
            "Containers": [
                "Docker"
            ],
            "Other": [
                "Cloud",
                "DevOps",
                "CI/CD"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "Foxintelligence",
        "location": "Paris, √éle-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/devops-site-reliability-engineer-at-foxintelligence-3876388754?position=5&pageNum=0&refId=NuDbZkBPOnBALTaaBOYlpw%3D%3D&trackingId=HdPJd%2FkFGx5d%2Fe1ZdsPoGw%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Chez Foxintelligence, nous sommes des amoureux de la data. ü§ì\nNotre mission est de rendre les consommateurs et les marques plus intelligents, gr√¢ce √† une donn√©e de march√© r√©volutionnaire issue de l'intelligence collective. Pour les consommateurs, Foxintelligence rend accessibles et utiles leurs donn√©es transactionnelles issues de leurs bo√Ætes mail ou comptes bancaires. En les anonymisant, nous cr√©ons des statistiques uniques qui permettent aux marques de rester en phase avec les produits qui se vendent le mieux et les attentes des consommateurs.\nNous publions une application grand public aim√©e par des millions de personnes (Cleanfox, 5m+ de t√©l√©chargements, 4.8/5 üíñ sur l'app store et le play store) et pr√©parons le lancement d'une app de bilan carbone √† l'exp√©rience radicalement nouvelle. Gr√¢ce √† notre plateforme data, elle va rendre possible une prise de conscience massive des enjeux du changement climatique üåç et des actions individuelles possibles pour le combattre. Nous pensons que l'information est une force de changement puissante, lorsqu'elle s'appuie sur la data.\nUtilisant ces donn√©es personnelles totalement anonymis√©es, notre plateforme SaaS foxintelligence.io est devenue la r√©f√©rence de la market intelligence digitale en Europe avec des dizaines de grands groupes clients. Le point commun entre Deliveroo, Just Eat, Mano Mano, BackMarket ou The Boston Consulting Group ? Ils vont tr√®s vite (on ne s'ennuie pas avec eux !) et ils nous font tous confiance !\nSoutenus par des investisseurs de premier plan (17m lev√©s aupr√®s de Daphni, Partech, GFC et eFounders) et r√©cemment int√©gr√© au groupe NielsenIQ nous sommes maintenant √† la conqu√™te de l'Europe et en phase d'hyper-croissance.\nSi notre FoxHQ reste √† Paris, notre √©quipe de plus de 120 talents pluridisciplinaires (tech, data et business) travaille depuis partout en France et m√™me en dehors (ex. Turquie). Nous pensons que notre politique remote-first, notre culture forte (bienveillance, exigence, r√©silience et data-first) et notre innovation permanente en termes de modes de travail (ex. grille de salaire transparente, formation au changement climatique, transparence sur la strat√©gie) sont les cl√©s de notre r√©ussite collective.... et de ta r√©ussite avec nous !\nJob Description\nFoxintelligence recherche\nun(une) DevOps/Site Reliability Engineer.\nTa mission consiste √† travailler avec le reste de l'√©quipe DevOps / SRE et les √©quipes de d√©veloppement afin d'assurer disponibilit√©, performance, efficacit√© et s√©curit√© maximale des services applicatifs. Nous travaillons en collaboration rapproch√©e avec le CTO et les d√©veloppeurs et nos challenges en terme de gestion de la data feront de toi un expert en infrastructure r√©siliente et performante ! Nos objectifs sont d'automatiser un maximum nos op√©rations, nous tenons donc √† g√©rer le maximum en Infra As Code (IaC), ce qui nous permet de gagner en r√©silience et d'anticiper au mieux notre croissance internationale.\nVoici quelques chiffres de production pour donner une id√©e des volumes que nous traitons :\n40 TB op√©rationnels (noSQL et SQL) pour nos applications grand public et en entr√©e de notre flux \"Big Data\"\n800 TB pour la partie analytique\n3000-6000 conteneurs en parall√®le en fonction des pics de charge\n15 √† 45 millions d'appels de fonctions serverless par jour\n1 millard de messages de logs chaque jour\nTes responsabilit√©s au quotidien :\nAssurer le bon fonctionnement de notre infrastructure AWS (suivi du monitoring, cr√©ation d'alertes, anticipations des probl√®mes)\nD√©ployer de nouvelles architectures AWS via Terraform, Helm, Ansible\nAdministration K8S / Karpenter\nAdministration des outils transverses fournis aux d√©veloppeurs (Jenkins, Vault, Nexus, Grafana, ELK, etc..)\nMaitrise des co√ªts - S√©curit√© - Support aux d√©veloppeurs (1jour/semaine max)\nRequirements\nComp√©tences n√©cessaires (ce qu'il te faut pour r√©ussir sur ce poste) :\nSoft Skills\nProactivit√©\nRigueur\nR√©activit√©\nAisance relationnelle\nHard Skills\nBonne connaissance des briques techniques AWS (S3, EC2, ALB, API Gateway, Cloudfront, Lambda, etc)\nBonne connaissance de Terraform pour construire l'infrastructure AWS\nExp√©rience avec Kubernetes + Helm - Connaissance de GCP / BigQuery\nMonitoring Prometheus/Grafana/AlertManager et/ou Cloudwatch\nMaitrise de Git\nMaitrise d'un langage de programmation et/ou de scripting (shell)\nComp√©tences additionnelles\nAdministration de BDD\nExp√©rience GCP avanc√©e\nLadies\nLes √©tudes montrent que les femmes ont moins tendance √† postuler √† une offre d'emploi quand elles n'ont pas toutes les qualifications requises. Ladies, ne vous mettez pas de barri√®re et donnez-nous la chance de nous faire notre propre avis, nous serons toujours ravis d'√©changer avec vous ! Si notre raison d'√™tre vous parle, postulez !\nSelf-made data lovers\nLes dipl√¥mes c'est bien, les skills c'est mieux et l'exp√©rience t'en donne. Aucun dipl√¥me n'est requis chez nous, c'est les comp√©tences et l'√©nergie qui comptent !\nRecruitment process\nRound 0 : entretien (fit) avec notre Head of People\nRound 1 : entretiens (exp√©rience et fit) avec notre √©quipe DevOps\nRound 2 : Live coding\nDecision Round : Entretien (fit et vision) avec notre CTO\nBenefits\nAvantages/ce que nous offrons :\nSalaire et variable comp√©titifs\nRemote friendly (+ budget am√©nagement de l'espace de travail @Home)\nBonus Cooptation\nBonne assurance sant√© (Alan)\nTitres restaurants (swile) : pris en charge √† 60% par Fox\nSyst√®me de cr√®che subventionn√© par Fox\nCulture forte et pratiques de management √† la pointe (strat√©gie et r√©sultats financiers transparents, feedback 360, grille de salaire innovante et transparente etc.)\nShow more\nShow less",
        "details": {
            "JobDetail": [
                "Remote"
            ],
            "TypeContract": "",
            "Salary": "40",
            "Level": "",
            "Experience": null
        },
        "title": "devops",
        "skills": {
            "DataBase": [
                "SQL",
                "NoSQL"
            ],
            "CloudComputing": [
                "GCP",
                "AWS"
            ],
            "DevTools": [
                "Git",
                "Jenkins"
            ],
            "DBMS": [
                "BigQuery"
            ],
            "Automation": [
                "Kubernetes",
                "Ansible"
            ],
            "InfrastructureAsCode": [
                "Terraform"
            ],
            "Containers": [
                "Kubernetes"
            ],
            "Other": [
                "Statistiques",
                "Big Data",
                "DevOps"
            ],
            "EnSoftSkils": [
                "Collaboration"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "Orange Logic",
        "location": "√éle-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/devops-engineer-at-orange-logic-3916254305?position=6&pageNum=0&refId=NuDbZkBPOnBALTaaBOYlpw%3D%3D&trackingId=ysbkrTDSevxoFQWVICFFjg%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "For more than two decades, Orange Logic has empowered a wide range of clients with its digital asset management system, Cortex. We‚Äôve worked with almost every industry, from Finance to NGOs, Media giants to educational institutions; securing and organizing their assets. The DevOps Engineer introduces processes, tools, and methodologies to balance needs throughout the software development life cycle, from coding and deployment, to maintenance and updates.\nWhat you can expect in your role:\nInfrastructure provisioning, optimization and management.\nCloud architecture & system administration.\nManage and improve the observability stack (metrics, logs, traces, alerting, visualization).\nDealing with security requirements and automations proposing a good balance.\nActs as the DevOps advocate; helps evangelize and educate the DevOps way across the organization.\nDevelop new system and application plans to ensure operational reliability.\nAssist in managing and maintaining a network of hosted servers.\nEnforce / help about security good practices at dev level to prevent breaches.\nParticipate to optimize cloud costs.\nYou are:\nExperienced Infrastructure as Code with CloudFormation/Terraform.\nExperienced on containers approach with Docker (Linux and Windows).\nA Subject Matter Expert on cloud infrastructure (e.g. AWS, Google Cloud, Azure).\nExperience with CI/CD pipelines (Jenkins, TeamCity, Azure Pipelines) and ElasticSearch\nExperience with configuration management tools (e.g. Chef, Puppet or Ansible).\nExperience in cloud native approach and containers orchestration tools (e.g. Kubernetes).\nProficient with Windows/Linux systems using a terminal (e.g. Bash, Powershell).\nHands-on experience with developer toolset and practices such as using source control, giving and receiving code reviews, writing unit tests and familiarity with agile principles.\nStrong understanding of common system architecture, provisioning and automation.\nPerks of joining the team:\nCompetitive compensation & benefits package\nRemote work environment\nHow to get started:\nIf you‚Äôre up for the challenge to be part of a growing DevOps team we‚Äôd like to hear from you. Apply today!\nOrange Logic is an equal opportunity employer. We celebrate diversity and are committed to creating an inclusive environment for all our employees.\nShow more\nShow less",
        "details": {
            "JobDetail": [
                "Remote"
            ],
            "TypeContract": "",
            "Salary": "Package",
            "Level": "",
            "Experience": null
        },
        "title": "devops",
        "skills": {
            "ProgLanguage": [
                "Bash"
            ],
            "DataBase": [
                "Elasticsearch"
            ],
            "MachineLearning": [
                "Orange"
            ],
            "CloudComputing": [
                "AWS",
                "Azure"
            ],
            "DevTools": [
                "Jenkins",
                "Docker"
            ],
            "OS": [
                "Linux",
                "Windows"
            ],
            "Automation": [
                "Chef",
                "Kubernetes",
                "Puppet",
                "Ansible"
            ],
            "InfrastructureAsCode": [
                "CloudFormation",
                "Terraform"
            ],
            "Containers": [
                "Docker",
                "Kubernetes"
            ],
            "Other": [
                "Cloud",
                "DevOps",
                "CI/CD"
            ],
            "EnSoftSkils": [
                "Organization"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "Stakha",
        "location": "France",
        "link": "https://fr.linkedin.com/jobs/view/devops-engineer-at-stakha-3902900406?position=7&pageNum=0&refId=NuDbZkBPOnBALTaaBOYlpw%3D%3D&trackingId=sluMCbrXqSWnTEumjXBcRg%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Pour le compte de son client, Stakha est √† la recherche d‚Äôun¬∑e DevOps Engineer en full-remote (55/65k‚Ç¨\nbruts annuels\n) pour rejoindre une\nFintech\nde 20 collaborateurs dans le cadre d'une cr√©ation de poste.\nLe profil recherch√© doit absolument avoir une exp√©rience de plus de 4\nans\nen tant qu'Ing√©nieur DevOps/SRE (Dev & Ops)\nAu sein de l'√©quipe tech, vous participez √† l'am√©lioration global du produit.\nLe poste en quelques mots :\nüåêEntreprise : Start-up - SaaS\nüè¢Localisation :\nFull Remote\nüí∞Salaire : 55k‚Ç¨ √† 65k‚Ç¨\nüéØPrincipales responsabilit√©s :\nConcevoir et orchestrer l'infrastructure pour maximiser les performances (IaC)\nS√©lectionner et int√©grer les outils et services n√©cessaires au product\nContribuer activement √† la s√©curit√© globale du syst√®me.\nüöÄTech Stack : Kube, Terraform, Docker, Cloud\n‚û°Ô∏è amaury@stakha.io\nShow more\nShow less",
        "details": {
            "JobDetail": [
                "Remote",
                "Full"
            ],
            "TypeContract": "",
            "Salary": "55k",
            "Level": "",
            "Experience": "4 an(s)"
        },
        "title": "devops",
        "skills": {
            "DevTools": [
                "Docker"
            ],
            "InfrastructureAsCode": [
                "Terraform"
            ],
            "Containers": [
                "Docker"
            ],
            "Other": [
                "Cloud",
                "DevOps"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "IC Resources",
        "location": "Paris, √éle-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/devops-engineer-at-ic-resources-3866824508?position=8&pageNum=0&refId=NuDbZkBPOnBALTaaBOYlpw%3D%3D&trackingId=RdfTiX3VDyiaAlfmzT19Sg%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Global AudioVisual technology company is looking to hire an experienced DevOps Engineer to join their team in Paris.\nWorking closely with the SW engineering and validation teams, your role will involve the design, development and automation of development and validation infrastructures and processes, as they look to move their CI/CD processes forward.\nKey responsibilities:\nDefine / optimise continuous integration and deployment pipelines for their solutions\nAutomate infrastructure management processes\nSupport implementation of the CI/CD pipeline\nCollaborate with development teams to integrate DevSecOps best practices into their workflow\nInnovate and make the validation process of their products more efficient with new tools\nIntegrate third-party applications / modules into the CI/CD chain\nEnsure systems and data security at every stage of the software development lifecycle\nIdentify and resolve system performance, reliability and scalability issues\nKey skills/experience required:\nIn-depth knowledge of CI/CD principles and associated tools (Gitlab CI, Jenkins, etc.)\nExperience with Docker\nGit and Git-based workflow e.g. branching practices\nStrong scripting skills (Python, Bash, PowerShell, etc.)\nLinux environment (ideally Ubuntu, Debian, CentoS)\nAutomation tools and configuration management (Ansible type, Puppet, Chef, etc.)\nKnowledge of technologies related to virtualization, cloud\nAgile methodology\nCode quality tools (SonarQube type..)\nKnowledge of testing and validation within Hi-Tech engineering organisations\nExposure to embedded development technologies/environments\nIdeally, you will have worked in a similar DevOps role within a SW & HW tech company.\nThey are one of the world's leading companies in the design and manufacture of professional AV tech - this is your chance to join them as they continue to grow!\nThis is a hybrid role\nIf you are interested, please contact Matt Andrews at IC Resources for more information!\nShow more\nShow less",
        "details": {
            "JobDetail": [],
            "TypeContract": "",
            "Salary": "",
            "Level": "",
            "Experience": null
        },
        "title": "devops",
        "skills": {
            "ProgLanguage": [
                "Bash",
                "Python"
            ],
            "DevTools": [
                "Git",
                "Docker",
                "Jenkins"
            ],
            "OS": [
                "Linux"
            ],
            "Automation": [
                "Chef",
                "Puppet",
                "Ansible"
            ],
            "Containers": [
                "Docker"
            ],
            "Collaboration": [
                "Teams"
            ],
            "Other": [
                "Cloud",
                "DevOps",
                "CI/CD"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "Madbox",
        "location": "Paris, √éle-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/devops-engineer-at-madbox-3897759681?position=9&pageNum=0&refId=NuDbZkBPOnBALTaaBOYlpw%3D%3D&trackingId=fL4u3ZMiax%2BkQAOuSqq5Jw%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Madbox is a fast-growing mobile gaming company with a very unique way of developing games. Everything has been made for teams to take as much\nownership\nas possible, unleash their\ncreativity\n, bring\nperformance\n, and have as much\nfun\nas possible.\nIn July 2022, we launched our\nPocket Champs\ngame worldwide which quickly became one of the top-grossing games in its category.\nThe game has been scaling a lot since the launch and is now supporting millions of monthly users. All these players are interactive with backend systems that we have developed internally and deployed based on our internal knowledge.\nBut the stakes are getting high and we cannot afford to have incidents on these services because it could damage the players experience. We are now looking for someone that has some expertise on deploying online applications that will be consumed by millions of players and would hold on under a heavy load.\nThis is where you come in:\ntake this DevOps / SRE position over and be a driving force of this new Chapter! üî•\nThe beginning of your journey at Madbox as an SRE Engineer:\n- Starts with meeting your team, discovering who is who and engaging with everyone involved (or not) in your missions.\n- Continues with getting familiar with our stack, discovering our environment, tools and processes.\n- You will of course play our games and learn more about how we are making them the ‚ÄúMadbox way‚Äù !\n- Everything will be made for you to get you up to speed, take ownership and be ready to tackle your missions.\nResponsibilities & Scope :\n- Design the backend infrastructure to host our Gaming Backend projects (APIs, Game Servers, Storage solutions‚Ä¶).\n- Setup the monitoring services to allow tracking the health metrics of our backend applications.\n- Setup alerts and watch over the health of our backend applications to raise an alarm every time an issue occurs.\n- Alert the right team.\n- Give a clear criticality information to define how quickly the issue needs to be solved\n- Define SLA processes for each different level of criticality that can be followed to keep the service available.\n- Provide as much context as you can from the metrics and logs you see on the dashboards.\n- Setup our backend application to scale up & down automatically to optimize our cost.\n- Follow up and make sure that our services scale properly and be ready to operate the scaling up / down manually if necessary.\n- Identify bottlenecks in our backend applications and recommend optimization that the Gaming Backend Developers team could make to optimize the application.\n- Keep a vigil eye on the solutions available on the market.\nProfile\n- You have 3 years of hands-on experience in a DevOps / SRE position.\n- You are data-oriented, as you measure the impact of the solutions you implement.\n- You have proven experience at deploying applications that are accessible to millions of users.\n- You are fully proficient in English.\n- You‚Äôre passionate about building systems that scale.\n- You focus on stability and availability.\n- You‚Äôre a team player who can explain their work and share their knowledge with other technical people.\nHiring Process\n- A call with a recruiter\n- A call with the hiring manager\n- A home assignment\n- A review of the test with the hiring manager and someone from the automation team\n- A meet the team interview\nAll our offers are extended within 48 hours maximum\nPerks and benefits\nCompetitive compensation :\nour compensation grid is regularly reviewed based on the evolution on the market to ensure everyone at Madbox is fairly compensated and receives frequent updates.\nHybrid remote policy:\n3 days on site minimum per week + 15 additional working days fully remote per year\nCWS\n: Culture, Wellness & Sport,\nis a budget Madbox dedicated to each employee for them to self develop and take care of themselves\nHolidays\n: hyper-flexible 30 days off policy (take it when you need it)\nHealth of Our Madboxers is Essential:\nAlan Health Insurance (75% covered by Madbox)\nLunch coupons:\nTake advantage of the Swile card (60% covered by Madbox)\nTransport Fees :\n50% covered by Madbox\nAmazing Offices:\nCome and explore our offices in the heart of Paris (Bonne Nouvelle Station) and Barcelona (Diagonal Station)! From taking a nap in our ‚Äújungle‚Äù in Paris Office to soaking up the sun on the rooftop in Barcelona at lunch, we have thought of everything to make you feel right at home. üßò‚Äç‚ôÇÔ∏è\nBonus\n: Our fantastic Workplace Managers will make sure to provide you with the coffee/tea/snacks/drinks of your choice!\nHome office Expenses bonus\nTeam Macbook or Team PC?\nüñ• We provide all the necessary equipment\nEnglish Lessons\n: as our main langage in both studios is English, you can enjoy group lessons with your peers thanks to our private teacher\nMadgen :\nyearly company event\nContract and location\nLocation\n: This position is available in Paris, 19-21 Rue Poissonni√®re üá´üá∑\nor/and in Barcelona, Utopicus, Pla√ßa de Gal¬∑la Plac√≠dia, 1, 3, üá™üá∏\nContract\n: Permanent full-time contract\nShow more\nShow less",
        "details": {
            "JobDetail": [
                "Remote",
                "Full"
            ],
            "TypeContract": "",
            "Salary": "",
            "Level": "",
            "Experience": null
        },
        "title": "devops",
        "skills": {
            "Collaboration": [
                "Teams"
            ],
            "Other": [
                "DevOps"
            ],
            "EnSoftSkils": [
                "Creativity"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "SELLIA",
        "location": "Paris, √éle-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/cloud-engineer-at-sellia-3902686769?position=10&pageNum=0&refId=NuDbZkBPOnBALTaaBOYlpw%3D%3D&trackingId=cTidfsCiFx1NWhlcZM8Uhw%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Nous recherchons un Ops Senior en environnement Kubernetes sur du cloud Azure pour prendre en charge l‚Äôautomatisation du d√©ploiement de nos applications, le suivi de notre infrastructure et l‚Äôoptimisation des co√ªts des environnements.\nLes missions :\net d√©ployer des infrastructures pour applications cloud (y compris sur les services de CI/CD)\nen place des outils de s√©curisation, monitoring, backup, r√©partition des charges, etc\nles processus et architectures\nau processus de certification ISO (documentation, tests, etc)\n√† la conception et au d√©veloppement des architectures cloud en utilisant les meilleures pratiques et les services adapt√©s (Azure).\nen place et g√©rer des clusters Kubernetes pour le d√©ploiement d'applications et de micro-services.\navec les √©quipes de data science pour int√©grer les donn√©es et mod√®les selon une approche MLOps.\nles bases de donn√©es relationnelles (postgreSQL) et MongoDB dans les solutions architecturales, en tenant compte des exigences de performances et de disponibilit√©.\nVotre profil :\nann√©es d‚Äôexp√©riences minimum sur des projets similaires\ncertifications Azure MS devops engineer expert serait un plus\nmoins une exp√©rience significative sur Kubernetes.\ndes bases de donn√©es relationnelles et exp√©rience avec MongoDB.\napprofondie des principes d'architecture logicielle, de la conception de syst√®mes √©volutifs et de la s√©curit√© des applications.\n√† communiquer efficacement et √† travailler en √©quipe, tout en faisant preuve d'autonomie.\ncompr√©hension des m√©thodologies Agile et des pratiques DevOps.\nLes technologies suivantes n‚Äôont pas de secret pour vous :\n: Windows, Linux (ubuntu, WSL2), r√©seaux\n: JavaScript/TypeScript, Python, Shell\nde donn√©es : postgreSQL , mongoDB\n: Docker/Podman, Kubernetes (AKS/EKS) : Helm, ISTIO,\n: Cloud functions\nGitOps, Serverless, Terraform, Helm, Ansible, Packer\nDeployment: Cloud CI/CD\n: Github, Consul, NGINX, WebPack, AWS Kinesis, Keycloak, Azure Devops\nShow more\nShow less",
        "details": {
            "JobDetail": [
                "Senior"
            ],
            "TypeContract": "",
            "Salary": "",
            "Level": "",
            "Experience": null
        },
        "title": "cloud architect /engineer ",
        "skills": {
            "ProgLanguage": [
                "Python"
            ],
            "DataBase": [
                "MongoDB"
            ],
            "CloudComputing": [
                "AWS",
                "Azure"
            ],
            "DevTools": [
                "Docker"
            ],
            "OS": [
                "Linux",
                "Windows"
            ],
            "DBMS": [
                "PostgreSQL"
            ],
            "Automation": [
                "Kubernetes",
                "Ansible"
            ],
            "InfrastructureAsCode": [
                "Terraform"
            ],
            "Containers": [
                "Docker",
                "Kubernetes"
            ],
            "Other": [
                "Cloud",
                "DevOps",
                "CI/CD"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "Teolia",
        "location": "Paris, √éle-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/devops-cloud-engineer-at-teolia-3902427701?position=11&pageNum=0&refId=NuDbZkBPOnBALTaaBOYlpw%3D%3D&trackingId=8WUrSvcPSsF9X2U5dCb73w%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Pour toi, DevOps n‚Äôest pas juste un ensemble de technologies\n, mais un moyen d‚Äôaccompagner efficacement un client dans ses probl√©matiques m√©tiers : r√©duction du time-to-market, fiabilisation des produits et auto-r√©silience, r√©duction des co√ªts, s√©curisation avec l‚Äôapproche shift-left (DevSecOps)‚Ä¶\nAlors cette annonce devrait te plaire\nüòä\nTes missions\nTu apporteras ton expertise DevOps aupr√®s de nos clients dans leur projet de transformation digitale et performance op√©rationnelle. Concr√®tement, dans ton quotidien tu pourras √™tre amen√©.e √† :\nTravailler aussi bien avec les √©quipes de d√©veloppement que les √©quipes de production afin d‚Äôautomatiser et fluidifier le d√©ploiement et le maintien des applicatifs (CI/CD).\nMettre en place une strat√©gie de test adapt√©e afin de r√©duire au maximum les r√©gressions et les bugs remont√©es par les utilisateurs.\nD√©ployer les ressources √† travers une technologie d‚ÄôIaC (Terraform like ‚Äì ou Azure ARM/Blueprint/Bicep - ou AWS cloud formation)\nMettre en place l‚Äôobservabilit√© des applications et assurer leur niveau de disponibilit√© : monitoring / alerting, logging, anticipation des pics de charges\nOp√©rer comme SRE : DRT, RTO et RPO\nContribuer comme Cloud architect + FinOps : design de solutions cloud native, architecture des solutions clouds, gestion du multicloud, mise en place de dashboard d‚Äôanalyse des co√ªts et proposition de r√©duction\nOp√©rer comme DevSecOps: mise en place d‚Äôanalyse et de correction de s√©curit√© bout en bout, approche shift-left‚Ä¶\nComment nous l‚Äôop√©rerons ensemble :\nEn √©tant capable d‚Äôidentifier et d‚Äôautomatiser les traitements √† forte valeur ajout√©e : quick-wins\nUn ADN de\nDoer\n: r√©aliser des choses rapidement et en qualit√©.\nUn ADN d‚Äô\nEnabler\n: notre force vient du fait que nous formons o√π nous intervenons (nous croyons sinc√®rement que la meilleure √©quipe est celle o√π personne n‚Äôest indispensable, tu en penses quoi ? üòâ)\nEn nous rejoignant, ce qu‚Äôon t‚Äôapporte (attention liste non exhaustive)\n2 mantras chez Teolia : la FORMATION et le SUIVI.\nEn nous rejoignant, tu :\nB√©n√©ficieras d‚Äôun\naccompagnement sur mesure\n(formations techniques, mise en pratique). Cette formation se base sur une analyse 360 de ton profil afin de te proposer une formation adapt√©e en fonction de ce que tu dois apprendre et de ce que tu veux apprendre.\nTe formeras de mani√®re continue : entre membres de l‚Äô√©quipe et via une plateforme d‚Äôapprentissage\nValideras tes acquis via les\ncertifications\n(groupes de certifications pour plus d‚Äô√©mulation et financement par Teolia)\nSeras accompagn√©.e en mission : par ton commercial et ton practice leader afin de t‚Äôaider sur les √©ventuelles probl√©matiques techniques, d√©tecter des besoins de formation/certifications, t‚Äôaider √† prendre du recul sur les transformations √† op√©rer\nEt cerise sur le cheesacake : Teolia c‚Äôest aussi et avant tout une communaut√© aux petits oignons (des gens\npassionn√©s et accueillants\n,\nune communaut√© qui ne laisse jamais quelqu‚Äôun sur le c√¥t√©\n).\nTon profil : si on parlait de toi?\nD'une formation sup√©rieure en informatique minimum BAC+3, tu justifies id√©alement de 2 ans d'exp√©rience minimum sur un poste d‚Äôing√©nieur DevOps (une belle alternance de 2/3 ans nous va aussi).\nSi on r√©sume tes domaines de comp√©tences/connaissances :\n¬∑ Une base solide en Syst√®me et r√©seau\n¬∑ Maitrise d‚Äôun outil de Build et de packaging\n¬∑ Est-il besoin de mentionner la Containerisation comme essentielle üòâ\n¬∑ Un outil de Deploy (ex : Kubernetes, Swarm, XLDeploy, ‚Ä¶)\n¬∑ Un outil de CI/CD\n¬∑ Un cloud provider\n¬∑ Id√©alement connaissance de l‚ÄôInfrastructure as Code et du Monitoring / Alerting (ex : Prometheus, Grafana, ‚Ä¶)\n¬∑ A l‚Äôaise dans des contextes anglophones (pas besoin de disserter sur la photo de famille retouch√©e de Kate Middleton mais tu vois l‚Äôid√©e ).\nShow more\nShow less",
        "details": {
            "JobDetail": [],
            "TypeContract": "",
            "Salary": "",
            "Level": "Bac+3",
            "Experience": "2 an(s)"
        },
        "title": "devops",
        "skills": {
            "CloudComputing": [
                "AWS",
                "Azure"
            ],
            "Automation": [
                "Kubernetes"
            ],
            "InfrastructureAsCode": [
                "Terraform"
            ],
            "Containers": [
                "Kubernetes"
            ],
            "Other": [
                "Cloud",
                "DevOps",
                "CI/CD"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "Cronos Europa",
        "location": "Strasbourg, Grand Est, France",
        "link": "https://fr.linkedin.com/jobs/view/junior-devops-engineer-at-cronos-europa-3908284316?position=12&pageNum=0&refId=NuDbZkBPOnBALTaaBOYlpw%3D%3D&trackingId=TQmLRhcxdV%2FvqbGXvh75uA%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "We are currently looking for a Junior DevOps Engineer to strengthen the Cronos Europa team.\nResponsibilities\nDevelop tools and infrastructures to support Build & Deployment activities.\nManage, support, and enhance Build and Deployment pipelines for efficiency and reliability.\nImplement DevOps strategies and associated processes effectively to streamline operations and enhance collaboration.\nTechnical Skills\nThorough understanding of the Software Development Life Cycle (SDLC) and Agile methodologies.\nProficiency in automation tools for implementing continuous integration and continuous delivery.\nWorking knowledge of popular DevOps tools such as GIT, Jenkins, Ansible, Artifactory, SonarQube, and OpenShift.\nFamiliarity with scripting languages, such as Groovy, to streamline processes.\nBonus points for experience with mobile device technologies like React Native and Xcode, as well as familiarity with Android and iOS operating systems.\nProfile\n2 years' experience\nBachelor degree in IT\nMinimum B2 level of English proficiency. French language skills are a plus but not mandatory.\nGood reasoning and communication\nWhy Cronos Group? We'll propose you\nAn attractive salary package\nA good work-life balance environment\nThe assurance of working in cutting-edge technologies in an entrepreneurial spirit.\nThe opportunity to develop your skills thanks to tailor-made training courses according to your needs\nA good job in a friendly place\nIf you wish to integrate a dynamic structure on a human scale while working with the latest technologies, don't wait anymore and join Cronos!\nShow more\nShow less",
        "details": {
            "JobDetail": [
                "Junior"
            ],
            "TypeContract": "",
            "Salary": "Salary, Package",
            "Level": "",
            "Experience": null
        },
        "title": "devops",
        "skills": {
            "DevTools": [
                "Git",
                "Jenkins"
            ],
            "Automation": [
                "Ansible"
            ],
            "Containers": [
                "OpenShift"
            ],
            "Other": [
                "DevOps"
            ],
            "EnSoftSkils": [
                "Communication",
                "Collaboration"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "Neosoft",
        "location": "Paris, √éle-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/devops-engineer-at-neosoft-3902390640?position=13&pageNum=0&refId=NuDbZkBPOnBALTaaBOYlpw%3D%3D&trackingId=QT044j2gDKahrIBitPLYIg%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Dans le cadre du renforcement de nos √©quipes, nous recherchons un consultant DevOps (c√¥t√© Obs) confirm√© pour rejoindre le plus gros projet infrastructure du groupe N√©o-Soft (Multi-Cloud, DevOps, Agile). Si vous √™tes la bonne personne, c'est que vous aimez les probl√©matiques li√©es √† l'infrastructure, le travail d'√©quipe, et plus largement le monde de l'IT. Vous √™tes fier de votre travail et vous avez quelques beaux projets CI/CD √† votre actif.\nLes environnements techniques recherch√©s ? : [Linux et Windows] ; [Jenkins ; Ansible ; GitLabCI ; Terraform ; Kubernetes] ; [AWS ; Azure ; GCP] ...\nLa cible ? Une offre de service infrastructure ainsi qu'un centre de comp√©tences multisites qui tend √† industrialiser la m√©thodologie DevOps au sein de ses √©quipes ainsi qu'√† proposer un service cloud √† haute valeur ajout√©e.\nLes pr√©requis ? L'anglais, indispensable, l'aisance technique et la maitrise de l'outillage CI/CD.\nA vos CV ! :)\nShow more\nShow less",
        "details": {
            "JobDetail": [
                "Confirm√©"
            ],
            "TypeContract": "",
            "Salary": "",
            "Level": "",
            "Experience": null
        },
        "title": "devops",
        "skills": {
            "CloudComputing": [
                "GCP",
                "AWS",
                "Azure"
            ],
            "DevTools": [
                "Jenkins"
            ],
            "OS": [
                "Linux",
                "Windows"
            ],
            "Automation": [
                "Kubernetes",
                "Ansible"
            ],
            "InfrastructureAsCode": [
                "Terraform"
            ],
            "Containers": [
                "Kubernetes"
            ],
            "Other": [
                "Cloud",
                "DevOps",
                "CI/CD"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "zefa",
        "location": "Strasbourg, Grand Est, France",
        "link": "https://fr.linkedin.com/jobs/view/devops-engineer-at-zefa-3901115060?position=14&pageNum=0&refId=NuDbZkBPOnBALTaaBOYlpw%3D%3D&trackingId=7Lqd8pCQXu2hvMEQe1EUEA%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "DevOps Engineer\nFreelance - 12 months\nFrance Strasburg\nProject experience:\n‚Ä¢ Develop tools and infrastructures in order to support Build &\nDeployment activities;\n‚Ä¢ Manage, support and improve Build and Deployment pipelines;\n‚Ä¢ Effectively implement a DevOps strategy and associated\nprocesses\nKnowledge and Skills required:\n‚Ä¢ Thorough understanding of the SDLC, and knowledge of Agile\nmethodologies;\n‚Ä¢ Knowledge of automation tools used to implement continuous\nintegration and continuous delivery;\n‚Ä¢ Working knowledge of known DevOps tools like Git, Jenkins,\nAnsible, Artifactory, Sonarqube, Openshift;\n‚Ä¢ Knowledge of scripting languages (like Groovy);\n‚Ä¢ Knowledge on mobile device technologies (React Native,\nxCode) and Operating systems (Android, iOS) would be\nadvantageous;\nThis is a 2 stage process, with an ideal start date in MAY.\nLet's connect and explore this project together!\nShow more\nShow less",
        "details": {
            "JobDetail": [],
            "TypeContract": "",
            "Salary": "",
            "Level": "",
            "Experience": null
        },
        "title": "devops",
        "skills": {
            "DevTools": [
                "Git",
                "Jenkins"
            ],
            "Automation": [
                "Ansible"
            ],
            "Containers": [
                "OpenShift"
            ],
            "Other": [
                "DevOps"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "Astek",
        "location": "Nice, Provence-Alpes-C√¥te d'Azur, France",
        "link": "https://fr.linkedin.com/jobs/view/devops-engineer-%E2%80%93-nice-france-h-f-at-astek-3879635895?position=15&pageNum=0&refId=NuDbZkBPOnBALTaaBOYlpw%3D%3D&trackingId=hGj84aAdfHKHQ03YP%2FIeTQ%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "CDI\nNice - France\nPubli√©e il y a 2 jours\nLe Groupe Astek\nCe Que Nous Allons Accomplir Ensemble :\nRejoindre une √©quipe dans les domaines du transport et du tourisme sur des projets ambitieux dans lesquels la satisfaction clients et les solutions √† valeur ajout√©e jouent un r√¥le crucial.\nVotre Mission, Si Vous L‚Äôacceptez :\nComprendre les exigences du client ;\nEncourager et construire des processus automatis√©s dans la mesure du possible\nContr√¥ler les processus tout au long du cycle de vie pour s‚Äôassurer de leur respect\nD√©finir et param√©trer les processus de d√©veloppement, de test, de mise en production, de mise √† jour et de support pour le fonctionnement DevOps.\nVotre Future √âquipe :\nVenez rejoindre une √©quibe ambitieuse et dynamique dans un environnement international\nVotre stack de jeu\nAnsible, Python, Jenkins, Docker et Kubernetes\nLes Petits Plus Du Projet :\nVous √©voluerez au sein d‚Äôune √©quipe impliqu√©e et r√©active dans un environnement international et interviendrez sur des projets passionnants et enrichissants.\nVous ?\nDipl√¥m√©(e) d‚Äôune √©cole d‚Äôing√©nieur ou √©quivalent de niveau Bac+5. Vous justifiez id√©alement d‚Äôune exp√©rience sur un poste similaire ;\nVotre personnalit√©, votre esprit d‚Äô√©quipe, votre autonomie, votre relationnel, votre rigueur, votre cr√©ativit√© ainsi que votre curiosit√© seront des atouts essentiels pour mener √† bien vos missions sur le projet ;\nVous maitrisez les comp√©tences techniques backend de base : Python, Kubernetes, Jenkins, Docker,‚Ä¶\nAstek\nCr√©√© en France en 1988, Astek est un acteur mondial de l‚Äôing√©nierie et du conseil en technologies. Fort de son expertise dans de nombreux secteurs industriels et tertiaires, Astek accompagne ses clients internationaux dans le d√©ploiement intelligent de leurs produits et de leurs services, et dans la mise en ≈ìuvre de leur transformation digitale.\nDepuis sa cr√©ation, le Groupe a fond√© son d√©veloppement sur une forte culture d‚Äôentrepreneuriat et d‚Äôinnovation, et sur l‚Äôaccompagnement et la mont√©e en comp√©tence de\nses 7800 collaborateurs\nqui s‚Äôengagent chaque jour √† promouvoir la compl√©mentarit√© entre les technologies num√©riques et l‚Äôing√©nierie des syst√®mes complexes.\nRejoignez un Groupe en fort d√©veloppement en France et √† travers le monde ayant r√©alis√© un chiffre d‚Äôaffaires de 600 M‚Ç¨ en 2023.\nTous les d√©tails sur le Groupe sur le site https://astekgroup.fr. Et vous pouvez aussi nous suivre sur notre blog : https://blog.groupeastek.com.\nRencontrons-nous\nKillian, notre Talent Acquisition Officer, vous contactera afin de faire un point avec vous.\nEnsuite, Vous √âchangerez Avec :\nvotre futur manager (futur N+1) afin de discuter de ASTEK, votre parcours, vos attentes et la mission ;\nvotre directeur d‚Äôagence pour valider votre int√©r√™t pour le poste et vous pr√©senter les √©l√©ments contractuels.\nNos Plus\nAstek est green et fait b√©n√©ficier ses salari√©s d‚Äôune indemnit√© kilom√©trique v√©lo\nUne politique CARE sur-mesure d√©ploy√©e par nos √©quipes RH pour nos collaborateurs (https://astekgroup.fr/engagements)\nNotre charte de la Diversit√©\nBienvenue dans la team ! Allez-y, maintenant c‚Äôest √† vous de jouer !\nMots-cl√©s :\ndevops ‚Äì ing√©nieur ‚Äì ing√©nieure ‚Äì consultant ‚Äì consultante ‚Äì terraform ‚Äì ansible ‚Äì python\nCaract√©ristiques de l'emploi\nCat√©gorie Ing√©nieur\nJob Industry Distribution / Services Internet, Transports Terrestres\nPostuler en ligne\nNom *\nPr√©nom *\nEmail *\nUn email valide est requis.\nT√©l√©phone *\nUn num√©ro de t√©l√©phone valide est requis.\nJoindre un CV *\nMots-cl√©s :\ndevops ‚Äì ing√©nieur ‚Äì ing√©nieure ‚Äì consultant ‚Äì consultante ‚Äì terraform ‚Äì ansible ‚Äì python\nShow more\nShow less",
        "details": {
            "JobDetail": [],
            "TypeContract": "CDI",
            "Salary": "",
            "Level": "Bac+5",
            "Experience": null
        },
        "title": "devops",
        "skills": {
            "ProgLanguage": [
                "Python"
            ],
            "DevTools": [
                "Jenkins",
                "Docker"
            ],
            "Automation": [
                "Kubernetes",
                "Ansible"
            ],
            "InfrastructureAsCode": [
                "Terraform"
            ],
            "Containers": [
                "Docker",
                "Kubernetes"
            ],
            "Other": [
                "DevOps"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "fifty-five",
        "location": "Paris, √éle-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/data-cloud-engineer-h-f-at-fifty-five-3910028674?position=16&pageNum=0&refId=NuDbZkBPOnBALTaaBOYlpw%3D%3D&trackingId=8mWgqi050hRhEboDwNYoiA%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Data & Cloud Engineer\nfifty-five est une data-company d'un genre nouveau qui aide les marques √† exploiter les donn√©es pour am√©liorer le marketing, les m√©dias et l'exp√©rience client gr√¢ce √† une combinaison de services de conseil et de technologie sp√©cialis√©s.\nEn tant que pilier data et marketing du Brandtech Group, nous offrons des services qui combinent le conseil en strat√©gie, les services de cloud, le conseil en m√©dia et l'exp√©rience client.\nfifty-five, c'est plus de 400 experts du num√©rique. Des digital consultants, des sp√©cialistes du tracking et du m√©dia, des ing√©nieurs et des data scientists, travaillent tous en √©troite collaboration pour fournir des conseils marketing de haut niveau et une assistance technique aux marques, dans tout type d'industrie, partout dans le monde.\nPartenaire des annonceurs de la collecte √† l'activation et l'exploitation des donn√©es, nous aidons les organisations √† devenir de v√©ritables entit√©s omnicanales ma√Ætrisant l'efficacit√© de leur √©cosyst√®me digital et ses synergies avec le monde physique.\nBas√© √† Paris, nous op√©rons sur 3 fuseaux horaires depuis nos 10 bureaux, situ√©s √† Paris, Londres, Gen√®ve, Milan, Shanghai, Hong Kong, Shenzhen, Taipei, Singapour et New York. fifty-five attache une importance particuli√®re au bien-√™tre de ses collaborateurs, ce qui lui a permis de figurer dans le classement Best Workplaces France en 2018.\nContexte :\nL'√©quipe d'ing√©nierie d√©veloppe et met en ≈ìuvre les solutions techniques permettant la r√©alisation de pipelines de donn√©es et l'impl√©mentation de data platform pour nos clients : r√©cup√©ration de datas sur de multiples sources de donn√©es (APIs, files, etc.), data cleaning, data processing, automation et monitoring de l'ensemble. L'√©quipe s'appuie sur des technologies r√©centes (docker, kubernetes, terraform, notebooks, etc.) et met en place ses projets dans les diff√©rents clouds du march√© (GCP, Azure, AWS...).\nMission :\nNous sommes √† la recherche d'une personne capable de r√©aliser des projets techniques pour r√©pondre aux besoins de nos clients (par exemple: syst√®me de recommandations de produits, d√©tection d'anomalies, ranking). Les activit√©s vont du chiffrage et du sizing technique √† la mise en ≈ìuvre des architectures, en passant par la revue des sp√©cifications fonctionnelles et la production de code. Le Data & Cloud Engineer sera √©paul√© par un Lead dans ses missions. Il sera √©galement amen√© √† participer √† la R&D et √† accompagner les √©quipes transverses dans la mise en place d'outils de travail internes (librairies pour les data scientists, environnement Notebooks pour les data analysts et data scientists, d√©veloppement de frameworks sur diff√©rents cloud providers, etc.).\nNous souhaitons trouver la bonne personne pour faire √©voluer ou cr√©er de nouvelles solutions dans ce cadre. Les missions comprennent aussi bien du prototypage rapide pour des d√©monstrateurs, que de la production de code robuste qui tourne en production tous les jours.\nComp√©tences et exp√©riences :\n2 ans d'exp√©rience en tant que Data Engineer\nMa√Ætrise de Python, SQL\nMa√Ætrise des environnements Cloud. Id√©alement certifi√© GCP, Azure ou AWS\nBonne connaissance de Docker/Kubernetes\nBonne connaissance d'au moins un data warehouse (BigQuery, Snowflake, etc)\nConnaissance autour des Notebooks (Jupyter)\nA l'aise avec des concepts li√©s aux APIs (OAuth, REST, etc.)\nA l'aise avec les notions d'Infrastructure as Code (Terraform)\nAu courant des pratiques GitOps et connaissances des concepts autour du CI/CD\nLa ma√Ætrise d'un orchestrateur, comme Apache Airflow, est un plus\nEsprit d'√©quipe (collaborer aux tests unitaires, revue de code, partage de code, sprints)\nBon niveau en fran√ßais et en anglais\nA d√©j√† travaill√© en mode projet avec des interlocuteurs vari√©s (consultant, data analyst, data scientist)\nUne exp√©rience en marketing digital est un plus\nNous proposons :\nun bureau au centre de Paris avec terrasse et jardin\nun environnement multiculturel avec des collaborateurs aux nationalit√©s multiples (France, Royaume-Uni, Etats-Unis, Chine, Tunisie, Italie et plus)\ndes projets avec nos bureaux √† Londres, Hong Kong, New York, Shanghai, Gen√®ve, Shenzhen et Taipei\ndes TGIF et supers soir√©es\nShow more\nShow less",
        "details": {
            "JobDetail": [],
            "TypeContract": "",
            "Salary": "",
            "Level": "",
            "Experience": "2 an(s)"
        },
        "title": "data engineer",
        "skills": {
            "ProgLanguage": [
                "R",
                "Python"
            ],
            "DataBase": [
                "SQL"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [
                "Apache Airflow"
            ],
            "CloudComputing": [
                "GCP",
                "AWS",
                "Azure"
            ],
            "DevTools": [
                "Docker"
            ],
            "DBMS": [
                "BigQuery",
                "Snowflake"
            ],
            "Automation": [
                "Airflow",
                "Kubernetes"
            ],
            "InfrastructureAsCode": [
                "Terraform"
            ],
            "Containers": [
                "Docker",
                "Kubernetes"
            ],
            "Other": [
                "Cloud",
                "CI/CD"
            ],
            "EnSoftSkils": [
                "Collaboration"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "PRIMA Partners Global",
        "location": "Paris",
        "link": "https://fr.linkedin.com/jobs/view/cloud-engineer-at-prima-partners-global-3913218700?position=17&pageNum=0&refId=NuDbZkBPOnBALTaaBOYlpw%3D%3D&trackingId=I1tIcBd3aJ8SyZ0JhDhJXg%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Cloud Engineer | ESSENTIAL SKILL\n:\nFrench language skills (Written & Verbal)\nengineering experience, including Cloud Migrations\nto work across Amazon Web Services (AWS), Google Cloud Platform & Azure environments.\nin automation/scripting languages such as Python/Bash/PowerShell & CI/CD pipeline tools like GitLabCI/Jenkins\nof Infrastructure as code tools like Terraform/CloudFormation\nunderstanding of security best practices and hands-on experience with security tools\nanalytical and problem-solving abilities\n& End User Management experience\ncommunication skills (Written & Verbal)\nCloud Engineer | OVERVIEW\n:\nOur client require a Permanent In-House Cloud Engineer with strong project management skills to lead Cloud initiatives, collaborating closely with IT and Digital stakeholders.\nYour responsibilities will include designing, implementing, and maintaining Cloud infrastructures across AWS, GCP, and Azure platforms, optimizing performance, and deploying automation solutions. You willll oversee outsourced workstreams, monitor Cloud infrastructure performance, and stay updated on Cloud Computing and DevOps trends.\nProficiency in configuring CI/CD pipelines using tools like Jenkins, CircleCI, or TravisCI, and experience with containerization and orchestration technologies like Docker and Kubernetes is essential. Knowledge of infrastructure as code tools such as Terraform and CloudFormation is also required.\nShow more\nShow less",
        "details": {
            "JobDetail": [],
            "TypeContract": "",
            "Salary": "",
            "Level": "",
            "Experience": null
        },
        "title": "cloud architect /engineer ",
        "skills": {
            "ProgLanguage": [
                "Bash",
                "Python"
            ],
            "CloudComputing": [
                "GCP",
                "AWS",
                "Google Cloud Platform",
                "Azure"
            ],
            "DevTools": [
                "Jenkins",
                "Docker"
            ],
            "Automation": [
                "Kubernetes"
            ],
            "InfrastructureAsCode": [
                "CloudFormation",
                "Terraform"
            ],
            "Containers": [
                "Docker",
                "Kubernetes"
            ],
            "Other": [
                "Cloud",
                "DevOps",
                "CI/CD"
            ],
            "EnSoftSkils": [
                "Communication"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "AgileBio",
        "location": "Paris, √éle-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/devops-engineer-at-agilebio-3913553806?position=18&pageNum=0&refId=NuDbZkBPOnBALTaaBOYlpw%3D%3D&trackingId=uFdTNYDafKLTKCdkqxKOSw%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Company Description\nAgileBio is a scientific IT solutions company based in Paris. We specialize in providing biometric, RFID, and traceability solutions for laboratories, R&D, and the biotech and pharmaceutical industries. Our main product, LabCollector, is a full-web LIMS (Laboratory Information Management System) that offers easy deployment options, including on-site installations, unlike traditional SaaS solutions.\nRole Description\nThis is a full-time on-site role for a DevOps Engineer at AgileBio. As a DevOps Engineer, you will be responsible for tasks such as infrastructure as code (IaC) development, software development, continuous integration, system administration, and Linux management. You will work closely with cross-functional teams to support the deployment and maintenance of AgileBio's IT solutions.\nQualifications\nInfrastructure as code (IaC) development, software development, and continuous integration skills\nSystem administration and Linux management experience\nExperience with containerization technologies such as Docker and Kubernetes\nKnowledge of cloud platforms on AWS\nKnowledge on Jenkins\nExpert in Linux\nCompetence in IOT, TCP/IP and networks\nStrong problem-solving and troubleshooting abilities\nAbility to work effectively in a collaborative, agile environment\nExcellent communication and interpersonal skills\nRelevant certifications such as AWS Certified DevOps Engineer or Red Hat Certified Engineer (RHCE) are a plus\nShow more\nShow less",
        "details": {
            "JobDetail": [
                "Full"
            ],
            "TypeContract": "",
            "Salary": "",
            "Level": "",
            "Experience": null
        },
        "title": "devops",
        "skills": {
            "ProgLanguage": [
                "R"
            ],
            "DataAnalytics": [
                "R"
            ],
            "CloudComputing": [
                "AWS"
            ],
            "DevTools": [
                "Jenkins",
                "Docker"
            ],
            "OS": [
                "Linux"
            ],
            "Automation": [
                "Kubernetes"
            ],
            "Containers": [
                "Docker",
                "Kubernetes"
            ],
            "Collaboration": [
                "Teams"
            ],
            "Other": [
                "Cloud",
                "DevOps"
            ],
            "EnSoftSkils": [
                "Communication",
                "Interpersonal Skills"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "Thales Digital Identity and Security",
        "location": "La Ciotat, Provence-Alpes-C√¥te d'Azur, France",
        "link": "https://fr.linkedin.com/jobs/view/cloud-engineer-h-f-at-thales-digital-identity-and-security-3908299124?position=19&pageNum=0&refId=NuDbZkBPOnBALTaaBOYlpw%3D%3D&trackingId=Wvl5HMHyOwr3w90rfooKEQ%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "QUI ETES-VOUS ?\nVous poss√©dez une premi√®re exp√©rience professionnelle sur ce m√©tier.\nVos exp√©rience et expertises vous permettent de conna√Ætre :\nles approches DevSecOps de projets de d√©veloppement logiciel ;\nle d√©veloppement de pipelines GitlabCI ou Jenkins ;\nles outils de qualim√©trie et de s√©curit√©, ainsi que leur automatisation dans les pipelines ;\nle d√©veloppement de pipelines permettant le delivery d'applications ;\nle deploiment de services kubernetes.\ndes connaissances dans le Cloud\nVos comp√©tences techniques :\nd√©veloppement de pipelines (Gitlab CI, Jenkins) ;\nd√©veloppement d‚Äô√©tapes types permettant d‚Äô√™tre r√©utilis√©e au sein de pipeline (SAST, DAST, Code Quality‚Ä¶)\nKubernetes setup, management and tools\nHelm v2 & v3\nConnaissance des infrastructures informatiques, r√©seau, stockage et contain√©risation Docker\nBonne connaissances des pratiques de Linux\nConnaissance des outils de gestion de configuration (Git)\nVos soft skills :\nAutonome, curieux et team player\nCapacit√© √† apprendre rapidement et √† s‚Äôadapter √† de nouvelles technologies, aux outils et √† l'organisation\nCE QUE NOUS POUVONS ACCOMPLIR ENSEMBLE :\nVenez rejoindre le Digital Hub de l'Engineering Competence Center France (ECCF) de Thales, √† La Ciotat !\nSp√©cialis√©e dans les technologies de transformation digitale, cette √©quipe dynamique et en pleine croissance s'int√®gre dans les projets des diff√©rentes unit√©s de Thales : D√©fense, Spatial, A√©ronautique, Identit√© et S√©curit√© Num√©rique. Elle met en oeuvre, au sein des projets op√©rationnels, ses comp√©tences d'architecture et de d√©veloppement de micro-services, de cloud design, de pipelines automatis√©es, de devops et de cybers√©curit√©, pour acc√©l√©rer les transformations des logiciels vers ces technologies modernes.\nEn nous rejoignant sur ce poste, vous aurez le r√¥le d'Ing√©nieur DevSecOps.\nVous int√©grerez une squad agile en charge de la mise en place et du maintien en condition op√©rationnelle des chaines d'int√©gration et de delivery continues et automatis√©es (CICD) d'un projet phare de nos activit√©s spatiale.\nShow more\nShow less",
        "details": {
            "JobDetail": [],
            "TypeContract": "",
            "Salary": "",
            "Level": "",
            "Experience": null
        },
        "title": "cloud architect /engineer ",
        "skills": {
            "DevTools": [
                "Git",
                "Docker",
                "Jenkins"
            ],
            "OS": [
                "Linux"
            ],
            "Automation": [
                "Kubernetes"
            ],
            "Containers": [
                "Docker",
                "Kubernetes"
            ],
            "Other": [
                "Cloud",
                "DevOps"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "zefa",
        "location": "Strasbourg, Grand Est, France",
        "link": "https://fr.linkedin.com/jobs/view/devops-engineer-at-zefa-3901115329?position=20&pageNum=0&refId=NuDbZkBPOnBALTaaBOYlpw%3D%3D&trackingId=JH5B1uQ3B012%2FtmyFc%2FUpw%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "‚Ä¢Develop tools and infrastructures in order to support Build &\nDeployment activities;\n‚Ä¢ Manage, support and improve Build and Deployment pipelines;\n‚Ä¢ Effectively implement a DevOps strategy and associated\nprocesses\n‚Ä¢Minimum 6 years of IT professional experience;\n‚Ä¢ Minimum 3 years of relevant professional experience in a\nDevOps role, involved in maintaining DevOps tools & platform.\n‚Ä¢Thorough understanding of the SDLC, and knowledge of Agile\nmethodologies;\n‚Ä¢ Knowledge of automation tools used to implement continuous\nintegration and continuous delivery;\n‚Ä¢ Working knowledge of known DevOps tools like Git, Jenkins,\nAnsible, Artifactory, Sonarqube, Openshift;\n‚Ä¢ Knowledge of scripting languages (like Groovy);\n‚Ä¢ Knowledge on mobile device technologies (React Native,\nxCode) and Operating systems (Android, iOS) would be\nadvantageous;\n‚Ä¢ Technical writing skills would be an advantage\nShow more\nShow less",
        "details": {
            "JobDetail": [],
            "TypeContract": "",
            "Salary": "",
            "Level": "",
            "Experience": null
        },
        "title": "devops",
        "skills": {
            "DevTools": [
                "Git",
                "Jenkins"
            ],
            "Automation": [
                "Ansible"
            ],
            "Containers": [
                "OpenShift"
            ],
            "Other": [
                "DevOps"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "Coders Connect",
        "location": "Lyon, Auvergne-Rh√¥ne-Alpes, France",
        "link": "https://fr.linkedin.com/jobs/view/devops-engineer-at-coders-connect-3905662055?position=21&pageNum=0&refId=NuDbZkBPOnBALTaaBOYlpw%3D%3D&trackingId=aEsdbErO948rAtGcjIb0VA%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "This\nhybrid role\nis based in\nLyon\n, France, allowing you to split your time between working from home and our office in this culturally rich city. Proficiency in\nEnglish\nis essential, ensuring effective communication within our diverse and collaborative work environment. This arrangement supports a balanced lifestyle and fosters productivity.\nCoders Connect\nis thrilled to announce its partnership with a leading provider of innovative B2B SaaS solutions. This collaboration marks a pivotal moment in redefining the assessment of building materials, guiding decisions for sustainable transportation infrastructure. With a commitment to cutting-edge technology and unwavering core values of innovation, quality, collaboration, and customer satisfaction, our partner empowers stakeholders across the construction value chain in navigating the digital era and progressing towards net-zero objectives.\nPosition Overview:\nAs a\nDevOps Engineer,\nyou will hold a critical role in a dynamic, multicultural, and internationally diverse environment. With English as the working language, you will operate within an agile framework, primarily focused on Kanban. Your responsibilities will include automating cloud-native solutions on platforms such as AWS, managing deployments through Kubernetes, and spearheading efforts to boost infrastructure reliability and performance. By leading a skilled team of engineers and offering cross-functional technical guidance, you will ensure that our platform operates flawlessly and consistently stays ahead in technological innovation and efficiency.\nResponsibilities:\nCloud-Native Development and Automation:\nDesign, implement, and manage cloud-native solutions in line with architectural standards.\nUse Infrastructure as Code (IaC) tools such as AWS CDK, AWS CloudFormation, or Terraform to enhance deployment processes.\nAutomate CI/CD pipelines using tools like GitLab CI/CD and manage container orchestration with Kubernetes to improve service deployment and scalability.\nAdvanced Observability in Cloud-Native Environments:\nImplement and manage observability frameworks tailored for cloud-native applications.\nUtilize tools and standards like OpenSearch, Grafana, OpenTelemetry, and OpenTracing to enhance monitoring and application performance optimization.\nCreate and manage dashboards and alerts based on key performance metrics, using observability data to proactively address issues and guide architectural and operational improvements.\nSupport and Collaboration:\nAssist and guide a team of engineers in adhering to best practices, clarifying specifications, and fostering professional growth.\nWork closely with cross-functional teams to ensure that infrastructure and backend developments align with product and design requirements, contributing to the platform‚Äôs strategy and innovation.\nContinuous Learning:\nStay updated on the latest trends and best practices in cloud architecture, DevOps, and observability.\nParticipate in internal training sessions, workshops, and code reviews.\nRequirements\nEssential:\nBachelor's degree in Computer Science or equivalent.\nAt least 3 years' experience in cloud architecture, cloud-native development, or operations, preferably with AWS.\nMinimum 2 years' experience with observability tools like OpenSearch and OpenTracing.\nExperience in building cloud-native platforms using Kubernetes on AWS.\nFamiliarity with agile development methodologies such as Kanban or SCRUM.\nProficiency in TypeScript or Python.\nStrong experience with GitLab CI/CD pipelines and AWS core services.\nNice to Have:\nUnderstanding of SaaS application development.\nKnowledge of database systems like PostgreSQL, MongoDB, Redis.\nExperience as a Full Stack Developer using Node.js, Java, or Python.\nExperience with workflow automation leveraging AI or LowCode solutions.\nImportant Soft Skills:\nExcellent communication skills for effective collaboration with external developers and explaining technical concepts to non-technical stakeholders.\nAbility to prioritise and delegate tasks efficiently.\nProficient in conducting code reviews and providing constructive feedback.\nSkilled in creating a positive and collaborative team environment.\nStrong organizational skills to manage multiple tasks and coordinate smoothly with external teams.\nCapable of handling project documentation thoroughly and accurately.\nProficient in presenting technical ideas to both technical and non-technical audiences.\nBenefits\nCompetitive salary and performance-based incentives.\nComprehensive benefits package.\nAccess to online learning platform.\nParticipation in tech conference.\nOpportunities for professional development and career growth within a dynamic and innovative company.\nA collaborative and inclusive work environment that values creativity and teamwork.\nShow more\nShow less",
        "details": {
            "JobDetail": [
                "Full"
            ],
            "TypeContract": "",
            "Salary": "Salary, Package",
            "Level": "",
            "Experience": null
        },
        "title": "devops",
        "skills": {
            "ProgLanguage": [
                "Java",
                "Python"
            ],
            "DataBase": [
                "MongoDB"
            ],
            "CloudComputing": [
                "AWS"
            ],
            "DBMS": [
                "PostgreSQL"
            ],
            "Automation": [
                "Kubernetes"
            ],
            "InfrastructureAsCode": [
                "CloudFormation",
                "Terraform"
            ],
            "Containers": [
                "Kubernetes"
            ],
            "Collaboration": [
                "Teams"
            ],
            "Other": [
                "Cloud",
                "DevOps",
                "CI/CD"
            ],
            "EnSoftSkils": [
                "Teamwork",
                "Communication",
                "Collaboration",
                "Creativity"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "DataGalaxy",
        "location": "Lyon, Auvergne-Rh√¥ne-Alpes, France",
        "link": "https://fr.linkedin.com/jobs/view/infrastructure-cloud-run-engineer-at-datagalaxy-3877318102?position=22&pageNum=0&refId=NuDbZkBPOnBALTaaBOYlpw%3D%3D&trackingId=3fZ7p2gl1ebfzwXsEP8QJQ%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Who we are:\nFounded in Lyon, FR in 2015, DataGalaxy is the industry's first Data Knowledge Catalog helping organizations understand how their entire business runs on data. Our data management platform is dedicated to providing user-friendly metadata mapping, management, and knowledge sharing to support organizational data governance and literacy.\nDataGalaxy's Data Knowledge Catalog helps business users accelerate processes, reduce costs, and ensure regulatory compliance by providing an all-in-one data management and data governance platform. Our Data Catalog includes API to ease pre-existing data integration, AI services to automate data classification, and data lineage tracking to visualize data's entire lifecycle journey.\nFollowing our recent growth, DataGalaxy is blasting off to new heights! We've officially raised over $10M in funding and in 2023, DataGalaxy officially entered the American market. We're thrilled to continue expanding our active client base in the USA.\nOur mission:\nTo remain at the forefront of revolutionizing the modern business data catalog by empowering data professionals and business users through increasing data knowledge and providing an all-inclusive understanding of how businesses run on data. We're passionate about helping organizations facilitate rich collaboration, manage data as an asset, and derive powerful, data-driven decision-making.\nOur values: Be intentional. Be clear. Be bold. Be humble.\nAre you interested in joining an organization that values teamwork, ambition, enthusiasm, and collaboration? Each DataGalaxian brings unique knowledge, skills, and points of view that help us create a truly well-rounded crew! We encourage unique ideas, inventive thinking, and independent perspectives so that we can achieve out-of-this-world results together!\nWho we're looking for:\nWe're hiring someone who is:\nüí´ Ready to join a growing team\nüí´ Passionate about data\nüí´ Up-to-date with the latest industry news and developments\nüí´ Organized, autonomous, and a team player!\nWe are seeking a highly skilled and experienced Infrastructure / Cloud Run Engineer to join our dynamic team. This role focuses on maintaining the reliability, security, and cost efficiency of our cloud infrastructure, with a particular emphasis on Kubernetes and AWS ecosystems. The ideal candidate will have a strong background in cloud computing, containerization, and infrastructure management.\nKey Responsibilities\nMaintain Run Reliability: Ensure high availability and reliability of our cloud infrastructure, particularly Kubernetes clusters and AWS and Azure services. Proactively monitor system health, perform troubleshooting, and apply patches and updates as needed\nProduction Instance Management: Efficiently create and delete production instances, ensuring smooth deployments and minimal downtime. Work with development teams to understand requirements and deliver scalable solutions\nSecurity Management: Implement and maintain robust security measures for our cloud infrastructure. This includes managing access controls, network security configurations, and continuous monitoring for vulnerabilities. Managing compliance and security efforts on infrastructure\nCost Optimization: Monitor and optimize cloud resource usage to ensure cost efficiency. Implement cost-saving measures without compromising on performance or reliability\nTool and Technology Expertise: Utilize a range of tools and technologies to manage and improve our cloud infrastructure, with a focus on Kubernetes, AWS and Azure, and related technologies\nSkills and Qualifications\nMust-Have:\nPractical experience with Kubernetes for orchestration and management of containerized applications\nDeep understanding of AWS services, especially EKS. Experience in designing, deploying, and managing AWS-based infrastructure\nFamiliarity with IAM in AWS for managing access controls and permissions\nUnderstanding of VPC concepts to manage network configurations within AWS\nExperience on compliance and security best practices\nNice to Have:\nExperience with Helm, Docker, and secret management tools\nProficiency in GitOps tools such as Flux or Argo CD for continuous deployment\nKnowledge of security scanning tools like Trivy\nExperience with artifact registries and infrastructure as code tools (e.g., Cluster API, Terraform, OpenTofu, Crossplane)\nFamiliarity with monitoring and visualization tools such as Prometheus and Grafana\nFamiliarity with using powershell scripting\nExposure to other cloud providers like GCP and OVH is beneficial\nCloud Providers:\nAWS (must): Specifically, hands-on experience with EKS and knowledge of autoscaling\nAzure: Experience with azure infrastructure deployments is a must\nGCP and OVH (nice to have): Experience with this platform will be considered an advantage\nAdditional Requirements\nExcellent problem-solving skills and the ability to work independently or as part of a team\nStrong communication skills, both written and verbal, to effectively collaborate with cross-functional teams\nA commitment to continuous learning and staying updated with the latest trends and technologies in cloud computing and infrastructure management\nAbility to work in English and French\nüöÄWhat can you expect:\nOffices in the heart of Lyon and Paris, 10-15 minutes from the train stations\nFlexible working hours (\"forfait jour\")\nA real opportunity to join a French start-up that is a pioneer in its market üöÄ\nA chance to create your own career path with autonomy in multiple projects\nAn attractive remuneration according to your performance and your potential\nRemote work at will & 2.50‚Ç¨ net / dayüî•\nHealth insurance Apicil\nMeal vouchers (Swile card of 9‚Ç¨/day)\nPublic transport 50% reimbursement\nDaily coffee and snacks\nQuarterly team events and seminars\nShow more\nShow less",
        "details": {
            "JobDetail": [
                "Remote"
            ],
            "TypeContract": "",
            "Salary": "",
            "Level": "",
            "Experience": null
        },
        "title": "cloud architect /engineer ",
        "skills": {
            "CloudComputing": [
                "GCP",
                "AWS",
                "Azure"
            ],
            "DevTools": [
                "Docker"
            ],
            "Automation": [
                "Kubernetes"
            ],
            "InfrastructureAsCode": [
                "Terraform"
            ],
            "Containers": [
                "Docker",
                "Kubernetes"
            ],
            "Collaboration": [
                "Teams"
            ],
            "Other": [
                "Cloud"
            ],
            "EnSoftSkils": [
                "Teamwork",
                "Communication",
                "Organization",
                "Collaboration"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "ALTEN",
        "location": "Valbonne, Provence-Alpes-C√¥te d'Azur, France",
        "link": "https://fr.linkedin.com/jobs/view/devops-engineer-at-alten-3886545184?position=23&pageNum=0&refId=NuDbZkBPOnBALTaaBOYlpw%3D%3D&trackingId=PksGCVMyGo6XNGYbhn0KJw%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "The\ngoal\nof a Service Reliability Engineer (SRE) or DevOps will be to accelerate Application teams‚Äô ability\nto reliably and consistently deliver applications by developing standardized automation to control, build, and deploy managed services.\nThe main\nresponsibility\nis to participate in the successful delivery of the end to end services with agreed SLAs to our customers by leveraging, improving, designing and implementing services that automate application provisioning.\nYou will:\nparticipate to the building of tools and processes to support the infrastructure.\nleverage scripting to build required automation and tools on an ad-hoc basis.\nactively interface with software developers, system engineers, project management and database administrators on projects.\nOther responsibilities include ongoing issues such as capacity planning, change management, problem management, incident management, release management and performance improvement. You‚Äôll troubleshoot and resolve issues quickly and effectively.\nShow more\nShow less",
        "details": {
            "JobDetail": [],
            "TypeContract": "",
            "Salary": "",
            "Level": "",
            "Experience": null
        },
        "title": "devops",
        "skills": {
            "Collaboration": [
                "Teams"
            ],
            "Other": [
                "DevOps"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "Teads",
        "location": "Paris, √éle-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/cloud-security-engineer-at-teads-3752360703?position=24&pageNum=0&refId=NuDbZkBPOnBALTaaBOYlpw%3D%3D&trackingId=y396HxC7rgTUUlLS5Rumug%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Teads has an engineering team that brings together\n200+ talented individuals\nin 3 main locations (\nMontpellier, Paris, and Bucharest\n). We are organized in agile and autonomous\nfeature teams\nand share technical knowledge within several\ncommunities of practice\n.\nWe promote diversity and are committed to creating an inclusive environment to enable all employees to feel valued and respected, which fosters creativity and innovation by allowing constructive collaboration and open exchange of ideas.\nOur organization offers the opportunity for hybrid work, allowing for two days in the office and the option to work remotely for the remainder of the week. Additionally, we provide relocation packages for those who prefer to relocate to one of our engineering offices.\nüëâ Join a team of passionate people who build quality and responsible advertising, at scale!\nOur main Engineering challenges at Teads\nWorking in a very high-traffic environment (1.9 billion users per month, 100 billion events per day) with low latency and high availability constraints (2 million requests per second, responses in less than 150 milliseconds).\nRich and diverse tech stack and system architecture to optimize for performance, scalability, resiliency, and cost efficiency. We use mostly Scala and TypeScript, among others.\nManagement of large datasets with milliseconds order of magnitude access time, to compute in a near real-time complex auction resolution algorithm (18 million predictions per second).\nBuild efficient and easy-to-use web products used by thousands of users working for the world's most premium publishers, advertisers, and agencies.\nA fast-changing environment where we continuously collaborate with Product teams and constantly adapt our Cloud infrastructure for new features and Products.\nBring a wide diversity of profiles to the same level of quality and knowledge.\nWhat will you do?\nAs a\nCloud Security Engineer\n, your mission will be to:\nProvide technical leadership and consultation for infrastructure engineers and developers to ensure the secure deployment of technology\nAs part of a team, ensure the adoption of security architecture and engineering initiatives in order to effectively and securely support the organization in meeting specific business technology needs\nDrive consideration of cybersecurity tools and datasets to enhance detective and preventative control sets\nUnderstand technical security issues and the implications to Teads businesses and be able to communicate them to management\nUnderstand emerging security technologies and determine the appropriate use within business applications\nMaintain and enforce Teads cybersecurity policies and secure design baselines\nExecute and improve Teads Security architecture review process and ensure compliance for all business initiatives\nArchitect global programs that deploy strong security patterns and controls across applications and computing environments, while addressing security, business resiliency, privacy and compliance frameworks\nIdentify security vulnerabilities and guide developers and engineers in addressing these issues\nImprove architectural adoption through automation and efficiently use security tools to solve challenges at scale\nValidate reference architectures for security best practices and recommend changes to enhance security and reduce risk\nCollaborate with the corporate functions including Finance, HR, Legal and Privacy to ensure that Teads maintains a strong cybersecurity posture\nWhat will you bring to the team?\nProven hands-on experience securing cloud infrastructure\nProven hands-on experience securing global multi-cloud architectures from both compute and network infrastructure perspective\nProven hands-on experience securing operating systems\nProven hands-on experience with application security topics such as the OWASP top 10 and technical remediations required\nDetailed technical experience supporting and implementing SIEM & logging tools (Splunk, Kibana, Qradar)\nAbility to extract actionable intelligence from large volume aggregated log storage\nThorough understanding of Network and Compute architectures and, specifically the security aspects\nThorough understanding of compliance and regulatory frameworks and how they affect architecture designs and reviews\nGood verbal and written communication skills, specifically the ability to communicate within the context of the intended audience, whether that be senior executives or highly technical engineering resources.\nDetailed understanding of the threats faced by advertising and digital platforms organizations\nWorking knowledge of at least one programming language (Python, Go, Terraform etc.)\nWhy work at Teads?\nAt Teads, Product and Engineering work hand in hand and are aligned towards the same goal: to\nscale our business\nwhile continuing to create\nnew and exciting products\n.\nWe value team spirit, pragmatism, listening and we encourage initiatives.\nWe promote end-to-end development: ‚ÄúYou build it, you run it, you monitor it‚Äù.\nWe share knowledge and support with each other beyond any organizational boundary.\nWe fix issues during a blameless postmortem and learn from it so that it doesn‚Äôt happen twice.\nWe are working together to create great engineering, but we are also supportive to promote a great work-life balance.\nWe Care About You\nSecurity & Savings: Attractive package providing financial peace of mind, including competitive compensation, profit-sharing, daily meal vouchers (Swile), family health insurance (Alan), and a personalized relocation package (if needed).\nCareer Development: Continuous investment in our employees' skills: in-house and external training, tech conference opportunities, internal mobility (individual contributor or management career ladder).\nLife Balance: A well-balanced work-life for our employees is one of our top priorities: 35+ days off per year, hybrid work (2-3 days remote work per week, more is open to discussion), fully covered parental leave, and reserved daycare places.\nWellness: Prioritizing employee well-being through premium work equipment, enjoyable work environment (work-life balance, team building events, summits), remote work subsidy, promoting Diversity & Inclusion with internal & external initiatives (women speaking groups, dedicated school partnerships), dedicated charitable time and sustainability actions (Eco Tree, subsidy for eco-mobility).\nDiscover more about our culture and benefits on our Engineering website.\nWhat are our recruitment process steps?\nWe want to get to know you and we try to give you the insight you need to make an informed decision to join us. For that, you can find all the information in our Engineering hiring process article!\nAbout Teads\nTeads operates a leading, cloud-based, omnichannel platform that enables programmatic digital advertising across a global ecosystem of quality digital media.\nAs an end-to-end solution, Teads‚Äô modular platform allows partners to leverage buy-side, sell-side, creative, data and AI optimization technologies. For advertisers and their agencies, Teads offers a single access point to buy the inventory of many of the world‚Äôs best publishers and content providers.\nThrough exclusive global media partnerships, Teads enables advertisers and agencies to reach billions of unique monthly users in brand safe, responsible advertising environments, while improving the effectiveness and efficiency of digital ad transactions.\nTeads partners with the leading marketers, agencies and publishers through a team of 1,200+ people in 50 offices across more than 30 countries.\nWe're committed to creating a dynamic work environment that values diversity and inclusion, and represents employees across a variety of skill sets. We embrace contributions from all ages, sexes, races, ethnicities, religions, sexual orientations and gender identities.\nShow more\nShow less",
        "details": {
            "JobDetail": [
                "Remote",
                "Full",
                "Senior"
            ],
            "TypeContract": "",
            "Salary": "1.9",
            "Level": "",
            "Experience": null
        },
        "title": "cloud architect /engineer ",
        "skills": {
            "ProgLanguage": [
                "Scala",
                "Python"
            ],
            "InfrastructureAsCode": [
                "Terraform"
            ],
            "Collaboration": [
                "Teams"
            ],
            "Other": [
                "Cloud"
            ],
            "EnSoftSkils": [
                "Organization",
                "Leadership",
                "Collaboration",
                "Creativity",
                "Communication"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "ASTRELYA",
        "location": "√éle-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/devops-cloud-engineer-at-astrelya-3902688494?position=25&pageNum=0&refId=NuDbZkBPOnBALTaaBOYlpw%3D%3D&trackingId=bO8PEaJLvLn4NRYju%2BAvHA%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "ASTRELYA est un groupe de conseil et d‚Äôexpertise IT fond√© en 2017, pr√©sent en France (Paris et r√©gions) et en Suisse (Gen√®ve). Aujourd'hui plus de 280 collaborateurs accompagnent nos clients dans l‚Äôacc√©l√©ration et la transformation de leurs organisations.\nDans le cadre de notre d√©veloppement, nous recherchons un\nDevOps / Cloud Engineer F/H\n.\nVos r√¥les et responsabilit√©s :\nAm√©liorer et optimiser les outils li√©s √† la cha√Æne de production\nAutomatisation de process / t√¢ches\nGestion des configurations\nAdministration des serveurs et outils\nSupport aux √©quipes de d√©veloppement\nMa√Ætrise des process d‚Äôint√©gration continue / d√©ploiement\nProposer des nouvelles pratiques et de nouvelles solutions technologiques.\nStack technique :\nCI/CD\n: Jenkins, Sonar, Gitlab, GitLab CI, Ansible\nConteneurisation d‚Äôapplication & Orchestration :\nDocker, Docker Swarm, Kubernetes\nAWS : EC2, S3, ELM, r√¥le IAM, Cognito, Lamba‚Ä¶\nCI/CD : mise en ≈ìuvre, d√©finition d‚Äôarchitecture, int√©gration avec Jenkins, Ansible‚Ä¶\nComp√©tences Techniques :\nDe formation Ing√©nieur ou √©quivalent, vous justifiez d‚Äôune exp√©rience de 4 ans minimum en environnement DEVOPS / CLOUD sur la Stack ci-dessus.\nCI/CD : mise en ≈ìuvre, d√©finition d‚Äôarchitecture, int√©gration avec Jenkins, Ansible‚Ä¶\nVous avez en plus une tr√®s bonne connaissance de Linux Shell et d‚Äôautres langages de programmation (Java, Python‚Ä¶)\nConnaissance de l‚Äôinfrastructure as Code\nM√©thodologie Agile / SAFE\nVous faites preuve de rigueur et d'esprit d'analyse, vous √™tes force de proposition, vous √™tes r√©actif et avez le sens de l'√©coute et du travail d'√©quipe.\nPourquoi rejoindre ASTRELYA ?\nUne gestion de carri√®re personnalis√©e et un management de proximit√©\nUne politique active de formations / certifications (technique, m√©tier, leadership)\nUne offre vari√©e de missions d‚Äôexpertise\nUn engagement RSE fort : Ecovadis Gold, Signataire de la charte pour la diversit√©, du Pacte des Nations Unies et mise en place du M√©c√©nant de comp√©tences\nUne campagne de cooptation attractive\nAfterwork et event r√©guliers\nCette annonce vous correspond ? Postulez ! üöÄ\nTous nos postes sont ouverts aux personnes en situation de handicap.\nPour d√©couvrir l‚Äôensemble de nos offres : ASTRELYA - Expertise en Transformation Digitale & IT\nCette annonce vous correspond ? Postulez ! üöÄ\nTous nos postes sont ouverts aux personnes en situation de handicap.\nShow more\nShow less",
        "details": {
            "JobDetail": [],
            "TypeContract": "",
            "Salary": "",
            "Level": "",
            "Experience": "4 an(s)"
        },
        "title": "devops",
        "skills": {
            "ProgLanguage": [
                "Java",
                "Python"
            ],
            "CloudComputing": [
                "AWS"
            ],
            "DevTools": [
                "Jenkins",
                "Docker"
            ],
            "OS": [
                "Linux"
            ],
            "Automation": [
                "Kubernetes",
                "Ansible"
            ],
            "Containers": [
                "Docker",
                "Kubernetes"
            ],
            "Other": [
                "Cloud",
                "DevOps",
                "CI/CD"
            ],
            "EnSoftSkils": [
                "Leadership"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "WhiteLab Genomics",
        "location": "Paris, √éle-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/devops-cloud-engineer-with-it-experience-at-whitelab-genomics-3919802817?position=26&pageNum=0&refId=NuDbZkBPOnBALTaaBOYlpw%3D%3D&trackingId=UClWsukn%2FVCoeiLpwrD6Kg%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "WhiteLab Genomics\nwas founded with the belief that life-saving drugs should be accessible to all patients in need. United in our vision, we‚Äôve become a part of Y Combinator, French Tech 2030, Future 40 by Station F, and we‚Äôve been recognized by The Galien Foundation (‚ÄùBest Startup‚Äù category), among other institutions at the forefront of technology. Today, we strive to become the leading expert in A.I. for genomic medicine, operating as the go-to partner for research and development.\nIn this critical and multifaceted role\n, you will lead the maintenance, development, and fortification of our AI/IT infrastructure for genomic medicine. We‚Äôre in the process of setting up and scaling our Cloud infrastructure, and you‚Äôll play a valuable role in helping us scale up, leading the charge in optimizing our cloud services, streamlining workflows, and ensuring seamless integration with our DevOps practices and automation frameworks. To scale our current architecture to a higher level, you will help us identify our current bottlenecks, propose new Cloud based solutions, implement them, and help users to use them, allowing for enhanced efficiency. Fostering an atmosphere of productivity and teamwork, your expertise will drive our mission towards greater technological excellence and innovation.\nThis is an\nincredible opportunity\nto work on a diversity of engaging tasks in a hybrid role, forming the infrastructure of a vibrant start-up that seeks to make an impact on the future of healthcare ‚Äì- you'll play a crucial role in helping revolutionize genomic medicine with AI.\nOur Core Values:\nWe Believe that Care is Everything.\nWe Value our Collective Potential\nWe Cultivate Proactive Communication, Clarity and Respect\nWe Have a Can-Do Attitude\nWe Strive for Excellence\nWe‚Äôre Eager to Meet You If‚Ä¶\nProficiency in DevOps methodologies and tools, including proven experience in implementing robust continuous integration, continuous deployment (CI/CD) pipelines, infrastructure as code (IaC), and automated testing frameworks\nDemonstrated experience with coding (preferably Python) for automation tasks and infrastructure management and team interactions for orchestration tasks\nYou have expertise in cloud services (AWS, Azure, or Google Cloud), with a track record of designing, deploying, and managing scalable cloud-based infrastructure solutions tailored to business needs. Your comprehensive understanding of cloud services will enable seamless integration with DevOps practices and automation workflows\nYou have at least\n1 year of prior hands-on experience\nin managing IT equipment, tools, and issues at a tech company (preferably a tech start-up) and excel in administering SharePoint and email systems, ensuring smooth operations and user support\nYou possess great problem solving ability and can work autonomously\nYou have expertise in hardware, software, and network systems\nYou can manage pipelines, optimizing workflows for efficient deployment and delivery\nYour interpersonal skills allow you to collaborate effectively with cross-functional teams, including researchers, data scientists, business development professionals, and support functions\nYou can adapt to a dynamic and rapidly evolving industry, staying on top of the latest IT advancements\nYou have excellent verbal and written communication skills and have experience interfacing with stakeholders and users in English - French proficiency is a plus!\nYou‚Äôre knowledgeable of standard practices for access control models, data protection regulations, IT security, and compliance protocols\nHere‚Äôs How You‚Äôll Make an Impact‚Ä¶\nYou‚Äôll provide strategic and technical leadership to all of our teams, guiding the development and implementation of innovative solutions towards orchestration, CI/CD and security standards\nYou‚Äôll set up and manage CI/CD pipelines to automate processes\nYou‚Äôll write automation scripts to automate routine orchestration tasks and manage our infrastructure efficiently\nYou‚Äôll design, deploy, and manage scalable cloud-based infrastructure solutions\nYou‚Äôll integrate cloud services with DevOps practices and automation workflows\nYou‚Äôll oversee the operation and maintenance of IT tools and infrastructure, ensuring reliability, performance, and security\nYou‚Äôll manage user roles, permissions, and access control for Cloud services, SharePoint, and email systems in compliance with data protection regulations\nYou‚Äôll administer and optimize SharePoint and other collaboration tools to enhance team productivity\nYou‚Äôll ensure all technology systems and platforms operate reliably and efficiently\nYou‚Äôll implement and maintain security policies and procedures, conducting regular audits to ensure compliance with industry standards\nYou‚Äôll provide technical support, resolving issues related to hardware, software, network problems, systems, and access permissions\nYou‚Äôll manage and maintain all IT equipment and tools, ensuring they‚Äôre up to date and in good working condition\nYou‚Äôll lead Cloud and Helpdesk projects from inception to completion, ensuring projects are delivered on time, within budget, and meet quality standards\nYou‚Äôll implement best practices in IT operations and cybersecurity to safeguard company data and systems\nShow more\nShow less",
        "details": {
            "JobDetail": [],
            "TypeContract": "",
            "Salary": "",
            "Level": "",
            "Experience": null
        },
        "title": "devops",
        "skills": {
            "ProgLanguage": [
                "Python"
            ],
            "CloudComputing": [
                "AWS",
                "Azure"
            ],
            "Collaboration": [
                "Teams"
            ],
            "Other": [
                "Cloud",
                "DevOps",
                "CI/CD"
            ],
            "EnSoftSkils": [
                "Teamwork",
                "Leadership",
                "Collaboration",
                "Problem Solving",
                "Interpersonal Skills",
                "Communication"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "Equativ",
        "location": "Paris, √éle-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/cloud-engineer-at-equativ-3804533620?position=27&pageNum=0&refId=NuDbZkBPOnBALTaaBOYlpw%3D%3D&trackingId=GoeDZSf1GqxafEbArjRwwg%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "üë´ About the team\nAt Equativ, we‚Äôre on a mission to develop advertising technologies that empower our customers to reach their digital business goals. This means that we rely on massively scalable, widely distributed, highly available, and efficient software systems; the platform deals with over 3 millions requests per second managed by 3,000 servers.\nOur innovation team based in Paris, Nantes, Limoges, Krakow and Berlin is composed of 100+ straightforward and energetic engineers working in an Agile environment and ready to tackle the most complex technical challenges.\nYour mission üëá\nWithin infra BU you will join the Platform department that strives to develop and deploy self-serve tooling to empower our RnD team.\nOur platform is gradually moving to a hybrid cloud platform. You will be joining as the second member of our cloud platform team:\nYou will help deliver a smooth transition of our RnD team to a hybrid cloud architecture.\nYou will be responsible for cloud governance and FinOps.\nYou will provide help to our engineering teams in order to optimize costs of our GCP components\nWhat you will do ‚úèÔ∏è\nAs a Cloud engineer in our new cloud platform team your missions will be to:\nDesign and develop self-serve tooling for our engineering teams to transition and maintain their workloads to the cloud.\nDesign and instrumentalize Finops guidelines to manage the overall ROI of our cloud infrastructure.\nHelp design and develop our cost management framework to help teams optimize their operational ROI.\nPropagate best-practices and know-how on cloud services and architectural patterns.\nImplement terraform modules to support our IAC approach on the cloud.\nEvaluate the CO2 savings associated with optimizing our cloud infrastructure usage.\nAbout you üëã\nMaster degree in Computer science or similar field of study.\n1+ years of System, Cloud or Software Engineering experience ideally in the web industry.\nAutonomous and innovative mindset.\nExperience in GCP cloud governance for production projects and collaboration within a 5+ engineering team.\nFluent with DevOps practices, specifically on Google Cloud Platform.\nInterested in the impact of technical decisions on business (finops approach) and environmental outcomes.\nWorking proficiency and communication skills in verbal and written English.\nNice to have:\nExperience in one or more of the following GCP topics: Finops, big data components for large datasets, Kubernetes administration.\nExperience working with IaC (Terraform or other).\nExperience in software development (Go, Python or equivalent).\nHow you'll grow üöÄ\nWithin 1 month:\nYou'll be just finishing your onboarding.\nYou'll probably have tackled a few small tasks with your peer.\nWithin 4 months:\nYou'll be trusted to review budget increases from development teams.\nYou'll be expected to propose small-scale optimisations on our cloud architecture.\nWithin 9 months:\nYou'll be in contact with most of the tech leads operating on GCP.\nYou'll be evolving our terraform architecture to deploy resources to the cloud.\nYou‚Äôll start getting a grasp on the AdTech business.\nüëã About us\nEquativ is the new single name for Smart Adserver, DynAdmic, LiquidM and Nowtilus ‚Äî four proven innovators in advertising technology. The vertically integrated company provides brand and privacy-safe solutions that empower its clients to achieve maximum impact while respecting the rights of consumers. The union combines client expertise and engineering excellence to serve the interests of both the supply- side and demand-side with equal professionalism and technical sophistication.\nHeadquartered in Paris and New York, Equativ operates globally with a team of more than 550 people in 20 offices. Equativ offers the market its own independent ad server, SSP, buyer tools, and media services to fulfill the promise of advertising technology. Learn more at Equativ.com.\nThe company is ranked on the Deloitte Technology Fast 500 EMEA and in the Financial Times‚Äô FT 1000: Europe‚Äôs Fastest-Growing Companies.\nEquativ (formerly Smart AdServer) has been awarded the HappyIndex@Work label and is proud to be among the best companies in the ChooseMyCompany ranking, recognized for its flexible working environment.\nCome and lead the charge with us in building a transparent ecosystem based on quality!\n----------------------\nEquativ is an equal opportunity employer. Equal access to employment, services, and programs are available to everyone, regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity, or Veteran status. If you require reasonable accommodation throughout the application and/or interview process, please contact the recruitment team at ta-team@equativ.com\nShow more\nShow less",
        "details": {
            "JobDetail": [],
            "TypeContract": "",
            "Salary": "",
            "Level": "",
            "Experience": null
        },
        "title": "cloud architect /engineer ",
        "skills": {
            "ProgLanguage": [
                "Python"
            ],
            "CloudComputing": [
                "GCP",
                "Google Cloud Platform"
            ],
            "Automation": [
                "Kubernetes"
            ],
            "InfrastructureAsCode": [
                "Terraform"
            ],
            "Containers": [
                "Kubernetes"
            ],
            "Collaboration": [
                "Teams"
            ],
            "Other": [
                "Cloud",
                "Big Data",
                "DevOps"
            ],
            "EnSoftSkils": [
                "Communication",
                "Collaboration"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "Astek",
        "location": "Antibes, Provence-Alpes-C√¥te d'Azur, France",
        "link": "https://fr.linkedin.com/jobs/view/devops-engineer-%E2%80%93-antibes-france-h-f-at-astek-3829412893?position=28&pageNum=0&refId=NuDbZkBPOnBALTaaBOYlpw%3D%3D&trackingId=uEi9cPI%2BZkMctWvIAKSkig%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "CDI\nAntibes - France\nPubli√©e il y a 2 jours\nLe Groupe Astek\nCe Que Nous Allons Accomplir Ensemble :\nRejoindre une √©quipe dans les domaines du transport et du tourisme sur des projets ambitieux dans lesquels la satisfaction clients et les solutions √† valeur ajout√©e jouent un r√¥le crucial.\nVotre Mission, Si Vous L‚Äôacceptez :\nComprendre les exigences du client ;\nEncourager et construire des processus automatis√©s dans la mesure du possible\nContr√¥ler les processus tout au long du cycle de vie pour s‚Äôassurer de leur respect\nD√©finir et param√©trer les processus de d√©veloppement, de test, de mise en production, de mise √† jour et de support pour le fonctionnement DevOps.\nVotre Future √âquipe :\nVenez rejoindre une √©quibe ambitieuse et dynamique dans un environnement international\nVotre stack de jeu\nAnsible, Python, Jenkins, Docker et Kubernetes\nLes Petits Plus Du Projet :\nVous √©voluerez au sein d‚Äôune √©quipe impliqu√©e et r√©active dans un environnement international et interviendrez sur des projets passionnants et enrichissants.\nVous ?\nDipl√¥m√©(e) d‚Äôune √©cole d‚Äôing√©nieur ou √©quivalent de niveau Bac+5. Vous justifiez id√©alement d‚Äôune exp√©rience sur un poste similaire ;\nVotre personnalit√©, votre esprit d‚Äô√©quipe, votre autonomie, votre relationnel, votre rigueur, votre cr√©ativit√© ainsi que votre curiosit√© seront des atouts essentiels pour mener √† bien vos missions sur le projet ;\nVous maitrisez les comp√©tences techniques backend de base : Python, Kubernetes, Jenkins, Docker,‚Ä¶\nAstek\nCr√©√© en France en 1988, Astek est un acteur mondial de l‚Äôing√©nierie et du conseil en technologies. Fort de son expertise dans de nombreux secteurs industriels et tertiaires, Astek accompagne ses clients internationaux dans le d√©ploiement intelligent de leurs produits et de leurs services, et dans la mise en ≈ìuvre de leur transformation digitale.\nDepuis sa cr√©ation, le Groupe a fond√© son d√©veloppement sur une forte culture d‚Äôentrepreneuriat et d‚Äôinnovation, et sur l‚Äôaccompagnement et la mont√©e en comp√©tence de\nses 7800 collaborateurs\nqui s‚Äôengagent chaque jour √† promouvoir la compl√©mentarit√© entre les technologies num√©riques et l‚Äôing√©nierie des syst√®mes complexes.\nRejoignez un Groupe en fort d√©veloppement en France et √† travers le monde ayant r√©alis√© un chiffre d‚Äôaffaires de 600 M‚Ç¨ en 2023.\nTous les d√©tails sur le Groupe sur le site https://astekgroup.fr. Et vous pouvez aussi nous suivre sur notre blog : https://blog.groupeastek.com.\nRencontrons-nous\nKillian, notre Talent Acquisition Officer, vous contactera afin de faire un point avec vous.\nEnsuite, Vous √âchangerez Avec :\nvotre futur manager (futur N+1) afin de discuter de ASTEK, votre parcours, vos attentes et la mission ;\nvotre directeur d‚Äôagence pour valider votre int√©r√™t pour le poste et vous pr√©senter les √©l√©ments contractuels.\nNos Plus\nAstek est green et fait b√©n√©ficier ses salari√©s d‚Äôune indemnit√© kilom√©trique v√©lo\nUne politique CARE sur-mesure d√©ploy√©e par nos √©quipes RH pour nos collaborateurs (https://astekgroup.fr/engagements)\nNotre charte de la Diversit√©\nBienvenue dans la team ! Allez-y, maintenant c‚Äôest √† vous de jouer !\nMots-cl√©s :\ndevops ‚Äì ing√©nieur ‚Äì ing√©nieure ‚Äì consultant ‚Äì consultante ‚Äì terraform ‚Äì ansible ‚Äì python\nCaract√©ristiques de l'emploi\nCat√©gorie Ing√©nieur\nJob Industry Distribution / Services Internet, Transports Terrestres\nPostuler en ligne\nNom *\nPr√©nom *\nEmail *\nUn email valide est requis.\nT√©l√©phone *\nUn num√©ro de t√©l√©phone valide est requis.\nJoindre un CV *\nMots-cl√©s :\ndevops ‚Äì ing√©nieur ‚Äì ing√©nieure ‚Äì consultant ‚Äì consultante ‚Äì terraform ‚Äì ansible ‚Äì python\nShow more\nShow less",
        "details": {
            "JobDetail": [],
            "TypeContract": "CDI",
            "Salary": "",
            "Level": "Bac+5",
            "Experience": null
        },
        "title": "devops",
        "skills": {
            "ProgLanguage": [
                "Python"
            ],
            "DevTools": [
                "Jenkins",
                "Docker"
            ],
            "Automation": [
                "Kubernetes",
                "Ansible"
            ],
            "InfrastructureAsCode": [
                "Terraform"
            ],
            "Containers": [
                "Docker",
                "Kubernetes"
            ],
            "Other": [
                "DevOps"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "Contemporary Amperex Technology Co., Limited",
        "location": "Paris, √éle-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/cloud-platform-engineer-at-contemporary-amperex-technology-co-limited-3888137773?position=29&pageNum=0&refId=NuDbZkBPOnBALTaaBOYlpw%3D%3D&trackingId=IVIKyTQ2n1ePTL3O87wMDQ%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "CATL invites you to continue our legend of green energy. CATL is a World Fortune 300 Company, a global leader who provides premier EV battery and energy storage battery for the world. CATL‚Äôs EV battery consumption volume has ranked No.1 in the world for six consecutive years and global energy storage battery shipment has also ranked No.1 for two consecutive years.\nJob Responsibilities:\n1. Responsible for the operation of overseas big data platforms, formulate data access plans and programs, promote the implementation of data access programs, and realize data access of big data platforms;\n2. Responsible for customer docking, daily customer operation, demand communication and demand analysis of commercial vehicles, passenger cars and energy storage in Europe;\n3. Responsible for data management and data operation, coordinate internal and external resources, and form a normative docking process;\n4. Study the mechanism of battery products, collect data characteristics, and analyze data of specific business problems based on technical indicators;\n5. Responsible for the application and landing of the algorithm model, carry out data cleaning, prediction model establishment, training and optimization for the application scenario, and solve the problems of target recognition, classification, prediction, fault diagnosis and prediction in the scenario;\n6. Responsible for daily operation and maintenance of big data platform, such as operation and maintenance and algorithm deployment.\nJob requirements:\n1.Master degree or above, major in computer,software engineering, data science, vehicle engineering, management science and engineering, artificial intelligence, mathematical statistics and other science and engineering;\n2.‚ë† Familiar with commonly used machine learning and deep learning algorithms and models;\n‚ë° Familiar with mainstream cloud platform products (AWS, Azure, etc.) and understand the cloud native architecture system;\n‚ë¢ Familiar with Linux system principle and shell programming.\n3.‚ë† Have the understanding and mastery of Hadoop ecological technology stack, including but not limited to Spark, flink, storm, kafka, flume, HDFS, etc.;\n‚ë° Familiar with distributed storage and database technologies, including but not limited to ClickHouse, Greenplum, Redis, MonogoDB, ElasticSearch, etc., and skilled in using common data warehouse architectures;\n‚ë¢Master Java, Python, R and other programming languages, and skillfully use Python for data analysis;\n4. At least 2 years working experience in big data platform development or data analysis, experience in automobile industry, new energy or car networking industry is preferred;\n5. English as the working language, familiar with French is preferred;\n6. Strong communication and coordination skills, strong problem analysis and problem-solving skills, strong learning ability,business insight and data understanding ability, high sense of responsibility, and positive working attitude, cheerful personality, with certain pressure resistance.\nShow more\nShow less",
        "details": {
            "JobDetail": [
                "Full"
            ],
            "TypeContract": "",
            "Salary": "",
            "Level": "",
            "Experience": null
        },
        "title": "cloud architect /engineer ",
        "skills": {
            "ProgLanguage": [
                "R",
                "Java",
                "Python"
            ],
            "DataBase": [
                "Elasticsearch"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [
                "Hadoop",
                "Flink",
                "Spark"
            ],
            "CloudComputing": [
                "AWS",
                "Azure"
            ],
            "OS": [
                "Linux"
            ],
            "Other": [
                "Machine Learning",
                "Cloud",
                "Big Data"
            ],
            "EnSoftSkils": [
                "Communication"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "STATION F",
        "location": "Nantes, Pays de la Loire, France",
        "link": "https://fr.linkedin.com/jobs/view/cloud-engineer-at-station-f-3919657457?position=30&pageNum=0&refId=NuDbZkBPOnBALTaaBOYlpw%3D%3D&trackingId=CLBRBQk5MIiONyudToOm3w%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "About\nAB Tasty is a global leader in AI-powered experience optimization solutions empowering brands using personalization, experimentation, recommendations, and search to build better experiences on their websites and apps.\nIntegrated into a single platform, AB Tasty offers web and API-based solutions that provide companies with a unified approach to facilitating seamless experiences for customers.\nBrands use AB Tasty‚Äôs platform to align digital, e-commerce, and product teams on revenue goals by maximizing digital impact.\nFounded in 2013, AB Tasty‚Äôs customer roster includes world-leading brands such as Kering, McDonald‚Äôs, Ulta Beauty, L‚ÄôOreal, Disneyland Paris, and LVMH among others.\nAB Tasty has 12 offices across the globe : North America, Europe, Asia Pacific (Australia and Singapore).\nJob Description\nAB Tasty is a global leader in AI-powered experience optimization solutions empowering brands using personalization, experimentation, recommendations, and search to build better experiences on their websites and apps. Integrated into a single platform, AB Tasty offers web and API-based solutions that provide companies with a unified approach to creating seamless experiences for customers.\nBrands use AB Tasty‚Äôs platform to align digital, e-commerce, and product teams on revenue goals by optimizing and innovating digital experiences.\nFounded in 2013, AB Tasty‚Äôs customer roster includes world-leading brands such as Kering, McDonald‚Äôs, Ulta Beauty, L‚ÄôOreal, Disneyland Paris, and LVMH among others.\nAB Tasty has 12 offices across the globe: North America, Europe, Asia Pacific\nWe are seeking a motivated Cloud Engineer to become an integral part of our cloud infrastructure team.\nThe successful candidate will have practical experience working with cloud services (AWS or GCP) and a desire to develop their skills across a range of technologies and projects.\nThis role involves contributing to the development, optimization, and maintenance of our cloud-based infrastructures, ensuring they meet our standards for scalability, reliability, and security.\nContract & Location\nPermanent full-time contract\nParis or Nantes Office\nSmooth remote work policy (up to 3 days a week)\nWhat You Will Do\nAssist in the migration of applications and services from legacy cloud infrastructure to brand-new, well-architectured cloud infrastructures, ensuring a smooth and efficient transition.\nAssist development and product teams in utilizing cloud infrastructures effectively, providing support and guidance to maximize productivity and efficiency.\nSupport the design and implementation of cloud solutions, contributing to the overall architecture while also taking on specific tasks and projects.\nParticipate in the deployment and management of infrastructure as code, using tools such as Terraform.\nContribute to the development of automation scripts and tools to streamline operational processes using Python, Bash, or similar languages.\nWork closely with product and technical teams to understand requirements and ensure cloud solutions align with business goals.\nMonitor and maintain cloud environments to ensure optimal performance, cost-efficiency, and compliance with security standards.\nContinuously learn and stay up-to-date with emerging cloud technologies and practices.\nWhat We Offer\nHuge impact. AB Tasty is only as great as our team. By directly developing the publicly accessible SaaS platform used by all our clients, you‚Äôll have a direct impact on the company‚Äôs success.\nThe opportunity to unleash your creativity. You‚Äôll be free to contribute to the processes, the tools and the organisation of the team, according the agile principles.\nNo micromanaging. Be the owner of your effort - you‚Äôll be one of the team and fully trusted to take responsibility for your tasks. You‚Äôll have every incentive to make a real impact.\nInternational reach. Our audience is wildly international, and our team is too. Although our HQ is located in France, our company language is English.\nContinuous education. We offer many opportunities for each employee to learn and grow from a mix of professional and non professional topics.\nUnique career opportunity. By joining a fast-growing company that‚Äôs making waves in the tech industry, you‚Äôll have a wonderful chance to enhance your learning and advance in your career faster than you ever thought possible.\nLots. Of. Fun. Our incredible magic makers organize awesome events, such as team games, drinks, yoga classes, parties, and a company-wide retreat every year with employees from all countries gathering for 2 days of fun.\nRemote working, flexible schedule. This isn‚Äôt a ‚Äúclock in, clock out‚Äù company. We care about your productivity, not tracking every minute you‚Äôre on site. It‚Äôs up to you to always be responsible for your work, no matter where you are or what schedule you‚Äôre keeping.\nTime for yourself. After a year within AB Tasty, we offer you a day off during which we simply ask you to think about your career expectations with us. It's not always easy to find time for introspection and to envision what path can lead us to a happy career so we offer a Retreat Day as an opportunity to reflect on that. We not only aim to succeed, but also to make you succeed.\nWhat We Are Looking For\n1+ years of experience in a cloud engineering role, or relevant experience in a cloud-focused project.\nFamiliarity with at least one major cloud provider (AWS, GCP) and its core services.\nExperience with infrastructure as code (Terraform) is a plus.\nExcellent communication skills, both written and verbal.\nAdditional Information\nContract Type: Full-Time\nLocation: Nantes\nPossible partial remote\nShow more\nShow less",
        "details": {
            "JobDetail": [
                "Remote",
                "Full"
            ],
            "TypeContract": "",
            "Salary": "",
            "Level": "",
            "Experience": null
        },
        "title": "cloud architect /engineer ",
        "skills": {
            "ProgLanguage": [
                "Bash",
                "Python"
            ],
            "CloudComputing": [
                "GCP",
                "AWS"
            ],
            "InfrastructureAsCode": [
                "Terraform"
            ],
            "Collaboration": [
                "Teams"
            ],
            "Other": [
                "Cloud"
            ],
            "EnSoftSkils": [
                "Creativity",
                "Communication"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "Teads",
        "location": "Montpellier, Occitanie, France",
        "link": "https://fr.linkedin.com/jobs/view/cloud-security-engineer-at-teads-3757698693?position=31&pageNum=0&refId=NuDbZkBPOnBALTaaBOYlpw%3D%3D&trackingId=o%2BAqghG4UORpShFIGKCoAg%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Teads has an engineering team that brings together\n200+ talented individuals\nin 3 main locations (\nMontpellier, Paris, and Bucharest\n). We are organized in agile and autonomous\nfeature teams\nand share technical knowledge within several\ncommunities of practice\n.We promote diversity and are committed to creating an inclusive environment to enable all employees to feel valued and respected, which fosters creativity and innovation by allowing constructive collaboration and open exchange of ideas.\nOur organization offers the opportunity for hybrid work, allowing for two days in the office and the option to work remotely for the remainder of the week. Additionally, we provide relocation packages for those who prefer to relocate to one of our engineering offices.\nüëâ Join a team of passionate people who build quality and responsible advertising, at scale!\nOur main Engineering challenges at Teads\nWorking in a very high-traffic environment (1.9 billion users per month, 100 billion events per day) with low latency and high availability constraints (2 million requests per second, responses in less than 150 milliseconds).\nRich and diverse tech stack and system architecture to optimize for performance, scalability, resiliency, and cost efficiency. We use mostly Scala and TypeScript, among others.\nManagement of large datasets with milliseconds order of magnitude access time, to compute in a near real-time complex auction resolution algorithm (18 million predictions per second).\nBuild efficient and easy-to-use web products used by thousands of users working for the world's most premium publishers, advertisers, and agencies.\nA fast-changing environment where we continuously collaborate with Product teams and constantly adapt our Cloud infrastructure for new features and Products.\nBring a wide diversity of profiles to the same level of quality and knowledge.\nWhat will you do?\nAs a\nCloud Security Engineer\n, your mission will be to:\nProvide technical leadership and consultation for infrastructure engineers and developers to ensure the secure deployment of technology\nAs part of a team, ensure the adoption of security architecture and engineering initiatives in order to effectively and securely support the organization in meeting specific business technology needs\nDrive consideration of cybersecurity tools and datasets to enhance detective and preventative control sets\nUnderstand technical security issues and the implications to Teads businesses and be able to communicate them to management\nUnderstand emerging security technologies and determine the appropriate use within business applications\nMaintain and enforce Teads cybersecurity policies and secure design baselines\nExecute and improve Teads Security architecture review process and ensure compliance for all business initiatives\nArchitect global programs that deploy strong security patterns and controls across applications and computing environments, while addressing security, business resiliency, privacy and compliance frameworks\nIdentify security vulnerabilities and guide developers and engineers in addressing these issues\nImprove architectural adoption through automation and efficiently use security tools to solve challenges at scale\nValidate reference architectures for security best practices and recommend changes to enhance security and reduce risk\nCollaborate with the corporate functions including Finance, HR, Legal and Privacy to ensure that Teads maintains a strong cybersecurity posture\nWhat will you bring to the team?\nProven hands-on experience securing cloud infrastructure\nProven hands-on experience securing global multi-cloud architectures from both compute and network infrastructure perspective\nProven hands-on experience securing operating systems\nProven hands-on experience with application security topics such as the OWASP top 10 and technical remediations required\nDetailed technical experience supporting and implementing SIEM & logging tools (Splunk, Kibana, Qradar)\nAbility to extract actionable intelligence from large volume aggregated log storage\nThorough understanding of Network and Compute architectures and, specifically the security aspects\nThorough understanding of compliance and regulatory frameworks and how they affect architecture designs and reviews\nGood verbal and written communication skills, specifically the ability to communicate within the context of the intended audience, whether that be senior executives or highly technical engineering resources.\nDetailed understanding of the threats faced by advertising and digital platforms organizations\nWorking knowledge of at least one programming language (Python, Go, Terraform etc.)\nWhy work at Teads?\nAt Teads, Product and Engineering work hand in hand and are aligned towards the same goal: to\nscale our business\nwhile continuing to create\nnew and exciting products\n.\nWe value team spirit, pragmatism, listening and we encourage initiatives.\nWe promote end-to-end development: ‚ÄúYou build it, you run it, you monitor it‚Äù.\nWe share knowledge and support with each other beyond any organizational boundary.\nWe fix issues during a blameless postmortem and learn from it so that it doesn‚Äôt happen twice.\nWe are working together to create great engineering, but we are also supportive to promote a great work-life balance.\nWe Care About You\nSecurity & Savings: Attractive package providing financial peace of mind, including competitive compensation, profit-sharing, daily meal vouchers (Swile), family health insurance (Alan), and a personalized relocation package (if needed).\nCareer Development: Continuous investment in our employees' skills: in-house and external training, tech conference opportunities, internal mobility (individual contributor or management career ladder).\nLife Balance: A well-balanced work-life for our employees is one of our top priorities: 35+ days off per year, hybrid work (2-3 days remote work per week, more is open to discussion), fully covered parental leave, and reserved daycare places.\nWellness: Prioritizing employee well-being through premium work equipment, enjoyable work environment (work-life balance, team building events, summits), remote work subsidy, promoting Diversity & Inclusion with internal & external initiatives (women speaking groups, dedicated school partnerships), dedicated charitable time and sustainability actions (Eco Tree, subsidy for eco-mobility).\nDiscover more about our culture and benefits on our Engineering website.\nWhat are our recruitment process steps?\nWe want to get to know you and we try to give you the insight you need to make an informed decision to join us. For that, you can find all the information in our Engineering hiring process article!\nAbout Teads\nTeads operates a leading, cloud-based, omnichannel platform that enables programmatic digital advertising across a global ecosystem of quality digital media.\nAs an end-to-end solution, Teads‚Äô modular platform allows partners to leverage buy-side, sell-side, creative, data and AI optimization technologies. For advertisers and their agencies, Teads offers a single access point to buy the inventory of many of the world‚Äôs best publishers and content providers.\nThrough exclusive global media partnerships, Teads enables advertisers and agencies to reach billions of unique monthly users in brand safe, responsible advertising environments, while improving the effectiveness and efficiency of digital ad transactions.\nTeads partners with the leading marketers, agencies and publishers through a team of 1,200+ people in 50 offices across more than 30 countries.\nWe're committed to creating a dynamic work environment that values diversity and inclusion, and represents employees across a variety of skill sets. We embrace contributions from all ages, sexes, races, ethnicities, religions, sexual orientations and gender identities.\nShow more\nShow less",
        "details": {
            "JobDetail": [
                "Remote",
                "Full",
                "Senior"
            ],
            "TypeContract": "",
            "Salary": "1.9",
            "Level": "",
            "Experience": null
        },
        "title": "cloud architect /engineer ",
        "skills": {
            "ProgLanguage": [
                "Scala",
                "Python"
            ],
            "InfrastructureAsCode": [
                "Terraform"
            ],
            "Collaboration": [
                "Teams"
            ],
            "Other": [
                "Cloud"
            ],
            "EnSoftSkils": [
                "Organization",
                "Leadership",
                "Collaboration",
                "Creativity",
                "Communication"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "Sidetrade",
        "location": "Boulogne-Billancourt, √éle-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/senior-devops-engineer-sre-h-f-at-sidetrade-3919625910?position=32&pageNum=0&refId=NuDbZkBPOnBALTaaBOYlpw%3D%3D&trackingId=7byL7YdUvBYG7URWDllZRA%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Calling all tech enthusiasts! Are you a problem-solving, curious, and strategic DevOps SRE Engineer? Join us at Sidetrade, the leading global SaaS provider recognized by Gartner.(https://go.sidetrade.com/GartnerMagicQuadrant22.ht)\nIndulge your passion for high-availability software and performance enhancement as part of our dynamic team. Embrace the challenge, embrace the excitement - become a DevOps SRE Engineer and thrive! Shape the future of AI-powered Order-to-Cash at Sidetrade today. Join us in creating innovative solutions that redefine the industry!\nAbout Sidetrade‚ÄØand its amazing R&D team\nSidetrade is a fast-growing international software company that is transforming the Order-to-Cash process for global enterprises. Its AI-powered SaaS platform digitizes the financial customer journey, empowering CFOs to secure and accelerate cash flow generation. Recognized as a Leader in Gartner's Magic Quadrant for two consecutive years, Sidetrade fosters a culture of innovation, collaboration, and customer-centricity from its headquarters in Europe and North America.\nThe R&D team comprises experienced tech professionals who share a deep passion for technology. Together, they are dedicated to developing cutting-edge software solutions that drive the transformation of our customers' work processes. We provide comprehensive training, coaching, resources, and mentorship to empower every team member's growth and nurture their success.\nRequirements\nWhat you will love at Sidetrade:\nWe are seeking a passionate and knowledgeable DevOps SRE Engineer with a multifaceted skill set. Immerse yourself in the exhilarating world of AI and Data Science within our cutting-edge tech environment. Collaborate with like-minded individuals, embracing the latest tools, techniques, and technologies. Fuel your professional growth and innovation within our agile development ecosystem.\nAs a key member of our development team, you will deliver high-quality new features and product enhancements via our online platform. Collaborating with multi-disciplinary teams across the UK and France (with some travel required) will be your forte as you innovate to achieve goals and support the implementation of secure design principles according to policies and standards of Information Security. Explore latest tools and techniques, driving innovation within our R&D team.\nTake control of implementing cutting-edge solutions that optimize our processes. Level up your talent and ignite your development journey!\nWhy you should be working here:\nA strong and demonstrable passion for constantly learning and continuously improving in familiarity with industry leading DevOps/SRE best practices and technologies.\nYou have 5 years+ experience in :\nDeveloping or operating mission-critical systems\nSetup and use of IaC provisioning and deployment tools such as Docker, Terraform and Ansible\nScripting skills with Shell;\nGood knowledge of automation tools\nGood general knowledge of network security (Firewalling, application protection);\nGood knowledge of monitoring tools (Prometheus, grafana, etc.)\nGood knowledge of Linux and Windows systems\nGood knowledge about DNS, DHCP, IPAM, TCP/IP network architectures, HTTP/HTTPS and other Internet protocols.\nYou are aware of security constraints linked to our ISO27001 certification and attached to the roles and responsibilities of this position.\nA plus :\nConcepts and associated tools around containerised and virtualised environments such as Rancher / Kubernetes\nYou worked before with HyperV virtualization technology and Microsoft Azure\nYou speak English fluently, French a plus\nYour first 90 days:\nJoin our Immersive Bootcamp\nReview your onboarding plan with your manager and develop an action plan to achieve your goals\nCollaborate with the team and participate to the roadmap to optimize software performancebuild your internal network across all departments\nExpand your skill set, share your expertise and unlock your full potential\nAt Sidetrade, we cultivate a multicultural environment that fuels innovation. With over 22 nationalities represented, we strongly value diversity, gender equality, inclusivity, and fairness. As an equal opportunity employer, we reject all forms of discrimination and harassment. Your unique contributions are celebrated, driving collective success in our inclusive workplace.\nDiscover more on www.sidetrade.com\nAgencies\nOnly applications from invited agencies through the Workable portal will be accepted. Unsolicited CVs sent directly to managers or HR will not incur any fees.\nShow more\nShow less",
        "details": {
            "JobDetail": [
                "Full"
            ],
            "TypeContract": "",
            "Salary": "",
            "Level": "",
            "Experience": null
        },
        "title": "devops",
        "skills": {
            "ProgLanguage": [
                "R"
            ],
            "DataAnalytics": [
                "R"
            ],
            "CloudComputing": [
                "Azure"
            ],
            "DevTools": [
                "Docker"
            ],
            "OS": [
                "Linux",
                "Windows"
            ],
            "Automation": [
                "Kubernetes",
                "Ansible"
            ],
            "InfrastructureAsCode": [
                "Terraform"
            ],
            "Containers": [
                "Docker",
                "Kubernetes"
            ],
            "Collaboration": [
                "Teams"
            ],
            "Other": [
                "DevOps"
            ],
            "EnSoftSkils": [
                "Collaboration"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "MotorK",
        "location": "Paris, √éle-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/cloud-engineer-at-motork-3892286206?position=33&pageNum=0&refId=NuDbZkBPOnBALTaaBOYlpw%3D%3D&trackingId=NFsVPvQvl%2FY3aQMAdhdULg%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "MotorK is the leading sales and marketing technology company in Europe, specialising in the automotive sector. At MotorK, our mission is to empower manufacturers and dealerships to sell more with innovative, cloud-based products and services to offer the best digital customer experience.\nWe are on a fast and ambitious trajectory and serving 90% of the automotive manufacturers. To continue our growth, we are hiring new talents. If you want to spark the future of the automotive world, join us.\nWe're headquartered in Milan, Italy, where you'll find most of our employees but the teams you'll work with areas across Europe and the UK.\nYou will be the kubernetes expert inside a team of 5 cloud engineers; your role is key to make sure the existing clusters in MotorK are well managed. You will also be the drive for future improvements and implementation of best practices related to k8s and cloud native technologies in MotorK.\nThings you will do:\nIncrease the efficiency of our software development lifecycle thanks to best practices and infrastructure improvements\nBuild and provide tools to increase developer experience\nImprove and scale our cloud infrastructure, making sure governance, cost and security are under control\nDevelop and improve platform monitoring strategies\nPerform capacity management and load testing\nProvide cloud infrastructure support for the entire Research & Development department\nTechnologies you might work with include:\nOrchestration: Kubernetes, Docker\nCloud: AWS, GCP\nWeb: Nginx, Cloudflare\nData: Kafka, MySQL, Postgres, RabbitMQ, MongoDB\nMonitoring: Grafana, Loki, Prometheus\nCode: PHP, Java, Groovy, Python, Javascript\nRequirements\nStrong hands-on production experience on Kubernetes, at least 3 years\nExperience with at least one Cloud Provider, preferably AWS.\nGood to have\nUnderstanding of SRE and DevOps practices\nExperience with Infrastructure as Code (Ansible, Terraform)\nKnowledge of CI/CD\nRelevant experience with RDBMS (mysql, postgres), troubleshooting and optimization\nBackground in Linux environments as Administrator\nExperience on scripting (bash, python)\nPractical knowledge of networking, both cloud and bare-metal\nGood knowledge of monitoring and log collection tools (grafana, prometheus, loki)\nExperience with PHP or Java on k8s is a plus\nExperience with OSS CMS (WordPress, Joomla...) is a plus\nBenefits\nWork pattern and location\nPermanent contract\nHybrid Role\nWhat you can expect from the recruitment process:\nHR interview\nHiring Manager interview, Infrastructure Manager\nC-level interview, VP R&D\nMotorK is an Equal Opportunity Employer and Prohibits Discrimination and Harassment of Any kind. Our company is committed to the principle of equal employment opportunity for all employees and to providing employees with a work environment free of discrimination and harassment. All employment decisions at MotorK are based on business needs, job requirements, and individual qualifications, without regard to race, colour, religion or belief, age, family or parental status, or any other status protected by the laws or regulations in the locations where we operate.\nShow more\nShow less",
        "details": {
            "JobDetail": [],
            "TypeContract": "",
            "Salary": "",
            "Level": "",
            "Experience": null
        },
        "title": "cloud architect /engineer ",
        "skills": {
            "ProgLanguage": [
                "R",
                "Java",
                "Bash",
                "Python"
            ],
            "DataBase": [
                "MongoDB"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [
                "Spark"
            ],
            "CloudComputing": [
                "GCP",
                "AWS"
            ],
            "DevTools": [
                "Docker"
            ],
            "OS": [
                "Linux"
            ],
            "DBMS": [
                "MySQL"
            ],
            "Automation": [
                "Kubernetes",
                "Ansible"
            ],
            "InfrastructureAsCode": [
                "Terraform"
            ],
            "Containers": [
                "Docker",
                "Kubernetes"
            ],
            "Collaboration": [
                "Teams"
            ],
            "Other": [
                "Cloud",
                "DevOps",
                "CI/CD"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "MERITIS",
        "location": "Aix-en-Provence, Provence-Alpes-C√¥te d'Azur, France",
        "link": "https://fr.linkedin.com/jobs/view/devops-engineer-h-f-at-meritis-3815739629?position=34&pageNum=0&refId=NuDbZkBPOnBALTaaBOYlpw%3D%3D&trackingId=rmloD%2FcDTzBLKLjCa2iK8g%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Descriptif de l‚Äôentreprise\n:\nMeritis est une soci√©t√© de conseil sp√©cialis√©e en transformation digitale des organisations, fond√©e en 2007 par S√©bastien Videment.\nInstall√©e initialement √† Paris, elle s‚Äôest d√©ploy√©e en r√©gions et assure d√©sormais une pr√©sence dans les plus grandes villes de France : Sophia-Antipolis, Montpellier, Nantes, Bordeaux, Lyon, Aix-en-Provence, Lille et m√™me √† Lisbonne au Portugal depuis 2023.\nNos experts accompagnent des clients de divers secteurs dans l‚Äôint√©gralit√© de leurs besoins de transformations num√©riques √† travers de nombreux domaines d‚Äôexpertise : Finance, Software Engineering, Cloud & Infrastructure, Data, Transformation Digitale et Cybers√©curit√©.\nFort de ses valeurs d‚Äôexigence, d‚Äôhumilit√©, de bienveillance et de proximit√©, le cabinet de +900 collaborateurs prim√© √† 5 reprises au palmar√®s Great Place To Work¬Æ connait une tr√®s forte croissance et projette d‚Äôatteindre 100M‚Ç¨ de chiffre d‚Äôaffaires en 2024 et de d√©passer la barre symbolique des 1000 collaborateurs.\nNous mettons un point d‚Äôhonneur √† √™tre proche de nos collaborateurs et √† les accompagner de mani√®re individualis√©e quelles que soient leurs fonctions dans l‚Äôentreprise. Certifi√©e Great Place To Work depuis 2013, notre conception du bien-√™tre au travail va bien au-del√† d'un simple label, ce sont nos collaborateurs qui en parlent le mieux : https://www.glassdoor.fr/Avis/Meritis-Avis-E1163008.htm\nDescriptif du poste :\nEn tant que\nIng√©nieur DevOps (H/F),\nvous int√©grerez une entreprise dynamique √©voluant dans un contexte international et un environnement de travail agile. Vos missions seront :\nMettre en place et maintenir les chaines CI/CD de bout en bout\nContribuer aux travaux de fusion de pipelines en vue de rationaliser\nMigrer les pipelines obsol√®tes vers des versions d'outils valid√©es par la strat√©gie entreprise\nD'accompagner les √©quipes de d√©veloppement √† l'appropriation de la m√©thode Devops et des outils mis √† disposition\nParticiper aux r√©flexions de veille sur le p√©rim√®tre du service\nQualification :\nVous avez un dipl√¥me d‚Äôing√©nieur (Bac+5).\nVous disposez d'au moins 5 ans d'exp√©rience dans un environnement DevOps\nVous √™tes issu(e) d'une formation d'ing√©nieur syst√®me et/ou de d√©veloppeur\nVous √™tes dot√©(e) d‚Äôune grande capacit√© d‚Äôadaptation.\nVous r√™vez de progresser entour√©(e) de personnes de tous niveaux d‚Äôexpertise\nOutils / technologies\n:\nJenkins\nGit\nSonar\nCheckmarx\nAngular\nInformations compl√©mentaires\n:\nDes parcours professionnels sur mesure (√©volution de carri√®re, formations adapt√©es, mentoring‚Ä¶) ;‚Äã\nAvoir le choix de sa mission et un accompagnement personnalis√© tout au long de votre carri√®re ;‚Äã\nEvoluer dans un environnement o√π l‚Äôapprentissage est favoris√© : formations certifiantes, e-learning, meetUp, concours de code, parcours d‚Äô√©volutions etc ;‚Äã\nFaire partie de communaut√©s d‚Äôexperts qui partagent leurs savoirs et exp√©riences au sein de nos centres de comp√©tences ;‚Äã\nUn environnement convivial avec de nombreux √©v√©nements festifs (soir√©e annuelle, s√©minaires & teambuiding, d√©jeuners et afterworks‚Ä¶) ;‚Äã\n‚Äã\n\"Meritis est engag√©e dans la Responsabilit√© Soci√©tale des Entreprises. Nous valorisons notre impact positif sur la soci√©t√© et l'environnement. Notre d√©marche RSE guide chacune de nos actions pour promouvoir l'√©quit√©, la durabilit√© et le bien-√™tre de nos collaborateurs. Rejoignez-nous pour √™tre partie prenante de cette d√©marche responsable, o√π chacun de nos talents contribue √† construire un avenir meilleur.\nNos diff√©rences sont nos atouts. C‚Äôest pourquoi Meritis s'implique en faveur de la diversit√© et de la non-discrimination. Tous nos m√©tiers sont accessibles aux personnes en situation de handicap.\"\nShow more\nShow less",
        "details": {
            "JobDetail": [],
            "TypeContract": "",
            "Salary": "",
            "Level": "Bac+5",
            "Experience": "5 an(s)"
        },
        "title": "devops",
        "skills": {
            "DevTools": [
                "Git",
                "Jenkins"
            ],
            "Other": [
                "Cloud",
                "DevOps",
                "CI/CD"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "fifty-five",
        "location": "Paris, √éle-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/lead-cloud-devops-engineer-h-f-at-fifty-five-3883929582?position=35&pageNum=0&refId=NuDbZkBPOnBALTaaBOYlpw%3D%3D&trackingId=3LiXyHZ8fd%2Fxi6o%2FrCC9lQ%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Cloud & DevOps Lead\nfifty-five est une data-company d'un genre nouveau qui aide les marques √† exploiter les donn√©es pour am√©liorer le marketing, les m√©dias et l'exp√©rience client gr√¢ce √† une combinaison de services de conseil et de technologie sp√©cialis√©s.\nEn tant que pilier data et marketing du Brandtech Group, nous offrons des services qui combinent le conseil en strat√©gie, les services de cloud, le conseil en m√©dia et l'exp√©rience client.\nfifty-five, c'est plus de 400 experts du num√©rique. Des digital consultants, des sp√©cialistes du tracking et du m√©dia, des ing√©nieurs et des data scientists, travaillent tous en √©troite collaboration pour fournir des conseils marketing de haut niveau et une assistance technique aux marques, dans tout type d'industrie, partout dans le monde.\nPartenaire des annonceurs de la collecte √† l'activation et l'exploitation des donn√©es, nous aidons les organisations √† devenir de v√©ritables entit√©s omnicanales ma√Ætrisant l'efficacit√© de leur √©cosyst√®me digital et ses synergies avec le monde physique.\nBas√© √† Paris, nous op√©rons sur 3 fuseaux horaires depuis nos 10 bureaux, situ√©s √† Paris, Londres, Gen√®ve, Milan, Shanghai, Hong Kong, Shenzhen, Taipei, Singapour et New York. fifty-five attache une importance particuli√®re au bien-√™tre de ses collaborateurs, ce qui lui a permis de figurer dans le classement Best Workplaces France en 2018.\nContexte :\nfifty-five d√©veloppe r√©guli√®rement des nouvelles solutions bas√©es sur du data processing et dans certains cas du machine learning pour r√©pondre aux besoins pr√©cis de ses clients (par exemple: syst√®me de recommandations de produits, d√©tection d'anomalies, ranking).\nL'√©quipe d'Ing√©nierie adresse √† la fois les outils internes ainsi que les projets clients. L'√©quipe Infrastructure au sein de l'√©quipe Ing√©nierie est responsable de l'infrastructure 55, des outils / scripts d'automation ainsi que des best practices Cloud & DevOps que le reste de l'√©quipe est amen√© √† utiliser dans le cadre de leurs projets (internes ou clients). . L'infrastructure 55 recouvre de mani√®re non exhaustive : les outils de d√©veloppement et la stack DevOps (Gitlab, Jupyterhub, Terraform, Docker, Jenkins, etc.), l'h√©bergement des outils d√©velopp√©s en interne (stack Spring Boot / Angular / MongoDB / Keycloak / Vault h√©berg√© sur GKE), les outils de gouvernance cloud (alerting automatique, billing, etc.), les frameworks templatis√©s que les autres membres de l'√©quipe peuvent utiliser dans le cadre de leurs missions clients (architectures Clouds d√©ployables via Terraform et templatis√©es, sur les 3 cloud publics GCP / Azure / AWS). L'√©quipe intervient √©galement sur l'automatisation de diff√©rents process internes : gestion du billing, ERP automations, etc. L'√©quipe Infrastructure regroupe des Cloud Engineers, DevOps Engineers, Software Engineers (Python).\nMission :\nNous sommes √† la recherche de notre Cloud & DevOps Lead qui sera responsable de l'√©quipe Infrastructure. Il aura en responsabilit√© √† la fois la stack technique interne utilis√© par l'Ing√©nierie et son h√©bergement, ainsi que les best practices et frameworks utilis√©s par les autres ing√©nieurs. Son r√¥le :\n√ätre garant de la disponibilit√© et de la s√©curit√© de l'infrastructure\nMettre en place et surveiller les best practices Infra : GitOps, gouvernance Cloud, FinOps\nS'assurer de la bonne r√©utilisabilit√© des composants / frameworks / templates\nAccompagner son √©quipe dans le suivi des t√¢ches, la mont√©e en comp√©tences et l'expertise au quotidien\nComp√©tences et exp√©riences :\nUne premi√®re exp√©rience sur un poste similaire et un minimum de 4 ans d'exp√©rience.\nMa√Ætrise des environnements Cloud. Id√©alement certifi√© GCP, Azure et/ou AWS\nMa√Ætrise de l'Infrastructure as Code (Terraform)\nMa√Ætrise de Docker/Kubernetes\nMa√Ætrise des pratiques GitOps et CI/CD\nMa√Ætrise de Python, SQL et √©ventuellement Java\nUne connaissance des activit√©s IT est un plus (IDP, user management, device management, DNS management, network, etc.)\nEsprit d'√©quipe (collaborer aux tests unitaires, revue de code, partage de code, sprints)\nBon niveau en fran√ßais et en anglais\nNous proposons :\nun bureau au centre de Paris avec terrasse et jardin\nun environnement multiculturel avec des collaborateurs aux nationalit√©s multiples (France, Royaume-Uni, Etats-Unis, Chine, Tunisie, Italie et plus)\ndes projets avec nos bureaux √† Londres, Hong Kong, New York, Shanghai, Gen√®ve, Shenzhen et Taipei\ndes TGIF et supers soir√©es\nShow more\nShow less",
        "details": {
            "JobDetail": [],
            "TypeContract": "",
            "Salary": "",
            "Level": "",
            "Experience": "4 an(s)"
        },
        "title": "devops",
        "skills": {
            "ProgLanguage": [
                "Java",
                "Python"
            ],
            "DataBase": [
                "SQL",
                "MongoDB"
            ],
            "CloudComputing": [
                "GCP",
                "AWS",
                "Azure"
            ],
            "DevTools": [
                "Jenkins",
                "Docker"
            ],
            "Automation": [
                "Kubernetes"
            ],
            "InfrastructureAsCode": [
                "Terraform"
            ],
            "Containers": [
                "Docker",
                "Kubernetes"
            ],
            "Other": [
                "Machine Learning",
                "Cloud",
                "DevOps",
                "CI/CD"
            ],
            "EnSoftSkils": [
                "Collaboration"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "Equativ",
        "location": "Paris, √éle-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/sre-devops-engineer-at-equativ-3853475202?position=36&pageNum=0&refId=NuDbZkBPOnBALTaaBOYlpw%3D%3D&trackingId=i731NNFa%2B7m56h5tZQ9%2Fxg%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "üë´ About the team\nAt Equativ, we‚Äôre on a mission to develop advertising technologies that empower our customers to reach their digital business goals. This means that we rely on massively scalable, widely distributed, highly available, and efficient software systems; the platform deals with over 3 millions requests per second managed by 3,000 servers.\nOur innovation team based in Paris, Nantes, Limoges, Krakow and Berlin is composed of 100+ straightforward and energetic engineers working in an Agile environment and ready to tackle the most complex technical challenges.\nYour mission üëá\nWithin infrastructure BU you will join the Platform department that strives to develop and deploy self-serve tooling to empower our RnD team.\nAs a member of our application SRE team, you will work closely with dev and platform teams to:\nAccelerate time to market and reliability of our backend services\nEnsure that our platform availability fulfills its SLA of 99.95%.\nWhat you will do ‚úèÔ∏è\nAs a backend application SRE, your key responsibilities will be:\nCommunication Bridge:\nAct as the primary liaison between the R&D and Platform, DevSecOps and Ops teams\nAligning Best Practices:\nImplement and align DevOps mindset and best practices, including SLOs framework, monitoring, and alerting, across diverse applications.\nWork closely with dev teams to ensure adherence to industry standards and best practices, optimizing the efficiency and reliability of our platform.\nKnowledge Sharing:\nFacilitate knowledge transfer sessions to empower development teams with increased autonomy on DevOps matters and improved services reliability\nProduction awareness:\nAssist on identifying service errors, instability patterns and latency issues\nActively participate in production impediments (PIMPs), postmortems, and incident handling, contributing to a proactive production environment.\nProvide insights and recommendations for improving production processes and preventing future incidents.\nAbout you üëã\nMaster degree in Computer science or similar field of study.\n2+ years of System or Software Engineering experience ideally in the web industry.\nFluent with DevOps practices.\nExperience in at least one of the following topics: CI/CD pipelines (gitlab, ‚Ä¶), Kubernetes administration (Rancher, argoCD, ‚Ä¶), Monitoring and alerting (prometheus, grafana stack, ‚Ä¶) with a focus on backend applications\nExperience working with IaC (Terraform, GitOps, ‚Ä¶).\nAutonomous and innovative mindset.\nWorking proficiency and communication skills in verbal and written English.\nNice to have:\nExperience with troubleshooting live incidents and incident management.\nExperience in software development (Go, Python or equivalent).\nHow you'll grow üöÄ\nWithin 1 month:\nYou'll be just finishing your onboarding.\nYou'll probably have tackled a few small tasks with your peers.\nWithin 4 months:\nYou'll be trusted to endorse weekly Green Lantern role to assist day to day BE requests.\nYou'll be assigned to minor tasks to ramp up on our stacks and processes.\nWithin 9 months:\nYou'll be leading critical projects (Priority 0).\nYou'll be evolving in our technical architecture discussion.\nYou‚Äôll start getting a grasp on the AdTech business.\nüëã About us\nEquativ is the new single name for Smart Adserver, DynAdmic, LiquidM and Nowtilus ‚Äî four proven innovators in advertising technology. The vertically integrated company provides brand and privacy-safe solutions that empower its clients to achieve maximum impact while respecting the rights of consumers. The union combines client expertise and engineering excellence to serve the interests of both the supply- side and demand-side with equal professionalism and technical sophistication.\nHeadquartered in Paris and New York, Equativ operates globally with a team of more than 550 people in 20 offices. Equativ offers the market its own independent ad server, SSP, buyer tools, and media services to fulfill the promise of advertising technology. Learn more at Equativ.com.\nThe company is ranked on the Deloitte Technology Fast 500 EMEA and in the Financial Times‚Äô FT 1000: Europe‚Äôs Fastest-Growing Companies.\nEquativ (formerly Smart AdServer) has been awarded the HappyIndex@Work label and is proud to be among the best companies in the ChooseMyCompany ranking, recognized for its flexible working environment.\nCome and lead the charge with us in building a transparent ecosystem based on quality!\n----------------------\nEquativ is an equal opportunity employer. Equal access to employment, services, and programs are available to everyone, regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity, or Veteran status. If you require reasonable accommodation throughout the application and/or interview process, please contact the recruitment team at ta-team@equativ.com\nShow more\nShow less",
        "details": {
            "JobDetail": [],
            "TypeContract": "",
            "Salary": "",
            "Level": "",
            "Experience": null
        },
        "title": "devops",
        "skills": {
            "ProgLanguage": [
                "R",
                "Python"
            ],
            "DataAnalytics": [
                "R"
            ],
            "Automation": [
                "Kubernetes"
            ],
            "InfrastructureAsCode": [
                "Terraform"
            ],
            "Containers": [
                "Kubernetes"
            ],
            "Collaboration": [
                "Teams"
            ],
            "Other": [
                "DevOps",
                "CI/CD"
            ],
            "EnSoftSkils": [
                "Communication"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "Centric Software",
        "location": "Paris",
        "link": "https://fr.linkedin.com/jobs/view/senior-cloud-operations-engineer-at-centric-software-3916228666?position=37&pageNum=0&refId=NuDbZkBPOnBALTaaBOYlpw%3D%3D&trackingId=uvh4gjHY%2BxzTCaRNevyqhA%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Centric Software provides a Digital Transformation Platform for the most prestigious names in fashion, retail, footwear, luxury, outdoor and consumer goods. Centric‚Äôs flagship Product Lifecycle Management (PLM) platform, Centric 8, delivers enterprise-class merchandise planning, product development, sourcing, quality, and collection management functionality tailored for fast-moving consumer industries. Centric SMB provides innovative PLM technology and key industry learnings for emerging brands. Centric Visual Innovation Platform (VIP) offers a fully visual, transformative experience via large touchscreens and mobile devices, revolutionizing group decision-making and creative collaboration while dramatically condensing time to market and product innovation.\nJob Summary:\nThis role will be responsible for utilizing a diverse set of cloud technologies to support Centric Cloud Customers and to help build and maintain a scalable, robust, highly available platform for Centric‚Äôs C8 cloud application.\nThis position will report to the Senior Director, Cloud Operations.\nLocation:\nThis is a Remote - Europe (UK and EU-based candidates only*)\nWorking Time:\nCentral European Working hours\nResponsibilities:\nManage and maintain cloud infrastructure on platforms such as AWS, Azure, or Google Cloud.\nMonitor cloud resources to ensure availability and scalability.\nMonitor and optimize cloud resource utilization.\nRespond to and resolve time-critical customer issues in the public cloud.\nTroubleshoot cloud-related infrastructure incidents and issues.\nPerform customer deployments, migrations, and upgrades in the cloud environment.\nSupport automation projects, writing infrastructure as code (IaC) for provisioning and scaling resources.\nAssist in ensuring security best practices for the cloud are followed and customer data is secured.\nPerform database operations such as backup and restores.\nCollaborate with development, devOps and support teams to deploy and manage cloud-based applications and resolve issues.\nCreate and maintain documentation for cloud infrastructure and processes.\nStay up-to-date with cloud technology trends and best practices.\nPropose and implement improvements to cloud operations processes.\nQualifications:\nBachelor‚Äôs Degree Computer Science, MIS, or related technology field, or equivalent practical experience\n8+ years of experience in cloud operations and infrastructure management in AWS, Azure, or Google cloud\n5+ years in incident response and major incident management\nAdvanced Linux and Windows experience\nCertification in AWS, Azure or Google Cloud is a plus.\nSolid understanding of Cloud networking and security\nStrong scripting and automation skills (e.g., Python, Powershell)\nProficiency in infrastructure as code (IaC) and configuration management tools. (e.g, Terraform, Ansible)\nExpert knowledge in containerization and orchestration technologies (e.g., Docker Kubernetes, Rancher)\nExperience in version control, CI and automation tools such as Github/Bitbucket, Github Actions, Jenkins, Rundeck)\nExperience in deploying and troubleshooting Java based applications and microservices.\nExperience in deploying, configuring, and troubleshooting Database technologies like MSSQL, PostgreSQL and MongoDB\nExperience in monitoring and logging tools (e.g., Nagios, Prometheus, ELK stack)\nExperience with the following technologies: Virtualization, VPN, RDP, SSO, Kafka\nExperience working with Confluence/Jira\nWhat we offer:\nCompetitive salary and benefits\nA multifaceted job with a high degree of responsibility and a broad spectrum of opportunities\nOpportunity to work remotely with a dedicated and motivated team\nA remote work environment built on collaboration, flexibility, and respect\nVaried and challenging work to help you grow your technical skillset.\nShow more\nShow less",
        "details": {
            "JobDetail": [
                "Remote",
                "Full",
                "Senior"
            ],
            "TypeContract": "",
            "Salary": "Salary",
            "Level": "",
            "Experience": null
        },
        "title": "cloud architect /engineer ",
        "skills": {
            "ProgLanguage": [
                "Java",
                "Python"
            ],
            "DataBase": [
                "MongoDB"
            ],
            "CloudComputing": [
                "AWS",
                "Azure"
            ],
            "DevTools": [
                "Jenkins",
                "Docker"
            ],
            "OS": [
                "Linux",
                "Windows"
            ],
            "DBMS": [
                "PostgreSQL"
            ],
            "Automation": [
                "Kubernetes",
                "Ansible"
            ],
            "InfrastructureAsCode": [
                "Terraform"
            ],
            "NetworkSecurty": [
                "VPN"
            ],
            "Containers": [
                "Docker",
                "Kubernetes"
            ],
            "Collaboration": [
                "Confluence",
                "Teams",
                "JIRA"
            ],
            "Other": [
                "Cloud",
                "DevOps"
            ],
            "EnSoftSkils": [
                "Flexibility",
                "Collaboration"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "Euroclear",
        "location": "Paris, √éle-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/junior-devops-application-server-engineer-at-euroclear-3918734003?position=38&pageNum=0&refId=NuDbZkBPOnBALTaaBOYlpw%3D%3D&trackingId=gHtGV%2FK5QZdhl6oX9u6akA%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Location: Paris, France\nHeadquartered in Brussels and offices in more than 15 countries around the world, including Paris, Euroclear is the financial industry's leading provider of post-trade services globally. Our company ensures the settlement, custody and service of national and cross-border securities transactions, whether in bonds, shares, derivatives or investment funds. To put it simply, we are a bank for banks, and we are at the heart of the world financial system.\nEuroclear has an ambitious Group Strategy based on the following pillars:\nTransformation of the core business through smart process automation, analytics and value-added web-based user interface\nSetting up of a new Business line (i.e. Euroclear Information Services) aiming at monetizing the wealth of data acquired by Euroclear through its operations\nGeographical extension in emerging markets as well as partnerships in North America\nFurther streamlining of the post trade value chain leveraging off technologies such as Distributed Ledger Technologies\nAll the above requires amongst others:\nA rapid transformation of its IT towards Agile Software Development, DevOps, and the Cloud\nA collaborative platform managed jointly by Business and IT focused on driving innovation with staff and clients and delivering new digital products/services\nA highly automated IT that combines smartly resilience, security, speed and innovation\nIn this transformation context Group Technology Services (GTS) plans, builds and runs the global infrastructure of Euroclear, and is additionally responsible for the IT service management to the operating entities of the various Group markets. GTS operates its IT systems and IT services in such a way that, at an appropriate and benchmarked cost level, it can deliver the agreed levels of service to support the requirements of the business processes, for both normal operations and during disaster recovery.\nWe are looking for\nJunior DevOps Application Server Engineer\nto expand our division.\nYour role would be to\nDesign, implement and support Java Application Server based infrastructure solutions to support business opportunities in alignment with the enterprise architecture direction and standards\nAutomate the installing and maintaining of Java Application Server components on Linux and Windows operating systems within the datacentre using Ansible automation framework\nDevelop scripts to integrate Java Application Server components in the CI/CD pipeline (Infrastructure as code)\nEnsure business applications are successfully integrated and operated within the company‚Äôs business environment and in compliance with the standards\nParticipate in, support and manage the deployment of applications within test, pre-production and production environments\nIntegrate Java application server components into private cloud based on Kubernetes technology\nYour profile\nBachelor or Master degree in Computer Science/ Information Technology/ Engineering or comparable qualification\nIdeally a first job/traineeship experience in IT\nFluent in French and in English\nAble to demonstrate your ability to learn ICT technologies\nAble to easily adapt to new circumstances / technologies / procedures\nStress resistant and constructive whatever the context\nAble to comply with existing standards and acting with attention to detail\nA true team player who demonstrates good interpersonal skills\nAble to summarize complex technical situations in simple terms\nSolution and client oriented\nWhat we offer\nWe offer an excellent opportunity to practice and develop your talents in a highly professional and motivated team, dealing with multi-domains and involved in some of the most strategic projects for the company\nYou will have the possibility to extend your IT skills and progressively evolve to one of the various possible career paths\nThis role gives you the opportunity to work with recent technologies that will require you to continuously develop your experience and skills\nYou will receive trainings to further evolve in the role\nNew ways of working\nAt Euroclear, we believe in an ideal balance between office and remote work toward business, team and individual needs, enhancing more flexibility, trust and individual accountability.\nAbout us\nThe Euroclear group is at the heart of the global capital markets providing post-trade and related services to 90% of the world‚Äôs top banks. As a proven and resilient capital market infrastructure we have been offering vital financial services for over 50 years. Join us and help us serve our global customer franchise as we support their settlement and asset servicing of a variety of instruments, from domestic and international bonds to equities, investment funds and more.\nGreat Place to Work for All\nWe believe that our people are our strength. The diverse talents that our employees bring to the table, are directly linked to our global success. We are committed to creating an inclusive culture that celebrates diversity, and strive to be a Great Place to Work for All. All qualified applicants will be considered for employment, regardless of their race, religion, color, national origin, gender, sexual orientation, gender identity or expression, age, marital status, pregnancy, neuro-diversity, disability, or any other aspect that makes them unique. If you need any specific accommodation due to disability or any other reason, you can let the recruiter know during your application process.\nShow more\nShow less",
        "details": {
            "JobDetail": [
                "Remote",
                "Full",
                "Junior"
            ],
            "TypeContract": "",
            "Salary": "",
            "Level": "",
            "Experience": null
        },
        "title": "devops",
        "skills": {
            "ProgLanguage": [
                "Java"
            ],
            "OS": [
                "Linux",
                "Windows"
            ],
            "Automation": [
                "Kubernetes",
                "Ansible"
            ],
            "Containers": [
                "Kubernetes"
            ],
            "Other": [
                "Cloud",
                "DevOps",
                "CI/CD"
            ],
            "EnSoftSkils": [
                "Flexibility",
                "Interpersonal Skills"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "StrangeBee",
        "location": "Paris, √éle-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/cloud-engineer-aws-f-h-at-strangebee-3870967050?position=39&pageNum=0&refId=NuDbZkBPOnBALTaaBOYlpw%3D%3D&trackingId=5lPJsvinH7sHk%2FggAg5mXw%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "StrangeBee\nest un\n√©diteur de solutions de cybers√©curit√©\nd√©di√©es √† la\nR√©ponse aux Incidents\n.\nEn 2018, Thomas, Nabil & J√©r√¥me cr√©ent la soci√©t√© StrangeBee et poursuivent le d√©veloppement et l'enrichissement des applications open source TheHive & Cortex, entam√©s 4 ans auparavant.\nDevenue la r√©f√©rence, TheHive √©paule aujourd'hui des milliers d'analystes √† travers le monde, √† d√©fendre leur entreprise contre les cyberattaques quotidiennes.\nSes ambitions ? Renforcer son offre, r√©pondre aux besoins grandissants, et s'imposer comme leader des plateformes de r√©ponse aux incidents de cybers√©curit√©.\nVotre future √©quipe\nL'√©quipe des Produits Cloud supervise les offres IaaS et SaaS. Vous contribuerez directement au d√©veloppement et aux op√©rations de TheHive Cloud Platform, notre solution enti√®rement g√©r√©e h√©berg√©e sur AWS. Vous serez √©galement impliqu√© dans la mise √† jour r√©guli√®re et la publication de nos images IaaS sur AWS, Azure et Outscale.\nL'√©quipe travaille principalement √† distance, nous recherchons donc quelqu'un capable de faire preuve d'un haut niveau d'ind√©pendance et d'autonomie.\nDESCRIPTIF DE POSTE\nNotre √©quipe est en croissance et recherche un nouveau\nCloud Engineer\n. Vous serez profond√©ment impliqu√©.e dans tous les aspects du cycle de vie des produits IaaS et SaaS :\nD√©veloppement de nouveaux modules d'infra-as-code et am√©lioration de ceux existants.\nConception et d√©ploiement d'environnements techniques sur des infrastructures cloud.\nContribution √† la s√©curit√© et aux op√©rations quotidiennes de nos syst√®mes de production bas√©s sur le cloud. Ces syst√®mes tournent 24/7 et n√©cessitent des personnes disponibles et r√©actives afin de r√©pondre aux imp√©ratifs de production (incidents, changements, maintenance, etc.).\n√âvaluation de la conformit√© de nos produits avec diff√©rentes normes de s√©curit√© et mise en place de nouvelles fonctionnalit√©s de s√©curit√©.\nAm√©lioration de la surveillance des SLA et des processus de QA.\nR√©daction de documentation technique.\nD√©veloppement et mise √† jour de mod√®les d'infra-as-code pour nos clients IaaS.\nSupport aux clients IaaS et SaaS.\nPublication des mises √† jour des produits sur les places de march√© des fournisseurs de cloud.\nVous soutiendrez √©galement d'autres membres de l'√©quipe gr√¢ce √† votre expertise et pourriez occasionnellement encadrer des coll√®gues moins exp√©riment√©s (juniors, apprentis, stagiaires).\nPROFIL RECHERCH√â\nVous poss√©dez une connaissance approfondie et prouv√©e des services AWS (au moins deux ans d'exp√©rience pratique quotidienne).\nTerraform et Packer n'ont aucun secret pour vous en ce qui concerne la gestion des infrastructures cloud.\nVous avez √©crit et d√©ploy√© des dizaines de r√¥les Ansible.\nLinux est le seul OS auquel vous faites confiance pour la production et vous vous d√©brouillez bien avec Ubuntu. Vous pourriez secr√®tement √™tre un f√©tichiste de lignes de commande (c'est acceptable, nous n'avons pas besoin de le savoir).\nVotre console est en lecture seule; tout changement que vous apportez √† un syst√®me de production provient de l'Infra-as-Code (le code √©tant stock√© dans un VCS). Pour √™tre honn√™te, vous consid√©rez en fait que tout ce qui a √©t√© modifi√© manuellement est un d√©chet contamin√© qui devrait √™tre imm√©diatement d√©truit et red√©ploy√© √† partir d'une source propre et fiable.\nVous avez une grande exp√©rience de l'exploitation et du support de syst√®mes de production bas√©s sur le cloud, id√©alement sur AWS.\nTout votre code est dans Git, et uniquement dans Git.\nVous avez une certaine exp√©rience de Hashicorp Vault.\nVous avez une certaine connaissance des meilleures pratiques en mati√®re de s√©curit√© de l'information (vous avez mis en ≈ìuvre activement des fonctionnalit√©s de s√©curit√© sur des syst√®mes de production par le pass√©).\nVous √™tes un grand fan de documentation. Vous documentez toujours votre code. Vous savez r√©diger une documentation technique propre et structur√©e ainsi que des proc√©dures.\nCe que nous n'avons pas os√© demander mais appr√©cierions vraiment\nExp√©rience de publication sur les places de march√© des fournisseurs de cloud (AWS, Azure, GCP).\nExp√©rience de Terraform Cloud : vous savez ce que sont les modules et les espaces de travail.\nFamiliarit√© avec certains pipelines CI/CD.\nExp√©rience avec la stack Elastic.\nExp√©rience de l'utilisation de TheHive et Cortex !\nPROCESS DE RECRUTEMENT\nCall d√©couverte avec le service People (~30 min)\nTest de personnalit√© AssessFirst\nEntrevue technique avec ton futur manager (~1h)\nEntretien avec l‚Äôun des fondateurs (~1h)\n√âchange avec la Head of People\nShow more\nShow less",
        "details": {
            "JobDetail": [
                "Junior"
            ],
            "TypeContract": "",
            "Salary": "",
            "Level": "",
            "Experience": "4 an(s)"
        },
        "title": "cloud architect /engineer ",
        "skills": {
            "CloudComputing": [
                "GCP",
                "AWS",
                "Azure"
            ],
            "DevTools": [
                "Git"
            ],
            "OS": [
                "Linux"
            ],
            "Automation": [
                "Ansible"
            ],
            "InfrastructureAsCode": [
                "Terraform"
            ],
            "Other": [
                "Cloud",
                "CI/CD"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "Mistral AI",
        "location": "Paris, √éle-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/devops-engineer-at-mistral-ai-3878342741?position=40&pageNum=0&refId=NuDbZkBPOnBALTaaBOYlpw%3D%3D&trackingId=np7DJVrMqdOHDOOgpX4Xbw%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "We are seeking our first DevOps Engineer.\nResponsibilities\nCollaborate with AI/ML engineers and researchers to develop and implement a CI/CD that enables safe and reproducible experiments\nEnable seamless replication of work environment across several HPC clusters\nImplement and maintain monitoring, logging and alerting systems for both our large training runs and our client-facing APIs\nMake sure training environments are always available and ready on several clusters\nImprove development processes while finding the right balance between rigor, speed and flexibility for software development & research organization\nDevelop and own internal tooling\nCollaborate with our AI/ML engineers and data scientists to build and maintain a secure, scalable, and efficient infrastructure\nDevelop and implement CI/CD pipelines to streamline the evaluation and development of AI/ML models and other applications\nEnsure compliance with security best practices and industry standards\nWork closely with the development team to troubleshoot and resolve issues in production environments\nDevelop and maintain containerization and orchestration systems using tools like Docker and Kubernetes\nDocument processes and procedures to ensure consistency and knowledge sharing across the team\nAbout you:\nMaster‚Äôs degree in Computer Science, Engineering, or a related field, or equivalent experience\n3+ years of experience in a DevOps role, preferably in an AI/ML-focused environment\nStrong experience with Kubernetes-based cloud computing\nProficiency in scripting languages such as Python, Bash, or PowerShell\nExperience with CI/CD tools like Jenkins, GitLab CI, or CircleCI\nExperience with containerization and orchestration technologies such as Docker and Kubernetes\nStrong knowledge of Python development good practices\nHaving worked with GPUs before is a + but not required\nFamiliarity with infrastructure-as-code tools like Terraform or CloudFormation\nKnowledge of monitoring, logging, and alerting tools like Prometheus, Grafana, ELK Stack, or Datadog\nYou ideally have an experience in Slurm\nStrong understanding of networking, security, and system administration concepts\nExcellent problem-solving and communication skills\nSelf-motivated and able to work well in a fast-paced startup environment\nWhat We Offer:\nAbility to shape the exciting journey of AI and be part of the very early days of one of Europe‚Äôs hottest startup\nA fun, young, multicultural team and collaborative work environment ‚Äî based in Paris and London\nCompetitive salary and bonus structure\nComprehensive benefits package\nOpportunities for professional growth and development\nShow more\nShow less",
        "details": {
            "JobDetail": [],
            "TypeContract": "",
            "Salary": "Salary, Package",
            "Level": "",
            "Experience": null
        },
        "title": "devops",
        "skills": {
            "ProgLanguage": [
                "Bash",
                "Python"
            ],
            "DevTools": [
                "Jenkins",
                "Docker"
            ],
            "Automation": [
                "Kubernetes"
            ],
            "InfrastructureAsCode": [
                "CloudFormation",
                "Terraform"
            ],
            "Containers": [
                "Docker",
                "Kubernetes"
            ],
            "Other": [
                "ML",
                "Cloud",
                "DevOps",
                "CI/CD"
            ],
            "EnSoftSkils": [
                "Flexibility",
                "Communication",
                "Organization"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "Devoteam G Cloud",
        "location": "√éle-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/%F0%9F%9A%80cloud-devops-engineer%F0%9F%9A%80-at-devoteam-g-cloud-3916035882?position=41&pageNum=0&refId=NuDbZkBPOnBALTaaBOYlpw%3D%3D&trackingId=xaQANSZsf5Yzo29P56Hw2w%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "üöÄüíª Devoteam GCloud cherche un(e) Ninja du Cloud DevOps GCP pour rejoindre notre √©quipe de champions de l'innovation !\nSi vous √™tes pr√™t(e) √† transformer le monde du cloud avec votre expertise, votre cr√©ativit√© et votre √©nergie, alors cette annonce est faite pour vous :\nüîç\nVos Missions :\nD√©ployer et maintenir des infrastructures cloud fiables et √©volutives sur Google Cloud Platform (GCP)\nAutomatiser les processus de d√©veloppement, d'int√©gration et de d√©ploiement pour acc√©l√©rer la livraison de logiciels\nCollaborer avec des √©quipes multidisciplinaires pour concevoir des architectures cloud innovantes et r√©silientes\nParticiper √† l'optimisation des co√ªts et des performances des solutions cloud\nüí™\nCe que Vous Apportez :\nExp√©rience solide dans le d√©ploiement et la gestion d'infrastructures sur GCP\nMa√Ætrise des outils de d√©ploiement et d'orchestration (ex : Kubernetes, Terraform)\nComp√©tences en scripting et automatisation (ex : Bash, Python)\nPassion pour la r√©solution de probl√®mes complexes et l'am√©lioration continue\nüéâ\nCe que Nous Offrons :\nL'opportunit√© de travailler avec des technologies de pointe dans un environnement agile et collaboratif\nDes formations et des opportunit√©s de d√©veloppement professionnel pour stimuler votre croissance\nüöÄ\nPr√™t(e) √† D√©coller vers de Nouveaux Horizons ? Postulez d√®s Maintenant !\nRejoignez-nous pour repousser les limites du cloud et faire de grandes choses ensemble chez Devoteam GCloud ! üåàüöÄ\nLe Groupe Devoteam oeuvre pour l'√©galit√© des chances, pour la promotion de ses collaboratrices et de ses collaborateurs au m√©rite et lutte activement contre toute forme de discrimination. Nous sommes persuad√©s que la diversit√© contribue √† la cr√©ativit√©, au dynamisme et √† l'excellence de notre organisation.\nTous nos postes sont ouverts aux personnes en situation de handicap\nShow more\nShow less",
        "details": {
            "JobDetail": [],
            "TypeContract": "",
            "Salary": "",
            "Level": "",
            "Experience": null
        },
        "title": "devops",
        "skills": {
            "ProgLanguage": [
                "Bash",
                "Python"
            ],
            "CloudComputing": [
                "GCP",
                "Google Cloud Platform"
            ],
            "Automation": [
                "Kubernetes"
            ],
            "InfrastructureAsCode": [
                "Terraform"
            ],
            "Containers": [
                "Kubernetes"
            ],
            "Other": [
                "Cloud",
                "DevOps"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "Descartes Underwriting",
        "location": "Paris, √éle-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/devops-engineer-cdi-at-descartes-underwriting-3767096933?position=42&pageNum=0&refId=NuDbZkBPOnBALTaaBOYlpw%3D%3D&trackingId=DrgcVcpX%2FuFOTGZeeowtgg%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "About Descartes Underwriting\nDescartes was born out of the conviction that the ever-increasing complexity of risks faced by corporations, governments and vulnerable communities calls for a renewed approach in insurance. Our team brings together industry veterans from the most renowned institutions (AXA, SCOR, Swiss Re, Marsh, Aon, ...) and scientists on top of their field to bring underwriting excellence. After 5 years of existence, Descartes has secured a leading position in parametric insurance for weather and climate-related risks utilizing machine learning, real-time monitoring from satellite imagery & IoT. After a successful Series B raise of $120M USD, we launched Descartes Insurance, a 'full stack' insurer licensed to underwrite risk by the French regulator ACPR. With a growing corporate client base (350+ and counting), our diverse team is headquartered in Paris and operates out of our 13 global offices in North America, Europe, Australia, Singapore, Hong Kong and Japan. Descartes is trusted by a panel of A-rated (re)insurers to carry out its activities.\nAbout Your Role\nDue to our consistent growth, we are seeking to expand our Data, Software and DevOps team.\nAt the core of our company, as a\nDevOps Engineer\nyour main assignments will be to make direct contributions to the CI/CD and setup cloud resources to release, deploy, maintain and run our climate risk models. You will also have to provide support to data scientists and software engineers running and developing our models. Your secondary mission will be to connect the external tools to automate the flow of information between the tech and business side.\nüîî\nKEY MISSIONS\nüîî\nSetup, automate, maintain and update:\nCI/CD pipelines;\nData storage process;\nPackage versioning and releasing pipeline;\nDocker environment;\nModularization of code base.\nVM and compute instances:\nConnections to external and internal APIs;\nNotification process with chat tools;\nWebsite hosting;\nAssess and evaluate the cost and the security of software architecture and implementation.\nParticipate in:\nTech stack selection;\nDiscussions with tech partners;\nTraining of tech and underwriting teams;\nSupport and debug of internal users;\nManagement of IAM policies, groups and users.\nTECH STACK\nüñ•\nÔ∏è\nCloud provider: GCP\nCode versioning tool: Git + Gitlab\nOS: Linux\nContainer: Docker\nContainer orchestrator: Kubernetes\nInfrastructure as code tool: terraform\nScripting: bash\nCode base: Python\nNotification tool: Slack\nAbout You\nEXPERIENCE & QUALIFICATIONS\n‚Äç\nüíª\n‚Äç\nüíª\n[Hard skills]\nKnowledge of the tech stack and demonstrated proficiency in production environments;\nExperience with Docker;\nExperience automating a CI/CD pipeline;\nFluent in English and in French;\n[Soft skills]\nDesire to train junior developers and explain CI/CD and cloud tool;\nContribute to a rigorous data engineering culture;\nExcellent communication skills, in both formal and informal settings, and in English and French.\n[Nice-to-have]\nExperience releasing python package;\nExperience working on data science projects or scientific code;\nExperience in HPC;\nContribution to an open source project.\nMINDSET\nüí•\nStrong interest in climate issues (it‚Äôs not a hoax, many people suffer from it)\nBeing comfortable to work alongside corporate insurers (some still wear suits üëî)\nWillingness to help junior developers (remember how you were when you started üí¨)\nStrong team spirit and ability to work (you‚Äôll have to review code and have your code reviewed)\nRigorous, creative and meticulous mind (we handle large insurance, we take our time)\nStrong desire to learn (there‚Äôs no limitation to the tech used, we‚Äôre happy to test and learn new tools)\nEagerness to work in a multi-cultural environment (policies and teams are from all around the world üó∫Ô∏è)\nWHY JOIN DESCARTES UNDERWRITING?\nOpportunity to work and learn with teams from the most prestigious schools and research labs in the world, allowing you to progress towards technical excellence;\nCommitment from Descartes to its staff of continued learning and development (think annual seminars, training etc.) ;\nWork in a collaborative & professional environment ;\nBe part of an international team, passionate about diversity ;\nJoin a company with a true purpose ‚Äì help us help our clients be more resilient towards climate risks;\nA competitive salary, bonus and benefits;\nYou can benefit from a punctual home office days.\nAt Descartes Underwriting, we cherish value of diversity whatever it may be. We are committed to fighting against all forms of discrimination and for equal opportunities. We foster an inclusive work environment that respects all differences.\nWith equal skills, all our positions are open to people with disabilities.\nRECRUITMENT PROCESS\nStep 1: Call and HR Interview with our Talent Recruiter\nStep 2: Technical project submitted via GitHub\nStep 3: Technical interview\nStep 4: Manager interview\nStep 5: Final round interview with the team (Candidates can opt to have the manager interview before the technical project and interview)\nShow more\nShow less",
        "details": {
            "JobDetail": [
                "Full",
                "Junior"
            ],
            "TypeContract": "",
            "Salary": "1, 1",
            "Level": "",
            "Experience": null
        },
        "title": "devops",
        "skills": {
            "ProgLanguage": [
                "Bash",
                "Python"
            ],
            "CloudComputing": [
                "GCP"
            ],
            "DevTools": [
                "Git",
                "Docker"
            ],
            "OS": [
                "Linux"
            ],
            "Automation": [
                "Kubernetes"
            ],
            "InfrastructureAsCode": [
                "Terraform"
            ],
            "Containers": [
                "Docker",
                "Kubernetes"
            ],
            "Collaboration": [
                "Slack",
                "Teams"
            ],
            "Other": [
                "Machine Learning",
                "Cloud",
                "DevOps",
                "CI/CD"
            ],
            "EnSoftSkils": [
                "Communication"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "Mobiskill | WEFY Group",
        "location": "Paris, √éle-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/devops-engineer-futur-head-of-infra-at-mobiskill-wefy-group-3918169619?position=43&pageNum=0&refId=NuDbZkBPOnBALTaaBOYlpw%3D%3D&trackingId=Y%2FtTYtuBXVol6kfgyuP%2Fzw%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Context :\nTheir ambitions ? To develop a no-code tool for financial operators based on blockchain. The problems are diverse, and the project is less than two years old.\nYou'll be joining a team of 10 people and will be one of the company's first DevOps Engineer.\nAre you looking for a job with big challenges and prospects for rapid advancement to Head of Infra ? Then you'll want to read on !\nYour Responsibilities :\nAs the first DevOps Engineer you will be responsible for implementing the infrastructure and ensuring that the DevOps culture is respected internally\nScale our infrastructure globally (GCloud, K8S, postgresql, terraform)\nManage the relationship with providers in multiple countries\nBe responsible for the uptime of the platform\nRecruit and manage a team of SREs and backend developers\nArchitecture the monitoring and data stack\nContribute to the overall development of Metal Gear, regardless of roles and responsibilities\nYour profile :\nYou have at least 3 years' significant experience as a DevOps\nYou are sensitive to security issues, ideally you are interested in blockchain and/or have initial experience in the fintech sector\nYou are fluent in English (read, written and spoken), French is optional\nYou are autonomous and rigorous\nYou are quality-focused, with a perfectionist mindset\nYou are experienced with modern development concepts: CI/CD, automated testing, agile methodologies\nBonus point :\nYou have an appetite for blockchain-related issues, particularly security-related issues\nAn experience working on SaaS infrastructure products\nWhy should you join them ?\nThe opportunity to move up to Head of Infra and recruit your own team at term\nAn attractive package : fix + BSPCE)\nYou will be taking part in a project that makes sense, with the aim of making certain financial services accessible to everyone, even on the other side of the world.\nYou'll be working in an international environment\nYou'll be joining a young, dynamic company where you'll have a direct and significant impact on its development, as well as on the product itself.\nYou'll be joining a team of passionate people !\nOffices right in the centre of Paris (1 remote day per week)\nShow more\nShow less",
        "details": {
            "JobDetail": [
                "Remote"
            ],
            "TypeContract": "",
            "Salary": "1",
            "Level": "",
            "Experience": null
        },
        "title": "devops",
        "skills": {
            "DBMS": [
                "PostgreSQL"
            ],
            "InfrastructureAsCode": [
                "Terraform"
            ],
            "Other": [
                "DevOps",
                "CI/CD"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "Harnham",
        "location": "Paris, √éle-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/devops-engineer-at-harnham-3869587731?position=44&pageNum=0&refId=NuDbZkBPOnBALTaaBOYlpw%3D%3D&trackingId=y7r4bNZgzTJNxoka97KD0g%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Devops engineer GCP\nMinimum 2 ans d'esp√©rience\n2j TT\nParis\nUP to 55K‚Ç¨\nCDI\nNous recherchons pour l'un de nos clients, une startup dynamique en pleine croissance, sp√©cialis√©e dans le domaine de la technologie et de l'innovation.\nDescription du Poste :\nVous serez responsable de la mise en place et de la gestion de nos infrastructures cloud sur Google Cloud Platform (GCP), ainsi que du d√©ploiement et de la maintenance de nos applications.\nResponsabilit√©s :\nConcevoir, mettre en ≈ìuvre et maintenir des pipelines CI/CD robustes.\nAutomatiser les t√¢ches de d√©ploiement, de gestion et de surveillance des syst√®mes.\nCollaborer avec les √©quipes de d√©veloppement pour garantir des environnements de d√©veloppement, de test et de production efficaces.\nG√©rer les incidents et garantir la disponibilit√© et la fiabilit√© des syst√®mes.\nOptimiser les performances et la scalabilit√© de notre infrastructure.\nComp√©tences Requises :\nExp√©rience pratique dans un r√¥le de DevOps, avec au moins 2 ans d'exp√©rience.\nMa√Ætrise des services et des outils de Google Cloud Platform (GCP).\nSolides comp√©tences en automatisation avec des outils tels que Terraform, Ansible ou √©quivalents.\nBonne connaissance des pipelines CI/CD, des conteneurs (Docker) et des orchestrateurs (Kubernetes).\nExcellentes comp√©tences en r√©solution de probl√®mes et en communication.\nAvantages :\nRejoignez une √©quipe passionn√©e dans un environnement stimulant et innovant.\nOpportunit√© de travailler sur des projets technologiquement avanc√©s.\nShow more\nShow less",
        "details": {
            "JobDetail": [],
            "TypeContract": "CDI",
            "Salary": "",
            "Level": "",
            "Experience": "2 an(s)"
        },
        "title": "devops",
        "skills": {
            "CloudComputing": [
                "GCP",
                "Google Cloud Platform"
            ],
            "DevTools": [
                "Docker"
            ],
            "Automation": [
                "Kubernetes",
                "Ansible"
            ],
            "InfrastructureAsCode": [
                "Terraform"
            ],
            "Containers": [
                "Docker",
                "Kubernetes"
            ],
            "Other": [
                "Cloud",
                "DevOps",
                "CI/CD"
            ],
            "EnSoftSkils": [
                "Communication"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "AXA Group Operations",
        "location": "Paris, √éle-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/devops-azure-platform-engineer-at-axa-group-operations-3887945584?position=45&pageNum=0&refId=NuDbZkBPOnBALTaaBOYlpw%3D%3D&trackingId=VkaNBVA%2B%2BZzpguP6Pq8ZKg%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Job purpose\nOur department is committed to offering to our customer entities cloud-based solutions that run with the expected performance and robustness, while being efficient and cost-effective.\nThe AXA GO product ‚ÄòRisk Projection Engine - Sunrise‚Äô is an actuarial platform for dynamic financial analysis\n(DFA) based on models and using stochastic projections for predictions on Solvency 2, IFRS17, ALM and Internal Model Review and it‚Äôs widely used at AXA.\nThe Risk Projection Engine - Sunrise Product runs in Azure Cloud environment and it‚Äôs supported by a team of 6 specialists spread between France and Portugal GO offices. The purpose of this position is to lead the Azure Platform Engineers team and drive the cloud strategy for RPE Sunrise.\nMain mission\nYour responsibilities include:\nLead the Azure Platform Engineer team using Agile practices to ensure communication, work distributions and knowledge sharing.\nSupport the definition and implementation of RPE-Sunrise Azure strategy deploying scalable, reliable, and highly available infrastructure solutions in Azure.\nMonitor and optimize Azure performance and cost.\nWork with the security team to ensure that Azure resources are configured securely and are compliant with applicable AXA security standards and regulations.\nAutomate infrastructure deployment and configuration processes to increase efficiency, consistency, and reliability.\nTroubleshoot and resolve issues related to Azure infrastructure, working with other IT teams as Network and Cloud Broker to resolve issues quickly.\nExperience and Technical skills\nExpertise in using Azure DevOps and related tools such as Visual Studio, Git, Jenkins, and Docker.\nKnowledge of continuous integration (CI) and continuous delivery/deployment (CD) concepts and methodologies.\nExperience with Microsoft Azure cloud computing platforms.\nExperience on Azure managed services (SQL Server, PostgreSQL, Azure Storage Account, ...).\nExperience on Azure network and security components (build and run): VNet, Network Security Group, Monitoring of resources and the best practices surrounding them.\nMastery of Azure resource monitoring tool (OMS).\nExperience on best practices in terms of architecture design (AD, Storage, Managed services, etc.)\nExperience on the Kubernetes Ecosystem (Node, Pod, Ingress, ConfigMap, FleexVolume, Services, NetworkPolicy, CertManager, ...).\nExperience on automation of deployment of architectures and configurations (PowerShell, Python, JSON, ARM, YAML, HELM, Terraform).\nStrong understanding of software development processes, including Agile and DevOps methodologies.\nSolid understanding of software development lifecycles and Agile methodologies.\nA bachelor's or master's degree in computer science, information technology, or a related field.\nSoft skills / transversal skills\nProblem solving mindset\nStakeholder management\nCommunication and collaboration skills, adaptive to different levels of the organization, from executive forums to technical teams\nAutonomy and self-drive, but also teamwork and leadership\nAnalytical thinking, attention to detail, and problem-solving\nEnglish proficiency\nShow more\nShow less",
        "details": {
            "JobDetail": [],
            "TypeContract": "",
            "Salary": "",
            "Level": "",
            "Experience": null
        },
        "title": "devops",
        "skills": {
            "ProgLanguage": [
                "Python"
            ],
            "DataBase": [
                "SQL"
            ],
            "DataSerialization": [
                "Json"
            ],
            "CloudComputing": [
                "Azure"
            ],
            "DevTools": [
                "Git",
                "Docker",
                "Jenkins"
            ],
            "DBMS": [
                "PostgreSQL",
                "SQL Server"
            ],
            "Automation": [
                "Kubernetes"
            ],
            "InfrastructureAsCode": [
                "Terraform"
            ],
            "Containers": [
                "Docker",
                "Kubernetes"
            ],
            "Collaboration": [
                "Teams"
            ],
            "Other": [
                "Cloud",
                "DevOps"
            ],
            "EnSoftSkils": [
                "Organization",
                "Teamwork",
                "Leadership",
                "Collaboration",
                "Problem Solving",
                "Communication"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "ATLANSE",
        "location": "Issy-les-Moulineaux, √éle-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/data-engineer-devops-at-atlanse-3918368657?position=46&pageNum=0&refId=NuDbZkBPOnBALTaaBOYlpw%3D%3D&trackingId=rOXvbQkkw5nEHzGIwYBf2w%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Vous interviendrez au sein de l‚Äô√©quipe Analytics et contribuerez au d√©veloppement de la plateforme DataHub, dans un environnement international.\nMissions :\nAnalyser les besoins aupr√®s des utilisateurs de Datahub (m√©tiers, √©quipes IT, process...), formalisation des √©changes, des process et d√©veloppements √† effectuer\nActivit√©s DevOps pour les applications Datahub :\nEffectuer les d√©ploiements et mises √† jour d‚Äôapplications sur clusters Kubernetes\nAssurer la customisation et les param√©trages avanc√©s d‚Äôapplications open-sources\nParticiper √† l‚Äôam√©lioration continue de la stabilit√© des applications\nR√©aliser le monitoring des applications\nVeiller √† la r√©alisation et au suivi des sujets d‚Äôarchitecture IT avec des sp√©cialistes architecture IT (r√©seau, cluster Kuberneters, bases de donn√©es relationnelles, containers, usage des ressources de calculs)\nR√©aliser les d√©veloppements :\nAutomatisation de t√¢ches planifi√©es (rafraichissements de donn√©es, calculs de KPI, op√©rations techniques‚Ä¶) avec Python\nTraitement de donn√©es Parquet (modifications des donn√©es et sch√©mas) avec pyArrow, pySpark ou polars\nRequ√™tes Adhoc, qualit√© de donn√©es, mod√©lisation et r√©alisation de d√©veloppements SQL complexes (Ex : datasets pour rapports BI), performance tuning\nShow more\nShow less",
        "details": {
            "JobDetail": [],
            "TypeContract": "",
            "Salary": "",
            "Level": "",
            "Experience": null
        },
        "title": "data engineer",
        "skills": {
            "ProgLanguage": [
                "Python"
            ],
            "DataBase": [
                "SQL"
            ],
            "Automation": [
                "Kubernetes"
            ],
            "Containers": [
                "Kubernetes"
            ],
            "Other": [
                "DevOps"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "STATION F",
        "location": "Paris, √éle-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/devops-cloud-engineer-with-it-experience-at-station-f-3918620381?position=47&pageNum=0&refId=NuDbZkBPOnBALTaaBOYlpw%3D%3D&trackingId=QpjU8S3H2TvNbfqnYakz3Q%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "About\nWhiteLab Genomics est une soci√©t√© dynamique, en pleine croissance et engag√©e pour acc√©l√©rer la d√©couverte et le d√©veloppement des th√©rapies g√©nomiques gr√¢ce √† l'intelligence artificielle en aidant nos partenaires √† gu√©rir davantage de maladies √† un co√ªt abordable.\nIls d√©veloppent et ils op√®rent une plateforme d‚Äôintelligence artificielle unique afin d‚Äôacc√©l√©rer le d√©veloppement des th√©rapies g√©nomiques, bas√©es sur l‚ÄôADN et/ou l‚ÄôARN, une nouvelle g√©n√©ration de traitements adressant un large panel de pathologies allant des maladies neurod√©g√©n√©ratives jusqu‚Äôaux cancers. Les approches d‚ÄôIA associ√©es √† de grands jeux de donn√©es multi-omiques permettent de d√©couvrir de nouvelles th√©rapies et d‚Äôen simuler les effets pour optimiser leur design.\nJob Description\nWhiteLab Genomics\nwas founded with the belief that life-saving drugs should be accessible to all patients in need. United in our vision, we‚Äôve become a part of Y Combinator, French Tech 2030, Future 40 by Station F, and we‚Äôve been recognized by The Galien Foundation (‚ÄùBest Startup‚Äù category), among other institutions at the forefront of technology. Today, we strive to become the leading expert in A.I. for genomic medicine, operating as the go-to partner for research and development.\nIn this critical and multifaceted role\n, you will lead the maintenance, development, and fortification of our AI/IT infrastructure for genomic medicine. We‚Äôre in the process of setting up and scaling our Cloud infrastructure, and you‚Äôll play a valuable role in helping us scale up, leading the charge in optimizing our cloud services, streamlining workflows, and ensuring seamless integration with our DevOps practices and automation frameworks. To scale our current architecture to a higher level, you will help us identify our current bottlenecks, propose new Cloud based solutions, implement them, and help users to use them, allowing for enhanced efficiency. Fostering an atmosphere of productivity and teamwork, your expertise will drive our mission towards greater technological excellence and innovation.\nThis is an\nincredible opportunity\nto work on a diversity of engaging tasks in a hybrid role, forming the infrastructure of a vibrant start-up that seeks to make an impact on the future of healthcare ‚Äì- you'll play a crucial role in helping revolutionize genomic medicine with AI.\nOur Core Values\nWe Believe that Care is Everything.\nWe Value our Collective Potential\nWe Cultivate Proactive Communication, Clarity and Respect\nWe Have a Can-Do Attitude\nWe Strive for Excellence\nPreferred Experience\nWe‚Äôre Eager to Meet You If‚Ä¶\nYou're proficient in DevOps methodologies and tools, including proven experience in implementing robust continuous integration, continuous deployment (CI/CD) pipelines, infrastructure as code (IaC), and automated testing frameworks\nYou have demonstrated experience with coding (preferably Python) for automation tasks and infrastructure management and team interactions for orchestration tasks\nYou have expertise in cloud services (AWS, Azure, or Google Cloud), with a track record of designing, deploying, and managing scalable cloud-based infrastructure solutions tailored to business needs. Your comprehensive understanding of cloud services will enable seamless integration with DevOps practices and automation workflows\nYou have at least 1 year of prior hands-on experience in managing IT equipment, tools, and issues at a tech company (preferably a tech start-up) and excel in administering SharePoint and email systems, ensuring smooth operations and user support\nYou possess great problem solving ability and can work autonomously\nYou have expertise in hardware, software, and network systems\nYou can manage pipelines, optimizing workflows for efficient deployment and delivery\nYour interpersonal skills allow you to collaborate effectively with cross-functional teams, including researchers, data scientists, business development professionals, and support functions\nYou can adapt to a dynamic and rapidly evolving industry, staying on top of the latest IT advancements\nYou have excellent verbal and written communication skills and have experience interfacing with stakeholders and users in English - French proficiency is a plus!\nYou‚Äôre knowledgeable of standard practices for access control models, data protection regulations, IT security, and compliance protocols\nHere‚Äôs How You‚Äôll Make An Impact‚Ä¶\nYou‚Äôll provide strategic and technical leadership to all of our teams, guiding the development and implementation of innovative solutions towards orchestration, CI/CD and security standards\nYou‚Äôll set up and manage CI/CD pipelines to automate processes\nYou‚Äôll write automation scripts to automate routine orchestration tasks and manage our infrastructure efficiently\nYou‚Äôll design, deploy, and manage scalable cloud-based infrastructure solutions\nYou‚Äôll integrate cloud services with DevOps practices and automation workflows\nYou‚Äôll oversee the operation and maintenance of IT tools and infrastructure, ensuring reliability, performance, and security\nYou‚Äôll manage user roles, permissions, and access control for Cloud services, SharePoint, and email systems in compliance with data protection regulations\nYou‚Äôll administer and optimize SharePoint and other collaboration tools to enhance team productivity\nYou‚Äôll ensure all technology systems and platforms operate reliably and efficiently\nYou‚Äôll implement and maintain security policies and procedures, conducting regular audits to ensure compliance with industry standards\nYou‚Äôll provide technical support, resolving issues related to hardware, software, network problems, systems, and access permissions\nYou‚Äôll manage and maintain all IT equipment and tools, ensuring they‚Äôre up to date and in good working condition\nYou‚Äôll lead Cloud and Helpdesk projects from inception to completion, ensuring projects are delivered on time, within budget, and meet quality standards\nYou‚Äôll implement best practices in IT operations and cybersecurity to safeguard company data and systems\nAdditional Information\nContract Type: Full-Time\nStart Date: 24 June 2024\nLocation: Paris\nExperience: > 1 year\nPossible partial remote\nShow more\nShow less",
        "details": {
            "JobDetail": [
                "Remote",
                "Full"
            ],
            "TypeContract": "",
            "Salary": "",
            "Level": "",
            "Experience": null
        },
        "title": "devops",
        "skills": {
            "ProgLanguage": [
                "Python"
            ],
            "CloudComputing": [
                "AWS",
                "Azure"
            ],
            "Collaboration": [
                "Teams"
            ],
            "Other": [
                "Cloud",
                "DevOps",
                "CI/CD"
            ],
            "EnSoftSkils": [
                "Teamwork",
                "Leadership",
                "Collaboration",
                "Problem Solving",
                "Interpersonal Skills",
                "Communication"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "Inetum",
        "location": "Courbevoie, √éle-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/data-engineer-devops-h-f-at-inetum-3843956952?position=48&pageNum=0&refId=NuDbZkBPOnBALTaaBOYlpw%3D%3D&trackingId=Sn4Hl2dBAtfOzY6bsphgkA%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "D√©tail de l'offre\nInformations g√©n√©rales\nEntit√© de rattachement\nNous sommes une ESN agile, un groupe international certifi√© Top Employer Europe 2024.\nA l'√®re de la post-transformation digitale, nous mettons tout en ≈ìuvre pour que chacun de nos 28 000 athl√®tes du digital puisse se renouveler perp√©tuellement, en vivant positivement son propre flow digital.\nChacun de nos talents peut ainsi fa√ßonner son parcours de carri√®re selon ses app√©tences, entreprendre de mani√®re pragmatique avec ses clients pour un monde √† impact positif, innover localement dans 27 pays et harmoniser son investissement professionnel et son bien-√™tre personnel.\nRejoignez Inetum. Live your positive digital flow.\nTous nos postes sont ouverts aux personnes en situation de handicap.\nDescription du poste\nM√©tier\nConseil et Int√©gration - Business Consulting\nIntitul√© du poste\nData Engineer DevOps H/F\nContrat\nCDI\nDescription De La Mission\nQui sommes-nous ?\nNous sommes une ESN agile et un groupe international. A l'√®re de la post-transformation digitale, nous mettons tout en ≈ìuvre pour que chacun de nos 27 000 collaborateurs puisse se renouveler perp√©tuellement, en vivant positivement son propre flow digital. Chacun d'entre eux peut ainsi fa√ßonner son parcours de carri√®re selon ses app√©tences, entreprendre de mani√®re pragmatique avec ses clients pour un monde plus positif, innover localement dans 26 pays et harmoniser son investissement professionnel et son bien-√™tre personnel.\nRejoignez\nCapital Market, entit√© Inetum en Finance de March√©\n. Nous accompagnons les acteurs majeurs du secteur de la finance en France et √† l‚ÄôInternational.\nCultivant la double comp√©tence technique et fonctionnelle, nous intervenons sur des projets innovants √† haute valeur ajout√©e.\nQuelles sont nos valeurs ?\nüèÜ Excellence Notre culture de l‚Äôexcellence na√Æt de notre audace.\nü§ù Engagement S‚Äôassocier et grandir ensemble !\nüõ∞ Innovation Nos FabLab au service de la transformation digitale de nos clients.\nMissions propos√©es\nPour accompagner notre forte croissance, nous recherchons des\nData Engineer DevOps\npour le compte d‚Äôun acteur majeur de la finance de march√© en Europe et dans le monde. Dans ce contexte international et exigeant, vous travaillez sur la conception de solutions Big Data afin de r√©pondre aux besoins des op√©rationnels m√©tiers.\nPour mener √† bien ce projet, vous aurez pour responsabilit√©s de\nComprendre les enjeux des √©quipes Data et les accompagner. Faire le lien entre les environnements (datalake, datawarehouse et environnement de d√©ploiement du mod√®le) gr√¢ce √† des pipelines sophistiqu√©s\n√ätre r√©f√©rent et garant des bonnes pratiques pour le d√©veloppement des langages utilis√©s par l'√©quipe. Accompagner les Data Scientists dans l'optimisation de leurs algorithmes\nAssurer la viabilit√© des solutions de datamining et de machine learning de l'√©quipe Data et les mettre en production.Construire et optimiser des pipelines de donn√©es complexes (ETL et ELT)\nCoordonner le d√©veloppement et les op√©rations gr√¢ce √† l‚Äôautomatisation des flux de travail, la cr√©ation de services Web pr√©dictifs.\nD√©ployez ces mod√®les en utilisant les derni√®res techniques et pratiques (API REST, Docker, Tensorflow Serving, etc.)\nAnalyser et r√©soudre les anomalies li√©es aux performances et √† l‚Äô√©volutivit√© des solutions Cloud BI et Big Data\nProfil\nProfil souhait√©\nDe formation Ing√©nieur Grande Ecole ou √©quivalent, vous poss√©dez une premi√®re exp√©rience r√©ussite de trois ans minimum sur un poste √©quivalent id√©alement en banque d‚Äôinvestissement ou asset management.\nVous √™tes familier avec l‚Äôenvironnement Big Data (data grids, compute grids, REST based architectures, SGBDR, No-SQL Databases, GPUs)\nVous avez d√©j√† travaill√© avec la m√©thodologie Agile\nUne certaine aisance technique est √©galement requise (Jenkins, Docker, Ansible, Git, Scala, Kubernetes, Python/Java, Maven)\nUne double comp√©tence Cloud (AWS, Google Cloud, Azure) serait un v√©ritable plus\nEvoluant dans un contexte international, la ma√Ætrise de l'Anglais est n√©cessaire.\nL‚Äôaisance relationnelle, de l‚Äôautonomie, la gestion des priorit√©s, des capacit√©s d‚Äôanalyse et de synth√®se, ‚Ä¶ le savoir-√™tre est une composante importante dans notre processus de recrutement.\nTous nos postes sont ouverts aux personnes en situation de handicap.\nEt pourquoi Inetum Capital Market ?\nüòÑ Des missions int√©ressantes\nü§© Des perspectives d'√©volutions professionnelles et financi√®res\nüòé Les avantages d'un grand groupe international\nüòâ Un suivi r√©gulier\n‚úàÔ∏è Une aide √† la mobilit√© g√©ographique que vous soyez localis√© en France ou √† l'√©tranger\nüë®‚Äçüéì Des formations certifiantes\nü•≥ Des moments de FUN !\nLocalisation du poste\nLocalisation du poste\nFrance, Ile-de-France, 75 Paris\nVille\nCourbevoie\nCrit√®res candidat\nNiveau d'√©tudes min. requis\nBac+5\nNiveau d'exp√©rience min. requis\nPlus de 2 ans\nShow more\nShow less",
        "details": {
            "JobDetail": [],
            "TypeContract": "CDI",
            "Salary": "",
            "Level": "Bac+5",
            "Experience": "2 an(s)"
        },
        "title": "data engineer",
        "skills": {
            "ProgLanguage": [
                "Java",
                "Scala",
                "Python"
            ],
            "DataBase": [
                "SQL"
            ],
            "MachineLearning": [
                "TensorFlow"
            ],
            "CloudComputing": [
                "AWS",
                "Azure"
            ],
            "DevTools": [
                "Git",
                "Docker",
                "Jenkins"
            ],
            "Automation": [
                "Kubernetes",
                "Ansible"
            ],
            "Containers": [
                "Docker",
                "Kubernetes"
            ],
            "Other": [
                "Machine Learning",
                "Cloud",
                "Big Data",
                "DevOps"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "Licorne Society",
        "location": "Paris, √éle-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/devops-cloud-infrastructure-engineer-%40-start-up-at-licorne-society-3918088091?position=49&pageNum=0&refId=NuDbZkBPOnBALTaaBOYlpw%3D%3D&trackingId=zBNVGytNUyFdX%2B0ViHpbzg%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Licorne Society est √† la recherche de DevOps - Cloud Infrastructure Engineer pour des startups innovantes, ne laisse pas passer ta chance !\nC‚Äôest quoi Licorne Society ?\nLicorne Society est le seul outil qui te met en relation avec plus de 3000 startups recrutant en France, tous secteurs et m√©tiers confondus. Qu‚Äôelles soient en cr√©ation ou en phase d‚Äôhypercroissance, toutes les startups t‚Äôattendent sur Licorne Society. Ah oui, et c‚Äôest gratuit !\nNotre promesse : faire matcher ta recherche avec les meilleures opportunit√©s et mettre en avant ton profil aupr√®s des startups qui recrutent.\n>> www.licornesociety.com <<\nL'inscription Prend Moins De 10 Minutes. Tu Pourras Alors Acc√©der √† L'ensemble Des Offres En Startup Du March√© Et √ätre Contact√© Directement Par Les Recruteurs\n1 - Remplis ton profil et tes attentes.\n2 - Passe en revue les offres que nous te proposons en fonction de tes crit√®res de recherche et re√ßois une notification √† chaque nouvelle offre publi√©e. Avec notre mode Tinder, tu n‚Äôas qu‚Äô√† swiper les offres. Matcher avec le job de tes r√™ves n‚Äôa jamais √©t√© aussi simple !\n3 - Re√ßois des sollicitations directes pour des postes de DevOps - Cloud Infrastructure Engineer au sein de nos startups pr√©f√©r√©es (pour ne citer que BackMarket, PlayPlay, Payfit, Trustpair ou encore Choco)\nProfil Recherch√©\nTu as une premi√®re exp√©rience de DevOps - Cloud Infrastructure Engineer et tu es tr√®s motiv√© pour rejoindre une start-up / scale-up ou tu es pr√™t √† d√©crocher ton tout premier job\nTu as la fibre entrepreneuriale\nTu as soif de challenge et de nouveaux apprentissages\nTu es pr√™t √† cliquer sur le lien d‚Äôinscription : www.licornesociety.com\nLes parcours particuli√®rement valoris√©s chez Licorne Society :\ndes exemples de prises d‚Äôinitiatives ou projets men√©s avec l‚Äôesprit entrepreneurial\ndes exp√©riences dans des environnements particuli√®rement exigeants\ndes exemples de r√©alisations √©difiants ou r√©sultats chiffr√©s\nOn se dit √† tout de suite sur la plateforme ?\n>> www.licornesociety.com <<\nShow more\nShow less",
        "details": {
            "JobDetail": [],
            "TypeContract": "",
            "Salary": "",
            "Level": "",
            "Experience": null
        },
        "title": "devops",
        "skills": {
            "Other": [
                "Cloud",
                "DevOps"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "Thales",
        "location": "V√©lizy-Villacoublay, √éle-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/ing%C3%A9nieur-devops-sre-f-h-at-thales-3899044592?position=50&pageNum=0&refId=NuDbZkBPOnBALTaaBOYlpw%3D%3D&trackingId=ji3b0VY2ITNHhoK3uraI8A%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "QUI SOMMES-NOUS ?\nThales propose des syst√®mes d‚Äôinformation et de communication s√©curis√©s et interop√©rables pour les forces arm√©es, les forces de s√©curit√© et les op√©rateurs d‚Äôimportance vitale. Ces activit√©s, qui regroupent radiocommunications, r√©seaux, syst√®mes de protection, syst√®mes d‚Äôinformation critiques et cybers√©curit√©, r√©pondent aux besoins de march√©s o√π l‚Äôutilisation des nouvelles technologies num√©riques est d√©terminante. Thales intervient tout au long de la cha√Æne de valeur, des √©quipements aux syst√®mes en passant par le soutien logistique et les services associ√©s.\nPour r√©pondre √† ces nouveaux enjeux et aux demandes croissantes de solutions innovantes et de technologies √©mergentes, comp√©titives, et souvent complexes ; nous nous sommes dot√©s de collaborateurs qui vivent la culture Cloud et DevOps et sont form√©s aux concepts X As Code (Infra As Code, Security As Code, Network As Code, ‚Ä¶) m√™lant une forte culture du d√©veloppement logiciel aux probl√©matiques de d√©ploiement continu et aux contraintes de production.\nLe Centre de Comp√©tence Software Factory & Cloud constitu√© de plus de 500 personnes est sp√©cialis√© dans l‚Äôint√©gration et la s√©curisation de logiciels OpenSource, le d√©veloppement applicatif Cloud-natif, les architectures micro-services, la containerisation autour de Kubernetes, l‚Äôint√©gration et le d√©ploiement continu (CI/CD) et l‚Äôing√©nierie de fiabilit√© de site (SRE).\nQUI √äTES-VOUS ?\nIssu d‚Äôune formation Bac +5\n(√©cole d‚Äôing√©nieur, Master ou √©quivalent), Vous justifiez d‚Äôune\nexp√©rience de minimum 3 ans\nsur un poste similaire de\nConsultant\nDevops Cloud\n(H/F)\net vous ma√Ætrisez les points suivants :\nde la plateforme Azure dans son ensemble et de l‚Äô√©cosyst√®me associ√© : VNet/SubNet, VPN / ER, Azure FW, App Gateway, APIM, FD, AAD, etc\n(mod√®le de d√©ploiement Terraform et /ou ARM et/ou Bicep)\ndans Azure (Azure Policy, Azure Cost Management, etc)\net Exploitation Cloud Azure\ndu catalogue IaaS, PaaS sur Azure,\nPowerShell, Python\n(AZ-900, AZ-500, AZ-104, AZ-303, AZ-304) seraient un plus\nVous maitrisez l‚Äôanglais\n√† l‚Äôoral comme √† l‚Äô√©crit.\nVous avez une connaissance du secteur financier\net de ses m√©tiers (banque, assurance ou mutuelle).\nCE QUE NOUS POUVONS FAIRE ENSEMBLE :\nRegroup√©es en centres de comp√©tences logiciel, nos √©quipes participent √† des projets innovants et strat√©giques pour nos clients Grand Comptes dans des secteurs d‚Äôactivit√©s vari√©s (la D√©fense, de l‚ÄôEnergie, de la Cybers√©curit√© et de l‚ÄôA√©ronautique). Notre √©quipe du secteur\nBanque, Assurance, Mutuelle\nest √† la recherche d‚Äôun\nIng√©nieur DevOps/SRE\npour poursuivre leur croissance.\nActeurs majeurs bancaires en France, nos clients mettent en ≈ìuvre des programmes de transformation dans tous les m√©tiers bancaires afin d‚Äôoffrir une nouvelle exp√©rience √† leurs clients et leurs collaborateurs, d‚Äôacc√©l√©rer la digitalisation et √† am√©liorer l‚Äôefficacit√© op√©rationnelle, et ceci de fa√ßon responsable.\nL‚Äôutilisation de l‚ÄôIA, de la DATA, le d√©veloppement du cloud, la convergence des plateformes technologiques et le d√©ploiement de l‚ÄôAPIsation du syst√®me d‚Äôinformation sont au c≈ìur de leur mod√®le et donc de nos missions. Vous interviendrez sur des projets de modernisation du SI, de mutualisation et d‚Äôindustrialisation de solutions num√©riques innovantes.\nVos missions seront les suivantes :\nCr√©ation d‚Äôinfrastructures sur le Cloud Azure\nen utilisant Terraform (Infra As Code)\nAccompagnement des √©quipes de devs\nau quotidien dans une d√©marche DevOps / GitOps\nR√©soudre des incidents\nen investiguant sur les causes racines et en automatisant leur r√©solution au sein de la squad SRE (Site Reliability Engineer).\nMigrations Cloud et Kubernetes\nMise en place et automatisation de la cha√Æne de CI/CD\nProposer/participer √† des projets d‚Äôinnovation pour enrichir les offres cloud\nLe Poste requiert une forte app√©tence technique. L‚Äôaccompagnement consiste √©galement √† mettre en ≈ìuvre les solutions pr√©conis√©es.\nLa perspective de rejoindre un Groupe innovant vous motive ? Alors rejoignez-nous en postulant √† cette offre !\nInnovation, passion, ambition : rejoignez Thales et cr√©ez le monde de demain, d√®s aujourd‚Äôhui.\nShow more\nShow less",
        "details": {
            "JobDetail": [],
            "TypeContract": "",
            "Salary": "",
            "Level": "",
            "Experience": "3 an(s)"
        },
        "title": "devops",
        "skills": {
            "ProgLanguage": [
                "Python"
            ],
            "CloudComputing": [
                "Azure"
            ],
            "Automation": [
                "Kubernetes"
            ],
            "InfrastructureAsCode": [
                "Terraform"
            ],
            "NetworkSecurty": [
                "VPN"
            ],
            "Containers": [
                "Kubernetes"
            ],
            "Other": [
                "Cloud",
                "DevOps",
                "CI/CD"
            ],
            "EnSoftSkils": [
                "Communication"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "Extia",
        "location": "Paris, √éle-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/data-engineer-devops-h-f-at-extia-3599185622?position=51&pageNum=0&refId=NuDbZkBPOnBALTaaBOYlpw%3D%3D&trackingId=bOBdBmlIQJrRbgF6oSqKNQ%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Vous souhaitez rejoindre une entreprise qui place l‚Äôhumain au c≈ìur de ses pr√©occupations ? On vous attend chez\nExtia\n!\nSoci√©t√© de conseil sp√©cialis√©e dans les m√©tiers de l‚ÄôIT, de l‚Äôing√©nierie et du digital, Extia privil√©gie depuis sa cr√©ation en 2007 une approche qui allie performance et bien-√™tre au travail. Une vision de l‚Äôentreprise partag√©e aujourd‚Äôhui par plus de 2 500 Extiens en France et √† l'international et r√©compens√©e par le label Great Place to Work¬Æ depuis 13 ans, notamment en\n2024 o√π les Extiens se hissent √† la premi√®re place du palmar√®s Best Workplaces France\n!\nChez Extia, c‚Äôest ¬´ D‚Äôabord qui, ensuite quoi ¬ª alors, allons-y !\nD'abord qui\nCurieux, vous adorez partager les derni√®res id√©es innovantes que vous avez d√©couvertes\nRigoureux, vous ne laissez rien au hasard\nPers√©v√©rant, vous ne perdez jamais, soit vous gagnez, soit vous apprenez\nEnsuite quoi\nDans le cadre de votre mission, vos taches principales sont\n:\nL'impl√©mentation de solutions techniques\nSens de l‚Äô√©change avec les diff√©rents √©quipiers, contributeurs de la division Data.\n√âchanges et pr√©paration de demos avec les IT m√©tiers.\nMaintien d'une veille technologique permanente.\nLes comp√©tences techniques\n:\nAnalyse et d√©veloppement\nD√©veloppement en Java jusqu‚Äô√† l‚Äôint√©gration avec les chaines CI/CD\nMaitrise des langages de programmation Java, Scala et Python\nMa√Ætrise de Ansible, Terraform, Kubernetes...\nMa√Ætrise de l‚Äô√©cosyst√®me Hadoop, Spark, Kafka, ElasticSearch\nShow more\nShow less",
        "details": {
            "JobDetail": [],
            "TypeContract": "",
            "Salary": "",
            "Level": "",
            "Experience": "13 an(s)"
        },
        "title": "data engineer",
        "skills": {
            "ProgLanguage": [
                "Java",
                "Scala",
                "Python"
            ],
            "DataBase": [
                "Elasticsearch"
            ],
            "BigData": [
                "Hadoop",
                "Spark"
            ],
            "Automation": [
                "Kubernetes",
                "Ansible"
            ],
            "InfrastructureAsCode": [
                "Terraform"
            ],
            "Containers": [
                "Kubernetes"
            ],
            "Other": [
                "CI/CD"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "Glocomms",
        "location": "France",
        "link": "https://fr.linkedin.com/jobs/view/cloud-security-engineer-at-glocomms-3910052052?position=52&pageNum=0&refId=NuDbZkBPOnBALTaaBOYlpw%3D%3D&trackingId=pRj5n9hfB0wpf%2B0fh03Zpg%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Senior ServiceNow Consultant\nOffice Location : Toulouse\nFully remote\nEnglish and French speaking project\nContract : 2 year project on a 6 month rolling contract\nStart date: Monday 3rd June\nWe are seeking a skilled and experienced Cloud Security Engineer to join our customer's team. The ideal candidate will be responsible for designing, implementing, and maintaining security measures to protect our cloud-based infrastructure and applications. The Cloud Security Engineer will work closely with our DevOps and IT teams to ensure that our cloud environments meet the highest standards of security and compliance.\nResponsibilities:\nDesign and implement security measures to protect cloud-based infrastructure and applications.\nConduct regular security assessments and audits of cloud environments.\nDevelop and maintain security policies, standards, and procedures for cloud environments.\nImplement access controls, encryption, and other security features to protect data in the cloud.\nMonitor cloud environments for security incidents and respond to incidents in a timely manner.\nWork closely with DevOps and IT teams to integrate security best practices into cloud deployment pipelines.\nStay up-to-date on the latest trends and developments in cloud security and recommend new security technologies and techniques.\nCollaborate with internal teams and external vendors to resolve security issues and implement security solutions.\nRequirements:\nBachelor's degree in Computer Science, Information Security, or a related field.\n5+ years of experience working in cloud security or a related field.\nIn-depth knowledge of cloud platforms such as AWS, Azure, or Google Cloud Platform.\nExperience with cloud security technologies and tools, such as IAM, WAF, and SIEM.\nStrong understanding of networking and network security principles.\nExperience with scripting languages such as Python, PowerShell, or Bash.\nCertifications such as Certified Cloud Security Professional (CCSP), Certified Information Systems Security Professional (CISSP), or AWS Certified Security Specialty are a plus.\nExcellent communication and collaboration skills.\nShow more\nShow less",
        "details": {
            "JobDetail": [
                "Remote",
                "Full",
                "Senior"
            ],
            "TypeContract": "",
            "Salary": "",
            "Level": "",
            "Experience": null
        },
        "title": "cloud architect /engineer ",
        "skills": {
            "ProgLanguage": [
                "Bash",
                "Python"
            ],
            "CloudComputing": [
                "AWS",
                "Google Cloud Platform",
                "Azure"
            ],
            "Collaboration": [
                "Teams"
            ],
            "Other": [
                "Cloud",
                "DevOps"
            ],
            "EnSoftSkils": [
                "Communication",
                "Collaboration"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "Scaleway",
        "location": "France",
        "link": "https://fr.linkedin.com/jobs/view/devops-engineer-block-storage-at-scaleway-3918147786?position=53&pageNum=0&refId=NuDbZkBPOnBALTaaBOYlpw%3D%3D&trackingId=62wASrBEFl9kwKTkB5q1cw%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "About the job\nThe Storage Team is one of the pillars of Scaleway. This team not only develops the Scaleway Elements storage products (Block Storage), but also supports all the other Scaleway Elements products that rely on Block Storage (Instances, Database, Registry, Kubernetes, and more) for proper usage. In a challenging environment, and within a team that manages hundreds of storage servers across various regions, you will be responsible for developing, automating, and enhancing Scaleway‚Äôs Block Storage solution.\nThis service launched by Scaleway offers resilient, redundant, and high-availability storage for its numerous clients. Your missions will require programming, automation, and architecture skills. On top of your daily activities within your team, you will need to interact with all of Scaleway‚Äôs teams, especially Instances, Network, Hardware, and Platform.\nMinimum Qualifications\nExperienced System Engineer who is passionate about DevOps best practices and cloud architecture, ideally with over 5 years of experience\nExperience with (and love for) storage systems\nStrong system-level programming skills\nGood understanding of Golang.\nExperience with a continuous integration workflow, Gitlab, and Git\nStrong Linux knowledge\nDistributed systems (and debugging them)\nResponsibilities\nDeploying infrastructure in new Availability Zones\nImproving & bringing forward new ideas for our current infrastructure\nReacting to eventual failures in collaboration with other teams\nPresenting your work during tech meetings\nCoding, peer review, and deployment\nCustomer support in relation to your product\nDeploying your code\nPreferred qualifications\nSolid experience with Ceph in high capacity and/or performance environment\nGreat oral and written communication skills\nInfrastructure deployment with Ansible\nVery good command of English\nTechnical Stack\nCeph\nUbuntu/Debian\nAnsible\nGolang\nProtobuf\nPostgresql\nLocation\nThis position is based in our offices in Paris or Lille (France)\nRecruitment Process\nScreening call - 30 mins with the recruiter\nManager Interview - 45 mins\nTechnical Interviews\nHR Interview - 45 mins\nHead of Interview - 45 mins\nOffer sent - 48 hours\nShow more\nShow less",
        "details": {
            "JobDetail": [],
            "TypeContract": "",
            "Salary": "",
            "Level": "",
            "Experience": null
        },
        "title": "devops",
        "skills": {
            "DevTools": [
                "Git"
            ],
            "OS": [
                "Linux"
            ],
            "DBMS": [
                "PostgreSQL"
            ],
            "Automation": [
                "Kubernetes",
                "Ansible"
            ],
            "Containers": [
                "Kubernetes"
            ],
            "Collaboration": [
                "Teams"
            ],
            "Other": [
                "Cloud",
                "DevOps"
            ],
            "EnSoftSkils": [
                "Communication",
                "Collaboration"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "Cloud Temple",
        "location": "√éle-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/cloud-engineer-storage-at-cloud-temple-3779352432?position=54&pageNum=0&refId=NuDbZkBPOnBALTaaBOYlpw%3D%3D&trackingId=SJlp%2BR9jCag6kk0bkGq1wA%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Afin de consolider notre √©quipe Computing & Storage, Cloud Temple vous offre l'opportunit√© de nous rejoindre en tant que Cloud Engineer Storage F/H.\nMISSIONS :\nAu sein de l‚Äô√©quipe de Computing & Storage, vous √™tes responsable du maintien et de l‚Äô√©volution de nos infrastructures compute et virtualisation ainsi que de la stabilit√© du service rendu au client. Vous travaillez sur des infrastructures certifi√©es (SecNumCloud, HDS) avec de fortes contraintes de s√©curit√© et de disponibilit√©.\nEn tant que Cloud Engineer Storage , vous aurez comme mission :\nAssurer la gestion des √©v√®nements et incidents de production\nAssurer une r√©solution rapide en cas d‚Äôincident, identifier les causes racines et amener des correctifs\nMaintenir la conformit√© op√©rationnelle et s√©curitaire des services\nAssurer la gestion des changements en production en validant le niveau de risques en rapport avec les niveaux de service\nParticiper aux projets d‚Äô√©volution et de transformation des infrastructures et services\nAgr√©menter et maintenir une base de connaissances techniques\nAssurer un suivi du traitement des incidents de bout en bout\nExigence du poste :\nNiveau de dipl√¥mes :\nBAC + 5\nComp√©tences requises :\nConnaissance des outils Git, GitLab (CI/CD), Docker, Terraform, Ansible\nMaitrise des concepts ITIL\nConnaissance des produits VMware est un atout\nMaitrise d‚Äôau moins un langage de programmation : Python, Bash, PHP, Golang, JAVA\nMa√Ætrise des environnements UNIX (FeedBSD, Linux, Solaris) et r√©seaux IP\nConnaissances linguistiques :\nAnglais : lu, parl√© et √©crit\nExp√©rience attendue\nAu moins 2 ans sur un poste similaire\nExp√©rience en administration d‚Äôinfrastructure diverse et en gestion d‚Äôenvironnement de production informatique certifi√©s\nConnaissance des architectures des syst√®mes d‚Äôinformation\nMa√Ætrise des protocoles et solutions de stockage standards\nCapacit√© √† automatiser des actions op√©rationnelles au travers des scripts ou de programme\nMa√Ætrise des solutions de supervision des services et leurs performances\nCapacit√© √† proposer et faire √©voluer les process et outils de gestion de la production\nSavoir √™tre attendus\nSens de la qualit√© de service\nCapacit√© d‚Äôadaptation et d‚Äôautomatisation dans un environnement en perp√©tuelle √©volution\nExcellentes comp√©tences organisationnelles\nCapacit√© √† g√©rer les situations de crise\nShow more\nShow less",
        "details": {
            "JobDetail": [],
            "TypeContract": "",
            "Salary": "",
            "Level": "",
            "Experience": "2 an(s)"
        },
        "title": "cloud architect /engineer ",
        "skills": {
            "ProgLanguage": [
                "Java",
                "Bash",
                "Python"
            ],
            "DevTools": [
                "Git",
                "Docker"
            ],
            "OS": [
                "Linux"
            ],
            "Automation": [
                "Ansible"
            ],
            "InfrastructureAsCode": [
                "Terraform"
            ],
            "Virtualisation": [
                "VMware"
            ],
            "Containers": [
                "Docker"
            ],
            "Other": [
                "Cloud",
                "CI/CD"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "Mazars",
        "location": "Paris, √éle-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/devops-engineer-at-mazars-3850005993?position=55&pageNum=0&refId=NuDbZkBPOnBALTaaBOYlpw%3D%3D&trackingId=ikPkXYPJBAlMpIHhKsp2jw%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Votre poste\nMazars is a leading international audit, tax and advisory firm, aspiring to build the economic foundations of a fair and prosperous world. Operating as a united partnership, Mazars works as one integrated team, leveraging expertise, scale and cultural understanding to deliver exceptional and tailored services in audit and accounting, as well as tax, financial advisory, consulting and legal services*.\nFounded in Europe, Mazars is present in over 95 countries and territories, with 47,000 professionals ‚Äì 30,000 in our integrated partnership, 17,000 via the Mazars North America Alliance ‚Äì dedicated to helping clients make the most of business opportunities and operate with confidence.\n*where permitted under applicable country laws.\nVos principales missions\nThis is a permanent role reporting to Head of Platforms.\nTechnology & digital solutions (T&DS)\nMandated by Mazars Global Executive Board, the Technology & digital solutions team is leading Mazars digital transformation to unleash the next stage of Mazars growth. Specifically, the transformation will allow easier collaboration across geographies, quicker scalable service offering to clients in a safe, modern and sustainable way. As a result, Mazarians will enjoy a seamless experience and deliver more value to clients every day.\nTo reach these goals, Technology & digital solutions transformation programme aims at consolidating the IT operations from a multi-local model spread across 99+ countries into a global model. This includes the infrastructure and the operating model design needed to support Mazars business, people and clients now and in the future.\nThe success of this change relies on the great expertise and relentless engagement of every member of the team. This is a great moment to join the Technology & digital solutions organisation and be part of the delivery of this major transformation over the coming years!\nDevOps Engineer\nRole Purpose, Accountabilities, Experience, Knowledge, And Skills\nWe are looking for a DevOps Engineer to install, maintain, document, upgrade and optimise cloud & hybrid infrastructure while ensuring the reliability, security and availability of said platform, in close collaboration with the entire Global IT programme team.\nKey Responsibilities\nBuild\nManage the deployment of solutions, encompassing both applications and infrastructure, either through hands-on delivery or with third party support\nEnsure that deployments of new solutions comply with Global IT Enterprise Architectural standards\nOversee the handover of solutions into relevant service management teams via preparation of appropriate documentation and relevant training\nImagine, architect, develop, deploy, and evolve CI and CD systems for our cloud applications\nWrite Infrastructure as Code (IaC) using industry standard tools and services\nWrite application deployment automation using industry standard deployment and configuration tools\nRun\nProvide support and day to day administrator for deployed solutions\nOversee incident management activities related to global solutions and liaise with third party support partners through to resolution\nMonitor deployed solutions to ensure they are operating in an optimal manner\nManage patching, upgrades, service packs of compute components\nMaintain relevant documentation over the lifecycle of solutions ensuring they are kept up to date.\nVotre profil\nYou speak fluent English, and at least one other European language (French, Dutch, Spanish, ...)\nGood knowledge of IT best practices and design patterns.\nExcellent knowledge of (hybrid) cloud concepts and technologies, preferably utilizing Azure and Microsoft technologies. You are familiar with governance, monitoring, IAM, storage and server(less) infrastructure, and container concepts.\nCI/CD pipelines have no secrets for you anymore: you have a good experience in building a continuous delivery process: version management, automation, infrastructure as code\nKnowledge of Bicep.\nYou should be curious and fast at picking up new things with a sharp eye for details.\nYou should be eager to grow your skills and to embrace new challenges.\nPreferred Certifications\nAZ-104, AZ-900 preferred.\nAZ-400 highly desired\nShow more\nShow less",
        "details": {
            "JobDetail": [],
            "TypeContract": "",
            "Salary": "",
            "Level": "",
            "Experience": null
        },
        "title": "devops",
        "skills": {
            "CloudComputing": [
                "Azure"
            ],
            "Collaboration": [
                "Teams"
            ],
            "Other": [
                "Cloud",
                "DevOps",
                "CI/CD"
            ],
            "EnSoftSkils": [
                "Collaboration"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "Matomo",
        "location": "Paris, √éle-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/senior-cloud-devops-engineer-100%25-remote-europe-at-matomo-3883003015?position=56&pageNum=0&refId=NuDbZkBPOnBALTaaBOYlpw%3D%3D&trackingId=16d9rgitSoXgFNOAO479TQ%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Introduction\nWe‚Äôre looking for an experienced DevOps engineer to work on our cloud hosted SaaS platform. We are the creators of Matomo, the leading open source web analytics solution that gives people full control of their data and built-in privacy. We have challenges to solve and need you!\nWe are fully remote and we collaborate online. We are a small, flexible team, and when you come onboard you will play an integral part in engineering. You‚Äôll help us to make our products better and deliver a great experience to our customers.\nKey Responsibilities\nBuild, manage and automate our SaaS web analytics platform on AWS\nEnsuring availability, performance, security, and scalability of the platform\nMaintain and improve CI/CD pipelines, Infrastructure as code, monitoring and alerting systems\nSupport software development, product and customer support teams to achieve business outcomes\nTake ownership of technical issues, and work with the team to resolve more advanced issues when necessary\nRespond to application and security incidents via a rotating On-Call schedule (two thirds of the time, including nights and weekends)\nMinimum Qualifications\n5+ years commercial experience working with the AWS cloud\nProficient with modern IaC tooling (e.g., Terraform, Cloud Formation, Pulumi)\nProficient in at least 1 popular scripting languages (e.g., Python, Typescript/Javascript)\nProficient in container technologies (e.g., Docker, Docker Compose, Kubernetes)\nProficient in Linux systems and shell scripting\nProficient in declarative modern CI/CD patterns (e.g., GitHub Action, Bitbucket Pipeline, GitLab CI/CD)\nProficient with modern software engineering workflows (e.g., Git, pull request, code review)\nUnderstanding of network topologies, high availability principles\nUnderstanding of monitoring concepts (e.g., metrics, dimensions, log analysis)\nStrong analytical skills and a passion for it to understand complex business logic\nGreat communication and collaboration skills\nAbility to work independently\nWilling to provide on-call support\nNice to have\nWorking knowledge of PHP\nMySQL server and SQL query optimisation\nLocation\n100% Remote work position ( Candidates must be willing to work a minimum of 4 hours overlapping with New Zealand per week)\nBenefits\nRemote work (save many hours on commute, and save money)\nCo-working space paid for and/or work from home\nAll home office equipment paid for (laptop, desk, chair, standing desk, lights, etc.)\nFlexible hours\n25 days of paid holidays per year plus your national public holidays\nSick leave\nHealth Insurance: Your Well-being, Our Priority\nA huge ‚Äúplayground‚Äù to grow your skill set\nVolunteering Day: Empower Your Impact\nBereavement Leave for Pets: Compassion Beyond Boundaries\nTraining Opportunities\nMental Health Support Services\nOpportunity to work in a customer obsessed business, dedicated to building high-quality software with a strong mission of helping people grow their web projects while keeping full control of their data\nOpportunity to have an immediate impact on a product that is used by more than 1 million websites and almost 2% of the whole Internet\nAbout InnoCraft And Matomo Analytics\nAt InnoCraft, we offer analytics products and SaaS to enable our users to grow their business. We believe in openness, privacy and 100% data ownership. Our mission is to liberate analytics and we are passionate about measuring for success. That‚Äôs why we created Matomo Analytics, the leading open source analytics platform used on more than 1 million websites and apps in over 150 countries, available in more than 50 languages. The Matomo platform collects, stores and processes a lot of information: hundreds of millions of data points each month. We create intuitive, simple and beautiful reports that delight our users.\nInnoCraft celebrates the things that make you, you! We are an inclusive employer and do not discriminate against any employee or applicant for employment because of race, color, religion, sex, sexual orientation, gender identity, national origin, age, marital status or disability. We actively seek diver\nsity in our workplace and embrace individuals with unique backgrounds, perspectives, and abilities!\nCome join our growing team that‚Äôs helping ensure a safer, more privacy focused web/internet!\n#Hiring\nShow more\nShow less",
        "details": {
            "JobDetail": [
                "Remote",
                "Full"
            ],
            "TypeContract": "",
            "Salary": "",
            "Level": "",
            "Experience": null
        },
        "title": "devops",
        "skills": {
            "ProgLanguage": [
                "Python"
            ],
            "DataBase": [
                "SQL"
            ],
            "CloudComputing": [
                "AWS"
            ],
            "DevTools": [
                "Git",
                "Docker"
            ],
            "OS": [
                "Linux"
            ],
            "DBMS": [
                "MySQL"
            ],
            "Automation": [
                "Kubernetes"
            ],
            "InfrastructureAsCode": [
                "Terraform"
            ],
            "Containers": [
                "Docker",
                "Kubernetes"
            ],
            "Collaboration": [
                "Teams"
            ],
            "Other": [
                "Cloud",
                "DevOps",
                "CI/CD"
            ],
            "EnSoftSkils": [
                "Communication",
                "Collaboration"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "STATION F",
        "location": "Paris, √éle-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/devops-cloud-engineer-at-station-f-3824854750?position=57&pageNum=0&refId=NuDbZkBPOnBALTaaBOYlpw%3D%3D&trackingId=WiKAqr%2Bd5xpJNB6dDqu10A%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "√Ä propos\nAllphins is the leading InsurTech company that provides risk management solutions for the insurance industry.\nAfter starting as a member of the Lloyd's Lab (reputable Insurtech accelerator in London) and being hosted at Station F (Paris), we now help 25+ clients cover all major commercial lines including Property, Energy, Political Risk, Trade Credit, Cyber, Casualty & Terrorism. Our goal is to help (re)insurers better analyse risks and make the right decisions.\nWith a strong international presence (UK & US) and self-financed growth (from 4 to 15 employees in 2 years), we seek to become the leading risk management platform for speciality risks.\nDescriptif du poste\nActivity\nAs a Cloud Devops at Allphins you will :\nImprove, maintain the current cloud infrastructure and helping the development team to scale the application\nApply site reliability engineering practices to a service (?)\nInsure the security of the app\nDevelop CI/CD for containerize application\nImplement infrastructure monitoring and optimize service performance\nEnsure the quality of the various release\nTechno\nCloud provider: GCP ( GKE, Network stack, Dataproc,...)\nContainerize app deploiment : Docker, Helm, kubernetes\nInfra as Code: Terraform\nCode versioning: Git\nDatabase technology: Postgresql, redis\nCode base: Python\nTechno Nice To Have\nKnowledge in big data architecture (using sprak, airflow etc‚Ä¶)\nKnowledge in API development in python\nCode quality tools\nSoftskills\nExperience working with the scrum methodology\nProfil recherch√©\nBackground : Master + 5 - Engineer\nExperience : 2 - 5 years\nSignificant experience as a devops engineering in a GCP environment.\nNice to have : you have already worked in a start up environment\nFluent in english\nWork at Allphins\n‚òÄÔ∏è Key responsibilities: autonomy, impact & strong visibility\nüåè Work in an international environment\nüí∏ Attractive remuneration (with benefits : Swile Card, Alan..)\nüíª Hybrid working possible (2/3 days remote)\nüöÄ Great career opportunities & solid learning\nüè¢ Offices in the center of Paris (WeWork Jules Lefebvre)\nü¶æ High-end equipments (tools & technologies)\nüèñÔ∏è One off-site per year\nProcess de recrutement\nInterview HR\nTech interview and case study\nInterview with Jean-Baptiste, CTO and co founder\nInformations compl√©mentaires\nType de contrat : CDI\nLieu : Paris\nNiveau d'√©tudes : Bac +5 / Master\nExp√©rience : > 4 ans\nT√©l√©travail partiel possible\nSalaire : entre 49996‚Ç¨ et 60000‚Ç¨ / an\nShow more\nShow less",
        "details": {
            "JobDetail": [
                "Remote"
            ],
            "TypeContract": "CDI",
            "Salary": "49996",
            "Level": "",
            "Experience": "4 an(s)"
        },
        "title": "devops",
        "skills": {
            "ProgLanguage": [
                "Python"
            ],
            "CloudComputing": [
                "GCP"
            ],
            "DevTools": [
                "Git",
                "Docker"
            ],
            "DBMS": [
                "PostgreSQL"
            ],
            "Automation": [
                "Airflow",
                "Kubernetes"
            ],
            "InfrastructureAsCode": [
                "Terraform"
            ],
            "Containers": [
                "Docker",
                "Kubernetes"
            ],
            "Other": [
                "Cloud",
                "Big Data",
                "DevOps",
                "CI/CD"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "Harnham",
        "location": "Paris, √éle-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/cloud-engineer-azure-at-harnham-3850370394?position=58&pageNum=0&refId=NuDbZkBPOnBALTaaBOYlpw%3D%3D&trackingId=YhfI68TMmLwFFOtDlPqW2g%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Cloud Engineer\nMinimum 1 an d'exp√©rience en tant que Cloud engineer\nParis\n2jTT\nCDI\nNous sommes √† la recherche d'un(e) Cloud Engineer talentueux(se) pour rejoindre une √©quipe dynamique dans le secteur du retail. En tant que Cloud Engineer, vous serez au c≈ìur de notre transformation digitale, contribuant √† la conception, √† la mise en ≈ìuvre et √† la maintenance de l'infrastructure cloud.\nStack technique : Azure, Powershell, ElasticSearch, Kibana, Grafana,\nResponsabilit√©s Principales:\nConcevoir, d√©ployer et g√©rer notre infrastructure cloud sur Microsoft Azure, garantissant sa stabilit√©, sa s√©curit√© et sa performance.\nD√©velopper des solutions d'automatisation pour le provisionnement, la configuration et la gestion des ressources cloud.\nCollaborer √©troitement avec les √©quipes techniques et m√©tier pour comprendre les besoins et proposer des solutions cloud adapt√©es.\nAssurer la conformit√© aux normes de s√©curit√© et de gouvernance cloud.\nSurveiller et optimiser les performances des services cloud pour garantir une exp√©rience utilisateur optimale.\nQualifications Recherch√©es:\nDipl√¥me de Master en informatique ou dans un domaine connexe, ou exp√©rience √©quivalente avec au moins 1 an d'exp√©rience dans un poste similaire.\nExp√©rience av√©r√©e dans la conception, la mise en ≈ìuvre et la gestion d'infrastructures cloud, de pr√©f√©rence sur\nMicrosoft Azure\n.\nMa√Ætrise des outils et technologies DevOps, notamment\nAzure DevOps, PowerShell et Terraform\n.\nConnaissance approfondie des technologies de conteneurisation telles que\nKubernetes\n.\nExp√©rience avec Elastic Search serait un atout.\nForte passion pour l'innovation et la r√©solution de probl√®mes, avec une orientation vers l'automatisation et l'am√©lioration continue.\nCapacit√© √† travailler de mani√®re proactive et autonome, avec un excellent esprit d'√©quipe.\nMa√Ætrise du fran√ßais et de l'anglais est n√©cessaire.\nShow more\nShow less",
        "details": {
            "JobDetail": [],
            "TypeContract": "CDI",
            "Salary": "",
            "Level": "",
            "Experience": null
        },
        "title": "cloud architect /engineer ",
        "skills": {
            "DataBase": [
                "Elasticsearch"
            ],
            "CloudComputing": [
                "Azure"
            ],
            "Automation": [
                "Kubernetes"
            ],
            "InfrastructureAsCode": [
                "Terraform"
            ],
            "Containers": [
                "Kubernetes"
            ],
            "Other": [
                "Cloud",
                "DevOps"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "OPEN",
        "location": "Levallois-Perret, √éle-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/cloud-architect-azure-h-f-at-open-3720167006?position=59&pageNum=0&refId=NuDbZkBPOnBALTaaBOYlpw%3D%3D&trackingId=naa0VJmdk4499bQL4U2awQ%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Qui sommes-nous ?\nRejoindre la BU Cloud & DevOps, c‚Äôest rejoindre La communaut√© d'experts techniques qui accompagne des sujets strat√©giques et transverses pour Open France.\nVous serez en charge d'accompagner et conseiller nos clients autour des sujets Microsoft Cloud Azure depuis l‚Äôexpression et la collecte de leurs besoins fonctionnels.\nVos missions d√©taill√©es\nD√©finir les architectures cibles Cloud et Hybride qui vont soutenir les briques du SI Client et capitaliser sur les projets pour d√©finir nos standards d‚Äôarchitecture.\nD√©finir les chemins de migration et de transition des applications et des workloads clients vers Microsoft Azure,\nImpl√©menter ou coordonner l‚Äôint√©gration des architectures et des solutions propos√©es,\nAccompagner nos forces de vente dans les soutenances des dossiers de r√©ponse complexes,\nParticiper activement √† la conception des nouvelles offres, en capitalisant sur les projets et les architectures d√©j√† produites.\nVous\nDisposez d‚Äôune premi√®re exp√©rience significative dans la conception d‚Äôarchitecture de solutions et de services Cloud/SaaS privil√©gi√©s sur Microsoft Cloud Azure,\nMaitrisez sur le plan technique les concepts d‚Äôarchitecture en Cloud Public : Microsoft Azure, IaaS/PaaS/SaaS, Azure Stack(s), solutions hybrides et multicloud, s√©curit√© et gouvernance du Cloud, modernisation d‚Äôapplications et de donn√©es,\nAimez travailler en √©quipe et dans la bonne humeur,\nAvez le sens du service,\nAvez le go√ªt du challenge et la culture du r√©sultat,\nü§ù Vous √™tes mettre de votre carri√®re : Comment ?\nInt√©grer des projets transverses et strat√©giques : outils interne, meetup, summit, formation, avant-ventes, chiffrage, veille, audit SI ‚Ä¶\nEvoluer vers votre r√¥le gr√¢ce √† un accompagnement personnalis√© et un parcours de formation et certifications adapt√©.\nNotre process de recrutement\nBref √©change t√©l√©phonique\nRencontre RH pour parler de vous, de vos aspirations professionnelles et vous pr√©senter Open,\nEchange avec l‚Äôun des experts\nTemps de partage avec votre futur manager.\n‚úÖApr√®s vous avoir souhait√© la bienvenue vous b√©n√©ficiez d‚Äôun parcours d‚Äôint√©gration sur-mesure.\nCODE REC : ACH23516\nQu‚Äôattendez-vous pour √™tre Open ?\nShow more\nShow less",
        "details": {
            "JobDetail": [
                "Hybride"
            ],
            "TypeContract": "",
            "Salary": "",
            "Level": "",
            "Experience": null
        },
        "title": "data architect",
        "skills": {
            "CloudComputing": [
                "Azure"
            ],
            "Other": [
                "Cloud",
                "DevOps"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "fifty-five",
        "location": "Paris, √éle-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/senior-data-cloud-engineer-h-f-at-fifty-five-3915044673?position=60&pageNum=0&refId=NuDbZkBPOnBALTaaBOYlpw%3D%3D&trackingId=3mDM8SFFfN23w70AQMCGNQ%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Senior Data & Cloud Engineer\nfifty-five est une data-company d'un genre nouveau qui aide les marques √† exploiter les donn√©es pour am√©liorer le marketing, les m√©dias et l'exp√©rience client gr√¢ce √† une combinaison de services de conseil et de technologie sp√©cialis√©s.\nEn tant que pilier data et marketing du Brandtech Group, nous offrons des services qui combinent le conseil en strat√©gie, les services de cloud, le conseil en m√©dia et l'exp√©rience client.\nfifty-five, c'est plus de 400 experts du num√©rique. Des digital consultants, des sp√©cialistes du tracking et du m√©dia, des ing√©nieurs et des data scientists, travaillent tous en √©troite collaboration pour fournir des conseils marketing de haut niveau et une assistance technique aux marques, dans tout type d'industrie, partout dans le monde.\nPartenaire des annonceurs de la collecte √† l'activation et l'exploitation des donn√©es, nous aidons les organisations √† devenir de v√©ritables entit√©s omnicanales ma√Ætrisant l'efficacit√© de leur √©cosyst√®me digital et ses synergies avec le monde physique.\nBas√© √† Paris, nous op√©rons sur 3 fuseaux horaires depuis nos 10 bureaux, situ√©s √† Paris, Londres, Gen√®ve, Milan, Shanghai, Hong Kong, Shenzhen, Taipei, Singapour et New York. fifty-five attache une importance particuli√®re au bien-√™tre de ses collaborateurs, ce qui lui a permis de figurer dans le classement Best Workplaces France en 2018.\nContexte :\nL'√©quipe d'ing√©nierie d√©veloppe et met en ≈ìuvre les solutions techniques permettant la r√©alisation de pipelines de donn√©es et l'impl√©mentation de data platform pour nos clients : r√©cup√©ration de datas sur de multiples sources de donn√©es (APIs, files, etc.), data cleaning, data processing, automation et monitoring de l'ensemble. L'√©quipe s'appuie sur des technologies r√©centes (docker, kubernetes, terraform, notebooks, etc.) et met en place ses projets dans les diff√©rents clouds du march√© (GCP, Azure, AWS...).\nMission :\nNous sommes √† la recherche d'une personne capable de r√©aliser des projets techniques pour r√©pondre aux besoins de nos clients (par exemple: syst√®me de recommandations de produits, d√©tection d'anomalies, ranking). Les activit√©s vont du chiffrage et du sizing technique √† la mise en ≈ìuvre des architectures, en passant par la revue des sp√©cifications fonctionnelles et la production de code. Le Data & Cloud Engineer sera √©paul√© par un Lead dans ses missions. Il sera √©galement amen√© √† participer √† la R&D et √† accompagner les √©quipes transverses dans la mise en place d'outils de travail internes (librairies pour les data scientists, environnement Notebooks pour les data analysts et data scientists, d√©veloppement de frameworks sur diff√©rents cloud providers, etc.).\nNous souhaitons trouver la bonne personne pour faire √©voluer ou cr√©er de nouvelles solutions dans ce cadre. Les missions comprennent aussi bien du prototypage rapide pour des d√©monstrateurs, que de la production de code robuste qui tourne en production tous les jours.\nComp√©tences et exp√©riences :\n4-5 ans d'exp√©rience en tant que Data Engineer\nMa√Ætrise de Python, SQL\nMa√Ætrise des environnements Cloud. Id√©alement certifi√© GCP, Azure ou AWS\nBonne connaissance de Docker/Kubernetes\nBonne connaissance d'au moins un data warehouse (BigQuery, Snowflake, etc)\nConnaissance autour des Notebooks (Jupyter)\nA l'aise avec des concepts li√©s aux APIs (OAuth, REST, etc.)\nA l'aise avec les notions d'Infrastructure as Code (Terraform)\nAu courant des pratiques GitOps et connaissances des concepts autour du CI/CD\nLa ma√Ætrise d'un orchestrateur, comme Apache Airflow, est un plus\nEsprit d'√©quipe (collaborer aux tests unitaires, revue de code, partage de code, sprints)\nBon niveau en fran√ßais et en anglais\nA d√©j√† travaill√© en mode projet avec des interlocuteurs vari√©s (consultant, data analyst, data scientist)\nUne exp√©rience en marketing digital est un plus\nNous proposons :\nun bureau au centre de Paris avec terrasse et jardin\nun environnement multiculturel avec des collaborateurs aux nationalit√©s multiples (France, Royaume-Uni, Etats-Unis, Chine, Tunisie, Italie et plus)\ndes projets avec nos bureaux √† Londres, Hong Kong, New York, Shanghai, Gen√®ve, Shenzhen et Taipei\ndes TGIF et supers soir√©es\nShow more\nShow less",
        "details": {
            "JobDetail": [
                "Senior"
            ],
            "TypeContract": "",
            "Salary": "",
            "Level": "",
            "Experience": "5 an(s)"
        },
        "title": "data engineer",
        "skills": {
            "ProgLanguage": [
                "R",
                "Python"
            ],
            "DataBase": [
                "SQL"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [
                "Apache Airflow"
            ],
            "CloudComputing": [
                "GCP",
                "AWS",
                "Azure"
            ],
            "DevTools": [
                "Docker"
            ],
            "DBMS": [
                "BigQuery",
                "Snowflake"
            ],
            "Automation": [
                "Airflow",
                "Kubernetes"
            ],
            "InfrastructureAsCode": [
                "Terraform"
            ],
            "Containers": [
                "Docker",
                "Kubernetes"
            ],
            "Other": [
                "Cloud",
                "CI/CD"
            ],
            "EnSoftSkils": [
                "Collaboration"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "WhiteLab Genomics",
        "location": "Paris, √éle-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/devops-cloud-engineer-with-it-experience-at-whitelab-genomics-3919802817?position=1&pageNum=2&refId=UAjmJD%2Bo5LxF5kj2yfoeDg%3D%3D&trackingId=eHEToi0UkvdlfCNxArZA9w%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "WhiteLab Genomics\nwas founded with the belief that life-saving drugs should be accessible to all patients in need. United in our vision, we‚Äôve become a part of Y Combinator, French Tech 2030, Future 40 by Station F, and we‚Äôve been recognized by The Galien Foundation (‚ÄùBest Startup‚Äù category), among other institutions at the forefront of technology. Today, we strive to become the leading expert in A.I. for genomic medicine, operating as the go-to partner for research and development.\nIn this critical and multifaceted role\n, you will lead the maintenance, development, and fortification of our AI/IT infrastructure for genomic medicine. We‚Äôre in the process of setting up and scaling our Cloud infrastructure, and you‚Äôll play a valuable role in helping us scale up, leading the charge in optimizing our cloud services, streamlining workflows, and ensuring seamless integration with our DevOps practices and automation frameworks. To scale our current architecture to a higher level, you will help us identify our current bottlenecks, propose new Cloud based solutions, implement them, and help users to use them, allowing for enhanced efficiency. Fostering an atmosphere of productivity and teamwork, your expertise will drive our mission towards greater technological excellence and innovation.\nThis is an\nincredible opportunity\nto work on a diversity of engaging tasks in a hybrid role, forming the infrastructure of a vibrant start-up that seeks to make an impact on the future of healthcare ‚Äì- you'll play a crucial role in helping revolutionize genomic medicine with AI.\nOur Core Values:\nWe Believe that Care is Everything.\nWe Value our Collective Potential\nWe Cultivate Proactive Communication, Clarity and Respect\nWe Have a Can-Do Attitude\nWe Strive for Excellence\nWe‚Äôre Eager to Meet You If‚Ä¶\nProficiency in DevOps methodologies and tools, including proven experience in implementing robust continuous integration, continuous deployment (CI/CD) pipelines, infrastructure as code (IaC), and automated testing frameworks\nDemonstrated experience with coding (preferably Python) for automation tasks and infrastructure management and team interactions for orchestration tasks\nYou have expertise in cloud services (AWS, Azure, or Google Cloud), with a track record of designing, deploying, and managing scalable cloud-based infrastructure solutions tailored to business needs. Your comprehensive understanding of cloud services will enable seamless integration with DevOps practices and automation workflows\nYou have at least\n1 year of prior hands-on experience\nin managing IT equipment, tools, and issues at a tech company (preferably a tech start-up) and excel in administering SharePoint and email systems, ensuring smooth operations and user support\nYou possess great problem solving ability and can work autonomously\nYou have expertise in hardware, software, and network systems\nYou can manage pipelines, optimizing workflows for efficient deployment and delivery\nYour interpersonal skills allow you to collaborate effectively with cross-functional teams, including researchers, data scientists, business development professionals, and support functions\nYou can adapt to a dynamic and rapidly evolving industry, staying on top of the latest IT advancements\nYou have excellent verbal and written communication skills and have experience interfacing with stakeholders and users in English - French proficiency is a plus!\nYou‚Äôre knowledgeable of standard practices for access control models, data protection regulations, IT security, and compliance protocols\nHere‚Äôs How You‚Äôll Make an Impact‚Ä¶\nYou‚Äôll provide strategic and technical leadership to all of our teams, guiding the development and implementation of innovative solutions towards orchestration, CI/CD and security standards\nYou‚Äôll set up and manage CI/CD pipelines to automate processes\nYou‚Äôll write automation scripts to automate routine orchestration tasks and manage our infrastructure efficiently\nYou‚Äôll design, deploy, and manage scalable cloud-based infrastructure solutions\nYou‚Äôll integrate cloud services with DevOps practices and automation workflows\nYou‚Äôll oversee the operation and maintenance of IT tools and infrastructure, ensuring reliability, performance, and security\nYou‚Äôll manage user roles, permissions, and access control for Cloud services, SharePoint, and email systems in compliance with data protection regulations\nYou‚Äôll administer and optimize SharePoint and other collaboration tools to enhance team productivity\nYou‚Äôll ensure all technology systems and platforms operate reliably and efficiently\nYou‚Äôll implement and maintain security policies and procedures, conducting regular audits to ensure compliance with industry standards\nYou‚Äôll provide technical support, resolving issues related to hardware, software, network problems, systems, and access permissions\nYou‚Äôll manage and maintain all IT equipment and tools, ensuring they‚Äôre up to date and in good working condition\nYou‚Äôll lead Cloud and Helpdesk projects from inception to completion, ensuring projects are delivered on time, within budget, and meet quality standards\nYou‚Äôll implement best practices in IT operations and cybersecurity to safeguard company data and systems\nShow more\nShow less",
        "details": {
            "JobDetail": [],
            "TypeContract": "",
            "Salary": "",
            "Level": "",
            "Experience": null
        },
        "title": "devops",
        "skills": {
            "ProgLanguage": [
                "Python"
            ],
            "CloudComputing": [
                "AWS",
                "Azure"
            ],
            "Collaboration": [
                "Teams"
            ],
            "Other": [
                "Cloud",
                "DevOps",
                "CI/CD"
            ],
            "EnSoftSkils": [
                "Teamwork",
                "Leadership",
                "Collaboration",
                "Problem Solving",
                "Interpersonal Skills",
                "Communication"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "Equativ",
        "location": "Paris, √éle-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/cloud-engineer-at-equativ-3804533620?position=2&pageNum=2&refId=UAjmJD%2Bo5LxF5kj2yfoeDg%3D%3D&trackingId=lDzrBRhdea%2BAEXBS%2FUA16Q%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "üë´ About the team\nAt Equativ, we‚Äôre on a mission to develop advertising technologies that empower our customers to reach their digital business goals. This means that we rely on massively scalable, widely distributed, highly available, and efficient software systems; the platform deals with over 3 millions requests per second managed by 3,000 servers.\nOur innovation team based in Paris, Nantes, Limoges, Krakow and Berlin is composed of 100+ straightforward and energetic engineers working in an Agile environment and ready to tackle the most complex technical challenges.\nYour mission üëá\nWithin infra BU you will join the Platform department that strives to develop and deploy self-serve tooling to empower our RnD team.\nOur platform is gradually moving to a hybrid cloud platform. You will be joining as the second member of our cloud platform team:\nYou will help deliver a smooth transition of our RnD team to a hybrid cloud architecture.\nYou will be responsible for cloud governance and FinOps.\nYou will provide help to our engineering teams in order to optimize costs of our GCP components\nWhat you will do ‚úèÔ∏è\nAs a Cloud engineer in our new cloud platform team your missions will be to:\nDesign and develop self-serve tooling for our engineering teams to transition and maintain their workloads to the cloud.\nDesign and instrumentalize Finops guidelines to manage the overall ROI of our cloud infrastructure.\nHelp design and develop our cost management framework to help teams optimize their operational ROI.\nPropagate best-practices and know-how on cloud services and architectural patterns.\nImplement terraform modules to support our IAC approach on the cloud.\nEvaluate the CO2 savings associated with optimizing our cloud infrastructure usage.\nAbout you üëã\nMaster degree in Computer science or similar field of study.\n1+ years of System, Cloud or Software Engineering experience ideally in the web industry.\nAutonomous and innovative mindset.\nExperience in GCP cloud governance for production projects and collaboration within a 5+ engineering team.\nFluent with DevOps practices, specifically on Google Cloud Platform.\nInterested in the impact of technical decisions on business (finops approach) and environmental outcomes.\nWorking proficiency and communication skills in verbal and written English.\nNice to have:\nExperience in one or more of the following GCP topics: Finops, big data components for large datasets, Kubernetes administration.\nExperience working with IaC (Terraform or other).\nExperience in software development (Go, Python or equivalent).\nHow you'll grow üöÄ\nWithin 1 month:\nYou'll be just finishing your onboarding.\nYou'll probably have tackled a few small tasks with your peer.\nWithin 4 months:\nYou'll be trusted to review budget increases from development teams.\nYou'll be expected to propose small-scale optimisations on our cloud architecture.\nWithin 9 months:\nYou'll be in contact with most of the tech leads operating on GCP.\nYou'll be evolving our terraform architecture to deploy resources to the cloud.\nYou‚Äôll start getting a grasp on the AdTech business.\nüëã About us\nEquativ is the new single name for Smart Adserver, DynAdmic, LiquidM and Nowtilus ‚Äî four proven innovators in advertising technology. The vertically integrated company provides brand and privacy-safe solutions that empower its clients to achieve maximum impact while respecting the rights of consumers. The union combines client expertise and engineering excellence to serve the interests of both the supply- side and demand-side with equal professionalism and technical sophistication.\nHeadquartered in Paris and New York, Equativ operates globally with a team of more than 550 people in 20 offices. Equativ offers the market its own independent ad server, SSP, buyer tools, and media services to fulfill the promise of advertising technology. Learn more at Equativ.com.\nThe company is ranked on the Deloitte Technology Fast 500 EMEA and in the Financial Times‚Äô FT 1000: Europe‚Äôs Fastest-Growing Companies.\nEquativ (formerly Smart AdServer) has been awarded the HappyIndex@Work label and is proud to be among the best companies in the ChooseMyCompany ranking, recognized for its flexible working environment.\nCome and lead the charge with us in building a transparent ecosystem based on quality!\n----------------------\nEquativ is an equal opportunity employer. Equal access to employment, services, and programs are available to everyone, regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity, or Veteran status. If you require reasonable accommodation throughout the application and/or interview process, please contact the recruitment team at ta-team@equativ.com\nShow more\nShow less",
        "details": {
            "JobDetail": [],
            "TypeContract": "",
            "Salary": "",
            "Level": "",
            "Experience": null
        },
        "title": "cloud architect /engineer ",
        "skills": {
            "ProgLanguage": [
                "Python"
            ],
            "CloudComputing": [
                "GCP",
                "Google Cloud Platform"
            ],
            "Automation": [
                "Kubernetes"
            ],
            "InfrastructureAsCode": [
                "Terraform"
            ],
            "Containers": [
                "Kubernetes"
            ],
            "Collaboration": [
                "Teams"
            ],
            "Other": [
                "Cloud",
                "Big Data",
                "DevOps"
            ],
            "EnSoftSkils": [
                "Communication",
                "Collaboration"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "Astek",
        "location": "Antibes, Provence-Alpes-C√¥te d'Azur, France",
        "link": "https://fr.linkedin.com/jobs/view/devops-engineer-%E2%80%93-antibes-france-h-f-at-astek-3829412893?position=3&pageNum=2&refId=UAjmJD%2Bo5LxF5kj2yfoeDg%3D%3D&trackingId=FvyWkK7aw5uZBIQCKxvOfw%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "CDI\nAntibes - France\nPubli√©e il y a 2 jours\nLe Groupe Astek\nCe Que Nous Allons Accomplir Ensemble :\nRejoindre une √©quipe dans les domaines du transport et du tourisme sur des projets ambitieux dans lesquels la satisfaction clients et les solutions √† valeur ajout√©e jouent un r√¥le crucial.\nVotre Mission, Si Vous L‚Äôacceptez :\nComprendre les exigences du client ;\nEncourager et construire des processus automatis√©s dans la mesure du possible\nContr√¥ler les processus tout au long du cycle de vie pour s‚Äôassurer de leur respect\nD√©finir et param√©trer les processus de d√©veloppement, de test, de mise en production, de mise √† jour et de support pour le fonctionnement DevOps.\nVotre Future √âquipe :\nVenez rejoindre une √©quibe ambitieuse et dynamique dans un environnement international\nVotre stack de jeu\nAnsible, Python, Jenkins, Docker et Kubernetes\nLes Petits Plus Du Projet :\nVous √©voluerez au sein d‚Äôune √©quipe impliqu√©e et r√©active dans un environnement international et interviendrez sur des projets passionnants et enrichissants.\nVous ?\nDipl√¥m√©(e) d‚Äôune √©cole d‚Äôing√©nieur ou √©quivalent de niveau Bac+5. Vous justifiez id√©alement d‚Äôune exp√©rience sur un poste similaire ;\nVotre personnalit√©, votre esprit d‚Äô√©quipe, votre autonomie, votre relationnel, votre rigueur, votre cr√©ativit√© ainsi que votre curiosit√© seront des atouts essentiels pour mener √† bien vos missions sur le projet ;\nVous maitrisez les comp√©tences techniques backend de base : Python, Kubernetes, Jenkins, Docker,‚Ä¶\nAstek\nCr√©√© en France en 1988, Astek est un acteur mondial de l‚Äôing√©nierie et du conseil en technologies. Fort de son expertise dans de nombreux secteurs industriels et tertiaires, Astek accompagne ses clients internationaux dans le d√©ploiement intelligent de leurs produits et de leurs services, et dans la mise en ≈ìuvre de leur transformation digitale.\nDepuis sa cr√©ation, le Groupe a fond√© son d√©veloppement sur une forte culture d‚Äôentrepreneuriat et d‚Äôinnovation, et sur l‚Äôaccompagnement et la mont√©e en comp√©tence de\nses 7800 collaborateurs\nqui s‚Äôengagent chaque jour √† promouvoir la compl√©mentarit√© entre les technologies num√©riques et l‚Äôing√©nierie des syst√®mes complexes.\nRejoignez un Groupe en fort d√©veloppement en France et √† travers le monde ayant r√©alis√© un chiffre d‚Äôaffaires de 600 M‚Ç¨ en 2023.\nTous les d√©tails sur le Groupe sur le site https://astekgroup.fr. Et vous pouvez aussi nous suivre sur notre blog : https://blog.groupeastek.com.\nRencontrons-nous\nKillian, notre Talent Acquisition Officer, vous contactera afin de faire un point avec vous.\nEnsuite, Vous √âchangerez Avec :\nvotre futur manager (futur N+1) afin de discuter de ASTEK, votre parcours, vos attentes et la mission ;\nvotre directeur d‚Äôagence pour valider votre int√©r√™t pour le poste et vous pr√©senter les √©l√©ments contractuels.\nNos Plus\nAstek est green et fait b√©n√©ficier ses salari√©s d‚Äôune indemnit√© kilom√©trique v√©lo\nUne politique CARE sur-mesure d√©ploy√©e par nos √©quipes RH pour nos collaborateurs (https://astekgroup.fr/engagements)\nNotre charte de la Diversit√©\nBienvenue dans la team ! Allez-y, maintenant c‚Äôest √† vous de jouer !\nMots-cl√©s :\ndevops ‚Äì ing√©nieur ‚Äì ing√©nieure ‚Äì consultant ‚Äì consultante ‚Äì terraform ‚Äì ansible ‚Äì python\nCaract√©ristiques de l'emploi\nCat√©gorie Ing√©nieur\nJob Industry Distribution / Services Internet, Transports Terrestres\nPostuler en ligne\nNom *\nPr√©nom *\nEmail *\nUn email valide est requis.\nT√©l√©phone *\nUn num√©ro de t√©l√©phone valide est requis.\nJoindre un CV *\nMots-cl√©s :\ndevops ‚Äì ing√©nieur ‚Äì ing√©nieure ‚Äì consultant ‚Äì consultante ‚Äì terraform ‚Äì ansible ‚Äì python\nShow more\nShow less",
        "details": {
            "JobDetail": [],
            "TypeContract": "CDI",
            "Salary": "",
            "Level": "Bac+5",
            "Experience": null
        },
        "title": "devops",
        "skills": {
            "ProgLanguage": [
                "Python"
            ],
            "DevTools": [
                "Jenkins",
                "Docker"
            ],
            "Automation": [
                "Kubernetes",
                "Ansible"
            ],
            "InfrastructureAsCode": [
                "Terraform"
            ],
            "Containers": [
                "Docker",
                "Kubernetes"
            ],
            "Other": [
                "DevOps"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "Contemporary Amperex Technology Co., Limited",
        "location": "Paris, √éle-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/cloud-platform-engineer-at-contemporary-amperex-technology-co-limited-3888137773?position=4&pageNum=2&refId=UAjmJD%2Bo5LxF5kj2yfoeDg%3D%3D&trackingId=VTzkp1FzC5uNkAZGjntn9Q%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "CATL invites you to continue our legend of green energy. CATL is a World Fortune 300 Company, a global leader who provides premier EV battery and energy storage battery for the world. CATL‚Äôs EV battery consumption volume has ranked No.1 in the world for six consecutive years and global energy storage battery shipment has also ranked No.1 for two consecutive years.\nJob Responsibilities:\n1. Responsible for the operation of overseas big data platforms, formulate data access plans and programs, promote the implementation of data access programs, and realize data access of big data platforms;\n2. Responsible for customer docking, daily customer operation, demand communication and demand analysis of commercial vehicles, passenger cars and energy storage in Europe;\n3. Responsible for data management and data operation, coordinate internal and external resources, and form a normative docking process;\n4. Study the mechanism of battery products, collect data characteristics, and analyze data of specific business problems based on technical indicators;\n5. Responsible for the application and landing of the algorithm model, carry out data cleaning, prediction model establishment, training and optimization for the application scenario, and solve the problems of target recognition, classification, prediction, fault diagnosis and prediction in the scenario;\n6. Responsible for daily operation and maintenance of big data platform, such as operation and maintenance and algorithm deployment.\nJob requirements:\n1.Master degree or above, major in computer,software engineering, data science, vehicle engineering, management science and engineering, artificial intelligence, mathematical statistics and other science and engineering;\n2.‚ë† Familiar with commonly used machine learning and deep learning algorithms and models;\n‚ë° Familiar with mainstream cloud platform products (AWS, Azure, etc.) and understand the cloud native architecture system;\n‚ë¢ Familiar with Linux system principle and shell programming.\n3.‚ë† Have the understanding and mastery of Hadoop ecological technology stack, including but not limited to Spark, flink, storm, kafka, flume, HDFS, etc.;\n‚ë° Familiar with distributed storage and database technologies, including but not limited to ClickHouse, Greenplum, Redis, MonogoDB, ElasticSearch, etc., and skilled in using common data warehouse architectures;\n‚ë¢Master Java, Python, R and other programming languages, and skillfully use Python for data analysis;\n4. At least 2 years working experience in big data platform development or data analysis, experience in automobile industry, new energy or car networking industry is preferred;\n5. English as the working language, familiar with French is preferred;\n6. Strong communication and coordination skills, strong problem analysis and problem-solving skills, strong learning ability,business insight and data understanding ability, high sense of responsibility, and positive working attitude, cheerful personality, with certain pressure resistance.\nShow more\nShow less",
        "details": {
            "JobDetail": [
                "Full"
            ],
            "TypeContract": "",
            "Salary": "",
            "Level": "",
            "Experience": null
        },
        "title": "cloud architect /engineer ",
        "skills": {
            "ProgLanguage": [
                "R",
                "Java",
                "Python"
            ],
            "DataBase": [
                "Elasticsearch"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [
                "Hadoop",
                "Flink",
                "Spark"
            ],
            "CloudComputing": [
                "AWS",
                "Azure"
            ],
            "OS": [
                "Linux"
            ],
            "Other": [
                "Machine Learning",
                "Cloud",
                "Big Data"
            ],
            "EnSoftSkils": [
                "Communication"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "STATION F",
        "location": "Nantes, Pays de la Loire, France",
        "link": "https://fr.linkedin.com/jobs/view/cloud-engineer-at-station-f-3919657457?position=5&pageNum=2&refId=UAjmJD%2Bo5LxF5kj2yfoeDg%3D%3D&trackingId=buVObDFW7aLeNfEgOMCeUw%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "About\nAB Tasty is a global leader in AI-powered experience optimization solutions empowering brands using personalization, experimentation, recommendations, and search to build better experiences on their websites and apps.\nIntegrated into a single platform, AB Tasty offers web and API-based solutions that provide companies with a unified approach to facilitating seamless experiences for customers.\nBrands use AB Tasty‚Äôs platform to align digital, e-commerce, and product teams on revenue goals by maximizing digital impact.\nFounded in 2013, AB Tasty‚Äôs customer roster includes world-leading brands such as Kering, McDonald‚Äôs, Ulta Beauty, L‚ÄôOreal, Disneyland Paris, and LVMH among others.\nAB Tasty has 12 offices across the globe : North America, Europe, Asia Pacific (Australia and Singapore).\nJob Description\nAB Tasty is a global leader in AI-powered experience optimization solutions empowering brands using personalization, experimentation, recommendations, and search to build better experiences on their websites and apps. Integrated into a single platform, AB Tasty offers web and API-based solutions that provide companies with a unified approach to creating seamless experiences for customers.\nBrands use AB Tasty‚Äôs platform to align digital, e-commerce, and product teams on revenue goals by optimizing and innovating digital experiences.\nFounded in 2013, AB Tasty‚Äôs customer roster includes world-leading brands such as Kering, McDonald‚Äôs, Ulta Beauty, L‚ÄôOreal, Disneyland Paris, and LVMH among others.\nAB Tasty has 12 offices across the globe: North America, Europe, Asia Pacific\nWe are seeking a motivated Cloud Engineer to become an integral part of our cloud infrastructure team.\nThe successful candidate will have practical experience working with cloud services (AWS or GCP) and a desire to develop their skills across a range of technologies and projects.\nThis role involves contributing to the development, optimization, and maintenance of our cloud-based infrastructures, ensuring they meet our standards for scalability, reliability, and security.\nContract & Location\nPermanent full-time contract\nParis or Nantes Office\nSmooth remote work policy (up to 3 days a week)\nWhat You Will Do\nAssist in the migration of applications and services from legacy cloud infrastructure to brand-new, well-architectured cloud infrastructures, ensuring a smooth and efficient transition.\nAssist development and product teams in utilizing cloud infrastructures effectively, providing support and guidance to maximize productivity and efficiency.\nSupport the design and implementation of cloud solutions, contributing to the overall architecture while also taking on specific tasks and projects.\nParticipate in the deployment and management of infrastructure as code, using tools such as Terraform.\nContribute to the development of automation scripts and tools to streamline operational processes using Python, Bash, or similar languages.\nWork closely with product and technical teams to understand requirements and ensure cloud solutions align with business goals.\nMonitor and maintain cloud environments to ensure optimal performance, cost-efficiency, and compliance with security standards.\nContinuously learn and stay up-to-date with emerging cloud technologies and practices.\nWhat We Offer\nHuge impact. AB Tasty is only as great as our team. By directly developing the publicly accessible SaaS platform used by all our clients, you‚Äôll have a direct impact on the company‚Äôs success.\nThe opportunity to unleash your creativity. You‚Äôll be free to contribute to the processes, the tools and the organisation of the team, according the agile principles.\nNo micromanaging. Be the owner of your effort - you‚Äôll be one of the team and fully trusted to take responsibility for your tasks. You‚Äôll have every incentive to make a real impact.\nInternational reach. Our audience is wildly international, and our team is too. Although our HQ is located in France, our company language is English.\nContinuous education. We offer many opportunities for each employee to learn and grow from a mix of professional and non professional topics.\nUnique career opportunity. By joining a fast-growing company that‚Äôs making waves in the tech industry, you‚Äôll have a wonderful chance to enhance your learning and advance in your career faster than you ever thought possible.\nLots. Of. Fun. Our incredible magic makers organize awesome events, such as team games, drinks, yoga classes, parties, and a company-wide retreat every year with employees from all countries gathering for 2 days of fun.\nRemote working, flexible schedule. This isn‚Äôt a ‚Äúclock in, clock out‚Äù company. We care about your productivity, not tracking every minute you‚Äôre on site. It‚Äôs up to you to always be responsible for your work, no matter where you are or what schedule you‚Äôre keeping.\nTime for yourself. After a year within AB Tasty, we offer you a day off during which we simply ask you to think about your career expectations with us. It's not always easy to find time for introspection and to envision what path can lead us to a happy career so we offer a Retreat Day as an opportunity to reflect on that. We not only aim to succeed, but also to make you succeed.\nWhat We Are Looking For\n1+ years of experience in a cloud engineering role, or relevant experience in a cloud-focused project.\nFamiliarity with at least one major cloud provider (AWS, GCP) and its core services.\nExperience with infrastructure as code (Terraform) is a plus.\nExcellent communication skills, both written and verbal.\nAdditional Information\nContract Type: Full-Time\nLocation: Nantes\nPossible partial remote\nShow more\nShow less",
        "details": {
            "JobDetail": [
                "Remote",
                "Full"
            ],
            "TypeContract": "",
            "Salary": "",
            "Level": "",
            "Experience": null
        },
        "title": "cloud architect /engineer ",
        "skills": {
            "ProgLanguage": [
                "Bash",
                "Python"
            ],
            "CloudComputing": [
                "GCP",
                "AWS"
            ],
            "InfrastructureAsCode": [
                "Terraform"
            ],
            "Collaboration": [
                "Teams"
            ],
            "Other": [
                "Cloud"
            ],
            "EnSoftSkils": [
                "Creativity",
                "Communication"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "Teads",
        "location": "Montpellier, Occitanie, France",
        "link": "https://fr.linkedin.com/jobs/view/cloud-security-engineer-at-teads-3757698693?position=6&pageNum=2&refId=UAjmJD%2Bo5LxF5kj2yfoeDg%3D%3D&trackingId=GePTW1CixwCFJIm%2BFfb3ig%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Teads has an engineering team that brings together\n200+ talented individuals\nin 3 main locations (\nMontpellier, Paris, and Bucharest\n). We are organized in agile and autonomous\nfeature teams\nand share technical knowledge within several\ncommunities of practice\n.We promote diversity and are committed to creating an inclusive environment to enable all employees to feel valued and respected, which fosters creativity and innovation by allowing constructive collaboration and open exchange of ideas.\nOur organization offers the opportunity for hybrid work, allowing for two days in the office and the option to work remotely for the remainder of the week. Additionally, we provide relocation packages for those who prefer to relocate to one of our engineering offices.\nüëâ Join a team of passionate people who build quality and responsible advertising, at scale!\nOur main Engineering challenges at Teads\nWorking in a very high-traffic environment (1.9 billion users per month, 100 billion events per day) with low latency and high availability constraints (2 million requests per second, responses in less than 150 milliseconds).\nRich and diverse tech stack and system architecture to optimize for performance, scalability, resiliency, and cost efficiency. We use mostly Scala and TypeScript, among others.\nManagement of large datasets with milliseconds order of magnitude access time, to compute in a near real-time complex auction resolution algorithm (18 million predictions per second).\nBuild efficient and easy-to-use web products used by thousands of users working for the world's most premium publishers, advertisers, and agencies.\nA fast-changing environment where we continuously collaborate with Product teams and constantly adapt our Cloud infrastructure for new features and Products.\nBring a wide diversity of profiles to the same level of quality and knowledge.\nWhat will you do?\nAs a\nCloud Security Engineer\n, your mission will be to:\nProvide technical leadership and consultation for infrastructure engineers and developers to ensure the secure deployment of technology\nAs part of a team, ensure the adoption of security architecture and engineering initiatives in order to effectively and securely support the organization in meeting specific business technology needs\nDrive consideration of cybersecurity tools and datasets to enhance detective and preventative control sets\nUnderstand technical security issues and the implications to Teads businesses and be able to communicate them to management\nUnderstand emerging security technologies and determine the appropriate use within business applications\nMaintain and enforce Teads cybersecurity policies and secure design baselines\nExecute and improve Teads Security architecture review process and ensure compliance for all business initiatives\nArchitect global programs that deploy strong security patterns and controls across applications and computing environments, while addressing security, business resiliency, privacy and compliance frameworks\nIdentify security vulnerabilities and guide developers and engineers in addressing these issues\nImprove architectural adoption through automation and efficiently use security tools to solve challenges at scale\nValidate reference architectures for security best practices and recommend changes to enhance security and reduce risk\nCollaborate with the corporate functions including Finance, HR, Legal and Privacy to ensure that Teads maintains a strong cybersecurity posture\nWhat will you bring to the team?\nProven hands-on experience securing cloud infrastructure\nProven hands-on experience securing global multi-cloud architectures from both compute and network infrastructure perspective\nProven hands-on experience securing operating systems\nProven hands-on experience with application security topics such as the OWASP top 10 and technical remediations required\nDetailed technical experience supporting and implementing SIEM & logging tools (Splunk, Kibana, Qradar)\nAbility to extract actionable intelligence from large volume aggregated log storage\nThorough understanding of Network and Compute architectures and, specifically the security aspects\nThorough understanding of compliance and regulatory frameworks and how they affect architecture designs and reviews\nGood verbal and written communication skills, specifically the ability to communicate within the context of the intended audience, whether that be senior executives or highly technical engineering resources.\nDetailed understanding of the threats faced by advertising and digital platforms organizations\nWorking knowledge of at least one programming language (Python, Go, Terraform etc.)\nWhy work at Teads?\nAt Teads, Product and Engineering work hand in hand and are aligned towards the same goal: to\nscale our business\nwhile continuing to create\nnew and exciting products\n.\nWe value team spirit, pragmatism, listening and we encourage initiatives.\nWe promote end-to-end development: ‚ÄúYou build it, you run it, you monitor it‚Äù.\nWe share knowledge and support with each other beyond any organizational boundary.\nWe fix issues during a blameless postmortem and learn from it so that it doesn‚Äôt happen twice.\nWe are working together to create great engineering, but we are also supportive to promote a great work-life balance.\nWe Care About You\nSecurity & Savings: Attractive package providing financial peace of mind, including competitive compensation, profit-sharing, daily meal vouchers (Swile), family health insurance (Alan), and a personalized relocation package (if needed).\nCareer Development: Continuous investment in our employees' skills: in-house and external training, tech conference opportunities, internal mobility (individual contributor or management career ladder).\nLife Balance: A well-balanced work-life for our employees is one of our top priorities: 35+ days off per year, hybrid work (2-3 days remote work per week, more is open to discussion), fully covered parental leave, and reserved daycare places.\nWellness: Prioritizing employee well-being through premium work equipment, enjoyable work environment (work-life balance, team building events, summits), remote work subsidy, promoting Diversity & Inclusion with internal & external initiatives (women speaking groups, dedicated school partnerships), dedicated charitable time and sustainability actions (Eco Tree, subsidy for eco-mobility).\nDiscover more about our culture and benefits on our Engineering website.\nWhat are our recruitment process steps?\nWe want to get to know you and we try to give you the insight you need to make an informed decision to join us. For that, you can find all the information in our Engineering hiring process article!\nAbout Teads\nTeads operates a leading, cloud-based, omnichannel platform that enables programmatic digital advertising across a global ecosystem of quality digital media.\nAs an end-to-end solution, Teads‚Äô modular platform allows partners to leverage buy-side, sell-side, creative, data and AI optimization technologies. For advertisers and their agencies, Teads offers a single access point to buy the inventory of many of the world‚Äôs best publishers and content providers.\nThrough exclusive global media partnerships, Teads enables advertisers and agencies to reach billions of unique monthly users in brand safe, responsible advertising environments, while improving the effectiveness and efficiency of digital ad transactions.\nTeads partners with the leading marketers, agencies and publishers through a team of 1,200+ people in 50 offices across more than 30 countries.\nWe're committed to creating a dynamic work environment that values diversity and inclusion, and represents employees across a variety of skill sets. We embrace contributions from all ages, sexes, races, ethnicities, religions, sexual orientations and gender identities.\nShow more\nShow less",
        "details": {
            "JobDetail": [
                "Remote",
                "Full",
                "Senior"
            ],
            "TypeContract": "",
            "Salary": "1.9",
            "Level": "",
            "Experience": null
        },
        "title": "cloud architect /engineer ",
        "skills": {
            "ProgLanguage": [
                "Scala",
                "Python"
            ],
            "InfrastructureAsCode": [
                "Terraform"
            ],
            "Collaboration": [
                "Teams"
            ],
            "Other": [
                "Cloud"
            ],
            "EnSoftSkils": [
                "Organization",
                "Leadership",
                "Collaboration",
                "Creativity",
                "Communication"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "Sidetrade",
        "location": "Boulogne-Billancourt, √éle-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/senior-devops-engineer-sre-h-f-at-sidetrade-3919625910?position=7&pageNum=2&refId=UAjmJD%2Bo5LxF5kj2yfoeDg%3D%3D&trackingId=Gr9FaaLDS0aHGBD5YD2MFA%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Calling all tech enthusiasts! Are you a problem-solving, curious, and strategic DevOps SRE Engineer? Join us at Sidetrade, the leading global SaaS provider recognized by Gartner.(https://go.sidetrade.com/GartnerMagicQuadrant22.ht)\nIndulge your passion for high-availability software and performance enhancement as part of our dynamic team. Embrace the challenge, embrace the excitement - become a DevOps SRE Engineer and thrive! Shape the future of AI-powered Order-to-Cash at Sidetrade today. Join us in creating innovative solutions that redefine the industry!\nAbout Sidetrade‚ÄØand its amazing R&D team\nSidetrade is a fast-growing international software company that is transforming the Order-to-Cash process for global enterprises. Its AI-powered SaaS platform digitizes the financial customer journey, empowering CFOs to secure and accelerate cash flow generation. Recognized as a Leader in Gartner's Magic Quadrant for two consecutive years, Sidetrade fosters a culture of innovation, collaboration, and customer-centricity from its headquarters in Europe and North America.\nThe R&D team comprises experienced tech professionals who share a deep passion for technology. Together, they are dedicated to developing cutting-edge software solutions that drive the transformation of our customers' work processes. We provide comprehensive training, coaching, resources, and mentorship to empower every team member's growth and nurture their success.\nRequirements\nWhat you will love at Sidetrade:\nWe are seeking a passionate and knowledgeable DevOps SRE Engineer with a multifaceted skill set. Immerse yourself in the exhilarating world of AI and Data Science within our cutting-edge tech environment. Collaborate with like-minded individuals, embracing the latest tools, techniques, and technologies. Fuel your professional growth and innovation within our agile development ecosystem.\nAs a key member of our development team, you will deliver high-quality new features and product enhancements via our online platform. Collaborating with multi-disciplinary teams across the UK and France (with some travel required) will be your forte as you innovate to achieve goals and support the implementation of secure design principles according to policies and standards of Information Security. Explore latest tools and techniques, driving innovation within our R&D team.\nTake control of implementing cutting-edge solutions that optimize our processes. Level up your talent and ignite your development journey!\nWhy you should be working here:\nA strong and demonstrable passion for constantly learning and continuously improving in familiarity with industry leading DevOps/SRE best practices and technologies.\nYou have 5 years+ experience in :\nDeveloping or operating mission-critical systems\nSetup and use of IaC provisioning and deployment tools such as Docker, Terraform and Ansible\nScripting skills with Shell;\nGood knowledge of automation tools\nGood general knowledge of network security (Firewalling, application protection);\nGood knowledge of monitoring tools (Prometheus, grafana, etc.)\nGood knowledge of Linux and Windows systems\nGood knowledge about DNS, DHCP, IPAM, TCP/IP network architectures, HTTP/HTTPS and other Internet protocols.\nYou are aware of security constraints linked to our ISO27001 certification and attached to the roles and responsibilities of this position.\nA plus :\nConcepts and associated tools around containerised and virtualised environments such as Rancher / Kubernetes\nYou worked before with HyperV virtualization technology and Microsoft Azure\nYou speak English fluently, French a plus\nYour first 90 days:\nJoin our Immersive Bootcamp\nReview your onboarding plan with your manager and develop an action plan to achieve your goals\nCollaborate with the team and participate to the roadmap to optimize software performancebuild your internal network across all departments\nExpand your skill set, share your expertise and unlock your full potential\nAt Sidetrade, we cultivate a multicultural environment that fuels innovation. With over 22 nationalities represented, we strongly value diversity, gender equality, inclusivity, and fairness. As an equal opportunity employer, we reject all forms of discrimination and harassment. Your unique contributions are celebrated, driving collective success in our inclusive workplace.\nDiscover more on www.sidetrade.com\nAgencies\nOnly applications from invited agencies through the Workable portal will be accepted. Unsolicited CVs sent directly to managers or HR will not incur any fees.\nShow more\nShow less",
        "details": {
            "JobDetail": [
                "Full"
            ],
            "TypeContract": "",
            "Salary": "",
            "Level": "",
            "Experience": null
        },
        "title": "devops",
        "skills": {
            "ProgLanguage": [
                "R"
            ],
            "DataAnalytics": [
                "R"
            ],
            "CloudComputing": [
                "Azure"
            ],
            "DevTools": [
                "Docker"
            ],
            "OS": [
                "Linux",
                "Windows"
            ],
            "Automation": [
                "Kubernetes",
                "Ansible"
            ],
            "InfrastructureAsCode": [
                "Terraform"
            ],
            "Containers": [
                "Docker",
                "Kubernetes"
            ],
            "Collaboration": [
                "Teams"
            ],
            "Other": [
                "DevOps"
            ],
            "EnSoftSkils": [
                "Collaboration"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "MotorK",
        "location": "Paris, √éle-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/cloud-engineer-at-motork-3892286206?position=8&pageNum=2&refId=UAjmJD%2Bo5LxF5kj2yfoeDg%3D%3D&trackingId=PG5l3xk5UoWMoi2iWIFJtw%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "MotorK is the leading sales and marketing technology company in Europe, specialising in the automotive sector. At MotorK, our mission is to empower manufacturers and dealerships to sell more with innovative, cloud-based products and services to offer the best digital customer experience.\nWe are on a fast and ambitious trajectory and serving 90% of the automotive manufacturers. To continue our growth, we are hiring new talents. If you want to spark the future of the automotive world, join us.\nWe're headquartered in Milan, Italy, where you'll find most of our employees but the teams you'll work with areas across Europe and the UK.\nYou will be the kubernetes expert inside a team of 5 cloud engineers; your role is key to make sure the existing clusters in MotorK are well managed. You will also be the drive for future improvements and implementation of best practices related to k8s and cloud native technologies in MotorK.\nThings you will do:\nIncrease the efficiency of our software development lifecycle thanks to best practices and infrastructure improvements\nBuild and provide tools to increase developer experience\nImprove and scale our cloud infrastructure, making sure governance, cost and security are under control\nDevelop and improve platform monitoring strategies\nPerform capacity management and load testing\nProvide cloud infrastructure support for the entire Research & Development department\nTechnologies you might work with include:\nOrchestration: Kubernetes, Docker\nCloud: AWS, GCP\nWeb: Nginx, Cloudflare\nData: Kafka, MySQL, Postgres, RabbitMQ, MongoDB\nMonitoring: Grafana, Loki, Prometheus\nCode: PHP, Java, Groovy, Python, Javascript\nRequirements\nStrong hands-on production experience on Kubernetes, at least 3 years\nExperience with at least one Cloud Provider, preferably AWS.\nGood to have\nUnderstanding of SRE and DevOps practices\nExperience with Infrastructure as Code (Ansible, Terraform)\nKnowledge of CI/CD\nRelevant experience with RDBMS (mysql, postgres), troubleshooting and optimization\nBackground in Linux environments as Administrator\nExperience on scripting (bash, python)\nPractical knowledge of networking, both cloud and bare-metal\nGood knowledge of monitoring and log collection tools (grafana, prometheus, loki)\nExperience with PHP or Java on k8s is a plus\nExperience with OSS CMS (WordPress, Joomla...) is a plus\nBenefits\nWork pattern and location\nPermanent contract\nHybrid Role\nWhat you can expect from the recruitment process:\nHR interview\nHiring Manager interview, Infrastructure Manager\nC-level interview, VP R&D\nMotorK is an Equal Opportunity Employer and Prohibits Discrimination and Harassment of Any kind. Our company is committed to the principle of equal employment opportunity for all employees and to providing employees with a work environment free of discrimination and harassment. All employment decisions at MotorK are based on business needs, job requirements, and individual qualifications, without regard to race, colour, religion or belief, age, family or parental status, or any other status protected by the laws or regulations in the locations where we operate.\nShow more\nShow less",
        "details": {
            "JobDetail": [],
            "TypeContract": "",
            "Salary": "",
            "Level": "",
            "Experience": null
        },
        "title": "cloud architect /engineer ",
        "skills": {
            "ProgLanguage": [
                "R",
                "Java",
                "Bash",
                "Python"
            ],
            "DataBase": [
                "MongoDB"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [
                "Spark"
            ],
            "CloudComputing": [
                "GCP",
                "AWS"
            ],
            "DevTools": [
                "Docker"
            ],
            "OS": [
                "Linux"
            ],
            "DBMS": [
                "MySQL"
            ],
            "Automation": [
                "Kubernetes",
                "Ansible"
            ],
            "InfrastructureAsCode": [
                "Terraform"
            ],
            "Containers": [
                "Docker",
                "Kubernetes"
            ],
            "Collaboration": [
                "Teams"
            ],
            "Other": [
                "Cloud",
                "DevOps",
                "CI/CD"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "MERITIS",
        "location": "Aix-en-Provence, Provence-Alpes-C√¥te d'Azur, France",
        "link": "https://fr.linkedin.com/jobs/view/devops-engineer-h-f-at-meritis-3815739629?position=9&pageNum=2&refId=UAjmJD%2Bo5LxF5kj2yfoeDg%3D%3D&trackingId=gn8keAP0BuJPdtk6j6WIyQ%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Descriptif de l‚Äôentreprise\n:\nMeritis est une soci√©t√© de conseil sp√©cialis√©e en transformation digitale des organisations, fond√©e en 2007 par S√©bastien Videment.\nInstall√©e initialement √† Paris, elle s‚Äôest d√©ploy√©e en r√©gions et assure d√©sormais une pr√©sence dans les plus grandes villes de France : Sophia-Antipolis, Montpellier, Nantes, Bordeaux, Lyon, Aix-en-Provence, Lille et m√™me √† Lisbonne au Portugal depuis 2023.\nNos experts accompagnent des clients de divers secteurs dans l‚Äôint√©gralit√© de leurs besoins de transformations num√©riques √† travers de nombreux domaines d‚Äôexpertise : Finance, Software Engineering, Cloud & Infrastructure, Data, Transformation Digitale et Cybers√©curit√©.\nFort de ses valeurs d‚Äôexigence, d‚Äôhumilit√©, de bienveillance et de proximit√©, le cabinet de +900 collaborateurs prim√© √† 5 reprises au palmar√®s Great Place To Work¬Æ connait une tr√®s forte croissance et projette d‚Äôatteindre 100M‚Ç¨ de chiffre d‚Äôaffaires en 2024 et de d√©passer la barre symbolique des 1000 collaborateurs.\nNous mettons un point d‚Äôhonneur √† √™tre proche de nos collaborateurs et √† les accompagner de mani√®re individualis√©e quelles que soient leurs fonctions dans l‚Äôentreprise. Certifi√©e Great Place To Work depuis 2013, notre conception du bien-√™tre au travail va bien au-del√† d'un simple label, ce sont nos collaborateurs qui en parlent le mieux : https://www.glassdoor.fr/Avis/Meritis-Avis-E1163008.htm\nDescriptif du poste :\nEn tant que\nIng√©nieur DevOps (H/F),\nvous int√©grerez une entreprise dynamique √©voluant dans un contexte international et un environnement de travail agile. Vos missions seront :\nMettre en place et maintenir les chaines CI/CD de bout en bout\nContribuer aux travaux de fusion de pipelines en vue de rationaliser\nMigrer les pipelines obsol√®tes vers des versions d'outils valid√©es par la strat√©gie entreprise\nD'accompagner les √©quipes de d√©veloppement √† l'appropriation de la m√©thode Devops et des outils mis √† disposition\nParticiper aux r√©flexions de veille sur le p√©rim√®tre du service\nQualification :\nVous avez un dipl√¥me d‚Äôing√©nieur (Bac+5).\nVous disposez d'au moins 5 ans d'exp√©rience dans un environnement DevOps\nVous √™tes issu(e) d'une formation d'ing√©nieur syst√®me et/ou de d√©veloppeur\nVous √™tes dot√©(e) d‚Äôune grande capacit√© d‚Äôadaptation.\nVous r√™vez de progresser entour√©(e) de personnes de tous niveaux d‚Äôexpertise\nOutils / technologies\n:\nJenkins\nGit\nSonar\nCheckmarx\nAngular\nInformations compl√©mentaires\n:\nDes parcours professionnels sur mesure (√©volution de carri√®re, formations adapt√©es, mentoring‚Ä¶) ;‚Äã\nAvoir le choix de sa mission et un accompagnement personnalis√© tout au long de votre carri√®re ;‚Äã\nEvoluer dans un environnement o√π l‚Äôapprentissage est favoris√© : formations certifiantes, e-learning, meetUp, concours de code, parcours d‚Äô√©volutions etc ;‚Äã\nFaire partie de communaut√©s d‚Äôexperts qui partagent leurs savoirs et exp√©riences au sein de nos centres de comp√©tences ;‚Äã\nUn environnement convivial avec de nombreux √©v√©nements festifs (soir√©e annuelle, s√©minaires & teambuiding, d√©jeuners et afterworks‚Ä¶) ;‚Äã\n‚Äã\n\"Meritis est engag√©e dans la Responsabilit√© Soci√©tale des Entreprises. Nous valorisons notre impact positif sur la soci√©t√© et l'environnement. Notre d√©marche RSE guide chacune de nos actions pour promouvoir l'√©quit√©, la durabilit√© et le bien-√™tre de nos collaborateurs. Rejoignez-nous pour √™tre partie prenante de cette d√©marche responsable, o√π chacun de nos talents contribue √† construire un avenir meilleur.\nNos diff√©rences sont nos atouts. C‚Äôest pourquoi Meritis s'implique en faveur de la diversit√© et de la non-discrimination. Tous nos m√©tiers sont accessibles aux personnes en situation de handicap.\"\nShow more\nShow less",
        "details": {
            "JobDetail": [],
            "TypeContract": "",
            "Salary": "",
            "Level": "Bac+5",
            "Experience": "5 an(s)"
        },
        "title": "devops",
        "skills": {
            "DevTools": [
                "Git",
                "Jenkins"
            ],
            "Other": [
                "Cloud",
                "DevOps",
                "CI/CD"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "fifty-five",
        "location": "Paris, √éle-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/lead-cloud-devops-engineer-h-f-at-fifty-five-3883929582?position=10&pageNum=2&refId=UAjmJD%2Bo5LxF5kj2yfoeDg%3D%3D&trackingId=WE4cJ5Wyh6HJDn3VRJhi%2Fw%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Cloud & DevOps Lead\nfifty-five est une data-company d'un genre nouveau qui aide les marques √† exploiter les donn√©es pour am√©liorer le marketing, les m√©dias et l'exp√©rience client gr√¢ce √† une combinaison de services de conseil et de technologie sp√©cialis√©s.\nEn tant que pilier data et marketing du Brandtech Group, nous offrons des services qui combinent le conseil en strat√©gie, les services de cloud, le conseil en m√©dia et l'exp√©rience client.\nfifty-five, c'est plus de 400 experts du num√©rique. Des digital consultants, des sp√©cialistes du tracking et du m√©dia, des ing√©nieurs et des data scientists, travaillent tous en √©troite collaboration pour fournir des conseils marketing de haut niveau et une assistance technique aux marques, dans tout type d'industrie, partout dans le monde.\nPartenaire des annonceurs de la collecte √† l'activation et l'exploitation des donn√©es, nous aidons les organisations √† devenir de v√©ritables entit√©s omnicanales ma√Ætrisant l'efficacit√© de leur √©cosyst√®me digital et ses synergies avec le monde physique.\nBas√© √† Paris, nous op√©rons sur 3 fuseaux horaires depuis nos 10 bureaux, situ√©s √† Paris, Londres, Gen√®ve, Milan, Shanghai, Hong Kong, Shenzhen, Taipei, Singapour et New York. fifty-five attache une importance particuli√®re au bien-√™tre de ses collaborateurs, ce qui lui a permis de figurer dans le classement Best Workplaces France en 2018.\nContexte :\nfifty-five d√©veloppe r√©guli√®rement des nouvelles solutions bas√©es sur du data processing et dans certains cas du machine learning pour r√©pondre aux besoins pr√©cis de ses clients (par exemple: syst√®me de recommandations de produits, d√©tection d'anomalies, ranking).\nL'√©quipe d'Ing√©nierie adresse √† la fois les outils internes ainsi que les projets clients. L'√©quipe Infrastructure au sein de l'√©quipe Ing√©nierie est responsable de l'infrastructure 55, des outils / scripts d'automation ainsi que des best practices Cloud & DevOps que le reste de l'√©quipe est amen√© √† utiliser dans le cadre de leurs projets (internes ou clients). . L'infrastructure 55 recouvre de mani√®re non exhaustive : les outils de d√©veloppement et la stack DevOps (Gitlab, Jupyterhub, Terraform, Docker, Jenkins, etc.), l'h√©bergement des outils d√©velopp√©s en interne (stack Spring Boot / Angular / MongoDB / Keycloak / Vault h√©berg√© sur GKE), les outils de gouvernance cloud (alerting automatique, billing, etc.), les frameworks templatis√©s que les autres membres de l'√©quipe peuvent utiliser dans le cadre de leurs missions clients (architectures Clouds d√©ployables via Terraform et templatis√©es, sur les 3 cloud publics GCP / Azure / AWS). L'√©quipe intervient √©galement sur l'automatisation de diff√©rents process internes : gestion du billing, ERP automations, etc. L'√©quipe Infrastructure regroupe des Cloud Engineers, DevOps Engineers, Software Engineers (Python).\nMission :\nNous sommes √† la recherche de notre Cloud & DevOps Lead qui sera responsable de l'√©quipe Infrastructure. Il aura en responsabilit√© √† la fois la stack technique interne utilis√© par l'Ing√©nierie et son h√©bergement, ainsi que les best practices et frameworks utilis√©s par les autres ing√©nieurs. Son r√¥le :\n√ätre garant de la disponibilit√© et de la s√©curit√© de l'infrastructure\nMettre en place et surveiller les best practices Infra : GitOps, gouvernance Cloud, FinOps\nS'assurer de la bonne r√©utilisabilit√© des composants / frameworks / templates\nAccompagner son √©quipe dans le suivi des t√¢ches, la mont√©e en comp√©tences et l'expertise au quotidien\nComp√©tences et exp√©riences :\nUne premi√®re exp√©rience sur un poste similaire et un minimum de 4 ans d'exp√©rience.\nMa√Ætrise des environnements Cloud. Id√©alement certifi√© GCP, Azure et/ou AWS\nMa√Ætrise de l'Infrastructure as Code (Terraform)\nMa√Ætrise de Docker/Kubernetes\nMa√Ætrise des pratiques GitOps et CI/CD\nMa√Ætrise de Python, SQL et √©ventuellement Java\nUne connaissance des activit√©s IT est un plus (IDP, user management, device management, DNS management, network, etc.)\nEsprit d'√©quipe (collaborer aux tests unitaires, revue de code, partage de code, sprints)\nBon niveau en fran√ßais et en anglais\nNous proposons :\nun bureau au centre de Paris avec terrasse et jardin\nun environnement multiculturel avec des collaborateurs aux nationalit√©s multiples (France, Royaume-Uni, Etats-Unis, Chine, Tunisie, Italie et plus)\ndes projets avec nos bureaux √† Londres, Hong Kong, New York, Shanghai, Gen√®ve, Shenzhen et Taipei\ndes TGIF et supers soir√©es\nShow more\nShow less",
        "details": {
            "JobDetail": [],
            "TypeContract": "",
            "Salary": "",
            "Level": "",
            "Experience": "4 an(s)"
        },
        "title": "devops",
        "skills": {
            "ProgLanguage": [
                "Java",
                "Python"
            ],
            "DataBase": [
                "SQL",
                "MongoDB"
            ],
            "CloudComputing": [
                "GCP",
                "AWS",
                "Azure"
            ],
            "DevTools": [
                "Jenkins",
                "Docker"
            ],
            "Automation": [
                "Kubernetes"
            ],
            "InfrastructureAsCode": [
                "Terraform"
            ],
            "Containers": [
                "Docker",
                "Kubernetes"
            ],
            "Other": [
                "Machine Learning",
                "Cloud",
                "DevOps",
                "CI/CD"
            ],
            "EnSoftSkils": [
                "Collaboration"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "Extia",
        "location": "Paris, √éle-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/data-engineer-devops-h-f-at-extia-3599185622?position=1&pageNum=5&refId=HqnBGIsq%2F7%2BaI9g3tHePPw%3D%3D&trackingId=8vqLx3jIEu9QspJOWI2I1Q%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Vous souhaitez rejoindre une entreprise qui place l‚Äôhumain au c≈ìur de ses pr√©occupations ? On vous attend chez\nExtia\n!\nSoci√©t√© de conseil sp√©cialis√©e dans les m√©tiers de l‚ÄôIT, de l‚Äôing√©nierie et du digital, Extia privil√©gie depuis sa cr√©ation en 2007 une approche qui allie performance et bien-√™tre au travail. Une vision de l‚Äôentreprise partag√©e aujourd‚Äôhui par plus de 2 500 Extiens en France et √† l'international et r√©compens√©e par le label Great Place to Work¬Æ depuis 13 ans, notamment en\n2024 o√π les Extiens se hissent √† la premi√®re place du palmar√®s Best Workplaces France\n!\nChez Extia, c‚Äôest ¬´ D‚Äôabord qui, ensuite quoi ¬ª alors, allons-y !\nD'abord qui\nCurieux, vous adorez partager les derni√®res id√©es innovantes que vous avez d√©couvertes\nRigoureux, vous ne laissez rien au hasard\nPers√©v√©rant, vous ne perdez jamais, soit vous gagnez, soit vous apprenez\nEnsuite quoi\nDans le cadre de votre mission, vos taches principales sont\n:\nL'impl√©mentation de solutions techniques\nSens de l‚Äô√©change avec les diff√©rents √©quipiers, contributeurs de la division Data.\n√âchanges et pr√©paration de demos avec les IT m√©tiers.\nMaintien d'une veille technologique permanente.\nLes comp√©tences techniques\n:\nAnalyse et d√©veloppement\nD√©veloppement en Java jusqu‚Äô√† l‚Äôint√©gration avec les chaines CI/CD\nMaitrise des langages de programmation Java, Scala et Python\nMa√Ætrise de Ansible, Terraform, Kubernetes...\nMa√Ætrise de l‚Äô√©cosyst√®me Hadoop, Spark, Kafka, ElasticSearch\nShow more\nShow less",
        "details": {
            "JobDetail": [],
            "TypeContract": "",
            "Salary": "",
            "Level": "",
            "Experience": "13 an(s)"
        },
        "title": "data engineer",
        "skills": {
            "ProgLanguage": [
                "Java",
                "Scala",
                "Python"
            ],
            "DataBase": [
                "Elasticsearch"
            ],
            "BigData": [
                "Hadoop",
                "Spark"
            ],
            "Automation": [
                "Kubernetes",
                "Ansible"
            ],
            "InfrastructureAsCode": [
                "Terraform"
            ],
            "Containers": [
                "Kubernetes"
            ],
            "Other": [
                "CI/CD"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "Glocomms",
        "location": "France",
        "link": "https://fr.linkedin.com/jobs/view/cloud-security-engineer-at-glocomms-3910052052?position=2&pageNum=5&refId=HqnBGIsq%2F7%2BaI9g3tHePPw%3D%3D&trackingId=uVExhRYAD8wJwPNIWvMIKA%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Senior ServiceNow Consultant\nOffice Location : Toulouse\nFully remote\nEnglish and French speaking project\nContract : 2 year project on a 6 month rolling contract\nStart date: Monday 3rd June\nWe are seeking a skilled and experienced Cloud Security Engineer to join our customer's team. The ideal candidate will be responsible for designing, implementing, and maintaining security measures to protect our cloud-based infrastructure and applications. The Cloud Security Engineer will work closely with our DevOps and IT teams to ensure that our cloud environments meet the highest standards of security and compliance.\nResponsibilities:\nDesign and implement security measures to protect cloud-based infrastructure and applications.\nConduct regular security assessments and audits of cloud environments.\nDevelop and maintain security policies, standards, and procedures for cloud environments.\nImplement access controls, encryption, and other security features to protect data in the cloud.\nMonitor cloud environments for security incidents and respond to incidents in a timely manner.\nWork closely with DevOps and IT teams to integrate security best practices into cloud deployment pipelines.\nStay up-to-date on the latest trends and developments in cloud security and recommend new security technologies and techniques.\nCollaborate with internal teams and external vendors to resolve security issues and implement security solutions.\nRequirements:\nBachelor's degree in Computer Science, Information Security, or a related field.\n5+ years of experience working in cloud security or a related field.\nIn-depth knowledge of cloud platforms such as AWS, Azure, or Google Cloud Platform.\nExperience with cloud security technologies and tools, such as IAM, WAF, and SIEM.\nStrong understanding of networking and network security principles.\nExperience with scripting languages such as Python, PowerShell, or Bash.\nCertifications such as Certified Cloud Security Professional (CCSP), Certified Information Systems Security Professional (CISSP), or AWS Certified Security Specialty are a plus.\nExcellent communication and collaboration skills.\nShow more\nShow less",
        "details": {
            "JobDetail": [
                "Remote",
                "Full",
                "Senior"
            ],
            "TypeContract": "",
            "Salary": "",
            "Level": "",
            "Experience": null
        },
        "title": "cloud architect /engineer ",
        "skills": {
            "ProgLanguage": [
                "Bash",
                "Python"
            ],
            "CloudComputing": [
                "AWS",
                "Google Cloud Platform",
                "Azure"
            ],
            "Collaboration": [
                "Teams"
            ],
            "Other": [
                "Cloud",
                "DevOps"
            ],
            "EnSoftSkils": [
                "Communication",
                "Collaboration"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "Scaleway",
        "location": "France",
        "link": "https://fr.linkedin.com/jobs/view/devops-engineer-block-storage-at-scaleway-3918147786?position=3&pageNum=5&refId=HqnBGIsq%2F7%2BaI9g3tHePPw%3D%3D&trackingId=FH0BUYlAO5FGSyD81OVxUA%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "About the job\nThe Storage Team is one of the pillars of Scaleway. This team not only develops the Scaleway Elements storage products (Block Storage), but also supports all the other Scaleway Elements products that rely on Block Storage (Instances, Database, Registry, Kubernetes, and more) for proper usage. In a challenging environment, and within a team that manages hundreds of storage servers across various regions, you will be responsible for developing, automating, and enhancing Scaleway‚Äôs Block Storage solution.\nThis service launched by Scaleway offers resilient, redundant, and high-availability storage for its numerous clients. Your missions will require programming, automation, and architecture skills. On top of your daily activities within your team, you will need to interact with all of Scaleway‚Äôs teams, especially Instances, Network, Hardware, and Platform.\nMinimum Qualifications\nExperienced System Engineer who is passionate about DevOps best practices and cloud architecture, ideally with over 5 years of experience\nExperience with (and love for) storage systems\nStrong system-level programming skills\nGood understanding of Golang.\nExperience with a continuous integration workflow, Gitlab, and Git\nStrong Linux knowledge\nDistributed systems (and debugging them)\nResponsibilities\nDeploying infrastructure in new Availability Zones\nImproving & bringing forward new ideas for our current infrastructure\nReacting to eventual failures in collaboration with other teams\nPresenting your work during tech meetings\nCoding, peer review, and deployment\nCustomer support in relation to your product\nDeploying your code\nPreferred qualifications\nSolid experience with Ceph in high capacity and/or performance environment\nGreat oral and written communication skills\nInfrastructure deployment with Ansible\nVery good command of English\nTechnical Stack\nCeph\nUbuntu/Debian\nAnsible\nGolang\nProtobuf\nPostgresql\nLocation\nThis position is based in our offices in Paris or Lille (France)\nRecruitment Process\nScreening call - 30 mins with the recruiter\nManager Interview - 45 mins\nTechnical Interviews\nHR Interview - 45 mins\nHead of Interview - 45 mins\nOffer sent - 48 hours\nShow more\nShow less",
        "details": {
            "JobDetail": [],
            "TypeContract": "",
            "Salary": "",
            "Level": "",
            "Experience": null
        },
        "title": "devops",
        "skills": {
            "DevTools": [
                "Git"
            ],
            "OS": [
                "Linux"
            ],
            "DBMS": [
                "PostgreSQL"
            ],
            "Automation": [
                "Kubernetes",
                "Ansible"
            ],
            "Containers": [
                "Kubernetes"
            ],
            "Collaboration": [
                "Teams"
            ],
            "Other": [
                "Cloud",
                "DevOps"
            ],
            "EnSoftSkils": [
                "Communication",
                "Collaboration"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "Cloud Temple",
        "location": "√éle-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/cloud-engineer-storage-at-cloud-temple-3779352432?position=4&pageNum=5&refId=HqnBGIsq%2F7%2BaI9g3tHePPw%3D%3D&trackingId=Gw%2FoyNnClWoTKSlDWpBS7w%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Afin de consolider notre √©quipe Computing & Storage, Cloud Temple vous offre l'opportunit√© de nous rejoindre en tant que Cloud Engineer Storage F/H.\nMISSIONS :\nAu sein de l‚Äô√©quipe de Computing & Storage, vous √™tes responsable du maintien et de l‚Äô√©volution de nos infrastructures compute et virtualisation ainsi que de la stabilit√© du service rendu au client. Vous travaillez sur des infrastructures certifi√©es (SecNumCloud, HDS) avec de fortes contraintes de s√©curit√© et de disponibilit√©.\nEn tant que Cloud Engineer Storage , vous aurez comme mission :\nAssurer la gestion des √©v√®nements et incidents de production\nAssurer une r√©solution rapide en cas d‚Äôincident, identifier les causes racines et amener des correctifs\nMaintenir la conformit√© op√©rationnelle et s√©curitaire des services\nAssurer la gestion des changements en production en validant le niveau de risques en rapport avec les niveaux de service\nParticiper aux projets d‚Äô√©volution et de transformation des infrastructures et services\nAgr√©menter et maintenir une base de connaissances techniques\nAssurer un suivi du traitement des incidents de bout en bout\nExigence du poste :\nNiveau de dipl√¥mes :\nBAC + 5\nComp√©tences requises :\nConnaissance des outils Git, GitLab (CI/CD), Docker, Terraform, Ansible\nMaitrise des concepts ITIL\nConnaissance des produits VMware est un atout\nMaitrise d‚Äôau moins un langage de programmation : Python, Bash, PHP, Golang, JAVA\nMa√Ætrise des environnements UNIX (FeedBSD, Linux, Solaris) et r√©seaux IP\nConnaissances linguistiques :\nAnglais : lu, parl√© et √©crit\nExp√©rience attendue\nAu moins 2 ans sur un poste similaire\nExp√©rience en administration d‚Äôinfrastructure diverse et en gestion d‚Äôenvironnement de production informatique certifi√©s\nConnaissance des architectures des syst√®mes d‚Äôinformation\nMa√Ætrise des protocoles et solutions de stockage standards\nCapacit√© √† automatiser des actions op√©rationnelles au travers des scripts ou de programme\nMa√Ætrise des solutions de supervision des services et leurs performances\nCapacit√© √† proposer et faire √©voluer les process et outils de gestion de la production\nSavoir √™tre attendus\nSens de la qualit√© de service\nCapacit√© d‚Äôadaptation et d‚Äôautomatisation dans un environnement en perp√©tuelle √©volution\nExcellentes comp√©tences organisationnelles\nCapacit√© √† g√©rer les situations de crise\nShow more\nShow less",
        "details": {
            "JobDetail": [],
            "TypeContract": "",
            "Salary": "",
            "Level": "",
            "Experience": "2 an(s)"
        },
        "title": "cloud architect /engineer ",
        "skills": {
            "ProgLanguage": [
                "Java",
                "Bash",
                "Python"
            ],
            "DevTools": [
                "Git",
                "Docker"
            ],
            "OS": [
                "Linux"
            ],
            "Automation": [
                "Ansible"
            ],
            "InfrastructureAsCode": [
                "Terraform"
            ],
            "Virtualisation": [
                "VMware"
            ],
            "Containers": [
                "Docker"
            ],
            "Other": [
                "Cloud",
                "CI/CD"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "Mazars",
        "location": "Paris, √éle-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/devops-engineer-at-mazars-3850005993?position=5&pageNum=5&refId=HqnBGIsq%2F7%2BaI9g3tHePPw%3D%3D&trackingId=VzhP7OXvojAFknR1xckV3g%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Votre poste\nMazars is a leading international audit, tax and advisory firm, aspiring to build the economic foundations of a fair and prosperous world. Operating as a united partnership, Mazars works as one integrated team, leveraging expertise, scale and cultural understanding to deliver exceptional and tailored services in audit and accounting, as well as tax, financial advisory, consulting and legal services*.\nFounded in Europe, Mazars is present in over 95 countries and territories, with 47,000 professionals ‚Äì 30,000 in our integrated partnership, 17,000 via the Mazars North America Alliance ‚Äì dedicated to helping clients make the most of business opportunities and operate with confidence.\n*where permitted under applicable country laws.\nVos principales missions\nThis is a permanent role reporting to Head of Platforms.\nTechnology & digital solutions (T&DS)\nMandated by Mazars Global Executive Board, the Technology & digital solutions team is leading Mazars digital transformation to unleash the next stage of Mazars growth. Specifically, the transformation will allow easier collaboration across geographies, quicker scalable service offering to clients in a safe, modern and sustainable way. As a result, Mazarians will enjoy a seamless experience and deliver more value to clients every day.\nTo reach these goals, Technology & digital solutions transformation programme aims at consolidating the IT operations from a multi-local model spread across 99+ countries into a global model. This includes the infrastructure and the operating model design needed to support Mazars business, people and clients now and in the future.\nThe success of this change relies on the great expertise and relentless engagement of every member of the team. This is a great moment to join the Technology & digital solutions organisation and be part of the delivery of this major transformation over the coming years!\nDevOps Engineer\nRole Purpose, Accountabilities, Experience, Knowledge, And Skills\nWe are looking for a DevOps Engineer to install, maintain, document, upgrade and optimise cloud & hybrid infrastructure while ensuring the reliability, security and availability of said platform, in close collaboration with the entire Global IT programme team.\nKey Responsibilities\nBuild\nManage the deployment of solutions, encompassing both applications and infrastructure, either through hands-on delivery or with third party support\nEnsure that deployments of new solutions comply with Global IT Enterprise Architectural standards\nOversee the handover of solutions into relevant service management teams via preparation of appropriate documentation and relevant training\nImagine, architect, develop, deploy, and evolve CI and CD systems for our cloud applications\nWrite Infrastructure as Code (IaC) using industry standard tools and services\nWrite application deployment automation using industry standard deployment and configuration tools\nRun\nProvide support and day to day administrator for deployed solutions\nOversee incident management activities related to global solutions and liaise with third party support partners through to resolution\nMonitor deployed solutions to ensure they are operating in an optimal manner\nManage patching, upgrades, service packs of compute components\nMaintain relevant documentation over the lifecycle of solutions ensuring they are kept up to date.\nVotre profil\nYou speak fluent English, and at least one other European language (French, Dutch, Spanish, ...)\nGood knowledge of IT best practices and design patterns.\nExcellent knowledge of (hybrid) cloud concepts and technologies, preferably utilizing Azure and Microsoft technologies. You are familiar with governance, monitoring, IAM, storage and server(less) infrastructure, and container concepts.\nCI/CD pipelines have no secrets for you anymore: you have a good experience in building a continuous delivery process: version management, automation, infrastructure as code\nKnowledge of Bicep.\nYou should be curious and fast at picking up new things with a sharp eye for details.\nYou should be eager to grow your skills and to embrace new challenges.\nPreferred Certifications\nAZ-104, AZ-900 preferred.\nAZ-400 highly desired\nShow more\nShow less",
        "details": {
            "JobDetail": [],
            "TypeContract": "",
            "Salary": "",
            "Level": "",
            "Experience": null
        },
        "title": "devops",
        "skills": {
            "CloudComputing": [
                "Azure"
            ],
            "Collaboration": [
                "Teams"
            ],
            "Other": [
                "Cloud",
                "DevOps",
                "CI/CD"
            ],
            "EnSoftSkils": [
                "Collaboration"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "Matomo",
        "location": "Paris, √éle-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/senior-cloud-devops-engineer-100%25-remote-europe-at-matomo-3883003015?position=6&pageNum=5&refId=HqnBGIsq%2F7%2BaI9g3tHePPw%3D%3D&trackingId=Kj%2FyEJBxdVKXnGaTrsZNmg%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Introduction\nWe‚Äôre looking for an experienced DevOps engineer to work on our cloud hosted SaaS platform. We are the creators of Matomo, the leading open source web analytics solution that gives people full control of their data and built-in privacy. We have challenges to solve and need you!\nWe are fully remote and we collaborate online. We are a small, flexible team, and when you come onboard you will play an integral part in engineering. You‚Äôll help us to make our products better and deliver a great experience to our customers.\nKey Responsibilities\nBuild, manage and automate our SaaS web analytics platform on AWS\nEnsuring availability, performance, security, and scalability of the platform\nMaintain and improve CI/CD pipelines, Infrastructure as code, monitoring and alerting systems\nSupport software development, product and customer support teams to achieve business outcomes\nTake ownership of technical issues, and work with the team to resolve more advanced issues when necessary\nRespond to application and security incidents via a rotating On-Call schedule (two thirds of the time, including nights and weekends)\nMinimum Qualifications\n5+ years commercial experience working with the AWS cloud\nProficient with modern IaC tooling (e.g., Terraform, Cloud Formation, Pulumi)\nProficient in at least 1 popular scripting languages (e.g., Python, Typescript/Javascript)\nProficient in container technologies (e.g., Docker, Docker Compose, Kubernetes)\nProficient in Linux systems and shell scripting\nProficient in declarative modern CI/CD patterns (e.g., GitHub Action, Bitbucket Pipeline, GitLab CI/CD)\nProficient with modern software engineering workflows (e.g., Git, pull request, code review)\nUnderstanding of network topologies, high availability principles\nUnderstanding of monitoring concepts (e.g., metrics, dimensions, log analysis)\nStrong analytical skills and a passion for it to understand complex business logic\nGreat communication and collaboration skills\nAbility to work independently\nWilling to provide on-call support\nNice to have\nWorking knowledge of PHP\nMySQL server and SQL query optimisation\nLocation\n100% Remote work position ( Candidates must be willing to work a minimum of 4 hours overlapping with New Zealand per week)\nBenefits\nRemote work (save many hours on commute, and save money)\nCo-working space paid for and/or work from home\nAll home office equipment paid for (laptop, desk, chair, standing desk, lights, etc.)\nFlexible hours\n25 days of paid holidays per year plus your national public holidays\nSick leave\nHealth Insurance: Your Well-being, Our Priority\nA huge ‚Äúplayground‚Äù to grow your skill set\nVolunteering Day: Empower Your Impact\nBereavement Leave for Pets: Compassion Beyond Boundaries\nTraining Opportunities\nMental Health Support Services\nOpportunity to work in a customer obsessed business, dedicated to building high-quality software with a strong mission of helping people grow their web projects while keeping full control of their data\nOpportunity to have an immediate impact on a product that is used by more than 1 million websites and almost 2% of the whole Internet\nAbout InnoCraft And Matomo Analytics\nAt InnoCraft, we offer analytics products and SaaS to enable our users to grow their business. We believe in openness, privacy and 100% data ownership. Our mission is to liberate analytics and we are passionate about measuring for success. That‚Äôs why we created Matomo Analytics, the leading open source analytics platform used on more than 1 million websites and apps in over 150 countries, available in more than 50 languages. The Matomo platform collects, stores and processes a lot of information: hundreds of millions of data points each month. We create intuitive, simple and beautiful reports that delight our users.\nInnoCraft celebrates the things that make you, you! We are an inclusive employer and do not discriminate against any employee or applicant for employment because of race, color, religion, sex, sexual orientation, gender identity, national origin, age, marital status or disability. We actively seek diver\nsity in our workplace and embrace individuals with unique backgrounds, perspectives, and abilities!\nCome join our growing team that‚Äôs helping ensure a safer, more privacy focused web/internet!\n#Hiring\nShow more\nShow less",
        "details": {
            "JobDetail": [
                "Remote",
                "Full"
            ],
            "TypeContract": "",
            "Salary": "",
            "Level": "",
            "Experience": null
        },
        "title": "devops",
        "skills": {
            "ProgLanguage": [
                "Python"
            ],
            "DataBase": [
                "SQL"
            ],
            "CloudComputing": [
                "AWS"
            ],
            "DevTools": [
                "Git",
                "Docker"
            ],
            "OS": [
                "Linux"
            ],
            "DBMS": [
                "MySQL"
            ],
            "Automation": [
                "Kubernetes"
            ],
            "InfrastructureAsCode": [
                "Terraform"
            ],
            "Containers": [
                "Docker",
                "Kubernetes"
            ],
            "Collaboration": [
                "Teams"
            ],
            "Other": [
                "Cloud",
                "DevOps",
                "CI/CD"
            ],
            "EnSoftSkils": [
                "Communication",
                "Collaboration"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "STATION F",
        "location": "Paris, √éle-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/devops-cloud-engineer-at-station-f-3824854750?position=7&pageNum=5&refId=HqnBGIsq%2F7%2BaI9g3tHePPw%3D%3D&trackingId=Pw4vpsKQ6r4WBJqY6iKyAg%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "√Ä propos\nAllphins is the leading InsurTech company that provides risk management solutions for the insurance industry.\nAfter starting as a member of the Lloyd's Lab (reputable Insurtech accelerator in London) and being hosted at Station F (Paris), we now help 25+ clients cover all major commercial lines including Property, Energy, Political Risk, Trade Credit, Cyber, Casualty & Terrorism. Our goal is to help (re)insurers better analyse risks and make the right decisions.\nWith a strong international presence (UK & US) and self-financed growth (from 4 to 15 employees in 2 years), we seek to become the leading risk management platform for speciality risks.\nDescriptif du poste\nActivity\nAs a Cloud Devops at Allphins you will :\nImprove, maintain the current cloud infrastructure and helping the development team to scale the application\nApply site reliability engineering practices to a service (?)\nInsure the security of the app\nDevelop CI/CD for containerize application\nImplement infrastructure monitoring and optimize service performance\nEnsure the quality of the various release\nTechno\nCloud provider: GCP ( GKE, Network stack, Dataproc,...)\nContainerize app deploiment : Docker, Helm, kubernetes\nInfra as Code: Terraform\nCode versioning: Git\nDatabase technology: Postgresql, redis\nCode base: Python\nTechno Nice To Have\nKnowledge in big data architecture (using sprak, airflow etc‚Ä¶)\nKnowledge in API development in python\nCode quality tools\nSoftskills\nExperience working with the scrum methodology\nProfil recherch√©\nBackground : Master + 5 - Engineer\nExperience : 2 - 5 years\nSignificant experience as a devops engineering in a GCP environment.\nNice to have : you have already worked in a start up environment\nFluent in english\nWork at Allphins\n‚òÄÔ∏è Key responsibilities: autonomy, impact & strong visibility\nüåè Work in an international environment\nüí∏ Attractive remuneration (with benefits : Swile Card, Alan..)\nüíª Hybrid working possible (2/3 days remote)\nüöÄ Great career opportunities & solid learning\nüè¢ Offices in the center of Paris (WeWork Jules Lefebvre)\nü¶æ High-end equipments (tools & technologies)\nüèñÔ∏è One off-site per year\nProcess de recrutement\nInterview HR\nTech interview and case study\nInterview with Jean-Baptiste, CTO and co founder\nInformations compl√©mentaires\nType de contrat : CDI\nLieu : Paris\nNiveau d'√©tudes : Bac +5 / Master\nExp√©rience : > 4 ans\nT√©l√©travail partiel possible\nSalaire : entre 49996‚Ç¨ et 60000‚Ç¨ / an\nShow more\nShow less",
        "details": {
            "JobDetail": [
                "Remote"
            ],
            "TypeContract": "CDI",
            "Salary": "49996",
            "Level": "",
            "Experience": "4 an(s)"
        },
        "title": "devops",
        "skills": {
            "ProgLanguage": [
                "Python"
            ],
            "CloudComputing": [
                "GCP"
            ],
            "DevTools": [
                "Git",
                "Docker"
            ],
            "DBMS": [
                "PostgreSQL"
            ],
            "Automation": [
                "Airflow",
                "Kubernetes"
            ],
            "InfrastructureAsCode": [
                "Terraform"
            ],
            "Containers": [
                "Docker",
                "Kubernetes"
            ],
            "Other": [
                "Cloud",
                "Big Data",
                "DevOps",
                "CI/CD"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "Harnham",
        "location": "Paris, √éle-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/cloud-engineer-azure-at-harnham-3850370394?position=8&pageNum=5&refId=HqnBGIsq%2F7%2BaI9g3tHePPw%3D%3D&trackingId=xYNN2NVn%2F32kEONH7jx09A%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Cloud Engineer\nMinimum 1 an d'exp√©rience en tant que Cloud engineer\nParis\n2jTT\nCDI\nNous sommes √† la recherche d'un(e) Cloud Engineer talentueux(se) pour rejoindre une √©quipe dynamique dans le secteur du retail. En tant que Cloud Engineer, vous serez au c≈ìur de notre transformation digitale, contribuant √† la conception, √† la mise en ≈ìuvre et √† la maintenance de l'infrastructure cloud.\nStack technique : Azure, Powershell, ElasticSearch, Kibana, Grafana,\nResponsabilit√©s Principales:\nConcevoir, d√©ployer et g√©rer notre infrastructure cloud sur Microsoft Azure, garantissant sa stabilit√©, sa s√©curit√© et sa performance.\nD√©velopper des solutions d'automatisation pour le provisionnement, la configuration et la gestion des ressources cloud.\nCollaborer √©troitement avec les √©quipes techniques et m√©tier pour comprendre les besoins et proposer des solutions cloud adapt√©es.\nAssurer la conformit√© aux normes de s√©curit√© et de gouvernance cloud.\nSurveiller et optimiser les performances des services cloud pour garantir une exp√©rience utilisateur optimale.\nQualifications Recherch√©es:\nDipl√¥me de Master en informatique ou dans un domaine connexe, ou exp√©rience √©quivalente avec au moins 1 an d'exp√©rience dans un poste similaire.\nExp√©rience av√©r√©e dans la conception, la mise en ≈ìuvre et la gestion d'infrastructures cloud, de pr√©f√©rence sur\nMicrosoft Azure\n.\nMa√Ætrise des outils et technologies DevOps, notamment\nAzure DevOps, PowerShell et Terraform\n.\nConnaissance approfondie des technologies de conteneurisation telles que\nKubernetes\n.\nExp√©rience avec Elastic Search serait un atout.\nForte passion pour l'innovation et la r√©solution de probl√®mes, avec une orientation vers l'automatisation et l'am√©lioration continue.\nCapacit√© √† travailler de mani√®re proactive et autonome, avec un excellent esprit d'√©quipe.\nMa√Ætrise du fran√ßais et de l'anglais est n√©cessaire.\nShow more\nShow less",
        "details": {
            "JobDetail": [],
            "TypeContract": "CDI",
            "Salary": "",
            "Level": "",
            "Experience": null
        },
        "title": "cloud architect /engineer ",
        "skills": {
            "DataBase": [
                "Elasticsearch"
            ],
            "CloudComputing": [
                "Azure"
            ],
            "Automation": [
                "Kubernetes"
            ],
            "InfrastructureAsCode": [
                "Terraform"
            ],
            "Containers": [
                "Kubernetes"
            ],
            "Other": [
                "Cloud",
                "DevOps"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "OPEN",
        "location": "Levallois-Perret, √éle-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/cloud-architect-azure-h-f-at-open-3720167006?position=9&pageNum=5&refId=HqnBGIsq%2F7%2BaI9g3tHePPw%3D%3D&trackingId=AGVc%2FDQYvXNEzb09Qzum5A%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Qui sommes-nous ?\nRejoindre la BU Cloud & DevOps, c‚Äôest rejoindre La communaut√© d'experts techniques qui accompagne des sujets strat√©giques et transverses pour Open France.\nVous serez en charge d'accompagner et conseiller nos clients autour des sujets Microsoft Cloud Azure depuis l‚Äôexpression et la collecte de leurs besoins fonctionnels.\nVos missions d√©taill√©es\nD√©finir les architectures cibles Cloud et Hybride qui vont soutenir les briques du SI Client et capitaliser sur les projets pour d√©finir nos standards d‚Äôarchitecture.\nD√©finir les chemins de migration et de transition des applications et des workloads clients vers Microsoft Azure,\nImpl√©menter ou coordonner l‚Äôint√©gration des architectures et des solutions propos√©es,\nAccompagner nos forces de vente dans les soutenances des dossiers de r√©ponse complexes,\nParticiper activement √† la conception des nouvelles offres, en capitalisant sur les projets et les architectures d√©j√† produites.\nVous\nDisposez d‚Äôune premi√®re exp√©rience significative dans la conception d‚Äôarchitecture de solutions et de services Cloud/SaaS privil√©gi√©s sur Microsoft Cloud Azure,\nMaitrisez sur le plan technique les concepts d‚Äôarchitecture en Cloud Public : Microsoft Azure, IaaS/PaaS/SaaS, Azure Stack(s), solutions hybrides et multicloud, s√©curit√© et gouvernance du Cloud, modernisation d‚Äôapplications et de donn√©es,\nAimez travailler en √©quipe et dans la bonne humeur,\nAvez le sens du service,\nAvez le go√ªt du challenge et la culture du r√©sultat,\nü§ù Vous √™tes mettre de votre carri√®re : Comment ?\nInt√©grer des projets transverses et strat√©giques : outils interne, meetup, summit, formation, avant-ventes, chiffrage, veille, audit SI ‚Ä¶\nEvoluer vers votre r√¥le gr√¢ce √† un accompagnement personnalis√© et un parcours de formation et certifications adapt√©.\nNotre process de recrutement\nBref √©change t√©l√©phonique\nRencontre RH pour parler de vous, de vos aspirations professionnelles et vous pr√©senter Open,\nEchange avec l‚Äôun des experts\nTemps de partage avec votre futur manager.\n‚úÖApr√®s vous avoir souhait√© la bienvenue vous b√©n√©ficiez d‚Äôun parcours d‚Äôint√©gration sur-mesure.\nCODE REC : ACH23516\nQu‚Äôattendez-vous pour √™tre Open ?\nShow more\nShow less",
        "details": {
            "JobDetail": [
                "Hybride"
            ],
            "TypeContract": "",
            "Salary": "",
            "Level": "",
            "Experience": null
        },
        "title": "data architect",
        "skills": {
            "CloudComputing": [
                "Azure"
            ],
            "Other": [
                "Cloud",
                "DevOps"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "fifty-five",
        "location": "Paris, √éle-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/senior-data-cloud-engineer-h-f-at-fifty-five-3915044673?position=10&pageNum=5&refId=HqnBGIsq%2F7%2BaI9g3tHePPw%3D%3D&trackingId=7%2BtFXlpUGRyTUk0pTaMArg%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Senior Data & Cloud Engineer\nfifty-five est une data-company d'un genre nouveau qui aide les marques √† exploiter les donn√©es pour am√©liorer le marketing, les m√©dias et l'exp√©rience client gr√¢ce √† une combinaison de services de conseil et de technologie sp√©cialis√©s.\nEn tant que pilier data et marketing du Brandtech Group, nous offrons des services qui combinent le conseil en strat√©gie, les services de cloud, le conseil en m√©dia et l'exp√©rience client.\nfifty-five, c'est plus de 400 experts du num√©rique. Des digital consultants, des sp√©cialistes du tracking et du m√©dia, des ing√©nieurs et des data scientists, travaillent tous en √©troite collaboration pour fournir des conseils marketing de haut niveau et une assistance technique aux marques, dans tout type d'industrie, partout dans le monde.\nPartenaire des annonceurs de la collecte √† l'activation et l'exploitation des donn√©es, nous aidons les organisations √† devenir de v√©ritables entit√©s omnicanales ma√Ætrisant l'efficacit√© de leur √©cosyst√®me digital et ses synergies avec le monde physique.\nBas√© √† Paris, nous op√©rons sur 3 fuseaux horaires depuis nos 10 bureaux, situ√©s √† Paris, Londres, Gen√®ve, Milan, Shanghai, Hong Kong, Shenzhen, Taipei, Singapour et New York. fifty-five attache une importance particuli√®re au bien-√™tre de ses collaborateurs, ce qui lui a permis de figurer dans le classement Best Workplaces France en 2018.\nContexte :\nL'√©quipe d'ing√©nierie d√©veloppe et met en ≈ìuvre les solutions techniques permettant la r√©alisation de pipelines de donn√©es et l'impl√©mentation de data platform pour nos clients : r√©cup√©ration de datas sur de multiples sources de donn√©es (APIs, files, etc.), data cleaning, data processing, automation et monitoring de l'ensemble. L'√©quipe s'appuie sur des technologies r√©centes (docker, kubernetes, terraform, notebooks, etc.) et met en place ses projets dans les diff√©rents clouds du march√© (GCP, Azure, AWS...).\nMission :\nNous sommes √† la recherche d'une personne capable de r√©aliser des projets techniques pour r√©pondre aux besoins de nos clients (par exemple: syst√®me de recommandations de produits, d√©tection d'anomalies, ranking). Les activit√©s vont du chiffrage et du sizing technique √† la mise en ≈ìuvre des architectures, en passant par la revue des sp√©cifications fonctionnelles et la production de code. Le Data & Cloud Engineer sera √©paul√© par un Lead dans ses missions. Il sera √©galement amen√© √† participer √† la R&D et √† accompagner les √©quipes transverses dans la mise en place d'outils de travail internes (librairies pour les data scientists, environnement Notebooks pour les data analysts et data scientists, d√©veloppement de frameworks sur diff√©rents cloud providers, etc.).\nNous souhaitons trouver la bonne personne pour faire √©voluer ou cr√©er de nouvelles solutions dans ce cadre. Les missions comprennent aussi bien du prototypage rapide pour des d√©monstrateurs, que de la production de code robuste qui tourne en production tous les jours.\nComp√©tences et exp√©riences :\n4-5 ans d'exp√©rience en tant que Data Engineer\nMa√Ætrise de Python, SQL\nMa√Ætrise des environnements Cloud. Id√©alement certifi√© GCP, Azure ou AWS\nBonne connaissance de Docker/Kubernetes\nBonne connaissance d'au moins un data warehouse (BigQuery, Snowflake, etc)\nConnaissance autour des Notebooks (Jupyter)\nA l'aise avec des concepts li√©s aux APIs (OAuth, REST, etc.)\nA l'aise avec les notions d'Infrastructure as Code (Terraform)\nAu courant des pratiques GitOps et connaissances des concepts autour du CI/CD\nLa ma√Ætrise d'un orchestrateur, comme Apache Airflow, est un plus\nEsprit d'√©quipe (collaborer aux tests unitaires, revue de code, partage de code, sprints)\nBon niveau en fran√ßais et en anglais\nA d√©j√† travaill√© en mode projet avec des interlocuteurs vari√©s (consultant, data analyst, data scientist)\nUne exp√©rience en marketing digital est un plus\nNous proposons :\nun bureau au centre de Paris avec terrasse et jardin\nun environnement multiculturel avec des collaborateurs aux nationalit√©s multiples (France, Royaume-Uni, Etats-Unis, Chine, Tunisie, Italie et plus)\ndes projets avec nos bureaux √† Londres, Hong Kong, New York, Shanghai, Gen√®ve, Shenzhen et Taipei\ndes TGIF et supers soir√©es\nShow more\nShow less",
        "details": {
            "JobDetail": [
                "Senior"
            ],
            "TypeContract": "",
            "Salary": "",
            "Level": "",
            "Experience": "5 an(s)"
        },
        "title": "data engineer",
        "skills": {
            "ProgLanguage": [
                "R",
                "Python"
            ],
            "DataBase": [
                "SQL"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [
                "Apache Airflow"
            ],
            "CloudComputing": [
                "GCP",
                "AWS",
                "Azure"
            ],
            "DevTools": [
                "Docker"
            ],
            "DBMS": [
                "BigQuery",
                "Snowflake"
            ],
            "Automation": [
                "Airflow",
                "Kubernetes"
            ],
            "InfrastructureAsCode": [
                "Terraform"
            ],
            "Containers": [
                "Docker",
                "Kubernetes"
            ],
            "Other": [
                "Cloud",
                "CI/CD"
            ],
            "EnSoftSkils": [
                "Collaboration"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "Renesas Electronics",
        "location": "Paris, √éle-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/site-reliability-engineer-ai-workbench-at-renesas-electronics-3897557499?position=1&pageNum=7&refId=AufKBH3ju6SkIv6PYkccnA%3D%3D&trackingId=QHi7IVm2AaSJ6sD8ezDFGg%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Company Description\nRenesas is one of the top global semiconductor companies in the world. We strive to develop a safer, healthier, greener, and smarter world, and our goal is to make every endpoint intelligent by offering product solutions in the automotive, industrial, infrastructure and IoT markets. Our robust product portfolio includes world-leading MCUs, SoCs, analog and power products, plus Winning Combination solutions that curate these complementary products. We are a key supplier to the world‚Äôs leading manufacturers of electronics you rely on every day; you may not see our products, but they are all around you.\nRenesas employs roughly 21,000 people in more than 30 countries worldwide. As a global team, our employees actively embody the Renesas Culture, our guiding principles based on five key elements: Transparent, Agile, Global, Innovative, and Entrepreneurial. Renesas believes in, and has a commitment to, diversity and inclusion, with initiatives and a leadership team dedicated to its resources and values. At Renesas, we want to build a sustainable future where technology helps make our lives easier. Join us and build your future by being part of what‚Äôs next in electronics and the world.\nOverview\nJob Description\nWe are seeking a skilled and experienced Site Reliability Engineer to join our team. In this role, you will be part of the AI & Cloud Engineering (ACE) Division and AI Workbench team. Our AI Workbench is a cloud-based environment to accelerate Automotive AI Software Development and Evaluation. The AI Workbench has 4 main functional blocks today, with one of those blocks providing access to both SILS (Software in the Loop Simulator) and HILS (Hardware in the Loop‚ÄØSimulator).\nAs a Site Reliability Engineer - ACE, you will be responsible for designing, building, and maintaining our infrastructure. You should have a strong background in cloud technologies and excellent problem-solving skills. You will work closely with multiple engineering teams (and cross-function teams) to support their infrastructure requirements.\nOur division‚Äôs mission is to use the latest AI and cloud technologies to develop the best AI inference for advanced driver safety engineers building self-driving vehicles and other high performance compute products. Renesas is the leading automotive electronics supplier globally, and this is a rare opportunity to develop the infrastructure required to deploy our AI software to the billions of devices we ship to customers every year. You will join our newly formed AI & Cloud Engineering organization of around 100 software engineers. Due to strong demand for our AI-related products we are planning to triple in size in the next three years, so there is lots of room for you to help us grow the team together while remaining small. Our team‚Äôs key locations are Tokyo, London, Paris, Dusseldorf, Beijing, Singapore, Ho Chi Minh City and other metropolitan areas, but you can also join fully remotely from other locations globally or get our support to relocate to our key hubs such as Tokyo.\nResponsibilities\nDesign, build, and maintain our division‚Äôs infrastructure that supports our application development, with a focus on reliability, scalability, and performance.\nImplement and automate deployment, monitoring, and scaling processes to ensure the smooth operation of our systems and services.\nMonitor system performance and reliability metrics, troubleshoot issues, and implement solutions to prevent downtime and improve efficiency.\nCollaborate with our teams Engineers to design, develop, and deploy reliable and scalable applications.\nDevelop and maintain tools and scripts for automation, configuration management, and monitoring of our infrastructure and applications.\nRespond to incidents and emergencies to minimize downtime and ensure reliability of or systems.\nContinuously evaluate and improve our infrastructure, processes, and practises to enhance reliability, scalability, and efficiency.\nStay up-to-date with industry trends, best practises, and emerging technologies in site reliability engineering and cloud computing.\nQualifications\nBachelor‚Äôs or Master‚Äôs degree in Computer Science, Information Technology, or related field.\nExperience working as a Site Reliability Engineer or in a similar role.\nProgramming skills in languages such as Python, Java, or similar.\nHands-on experience with cloud platforms such as AWS, Azure, or GCP.\nExperience with containerization technologies such as Docker and container orchestration platforms such as Kubernetes.\nProficiency in Linux system administration, shell scripting, and network troubleshooting.\nExperience with infrastructure as code tools such as Terraform, Ansible, or similar.\nKnowledge of CI/CD pipelines and automated testing frameworks.\nStrong analytical and problem-solving.\nExcellent communication and collaboration skills.\nAdditional Information\nRenesas Electronics Corporation empowers a safer, smarter and more sustainable future where technology helps make our lives easier. The leading global provider of microcontrollers, Renesas combines our expertise in embedded processing, analog, power and connectivity to deliver complete semiconductor solutions. These Winning Combinations accelerate time to market for automotive, industrial, infrastructure and IoT applications, enabling billions of connected, intelligent devices that enhance the way people work and live. Learn more at www.renesas.com.\nRenesas‚Äô mission, To Make Our Lives Easier, is underpinned by our company culture, TAGIE. TAGIE stands for Transparent, Agile, Global, Innovative and Entrepreneurial. Our goal is to embed this unique culture in everything we do to succeed as a company and create trust with our diverse colleagues, customers and stakeholders.\nRenesas Electronics is an equal opportunity and affirmative action employer, committed to supporting diversity and fostering a work environment free of discrimination on the basis of sex, race, religion, national origin, gender, gender identity, gender expression, age, sexual orientation, military status, veteran status, or any other basis protected by law. For more information, please read our Diversity & Inclusion Statement.\nShow more\nShow less",
        "details": {
            "JobDetail": [
                "Remote",
                "Full"
            ],
            "TypeContract": "",
            "Salary": "",
            "Level": "",
            "Experience": null
        },
        "title": "Other",
        "skills": {
            "ProgLanguage": [
                "Java",
                "Python"
            ],
            "CloudComputing": [
                "GCP",
                "AWS",
                "Azure"
            ],
            "DevTools": [
                "Docker"
            ],
            "OS": [
                "Linux"
            ],
            "Automation": [
                "Kubernetes",
                "Ansible"
            ],
            "InfrastructureAsCode": [
                "Terraform"
            ],
            "Containers": [
                "Docker",
                "Kubernetes"
            ],
            "Collaboration": [
                "Teams"
            ],
            "Other": [
                "Cloud",
                "CI/CD"
            ],
            "EnSoftSkils": [
                "Leadership",
                "Communication",
                "Organization",
                "Collaboration"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "CoinMarketCap",
        "location": "France",
        "link": "https://fr.linkedin.com/jobs/view/senior-devops-engineer-tech-at-coinmarketcap-3885180166?position=2&pageNum=7&refId=AufKBH3ju6SkIv6PYkccnA%3D%3D&trackingId=oTeLOiEUH%2BDc3IH6Xb%2FN0g%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Company Description\nPOWERING CRYPTO WITH DATA\nCoinMarketCap is the world‚Äôs most trusted and accurate source of data for cryptocurrencies. Used by millions of individuals, organizations, and exchanges, CoinMarketCap brings the most up-to-date market capitalizations, pricing, and cryptocurrency information to our users.\nPulling data from multiple exchanges and combining our robust research allows us to provide the most realistic representation of each cryptocurrency. As we grow, we will continue to provide access to our data wherever, whenever, and however is most helpful to our users.\nCREATING AN OPEN WORLD\nOur mission is to be the world‚Äôs authority on cryptocurrency data. We believe in an open and Decentralized world, where we play a pivotal role in powering decisions and insights to drive greater understanding and adoption of cryptocurrencies. We want to achieve this mission with people who truly believe in the value and potential of empowering individuals.\nJob Description\nImprove the stability and availability of global infrastructure and services\nDevelop and maintain automation CI/CD solutions for the company's products and services\nProactively collaborate with other teams and collect feedback to improve existing solutions\nEvaluate new technology options and vendor products to improve the company's automation capabilities\nEngage in and improve the whole lifecycle of service, from inception and design, through to deployment, operation, and refinement\nDevelop and maintain tools, re-designing capacity planning infrastructure for greater scalability\nTroubleshooting, diagnosing, fixing software issues, and ensuring data security\nDefine architecture improvements, and push for changes that improve reliability\nQualifications\nAt least 6 years extensive experience with AWS in Blockchain/Fintech industry\nExperience in large-scale, distributed systems\nExperience with tools such as Kubernates, Docker, Ansible, Terraform, etc\nDemonstrated programming skills in NodeJS, Python, Golang, or similar\nFamiliarity with CI/CD tools such as K8s, GitHub Action, Prow, ArgoCD, etc\nExperience with full-stack development is a plus\nAdditional Information\nWorking at CoinMarketCap\nDo something meaningful; Be a part of the future of finance technology and the leading company in the industry\nFast moving, challenging and unique business problems\nInternational work environment, flat organization, flexible working hours\nGreat career development opportunities in a growing company\nPossibility for relocation and international transfers mid-career\nCompetitive salary\nBy submitting a job application, you confirm that you have read and agree to our Candidate Privacy Notice.\nShow more\nShow less",
        "details": {
            "JobDetail": [
                "Full"
            ],
            "TypeContract": "",
            "Salary": "Salary",
            "Level": "",
            "Experience": null
        },
        "title": "devops",
        "skills": {
            "ProgLanguage": [
                "Python"
            ],
            "CloudComputing": [
                "AWS"
            ],
            "DevTools": [
                "Docker"
            ],
            "Automation": [
                "Ansible"
            ],
            "InfrastructureAsCode": [
                "Terraform"
            ],
            "Containers": [
                "Docker"
            ],
            "Collaboration": [
                "Teams"
            ],
            "Other": [
                "CI/CD"
            ],
            "EnSoftSkils": [
                "Organization"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "Ansys",
        "location": "Lyon",
        "link": "https://fr.linkedin.com/jobs/view/senior-devops-engineer-f-m-at-ansys-3918759103?position=3&pageNum=7&refId=AufKBH3ju6SkIv6PYkccnA%3D%3D&trackingId=51WT2uSnMtMPyEJbMOkI5A%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Requisition #:\n14312\nOur Mission: Powering Innovation That Drives Human Advancement\nWhen visionary companies need to know how their world-changing ideas will perform, they close the gap between design and reality with Ansys simulation. For more than 50 years, Ansys software has enabled innovators across industries to push boundaries by using the predictive power of simulation. From sustainable transportation to advanced semiconductors, from satellite systems to life-saving medical devices, the next great leaps in human advancement will be powered by Ansys.\nInnovate With Ansys, Power Your Career.\nSummary / Role Purpose\nAnsys is seeking a Senior DevOps Engineer to be part of a rapidly growing team that‚Äôs responsible for design, development, build and delivery of technology components that are consumed in different Ansys products. You will be working closely with Development and QA engineers, to deploy and manage GitHub, ADO pipelines, and with operations staff to ensure that systems are up and running smoothly.\nKey Duties And Responsibilities\nPerforms all DevOps activities, including the implementation, maintenance, monitoring, and verification of product builds and packaging to provide quality production builds\nUnderstands and employs best practices\nWorks closely with development to adjust builds and packaging to changing product requirements\nAnticipates future needs and technology evolution and proposes and participates in implementation of new solutions\nCreate sustainable systems and services through automation and uplifts\nDesign, build and maintain CI/CD pipelines in multiple environments and CSP\nMinimum Education/Certification Requirements And Experience\nBS in Engineering, Computer Science, or related field with 5 years‚Äô experience, MS with 3 years‚Äô experience, or PhD with 1 year experience in an Infrastructure/DevOps Engineering role\nExperience with CI/CD pipelines end-to-end, from code commits to production\nExperience with Azure DevOps (and Yaml)\nExperience with Conan, NuGet, wheel packages\nProficient in multiple scripting languages (e.g., Python, PowerShell, Bash)\nSource/version control (Git)\nGitHub actions\nExperience in installing, configuring and troubleshooting Windows & Linux based environments\nSelf-driven desire to continuously learn new technologies and skills, and solve tough problems\nAwareness of DevOps and Agile principles and the ability to apply them\nPreferred Qualifications And Skills\nExperience with Container technologies such as Docker\nExperience with secure development, coding, engineering practices\nExperience with Ansible, Terraform, etc.\nExperience with using monitoring and log analytics tools and creating dashboards\nExperience with C++ / .NET / JavaScript\nFamiliar with Platform as a Service (PaaS) technologies such as Kubernetes\nAt Ansys, we know that changing the world takes vision, skill, and each other. We fuel new ideas, build relationships, and help each other realize our greatest potential. We are ONE Ansys. We operate on three key components: the commitments to our stakeholders, the behaviors of how we work together, and the actions of how we deliver results.\nTogether as ONE Ansys, we are powering innovation that drives human advancement.\nOur Commitments\nAmaze with innovative products and solutions\nMake our customers incredibly successful\nAct with integrity\nEnsure employees thrive and shareholders prosper\nOur Values\nAdaptability: Be open, welcome what's next\nCourage: Be courageous, move forward passionately\nGenerosity: Be generous, share, listen, serve\nAuthenticity: Be you, make us stronger\nOur Actions\nWe commit to audacious goals\nWe work seamlessly as a team\nWe demonstrate mastery\nWe deliver outstanding results\nINCLUSION IS AT OUR CORE\nWe believe diverse thinking leads to better outcomes. We are committed to creating and nurturing a workplace that fuels this by welcoming people, no matter their background, identity, or experience, to a workplace where they are valued and where diversity, inclusion, equity, and belonging thrive.\nWelcome What‚Äôs Next In Your Career At Ansys\nAt Ansys, you will find yourself among the sharpest minds and most visionary leaders across the globe. Collectively we strive to change the world with innovative technology and transformational solutions. With a prestigious reputation in working with well-known, world-class companies, standards at Ansys are high ‚Äî met by those willing to rise to the occasion and meet those challenges head on. Our team is passionate about pushing the limits of world-class simulation technology, empowering our customers to turn their design concepts into successful, innovative products faster and at a lower cost.\nAt Ansys, it‚Äôs about the learning, the discovery, and the collaboration. It‚Äôs about the ‚Äúwhat‚Äôs next‚Äù as much as the ‚Äúmission accomplished.‚Äù And it‚Äôs about the melding of disciplined intellect with strategic direction and results that have, can, and do impact real people in real ways. All this is forged within a working environment built on respect, autonomy, and ethics.\nCREATING A PLACE WE‚ÄôRE PROUD TO BE\nAnsys is an S&P 500 company and a member of the NASDAQ-100. We are proud to have been recognized for the following more recent awards, although our list goes on: Newsweek‚Äôs Most Loved Workplace globally and in the U.S., Gold Stevie Award Winner, America‚Äôs Most Responsible Companies, Fast Company World Changing Ideas, Great Place to Work Certified (Belgium, China, Greece, France, India, Japan, Korea, Spain, Sweden, Taiwan, and U.K.).\nFor more information, please visit us at www.ansys.com\nAnsys is an Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, veteran status, and other protected characteristics.\nAnsys does not accept unsolicited referrals for vacancies, and any unsolicited referral will become the property of Ansys. Upon hire, no fee will be owed to the agency, person, or entity.\nShow more\nShow less",
        "details": {
            "JobDetail": [
                "Senior"
            ],
            "TypeContract": "",
            "Salary": "500",
            "Level": "",
            "Experience": null
        },
        "title": "devops",
        "skills": {
            "ProgLanguage": [
                "Bash",
                "Python"
            ],
            "CloudComputing": [
                "Azure"
            ],
            "DevTools": [
                "Git",
                "Docker"
            ],
            "OS": [
                "Linux",
                "Windows"
            ],
            "Automation": [
                "Kubernetes",
                "Ansible"
            ],
            "InfrastructureAsCode": [
                "Terraform"
            ],
            "Containers": [
                "Docker",
                "Kubernetes"
            ],
            "Other": [
                "DevOps",
                "CI/CD"
            ],
            "EnSoftSkils": [
                "Adaptability",
                "Collaboration"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "Harnham",
        "location": "Paris",
        "link": "https://fr.linkedin.com/jobs/view/devops-engineer-senior-at-harnham-3903596592?position=4&pageNum=7&refId=AufKBH3ju6SkIv6PYkccnA%3D%3D&trackingId=KJI2Ab0PNimSypUQiTn0eA%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "DevOps Engineer Senior (Paris Sportif)\n5 ans d'exp√©rience minimum\n3j tt\nParis\nUp to 80k‚Ç¨\nCDI\nDescription du Poste :\nVous √™tes un Expert DevOps √† la recherche d'une nouvelle opportunit√© dans le domaine passionnant des paris sportifs ? Nous avons le poste parfait pour vous ! Nous recrutons un DevOps exp√©riment√© avec un minimum de 5 ans d'exp√©rience pour rejoindre une √©quipe dynamique dans le secteur des paris sportifs en ligne. En tant qu'Expert DevOps, vous serez responsable de concevoir, de d√©velopper et de maintenir l'infrastructure cloud sur AWS, en mettant en ≈ìuvre les meilleures pratiques DevOps pour garantir des performances optimales et une scalabilit√© maximale.\nResponsabilit√©s :\nConception et d√©veloppement de l'infrastructure cloud sur AWS.\nAutomatisation des processus de d√©ploiement et de gestion des environnements.\nUtilisation de Terraform pour l'infrastructure as code.\nOptimisation des performances, de la s√©curit√© et de la scalabilit√©.\nCollaboration √©troite avec les √©quipes de d√©veloppement pour am√©liorer les pipelines CI/CD.\nSurveillance et r√©solution des probl√®mes li√©s √† l'infrastructure et aux applications.\nContribution √† l'am√©lioration continue des processus DevOps.\nExigences :\nMinimum de 5 ans d'exp√©rience en tant que DevOps, id√©alement dans le secteur des paris sportifs.\nExpertise avanc√©e avec AWS et exp√©rience significative avec Terraform.\nSolide compr√©hension des concepts DevOps et des pratiques d'automatisation.\nComp√©tences en scripting (Python, Shell) et en gestion des outils de monitoring.\nCapacit√© √† travailler de mani√®re autonome et en √©quipe dans un environnement agile.\nExcellentes comp√©tences en communication et en r√©solution de probl√®mes.\nMa√Ætrise de l'anglais, le fran√ßais serait un atout.\nInt√©ress√©(e) ?\nShow more\nShow less",
        "details": {
            "JobDetail": [
                "Senior"
            ],
            "TypeContract": "CDI",
            "Salary": "",
            "Level": "",
            "Experience": "5 an(s)"
        },
        "title": "devops",
        "skills": {
            "ProgLanguage": [
                "Python"
            ],
            "CloudComputing": [
                "AWS"
            ],
            "InfrastructureAsCode": [
                "Terraform"
            ],
            "Other": [
                "Cloud",
                "DevOps",
                "CI/CD"
            ],
            "EnSoftSkils": [
                "Communication",
                "Collaboration"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "Ubisoft Bordeaux",
        "location": "Bordeaux, Nouvelle-Aquitaine, France",
        "link": "https://fr.linkedin.com/jobs/view/devops-engineer-f-m-nb-at-ubisoft-bordeaux-3910070709?position=5&pageNum=7&refId=AufKBH3ju6SkIv6PYkccnA%3D%3D&trackingId=J5XICMrjgGAvXESCrfAT5Q%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Company Description\nAbout Ubisoft\nUbisoft‚Äôs 20,000 team members, working across more than 30 countries around the world, are bound by a common mission to enrich players‚Äô lives with original and memorable gaming experiences. Their commitment and talent have brought to life many acclaimed franchises such as Assassin‚Äôs Creed, Far Cry, Watch Dogs, Just Dance, Rainbow Six, and many more to come. Ubisoft is an equal opportunity employer that believes diverse backgrounds and perspectives are key to creating worlds where both players and teams can thrive and express themselves. If you are excited about solving game-changing challenges, cutting edge technologies and pushing the boundaries of entertainment, we invite you to join our journey and help us create the unknown.\nUbisoft Bordeaux\nFounded in September 2017, Ubisoft Bordeaux works with passion on the biggest AAAA‚Äôs game in order to offer the best gaming experiences to our players. Today, the studio has more than 400 talents, from 20 different nationalities, who work on licenses such as Assassin's Creed, Beyond Good & Evil 2, plus other unannounced free-to-play games. We are also working on exciting technologies with the Anvil team, Online services teams and with La Forge who seek to validate the value of technological innovations.\nHere is an opportunity to join a stimulating, international, ambitious but friendly studio and work in our new Game Streaming team.\nJob Description\nAs a DevOps Engineer of the Game Streaming team, you will be implementing CI/CD best practices for our interactive game streaming platform for internal and player-facing applications. You will contribute to the development of our infrastructure according to the needs of the team, working side by side with the Product and Development in a fast and creative atmosphere.\nOur team members are self-sufficient and have a problem-solving mindset. We are looking for people who are passionate about gaming and who are always one step ahead in development processes and release management.\nWe expect the candidate to be curious, open-minded, polyvalent, and comfortable exploring new architectures and solutions to deliver a brand-new platform.\nResponsibilities\nWork closely with teammates to design and build highly scalable, available, and reliable CI/CD processes using Ubisoft-recommended practices and tools\nOversee release management for cloud and native applications as well as related SDK\nApply site reliability engineering principles to our services; implement service monitoring strategies and optimize service performance\nManage individual priorities, deadlines, and deliverables\nContribute to engineering efforts from planning and organization to execution and delivery to solve complex engineering problems.\nQualifications\nMinimum Qualifications\nBA/BS in Computer Science, related technical field, or equivalent practical experience\n5 years of relevant work experience\nExperience with software development with one or more general programming languages (e.g. Go, Java, C/C++, Python, or JavaScript)\nPreferred Qualifications\nExperience with Gitlab and at least one additional CI/CD framework\nExperience with Container technology such as Kubernetes, or Docker\nExperience in automation, testing or monitoring framework development\nExperience with configuration management systems and cloud infrastructures such as OpenStack, AWS, Google, or Azure\nGo hands-on skills\nAbility to learn other coding languages as needed and contribute to the APIs integration on the client side\nDemonstrated ability to share knowledge via formal mentoring, reviewing code, reviewing design documents, providing technical talks, teaching classes, or as a consultant on projects\nAdditional Information\nThis job is open for a\npermanent contract.\nProcess:\nInterview with our Tech recruiter\nTechnical assesment\nInterview(s) with the team\nIf your application is not retained, you will receive a negative answer.\nAt Ubisoft, you can come as you are. We embrace diversity in all its forms. We‚Äôre committed to fostering a work environment that is inclusive and respectful of all differences, we\nvalue diversity at our company and do not discriminate on the basis of race, ethnicity, religion, gender, sexual orientation, age or disability status. All personal informations will be treated as confidential according to the Employment Equity act.\nCheck out this guide to help you with your application, and learn about our actions to encourage more diversity and inclusion.\nConsultez ce guide qui a pour but de vous accompagner dans votre candidature, et d√©couvrez nos actions pour encourager plus de diversit√© et d'inclusion.\nShow more\nShow less",
        "details": {
            "JobDetail": [],
            "TypeContract": "",
            "Salary": "",
            "Level": "",
            "Experience": null
        },
        "title": "devops",
        "skills": {
            "ProgLanguage": [
                "Java",
                "Python"
            ],
            "CloudComputing": [
                "AWS",
                "Azure"
            ],
            "DevTools": [
                "Docker"
            ],
            "Automation": [
                "Kubernetes"
            ],
            "Containers": [
                "Docker",
                "Kubernetes"
            ],
            "Collaboration": [
                "Teams"
            ],
            "Other": [
                "Cloud",
                "DevOps",
                "CI/CD"
            ],
            "EnSoftSkils": [
                "Organization"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "METEOJOB by CleverConnect",
        "location": "Paris, √éle-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/cloud-engineer-h-f-at-meteojob-by-cleverconnect-3917265563?position=6&pageNum=7&refId=AufKBH3ju6SkIv6PYkccnA%3D%3D&trackingId=vTlkef%2BsiStUJDKBLw7BAA%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Entreprise\nORIENTACTION EMPLOI est un cabinet de recrutement d√©ploy√© au niveau national, dans de nombreux secteurs d'activit√©s.\nNous accompagnons nos client.e.s partenaires dans la recherche de profils et conseillons nos candidat.e.s dans la concr√©tisation de leur projet professionnel.\nCDI, CDD, Freelance, Franchis√©,... Notre cabinet propose des aventures professionnelles adapt√©es aux perspectives et aux ambitions de chacun.\nDescription Du Poste\nNous recrutons pour notre client, une entreprise propri√©taire, d√©veloppeur et op√©rateur d'actifs immobiliers, un Cloud Engineer.\nVos Missions Principales Seront\nConcevoir, impl√©menter et maintenir les infrastructures Cloud sur les plateformes AWS, GCP et Azure.\nCollaborer √©troitement avec les √©quipes de d√©veloppement pour faciliter le d√©ploiement des applications et services.\nPiloter efficacement le travail des infog√©rants.\nMonitorer et optimiser les performances des infrastructures Cloud.\nD√©velopper et mettre en ≈ìuvre l'automatisation pour accro√Ætre l'efficacit√© des environnements Cloud.\nRester constamment inform√© des derni√®res tendances et bonnes pratiques du Cloud Computing et DevOps.\nConfigurer et superviser l'int√©gration et le d√©ploiement continus (CI/CD) √† l'aide d'outils tels que Jenkins, CircleCI ou TravisCI.\nImpl√©menter avec expertise les technologies de containerisation et d'orchestration comme Docker et Kubernetes.\nUtiliser de mani√®re efficace les outils d'infrastructure as code comme Terraform et CloudFormation.\nDescription Du Profil\nDipl√¥me d'ing√©nieur ou √©quivalent (BAC+5).\nMinimum 5 ans d'exp√©rience dans des r√¥les d'ing√©nierie Cloud, avec des r√©alisations de projets de migration vers le Cloud. (Move to Cloud, Cloud to Cloud)\nMa√Ætrise des environnements AWS, bonnes comp√©tences sur GCP et Azure.\nExp√©rience en automatisation et scripting avec des langages comme Python, Bash ou PowerShell.\nConnaissance des outils de pipeline CI/CD tels que GitLabCI, Jenkins, CircleCI ou TravisCI.\nExp√©rience avec des outils d'infrastructure as code comme Terraform et CloudFormation.\nConnaissance d'outils de monitoring et de logs comme Prometheus et Elasticsearch\nBonne compr√©hension des bonnes pratiques de s√©curit√© et exp√©rience dans l'impl√©mentation d'outils de s√©curisation.\nBonne compr√©hension des protocoles et architectures r√©seaux.\nCapacit√© d'analyse et de r√©solution de probl√®mes.\nDynamique, motiv√©, pragmatique et dot√© d'un fort esprit d'√©quipe.\nCapacit√© √† adapter le discours technique selon le niveau de compr√©hension des interlocuteurs, en fran√ßais et en anglais.\nUne exp√©rience sur les infrastructures On Premise serait un atout.\nLe poste est bas√© √† Paris 16. Des d√©placements professionnels sont √† pr√©voir.\nShow more\nShow less",
        "details": {
            "JobDetail": [],
            "TypeContract": "CDI, CDD",
            "Salary": "",
            "Level": "Bac+5",
            "Experience": "5 an(s)"
        },
        "title": "cloud architect /engineer ",
        "skills": {
            "ProgLanguage": [
                "Bash",
                "Python"
            ],
            "DataBase": [
                "Elasticsearch"
            ],
            "CloudComputing": [
                "GCP",
                "AWS",
                "Azure"
            ],
            "DevTools": [
                "Jenkins",
                "Docker"
            ],
            "Automation": [
                "Kubernetes"
            ],
            "InfrastructureAsCode": [
                "CloudFormation",
                "Terraform"
            ],
            "Containers": [
                "Docker",
                "Kubernetes"
            ],
            "Other": [
                "Cloud",
                "DevOps",
                "CI/CD"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "Madbox",
        "location": "Paris, √éle-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/devops-sre-engineer-h-f-paris-at-madbox-3843040454?position=7&pageNum=7&refId=AufKBH3ju6SkIv6PYkccnA%3D%3D&trackingId=%2BpirLj4CshcRVSIhXolXTg%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Madbox is a fast-growing mobile gaming company with a very unique way of developing games. Everything has been made for teams to take as much ownership as possible, unleash their creativity, bring performance, and have as much fun as possible.\nIn July 2022, we launched our Pocket Champs game worldwide which quickly became one of the top-grossing games in its category.\nThe game has been scaling a lot since the launch and is now supporting millions of monthly users. All these players are interactive with backend systems that we have developed internally and deployed based on our internal knowledge.\nBut the stakes are getting high and we cannot afford to have incidents on these services because it could damage the players experience. We are now looking for someone that has some expertise on deploying online applications that will be consumed by millions of players and would hold on under a heavy load.\nThis is where you come in: take this DevOps / SRE position over and be a driving force of this new Chapter! üî•\nAbout The Role\nThe beginning of your journey at Madbox as an SRE Engineer:\nStarts with meeting your team, discovering who is who and engaging with everyone involved (or not) in your missions\nContinues with getting familiar with our stack, discovering our environment, tools and processes\nYou will of course play our games and learn more about how we are making them the ‚ÄúMadbox way‚Äù !\nEverything will be made for you to get you up to speed, take ownership and be ready to tackle your missions\nResponsibilities & Scope :\nDesign the backend infrastructure to host our Gaming Backend projects (APIs, Game Servers, Storage solutions‚Ä¶)\nSetup the monitoring services to allow tracking the health metrics of our backend applications\nSetup alerts and watch over the health of our backend applications to raise an alarm every time an issue occurs\nAlert the right team\nGive a clear criticality information to define how quickly the issue needs to be solved\nDefine SLA processes for each different level of criticality that can be followed to keep the service available\nProvide as much context as you can from the metrics and logs you see on the dashboards\nSetup our backend application to scale up & down automatically to optimize our cost\nFollow up and make sure that our services scale properly and be ready to operate the scaling up / down manually if necessary\nIdentify bottlenecks in our backend applications and recommend optimization that the Gaming Backend Developers team could make to optimize the application\nKeep a vigil eye on the solutions available on the market\nProfile\nYou have 3 years of hands-on experience in a DevOps / SRE position\nYou are data-oriented, as you measure the impact of the solutions you implement\nYou have proven experience at deploying applications that are accessible to millions of users\nYou are fully proficient in English\nYou‚Äôre passionate about building systems that scale\nYou focus on stability and availability\nYou‚Äôre a team player who can explain their work and share their knowledge with other technical people\nHiring Process\nA call with a recruiter\nA call with the hiring manager\nA home assignment\nA review of the test with the hiring manager and someone from the automation team\nA meet the team interview\nAll our offers are extended within 48 hours maximum\nPerks and benefits\nCompetitive compensation : our compensation grid is regularly reviewed based on the evolution on the market to ensure everyone at Madbox is fairly compensated and receives frequent updates.\nHybrid remote policy: 3 days on site minimum per week + 15 additional working days fully remote per year\nCWS : Culture, Wellness & Sport, is a budget Madbox dedicated to each employee for them to self develop and take care of themselves\nHolidays : hyper-flexible 30 days off policy (take it when you need it)\nHealth of Our Madboxers is Essential: Alan Health Insurance (75% covered by Madbox)\nLunch coupons: Take advantage of the Swile card (60% covered by Madbox)\nTransport Fees : 50% covered by Madbox\nAmazing Offices: Come and explore our offices in the heart of Paris (Bonne Nouvelle Station) and Barcelona (Diagonal Station)! From taking a nap in our ‚Äújungle‚Äù in Paris Office to soaking up the sun on the rooftop in Barcelona at lunch, we have thought of everything to make you feel right at home. üßò‚Äç‚ôÇÔ∏è Bonus: Our fantastic Workplace Managers will make sure to provide you with the coffee/tea/snacks/drinks of your choice!\nHome office Expenses bonus\nTeam Macbook or Team PC? üñ• We provide all the necessary equipment\nEnglish Lessons : as our main langage in both studios is English, you can enjoy group lessons with your peers thanks to our private teacher\nMadgen : yearly company event\nContract and location\nLocation : This position is available in Paris, 19-21 Rue Poissonni√®re üá´üá∑\nor/and in Barcelona, Utopicus, Pla√ßa de Gal¬∑la Plac√≠dia, 1, 3, üá™üá∏\nContract : Permanent full-time contract\nShow more\nShow less",
        "details": {
            "JobDetail": [
                "Remote",
                "Full"
            ],
            "TypeContract": "",
            "Salary": "",
            "Level": "",
            "Experience": null
        },
        "title": "devops",
        "skills": {
            "Collaboration": [
                "Teams"
            ],
            "Other": [
                "DevOps"
            ],
            "EnSoftSkils": [
                "Creativity"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "Scaleway",
        "location": "Paris, √éle-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/devops-engineer-block-storage-at-scaleway-3880171827?position=8&pageNum=7&refId=AufKBH3ju6SkIv6PYkccnA%3D%3D&trackingId=rpBDNCFbyh7YxUJPF6FnuQ%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "About The Job\nThe Storage Team is one of the pillars of Scaleway. This team not only develops the Scaleway Elements storage products (Block Storage), but also supports all the other Scaleway Elements products that rely on Block Storage (Instances, Database, Registry, Kubernetes, and more) for proper usage. In a challenging environment, and within a team that manages hundreds of storage servers across various regions, you will be responsible for developing, automating, and enhancing Scaleway‚Äôs Block Storage solution.\nThis service launched by Scaleway offers resilient, redundant, and high-availability storage for its numerous clients. Your missions will require programming, automation, and architecture skills. On top of your daily activities within your team, you will need to interact with all of Scaleway‚Äôs teams, especially Instances, Network, Hardware, and Platform.\nMinimum Qualifications\nExperienced System Engineer who is passionate about DevOps best practices and cloud architecture, ideally with over 5 years of experience\nExperience with (and love for) storage systems\nStrong system-level programming skills\nGood understanding of Golang\nExperience with a continuous integration workflow, Gitlab, and Git\nStrong Linux knowledge\nDistributed systems (and debugging them)\nResponsibilities\nDeploying infrastructure in new Availability Zones\nImproving & bringing forward new ideas for our current infrastructure\nReacting to eventual failures in collaboration with other teams\nPresenting your work during tech meetings\nCoding, peer review, and deployment\nCustomer support in relation to your product\nDeploying your code\nPreferred Qualifications\nSolid experience with Ceph in high capacity and/or performance environment\nGreat oral and written communication skills\nInfrastructure deployment with Ansible\nVery good command of English\nTechnical Stack\nCeph\nUbuntu/Debian\nAnsible\nGolang\nProtobuf\nPostgresql\nLocation\nThis position is based in our offices in Paris or Lille (France)\nRecruitment Process\nScreening call - 30 mins with the recruiter\nManager Interview - 45 mins\nTechnical Interviews\nHR Interview - 45 mins\nHead of Interview - 45 mins\nOffer sent\nShow more\nShow less",
        "details": {
            "JobDetail": [],
            "TypeContract": "",
            "Salary": "",
            "Level": "",
            "Experience": null
        },
        "title": "devops",
        "skills": {
            "DevTools": [
                "Git"
            ],
            "OS": [
                "Linux"
            ],
            "DBMS": [
                "PostgreSQL"
            ],
            "Automation": [
                "Kubernetes",
                "Ansible"
            ],
            "Containers": [
                "Kubernetes"
            ],
            "Collaboration": [
                "Teams"
            ],
            "Other": [
                "Cloud",
                "DevOps"
            ],
            "EnSoftSkils": [
                "Communication",
                "Collaboration"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "Equativ",
        "location": "Paris, √éle-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/cloud-engineer-at-equativ-3804563418?position=9&pageNum=7&refId=AufKBH3ju6SkIv6PYkccnA%3D%3D&trackingId=qvMMd6o0PeHkY%2BStgG0sug%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "üë´ About the team\nAt Equativ, we‚Äôre on a mission to develop advertising technologies that empower our customers to reach their digital business goals. This means that we rely on massively scalable, widely distributed, highly available, and efficient software systems; the platform deals with over 3 millions requests per second managed by 3,000 servers.\nOur innovation team based in Paris, Nantes, Limoges, Krakow and Berlin is composed of 100+ straightforward and energetic engineers working in an Agile environment and ready to tackle the most complex technical challenges.\nYour mission üëá\nWithin infra BU you will join the Platform department that strives to develop and deploy self-serve tooling to empower our RnD team.\nOur platform is gradually moving to a hybrid cloud platform. You will be joining as the second member of our cloud platform team:\nYou will help deliver a smooth transition of our RnD team to a hybrid cloud architecture\nYou will be responsible for cloud governance and FinOps\nYou will provide help to our engineering teams in order to optimize costs of our GCP components\nWhat you will do ‚úèÔ∏è\nAs a Cloud engineer in our new cloud platform team your missions will be to:\nDesign and develop self-serve tooling for our engineering teams to transition and maintain their workloads to the cloud\nDesign and instrumentalize Finops guidelines to manage the overall ROI of our cloud infrastructure\nHelp design and develop our cost management framework to help teams optimize their operational ROI\nPropagate best-practices and know-how on cloud services and architectural patterns\nImplement terraform modules to support our IAC approach on the cloud\nEvaluate the CO2 savings associated with optimizing our cloud infrastructure usage\nAbout You üëã\nMaster degree in Computer science or similar field of study\n2+ years of System, Cloud or Software Engineering experience ideally in the web industry\nAutonomous and innovative mindset\nExperience in cloud governance (GCP preferred) for production projects and collaboration within a 5+ engineering team\nFluent with DevOps practices\nInterested in the impact of technical decisions on business (finops approach) and environmental outcomes\nWorking proficiency and communication skills in verbal and written English\nNice to have:\nExperience in one or more of the following topics: Finops, big data components for large datasets, Kubernetes administration\nExperience working with IaC (Terraform or other)\nExperience in software development (Go, Python or equivalent)\nHow you'll grow üöÄ\nWithin 1 month:\nYou'll be just finishing your onboarding\nYou'll probably have tackled a few small tasks with your peer\nWithin 4 months:\nYou'll be trusted to review budget increases from development teams\nYou'll be expected to propose small-scale optimisations on our cloud architecture\nWithin 9 months:\nYou'll be in contact with most of the tech leads operating on GCP\nYou'll be evolving our terraform architecture to deploy resources to the cloud\nYou‚Äôll start getting a grasp on the AdTech business\nüëã About us\nEquativ is the new single name for Smart Adserver, DynAdmic, LiquidM and Nowtilus ‚Äî four proven innovators in advertising technology. The vertically integrated company provides brand and privacy-safe solutions that empower its clients to achieve maximum impact while respecting the rights of consumers. The union combines client expertise and engineering excellence to serve the interests of both the supply- side and demand-side with equal professionalism and technical sophistication.\nHeadquartered in Paris and New York, Equativ operates globally with a team of more than 550 people in 20 offices. Equativ offers the market its own independent ad server, SSP, buyer tools, and media services to fulfill the promise of advertising technology. Learn more at Equativ.com.\nThe company is ranked on the Deloitte Technology Fast 500 EMEA and in the Financial Times‚Äô FT 1000: Europe‚Äôs Fastest-Growing Companies.\nEquativ (formerly Smart AdServer) has been awarded the HappyIndex@Work label and is proud to be among the best companies in the ChooseMyCompany ranking, recognized for its flexible working environment.\nCome and lead the charge with us in building a transparent ecosystem based on quality!\nEquativ is an equal opportunity employer. Equal access to employment, services, and programs are available to everyone, regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity, or Veteran status. If you require reasonable accommodation throughout the application and/or interview process, please contact the recruitment team at ta-team@equativ.com\nShow more\nShow less",
        "details": {
            "JobDetail": [],
            "TypeContract": "",
            "Salary": "",
            "Level": "",
            "Experience": null
        },
        "title": "cloud architect /engineer ",
        "skills": {
            "ProgLanguage": [
                "Python"
            ],
            "CloudComputing": [
                "GCP"
            ],
            "Automation": [
                "Kubernetes"
            ],
            "InfrastructureAsCode": [
                "Terraform"
            ],
            "Containers": [
                "Kubernetes"
            ],
            "Collaboration": [
                "Teams"
            ],
            "Other": [
                "Cloud",
                "Big Data",
                "DevOps"
            ],
            "EnSoftSkils": [
                "Communication",
                "Collaboration"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "Cloud Temple",
        "location": "Tours",
        "link": "https://fr.linkedin.com/jobs/view/cloud-support-engineer-h-f-at-cloud-temple-3885141496?position=10&pageNum=7&refId=AufKBH3ju6SkIv6PYkccnA%3D%3D&trackingId=km58dk4iXVl8bgvfZut%2Ffw%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Afin de consolider notre √©quipe Computing & Storage, Cloud Temple vous offre l'opportunit√© de nous rejoindre en tant que\nCloud Support Engineer .\nAu sein de l‚Äô√©quipe de Trusted Cloud Support, vous avez la charge du maintien en conditions op√©rationnelles de nos infrastructures compute et virtualisation, h√©berg√©es dans notre cloud priv√©, ainsi que de la prise en charge des tickets de supports escalad√©s par nos clients (internes ou externes). Vous travaillez sur des infrastructures certifi√©es (SecNumCloud, HDS) avec de fortes contraintes de s√©curit√© et de disponibilit√©. L‚Äô√©quipe est au premier rang des demandes et incidents, les activit√©s y sont par cons√©quent vari√©es et permettent rapidement de prendre du contexte et de mettre en ≈ìuvre des comp√©tences acquises, ainsi que d‚Äôen d√©velopper de nouvelles.\nMISSIONS :\nEn tant que\nCloud Support Engineer\n(F/H), vos responsabilit√©s seront :\nVous √™tes charg√© du maintien et de l'√©volution de nos infrastructures, ainsi que de la stabilit√© du service rendu au client.\nContribuer √† l‚Äôautomatisation en √©tant force de proposition\nCommuniquer avec nos clients et partenaires de l‚Äô√©tat d‚Äôavancement des sujets escalad√©s\nParticiper √† la livraison des Professional Services\nMaintenir la conformit√© op√©rationnelle et s√©curitaire des services\nParticiper aux projets d‚Äô√©volution et de transformation des infrastructures et services\nAgr√©menter et maintenir une base de connaissances techniques\nExigence du poste :\nNiveau de dipl√¥mes :\nBAC + 5\nComp√©tences requises :\nConnaissance des outils Git, GitLab (CI/CD), Docker, Terraform, Ansible\nMaitrise des concepts de conteneurisation (Docker, K8S) (des connaissances en OpenShift seraient un plus)\nMaitrise des concepts ITIL\nConnaissance des produits Cisco et IBM Storage\nConnaissances avanc√©es des r√©seaux LAN et WAN (VLAN, BGP)\nConnaissance des environnements UNIX (FreeBSD, Linux, Solaris)\nMaitrise d‚Äôau moins un langage de programmation : Python, Bash, PHP, Golang, JAVA\nConnaissance des produits de virtualisation VMware\nFacilit√©s r√©dactionnelles\nSens de la relation client\nConnaissances linguistiques :\nAnglais : lu, parl√© et √©crit\nExp√©rience attendue\n:\nAu moins 2 ans sur un poste similaire\nExp√©rience en administration d‚Äôinfrastructure diverses (une certification VMware serait un plus)\nConnaissance des diff√©rentes architectures de stockage (SAN / vSAN)\nCapacit√© √† automatiser des actions op√©rationnelles (scripts, dev)\nComp√©tences sur les solutions de supervision des services et leurs performances\nSavoir √™tre attendus\nPassionn√© par les infrastructures et le cloud (priv√© et/ou public)\nSens de la qualit√© de service\nCapacit√© d‚Äôadaptation et d‚Äôautomatisation dans un environnement en perp√©tuelle √©volution\nExcellentes comp√©tences organisationnelles\nCapacit√© √† g√©rer les situations de crise\nTravail en √©quipe\nShow more\nShow less",
        "details": {
            "JobDetail": [],
            "TypeContract": "",
            "Salary": "",
            "Level": "",
            "Experience": "2 an(s)"
        },
        "title": "cloud architect /engineer ",
        "skills": {
            "ProgLanguage": [
                "Java",
                "Bash",
                "Python"
            ],
            "DevTools": [
                "Git",
                "Docker"
            ],
            "OS": [
                "Linux"
            ],
            "Automation": [
                "Ansible"
            ],
            "InfrastructureAsCode": [
                "Terraform"
            ],
            "Virtualisation": [
                "VMware"
            ],
            "Containers": [
                "Docker",
                "OpenShift"
            ],
            "Other": [
                "Cloud",
                "CI/CD"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "Wiz",
        "location": "France",
        "link": "https://fr.linkedin.com/jobs/view/solutions-engineer-france-at-wiz-3867238861?position=1&pageNum=10&refId=bCEBNf%2BPt4%2BZw9jTJ1Np%2Fw%3D%3D&trackingId=LtwQaITDjiQQOwGf3H4%2BYQ%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Come join the company that is reinventing cloud security and empowering businesses to thrive in the cloud. As the fastest-growing startup ever, Wiz is on a mission to help organizations secure cloud environments that will accelerate their businesses. Trusted by security teams all over the world, we have a proven track record of success and a culture that values world-class talent.\nOur Wizards from over 13 countries work together to protect the infrastructure of our hundreds of customers, including over 40% of the Fortune 100, who trust us to scan and secure over 230 billion files daily. We‚Äôre the leading player in a massive and growing market, but it‚Äôs still early enough for you to make a significant impact. At Wiz, you‚Äôll have the freedom to think creatively, dream big, and use your full range of skills to contribute to our record growth. Come join our team and help us create secure cloud environments that allow the best companies to move faster.\nSummary\nAs a\nSolutions Engineer\n, you will be responsible for supporting our enterprise customers, reporting to the regional\nManager,\nSolutions Engineering\n. You will partner directly with regional account executives to help change our customers view and how they approach cloud security. You will be their trusted advisor for all matters related to cloud security across AWS, Azure, and GCP. We are passionate about technical sales and helping our customers achieve the maximum value from our solution.\nWhat You‚Äôll Do\nPartner with the sales team to provide technical leadership to our customers and prospective customers in conjunction with helping our team meet their quarterly sales targets.\nProvide presentations to our customers and prospective customers such as whiteboards, product demonstrations, slides, and proof of value outcomes.\nHelp our customers and prospective customers plan in-depth test plans for showing the value of the Wiz platform in their environment (proof of value).\nInvest time in learning new product features, industry related developments, and broadening your overall technical skillset.\nRepresent Wiz in technical forums such as trade shows, technical meet-ups, and industry events.\nWhat You‚Äôll Bring\nAbility to deliver world class demonstrations and training experience to our channel customers\nMastered the technical sales process\nThrive in a creative technical role assisting partners to build a technical business delivery model\nExperience in a sales engineering role delivering solutions to C-level executives at enterprise customers\nAbility to travel up to 50%\nCloud security experience\nAWS/Azure/GCP hands on experience\nNetwork engineering experience\nStrong operating system, virtual machine, and container knowledge\nKnowledge of risk-based security assessments and frameworks\nUnderstanding of cloud identity, access, certificates, and keys\nBONUS POINTS:\nExperience with traditional CSPM tools\nSaaS experience\nAwareness of the CI/CD process\nFamiliarity with Infrastructure as Code\nIf your experience is close but doesn‚Äôt fulfill all requirements, please apply. Wiz is on a mission to build a special company. To achieve our goal, we are focused on hiring Wizards with different backgrounds, perspectives, and experiences.\nWiz is an equal opportunity employer. We do not discriminate based upon race, religion, color, national origin, sex (including pregnancy, childbirth, reproductive health decisions, or related medical conditions), sexual orientation, gender identity, gender expression, age, status as a protected veteran, status as an individual with a disability, genetic information, political views or activity, or other applicable legally protected characteristics. We also consider qualified applicants with criminal histories, consistent with applicable federal, state and local law.\nBy submitting your application, you acknowledge that Wiz will process your personal data in accordance with Wiz's Privacy Policy.\nShow more\nShow less",
        "details": {
            "JobDetail": [
                "Full"
            ],
            "TypeContract": "",
            "Salary": "",
            "Level": "",
            "Experience": null
        },
        "title": "Other",
        "skills": {
            "CloudComputing": [
                "GCP",
                "AWS",
                "Azure"
            ],
            "Collaboration": [
                "Teams"
            ],
            "Other": [
                "Cloud",
                "CI/CD"
            ],
            "EnSoftSkils": [
                "Leadership"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "Keylent Inc",
        "location": "Us, √éle-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/devops-engineer-mahin-job-34202-at-keylent-inc-3916719541?position=2&pageNum=10&refId=bCEBNf%2BPt4%2BZw9jTJ1Np%2Fw%3D%3D&trackingId=KkEPgODRknR9CXuMYnVHAg%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Devops Engineer MAHIN-JOB-34202\nLocation: PHONEIX\nDeveloper experience in python, Ansible and pipeline construction Bash scripting Mid Level Python scripting Mid level Ci/CD experience required Terraform Mid level Packer Mid Level Vault Good to have AWS Experience Low Mid Level Azure Experience Low Mid Level\nResponsibilities\nDevelop and maintain automation scripts using Bash and Python to streamline deployment, configuration, and monitoring processes.\nDesign, implement, and manage CI/CD pipelines to enable continuous integration and delivery of software applications.\nCollaborate with development teams to ensure applications are designed for scalability, reliability, and performance.\nConfigure and manage cloud infrastructure on AWS or Azure, including EC2 instances, S3 buckets, VPCs, and more.\nMonitor system performance and troubleshoot issues, ensuring high availability and uptime for critical services.\nImplement security best practices and compliance standards across the infrastructure.\nParticipate in on-call rotations and respond to incidents in a timely manner.\nContinuously evaluate and implement new tools and technologies to improve efficiency and effectiveness.\nRequirements\nBachelor's degree in Computer Science, Engineering, or related field.\n3+ years of experience as a DevOps Engineer or similar role.\nProficiency in Bash scripting and Python scripting.\nHands-on experience with cloud platforms such as AWS or Azure.\nStrong understanding of CI/CD concepts and experience with tools like Jenkins, GitLab CI, or CircleCI.\nExperience with configuration management tools such as Ansible, Puppet, or Chef.\nFamiliarity with containerization technologies like Docker and orchestration tools like Kubernetes.\nExcellent problem-solving and communication skills.\nAbility to work effectively in a fast-paced, dynamic environment.\nPreferred Qualifications\nAWS or Azure certification (e.g., AWS Certified DevOps Engineer, Azure DevOps Engineer Expert).\nExperience with infrastructure as code tools such as Terraform or CloudFormation.\nKnowledge of monitoring and logging tools such as Prometheus, Grafana, ELK stack, or Splunk.\nUnderstanding of networking concepts and protocols.\nFamiliarity with Agile and DevOps methodologies.\nShow more\nShow less",
        "details": {
            "JobDetail": [],
            "TypeContract": "",
            "Salary": "",
            "Level": "",
            "Experience": null
        },
        "title": "devops",
        "skills": {
            "ProgLanguage": [
                "Bash",
                "Python"
            ],
            "CloudComputing": [
                "AWS",
                "Azure"
            ],
            "DevTools": [
                "Jenkins",
                "Docker"
            ],
            "Automation": [
                "Chef",
                "Kubernetes",
                "Puppet",
                "Ansible"
            ],
            "InfrastructureAsCode": [
                "CloudFormation",
                "Terraform"
            ],
            "Containers": [
                "Docker",
                "Kubernetes"
            ],
            "Collaboration": [
                "Teams"
            ],
            "Other": [
                "Cloud",
                "DevOps",
                "CI/CD"
            ],
            "EnSoftSkils": [
                "Communication"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "Apside",
        "location": "√éle-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/data-engineer-cloud-f-h-at-apside-3904088503?position=3&pageNum=10&refId=bCEBNf%2BPt4%2BZw9jTJ1Np%2Fw%3D%3D&trackingId=PtEgsBicH27fRvN6lxaa9g%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "üí•\nD√©couvrez la Vie Apsidienne\nüìπ\net vous aussi, devenez Apsidien\nOn aurait pu demander √† Chat GPT de vous d√©montrer en quoi\nApside est l‚ÄôESN qu‚Äôil vous faut,\nmais on pr√©f√®re que vous le d√©couvriez vous-m√™mes üëáüòè\nüî•\nD√©couvrez votre future mission\nüëâ\nContexte\nRejoignez notre Practise Cloud/Data, afin d‚Äôintervenir sur des sujets √† haute valeur ajout√©e !\nNotre\nclient migre actuellement toutes ses applications vers le cloud AWS.\nDe plus, dans le cadre du d√©veloppement d'un produit de restitution automatis√©e de donn√©es, ils recherchent actuellement d√©veloppeur data ayant d√©j√† travaill√© sur un projet similaire. La solution produit est techniquement con√ßue en lien avec le Tech Lead validant l'architecture logicielle √† mettre en place sur le cloud AWS.\nSecteur\n: culture/m√©dia\nM√©thode de travail\n: Agile Safe\nüòé Mission\nCapter les donn√©es (structur√©es et non structur√©es) produites dans les diff√©rentes applications\nInt√©grer les √©l√©ments\nStructurer la donn√©e (s√©mantique, etc‚Ä¶)\nCartographier les √©l√©ments √† disposition\nNettoyer la donn√©e (√©limination des doublons, etc‚Ä¶)\nValider la donn√©e\nCr√©er les r√©f√©rentiels de donn√©es\nEnvironnement technique\n:\nPython\nLambda\nStep Function\nAWS / AWS RDS\nPostegreSQL\nSnowflake\nSpark\nüìç\nLocalisation\nLa D√©fense\nüí∞\nLe package salarial que nous vous proposons\nContrat :\nCDI\nAvantages groupe :\ncarte ticket restaurant Swile, prime de mobilit√©, RTT, accord t√©l√©travail, Mutuelle, prime de cooptation, avantages CE, prise en charge de la mutuelle √† 100% etc‚Ä¶\nAvantages agence :\nCommunaut√© Cloud/Data, afterworks, communaut√© techlead\nFormation :\ncertifications techniques, cours particuliers d‚Äôanglais en interne, acc√®s √† un catalogue de formations gr√¢ce √† notre plateforme e-learning (\nAcademy by Apside\n) ou via nos organismes partenaires.\nüîÆ\n√î vous futur Apsidien, qui √™tes-vous ?\nAu moins 4 ans d'exp√©rience en tant que Data Engineer\nMaitrise de l‚Äôenvironnement cloud AWS\nForce de proposition, bon relationnel et autonome\nüòè\nApside a suscit√© votre curiosit√© ?\nDans un environnement marqu√© par une acc√©l√©ration des √©volutions technologiques, de transformations des usages et de disruptions majeures, Apside est un partenaire de confiance qui accompagne ses clients √† cr√©er de la valeur et √† adresser leurs enjeux strat√©giques en leur mettant √† disposition des expertises technologiques (\nData / IA, Cloud, Cyber\n) et une exp√©rience sectorielle (\nIndustrie, Banque, Assurance, Service, Secteur Public\n). Pour un accompagnement global, le groupe propose des offres transverses autour du\nHandicap\n(Apsid‚ÄôEA), du\nDigital Learning\n, et du\nConseil\n.\nü§î\nEt votre place dans tout √ßa ?\nüëâ Notre volont√©\nest de vous accompagner dans la construction et l‚Äô√©panouissement de votre carri√®re\nen nous appuyant notamment\nsur 3 piliers :\nUne\nr√©mun√©ration\n√† hauteur de vos investissements et de vos comp√©tences\nUne\ntrajectoire professionnelle\nstimulante sur mesure\nUn\nengagement\nautour des valeurs Apsidiennes : la qualit√© de vie et des conditions de travail au c≈ìur de nos enjeux\nEngag√©e pour\nun monde plus inclusif et plus responsable\n, Apside r√©invente l‚ÄôESN et propose l‚ÄôEngagement Soci√©tal et Num√©rique. D√©couvrez notre d√©marche RSE ainsi que notre vision de l‚ÄôEntreprise Engag√©e.\nConvaincu ? A vous de jouer, envoyez-nous votre CV !\nRejoignez l‚Äôaventure Apsidienne et d√©couvrez notre vision d‚Äôune ESN singuli√®re et r√©siliente\nüöÄ\nShow more\nShow less",
        "details": {
            "JobDetail": [],
            "TypeContract": "CDI",
            "Salary": "100",
            "Level": "",
            "Experience": "4 an(s)"
        },
        "title": "data engineer",
        "skills": {
            "ProgLanguage": [
                "Python"
            ],
            "BigData": [
                "Spark"
            ],
            "CloudComputing": [
                "AWS"
            ],
            "DBMS": [
                "Snowflake"
            ],
            "Other": [
                "Cloud"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "Talan",
        "location": "Paris, √éle-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/big-data-engineer-databricks-senior-h-f-cdi-at-talan-3909664424?position=4&pageNum=10&refId=bCEBNf%2BPt4%2BZw9jTJ1Np%2Fw%3D%3D&trackingId=rBvicrMXCThyKq9glOYCNA%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Talan est un groupe international de conseil en transformation et en innovation par la technologie, cr√©√© en 2002.\nNos 5000 consultantes et consultants partagent √† travers le monde l‚Äôaudace d‚Äôinnover, le go√ªt de l‚Äôexcellence, et l‚Äôenvie de relever les d√©fis les plus complexes.\nNous accompagnons les entreprises dans des secteurs vari√©s‚ÄØ: √©nergie, industrie, transport, finance, luxe‚Ä¶ √† travers 3 grandes expertises‚ÄØ:\nLe Conseil en Management et Innovation (320 Consultants en France)\nLa valorisation des donn√©es, leurs structurations, et leurs usages (Data et Technologies)\nL‚Äôint√©gration de solutions logicielles (Cloud et Applications Services)\nNos valeurs‚ÄØ: engagement, respect, partage, esprit d‚Äô√©quipe et optimisme.\nTalan est une entreprise responsable, reconnue par ses collaborateurs et attach√©e √† la diversit√©. Des am√©nagements peuvent √™tre propos√©s si vous √™tes en situation de handicap.\nRetrouvez nos engagements RSEiciet nos actions en faveur de la diversit√©ici\nJob Description\nNous sommes √† la recherche d‚Äôun Big Data Engineer Databricks S√©nior qui sera en charge de l‚Äôint√©gration des donn√©es: acquisition, pr√©paration, mod√©lisation et stockage, exposition, . Vous devrez faire preuve d‚Äôun √©tat d‚Äôesprit √† la fois innovant, m√©thodique, orient√© solution (et non probl√®me!), et communiquant.\nResponsabilit√©s\nManager des Big Data Engineer et Cloud Engineer\nCoacher techniquement les membres de l‚Äô√©quipe: solution et code review sur site, recommandation sur les formations √† suivre, certifications √† r√©aliser, ‚Ä¶\nAnalyse des besoins techniques m√©tiers, d√©finition de l‚Äôarchitecture solution et logiciel, r√©f√©rent technique, d√©veloppement et optimisation, code review, maintenir les pratiques Devops ‚ÄúYou build IT, You run IT‚Äù, support √† recette et mise en production, documentation, et parfois assumer le r√¥le de Scrum Master,‚Ä¶\nBenchmark de solutions et conseil aupr√®s de notre client sur les solutions technologiques √† adopter, en lien avec leurs besoins\nPartage de connaissances et formations interne\nQualifications\nIssu(e) d‚Äôune formation sup√©rieure (√©cole d‚Äôing√©nieur, master,‚Ä¶)\nVous disposez d‚Äôau moins 4 ann√©es d‚Äôexp√©rience dans le domaine du Big Data (et particuli√®rement sur le framework Spark), et au moins 6 ann√©es d‚Äôexp√©rience dans le d√©veloppement logiciel\nVous ma√Ætrisez led√©veloppement logiciel (Scala, Python ‚Ä¶), et vous disposez de solides exp√©riences dans la mise en place de pipelines de donn√©es\nVous ma√Ætrisez leFramework Spark (id√©alement sur Databricks) etson optimisation\nExp√©rience sur une plateforme Cloud serait un plus et id√©alement AWS\nExp√©rience sur des flux temps r√©elserait un plus : Kafka + Spark Streaming\nVous ma√Ætrisez les bases de donn√©es SQL et le langage SQL\nVous avez de l'exp√©rience sur les m√©thodes de stockage: HDFS, S3,,‚Ä¶\nVous avez de bonnes connaissances en devOps : Jenkins, Gitlab, Maven, ‚Ä¶\nLa connaissance des concepts suivants serait un +: DataOps, DataVault, DataMesh..\nConnaissance de l‚ÄôAgilit√©\nAutonome\nOrganis√©(e)\nSens du partage\nBonne communication\nOrientation produit et solution\nAdditional Information\nAVANTAGES\n:\nPlan de formation pour accompagner votre carri√®re (formations √©diteurs, certifications) gr√¢ce √† nos partenariats nous accordant une position de partenaire privil√©gi√©, et management de proximit√© par des experts\nLocaux modernes en centre-ville\nTop 5 du Palmar√®s Great Place to Work\nT√©l√©travail jusqu‚Äô√† 5 jours selon les missions, prime d‚Äô√©quipement de 100‚Ç¨\nMobilit√© en France et √† l‚Äô√©tranger\nTop 1% des entreprises √©valu√©es par Ecovadis dans le domaine social, environnemental et √©thique\nTickets restaurant, prime vacances, 50% transport (abonnement transport public), mutuelle\nPermanence handicap (consultant d√©di√© aux collaborateurs en situation de handicap et aux proches aidants)\nActionnariat salari√©\nPrime de cooptations\nRTT\nPROCESS RECRUTEMENT\n:\nL‚Äô√©quipe recrutement s‚Äôengage √† vous proposer un processus de recrutement rapide et fluide\n1 entretien RHpar Teams (45min)\n1 test technique\n1 entretien technique par Teams (1heure)\n1 entretien op√©rationnel avec le responsable de domaine, au si√®ge (1heure)\nShow more\nShow less",
        "details": {
            "JobDetail": [],
            "TypeContract": "",
            "Salary": "",
            "Level": "",
            "Experience": null
        },
        "title": "data engineer",
        "skills": {
            "ProgLanguage": [
                "Scala",
                "Python"
            ],
            "DataBase": [
                "SQL"
            ],
            "BigData": [
                "Databricks",
                "Spark"
            ],
            "CloudComputing": [
                "AWS"
            ],
            "DevTools": [
                "Jenkins"
            ],
            "Collaboration": [
                "Teams"
            ],
            "Other": [
                "Cloud",
                "Big Data",
                "DevOps"
            ],
            "EnSoftSkils": [
                "Communication"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "Scaleway",
        "location": "Lille, Hauts-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/devops-engineer-block-storage-at-scaleway-3880178183?position=5&pageNum=10&refId=bCEBNf%2BPt4%2BZw9jTJ1Np%2Fw%3D%3D&trackingId=LXvjALiiufQ6F5K2iaS%2BZA%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "About The Job\nThe Storage Team is one of the pillars of Scaleway. This team not only develops the Scaleway Elements storage products (Block Storage), but also supports all the other Scaleway Elements products that rely on Block Storage (Instances, Database, Registry, Kubernetes, and more) for proper usage. In a challenging environment, and within a team that manages hundreds of storage servers across various regions, you will be responsible for developing, automating, and enhancing Scaleway‚Äôs Block Storage solution.\nThis service launched by Scaleway offers resilient, redundant, and high-availability storage for its numerous clients. Your missions will require programming, automation, and architecture skills. On top of your daily activities within your team, you will need to interact with all of Scaleway‚Äôs teams, especially Instances, Network, Hardware, and Platform.\nMinimum Qualifications\nExperienced System Engineer who is passionate about DevOps best practices and cloud architecture, ideally with over 5 years of experience\nExperience with (and love for) storage systems\nStrong system-level programming skills\nGood understanding of Golang\nExperience with a continuous integration workflow, Gitlab, and Git\nStrong Linux knowledge\nDistributed systems (and debugging them)\nResponsibilities\nDeploying infrastructure in new Availability Zones\nImproving & bringing forward new ideas for our current infrastructure\nReacting to eventual failures in collaboration with other teams\nPresenting your work during tech meetings\nCoding, peer review, and deployment\nCustomer support in relation to your product\nDeploying your code\nPreferred Qualifications\nSolid experience with Ceph in high capacity and/or performance environment\nGreat oral and written communication skills\nInfrastructure deployment with Ansible\nVery good command of English\nTechnical Stack\nCeph\nUbuntu/Debian\nAnsible\nGolang\nProtobuf\nPostgresql\nLocation\nThis position is based in our offices in Paris or Lille (France)\nRecruitment Process\nScreening call - 30 mins with the recruiter\nManager Interview - 45 mins\nTechnical Interviews\nHR Interview - 45 mins\nHead of Interview - 45 mins\nOffer sent\nShow more\nShow less",
        "details": {
            "JobDetail": [],
            "TypeContract": "",
            "Salary": "",
            "Level": "",
            "Experience": null
        },
        "title": "devops",
        "skills": {
            "DevTools": [
                "Git"
            ],
            "OS": [
                "Linux"
            ],
            "DBMS": [
                "PostgreSQL"
            ],
            "Automation": [
                "Kubernetes",
                "Ansible"
            ],
            "Containers": [
                "Kubernetes"
            ],
            "Collaboration": [
                "Teams"
            ],
            "Other": [
                "Cloud",
                "DevOps"
            ],
            "EnSoftSkils": [
                "Communication",
                "Collaboration"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "Diverse Lynx",
        "location": "Us, √éle-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/devops-engineer-at-diverse-lynx-3869451140?position=6&pageNum=10&refId=bCEBNf%2BPt4%2BZw9jTJ1Np%2Fw%3D%3D&trackingId=wnXdcMQqAVjbbsqe7uECjg%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "8+ years of Very Strong with GitHub/Gitlab and deep understanding with Ansible.\nProficiency with any CI|CD tool example Jenkins, GitHub runners\nProficiency with developing pipelines\nGood understanding of Docker & Containerized applications\nGood knowledge on writing YAML\nOnsite Offshore Coordination\nOrganizing kick-offs for migrations of applications from On-Prem to Cloud (AZURE/AWS)\nAbility to follow standardized steps for migration factory\nAbility to work under pressure\nAbility to work well effectively with team-members with effective interpersonal, verbal and written communication skills\nDiverse Lynx LLC is an Equal Employment Opportunity employer. All qualified applicants will receive due consideration for employment without any discrimination. All applicants will be evaluated solely on the basis of their ability, competence and their proven capability to perform the functions outlined in the corresponding role. We promote and support a diverse workforce across all levels in the company.\nShow more\nShow less",
        "details": {
            "JobDetail": [],
            "TypeContract": "",
            "Salary": "",
            "Level": "",
            "Experience": null
        },
        "title": "devops",
        "skills": {
            "CloudComputing": [
                "AWS",
                "Azure"
            ],
            "DevTools": [
                "Jenkins",
                "Docker"
            ],
            "Automation": [
                "Ansible"
            ],
            "Containers": [
                "Docker"
            ],
            "Other": [
                "Cloud"
            ],
            "EnSoftSkils": [
                "Communication"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "iPepperGroup",
        "location": "Valbonne, Provence-Alpes-C√¥te d'Azur, France",
        "link": "https://fr.linkedin.com/jobs/view/devops-software-engineer-at-ipeppergroup-3907530533?position=7&pageNum=10&refId=bCEBNf%2BPt4%2BZw9jTJ1Np%2Fw%3D%3D&trackingId=gQTYSvSamEgmw0m1aFv0XQ%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Nous sommes le partenaire technologique pr√©f√©r√© de ceux qui changent le monde !\niPepper c'est avant tout une fa√ßon de travailler ensemble : se faire du bien, faire du bien et prendre soin de ses clients, salari√©s et partenaires !\nConsulting, Recrutement et Projets : une palette de services autour de la protection et la valorisation de la data.\nLe Poste\nNous recherchons pour l'un de nos clients un ing√©nieur DevOps / Software Engineer (H/F) exp√©riment√©(e) et √† l'aise en anglais pour rejoindre notre √©quipe dynamique et anglophone √† Sophia Antipolis.\nPossibilit√© de contrat : CDI / Portage salariale ou freelance.\nT√©l√©travail : 2 √† 3 jours par semaine.\nMission longue.\nProjet\nLa mission combine √† la fois des aspects de DevOps et de d√©veloppement logiciel.\nLe d√©fi de l'ann√©e √† venir consiste √† migrer les outils internes de l'h√©bergement h√©rit√© vers le Cloud Azure tout en adoptant les meilleures pratiques. En parall√®le, faire √©voluer un portail Django/React.\nLes autres outils utilis√©s par l'√©quipe sont en Java / Springboot / Angular.\nComme l'√©quipe est relativement petite, le travail est organis√© selon une m√©thodologie similaire √† Scrum avec un backlog Jira.\nLa mission principale est de construire une plateforme de bout en bout avec un environnement de premier ordre pour :\nAm√©liorer la productivit√© des d√©veloppeurs gr√¢ce √† des capacit√©s d'int√©gration et de d√©ploiement automatis√©es.\nD√©velopper, innover et maintenir des plateformes technologiques qui atteignent une agilit√©, une stabilit√© et des performances √©lev√©es.\nEnvisager, acc√©l√©rer les nouvelles versions et fournir des conseils sur la mani√®re d'am√©liorer les performances op√©rationnelles.\nProfil\nQualifications requises :\nExp√©rience significative en tant qu'Ing√©nieur DevOps ou D√©veloppeur Logiciel. (minimum 5 ans)\nSolides comp√©tences en int√©gration et d√©ploiement continu.\nMa√Ætrise des technologies de d√©veloppement web, y compris Django, React, Java, Springboot et Angular.\nCapacit√© √† travailler dans un environnement agile et √† s'adapter rapidement aux changements.\nBonnes comp√©tences en communication et capacit√© √† travailler efficacement en √©quipe.\nAnglais courant obligatoire (conversation quotidienne en anglais / √©quipe anglophone)\nSi vous √™tes passionn√©(e) par l'innovation technologique, que vous recherchez un environnement stimulant et que vous souhaitez contribuer au succ√®s d'une √©quipe dynamique, alors ce poste est fait pour vous !\nShow more\nShow less",
        "details": {
            "JobDetail": [],
            "TypeContract": "CDI",
            "Salary": "",
            "Level": "",
            "Experience": "5 an(s)"
        },
        "title": "software engineer",
        "skills": {
            "ProgLanguage": [
                "Java"
            ],
            "CloudComputing": [
                "Azure"
            ],
            "Collaboration": [
                "JIRA"
            ],
            "Other": [
                "Cloud",
                "DevOps"
            ],
            "EnSoftSkils": [
                "Communication"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "SFEIR",
        "location": "Nantes, Pays de la Loire, France",
        "link": "https://fr.linkedin.com/jobs/view/cloud-engineer-devops-f-h-nantes-at-sfeir-3477973777?position=8&pageNum=10&refId=bCEBNf%2BPt4%2BZw9jTJ1Np%2Fw%3D%3D&trackingId=dLYGil6ucWg8fGmzjDyTpw%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "C'est quoi SFEIR ? ü§î\nSFEIR, c'est avant tout une communaut√© de 900 techs en France, en Belgique et au Luxembourg.\nNous aidons nos clients √† :\nüîπ √ätre compatible avec le futur en d√©veloppant leurs architectures SI, Cloud et Data ;\nüîπ Donner de la valeur √† leurs donn√©es, innover avec l'IA ;\nüîπCr√©ateur de valeur gr√¢ce aux API & microservices;\nüîπ D√©velopper des applications web et mobiles pour am√©liorer leur exp√©rience client et se connecter partout.\nNotre culture d'entreprise est r√©solument tourn√©e vers l'expertise technologique, la transmission de connaissances et le respect de nos valeurs phares :\nbienveillance, inclusivit√©, excellence, libert√©, responsabilit√©.\nEt Nantes dans tout √ßa ?\nSFEIR Nantes c'est :\nüîπ Une agence cr√©e en 2018 par @Jean-Fran√ßois Garreau , co-fondateur du DevFest Nantes\nüîπ Une trentaine de consultant(e)s qui se connaissent toutes et tous\nüîπ 4 Managers qui sont aussi des consultants @Hoani , @Adrien , @Fr√©d√©ric , @Valentin\nüîπ Une dizaine de clients actifs en local et une centaine au niveau du groupe\nüîπ Des √©v√©nements en interne et en organis√©s chaque mois (afterworks, meetup, formations)\nüîπ Une communaut√© active : une cinquantaine de conf√©rences externes donn√©es en 2022 (Devfest, Devoxx, communaut√© JS‚Ä¶)\nüîπ Des locaux sur l'√Æle de Nantes dans le b√¢timent totem du num√©rique nantais.\nConcr√®tement, quel sera mon job ?\nEn mission pour un client, ton r√¥le est d‚Äôintroduire des processus, des outils et des m√©thodes pour √©quilibrer les besoins tout au long du cycle de d√©veloppement de logiciels, du codage et du d√©ploiement, jusqu'√† la maintenance et √† la mise √† jour.\nTu es en charge du d√©ploiement, du stockage, de la gestion et de la migration des donn√©es sur des solutions Cloud (\nGCP, AWS, Azure\n‚Ä¶).\n@Arthur et @Paul-Antoine , nos super commerciaux, seront √† ton √©coute pour d√©finir avec toi ta mission id√©ale et tu pourras en changer lorsque tu en auras fait le tour.\nVoici des exemples de projets r√©alis√©s par des sfeiriens pour te donner une id√©e :\nüîπ\nGuillaume\na int√©gr√© l‚Äô√©quipe SRE d‚Äôun √©diteur de logiciel. Son r√¥le est d‚Äôassurer et d'am√©liorer la fiabilit√© de l'infrastructure. Il automatise et industrialise des op√©rations sur l'infrastructure et am√©liore le monitoring de la plateforme.\nüîπ\nJulien\nr√©alise un projet dans l‚Äôunivers du luxe, de mise en place de fondations Cloud pour h√©berger la future plateforme Data en utilisant des outils tel que Terraform et Cloud Build\nEt si je souhaite √©voluer?\nNous proposons des possibilit√©s d'√©volution verticales et horizontales. Nous pourrons t'accompagner pour te certifier ou √©valuer sur une autre sp√©cialit√©, ou encore devenir\nLead Tech\nou\narchitecte.\nTu auras √©galement la possibilit√© de prendre des r√¥les en interne si tu le souhaites :\nüîπ\n√âvaluateur(trice)\ndans le processus de recrutement\nüîπ\nFormateur(trice)\naux Sfeir Schools ou au Sfeir Institute\nüîπ\nSpeaker(euse)\nlors de conf√©rences, meetups, talks internes, aupr√®s des √©coles\nüîπ\nEngineering manager\nsi tu veux manager une √©quipe tout en restant dans la technique\nEt si tu as d'autres envies, on en discute, chacun est diff√©rent et on fait au cas par cas.\nJe suis int√©ress√©(e) üôÇ, comment vous rejoindre ?\nSi cette annonce a fourni ton attention, il ne te reste plus qu'√† postuler.\n@Justine se font un plaisir de t'en dire plus üôÇ. Tu pourras ensuite te frotter √† nos c√©l√®bres\nPlayOffs\n: 3 tests d'√©valuation technique en pair-programming (algorithmie, langage, framework). Ne t'en fais pas, nos √©valuateur(trice)s sont bienveillant(e)s !\nEnfin, tu √©changeras avec Arthur et Paul-Antoine au commerce et Jean-Fran√ßois et @Arnaud , nos directeurs.\nChez Sfeir, la confiance, la bonne humeur et l'inclusion font partie de notre ADN.\nEn rejoignant notre communaut√©, tu deviendras un(e) Sfeirien(ne) bienveillant(e), libre et responsable.\n#L‚ÄôinclusionEstUneForce: Notre process de recrutement inclusif assure une √©galit√© de traitement et de chance aux candidats de tous horizons.\nShow more\nShow less",
        "details": {
            "JobDetail": [],
            "TypeContract": "",
            "Salary": "",
            "Level": "",
            "Experience": null
        },
        "title": "devops",
        "skills": {
            "CloudComputing": [
                "GCP",
                "AWS",
                "Azure"
            ],
            "InfrastructureAsCode": [
                "Terraform"
            ],
            "Other": [
                "Cloud"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "Quandela",
        "location": "Massy, √éle-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/software-integration-engineer-at-quandela-3759487196?position=9&pageNum=10&refId=bCEBNf%2BPt4%2BZw9jTJ1Np%2Fw%3D%3D&trackingId=3I8OY8dotTUg%2FmSA0J9MBw%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Quandela, a leader in the development and commercialization of Quantum Processing Units (QPU) based on the manipulation of single photons, is seeking a skilled and motivated Software Integration Engineer to join our team. As a Software Integration Engineer, you will play a crucial role in advancing our cutting-edge technology and contribute to shaping the future of quantum computing. At Quandela, we are committed to pushing the boundaries of what is possible in the world of quantum technology, and as a member of our team, you will have the opportunity to work on exciting and challenging projects that have the potential to revolutionize the field.\nResponsibilities\nParticipate in designing, developing and testing the software layers used to control and monitor the QPU\nCollaborate with a multidisciplinary team of engineers and scientists to integrate new features into the overall quantum computer architecture\nDeployment and control for system monitoring, diagnostics, and performance analysis\nParticipate in hardware and software testing procedures on QPUs or submodules\nWork closely with hardware engineers to develop hardware-software interfaces for efficient control and operation of quantum optical systems\nTroubleshoot and debug software issues that arise during integration and deployment\nDevelop and execute test plans to validate the performance and reliability of integrated systems\nRequirements\nProven experience in programming for hardware control\nStrong experience in Python, C++ optional but preferred\nKnowledge of Linux and Git required\nCurious and a fast learner\nExcellent problem-solving and analytical skills\nInterest in electronics, quantum optics and quantum computing\nStrong communication and collaboration abilities, with a proven track record of working effectively in a multidisciplinary team\nBenefits\nA diverse, dynamic, challenging, international team and environment.\nAll means necessary to carry-out high-impact projects\nStrong potential for fast career development within a rapidly growing company\nPart-time work-from-home\nEmployee profit-sharing scheme\nPrivate healthcare scheme\nMeal and transport subsidies\nShow more\nShow less",
        "details": {
            "JobDetail": [],
            "TypeContract": "",
            "Salary": "",
            "Level": "",
            "Experience": null
        },
        "title": "software engineer",
        "skills": {
            "ProgLanguage": [
                "Python"
            ],
            "DevTools": [
                "Git"
            ],
            "OS": [
                "Linux"
            ],
            "EnSoftSkils": [
                "Communication",
                "Collaboration"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "Saegus",
        "location": "Paris, √éle-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/consultant%C2%B7e-cloud-data-engineer-gcp-azure-at-saegus-3769067736?position=10&pageNum=10&refId=bCEBNf%2BPt4%2BZw9jTJ1Np%2Fw%3D%3D&trackingId=RWYo0puums7LCzppOsY1KA%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Qui est Saegus ?\nSaegus est la\nConsulTech\nqui accompagne ses clients (grands groupes du CAC 40 / SBF 120) dans leur transition vers l'entreprise intelligente et responsable de demain, le\nSmart Shift\n.\nLe\nSmart Shift\nrepr√©sente bien plus qu'une simple transition num√©rique. C'est une vision strat√©gique compl√®te qui int√®gre les technologies √©mergentes, telles que l'intelligence artificielle et l'utilisation performante et raisonn√©e de la Data, √† des changements culturels, organisationnels et de gouvernance.\nNous appliquons √©galement l‚Äôapproche Smart Shift pour offrir √† nos consultants un environnement propice √† leur d√©veloppement professionnel et √† leur √©panouissement : The Best Place To Grow. Au-del√† de pouvoir vivre l'exp√©rience d'un\nSmart Consultant\n(par l'IA), en rejoignant notre √©quipe, vous b√©n√©ficierez d'une culture d'entreprise ax√©e sur l'agilit√©, l'innovation et l'adaptabilit√©. Nous accompagnons nos Saegusien¬∑ne¬∑s √† d√©velopper de nouvelles comp√©tences, √† explorer les nouvelles technologies et √† cultiver un esprit entrepreneurial, le tout accompagn√© par une √©cole du conseil (parcours de formation propre √† Saegus), un catalogue de formations et de certifications et un coach interne.\nSmart Shift. For Real.\nSaegus est incarn√© par ses\nquatre d√©partements\n:\nShift Acceleration, pour acc√©l√©rer le passage d‚Äôune id√©e en un produit ou service au sein de grandes entreprises gr√¢ce √† des outils et m√©thodologies agiles ;\nSmart Data, pour rendre compr√©hensibles, exploitables et valorisables les donn√©es des entreprises ;\nSmart Workplace, pour cr√©er un environnement humain, physique et technologique optimal pour l‚Äôensemble des collaborateur¬∑rice¬∑s ;\nSmart Experience Factory, pour designer et d√©velopper des applications sur-mesure gr√¢ce √† une m√©thode centr√©e utilisateurs.\nAinsi, nous recrutons un.e Consultant¬∑e Cloud Data Engineer.\nConcr√®tement, quelle sera la mission et les r√©alisations attendues ‚ùì\nEn tant que\nConsultant¬∑e Data Engineer\n, tu seras int√©gr√©¬∑e √† l‚Äô√©quipe Smart Data dont la mission est d‚Äôaider ses clients √† tirer profit des technologies les plus innovantes pour valoriser leurs donn√©es. De l‚Äôacquisition √† la restitution, tu interviens sur chaque √©tape du processus d‚Äôaide √† la d√©cision.\nTu participeras aux missions de conseil et d‚Äôexpertise afin de contribuer √† l‚Äôatteinte des objectifs majeurs de nos clients et contribueras √† la\nr√©alisation de projets tels que\n:\n‚ö°Ô∏è Le design d‚Äôune plateforme Azure Cloud et la mise en place de pipeline d‚Äôingestion et exposition de donn√©es pour la mise √† disposition de donn√©es m√©tiers, rafra√Æchies toutes les 30mn\n‚ö°Ô∏è La mise en place des bonnes pratiques et l‚Äôinitialisation du Datalab pour un grand groupe d‚Äôassurance, et l‚Äôaccompagnement √† l‚Äôindustrialisation des algorithmes pour les usages m√©tiers\n‚ö°Ô∏è L‚Äôensemble des traitements d‚Äôingestion et pr√©paration des datasets afin d‚Äôalimenter des Dashboard de monitoring de l‚Äôactivit√© digitale Worldwide d‚Äôun grand groupe cosm√©tique afin de mesurer l‚Äôempreinte des marques sur les m√©dias et r√©seaux sociaux\n‚ö°Ô∏è L‚Äôaccompagnement √† la cr√©ation et l‚Äôactivit√© d‚Äôune Data Factory pour traiter l‚Äôensemble des donn√©es d‚Äôun grand groupe de distribution et mettre √† disposition des donn√©es qualifi√©es pour les diff√©rents use cases m√©tiers\nNous recherchons un.e passionn√©.e poss√©dant une envie de de f√©d√©rer et faire monter en valeur les consultants autour des th√©matiques Data Engineering recouvrant la mise en place de Plateforme de donn√©es, des bonnes pratiques de d√©veloppements et des process DataOps, l‚Äôindustrialisation de pipeline de traitements de donn√©es pouvant aller jusqu‚Äô√† la Data Visualisation.\n‚ûú Dans quel environnement ?\nEn fonction de tes missions et r√©alisations projet, tu seras amen√©¬∑e √† int√©grer des √©quipes compos√©es de Data Engineer, Data Scientist, Data Architects, organis√©es en mode agile. Tes activit√©s s‚Äôappuieront sur les m√©thodes et savoir-faire de Saegus et sur son catalogue d‚Äôoutils et technologies sur lesquels tu as une ma√Ætrise sur plusieurs d‚Äôentre eux :\n‚úÖ Bonnes connaissances sur les architectures data et cloud (connaissance d‚Äôun environnement Cloud) :\nAzure (Data Factory, Synapse, ADLS, Databricks)\nGoogle GCP (BigQuery, Composer, Data Studio)\n‚úÖ SQL, Python\n‚úÖ Spark, PySpark\n‚úÖ Airflow, Kafka, Jenkins\n‚úÖ Solides connaissances des processus collaboratifs et outils de d√©veloppement (DevOps, Git, CI/CD‚Ä¶)\nLes connaissances suivantes seraient un plus ‚§µÔ∏è\nOpenShift, Docker, Kubernetes\nData visualisation\nBases NoSQL\nCertification Data Engineer (Azure Data Engineer, Google Professional Data Engineer ou Snowflake SnowPro)\nCe que nous t‚Äôapportons\nüí´\nFORMATIONS ET D√âVELOPPEMENT DE CARRI√àRE\nUne journ√©e de formation incluse dans ton parcours d‚Äôonboarding lors de ton premier mois d‚Äôarriv√©e pour partager sur les fondamentaux et r√©pondre √† tes questions\nAcc√®s √† un coach interne et consultant comme toi pour t‚Äôaccompagner dans ton quotidien (questions en particulier, aide, mont√©e en comp√©tences)\nUn plan de formations et de certifications ambitieux (minimum 1 certification offerte par an)\n‚≠êÔ∏è\nAVANTAGES\nRemboursement de tes frais de transports (remboursement √† 100% de ton pass navigo ou forfait mobilit√© durable jusqu‚Äô√† 700‚Ç¨ par an pour l‚Äôutilisation et l‚Äôaide √† l‚Äôachat de mat√©riel de mobilit√© douce)\nTitres restaurant √† hauteur de 216‚Ç¨/mois pris en charge √† 60% par Saegus (Carte Swile)\nPrime vacances (vers√©e en juin)\nPrime t√©l√©phone 25‚Ç¨/mois\nPrime d‚Äôint√©ressement aux r√©sultats de l‚Äôentreprise\nPrise en charge par Saegus de la mutuelle √† la hauteur de 75%\nüëã\nCOH√âSION ET CONVIVIALIT√â\nOrganisation de deux activit√©s par mois (fun, solidaire ou excellence) par notre Team Anim\nUn s√©minaire annuel pour favoriser la coh√©sion entre Saegusiens\nAcc√®s aux locaux de Saegus, tr√®s accueillants dans le centre de Paris notamment lors de nos SaegUp mensuel\nProfil recherch√©\nüéØ\nId√©alement, en termes de comp√©tences, nous recherchons\n:\nUn profil de formation sup√©rieure (Bac + 5 minimum), ing√©nieur ou √©quivalent, avec une exp√©rience d‚Äôau moins 3 ou 4 ans minimum dans le domaine du Big Data.\nTu as d√©j√† men√© avec succ√®s plusieurs projets Big Data avec des r√©f√©rences significatives dans la mise en place de flux de donn√©es et de traitement de l‚Äôinformation.\nTu interviens en autonomie sur tes projets et as une premi√®re exp√©rience d‚Äôencadrement technique.\nTu es motiv√©.e pour int√©grer une structure alliant l‚Äôexigence d‚Äôun cabinet de conseil et le dynamisme et l‚Äôagilit√© d‚Äôune start-up.\nTu es un¬∑e tr√®s bon¬∑ne communiquant¬∑e et as un fort esprit d‚Äôinitiative, un go√ªt prononc√© pour les nouvelles technologies et un bon esprit de synth√®se.\nTon sens du service et ton √©coute client te permettront de t‚Äôinscrire parfaitement dans la culture de notre cabinet de conseil.\nLa\nma√Ætrise de l‚Äôanglais et du fran√ßais\n√† l‚Äô√©crit et √† l‚Äôoral est indispensable.\nShow more\nShow less",
        "details": {
            "JobDetail": [],
            "TypeContract": "",
            "Salary": "",
            "Level": "",
            "Experience": "4 an(s)"
        },
        "title": "data engineer",
        "skills": {
            "ProgLanguage": [
                "Python"
            ],
            "DataBase": [
                "SQL",
                "NoSQL"
            ],
            "BigData": [
                "Databricks",
                "Spark"
            ],
            "CloudComputing": [
                "GCP",
                "Azure"
            ],
            "DevTools": [
                "Git",
                "Docker",
                "Jenkins"
            ],
            "DBMS": [
                "BigQuery",
                "Snowflake"
            ],
            "Automation": [
                "Airflow",
                "Kubernetes"
            ],
            "Containers": [
                "Docker",
                "OpenShift",
                "Kubernetes"
            ],
            "Other": [
                "Cloud",
                "Big Data",
                "DevOps",
                "CI/CD"
            ],
            "EnSoftSkils": [
                "Initiative"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "Fieldbox",
        "location": "Bordeaux, Nouvelle-Aquitaine, France",
        "link": "https://fr.linkedin.com/jobs/view/cloud-solution-architect-paris-bordeaux-remote-at-fieldbox-3881559118?position=1&pageNum=12&refId=8y50RlLjosG8MBxznoHMvA%3D%3D&trackingId=5syFOTC0OKuhrSV5QAbVRw%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Our business:\nWe help industrial companies to accelerate their digital transformation and dramatically improve their operational efficiency and competitiveness with data, software and AI. Our clients include CAC 40 companies, as well as small and medium-sized companies on five continents and over 150 industrial sites.\nWhat makes us special:\nWe offer a complete range of services, combined with the use of latest technologies, covering the entire lifecycle of data-driven solutions, from ideation, business value assessment, industrialized solution development, to deployment, run and scale.\nOur positioning:\nWe seek long term partnership-relation with our clients. We can help them define their digital strategy and AI roadmap, build & run a solution, train, and transfer skills, set up and professionalize R&D or innovation units or digital & AI factories.\nOur teams:\nA virtuous combination of three areas of expertise:\nBusiness expertise: industrial operations & engineering.\nTechnical expertise: data science, software engineering & devops.\nDelivery management expertise: managing digital projects and setting digital factories.\nYour missions:\nAs a Cloud Architect,you will design and participate in the implementation of cloud solutions to support the digital transformation of our clients. You will work in agile mode, in an international context, on industrial projects.\nYour main missions :\nSupport pre-sales technical activities by translating client‚Äôs requirements into state-of-the-art architectures, while guiding customers through their digital transformation journey in the cloud :\nLead workshops to study and define customer requirements\nImagine and define the architecture that would best meet the specifications provided while taking in account the financial and security constraints of the client.\nHandle and resolve technical questions and challenges encountered by clients during the first phases of their projects\nDefine deployment methodologies and integration of the solution into the existing client‚Äôs ecosystem.\nParticipate in pre-sales meeting with clients to present the envisioned architectures\nLead end-to-end architecture projects (web applications, data engineering & processing pipelines) involving intensive use of industrial data, with a focus on performance, scalability and security issues\nSupervise the deployment and industrialization of the target architectures\nEnsure the security and reliability of deployed environments\nWork in collaboration with multidisciplinary teams, including DevOps, back-end, front-end, data, product and business skills to make every project a success.\nExperience and skills required:\nAt least 2 years' experience in Architect or tech lead full stack role\nYou have experience with the following technologies:\nCloud: Azure, Google Cloud, AWS, OVH\nDatabases & storage : PostgreSQL, TimeScaleDB, Redis, InfluxDB, S3 and alike\nProcessing and scheduling: Azure Data Factory, Azure Functions, Azure Synapse, Airflow, Argo, AWS Batch, AWS Step\nStreaming: Kafka, RabbitMQ, Kinesis, SQS\nDevops: Docker, Kubernetes\nMoreover :\nYou have proven experience in cloud or hybrid architectures\nYou love architecture diagrams ! (Excalidraw, Draw.io)\nYou demonstrate technical leadership and are able to communicate complex ideas effectively.\nYou know how to challenge customer requirements and Fieldbox objectives in order to optimize the proposed architecture.\nYou successfully manage the complex constraints of a production application through analysis and resolution.\nYou are customer and solution-oriented and have excellent interpersonal skills.\nFluency in English\nKnowledge of an industrial sector is a plus\nKnowledge in python is a plus\nAdvantage and benefits:\nFull remote possible (Metropolitan France only)\nWhat about our offices\nBordeaux: meet with your colleagues in a peaceful and calm space with an amazing view on ‚ÄúLes bassins √† flots‚Äù\nParis: enjoy a coworking space on the top of the Montparnasse tower with a 360 view of Paris\nWhat about our values :\nJoin a company which values care where everyone is in position to reach their full potential\nYou will work within an energetic team with a strong technical skill. Weekly engineering are organized every week to present and discuss technical topics\nCreate immediate impact on the company\nA quiz is sent every month in order to improve your comfort at work\nFun Activity:\nAfterwork every month with different theme ( bowling , board game , darts, beers bar, etc. )\nLunch break : outside lunchs, board game parties, and sport! (running, badminton, darts, yoga)\nCTFs\nTypical process includes 3 steps :\nHR interview\nInterview with operational team, aiming at testing your fit to the specific job,\nInterview with one or several founders to validate the application\nShow more\nShow less",
        "details": {
            "JobDetail": [
                "Remote",
                "Full"
            ],
            "TypeContract": "",
            "Salary": "",
            "Level": "",
            "Experience": null
        },
        "title": "data architect",
        "skills": {
            "ProgLanguage": [
                "R",
                "Python"
            ],
            "DataAnalytics": [
                "R"
            ],
            "CloudComputing": [
                "AWS",
                "Azure"
            ],
            "DevTools": [
                "Docker"
            ],
            "DBMS": [
                "PostgreSQL"
            ],
            "Automation": [
                "Airflow",
                "Kubernetes"
            ],
            "Containers": [
                "Docker",
                "Kubernetes"
            ],
            "Collaboration": [
                "Teams"
            ],
            "Other": [
                "Cloud",
                "DevOps"
            ],
            "EnSoftSkils": [
                "Leadership",
                "Interpersonal Skills",
                "Collaboration"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "Equativ",
        "location": "Paris, √éle-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/sre-devops-engineer-at-equativ-3853748999?position=2&pageNum=12&refId=8y50RlLjosG8MBxznoHMvA%3D%3D&trackingId=X5d%2B8oiaEXeGYEkw2mowpA%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "üë´ About the team\nAt Equativ, we‚Äôre on a mission to develop advertising technologies that empower our customers to reach their digital business goals. This means that we rely on massively scalable, widely distributed, highly available, and efficient software systems; the platform deals with over 3 millions requests per second managed by 3,000 servers.\nOur innovation team based in Paris, Nantes, Limoges, Krakow and Berlin is composed of 100+ straightforward and energetic engineers working in an Agile environment and ready to tackle the most complex technical challenges.\nYour mission üëá\nWithin infrastructure BU you will join the Platform department that strives to develop and deploy self-serve tooling to empower our RnD team.\nAs a member of our application SRE team, you will work closely with dev and platform teams to:\nAccelerate time to market and reliability of our backend services\nEnsure that our platform availability fulfills its SLA of 99.95%\nWhat you will do ‚úèÔ∏è\nAs a backend application SRE, your key responsibilities will be:\nCommunication Bridge:\nAct as the primary liaison between the R&D and Platform, DevSecOps and Ops teams\nAligning Best Practices:\nImplement and align DevOps mindset and best practices, including SLOs framework, monitoring, and alerting, across diverse applications\nWork closely with dev teams to ensure adherence to industry standards and best practices, optimizing the efficiency and reliability of our platform\nKnowledge Sharing:\nFacilitate knowledge transfer sessions to empower development teams with increased autonomy on DevOps matters and improved services reliability\nProduction awareness:\nAssist on identifying service errors, instability patterns and latency issues\nActively participate in production impediments (PIMPs), postmortems, and incident handling, contributing to a proactive production environment\nProvide insights and recommendations for improving production processes and preventing future incidents\nAbout You üëã\nMaster degree in Computer science or similar field of study\n2+ years of System or Software Engineering experience ideally in the web industry\nFluent with DevOps practices\nExperience in at least one of the following topics: CI/CD pipelines (gitlab, ‚Ä¶), Kubernetes administration (Rancher, argoCD, ‚Ä¶), Monitoring and alerting (prometheus, grafana stack, ‚Ä¶) with a focus on backend applications\nExperience working with IaC (Terraform, GitOps, ‚Ä¶)\nAutonomous and innovative mindset\nWorking proficiency and communication skills in verbal and written English\nNice to have:\nExperience with troubleshooting live incidents and incident management\nExperience in software development (Go, Python or equivalent)\nHow you'll grow üöÄ\nWithin 1 month:\nYou'll be just finishing your onboarding\nYou'll probably have tackled a few small tasks with your peers\nWithin 4 months:\nYou'll be trusted to endorse weekly Green Lantern role to assist day to day BE requests\nYou'll be assigned to minor tasks to ramp up on our stacks and processes\nWithin 9 months:\nYou'll be leading critical projects (Priority 0)\nYou'll be evolving in our technical architecture discussion\nYou‚Äôll start getting a grasp on the AdTech business\nüëã About us\nEquativ is the new single name for Smart Adserver, DynAdmic, LiquidM and Nowtilus ‚Äî four proven innovators in advertising technology. The vertically integrated company provides brand and privacy-safe solutions that empower its clients to achieve maximum impact while respecting the rights of consumers. The union combines client expertise and engineering excellence to serve the interests of both the supply- side and demand-side with equal professionalism and technical sophistication.\nHeadquartered in Paris and New York, Equativ operates globally with a team of more than 550 people in 20 offices. Equativ offers the market its own independent ad server, SSP, buyer tools, and media services to fulfill the promise of advertising technology. Learn more at Equativ.com.\nThe company is ranked on the Deloitte Technology Fast 500 EMEA and in the Financial Times‚Äô FT 1000: Europe‚Äôs Fastest-Growing Companies.\nEquativ (formerly Smart AdServer) has been awarded the HappyIndex@Work label and is proud to be among the best companies in the ChooseMyCompany ranking, recognized for its flexible working environment.\nCome and lead the charge with us in building a transparent ecosystem based on quality!\nEquativ is an equal opportunity employer. Equal access to employment, services, and programs are available to everyone, regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity, or Veteran status. If you require reasonable accommodation throughout the application and/or interview process, please contact the recruitment team at ta-team@equativ.com\nShow more\nShow less",
        "details": {
            "JobDetail": [],
            "TypeContract": "",
            "Salary": "",
            "Level": "",
            "Experience": null
        },
        "title": "devops",
        "skills": {
            "ProgLanguage": [
                "R",
                "Python"
            ],
            "DataAnalytics": [
                "R"
            ],
            "Automation": [
                "Kubernetes"
            ],
            "InfrastructureAsCode": [
                "Terraform"
            ],
            "Containers": [
                "Kubernetes"
            ],
            "Collaboration": [
                "Teams"
            ],
            "Other": [
                "DevOps",
                "CI/CD"
            ],
            "EnSoftSkils": [
                "Communication"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "Visian",
        "location": "Paris, √éle-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/ing%C3%A9nieur-devops-ia-at-visian-3894692222?position=3&pageNum=12&refId=8y50RlLjosG8MBxznoHMvA%3D%3D&trackingId=tDK9gJ87Tl%2FCiaK%2BDaCOYA%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Visian recherche pour son client grand compte bancaire un profil\nIng√©nieur(e) DevOps IA\n.\nLe contexte :\nLe socle Data Cloud de notre client con√ßoit et op√®re des plateformes ¬´ as a service ¬ª facilitant la mise en place d‚Äôarchitectures modernes, distribu√©es et hautement r√©silientes pour l‚Äôensemble des entit√©s du groupe.\nEn tant que\nData ops engineer\n, vous rejoindrez l‚Äô√©quipe data, actuellement constitu√©e de 40 personnes et organis√©e en 7 devs teams orient√©es produit dont le p√©rim√®tre s‚Äô√©tend de la conception du service √† son maintien en condition op√©rationnelle en production.\nEn tant que data ops engineer, vous √©voluerez dans un environnement technique complexe, distribu√©, s√©curis√© et hautement disponible. Vous travaillerez au sein d‚Äôune dev team affect√©e √† un produit en particulier et serez sollicit√© en fonction de vos expertises pour accompagner les autres dev teams data.\nLes missions :\nEn qualit√© d'Ing√©nieur(e) DevOps IA, vos principales missions seront les suivantes :\nMise en ≈ìuvre op√©rationnelle et techniques des produits Data :\nIndustrialiser et automatiser\nDocumenter les offres\nApporter une expertise technique\nMettre en production\nD√©finir des architectures\nD√©velopper des prototypes en lien avec les cas d‚Äôusages des entit√©s\nD√©montrer la valeur des offres Data aupr√®s des entit√©s\nParticiper au Daily meeting anim√© par le Squad Lead\nParticiper aux r√©unions de co-construction de la roadmap et de la mise en ≈ìuvre de la roadmap sous la gestion du product owner Data et du responsable du Squad dont il d√©pend\nPrendre des √©l√©ments de la backlog qui a √©t√© formalis√© par le Squad Lead et met en ≈ìuvre les √©l√©ments de la backlog\nRendre compte des difficult√©s auxquelles il est confront√© et propose des solutions pour les r√©soudre\nTravailler en √©quipe avec son Squad\nEtre Lead sur un produit technique au sein du Squad\nParticiper √† l‚Äô√©laboration des formations, des pr√©sentations aux r√©f√©rents Clusters et Entit√©s qui consomment ou pourraient consommer les produits dont a g√©r√© la mise en ≈ìuvre\nParticiper aux d√©monstrations de la plateforme\nParticiper √† l‚Äôensemble des rituels du Squad, de la plateforme et du socle\nPROFIL ATTENDU :\nTitulaire d'un dipl√¥me BAC+5 (√©cole d'ing√©nieur, √©cole de commerce, universit√©)\nVous justifiez d'une exp√©rience minimum de 3 ans en qualit√© d'Ing√©nieur Devops\nAnglais professionnel √† minima\nShow more\nShow less",
        "details": {
            "JobDetail": [],
            "TypeContract": "",
            "Salary": "",
            "Level": "Bac+5",
            "Experience": "3 an(s)"
        },
        "title": "devops",
        "skills": {
            "Collaboration": [
                "Teams"
            ],
            "Other": [
                "Cloud",
                "DevOps"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "Stack Labs",
        "location": "Paris",
        "link": "https://fr.linkedin.com/jobs/view/cloud-native-data-engineer-at-stack-labs-3918055497?position=4&pageNum=12&refId=8y50RlLjosG8MBxznoHMvA%3D%3D&trackingId=OuleBYg%2BjZAPnFR7S40zBw%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Pr√©sentation de l‚Äôentreprise :\nFond√©e par des passionn√©s de tech en 2017, Stack Labs est n√©e d‚Äôune conviction : privil√©gier l‚Äôexcellence technique et le partage de connaissances pour adresser les enjeux du Cloud.\nDans un contexte o√π les entreprises doivent acc√©l√©rer leur transformation num√©rique et s‚Äôadapter aux challenges de la migration vers le Cloud, nous avons acquis notre cr√©dibilit√© √† travers les projets strat√©giques de nos clients mais surtout gr√¢ce √† notre rayonnement dans les diff√©rentes communaut√©s et conf√©rences techniques dans le monde du Cloud (Devoxx, DevFest, GDG, etc.)\nPartenaire reconnu de Google (Partner of the year Google 2023 en France), et d‚ÄôAWS nous explorons toutes les nouvelles stacks techniques et les impl√©mentons sur des projets dans le secteur du spatial, IoT, fintech, automobile, a√©ronautique, etc.\nNotre devise : construire ensemble, partager nos connaissances et nos expertises au service de projets et produits ambitieux et innovants.\nEt concr√®tement ? Les stackers sont des experts tech qui interviennent sur des projets impliquant des technologies li√©es aux infrastructures √©lastiques. L‚Äô√®re du Cloud exige un apprentissage continu : les stackers d√©veloppent leur expertise √† travers de la veille et des codelabs sur du temps d√©di√© (une demi-journ√©e tous les 15 jours).\nNous recherchons avant tout des personnes engag√©es, ayant envie d‚Äôapprendre continuellement, qui portent nos valeurs de partage et de travail en √©quipe.\nDescription du poste :\nPour renforcer notre √©quipe data et accompagner notre croissance, nous recherchons actuellement un Data Engineer, avec une app√©tence pour les solutions Cloud.\nDe part votre m√©tier, vous serez amen√©(e) √† intervenir d√®s les phases amont de projets de migration cloud pour des clients √† forts enjeux de scalabilit√© sur du conseil technique et sur les fondamentaux du cloud public (infra as code & automatisation, s√©curit√©, observabilit√© ) jusqu‚Äô√† la mise en service des solutions.\nReconnu(e) pour votre polyvalence au sein des √©quipes, vous √™tes orient√©(e) aussi bien vers la sph√®re technique que vers l‚ÄôHumain.\nNotre √©cosyst√®me technique (indicatif, variable en fonction des missions) :\nArchitecture Data : ETL, ELT, Dataflow, Spark, Airflow, GCP Workflows\nBig Data: BigQuery, Firestore, Redshift, Athena, MongoDB\nContainers & microservices : Docker, Kubernetes, Istio,...\nArchitectures orient√©es messages : Kafka, PubSub,..\nAutomatisation & Infrastructure as Code (IaC) : Terraform, CloudFormation, Ansible, GitLab, GitHub,...\nPublic Cloud : AWS, GCP, ...\nLangages de d√©veloppement : Python, Go, Java...\nProfil Recherch√© :\nVous disposez de plusieurs exp√©riences en tant Data Engineer sur des plateforme cloud public, notamment dans la mise en place de pipelines et le traitement automatis√© des donn√©es. Vous avez une vraie app√©tence pour les technologies Cloud, et de l‚Äôexp√©rience sur au moins un fournisseur Cloud. Moteur au sein des √©quipes, vous √™tes naturellement tourn√©(e) vers la proactivit√©, le partage et la bienveillance. Plus qu‚Äôun profil type, nous recherchons chez Stack Labs des personnes proches de notre ADN : passionn√©es de tech, curieuses et disposant d‚Äôune v√©ritable ‚Äúsoif d‚Äôapprentissage‚Äù.\n√âvoluer avec Stack Labs, c‚Äôest ?\nS'√©panouir, apprendre et transmettre, au sein d‚Äôune v√©ritable communaut√© d'experts techniques du cloud.\nTravailler et acqu√©rir de l‚Äôexp√©rience sur des technologies √† fort potentiel strat√©gique\n√ätre form√©(e)/certifi√©(e) sur vos environnements de pr√©dilection (GCP, AWS, K8S,..)\nDevenir ambassadeur/ambassadrice de l‚Äôadoption des environnements Cloud\nAvoir la possibilit√© de r√©diger des articles, de pitcher, de devenir formatrice/formateur\nLa possibilit√© d'√©voluer vers un r√¥le de leader technique\nLes plus du Stacker :\n12 ‚ÄúStack Day‚Äù par an: une journ√©e tous les mois √† l‚Äôagence (Paris 9 ou Toulouse) consacr√©e aux retours d‚Äôexp√©riences, √† la veille et √† l‚Äôexploration de nouveaux sujets techniques\nDes conf√©rences pour se former et pitcher\nUn pack de bienvenue avec du mat√©riel de travail: choisissez votre propre configuration!\nLa flexibilit√©: possibiliter de t√©l√©travail en fonction des contextes clients.\nParticiper √† des √©v√®nements: afterworks, manifestations internes (soir√©es, team building, s√©minaires, etc.)\nShow more\nShow less",
        "details": {
            "JobDetail": [],
            "TypeContract": "",
            "Salary": "",
            "Level": "",
            "Experience": null
        },
        "title": "data engineer",
        "skills": {
            "ProgLanguage": [
                "Java",
                "Python"
            ],
            "DataBase": [
                "MongoDB"
            ],
            "BigData": [
                "Spark"
            ],
            "CloudComputing": [
                "GCP",
                "AWS"
            ],
            "DevTools": [
                "Docker"
            ],
            "DBMS": [
                "BigQuery"
            ],
            "Automation": [
                "Airflow",
                "Kubernetes",
                "Ansible"
            ],
            "InfrastructureAsCode": [
                "CloudFormation",
                "Terraform"
            ],
            "Containers": [
                "Docker",
                "Kubernetes"
            ],
            "Other": [
                "Cloud",
                "Big Data"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "Amadeus",
        "location": "Sophia Antipolis, Provence-Alpes-C√¥te d'Azur, France",
        "link": "https://fr.linkedin.com/jobs/view/cloud-solutions-engineer-at-amadeus-3890146341?position=5&pageNum=12&refId=8y50RlLjosG8MBxznoHMvA%3D%3D&trackingId=LG6bM3k3qqDbRR8X8RTx5Q%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Job Title\nCloud Solutions Engineer\nSummary Of The Role\nAmadeus R&D's transversal unit within the TEC organization is dedicated to delivering cloud platform capabilities, middleware components, and services to all Amadeus applications, serving clients worldwide in various sectors such as airline, hospitality, and travel agencies. This team focuses on ensuring strong resiliency, scalability, security, and reusability of frameworks, resources, and services. As part of this forward-thinking department, you will analyse demands, develop comprehensive solutions, and provide cost estimations for future years, crucial for building business cases and determining investment decisions. Collaborating closely with stakeholders, including responding to customer RFPs and participating in solution design coordination, the team offers valuable expertise on requirements impacting the platforms.\nIn This Role You Will\nCollect and clarify the requirements from the requester (R&D, Business Units, finance Guardrails)\nCoordinate the design of the solution in collaboration with architects and/or technical product managers regarding the platform needs.\nAssess the cost of these solutions, evaluating several scenarios, in collaboration with R&D.\nExpose the solution with the corresponding cost to top management, focusing on specificities, assumptions, and forecasts.\nExplain the cost estimations related to assumptions, and how assumptions have been chosen.\nCommunicate with requester, sometime Amadeus customer or acquired companies.\nInteract with finance providing budget input, with the platform delivery teams to launch the execution, with Product managers to see what can be done, and possibly influence the platform evolution.\nPotentially influence the platform evolution backlog in line with the technical product managers.\nAbout The Ideal Candidate\nBachelor‚Äôs degree in computing engineer or related field.\nExperience in a similar role\nExperience in computing, product management, and understanding of business cases.\nStrong notions in Architecture, Data Stores, network, computing.\nKnowledge in finance, business cases.\nFluent in English with excellent communication skills\nWhat We Can Offer You\nAdd your voice to a multicultural team of 16,000+ professionals.\nWork at one of the world‚Äôs top 15 software companies.\nChallenge yourself to find solutions to complex problems.\nFlexible hybrid work from 1-2 days per week.\nCompetitive compensation and benefits package.\nApplication process\nCreate your candidate profile in our system and upload your recent resume! Once you have applied, you‚Äôll receive feedback within 15 days.\nAre you ready to leave your footprint? Be the power behind better journeys.\nDiversity & Inclusion\nWe are an Equal Opportunity Employer and seek to hire the best candidate regardless of age, beliefs, disability, ethnicity, gender or sexual orientation.\nShow more\nShow less",
        "details": {
            "JobDetail": [],
            "TypeContract": "",
            "Salary": "15",
            "Level": "",
            "Experience": null
        },
        "title": "cloud architect /engineer ",
        "skills": {
            "ProgLanguage": [
                "R"
            ],
            "DataAnalytics": [
                "R"
            ],
            "Collaboration": [
                "Teams"
            ],
            "Other": [
                "Cloud"
            ],
            "EnSoftSkils": [
                "Communication",
                "Organization",
                "Collaboration"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "iPepperGroup",
        "location": "Alpes-de-Haute-Provence, Provence-Alpes-C√¥te d'Azur, France",
        "link": "https://fr.linkedin.com/jobs/view/ing%C3%A9nieur-cloud-devops-h-f-at-ipeppergroup-3914494594?position=6&pageNum=12&refId=8y50RlLjosG8MBxznoHMvA%3D%3D&trackingId=FDT%2BcDaYoC399sAYg%2Ffheg%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Nous sommes le partenaire technologique pr√©f√©r√© de ceux qui changent le monde ! iPepper c'est avant tout une fa√ßon de travailler ensemble : se faire du bien, faire du bien et prendre soin de ses clients, salari√©s et partenaires ! Coaching, Recrutement et Conseil : une palette de services autour de la protection et la valorisation de la data.\nLe Poste\nNous recherchons plusieurs Cloud / DevOps Engineer talentueux(ses) pour rejoindre l'aventure iPepper sur Nantes et sa p√©riph√©rie. Responsabilit√©s : - Concevoir, mettre en ≈ìuvre et maintenir une infrastructure Cloud, en utilisant des services tels que AWS, Azure, ou Google Cloud Platform, - Automatiser les processus de d√©ploiement et de gestion de l'infrastructure √† l'aide d'outils tels que Ansible ou Terraform, - Collaborer avec les √©quipes de d√©veloppement pour d√©finir les meilleures pratiques en mati√®re de d√©veloppement et d'exploitation des syst√®mes, - Mettre en place des pipelines d'int√©gration continue et de d√©ploiement continu, - Surveiller et analyser les performances du syst√®me, et proposer des am√©liorations, - Assurer la s√©curit√© et la conformit√© des syst√®mes et des donn√©es, - G√©rer les outils de surveillance tels que Prometheus, Grafana, et Datadog.\nProfil Recherch√©\nNotre TOP profil poss√®de : - Minimum de 4 ans d'exp√©rience professionnelle en tant que Cloud / DevOps Engineer, - Une solide exp√©rience dans la mise en place et la gestion d'infrastructures Cloud (AWS, Azure, GCP), - Une exp√©rience pratique avec les outils de surveillance tels que Prometheus, Grafana et Datadog, - Une connaissance des outils de conteneurisation tels que Docker et Kubernetes, - Des comp√©tences en scripting et en d√©veloppement (Python, Shell, PowerShell, etc.), - De bonnes connaissances en r√©seaux, - Une capacit√© √† travailler en √©quipe et √† collaborer efficacement avec les d√©veloppeurs, - D'excellentes comp√©tences en r√©solution de probl√®mes et en d√©pannage. Rejoignez nous !\nShow more\nShow less",
        "details": {
            "JobDetail": [],
            "TypeContract": "",
            "Salary": "",
            "Level": "",
            "Experience": "4 an(s)"
        },
        "title": "devops",
        "skills": {
            "ProgLanguage": [
                "Python"
            ],
            "CloudComputing": [
                "GCP",
                "AWS",
                "Google Cloud Platform",
                "Azure"
            ],
            "DevTools": [
                "Docker"
            ],
            "Automation": [
                "Kubernetes",
                "Ansible"
            ],
            "InfrastructureAsCode": [
                "Terraform"
            ],
            "Containers": [
                "Docker",
                "Kubernetes"
            ],
            "Other": [
                "Cloud",
                "DevOps"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "Team.is",
        "location": "Bordeaux, Nouvelle-Aquitaine, France",
        "link": "https://fr.linkedin.com/jobs/view/devops-platform-engineer-sre-en-full-remote-h-f-at-team-is-3917051324?position=7&pageNum=12&refId=8y50RlLjosG8MBxznoHMvA%3D%3D&trackingId=r2USnfuOCwrDBxkPaXNa3A%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Lanc√© en 2021, Team.is est une start-up de recrutement sp√©cialis√©e dans la chasse et le recrutement de profils IT, Digital, Ing√©nierie & Supply Chain.\nTeam.is c'est avant tout une entreprise √† taille humaine anim√©e par la passion du recrutement !\nTeam.is poss√®de l'expertise et l'√©nergie pour s'attaquer √† n'importe quel d√©fi. Mais nous ne sommes pas des robots du recrutement. Nous sommes des consultants qui vivent et respirent ce que nous faisons ! Nous sommes d√©termin√©s √† r√©aliser le meilleur travail possible pour cultiver des relations durables avec nos candidats et nos clients.\nEn postulant √† cette offre, vous aurez l'opportunit√© de rejoindre une entreprise prometteuse avec une forte diversit√© de projets. Notre client est une soci√©t√© de plate-forme de connectivit√© cellulaire offrant √† l'industrie automobile une nouvelle fa√ßon de permettre et d'am√©liorer le fonctionnement de ses voitures connect√©es √† l'√©chelle mondiale.\nFond√©e en 2021 par des entrepreneurs t√©l√©coms chevronn√©s et d'anciens cadres d'acteurs des t√©l√©coms, de l'IOT, de la voiture connect√©e et de la t√©l√©matique, l'entreprise recherche pour compl√©ter son √©quipe un Plateform Engineer H/F\nVos Missions Si Vous Les Acceptez\nAu sein de l'√©quipe Platform Engineering, vous participerez √† la d√©finition et √† l'√©laboration des infrastructures Kubernetes n√©cessaires au d√©veloppement et √† l'op√©ration de leurs solutions :\nCr√©ation et administration avec ArgoCD et CrossPlane de clusters Kubernetes dans le cloud public (aujourd'hui AWS) et priv√©\nMise en place et maintien de la haute disponibilit√©, ainsi que des solutions de logs et de m√©triques de l'infrastructure et des applicatifs\nInterconnections multi-clusters\nGestion des droits et de l'authentification, mise en place et maintien de la s√©curit√© op√©rationnelle\nD√©ploiement de services transverses (DB, r√©seau, etc.)\nD√©veloppement de CRD et d'op√©rateurs Kubernetes\nAutomatisation des proc√©dures de d√©ploiement et gestion des images Docker\nFormation des √©quipes √† Kubernetes et √† l'IaC\nAvantages\nNotre client √©tant organis√© en Holacratie, vous aurez toute libert√© de proposer le ou les roles que vous souhaiterez assumer afin de faire b√©n√©ficier au mieux l'√©quipe de votre exp√©rience. Vous pourrez √©galement d√©velopper de nouvelles comp√©tences en choisissant d'autres roles.\nL'entreprise propose du 100% t√©l√©travail, vous pourrez travailler de n'importe o√π en France. Si vous √™tes situ√© dans la r√©gion toulousaine ou ni√ßoise, il y a √©galement la possibilit√© de faire du co-working ponctuel.\nAutres Avantages\nEntre 8 et 11 jours de RTT par an\n3000‚Ç¨ HT de budget d'installation pour vous √©quiper - ce budget inclu votre laptop (Fame.work ou Macbook Pro)\n57.20 ‚Ç¨ / mois de prime t√©l√©travail\n2 rassemblements d'une semaine par an quelque part en France avec toute l'√©quipe\nPossibilit√© de co-working\nEt vous ?\nVous avez une exp√©rience comme Platform Engineer, DEVOPS ou SRE. Vous √™tes autonomes et vous aidez vos coll√®gues √† r√©soudre leurs probl√®mes gr√¢ce √† votre infrastructure. Vous parlez fran√ßais et vous √™tes √† l'aise en anglais. Bonus\nConnaissance r√©seaux et T√©l√©com\nAdministration syst√®me (gestion de data center)\nGestion de base de donn√©es\nMise en oeuvre de pratiques agile\nLe cadre technique de leur solution\nCloud public : AWS et GCP\nCloud priv√© : Equinix\nCI sur GitHub Actions + ArgoCD\nKubernetes et CrossPlane\nShow more\nShow less",
        "details": {
            "JobDetail": [],
            "TypeContract": "",
            "Salary": "",
            "Level": "",
            "Experience": null
        },
        "title": "devops",
        "skills": {
            "CloudComputing": [
                "GCP",
                "AWS"
            ],
            "DevTools": [
                "Docker"
            ],
            "Automation": [
                "Kubernetes"
            ],
            "Containers": [
                "Docker",
                "Kubernetes"
            ],
            "Other": [
                "Cloud",
                "DevOps"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "Apside",
        "location": "√éle-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/data-engineer-aws-s%C3%A9nior-at-apside-3825002635?position=8&pageNum=12&refId=8y50RlLjosG8MBxznoHMvA%3D%3D&trackingId=v3xp0zgIatvLsYT9k37s5Q%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "üí•\nD√©couvrez la Vie Apsidienne\nüìπ\net vous aussi, devenez Apsidien\nOn aurait pu demander √† Chat GPT de vous d√©montrer en quoi\nApside est l‚ÄôESN qu‚Äôil vous faut,\nmais on pr√©f√®re que vous le d√©couvriez vous-m√™mes üëáüòè\nüî•\nD√©couvrez votre future mission\nüëâ\nContexte\nRejoignez notre Practise Cloud/Data, afin d‚Äôintervenir sur des sujets √† haute valeur ajout√©e !\nDans le cadre du renforcement de leur √©quipe data, notre client recherche un data ing√©nieur qui sera amen√© √† travailler sur la mise en ≈ìuvre de plusieurs produits data visant √† l'exposition et la mise en qualit√© des donn√©es de r√©f√©rences.\nL'environnement de travail est sur le cloud AWS avec terraform en infra as code\nSecteur\n: culture/m√©dia\nM√©thode de travail\n: Agile / Scrum\nüòé Mission\nIngestion et traitement des sources de donn√©es\nPr√©paration des donn√©es (transformation fonctionnelle et technique)\nElaboration de syst√®me avanc√© de gestion de qualit√© de donn√©es\nElaboration d'API/workflow\nExposition des donn√©es (Elasticsearch, RDS) via des API pour les applications front\nPr√©paration des package de livraison en Infra as code\nGestion du cycle de livraison en production\nMCO\nR√©daction des documentations techniques\n‚Ä¶\nEnvironnement technique\n:\nAWS (lambda, EMR, APIGateway, cognito ...)\nPython\nTerraForm\nGit CI/CD\nElasticsearch\nPySpark\nJSON\nSQL (PostgreSQL)\nüìç\nLocalisation\nLa D√©fense\nüí∞\nLe package salarial que nous vous proposons\nContrat :\nCDI\nAvantages groupe :\ncarte ticket restaurant Swile, prime de mobilit√©, RTT, accord t√©l√©travail, Mutuelle, prime de cooptation, avantages CE, prise en charge de la mutuelle √† 100% etc‚Ä¶\nAvantages agence :\nint√©gration de la Practise Cloud/Data, afterworks, communaut√© techlead\nFormation :\ncertifications techniques, cours particuliers d‚Äôanglais en interne, acc√®s √† un catalogue de formations gr√¢ce √† notre plateforme e-learning (\nAcademy by Apside\n) ou via nos organismes partenaires.\nüîÆ\n√î vous futur Apsidien, qui √™tes-vous ?\nAu moins 5 ans d'exp√©rience en tant que Data Engineer\nMaitrise de l‚Äôenvironnement cloud AWS\nForce de proposition, bon relationnel et autonome\nüòè\nApside a suscit√© votre curiosit√© ?\nDans un environnement marqu√© par une acc√©l√©ration des √©volutions technologiques, de transformations des usages et de disruptions majeures, Apside est un partenaire de confiance qui accompagne ses clients √† cr√©er de la valeur et √† adresser leurs enjeux strat√©giques en leur mettant √† disposition des expertises technologiques (\nData / IA, Cloud, Cyber\n) et une exp√©rience sectorielle (\nIndustrie, Banque, Assurance, Service, Secteur Public\n). Pour un accompagnement global, le groupe propose des offres transverses autour du\nHandicap\n(Apsid‚ÄôEA), du\nDigital Learning\n, et du\nConseil\n.\nü§î\nEt votre place dans tout √ßa ?\nüëâ Notre volont√©\nest de vous accompagner dans la construction et l‚Äô√©panouissement de votre carri√®re\nen nous appuyant notamment\nsur 3 piliers :\nUne\nr√©mun√©ration\n√† hauteur de vos investissements et de vos comp√©tences\nUne\ntrajectoire professionnelle\nstimulante sur mesure\nUn\nengagement\nautour des valeurs Apsidiennes : la qualit√© de vie et des conditions de travail au c≈ìur de nos enjeux\nEngag√©e pour\nun monde plus inclusif et plus responsable\n, Apside r√©invente l‚ÄôESN et propose l‚ÄôEngagement Soci√©tal et Num√©rique. D√©couvrez notre d√©marche RSE ainsi que notre vision de l‚ÄôEntreprise Engag√©e.\nConvaincu ? A vous de jouer, envoyez-nous votre CV !\nRejoignez l‚Äôaventure Apsidienne et d√©couvrez notre vision d‚Äôune ESN singuli√®re et r√©siliente\nüöÄ\nShow more\nShow less",
        "details": {
            "JobDetail": [],
            "TypeContract": "CDI",
            "Salary": "100",
            "Level": "",
            "Experience": "5 an(s)"
        },
        "title": "data engineer",
        "skills": {
            "ProgLanguage": [
                "Python"
            ],
            "DataBase": [
                "Elasticsearch",
                "SQL"
            ],
            "DataSerialization": [
                "Json"
            ],
            "CloudComputing": [
                "AWS"
            ],
            "DevTools": [
                "Git"
            ],
            "DBMS": [
                "PostgreSQL"
            ],
            "InfrastructureAsCode": [
                "Terraform"
            ],
            "Other": [
                "Cloud",
                "CI/CD"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "Density",
        "location": "Paris, √éle-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/infrastructure-engineer-at-density-3728504793?position=9&pageNum=12&refId=8y50RlLjosG8MBxznoHMvA%3D%3D&trackingId=uoVn7tIzShVVE0c6RFokAw%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "About Density\nDensity's mission is to measure and improve our footprint on the world.\nWe help companies understand how their workplaces are used. At Density, we build one of the most advanced people sensing systems in the world. Density can tell you how many people are in any room in near real-time, with very high degrees of accuracy and without invading privacy.\nWe translate that data into actionable, opinionated insights that help companies increase the financial and experiential performance of any workplace. Today, we work with companies ranging from Fortune 1000 to high growth such as Uber, Pinterest, Shopify and Okta, occupying more than a billion square feet worldwide.\nThe result: lower emissions, less waste, better access, safer buildings and better designed cities. It is a long term pursuit and one we could use your help achieving. That's where you come in.\nThe opportunity:\nWe're looking for talented Infrastructure Engineers to help us build one of the most advanced people sensing systems in the world. We're architecting infrastructure where annual, unscheduled downtime is measured in minutes. We're building intelligent redundancies so missed events are an oddity. The Infrastructure team is responsible for all of the cloud resources that power Density's business. We're a small group of engineers with broad experience and a passion for building reliable systems and thoughtful tools. Our positioning within Density is unique‚Äî our customers are other members of the engineering team. The products we build help application engineers deliver value to Density's customers quickly and effectively. As a Senior Infrastructure Engineer, you will help define, design, build, and manage the infrastructure that enables these products.\nIn this role you will:\nOwn, operate, and maintain production Kubernetes clusters running thousands of containers.\nBe a core contributor to our roadmap initiatives, namely our migration to Kubernetes and re-architecture of internal tooling. Since we are transitioning to Kubernetes, having knowledge of Nomad is not a requirement but a nice to have.\nLook for areas of improvement across our stack, design a solution, and see it through to production.\nEvangelize new designs and work with developer feedback to build a system that is robust, easy to use, and satisfies the use case.\nParticipate in 24/7 on call rotation for infrastructure issues. Participate in and coordinate incident response during production outages.\nFind satisfaction in working remotely from your home.\nThe ideal candidate will have:\n5+ years experience in an SRE, Infrastructure or DevOps role.\nBackground operating and maintaining container orchestration platforms like Kubernetes\nExperience with automation and configuration management tools like Terraform, Packer, Ansible, or equivalent\nStrong background in Linux/Unix fundamentals, including systemd, shell scripting, performance tuning\nAbility to design and manage CI / CD pipelines (ArgoCD, Helm, Sops, Github Actions .. )\nExperience with incident response processes and outage resolution\nStrong writing skills; ability to craft clear and concise documentation\nNice-To-Have:\nSignificant prior experience with observability and logging platforms such as DataDog and OpenSearch.\nSignificant prior experience operating and maintaining high performance logging and metrics pipelines using Vector, Fluentd, or similar.\nExperience using observability tools to tie metrics to application scaling.\nHave built metrics pipelines processing 100,000s or 1,000,000s of lines per minute.\nExperience operating APIs and web applications, like Go Gin/Connect-GO, Rust, Python Django/Flask,etc.\nA solid understanding of Linux security fundamentals.\nWe offer:\nA company full of fun, smart, talented and legitimately kind teammates. Our culture powers everything we do and we work hard to nurture it by bringing on the right humans.\nA team hailing from innovators like Apple, LinkedIn, Stripe, Meraki, Flexport, WeWork, NASA & beyond.\n$227M raised from investors including Kleiner Perkins, Founders Fund and Upfront Ventures.\nThe chance to change the built world as we know it.\nYou can read more about our values here.\nDensity provides equal employment opportunities to all employees and applicants for employment and prohibits discrimination and harassment of any type without regard to race, color, religion, age, sex, national origin, disability status, genetics, protected veteran status, sexual orientation, gender identity or expression, or any other characteristic protected by federal, state or local laws.\nThis policy applies to all terms and conditions of employment, including recruiting, hiring, placement, promotion, termination, layoff, recall, transfer, leaves of absence, compensation and training.\nJob Compensation Range:\nSalary Range: ‚Ç¨60,000.00 - ‚Ç¨90,000.00\nPreferred Primary Location: Paris, France\nAn important note on salary:\nThe annual pay range for this position is based on the preferred primary location of the role which is listed above. If you are applying to this role at a location that is not the preferred primary location, please keep in mind the salary range will vary and may fall outside of what is listed. Only in truly rare and exceptional circumstances, where an external candidate has experience, credentials or expertise that far exceed those required or expected for the position, would the Density consider paying a salary or rate near the higher end of the range. Equity may be provided as part of the compensation package, in addition to a full range of medical, financial, and/or other benefits, depending on the position offered.\nShow more\nShow less",
        "details": {
            "JobDetail": [
                "Remote",
                "Full",
                "Senior"
            ],
            "TypeContract": "",
            "Salary": "60,000",
            "Level": "",
            "Experience": null
        },
        "title": "Other",
        "skills": {
            "ProgLanguage": [
                "Python"
            ],
            "OS": [
                "Linux"
            ],
            "Automation": [
                "Kubernetes",
                "Ansible"
            ],
            "InfrastructureAsCode": [
                "Terraform"
            ],
            "Containers": [
                "Kubernetes"
            ],
            "Other": [
                "CI / CD",
                "Cloud",
                "DevOps"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "CryptoNext Security",
        "location": "Paris, √éle-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/software-test-engineer-at-cryptonext-security-3900395021?position=10&pageNum=12&refId=8y50RlLjosG8MBxznoHMvA%3D%3D&trackingId=xXr22hyfsDyeykii9W0uxg%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "CryptoNext Security is seeking a highly motivated and skilled\nSoftware Test Engineer / ing√©nieur de test et validation logiciels\nto join our R&D team focused on post-quantum cryptography. The ideal candidate will have a strong background in software development and cybersecurity solutions with a passion for pushing the boundaries of what is currently possible in the field.\nWorking within CryptoNext R&D, the Software Test Engineer plays a critical role in ensuring the quality and reliability of software products. He focus on testing procedures, identifying and reporting issues, and collaborating with development teams.\nPrincipal duties and responsibilities\nDesign and implementing testing strategies, testing procedures:\nDevelop testing procedures to evaluate the performance and validation of software.\nBuild software testing programs that automate testing processes.\nExecuting Testing Procedures:\nRun software testing procedures to assess the software‚Äôs functionality\nDocument all testing procedures and report any identified bugs.\nMake recommendations to improve the software product.\nCollaboration:\nWork closely with other Test Engineers, Software Programmers, and team members.\nAttend meetings with the development team and clients.\nKnowledge, skills, abilities, degree\nEducation and experience:\nEngineering Degree.\nExperience at least 2 years of experience in software testing, preferably for cybersecurity products.\nTechnical skills:\nProficiency in testing tools,\nKnowledge of scripting languages and programming languages such as C/C++.\nLanguage: excellent French / English communication skills (both written and spoken).\nInterpersonal skills:\nStrong analytical and problem-solving abilities.\nEffective planning and organizational skills.\nAbility to work independently and as part of a team.\nTerms of employment\nBased in Paris, hybrid work.\nFull time position\nCDI (Contrat √† Dur√©e Ind√©termin√©e), under French Law.\nSalary competitive and commensurate with experience.\nShow more\nShow less",
        "details": {
            "JobDetail": [
                "Full"
            ],
            "TypeContract": "CDI",
            "Salary": "Salary",
            "Level": "",
            "Experience": null
        },
        "title": "software engineer",
        "skills": {
            "ProgLanguage": [
                "R"
            ],
            "DataAnalytics": [
                "R"
            ],
            "Collaboration": [
                "Teams"
            ],
            "EnSoftSkils": [
                "Interpersonal Skills",
                "Communication",
                "Collaboration"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "Seyos",
        "location": "St.-Maurice, √éle-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/data-engineer-devops-h-f-at-seyos-3786210667?position=1&pageNum=15&refId=OMURzinLd5E%2BW2XWlKoc1w%3D%3D&trackingId=I4wCQ10w4vfBbBurtFbRzA%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Description\nNotre client est un\ngrand groupe international\npr√©sent dans plus de 50 pays et qui compte environ 180 000 collaborateurs.\nLeur m√©tier est de concevoir et d√©ployer des solutions qui favorisent le d√©veloppement durable des pays et des entreprises (notamment dans les secteurs de la gestion de l‚Äôeau, des d√©chets et de l‚Äô√©nergie). L'objectif est de\ndevenir la soci√©t√© de r√©f√©rence de la transformation √©cologique.\nTr√®s engag√©s en faveur de la plan√®te, avec l'objectif d'un futur meilleur et durable, la soci√©t√© vous offre la possibilit√© de donner du sens √† votre activit√© professionnelle.\nNous recherchons, pour leur\nDigital Factory\n,\nun\nData Engineer / DevOps\npour rejoindre cette √©quipe et garantir que les clients b√©n√©ficient de la meilleure exp√©rience possible.\nLocalisation :\nSaint-Maurice (√éle-de-France)\nR√©mun√©ration :\nEntre 50K‚Ç¨ et 70K‚Ç¨ (selon le profil)\nStack :\nGit, Python ou R, CI/CD, Terraform, AWS SAM, NoSQL\nT√©l√©travail :\n2 jours / semaine\nVos missions :\nCollaborer avec des analystes de donn√©es et des data scientists pour d√©velopper des modÔøΩÔøΩles de donn√©es, des algorithmes et des pr√©dictions.\nConcevoir, d√©velopper et tester des infrastructures de pipelines de donn√©es ainsi que des syst√®mes de bases de donn√©es.\nVeiller au respect des normes de l'industrie pour toutes les infrastructures et processus de donn√©es actuels, en utilisant des technologies avanc√©es en ing√©nierie des donn√©es.\nTravailler en collaboration avec diff√©rentes √©quipes, internes et externes, pour optimiser la qualit√© des donn√©es, mettre en ≈ìuvre des solutions √©volutives et partager continuellement les connaissances au sein de l'√©quipe.\nProfil recherch√©\nProfil recherch√© :\nVous poss√©dez une exp√©rience d'au moins cinq ans dans un r√¥le de Data Engineer / DevOps.\nVous d√©montrez des comp√©tences avanc√©es en bases de donn√©es relationnelles et NoSQL.\nVous avez une connaissance approfondie des outils d'automatisation et d'infrastructure en tant que code (CI/CD, Terraform, AWS SAM).\nVous ma√Ætrisez couramment l'anglais et le fran√ßais.\nVous √™tes familier avec la culture DevOps.\nLes avantages\nUne r√©mun√©ration attractive en fonction de votre exp√©rience.\nTickets Restaurant, Mutuelle, Cong√©s Pay√©s, RTT.\nV√©lo √©lectrique de fonction.\nShow more\nShow less",
        "details": {
            "JobDetail": [],
            "TypeContract": "",
            "Salary": "",
            "Level": "",
            "Experience": null
        },
        "title": "data engineer",
        "skills": {
            "ProgLanguage": [
                "R",
                "Python"
            ],
            "DataBase": [
                "NoSQL"
            ],
            "DataAnalytics": [
                "R"
            ],
            "CloudComputing": [
                "AWS"
            ],
            "DevTools": [
                "Git"
            ],
            "InfrastructureAsCode": [
                "Terraform"
            ],
            "Other": [
                "DevOps",
                "CI/CD"
            ],
            "EnSoftSkils": [
                "Collaboration"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "CIRCLE",
        "location": "Montbonnot-Saint-Martin, Auvergne-Rh√¥ne-Alpes, France",
        "link": "https://fr.linkedin.com/jobs/view/cloud-software-engineer-at-circle-3902063618?position=2&pageNum=15&refId=OMURzinLd5E%2BW2XWlKoc1w%3D%3D&trackingId=JL0bQrn8uLyv7qM9mIxbCw%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Circle Anatoscope Intuitive Design est une soci√©t√© fond√©e en 2016 par Biotech Dental - acteur majeur de l‚Äôindustrie dentaire en France - et Anatoscope - startup issue en 2015 du CNRS, de l‚ÄôINRIA et d‚Äôuniversit√©s - r√©cemment rejoints par des g√©ants internationaux du dentaire. Nous d√©veloppons un service web radicalement novateur permettant aux dentistes et proth√©sistes de produire des proth√®ses dentaires de la plus haute qualit√© et au meilleur co√ªt, gr√¢ce √† une int√©gration des flux de sp√©cification, conception et fabrication. Notre application web permet au dentiste de sp√©cifier un diagnostic, un traitement, et de pousser des fichiers d'imagerie issus de scanners 3D intra-oraux. Une proth√®se est automatiquement mod√©lis√©e d‚Äôapr√®s l'imagerie du patient et les sp√©cifications de l'appareil, puis le proth√©siste peut la retoucher directement depuis le portail web avec nos outils maison de mod√©lisation 3D. Une fois valid√©e, la proth√®se est export√©e vers des machines de fabrication. Notre soci√©t√© compte une quarantaine de salari√©s r√©partis dans nos locaux de Grenoble et Montpellier ainsi que divers lieux de t√©l√©travail. C‚Äôest une entreprise √† taille humaine qui veut peser dans l‚Äôunivers m√©dical, avec de bonnes conditions de travail et compos√©e de gens tr√®s talentueux. Nos valeurs principales sont l'int√©grit√©, la bienveillance et le plaisir.\nNous recherchons un Cloud Software Engineer en CDI.\nVotre p√©rim√®tre concerne notre service de calculs d√©port√©s et de streaming d‚Äôapplications 3D dans le cloud. Bien qu‚Äôinvisible des utilisateurs, c‚Äôest une pi√®ce centrale de notre solution SaaS permettant aux proth√©sistes et dentistes de travailler sur des applications de CAO √† la pointe depuis un simple navigateur web sur un ordinateur standard.\n- Membre Dev(Sec)Ops d‚Äôune nouvelle √©quipe Cloud mixant d√©veloppeurs et profils sp√©cialis√©s en infrastructure cloud. Cette √©quipe est charg√©e du d√©veloppement et du maintien en condition op√©rationnelle du service de calcul d√©port√©s et de streaming dans le cloud ayant vocation √† remplacer le syst√®me actuel en production.\n- D√©veloppement de modules et d‚ÄôAPI pour notre orchestrateur de conteneurs bas√© sur Kubernetes\n- D√©veloppement du pipeline de test/versioning/packaging/d√©ploiement\n- Participation au d√©veloppement de notre technologie de streaming - Intervention en tant que support de niveau 3\nTechnologies:\n- Code : Go, Bash, YAML, Python\n- Orchestration : Docker, Kubernetes (k3s) - CI/CD : Gitlab\n- Cloud providers : AWS, GCP - IaC : Terraform, Packer, Ansible\n- OS : Linux (Debian, Ubuntu) - Supervision : Grafana, Loki, Prometheus\n- Streaming: TurboVNC\nProfil recherch√© :\n- Dipl√¥me bac+5\n- Environ 5 ans d‚Äôexp√©rience dans un poste similaire\n- Vous √™tes rigoureux, pragmatique et avez une app√©tence pour le travail bien fait.\n- Vous avez de bonnes capacit√©s de communication et n‚Äôh√©sitez pas √† documenter et partager vos travaux.\nComp√©tences techniques recherch√©es :\n- D√©veloppement dans un contexte web/cloud (back-end / API)\n- Bonnes pratiques de d√©veloppement et de qualit√© de code (TDD, revues, KISS, linters, couverture)\n- Connaissance fonctionnelle de Kubernetes\n- Ma√Ætrise de Git - Ma√Ætrise d‚Äôoutils de CICD - Ma√Ætrise de Docker\n- D√©veloppement en Go\nEn plus :\n- D√©veloppement dans Kubernetes (CRD, controllers, operators)\n- Connaissances sur la m√©thodologie DevSecOps - Connaissances sur la supervision d‚Äôapplications\n- Connaissance en infrastructure cloud - Connaissances sur l‚ÄôInfrastructure-as-Code (Terraform)\n- Connaissances sur les outils des cloud providers GCP & AWS\n- D√©veloppement en C\nLes conditions et avantages :\n- Lieu de travail : Grenoble (Montbonnot)\n- T√©l√©travail partiel possible\n- Tickets restaurant\n- Indemnit√© kilom√©trique v√©lo boost√©e\n- Tr√®s bonne compl√©mentaire sant√© et pr√©voyance\n- Compte Epargne Temps\n- Disponible d√®s que possible\n- Salaire : selon exp√©rience\nShow more\nShow less",
        "details": {
            "JobDetail": [],
            "TypeContract": "CDI",
            "Salary": "Salaire",
            "Level": "Bac+5",
            "Experience": "5 an(s)"
        },
        "title": "software engineer",
        "skills": {
            "ProgLanguage": [
                "Bash",
                "Python"
            ],
            "CloudComputing": [
                "GCP",
                "AWS"
            ],
            "DevTools": [
                "Git",
                "Docker"
            ],
            "OS": [
                "Linux"
            ],
            "Automation": [
                "Kubernetes",
                "Ansible"
            ],
            "InfrastructureAsCode": [
                "Terraform"
            ],
            "Containers": [
                "Docker",
                "Kubernetes"
            ],
            "Other": [
                "Cloud",
                "CI/CD"
            ],
            "EnSoftSkils": [
                "Communication"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "myGwork - LGBTQ+ Business Community",
        "location": "Paris, √éle-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/devops-engineer-intern-at-mygwork-lgbtq%2B-business-community-3855495327?position=3&pageNum=15&refId=OMURzinLd5E%2BW2XWlKoc1w%3D%3D&trackingId=LE1Aln252qNKOHd1R9%2F2lw%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "This inclusive employer is a member of myGwork ‚Äì the largest global platform for the LGBTQ+ business community.\nWhat You'll Do\nThe Platform teams keep one of the largest computing platforms in the AdTech world functioning like clockwork. They keep our products running using a broad selection of technologies, like large scale data compute & storage services (Hadoop, SQL & NoSQL), streaming (Kafka), platform as a service (Chef, Mesos), identity management (Kerberos) and analytics (Hive, Druid, Vertica), as well as an extensive monitoring/observability infrastructure.\nFor the Internship, you will be in a team of 5-7, working closely with your mentor to drive your project, design and ensure best practices are applied. You can ask questions and participate in all knowledge sharing sessions/workshops, etc. You are encouraged to actively voice your ideas whilst learning how to build and ship quality code into production which will likely affect millions of users instantly.\nSkills\nDuring your internship (6 months) and according to your choice, skills and interest, you can tackle one of the following subjects/ teams:\nObservability: Select, test and integegrate a reporting tool with the current stack: Prometheus / Graphite / Gafana / Elasticseach / Kibana. Migrate Grafana to containers and integrate with SSO. Build a log streaming interface\nData Processing: Be part of a team that builds our BigDataFlow platform and writes code to provide insight, give the platform users info about changes impacting their datasets (2) and even hint them about optimization opportunities.\nDistributed System SDKs: Smart cache invalidation in a distributed system.\nContinuous Deployment: Implement a mutation testing solution that is integrated into the Criteo CI/CD pipeline.\nProduct Reliability Engineering: Migrate admin handlers' UI to Angular and help develop a load testing pipeline.\nRivers: Create a Streaming Portal UI.\nData Development Cycle: Leverage the data that we scrape from all our data processing systems to provide automatic monitoring and alerting and in-depth analysis to data producers so that they can understand the sources of delays and make better decisions on the design of their pipeline dependencies.\nWho You Are\nYou are in your final year of study in System/Software Engineering or related fields.\nYou are interested in developing web-based applications and working on Linux environment.\nYou are experienced in Object Oriented Programming.\nYou are a problem solver, a fixer, and a creative technologist. We believe coding is a talent and a passion, not just a skill.\nYou are a strong communicator and a team player who can work efficiently with others.\nYou are fluent in English\nWe acknowledge that many candidates may not meet every single role requirement listed above. If your experience looks a little different from our requirements but you believe that you can still bring value to the role, we‚Äôd love to see your application!\nWho We Are\nCriteo is the global commerce media company that enables marketers and media owners to deliver richer consumer experiences and drive better commerce outcomes through its industry leading Commerce Media Platform.\nAt Criteo, our culture is as unique as it is diverse. From our offices around the world or from home, our incredible team of 3,600 Criteos collaborates to develop an open and inclusive environment. We seek to ensure that all of our workers are treated equally, and we do not tolerate discrimination based on race, gender identity, gender, sexual orientation, color, national origin, religion, age, disability, political opinion, pregnancy, migrant status, ethnicity, marital or family status, or other protected characteristics at all stages of the employment lifecycle including how we attract and recruit, through promotions, pay decisions, benefits, career progression and development. We aim to ensure employment decisions and actions are based solely on business-related considerations and not on protected characteristics. As outlined in our Code of Business Conduct and Ethics, we strictly forbid any kind of discrimination, harassment, mistreatment or bullying towards colleagues, clients, suppliers, stakeholders, shareholders, or any visitors of Criteo. All of this supports us in our mission to power the world‚Äôs marketers with trusted and impactful advertising encouraging discovery, innovation and choice in an open internet.\nWhy Join Us\nAt Criteo, we take pride in being a caring culture and are committed to providing our employees with valuable benefits that support their physical, emotional and financial wellbeing, their interests and the important life events. We aim to create a place where people can grow and learn from each other while having a meaningful impact. We want to set you up for success in your job, and an important part of that includes comprehensive perks & benefits. Benefits may vary depending on the country where you work and the nature of your employment with Criteo. When determining compensation, we carefully consider a wide range of job-related factors, including experience, knowledge, skills, education, and location. These factors can cause your compensation to vary.\nShow more\nShow less",
        "details": {
            "JobDetail": [
                "Full"
            ],
            "TypeContract": "",
            "Salary": "",
            "Level": "",
            "Experience": null
        },
        "title": "devops",
        "skills": {
            "DataBase": [
                "SQL",
                "NoSQL"
            ],
            "BigData": [
                "Hadoop"
            ],
            "OS": [
                "Linux"
            ],
            "Automation": [
                "Chef"
            ],
            "Collaboration": [
                "Teams"
            ],
            "Other": [
                "CI/CD"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "Splio",
        "location": "Paris, √éle-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/site-reliability-engineer-sre-devops-m-f-at-splio-3826118662?position=4&pageNum=15&refId=OMURzinLd5E%2BW2XWlKoc1w%3D%3D&trackingId=suMq6aC%2Fsox4vPETJLCcAw%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "L'entreprise\nSplio est une scale-up du march√© des technologies marketing et digitales\ndont le si√®ge est √† Paris (Op√©ra). L‚Äôentreprise compte plus de 250 collaborateurs et 4 bureaux en Europe et MEA.\nSplio √©dite une plateforme marketing SaaS\nqui int√®gre CDP et Marketing Automation ainsi que toutes les fonctionnalit√©s essentielles du CRM (fid√©lit√©, Mobile Wallets), en une seule et m√™me plateforme boost√©e √† l‚ÄôIA.\nLa plateforme permet aux √©quipes CRM du retail, e-commerce, FMCG et des T√©l√©coms de communiquer et fid√©liser leurs clients de fa√ßon personnalis√©e sur tous les canaux (email, SMS, Push Wallet...)\nPlus de 500 entreprises du retail, e-commerce, FMCG et des T√©l√©coms, √† travers l‚ÄôEurope et le MEA utilisent Splio au quotidien, parmi lesquelles Nature et D√©couvertes, Longchamp, Bazarchic, APC, The Kooples, Fnac-Darty, Micromania, Faguo, Cyrillus, Orange ou encore Samsung.\nLe poste\nL'√©quipe SRE est responsable de la disponibilit√© de la plateforme, de son √©volution et de sa s√©curisation. En rejoignant l'√©quipe SRE, tu seras rattach√©(e) au SRE Manager et en charge de l'infrastructure de la plateforme Splio, qui est h√©berg√©e majoritairement sur AWS et GCP.\nTes objectifs sont d'automatiser le d√©ploiement de la plateforme et d'aider √† maintenir l'√©volution de la plateforme, la scalabilit√© et les faibles co√ªts d'infrastructure. Plus pr√©cis√©ment, tes principales missions seront les suivantes:\nCr√©er et d√©ployer de nouvelles solutions\nAssurer la disponibilit√© de la plateforme\nAutomatiser le d√©ploiement de la plateforme\nTravailler avec les √©quipes R&D et Product Management pour le d√©ploiement de l'application en utilisant CI/CD\nG√©rer l'astreinte toutes les 6 √† 8 semaines (en alternance avec les autres membres de l'√©quipe)\nAm√©liorer continuellement la s√©curit√© de la plateforme : maintenir les acc√®s, appliquer les mises √† jour, cr√©er une architecture s√©curis√©e.\nEnvironnement technique\nCloud: GCP et AWS\nTerraform /Terragrunt\nLinux (Debian) / Open Source ADN\nPuppet\nBigQuery / MySQL/ Clickhouse/ Redis / PostGresSQL would be a plus\nKafka / Pulsar\nKubernetes & Docker\nCI / CD: Gitlab EE.\nOpensearch / Prometheus / Grafana\nProfil recherch√©\nAu moins 3 ans d'exp√©rience en tant que DevOps/SRE.\nMa√Ætrise de GCP: CloudRun, Composer, BigQuery, IAM.\nEnvie de se perfectionner sur AWS\n√ätre curieux et autonome, aimer partager ses connaissances avec ses coll√®gues\nExcellente capacit√© d'organisation et capacit√© √† travailler dans un environnement agile\nBonne communication orale et √©crite en anglais et en fran√ßais\nAvantages\nüå¥ 12 Splio days (jours off), en plus des 25 jours cong√©s l√©gaux\nüõãÔ∏è Politique de remote : 5 jours au bureau par mois dans l‚Äôune des villes o√π Splio a un bureau (Paris, Barcelone, Tunis)\nüòã Une carte swile pour les repas (√† raison de 10‚Ç¨ par jour)\nüë®‚Äçüë©‚ÄçÔøΩÔøΩ‚Äçüë¶ Possibilit√© de se rendre ou de participer √† des conf√©rence une ou deux fois par an\nInt√©ress√©(e) ? Rejoins-nous !\n45 minutes d'entretien en visio avec notre HRBP pour apprendre √† te conna√Ætre et √©changer sur tes exp√©riences et motivations √† rejoindre Splio.\n45 minutes d'entretien en visio avec Yvan Leizour, SRE Manager et Romain Concaud, Devops Manager pour √©changer plus en d√©tail sur le r√¥le de SRE.\n1 heure de cas pratique dans notre bureau √† Paris avec une partie Q&A afin d'√©valuer tes comp√©tences techniques.\n30 minutes d'√©change en visio avec notre CTO\nShow more\nShow less",
        "details": {
            "JobDetail": [
                "Remote"
            ],
            "TypeContract": "",
            "Salary": "",
            "Level": "",
            "Experience": "3 an(s)"
        },
        "title": "devops",
        "skills": {
            "ProgLanguage": [
                "R"
            ],
            "DataAnalytics": [
                "R"
            ],
            "MachineLearning": [
                "Orange"
            ],
            "CloudComputing": [
                "GCP",
                "AWS"
            ],
            "DevTools": [
                "Docker"
            ],
            "OS": [
                "Linux"
            ],
            "DBMS": [
                "BigQuery",
                "MySQL"
            ],
            "Automation": [
                "Kubernetes",
                "Puppet"
            ],
            "InfrastructureAsCode": [
                "Terraform"
            ],
            "Containers": [
                "Docker",
                "Kubernetes"
            ],
            "Other": [
                "CI / CD",
                "Cloud",
                "DevOps",
                "CI/CD"
            ],
            "EnSoftSkils": [
                "Communication"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "Orange Logic",
        "location": "France",
        "link": "https://fr.linkedin.com/jobs/view/software-engineer-at-orange-logic-3862540191?position=5&pageNum=15&refId=OMURzinLd5E%2BW2XWlKoc1w%3D%3D&trackingId=ahz1vwdhoO2r2BJgm85HLw%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "For more than two decades, Orange Logic has empowered a wide range of clients with its digital asset management system, Cortex. We‚Äôve worked with almost every industry, from Finance to NGOs, Media giants to educational institutions, securing and organizing their assets. The Software Engineer will enhance Orange Logic‚Äôs software by participating in the design, development, maintenance and testing process.\nWhat you can expect in your role:\nTaking ownership of projects and having the opportunity to further your knowledge by exploring machine learning, security, DevOps, and more.\nDeveloping scalable new features for our software product that exceeds our customer‚Äôs needs.\nBuilding architecture for our platform to ensure optimal performance.\nObtaining requirement feedback from internal teams/clients to maintain/support the product development.\nWrite the Unit Tests for robust development.\nPerforming code reviews on other team member‚Äôs work.\nYou are:\nProficient with English (both verbal and written).\nHave 3+ years‚Äô practical experience on a web-based application.\nProficient with any backend programming languages (e.g. .NET, Java, Python, etc.).\nA strong fundamental understanding of software development.\nAn understanding of complex algorithms and data structures, as well as a passion for intellectual challenges.\nStrong self-discipline for delivering well-tested, complete features/modules under a tight schedule and the capability for rational thinking.\nExperience with the database management tool SQL is a plus, but not mandatory.\nObtained bachelor‚Äôs degree in any relevant major (e.g. Information Technology, Computer Science, etc.).\nPerks of joining the team:\nCompetitive compensation & benefits package\nRemote Work Environment\nHow to get started:\nIf you‚Äôre up for the challenge to be part of a growing engineering team we‚Äôd like to hear from you. Apply today!\nShow more\nShow less",
        "details": {
            "JobDetail": [
                "Remote"
            ],
            "TypeContract": "",
            "Salary": "Package",
            "Level": "",
            "Experience": null
        },
        "title": "software engineer",
        "skills": {
            "ProgLanguage": [
                "Java",
                "Python"
            ],
            "DataBase": [
                "SQL"
            ],
            "MachineLearning": [
                "Orange"
            ],
            "Collaboration": [
                "Teams"
            ],
            "Other": [
                "Machine Learning",
                "DevOps"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "SFEIR",
        "location": "Paris, √éle-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/cloud-data-engineer-at-sfeir-3634254863?position=6&pageNum=15&refId=OMURzinLd5E%2BW2XWlKoc1w%3D%3D&trackingId=WnHVbLlS8LX6FhUg7GWXdA%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "C'est quoi SFEIR ? ü§î\nSFEIR, c'est avant tout une communaut√© de 900 Techs en France, en Belgique et au Luxembourg.\nNous aidons nos clients √† :\nD√©velopper des applications web et mobiles pour am√©liorer leur exp√©rience client et se connecter partout ;\n√ätre compatible avec le futur en d√©veloppant leurs architectures SI, Cloud et Data\nDonner de la valeur √† leurs donn√©es, innover avec l‚ÄôIA ;\nCr√©er de la valeur gr√¢ce aux API & microservices.\nNotre culture d'entreprise est r√©solument tourn√©e vers l'expertise technologique, la transmission de connaissances et le respect de nos valeurs phares : bienveillance, inclusivit√©, excellence, libert√©, responsabilit√©.\nSFEIR Paris c‚Äôest aussi :\nüîπ Une agence co-dirig√©e par Cyril Balit & Arnaud Waller\nüîπ 400 Experts, dont 100 Sfeiriens sur l‚Äôexpertise Data\nüîπ 70 clients actifs en Ile-de-France et 120 au niveau du Groupe\nüîπ 41 Engineering Managers pour un suivi de proximit√©\nüîπ 370 certifications obtenues en 2022\nüîπ Des √©v√®nements en interne organis√©s chaque mois (afterworks, meetups, formations)\nüîπ Une communaut√© active : une cinquantaine de conf√©rences donn√©es en 2022 (Devoxx ‚Ä¶)\nConcr√®tement, quel sera mon job ?\nEn mission pour un client sur des stacks r√©centes, vous concevez et vous d√©veloppez des solutions logicielles en Python.\nChez nous, tu ne feras pas de TMA ‚Ä¶ Mais tu travailleras des projets de transformation ou de build de nouveaux produits üòâ .\nAu-del√† de ta ma√Ætrise du python et de son √©cosyst√®me (ex : sql,terraform ‚Ä¶) tu es quelqu'un de curieux(se) et dans le partage !\nPar exemple :\n@Vincent, Data Engineer chez SFEIR, construit la plateforme de donn√©es d'une soci√©t√© historique de livraison et de suivi de colis, au sein d'un √©cosyst√®me Cloud. Cette plateforme a pour premi√®re vocation d'aider au pilotage op√©rationnel de l'activit√© et doit √™tre suffisamment √©volutive pour accueillir les besoins qu'exprimeront les √©quipes m√©tiers. Je travaille sur la Stack suivante : Talend, Cloud Composer, BigQuery, DBT, Power BI\n@Thibaud intervient sur diff√©rents projets ML en tant que Senior ML Engineer et ML Architect. Il va travailler sur la conception d'application ML et sur la mise en ≈ìuvre d'algorithmes et d'outils ML appropri√©s sur Google Cloud (Vertex IA, BigQUery, Storage,...) dans le secteur automotive.\nEt si je souhaite √©voluer ?\nNous proposons des possibilit√©s d'√©volution verticales et horizontales.\nTu auras √©galement la possibilit√© de prendre des r√¥les en interne si tu le souhaites :\nüîπ √âvaluateur¬∑rice dans le process de recrutement\nüîπ Formateur¬∑rice aux Sfeir Schools ou avec Sfeir Institute\nüîπ Speaker¬∑euse lors de conf√©rences, meetups, talks internes, aupr√®s des √©coles\nüîπ Engineering Manager si tu veux manager une √©quipe tout en restant dans la technique\nEt si tu as d'autres envies, on en discute, chacun est diff√©rent et on fait au cas par cas.\nA quelle r√©mun√©ration je peux pr√©tendre chez SFEIR ?\nChez nous, pas de grille de salaire fig√©e dans le marbre !\nSFEIR collecte vos donn√©es √† caract√®re personnel afin de traiter votre candidature. Pour en savoir plus sur la gestion de vos donn√©es personnelles et pour exercer vos droits, nous vous invitons √† consulter notre Politique de confidentialit√© .\nShow more\nShow less",
        "details": {
            "JobDetail": [
                "Senior"
            ],
            "TypeContract": "",
            "Salary": "Salaire",
            "Level": "",
            "Experience": null
        },
        "title": "data engineer",
        "skills": {
            "ProgLanguage": [
                "Python"
            ],
            "DataBase": [
                "SQL"
            ],
            "DataVisualisation": [
                "Power BI"
            ],
            "DBMS": [
                "BigQuery"
            ],
            "InfrastructureAsCode": [
                "Terraform"
            ],
            "Other": [
                "Cloud",
                "ML"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "Technology & Strategy",
        "location": "Lyon, Auvergne-Rh√¥ne-Alpes, France",
        "link": "https://fr.linkedin.com/jobs/view/data-engineer-h-f-at-technology-strategy-3881556102?position=7&pageNum=15&refId=OMURzinLd5E%2BW2XWlKoc1w%3D%3D&trackingId=D%2FbgsGCBYAQl67OwvcCsPQ%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "D√©couvrez Novencia\n:\nExpert en Data et Intelligence Artificielle, nous aidons nos clients √† exploiter et √† valoriser leurs donn√©es sous toutes ses formes en les accompagnant sur des projets de Data Analyse, Data Gourvernance, Data Architecture, Data Science, et Data Engineering‚Ä¶\nVous avez une solide exp√©rience de minimum 2 ans dans l'ing√©nierie des donn√©es et vous √™tes √† la recherche de nouveaux d√©fis ? Bouclez votre ceinture, la suite est pour vous !\nType de contrat : CDI\nLieu : Lyon\nEn qualit√© de Data Engineer (H/F), votre r√¥le sera :\nConcevoir et proposer les solutions de d√©veloppement r√©pondant aux besoins fonctionnels et techniques des projets big data.\nTu participes √† la conception de solutions permettant le traitement de volumes importants de pipelines donn√©es.\nR√©aliser ces solutions par l‚Äô√©criture de code, en respectant les m√©thodes et proc√©dures qualit√©s d√©finies au sein du d√©partement Technique.\nMise √† disposition s√©curis√© et lisible de la data.\nS‚Äôassurer de la conformit√© fonctionnelle et technique de ces r√©alisations en effectuant les tests automatis√©s n√©cessaire et la mise en place de monitoring (syst√®me et qualit√©).\nAssurer la maintenance des applicatifs / plateforme data science\nAssurer une veille technologique\nVous disposez des comp√©tences suivantes :\nMaitrise des plateformes Cloud (AWS, GCP ou Azure), de Scala et de SQL.\nUn.e touche √† tout : poss√©dant des comp√©tences en langage Python/Spark, de bonnes capacit√©s de mod√©lisation, une forte app√©tence pour le Big Data\nFin.e connaisseur.euse : Data Engineer convaincu, tr√®s peu de secrets pour les clusters et pour les calculs parall√®les\nExplorateur.trice : d√©couvre de nouvelles technos gr√¢ce √† une veille r√©guli√®re\nD√©brouillard.e : rel√®ve de nouveaux d√©fis\nNotre objectif commun est de co-construire votre carri√®re en fonction de vos aspirations et de vos comp√©tences.\nContactez-moi en message priv√© ou par mail √† s.ziki@technologyandstrategy.com !\nLet's make it possible #together\n*Nos postes sont ouverts aux personnes b√©n√©ficiant d‚Äôune Reconnaissance de la Qualit√© de Travailleur Handicap√© (RQTH). T&S Groupe encourage la diversit√© et l‚Äô√©galit√© sur le lieu de travail. Tous les candidats qualifi√©s H/F/* sont pris en consid√©ration pour un emploi sur un m√™me pied d'√©galit√©.\nShow more\nShow less",
        "details": {
            "JobDetail": [],
            "TypeContract": "CDI",
            "Salary": "",
            "Level": "",
            "Experience": "2 an(s)"
        },
        "title": "data engineer",
        "skills": {
            "ProgLanguage": [
                "Scala",
                "Python"
            ],
            "DataBase": [
                "SQL"
            ],
            "BigData": [
                "Spark"
            ],
            "CloudComputing": [
                "GCP",
                "AWS",
                "Azure"
            ],
            "Other": [
                "Cloud",
                "Big Data"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "Capgemini",
        "location": "Bordeaux, Nouvelle-Aquitaine, France",
        "link": "https://fr.linkedin.com/jobs/view/data-engineer-bordeaux-at-capgemini-3889788624?position=8&pageNum=15&refId=OMURzinLd5E%2BW2XWlKoc1w%3D%3D&trackingId=ziv0UCdYzrS%2B%2FMwV51It7Q%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Choisir Capgemini, c'est choisir une entreprise o√π vous serez en mesure de fa√ßonner votre carri√®re selon vos aspirations. Avec le soutien et l'inspiration d'une\ncommunaut√© d‚Äôexperts dans le monde entier, vous pourrez r√©√©crire votre futur. Rejoignez-nous pour red√©finir les limites de ce qui est possible, contribuer √† lib√©rer la\nvaleur de la technologie pour les plus grandes organisations et participer √† la construction d‚Äôun monde plus durable et inclusif.\nVos missions :\nVous √™tes passionn√© par le domaine de la Data, vous souhaitez prendre part √† des projets d'envergure, concevoir des solutions, les impl√©menter et les faire √©voluer?\nAlors rejoignez notre √©quipe Data Engineering Services au sein de Capgemini Cloud Infrastructure Services en tant que Data Engineer.\nVous avez acquis une exp√©rience solide dans le d√©veloppement, la mise en ≈ìuvre et l‚Äôoptimisation de solutions pour le traitement d'un grand volume de donn√©es, vous √™tes capable de cr√©er des solutions qui r√©pondent aux besoins m√©tiers et IT, alors rejoignez notre √©quipe d‚Äôexperts.\nEn qualit√© de Data engineer, vos missions sont les suivantes :\n‚ñ™ Concevoir et d√©velopper des solutions Data/IA.\n‚ñ™ Accompagner les M√©tier dans la compr√©hension et la mise en ≈ìuvre de solution orient√©es donn√©es.\n‚ñ™ Collaborer avec les Dev, les Ops, les experts infrastructures dans la construction de solutions et d‚Äôinfrastructures ax√©es sur les donn√©es.\n‚ñ™ G√©rer un √©cosyst√®me de partenaires data et assurer un haut niveau d'expertise\n‚ñ™ Assurer un r√¥le de veille technologique sur tous les outils autours de la data, de l‚ÄôIA et de la BI.\nVotre profil :\nVous √™tes issu d‚Äôune formation ing√©nieur ou √©quivalent bac+5 informatique sp√©cialis√©e en DATA et vous justifiez d‚Äôune exp√©rience de 3 √† 5 ans dans un r√¥le similaire. Expert dans une technologie de base de donn√©es relationnelle (PostgreSQL, Oracle...)\nExpert dans une technologie de base NoSQL (MongoDB, Cassandra...)\nVous maitrisez un framework de manipulation de donn√©es (Hadoop, Spark, Kafka...)\nVous maitrisez les concepts DevOps et avez de bonnes notions en scripting et d√©veloppement\nVous avez une exp√©rience des outils BI et de data visualisation (Kibana, PowerBI...)\nLa maitrise de l'anglais est n√©cessaire.\n3 raisons de nous rejoindre :\nQualit√© de vie au travail :\naccord de t√©l√©travail en France et √† l‚Äôinternational, accord sur l‚Äô√©galit√© professionnelle, la parentalit√©, l‚Äô√©quilibre des temps et la mobilit√© durable.\nApprentissage en continu :\ncertifications et formations en libre acc√®s, accompagnement sur mesure avec votre career manager, parcours d‚Äôint√©gration sur 9 mois.\nAvantages groupe & CSE :\nplan actionnariat, tarif pr√©f√©rentiels, remboursement partiel vacances, remboursement de votre abonnement sportif ou culture\nNos engagements et priorit√©s :\nLe groupe Capgemini encourage une culture inclusive dans un cadre multiculturel et handi-accueillant. En nous rejoignant, vous int√©grez un collectif qui valorise la diversit√©, d√©veloppe le potentiel de ses talents, s‚Äôengage dans des initiatives solidaires avec ses partenaires, et se mobilise pour r√©duire son impact environnemental sur tous ses sites et aupr√®s de ses clients.\n√Ä propos de Capgemini :\nCapgemini est un leader mondial, responsable et multiculturel, regroupant pr√®s de 350 000 personnes dans plus de 50 pays. Fort de 55 ans d‚Äôexp√©rience, nous sommes un partenaire strat√©gique des entreprises pour la transformation de leurs activit√©s en tirant profit de toute la puissance de la technologie et des innovations dans les domaines en perp√©tuelle √©volution tels que le cloud, la data, l‚ÄôIntelligence Artificielle, la connectivit√©, les logiciels, l‚Äôing√©nierie digitale ou les plateformes.\nGet The Future You Want* | www.capgemini.com/fr-fr\n*Capgemini, le futur que vous voulez\nShow more\nShow less",
        "details": {
            "JobDetail": [],
            "TypeContract": "",
            "Salary": "",
            "Level": "Bac+5",
            "Experience": "5 an(s)"
        },
        "title": "data engineer",
        "skills": {
            "DataBase": [
                "MongoDB",
                "Cassandra",
                "NoSQL"
            ],
            "BigData": [
                "Hadoop",
                "Spark"
            ],
            "DBMS": [
                "PostgreSQL"
            ],
            "SoftBigDataProcessing": [
                "Cassandra"
            ],
            "Other": [
                "Cloud",
                "DevOps"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "Yooz",
        "location": "Montpellier, Occitanie, France",
        "link": "https://fr.linkedin.com/jobs/view/ing%C3%A9nieur-cloud-f-h-at-yooz-3903672660?position=9&pageNum=15&refId=OMURzinLd5E%2BW2XWlKoc1w%3D%3D&trackingId=7i8ltvEXzTU9kGz5RVtmhA%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Avec plus de 200 000 utilisateurs dans plus de 40 pays, nous recherchons des personnalit√©s passionn√©es et engag√©es, pour continuer √† am√©liorer la satisfaction de nos clients et renforcer notre position de leader sur le march√©.\nCertifi√©e Great Place To Work, notre entreprise offre des conditions de travail agr√©ables, tant au niveau des locaux (√† Aimargues ou¬†Montpellier), du rythme (hybride, ouvert au t√©l√©travail) que des activit√©s (foot, crossfit, boxe, piscine ext√©rieure accessible librement) pour renforcer la coh√©sion d‚Äô√©quipe.\nNotre division\nIT\nrecherche aujourd‚Äôhui\nun(e) Cloud Operation Engineer, en CDI.\nA ce titre, vous serez en charge de :\nAssurer la maintenance et le suivi des plateformes Yooz Linux, avec Prometheus, Grafana, et autres.\nAssurer la maintenance des plateformes Yooz Windows.\nSuivre le maintien en condition op√©rationnelle de nos databases et applications, des serveurs et r√©soudre les incidents/anomalies potentiel(le)s.\nAccompagner nos √©quipes sur leurs probl√©matiques d'infrastructure.\nCollaborer avec le support Azure Cloud et utiliser les outils associ√©s √† Microsoft Azure.\nVos atouts pour ce r√¥le :\nDe Formation Bac+3, ou √©quivalent, vous disposez d'une exp√©rience confirm√©e sur des fonctions similaires.\nVous √™tes rigoureux(se) et m√©ticuleux(se).\nVous √™tes √† l'aise dans des environnements Windows et Linux.\nVous disposez de connaissances solides en r√©seau et s√©curit√©, en gestion de bases de donn√©es (PostgreSQL).\nVous √™tes √† l'aise avec l'utilisation de scripts Linux (Shell, Python), de Microsoft PowerShell et, id√©alement, de Javascript.\nLa ma√Ætrise de l‚Äôanglais est souhait√©e.\nPourquoi rejoindre Yooz ?\nYooz est une entreprise o√π plus de 95% des collaborateurs estiment qu‚Äôil fait vraiment bon travailler.\nEquit√©, respect, convivialit√©, cr√©dibilit√©\nmais aussi\nfiert√©\nsont autant de valeurs mises en avant par les 450 salari√©s du groupe au travers de notre label Great Place to Work.\nNous veillons chaque jour √† cr√©er un cadre de travail positif et √©panouissant pour que chacun puisse √©voluer dans les meilleures conditions.\nVous pensez correspondre √† nos valeurs et √† cette opportunit√© ? N‚Äôh√©sitez plus et adressez-nous votre candidature !\nYooz est une entreprise multiculturelle engag√©e en mati√®re d‚Äô√©galit√© professionnelle. Nous sommes convaincus que notre force r√©side en la diversit√© de nos talents, et sommes fiers de garantir un acc√®s √©gal √† l‚Äôemploi et aux promotions √† tous nos candidats et employ√©s, quel que soit leur sexe, origine, orientation sexuelle, religion, handicap, √¢ge, ou tout autre statut prot√©g√© par la loi. Yooz luttera toujours contre toute forme de discrimination et de harc√®lement.\nShow more\nShow less",
        "details": {
            "JobDetail": [
                "Hybride",
                "Confirm√©"
            ],
            "TypeContract": "CDI",
            "Salary": "",
            "Level": "Bac+3",
            "Experience": null
        },
        "title": "cloud architect /engineer ",
        "skills": {
            "ProgLanguage": [
                "Python"
            ],
            "CloudComputing": [
                "Azure"
            ],
            "OS": [
                "Linux",
                "Windows"
            ],
            "DBMS": [
                "PostgreSQL"
            ],
            "Other": [
                "Cloud"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "Wiser Solutions, Inc.",
        "location": "Paris, √éle-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/software-engineer-crawling-at-wiser-solutions-inc-3909448442?position=10&pageNum=15&refId=OMURzinLd5E%2BW2XWlKoc1w%3D%3D&trackingId=mYbGAMFcu1ogDwmgUp4Ojg%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Wiser Solutions is a suite of in-store and eCommerce intelligenceand execution tools. We're on a mission to enable brands, retailers, and retail channel partners to gather intelligence and automate actions to optimize in-store and online pricing, marketing, and operations initiatives. Our Commerce Execution Suite is available globally.\nJob Description\nLocation: Remote in France\nVeuillez soumettre votre curriculum vitae en anglais\nNous recherchons un Software Engineer (Crawling) hautement qualifi√© pour √™tre un contributeur essentiel au d√©veloppement de notre suite de crawlers et d'extractions. Si vous aimez travailler sur des probl√®mes complexes et √©crire un code propre, vous allez adorerer ce r√¥le. Notre objectif est de r√©soudre un probl√®me complexe. Notre travail consiste √† collecter, cat√©goriser et analyser des donn√©es semi-structur√©es provenant de diff√©rentes sources (plus de 200 millions de produits provenant de plus de 100 sites Web dans notre catalogue de plus de 500 millions de produits). Nous aidons nos clients √† d√©couvrir de nouveaux mod√®les dans leurs donn√©es pouvant √™tre exploit√©s afin qu'ils deviennent plus comp√©titifs et augmentent leurs revenus.\nFonctions essentielles:\nD√©velopper et maintenir divers crawlers et composants c√¥t√© serveur.\nAssurer des performances optimales des diff√©rentes bases de donn√©es et une r√©activit√© aux demandes frontend.\nD√©velopper des applications haute performance en √©crivant un code testable, r√©utilisable et efficace.\nMettre en place des protocoles de s√©curit√© efficaces, des mesures de protection des donn√©es et des solutions de stockage.\nEffectuer des tests diagnostiques, r√©parer les d√©fauts et fournir un support technique.\nDocumenter les processus, y compris les sch√©mas de base de donn√©es, ainsi que pr√©parer des rapports.\nRecommander et mettre en ≈ìuvre des am√©liorations aux processus et technologies.\nApporter de nouvelles id√©es √† la table - certaines de nos meilleures innovations viennent de l'√©quipe.\nTechnologies utilis√©es:\nLangages : La ma√Ætrise de Python, JavaScript (JS), HTML et SQL est essentielle.\nEnvironnement : Exp√©rience avec la Google Cloud Platform (GCP), Kubernetes, les pratiques d'int√©gration continue et de d√©ploiement continu (CI/CD), GitHub etCircleCI.\nMariaDB, MySQL, MongoDB\nQualifications\nExp√©rience : Un minimum de 3 ans dans un domaine pertinent est requis.\nProtocoles : Bonne compr√©hension des protocoles TCP/IP et HTTP.\nConnaissance en s√©curit√© Web : Familiarit√© avec les principes et pratiques de s√©curit√© Web.\nSyst√®mes : Comp√©tent dans le travail avec les syst√®mes d'exploitation bas√©s sur Linux, notamment Debian et Ubuntu.\nM√©thodologie : Les m√©thodologies Agile et Scrum devraient √™tre naturelles.\nExcellentes comp√©tences interpersonnelles, de communication et de collaboration.\nExpertise en d√©veloppement back-end en utilisant Python.\nCompr√©hension solide de la GCP, de Kubernetes et des concepts d'infrastructure.\nComp√©tences en programmation RDBMS & SQL (l'exp√©rience avec MYSQL, MariaDB & MongoDB est un plus).\nCe poste peut n√©cessiter d‚Äô√™tre sur appel pour r√©soudre des probl√®mes critiques li√©s aux applications de production en dehors des heures normales de travail.\nFacultatif:\nConnaissance facultative de l'intelligence artificielle (IA) et de l'apprentissage automatique (ML), de l'analyse de donn√©es et de AWS serait un plus.\nPoints bonus:\nExp√©rience de travail sur des environnements de microservices ou de syst√®mes distribu√©s.\nExp√©rience avec la conception orient√©e domaine.\nExp√©rience avec la mod√©lisation C4.\nExp√©rience de travail dans un environnement de vente au d√©tail ou de commerce √©lectronique\nAdditional Information\nEEO STATEMENT\nWiser Solutions, Inc. is an Equal Opportunity Employer and prohibits Discrimination, Harassment, and Retaliation of any kind. Wiser Solutions, Inc. is committed to the principle of equal employment opportunity for all employees and applicants, providing a work environment free of discrimination, harassment, and retaliation. All employment decisions at Wiser Solutions, Inc. are based on business needs, job requirements, and individual qualifications, without regard to race, color, religion, sex, national origin, family or parental status, disability, genetics, age, sexual orientation, veteran status, or any other status protected by the state, federal, or local law. Wiser Solutions, Inc. will not tolerate discrimination, harassment, or retaliation based on any of these characteristics.\nShow more\nShow less",
        "details": {
            "JobDetail": [
                "Remote"
            ],
            "TypeContract": "",
            "Salary": "",
            "Level": "",
            "Experience": "3 an(s)"
        },
        "title": "software engineer",
        "skills": {
            "ProgLanguage": [
                "Python"
            ],
            "DataBase": [
                "SQL",
                "MongoDB"
            ],
            "CloudComputing": [
                "GCP",
                "AWS",
                "Google Cloud Platform"
            ],
            "OS": [
                "Linux"
            ],
            "DBMS": [
                "MySQL"
            ],
            "Automation": [
                "Kubernetes"
            ],
            "Containers": [
                "Kubernetes"
            ],
            "Other": [
                "Cloud",
                "ML",
                "CI/CD"
            ],
            "EnSoftSkils": [
                "Communication",
                "Collaboration"
            ]
        }
    }
]