[
    {
        "source": "LinkedIn",
        "company": "Unreal Staffing, Inc",
        "location": "Paris, Île-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/data-scientist-at-unreal-staffing-inc-3913911173?position=2&pageNum=0&refId=EGCcUYgUshGnwQGGB%2BWgjg%3D%3D&trackingId=b8dp62KUpDcMYlHJdBr4Mg%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "About Us\nThe fashion industry contributes significantly to global greenhouse gas emissions. To address this, we developed a Carbon Management Platform tailored for the textile and fashion industry. We automate life-cycle assessment to help brands understand and reduce their environmental footprint.\nData At Our Company\nOur Data team manages customer data parsing and analytics. We clean and normalize customer data for accurate analysis and provide analytics on product-level environmental impacts.\nRequirements\nWhat You'll Be Working With\nInteresting data: Our data describes physical objects, such as shoes, t-shirts, and packaging boxes, enabling real insights into the environmental impact of products\nUnique opportunity: Apply your data science skills to reduce the environmental footprint of fashion companies\nWhat We're Looking For\nStrong communication skills\nExperience with heterogeneous data and basic NLP techniques\nProficiency in Python and SQL\nBasic software engineering skills\nBenefits\nRemote work in Europe\nCoworking space allowance up to €300/month\nModern amenities including MacBook, headset, ChatGPT subscription, GitHub Copilot, etc\n100% health insurance coverage with Alan at the best coverage level\nOption to work from our office in Paris\nWork retreats organized 3 times a year\nTransparent compensation package with salary range €60k - €80k and significant equity\nOpportunities for promotion based on performance and impact on the company\nStrong belief in open-source software and contribution to the community\nShow more\nShow less",
        "details": {
            "JobDetail": [
                "Remote"
            ],
            "TypeContract": "",
            "Salary": "60k, 60k",
            "Level": "",
            "Experience": null
        },
        "title": "data scientist",
        "skills": {
            "ProgLanguage": [
                "Python"
            ],
            "DataBase": [
                "SQL"
            ],
            "EnSoftSkils": [
                "Communication"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "VINCI Airports",
        "location": "Nanterre, Île-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/data-scientist-f-m-at-vinci-airports-3888479165?position=3&pageNum=0&refId=EGCcUYgUshGnwQGGB%2BWgjg%3D%3D&trackingId=%2B7dnXJx9uGyCKqHmokVW%2Bw%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Premier opérateur aéroportuaire privé au monde,\nVINCI Airports\ngère plus de 70 aéroports dans 13 pays en Europe, en Asie et sur le continent américain. Grâce à son expertise d’intégrateur global, VINCI Airports développe, finance, construit et exploite les aéroports en apportant sa capacité d’investissement et son savoir-faire dans l’optimisation de la performance opérationnelle, la modernisation des infrastructures et la conduite de leur transition environnementale.\nNous recherchons actuellement\nun(e) Data Scientist (F/M)\nen CDI.\nRattaché(e) au Département Data de la Direction financière de VINCI Airports, vous participerez, en coordination avec les équipes métiers et appuyé(e) par l’équipe d’ingénieurs Data (siège VINCI Airports et Pays), à la mise en œuvre du projet « SMART DATA HUB », un projet stratégique et passionnant, qui a pour vocation de fournir à l’ensemble des aéroports du groupe la capacité à mieux piloter la performance de l’activité autour de la Data.\nPour ce faire vous serez amené(e) à développer des solutions avancées en Data Science, Modèles de Machine Learning, avec un accent particulier sur le traitement du langage naturel (NLP) dans le département Data de VINCI Airports pour les besoins de digitalisation et d’amélioration des processus de VINCI Airports.\nMissions :\nModélisation et prévision : Concevoir, développer et mettre en œuvre des modèles statistiques et algorithmiques. Utiliser des méthodes d'apprentissage automatique et d'intelligence artificielle (IA) pour créer des modèles prédictifs.\nAnalyse des données : Collecter, nettoyer et préparer les données brutes en vue de leur analyse. Utiliser des techniques de visualisation et des outils statistiques pour explorer et comprendre les ensembles de données.\nExploitation des données : Identifier les opportunités d'amélioration des processus et des performances en utilisant les données disponibles. Travailler en étroite collaboration avec les équipes opérationnelles pour comprendre leurs besoins et proposer des solutions basées sur les données.\nCommunication des résultats : Présenter les résultats de l'analyse de manière claire et compréhensible à des publics non techniques. Collaborer avec des équipes multidisciplinaires pour fournir des recommandations basées sur les données pour la prise de décision stratégique.\nTravailler sur des projets impliquant des modèles de langage comme GPT développés par Open AI ou Google (ou autres nouvelles solutions sur le marché).\nParticiper à des formations et des ateliers avec les analystes de VINCI Airports pour développer leurs compétences techniques et méthodologiques grâce aux solutions Data science/NLP.\nL’ensemble de ces actions seront à entreprendre sur l’ensemble des domaines métiers de VINCI Airports : Trafic, commercial, opérations...\nEffectuer une veille constante sur les dernières avancées en Data Science, LLM et NLP pour proposer des solutions innovantes et les intégrer aux modèles développés par l’équipe Data.\nLe profil que nous recherchons à ce poste :\nDiplôme universitaire (Bac+5) en statistiques, mathématiques, informatique, science des données, Intelligence Artificielle ou un domaine connexe.\nExpérience pratique dans l'analyse de données et l'utilisation d'outils d'analyse tels que Python, R, SAS, SQL,…\nBonne connaissance des techniques d'apprentissage automatique (machine learning), des algorithmes statistiques et de l'analyse prédictive.\nConnaissance approfondie des concepts de Machine Learning et des bibliothèques telles que TensorFlow, PyTorch, Scikit-Learn.\nMotivation pour la recherche et la résolution de problèmes complexes.\nIntérêt et expérience en traitement du langage naturel (NLP), y compris la familiarité avec les modèles de langage comme GPT.\nCapacité à travailler de manière autonome et à gérer efficacement les projets, tout en respectant les délais impartis.\nCompétences en communication orale et écrite pour présenter des résultats complexes de manière claire et concise.\nCuriosité intellectuelle et passion pour l'exploration des données afin de découvrir des informations cachées et de générer des idées novatrices.\nTravail en équipe.\nVous êtes capable de converser en Anglais.\nShow more\nShow less",
        "details": {
            "JobDetail": [],
            "TypeContract": "CDI",
            "Salary": "",
            "Level": "Bac+5",
            "Experience": null
        },
        "title": "data scientist",
        "skills": {
            "ProgLanguage": [
                "R",
                "Python"
            ],
            "DataBase": [
                "SQL"
            ],
            "DataAnalytics": [
                "R"
            ],
            "MachineLearning": [
                "Scikit-Learn",
                "TensorFlow",
                "PyTorch"
            ],
            "Other": [
                "Statistiques",
                "Machine Learning"
            ],
            "EnSoftSkils": [
                "Communication",
                "Collaboration"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "Cephalgo",
        "location": "France",
        "link": "https://fr.linkedin.com/jobs/view/data-scientist-ai-at-cephalgo-3817203204?position=4&pageNum=0&refId=EGCcUYgUshGnwQGGB%2BWgjg%3D%3D&trackingId=a8LjCKmMx3Wpf%2FidiQ7Now%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "The ideal candidate's favorite words are learning, data, scale, and agility. You will leverage your strong collaboration skills and ability to extract valuable insights from highly complex data sets to ask the right questions and find the right answers.\nResponsibilities\nCollect, process, and clean data from diverse sources to prepare it for analysis, ensuring consistency and reliability\nAnalyze raw data: assessing quality, cleansing, structuring for downstream processing and applying machine learning (ML) and deep learning (DL) techniques\nA focus on quantitative analytics and data modeling.\nDesign accurate and scalable prediction algorithms\nEnsuring scalable ML/DL pipeline construction\nImplementing data storage solutions that optimize for volume, velocity, and variety of EEG data\nCollaborate with the team to bring analytical prototypes to production\nStay up-to-date with the latest technologies and trends in data science and machine learning\nQualifications\nMaster's degree or equivalent experience in Computer Science\nAt least 2 years' of experience in DL, quantitative analytics and data modeling\nA strong statistical and programming background\nExperienced in MLOP pipeline construction and big data technologies like Spark, MLFlow, Snowflake, Hadoop for hosting the data\nDeep understanding of predictive modeling, machine-learning, clustering and classification techniques, and algorithms\nFluency in a programming language (Python, C,C++, Java, SQL)\nExcellent problem-solving skills and ability to work independently or as part of a team\nExperienced in working interdisciplinary tasks\nWe Offer\nCompetitive salary and benefits package\nA collaborative work environment with a supportive team\nOpportunities for professional growth and development\nAccess to the latest tools and technologies.\nFlexible working hours and remote work options\nCEPHALGO focuses on introducing technological innovations to assist medical professionals to provide better mental health care. Located in Strasbourg, extended beyond Europe, CEPHALGO’s patient monitoring technique using EEG and AI has been applied in psychiatry across Europe. Further information can be found at https://cephalgo.com.\nShow more\nShow less",
        "details": {
            "JobDetail": [
                "Remote"
            ],
            "TypeContract": "",
            "Salary": "Salary, Package",
            "Level": "",
            "Experience": null
        },
        "title": "data scientist",
        "skills": {
            "ProgLanguage": [
                "Java",
                "Python"
            ],
            "DataBase": [
                "SQL"
            ],
            "BigData": [
                "Hadoop",
                "Spark"
            ],
            "DBMS": [
                "Snowflake"
            ],
            "Other": [
                "ML",
                "Machine Learning",
                "Big Data"
            ],
            "EnSoftSkils": [
                "Collaboration"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "eXalt Value",
        "location": "Île-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/data-scientist-ia-gen-at-exalt-value-3897781437?position=5&pageNum=0&refId=EGCcUYgUshGnwQGGB%2BWgjg%3D%3D&trackingId=UM27Hzftn9Wm7ZgAxIx6TA%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "eXalt\nest un cabinet de conseil IT\nPure player Data\n& IA basé à Paris (1er arrondissement).\nNotre offre s’articule autour de 4 piliers réunis au sein d’une même communauté pour un accompagnement à 360° alliant une expertise technique et méthodologique à une approche conseil métier:\nData Gouvernance & Project\nData Engineering & Big Data\nData Performance & Analytics\nData Science & IA\nFiliale du groupe eXalt créé en 2018,\nregroupant plus de\n950 collaborateurs en France\n(Paris, Lyon, Bordeaux, Lille, Nantes, Marseille)\net à l’international\n(Colombie, Etats-Unis, Espagne, Belgique),\neXalt Value\ndémontre une\nexpertise approfondie\ndans le domaine de la Data & IA et conseille les entreprises dans le déploiement de leurs stratégies data-driven.\nBénéficiant de la renommée et des relations client du groupe eXalt\n(1er dans la catégorie Conseil & Audit au classement des Champions de la Croissance 2024), eXalt Value\nest en pleine croissance et regroupe aujourd’hui une communauté d’expertise de plus de 60 collaborateurs en région parisienne.\nNos consultants interviennent sur d\nes projets d’envergure stimulants\ndans divers secteurs d’activité, Banque & Assurance, Médias, Transports, Retail, Tourisme, etc.\nNous recherchons un\nData Scientist IA Gen H/F\npour rejoindre notre communauté sur le\npilier Data Science & IA.\nVos missions:\nIdentifier les besoins spécifiques des différentes équipes, à travers des ateliers d'idéation, et proposer des solutions algorithmiques innovantes et adaptées à chaque situation.\nAnalyser les données disponibles pour sélectionner les modèles d'IA les plus pertinents face aux besoins identifiés, en tenant compte des particularités de chaque cas d'usage.\nDévelopper, tester et déployer les algorithmes des modèles d'apprentissage automatique et des algorithmes avancés pour résoudre des problèmes complexes grâce à des méthodes statistiques, mathématiques et de machine learning.\nCollaborer avec les Data Engineer afin d’intégrer les solutions IA dans les produits et les applications existants.\nExploiter les dernières avancées en matière d'IA, notamment le Deep Learning, le Reinforcement Learning, le Traitement du Langage Naturel (NLP), la vision par ordinateur, etc., pour créer des solutions innovantes.\nConseiller les clients tout au long du cycle de vie des projets sur les solutions techniques les plus adaptées à leurs environnements.\nLes Prérequis :\nTitulaire d'un Bac+5, idéalement Ecole d'Ingénieur\nCompréhension des enjeux business autours de\nl’exploitation des données et le déploiement des solutions IA\nMaîtrise du\nMachine Learning et du Deep Learning,\ny compris des principaux frameworks (TensorFlow, PyTorch, Scikit-learn, Pandas, NumPy,) et des méthodes statistiques.\nSolides connaissances de\nPython\n(Java, Spark, Scala sont un plus).\nAisance avec l'ensemble du cycle de vie de développement et de déploiement de modèles d'IA (MLOps).\nExpérience de travail en\nméthode Agile\nCapacité à travailler de manière autonome et en équipe.\nExcellentes compétences en communication et présentation.\nMaîtrise de l’anglais (oral & écrit dans un contexte international professionnel).\nVotre environnement eXalté:\nRejoindre\neXalt Value\n, c’est également :\nUn Lab IA\nau sein duquel vous pourrez expérimenter les divers outils et techniques, autour de use cases internes et externes.\nUn environnement de travail Collaboratif\nfavorisant les initiatives et projets transverses à la Practice Data & IA (Data Hub, etc ;)\nUn collectif de consultants passionnés,\ns’intéressant aux tendances innovantes du secteur\nUne Practice de proximité,\nprivilégiant la montée en compétence de ses collaborateurs (formations, coachings, mentorats, etc.)\nUn suivi individualisé et de proximité\npar un.e Data Sales Manager référent du compte client, un.e Chargé.e RH et un.e Practice Manager\nUne équipe sympa et dynamique,\nqui privilégie des moments de partage (séminaires, eXaltemps, meet-ups, déjeuners d’équipe, etc.)\nNotre processus de recrutement :\nUn entretien RH avec Estelle,\nà la suite duquel vous saurez tout (ou presque) d’eXalt Value,\nUn entretien technique avec un Manager IA assorti d’un échange technique,\nlors duquel vous aurez l’occasion de démontrer vos talents et de challenger vos acquis.\nUn entretien final avec la Directrice Associée ou le Directeur Opérationnel,\npour finir de vous convaincre de nous rejoindre 😊\nShow more\nShow less",
        "details": {
            "JobDetail": [],
            "TypeContract": "",
            "Salary": "",
            "Level": "Bac+5",
            "Experience": null
        },
        "title": "data scientist",
        "skills": {
            "ProgLanguage": [
                "Java",
                "Scala",
                "Python"
            ],
            "DataAnalytics": [
                "NumPy",
                "Pandas"
            ],
            "BigData": [
                "Spark"
            ],
            "MachineLearning": [
                "Scikit-Learn",
                "TensorFlow",
                "PyTorch"
            ],
            "Other": [
                "Statistiques",
                "Machine Learning",
                "Big Data"
            ],
            "EnSoftSkils": [
                "Communication"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "Checkout.com",
        "location": "Paris, Île-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/data-scientist-payment-success-at-checkout-com-3903448233?position=6&pageNum=0&refId=EGCcUYgUshGnwQGGB%2BWgjg%3D%3D&trackingId=Hb2W42IAFVrE0Fn6NSTnyQ%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Company Description\nCheckout.com is one of the most exciting fintechs in the world. Our mission is to enable businesses and their communities to thrive in the digital economy. We’re the strategic payments partner for some of the best known fast-moving brands globally such as Wise, Hut Group, Sony Electronics, Homebase, Henkel, Klarna and many others. Purpose-built with performance and scalability in mind, our flexible cloud-based payments platform helps global enterprises launch new products and create experiences customers love. And it's not just what we build that makes us different. It's how.\nWe empower passionate problem-solvers to collaborate, innovate and do their best work. That’s why we’re on the Forbes Cloud 100 list and a Great Place to Work accredited company. And we’re just getting started. We’re building diverse and inclusive teams around the world — because that’s how we create even better experiences for our merchants and our partners. And we need your help. Join us to build the digital economy of tomorrow.\nJob Description\nAbout the opportunity:\nWe empower businesses in the digital economy, and we know that every payment counts. Our Payment Performance team’s mission is to manage and optimise merchants’ payment flow, to achieve optimal conversion, compliance and cost.\nCheckout.com is looking for a data scientist to automate research and investigations tailored for our Tier-1 merchants. This role encompasses the development of automation tools for monitoring, including dashboards and auto-generated presentations, as well as in-depth diagnostic solutions powered by machine learning and recommendation engines.\nYou will also work closely with Payment Performance Managers to ensure the delivery of a high level of service to our key merchants, underpinned by data-driven expertise. The ideal candidate must be a driven technologist with an affinity for problem solving and creating new tools.\nWhat you'll be doing:\nConduct deep-dive exploratory data analysis to uncover insights and anomalies\nDevelop cutting-edge automation tools aimed at monitoring and optimising merchants’ performance\nCreate intuitive, real-time dashboards and reports to provide merchant performance visibility, enabling data-driven decision-making\nPropose enhancements of existing processes/tools by utilising statistical and machine learning techniques\nEffectively communicate research findings to both technical and non-technical stakeholders through reports and presentations\nQualifications\n2+ years experience as data scientist, working with large and diversified data sets\nBachelor’s degree, preferably in Mathematics / Statistics / Computer Science / Engineering, Finance or equivalent\nSQL/ Python knowledge to extract & analyse data from our Data Warehouse\nExperience with Git & Spark, Databricks, Retool, API\nAbility to find creative and effective solutions for business problems\nFlexible, adaptable and has a willingness to learn\nPayments or Fintech experience is a plus\nIf you don't meet all the requirements but think you might still be right for the role, please apply anyway. We're always keen to speak to people who connect with our mission and values\nIf possible, please submit CVs in English.\nAdditional Information\nApply without meeting all requirements statement\nIf you don't meet all the requirements but think you might still be right for the role, please apply anyway. We're always keen to speak to people who connect with our mission and values.\nWe believe in equal opportunities\nWe work as one team. Wherever you come from. However you identify. And whichever payment method you use.\nOur clients come from all over the world — and so do we. Hiring hard-working people and giving them a community to thrive in is critical to our success.\nWhen you join our team, we’ll empower you to unlock your potential so you can do your best work. We’d love to hear how you think you could make a difference here with us.\nWe want to set you up for success and make our process as accessible as possible. So let us know in your application, or tell your recruiter directly, if you need anything to make your experience or working environment more comfortable. We’ll be happy to support you.\nTake a peek inside life at Checkout.com via\nOur Culture video https://youtu.be/BEwnpHuadSw\nOur careers page https://www.checkout.com/careers\nOur LinkedIn Life pages bit.ly/3OaoN1U\nOur Instagram https://www.instagram.com/checkout_com/\nApply Without Meeting All Requirements Statement\nIf you don't meet all the requirements but think you might still be right for the role, please apply anyway. We're always keen to speak to people who connect with our mission and values.\nWe believe in equal opportunities\nWe work as one team. Wherever you come from. However you identify. And whichever payment method you use.\nOur clients come from all over the world — and so do we. Hiring hard-working people and giving them a community to thrive in is critical to our success.\nWhen you join our team, we’ll empower you to unlock your potential so you can do your best work. We’d love to hear how you think you could make a difference here with us.\nWe want to set you up for success and make our process as accessible as possible. So let us know in your application, or tell your recruiter directly, if you need anything to make your experience or working environment more comfortable. We’ll be happy to support you.\nTake a peek inside life at Checkout.com via\nOur Culture video https://youtu.be/BEwnpHuadSw\nOur careers page https://www.checkout.com/careers\nOur LinkedIn Life pages bit.ly/3OaoN1U\nOur Instagram https://www.instagram.com/checkout_com/\nShow more\nShow less",
        "details": {
            "JobDetail": [],
            "TypeContract": "",
            "Salary": "",
            "Level": "",
            "Experience": null
        },
        "title": "data scientist",
        "skills": {
            "ProgLanguage": [
                "Python"
            ],
            "DataBase": [
                "SQL"
            ],
            "BigData": [
                "Databricks",
                "Spark"
            ],
            "DevTools": [
                "Git"
            ],
            "Collaboration": [
                "Teams"
            ],
            "Other": [
                "Machine Learning",
                "Cloud"
            ],
            "EnSoftSkils": [
                "Problem Solving"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "Akademija Oxford",
        "location": "Val-De-Marne, Île-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/apprenti-e-data-scientist-at-akademija-oxford-3917870308?position=7&pageNum=0&refId=EGCcUYgUshGnwQGGB%2BWgjg%3D%3D&trackingId=ud3qOaXRCUmekjhAemQzEA%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Une des entreprises leader sur le marché de la santé, située dans le Val-De-Marne, recherche un.e Apprenti.e Data Scientist dans le cadre d’un contrat d’apprentissage et pour un démarrage en Octobre 2021.\nShow more\nShow less",
        "details": {
            "JobDetail": [],
            "TypeContract": "",
            "Salary": "",
            "Level": "",
            "Experience": null
        },
        "title": "data scientist",
        "skills": {}
    },
    {
        "source": "LinkedIn",
        "company": "Keley Consulting",
        "location": "Paris",
        "link": "https://fr.linkedin.com/jobs/view/data-scientist-at-keley-consulting-3908861590?position=8&pageNum=0&refId=EGCcUYgUshGnwQGGB%2BWgjg%3D%3D&trackingId=I4lzorkLRhl%2F8tNlJ5FOew%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Data Scientist F/H\nDescription de l'offre d'emploi\nAu sein de la practice data, vous accompagnerez nos clients dans la gestion, l’analyse et l’exploitation de leur données notamment grâce au développement de modèles IA et la mise en production de ceux-ci.\nResponsabilités\nVous interviendrez dans des secteurs variés sur des problématiques telles que :\nEvaluer les solutions technologiques liées à la data en effectuant des benchmarks\nCollecter, traiter et analyser des données volumineuses\nCommuniquer efficacement les résultats des analyses\nCréer de la valeur à partir des données en utilisant l’intelligence artificielle et la Data Science\nTravailler en étroite collaboration avec les métiers afin de comprendre leurs besoins et les impliquer dans le développement des outils IA\nDéployer les outils développés en environnement de prod (MLOps)\nA titre d’exemple, nous avons récemment mené les missions suivantes :\nDéveloppement d’outils d’optimisation des revenus pour le compte d’une compagnie aérienne\nEtude de l’impact du traitement de plaintes sur la customer lifetime value\nIndustrialisation de proof-of-concepts (ML Ops)\nDéveloppement de GPTMaker, un outil de création de chatbot s’appuyant sur des LLM\nProfil recherché\nDiplôme Bac+5 type école d’ingénieur ou université en Data Science / Statistiques\nExpérience de 2 à 5 ans en Data, avec au moins 1 an en tant que Data Scientist / Engineer\nMaîtrise des méthodes statistiques et leurs applications opérationnelles, ainsi que Python/Spark\nForte capacité d’organisation, d’analyse, d’écoute et de communication tout en étant force de conviction\nAnglais courant\nQualifications supplémentaires (atouts) :\nExpérience avec les outils du cloud (GCP, Azure, AWS …)\nExpérience dans le NLP (natural language processing)\nPourquoi rejoindre Keley ?\nKeley est un cabinet de conseil à taille humaine.\nAccélérateur de projet, nous accompagnons nos clients sur des programmes de transformation digitale & Data en apportant sens et performance. Autour de méthodologies produits issues du design et orientées résultat, nous cocréons avec nos clients en les accompagnant dans toutes les étapes de leurs projets, jusqu’à l’autonomie.\nParce que les Humains sont au cœur de la transformation digitale des entreprises, celle-ci est aussi culturelle : nous alignons stratégie produit, culture métiers et modèles opérationnels pour concevoir avec nos clients des solutions qui leur ressemblent et qui font le succès de leurs projets.\nNos valeurs\nPassionnés par notre métier, nous sommes des consultants en transformation digitale avec un sens aigu de l’engagement et du partage.\nDans un esprit coopératif et chaleureux, chaque collaborateur pourra trouver sa place, évoluer au cœur de nos métiers et atteindre ses objectifs grâce à des parcours de carrière évolutifs, clairs et transparents.\nNous croyons en la valeur de la diversité et de l'inclusion et encourageons les candidats de tous horizons à postuler.\nKeley vous propose une carrière passionnante dans un environnement stimulant, en vous permettant de travailler avec des grands comptes et sur des missions variées.\nPour vous offrir le meilleur environnement de travail possible, nous vous proposons :\nUn parcours de carrière clair et partagé pour évoluer rapidement au sein du cabinet\nUne politique de rémunération transparente et équitable\nUne charte de télétravail\nDes bureaux au cœur de Paris dans le 8ème arrondissement\nDes mentors et des buddys à l’écoute\nDes évènements de team building réguliers\nUne direction et un management toujours disponibles pour échanger (organisation flat)\nUn programme de formation adapté à vos besoins et incluant des formations externes certifiantes\nDes méthodes et outils de partage de connaissance pour vous nourrir mais aussi vous offrir une tribune : conférences internes hebdomadaires, articles, livres blancs, enquêtes et contenus vidéo\nUn MacBook car on aime les belles choses (surtout quand elles marchent bien)\nUne carte tickets restaurants\nUne prise en charge de la mutuelle à 100%\nUne prime de vacances\nShow more\nShow less",
        "details": {
            "JobDetail": [],
            "TypeContract": "",
            "Salary": "",
            "Level": "Bac+5",
            "Experience": "5 an(s)"
        },
        "title": "data scientist",
        "skills": {
            "ProgLanguage": [
                "Python"
            ],
            "BigData": [
                "Spark"
            ],
            "CloudComputing": [
                "GCP",
                "AWS",
                "Azure"
            ],
            "Other": [
                "Statistiques",
                "Cloud",
                "ML"
            ],
            "EnSoftSkils": [
                "Communication",
                "Collaboration"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "Mines Paris",
        "location": "Valbonne, Provence-Alpes-Côte d'Azur, France",
        "link": "https://fr.linkedin.com/jobs/view/data-scientist-m-w-at-mines-paris-3908686193?position=9&pageNum=0&refId=EGCcUYgUshGnwQGGB%2BWgjg%3D%3D&trackingId=%2FvXoxGYJ%2B1nc%2Fn%2B0%2BkVQgg%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "À propos de nous\nMines Paris est une des plus prestigieuses écoles d'ingénieurs en France. Mines Paris est un établissement public qui forme des ingénieurs généralistes via une expérience pédagogique innovante et pluridisciplinaire (sciences de l'ingénieur et sciences humaines et sociales). Son appartenance à l'Université PSL, qui se positionne dans le top 50 des classements internationaux, constitue une véritable opportunité d'enrichissement des parcours.\nMission\nYour Environment\nAs part of the scientific program of The Transition Institute 1.5 (TTI.5), which focuses on the conditions for the emergence of a transition to a low-carbon planet, taking into account technical, social, economic, political and geopolitical issues, Mines Paris - PSL has an opening for a Data Scientist.\nInsofar as these issues may represent obstacles to the transition, it is essential to understand their fundamentals and decipher the mechanisms that drive them. The TTI.5 scientific program has been designed to harmonize, enhance and extend the various research projects already on offer at Mines Paris - PSL. It is also intended to provide new impetus in areas that have been little addressed until now, but which are nonetheless essential to steering the transition, or to filling gaps such as that of a complete vision of the distribution of resources worldwide.\nYour Challenges And Responsabilities\nIn order to tackle the various transition strategies, it is essential to have a picture of the production of the various raw materials needed for today's and tomorrow's world. At the same time, the exploitation and circulation of different resources can be strongly impacted by geopolitical conditions and times of tension and conflict.\nThe aim of this project, with its high methodological stakes, is to develop and couple:\nglobal resource mapping for two critical \"identifiable\" resources (lithium and cobalt)\na mapping of armed tensions (conflicts, installation of military bases, etc.).\nTo achieve this, we will need to develop a tool for extracting data from a very large mass of information, to be identified, in a changing context that will need to be taken into account for the tool's sustainability.\nThe Development Prospects For This Work Could Include\na double cartography animated over time ;\nthe enrichment of military base and tension indicators, with an equal focus on cases of local armed non-tension around the resource\na scalable database that can be continuously updated\na tool that can be replicated for other resources in a rapidly changing world\nProfil\nLet's talk about you !...\nThe position is aimed at an engineer / master data scientist with a degree from a university or Grande Ecole. Additional skills in GIS would be a plus. He/she may receive in-house training on mining resource issues.\nThe candidate will be strongly encouraged to participate in TTI.5 activities, and may also take part in those of the referral centers. He/she must have demonstrated good teamwork skills.\nFluency in spoken and written English is imperative.\nKnowledge And Skills\nThe main skills required for this post are :\nMastery of algorithms and programming languages (ability to write efficient, scalable code)\nMastery of data management language and databases (ability to find, collect and analyze large volumes of data)\nMastery of data visualization tools\nSoft Skills\nSelf-motivated\nSpirit of initiative\nSense of teamwork\ncreativity\nFlexibility\nCommunication and teaching skills\nAnalytical skills\nThoroughness\n…And about us ! Working at Mines Paris also means :\nJoining a prestigious institution with a rich history\nPlaying a part in the digital transition and the transition to carbon neutrality to tackle the climate emergency\nBelonging to PSL University, ranked 41st in the Academic Ranking of World Universities\nJoin a dynamic, multidisciplinary team!\nA pleasant living environment in a pine forest, at the heart of the 1st technology cluster on the Côte d'Azur and 1st technology park in Europe!\nRéférence de l'offre : 6jpx490r88\nShow more\nShow less",
        "details": {
            "JobDetail": [],
            "TypeContract": "",
            "Salary": "",
            "Level": "",
            "Experience": null
        },
        "title": "data scientist",
        "skills": {
            "EnSoftSkils": [
                "Teamwork",
                "Flexibility",
                "Creativity",
                "Initiative",
                "Communication"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "Valeuriad",
        "location": "Nantes, Pays de la Loire, France",
        "link": "https://fr.linkedin.com/jobs/view/data-scientist-h-f-at-valeuriad-3741220588?position=10&pageNum=0&refId=EGCcUYgUshGnwQGGB%2BWgjg%3D%3D&trackingId=0NzlaazCIgt%2Fyy7fA73seQ%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Rejoins la\nTeam Data\ncréée par\nNicolas Greffard,\nDocteur en Intelligence Artificielle\n, déjà composée de\n20\nData Scientists\net\nData Engineer\ntalentueux 😍\nNous recherchons de\nnouvelles pépites\npour rejoindre notre équipe de choc et répondre aux\nmultiples problématiques Data science\nde nos\nclients nantais\nmais également\ncontribuer à nos projets de R&D\net travailler sur des\nconférences incroyables\n(DevFest, Salon de la Data)\n🤩\nTa future mission si tu l'acceptes\n😉\nNous te proposons d'intervenir au sein de nos\ngrandes DSI clientes\n, sur des sujets de\ncollecte\n, d\n'alimentation\net de\ntransformation de données\nautour de l’intelligence artificielle.\nLe job en détail\n🤩\nToutes Les Missions Ne Sont Pas Identiques, Mais Voici Des Exemples De Choses Sur Lesquelles Nos Data Scientists Sont Intervenus\nÉchange avec les architectes, les PO et PPO, les développeurs et la gouvernance de données ;\nDeep learning (RNN, LSTM, CNN, DQN) et Machine learning ;\nAnalyse de données : statistiques descriptives et exploratoires, Data Mining ;\nTraitement d’images (pattern matching, extraction de descripteurs, tf-idf et classification, etc..) et traitement de texte.\nTraitement du langage / Text-Mining (Word2Vec, BoW, BERT, etc..) ;\nRestitutiondes résultats : dataviz, indicateurs, dashboards (tableaux de bord), optimisation d’application streamlit ;\nMLOps : pour pour amener l'IA jusqu'à la prod ;\nAmélioration de modèles : validation croisée, sélection de descripteurs, métriques d’erreurs ;\nAssurer la veille technologique sur les algorithmes et outils de Data Science.\nLangages : Principalement du Python, souvent du SQL et parfois du R ou même du SAS ;\nFramework : ceux qui reviennent sans arrêt : Tensorflow, PyTorch, Huggingface, SkLearn, Lime, Streamlit, écosystème Hadoop ;\nIntégration continue : en fonction des contextes applicatifs : docker, docker-compose, Docker Swarm, GitHub actions, Jenkins, kubernetes, concourse.\nPourquoi choisir Valeuriad ?\n😊\nEn plus d’être aujourd’hui un acteur nantais reconnu de l’expertise IT, nous nous inscrivons depuis notre création dans une démarche d'entreprise\nOpale\net\nHolacratique\n, où l'ensemble de nos prises de décisions et projets sont réalisés par et avec l'ensemble de nos\n120 coéquipiers\n💪\nRejoindre Valeuriad, c'est pouvoir s'investir dans la co-construction de l'entreprise :\nPar un rôle, avec une fiche de poste et un temps dédié (gestionnaire des Ci’s, porteur des partenariats écoles, organisateur d’événements, PO des projets internes, gestion de l'Académie Valeuriad…).\nPar les projets stratégiques (200 jours mis à disposition pour les coéquipiers chaque année) pour créer et faire grandir des projets structurants (création de nouveaux avantages à l'ancienneté, création d'indicateurs mensuels pour être toujours plus transparents, mécénat de compétences pour des associations caritatives...).\nPar les projets cagnottes (150€ par coéquipiers et par an) pour réaliser des projets collaboratifs qui te tiennent à cœur avec d'autres Valeurieux (découverte du cécifoot, challenge écologique, challenges sportifs pour des dons à des associations humanitaires, borne photo...).\nPar les ateliers collaboratifs, chaque mois des brainstorming et ateliers de travail sont proposés par les différents porteurs de projets et sont ouverts à tous les volontaires.\nMais avant-tout nous sommes une\néquipe soudée\n, des collègues qui apprécient passer du temps ensemble lors de nos soirées hebdomadaires et se créer des\nsouvenirs inoubliables\n🤩 C'est pour ça que chez Valeuriad, le plus important pour nous reste le savoir-être : des passionnés, du dynamisme, des sourires, de l'écoute et le sens de la fête 😉\nShow more\nShow less",
        "details": {
            "JobDetail": [],
            "TypeContract": "",
            "Salary": "",
            "Level": "",
            "Experience": null
        },
        "title": "data scientist",
        "skills": {
            "ProgLanguage": [
                "R",
                "Python"
            ],
            "DataBase": [
                "SQL"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [
                "Hadoop"
            ],
            "MachineLearning": [
                "PyTorch",
                "TensorFlow"
            ],
            "Statistics": [
                "Statistiques Descriptives"
            ],
            "DevTools": [
                "Jenkins",
                "Docker"
            ],
            "Automation": [
                "Kubernetes"
            ],
            "Containers": [
                "Docker",
                "Kubernetes"
            ],
            "Other": [
                "Statistiques",
                "Machine Learning"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "AXA Group Operations",
        "location": "Paris, Île-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/machine-learning-engineer-at-axa-group-operations-3856840119?position=11&pageNum=0&refId=EGCcUYgUshGnwQGGB%2BWgjg%3D%3D&trackingId=IfpsSmfjsoUsU7D9rO3JrA%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Ready to shape the future? Join our team as a Machine Learning Engineer Extraordinaire!\nAbout the job\nBased in Paris or Barcelona, you will be part of the Artificial Intelligence Engineering team, in the Group Emerging Technologies and Data (GETD) division of AXA. This transversal team’s mission is both to build AI-powered initiatives (proofs of concept, proofs of value, pilots) with AXA entities & strategic partners and to define & implement MLOps best practices, tools, and collaboration models to be followed across the whole AXA Group. Our team is composed of 10 people, spread in 3 countries (France, Spain & Switzerland) and we work in hybrid mode (60% remote + 40% on-site).\nAXA is a global leader in insurance and asset management present in nearly 60 countries. We leverage Artificial Intelligence to protect our 100+ million customers, in every domain of core insurance (Property & Casualty, Life & Savings, Health, …). As a responsible company, AXA defined and follows strong Responsible AI principles around robustness, interpretability, fairness, and sustainability.\nKey responsibilities\nIn this role, you will:\nBuild and improve reusable tools & modelling pipelines and support knowledge sharing across several teams.\nWork with Data Scientists to improve both technical and statistical performance of models.\nConvert the machine learning models into application program interfaces (APIs) so that other applications can use them in alignment with architecture & infrastructure standards.\nSecure and monitor ML processing, including safeguards, A/B testing, fault-tolerance, and failover.\nContribute to the definition and deployment of best practices in Machine Learning & MLOps,\nContribute to the sharing of knowledge and expertise through communities and working groups (internal and external).\nHelp the different actors of the organization (such as product managers and stakeholders) understand what results they gain from MLOps and best engineering practices in Data and AI.\nWhat is needed to succeed\nAs we want you to succeed in this role, here is a list of examples of key factors:\n4+ years of experience with DevOps: versioning (Git), containers (Docker/Kubernetes), CI/CD, Static analysis tools, …\nProficiency in ML Ops and ML Engineering frameworks: experiment trackers (like mlFlow) & orchestrators (Airflow, Kubeflow, Sagemaker Pipeline)\nA practical knowledge in one of the popular ML Python libraries (TensorFlow, PyTorch, Keras, Scikit-Learn) and Open-Source libraries.\nA good understanding of Agile methodologies and a mindset of continuous improvement.\nAbility to articulate the results of your work for various audiences.\nGood communication in English and interpersonal skills for working in a multicultural work environment.\nPassion about solving challenging problems leveraging new technologies.\nNice to have\nHere are other elements we will consider:\n2+ years of experience in delivering and running ML models in production, using at least one of some of the main Big Data frameworks and platforms: Spark, Databricks, Snowflake, …\nPractical knowledge in Infrastructure as code (Terraform, CloudFormation, …).\nPractical knowledge of cloud services (Azure or Amazon Web Services).\nTheoretical knowledge in Event Driven Architecture (using Kafka, Event Hub, or Rabbit MQ).\nInsurance & Finance functional knowledge\nWhat we offer\nOn top of usual benefits, we also offer:\nHybrid working (60% remote + 40% on-site).\nGlobal communities of practice and 2 yearly global events gathering Engineers and Data Scientists.\nLearning and mentoring opportunities through partnerships with LinkedIn Learning and O’Reilly.\nAmong a strong Employee benefit program, mental health, and well-being platform to access personalised care.\nWe bring together the expertise, cultural diversity and creativity of over 8,000 employees worldwide. We’re committed to equal opportunities in all aspects of employment (gender, LGBT+, disabled persons, or people of different origins) and to promoting Diversity & Inclusion by creating a work environment where all employees are treated with dignity and respect, and where individual differences are valued.\nShow more\nShow less",
        "details": {
            "JobDetail": [
                "Remote"
            ],
            "TypeContract": "",
            "Salary": "",
            "Level": "",
            "Experience": null
        },
        "title": "machine learning engineer",
        "skills": {
            "ProgLanguage": [
                "Python"
            ],
            "BigData": [
                "Databricks",
                "Spark"
            ],
            "MachineLearning": [
                "Scikit-Learn",
                "PyTorch",
                "TensorFlow",
                "Keras"
            ],
            "CloudComputing": [
                "Azure"
            ],
            "DevTools": [
                "Git",
                "Docker"
            ],
            "DBMS": [
                "Snowflake"
            ],
            "Automation": [
                "Airflow",
                "Kubernetes"
            ],
            "InfrastructureAsCode": [
                "CloudFormation",
                "Terraform"
            ],
            "Containers": [
                "Docker",
                "Kubernetes"
            ],
            "Collaboration": [
                "Teams"
            ],
            "Other": [
                "CI/CD",
                "ML",
                "Big Data",
                "Machine Learning",
                "Cloud",
                "DevOps"
            ],
            "EnSoftSkils": [
                "Organization",
                "Collaboration",
                "Creativity",
                "Interpersonal Skills",
                "Communication"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "EyeTech Solutions",
        "location": "Paris, Île-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/data-scientist%E2%80%93-machine-learning-at-eyetech-solutions-3913336440?position=12&pageNum=0&refId=EGCcUYgUshGnwQGGB%2BWgjg%3D%3D&trackingId=n53I6DfQwIRgoS6pyiYOcw%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Data Scientist– Machine Learning\nTravailler sur le développement de modèle de machine learning prédictif.\nPour une Solution SaaS de monitoring analytique, prédictif et prescriptif en milieu industriel.\nData Scientist– Machine Learning\nFondée en 2016, notre société développe une solution SAAS dédiée au monitoring automatique des lignes de production.\nNotre équipe spécialisée dans les données est responsable de la conception, du développement et de la maintenance de la plateforme IA de notre solution, dont les principales fonctionnalités incluent le monitoring analytique, prédictif et prescriptif.\nCette même équipe est également chargée du développement d'une nouvelle plateforme IA qui sera intégrée à nos solutions existantes.\nNos solutions reposent sur une stack technologique moderne, utilisant des outils tels que Airflow, Mlflow, MongoDB, Kubernetes, CI/CD.\nData Scientist– Machine Learning\nTravaux sur le développement de modèle de machine learning prédictif\nCollaboration avec le Lead Data Scientist et le Lead Tech Senior pour définir les orientations du produit et organiser les tâches.\nContribution au développement des fonctionnalités liées aux données et à l’intelligence artificielle.\nCommunication et présentation clients.\nVeille scientifique et travaux de recherche et développement.\nData Scientist– Machine Learning\n3 ans d’expérience minimum en tant que Data Scientist (IA, ML) dans l’industrialisation d’un produit\nCapaciter à vulgariser, comprendre et transformer les besoins\nDiplome universitaire\nData Scientist– Machine Learning\nLocaux à Paris\nSalaire selon profil, entre 50K et 55K\nTélétravail 2 jours / semaine\nShow more\nShow less",
        "details": {
            "JobDetail": [
                "Senior"
            ],
            "TypeContract": "",
            "Salary": "50K",
            "Level": "",
            "Experience": "3 an(s)"
        },
        "title": "data scientist",
        "skills": {
            "DataBase": [
                "MongoDB"
            ],
            "Automation": [
                "Airflow",
                "Kubernetes"
            ],
            "Containers": [
                "Kubernetes"
            ],
            "Other": [
                "Machine Learning",
                "ML",
                "CI/CD"
            ],
            "EnSoftSkils": [
                "Communication",
                "Collaboration"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "Aether Energy (YC W24)",
        "location": "Paris, Île-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/machine-learning-engineer-at-aether-energy-yc-w24-3911654324?position=13&pageNum=0&refId=EGCcUYgUshGnwQGGB%2BWgjg%3D%3D&trackingId=LBa35KRODLiTFj01rb%2BGBg%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "We raised a $3M seed recently.\nWe encourage all applicants from the EU to apply.\nOverview\nAether is on a mission to develop a comprehensive AI-driven platform for the solar energy industry. Our founders have strong technical academic background from UC Berkeley, complemented by extensive technical experience gained at some of the most influential companies in the energy sector.\nAether is seeking a machine learning engineer with a strong background in software engineering.\nIdeal candidates should have backgrounds in Physics, Mechanical Engineering, Electrical Engineering, or Materials Science, coupled with expertise in Computational Mathematics. A Master's degree is essential for this role, while a PhD, though not mandatory, would be highly valuable.\nWe are proud of our recent success and invite you to check out our YCombinator launch at\nthis link\n.\nWe're Looking For Someone Who:\nGets things done. This is an emerging Y Combinator seed company, and we require you to make an impact from day one.\nYour growth potential here is unlimited.\nQualifications\nThis role will be 60% Machine Learning/Data Science focused, and 40% backend engineering focused. You will need to be comfortable writing production-level code.\nREQUIRED\nStrong proficiency in Python\nKnowledge of unsupervised and supervised machine learning techniques\nA deep understanding of Computer Vision models such as UNET, DeepLab, or HRNet (High-Resolution Network).\nInterested in developing foundational LLM models (our use-case is energy)\nProficiency in data exploration (using BigQuery, Jupyter notebooks, and SQL), model development, and the establishment of data/ML pipelines\nComfortable working with APIs and Databases.\nKnowledge of best practices in collaborative coding with tools like Git and CI/CD.\nStrong software engineering skills and an understanding of good design patterns.\nYou must be Fluent in English.\nPreferred -\nWe know you won’t know everything but having a good general breadth of the requirements below will set you apart.\nA keen interest in the intersection of physical systems and AI.\nKnowledge of the Django framework.\nFamiliarity with Python libraries, including Pandas, NumPy, scikit-learn, PyTorch/Tensorflow, PyTorch Lightning, and vector databases.\nCompetency in deploying data and code to cloud platforms (GCP/Digital Ocean).\nUnderstanding of energy related data: battery data, solar data, etc.\nIdeally, previous experience in high-growth start-ups.\nYour math has to be good. We will check for this.\nCompensation/Time Commitment/Location:\nYou will need to work US EST hours from Monday to Thursday. You must be in our Paris office 3x a week starting in August.\n1st 3 months will be on a contract basis to assess performance.\nShow more\nShow less",
        "details": {
            "JobDetail": [],
            "TypeContract": "",
            "Salary": "",
            "Level": "",
            "Experience": null
        },
        "title": "machine learning engineer",
        "skills": {
            "ProgLanguage": [
                "Python"
            ],
            "DataBase": [
                "SQL"
            ],
            "DataAnalytics": [
                "NumPy",
                "Pandas"
            ],
            "MachineLearning": [
                "Scikit-Learn",
                "TensorFlow",
                "PyTorch"
            ],
            "CloudComputing": [
                "GCP"
            ],
            "DevTools": [
                "Git"
            ],
            "DBMS": [
                "BigQuery"
            ],
            "Other": [
                "Machine Learning",
                "Cloud",
                "ML",
                "CI/CD"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "Mirakl",
        "location": "Paris, Île-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/machine-learning-engineer-at-mirakl-3879686188?position=14&pageNum=0&refId=EGCcUYgUshGnwQGGB%2BWgjg%3D%3D&trackingId=wddjfeLCyDYNCFGzs9oqcw%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Mirakl, leader et pionnier de l’économie de plateforme, propose aux entreprises une suite unique de solutions leur permettant de transformer significativement leur e-commerce afin d'accélérer de façon durable et rentable leur croissance. Depuis 2012, Mirakl accompagne les entreprises B2C et B2B avec la technologie la plus avancée, sécurisée et évolutive leur permettant de digitaliser leur activité et d'élargir leur offre via la marketplace ou le dropship, faciliter la gestion des catalogues et des paiements de leurs fournisseurs pour plus d'efficacité, offrir une expérience d'achat personnalisée à leurs clients, et augmenter leurs profits grâce au retail media. Basée à Paris et Boston, Mirakl est certifiée Great Place to Work.\nA propos de Mirakl Labs\nNos équipes techniques et produits, nommées Mirakl Labs, sont principalement réparties entre nos 2 hubs situés à Paris et à Bordeaux. Elles collaborent au quotidien afin d'adresser les problématiques de nos clients et utilisateurs en répondant à différents challenges liés aux nouvelles fonctionnalités, à la scalabilité, la sécurité et l’ergonomie…\nElles opèrent en mode agile et s'organisent en Squads composées d'un Squad Lead, de 5 développeurs, d'un Product Manager et d'un QA. Chaque Squad est spécialisée sur un scope fonctionnel afin de concevoir et réaliser de nouvelles features, leurs évolutions et des APIs (avec un découpage en micro-services). Nos équipes Infrastructure, Architecture, Sécurité, Documentation, Product Design, Data et Support opèrent en transverse en apportant leur expertise et de la cohérence sur l’ensemble des produits.\nToutes les équipes sont responsables de leur périmètre et chacun des collaborateurs apporte son expérience et ses idées. Innovation, feedback et implication dans les prises de décision sont au cœur de notre philosophie.\nEt pour favoriser ce partage avec d’autres passionnés, nous sommes sponsors, speakers, et hôtes de différents événements, meetups, et associations de la scène Tech en France. Au cours des dernières années, nous avons participé à des événements tels que Devoxx, ReactEurope, ProductConf et Flupa UX Days.\nA propos du job\nIntégré.e dans notre équipe Data Science, votre principale mission sera de prototyper, itérer, et mettre en production des algorithmes en collaboration avec les équipes Produit, les Data Engineers et les équipes de développement. Les sujets que vous traiterez auront un vrai impact sur nos clients : l’ambition est d’exploiter au maximum nos données riches et variées afin de développer leur chiffre d'affaires, d’optimiser la gestion opérationnelle de leur marketplace et de garantir la sécurité des utilisateurs et des transactions.\nA propos de l’équipe\nGet to Know the Data Science Team That Powers the Mirakl Platform\nCe qu’il y a pour vous dans ce job\nImplémenter, optimiser et déployer des algorithmes qui auront un impact visible sur plus de 500 sites e-commerce/marketplaces dans 40 pays dont certains une volumétrie très importantes (millions de produits, de clients, de commandes par an)\nTraiter des sujets très divers et variés d’un point de vue:\nBusiness\nMachine learning (NLP, Image processing, Time series, LLM, système de recommandation, etc.)\nInfrastructure (spark, model endpoints, etc.)\nUne plateforme Machine Learning et Data Platform state-of-the-art\nConcevoir et déployer des infrastructures à faible latence avec les Data Engineers\nUne vraie autonomie et responsabilité dans les projets dont vous avez l’ownership\nLa possibilité d'avoir un contrat freelance ou CDI\nNotre stack et nos outils\nPython, Tensorflow, Pytorch, Databricks, Spark, Aws, Airflow, MLflow, Delta Lake, SQL\nAu quotidien\n,\nvous allez :\nDesigner, optimiser et mettre en production des modèles de machine learning de façon scalable (apprentissage et inférence)\nRassembler et manipuler les données, prototyper des algorithmes de machine learning\nMettre en place et monitorer des serving endpoints\nParticiper à l’évolution de la plateforme Machine Learning de Mirakl\nContinuer à mettre en place des best practices de programmation mais aussi de déploiement\nEffectuer de la veille technologique sur les modèles state-of-the-art, ainsi que sur les stack machine learning\nPrésenter les résultats au weekly data science et aux sessions de brainstorming de l’équipe\nÉchanger avec les autres équipes pour affiner les cas d’utilisation, l’expérience utilisateur et les modes d’intégration\nVous aimerez ce job si :\nVous avez minimum 3 ans d’expérience en tant que Machine Learning Engineer (le poste est évolutif selon votre séniorité)\nVous avez de solides compétences en développement Python\nVous aimez le software engineering et le machine learning\nVous avez une expérience significative dans la mise en production, le scaling des modèles et des bests practices MLOps\nVous avez l’habitude de chercher, manipuler et analyser des données à forte volumétrie, idéalement avec Spark\nVous avez une bonne connaissance des algorithmes de Deep Learning (texte et/ou image), des architectures State-Of-the-Art - par exemple les Transformers\nVous avez de l’expérience dans l’optimisation de modèles de machine learning et de leur inférence\nVous avez de l’expérience dans la mise en place de serving de modèles\nVous aimez avoir l’ownership de vos sujets et aimez partager votre travail dans le cadre de présentations internes, dans des conférences ou en rédigeant des articles\nPetit plus :\nVous avez une expérience en environnement e-commerce, sur des algorithmes de systèmes de recommandations et/ou retail media\nVous avez une expérience dans le serving de modèles à faible latence\nVous êtes spécialiste NLP\nOptimisation de LLM\nMirakl est engagée en faveur de la diversité, de l’égalité des chances et de l’inclusion. Nous célébrons nos différences car nous sommes convaincus que les qualités visibles et invisibles de chaque Mirakl Worker sont une source de force et d’innovation. Dans le cadre de cet engagement, nous étudions toutes les candidatures sans distinction de : genre, ethnicité, religion, orientation sexuelle, handicap, âge ou toute autre caractéristique protégée par la loi.\nShow more\nShow less",
        "details": {
            "JobDetail": [],
            "TypeContract": "CDI",
            "Salary": "",
            "Level": "",
            "Experience": "3 an(s)"
        },
        "title": "machine learning engineer",
        "skills": {
            "ProgLanguage": [
                "Python"
            ],
            "DataBase": [
                "SQL"
            ],
            "BigData": [
                "Databricks",
                "Spark"
            ],
            "MachineLearning": [
                "PyTorch",
                "TensorFlow"
            ],
            "CloudComputing": [
                "AWS"
            ],
            "Automation": [
                "Airflow"
            ],
            "Other": [
                "Machine Learning"
            ],
            "EnSoftSkils": [
                "Collaboration"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "Mirakl",
        "location": "Paris, Île-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/machine-learning-engineer-at-mirakl-3879682593?position=15&pageNum=0&refId=EGCcUYgUshGnwQGGB%2BWgjg%3D%3D&trackingId=a%2Bf3OjukV2mgUJef50tD0w%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Mirakl, leader et pionnier de l’économie de plateforme, propose aux entreprises une suite unique de solutions leur permettant de transformer significativement leur e-commerce afin d'accélérer de façon durable et rentable leur croissance. Depuis 2012, Mirakl accompagne les entreprises B2C et B2B avec la technologie la plus avancée, sécurisée et évolutive leur permettant de digitaliser leur activité et d'élargir leur offre via la marketplace ou le dropship, faciliter la gestion des catalogues et des paiements de leurs fournisseurs pour plus d'efficacité, offrir une expérience d'achat personnalisée à leurs clients, et augmenter leurs profits grâce au retail media. Basée à Paris et Boston, Mirakl est certifiée Great Place to Work.\nA propos de Mirakl Labs\nNos équipes techniques et produits, nommées Mirakl Labs, sont principalement réparties entre nos 2 hubs situés à Paris et à Bordeaux. Elles collaborent au quotidien afin d'adresser les problématiques de nos clients et utilisateurs en répondant à différents challenges liés aux nouvelles fonctionnalités, à la scalabilité, la sécurité et l’ergonomie…\nElles opèrent en mode agile et s'organisent en Squads composées d'un Squad Lead, de 5 développeurs, d'un Product Manager et d'un QA. Chaque Squad est spécialisée sur un scope fonctionnel afin de concevoir et réaliser de nouvelles features, leurs évolutions et des APIs (avec un découpage en micro-services). Nos équipes Infrastructure, Architecture, Sécurité, Documentation, Product Design, Data et Support opèrent en transverse en apportant leur expertise et de la cohérence sur l’ensemble des produits.\nToutes les équipes sont responsables de leur périmètre et chacun des collaborateurs apporte son expérience et ses idées. Innovation, feedback et implication dans les prises de décision sont au cœur de notre philosophie.\nEt pour favoriser ce partage avec d’autres passionnés, nous sommes sponsors, speakers, et hôtes de différents événements, meetups, et associations de la scène Tech en France. Au cours des dernières années, nous avons participé à des événements tels que Devoxx, ReactEurope, ProductConf et Flupa UX Days.\nA propos du job\nIntégré.e dans notre équipe Data Science, votre principale mission sera de prototyper, itérer, et mettre en production des algorithmes en collaboration avec les équipes Produit, les Data Engineers et les équipes de développement. Les sujets que vous traiterez auront un vrai impact sur nos clients : l’ambition est d’exploiter au maximum nos données riches et variées afin de développer leur chiffre d'affaires, d’optimiser la gestion opérationnelle de leur marketplace et de garantir la sécurité des utilisateurs et des transactions.\nA propos de l’équipe\nGet to Know the Data Science Team That Powers the Mirakl Platform\nCe qu’il y a pour vous dans ce job\nImplémenter, optimiser et déployer des algorithmes qui auront un impact visible sur plus de 500 sites e-commerce/marketplaces dans 40 pays dont certains une volumétrie très importantes (millions de produits, de clients, de commandes par an)\nTraiter des sujets très divers et variés d’un point de vue:\nBusiness\nMachine learning (NLP, Image processing, Time series, LLM, système de recommandation, etc.)\nInfrastructure (spark, model endpoints, etc.)\nUne plateforme Machine Learning et Data Platform state-of-the-art\nConcevoir et déployer des infrastructures à faible latence avec les Data Engineers\nUne vraie autonomie et responsabilité dans les projets dont vous avez l’ownership\nLa possibilité d'avoir un contrat freelance ou CDI\nNotre stack et nos outils\nPython, Tensorflow, Pytorch, Databricks, Spark, Aws, Airflow, MLflow, Delta Lake, SQL\nAu quotidien\n,\nvous allez :\nDesigner, optimiser et mettre en production des modèles de machine learning de façon scalable (apprentissage et inférence)\nRassembler et manipuler les données, prototyper des algorithmes de machine learning\nMettre en place et monitorer des serving endpoints\nParticiper à l’évolution de la plateforme Machine Learning de Mirakl\nContinuer à mettre en place des best practices de programmation mais aussi de déploiement\nEffectuer de la veille technologique sur les modèles state-of-the-art, ainsi que sur les stack machine learning\nPrésenter les résultats au weekly data science et aux sessions de brainstorming de l’équipe\nÉchanger avec les autres équipes pour affiner les cas d’utilisation, l’expérience utilisateur et les modes d’intégration\nVous aimerez ce job si :\nVous avez minimum 3 ans d’expérience en tant que Machine Learning Engineer (le poste est évolutif selon votre séniorité)\nVous avez de solides compétences en développement Python\nVous aimez le software engineering et le machine learning\nVous avez une expérience significative dans la mise en production, le scaling des modèles et des bests practices MLOps\nVous avez l’habitude de chercher, manipuler et analyser des données à forte volumétrie, idéalement avec Spark\nVous avez une bonne connaissance des algorithmes de Deep Learning (texte et/ou image), des architectures State-Of-the-Art - par exemple les Transformers\nVous avez de l’expérience dans l’optimisation de modèles de machine learning et de leur inférence\nVous avez de l’expérience dans la mise en place de serving de modèles\nVous aimez avoir l’ownership de vos sujets et aimez partager votre travail dans le cadre de présentations internes, dans des conférences ou en rédigeant des articles\nPetit plus :\nVous avez une expérience en environnement e-commerce, sur des algorithmes de systèmes de recommandations et/ou retail media*\nVous avez une expérience dans le serving de modèles à faible latence\nVous êtes spécialiste NLP\nOptimisation de LLM\nMirakl est engagée en faveur de la diversité, de l’égalité des chances et de l’inclusion. Nous célébrons nos différences car nous sommes convaincus que les qualités visibles et invisibles de chaque Mirakl Worker sont une source de force et d’innovation. Dans le cadre de cet engagement, nous étudions toutes les candidatures sans distinction de : genre, ethnicité, religion, orientation sexuelle, handicap, âge ou toute autre caractéristique protégée par la loi.\nShow more\nShow less",
        "details": {
            "JobDetail": [],
            "TypeContract": "CDI",
            "Salary": "",
            "Level": "",
            "Experience": "3 an(s)"
        },
        "title": "machine learning engineer",
        "skills": {
            "ProgLanguage": [
                "Python"
            ],
            "DataBase": [
                "SQL"
            ],
            "BigData": [
                "Databricks",
                "Spark"
            ],
            "MachineLearning": [
                "PyTorch",
                "TensorFlow"
            ],
            "CloudComputing": [
                "AWS"
            ],
            "Automation": [
                "Airflow"
            ],
            "Other": [
                "Machine Learning"
            ],
            "EnSoftSkils": [
                "Collaboration"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "NuMind (YC S22)",
        "location": "Paris, Île-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/machine-learning-scientist-engineer-at-numind-yc-s22-3856851886?position=16&pageNum=0&refId=EGCcUYgUshGnwQGGB%2BWgjg%3D%3D&trackingId=o0yuwOQJ8MHxFaoofHaUqw%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "About Us\nNuMind (https://www.numind.ai/) is a software company developing a tool to create custom NLP models specialized in information extraction (see https://www.youtube.com/watch?v=MQhYe5HXqss). We also develop open-source foundation models (https://huggingface.co/numind), and write research papers (see https://arxiv.org/abs/2402.15343).\nWe aim to become leader in the field of custom information extraction.\nWe are a team of 7: CEO, CTO, COO, 2 senior software engineers, and 2 machine learning scientists. Our CEO was head of ML at Wolfram Research and our CTO co-founded Make.org.\nMost of the team are located in France (Paris).\nWe were part of YCombinator’s S22 batch, and raised a good seed round.\nJob Description\nNuMind is a tool to create NLP models (e.g. classifiers and entity recognizers). The user provides information about the task (e.g. by labeling documents), and the computer creates models automatically.\nYour job will be to make this happen in the most effective way. This will involve designing & testing various machine learning solutions, and implementing these solutions directly into NuMind.\nR&D topics include:\nTransfer learning, few-shot learning\nActive learning\nAutomatic machine learning\nPerformance measurements\nDistillation\nProbability calibration\nOut-of-domain robustness\nModel explanations\nThis position is for someone who has both a researcher and engineer mindset.\nResponsibilities\nTraining task-specific foundation models\nSetting up benchmarks to test ML solutions\nIdentifying & testing existing ML solutions\nDesigning & testing new ML solutions from scratch\nImplementing selected solutions into the product\nStaying up to date with relevant NLP research\nQualifications\nExpert-level understanding of machine learning.\nAbility to design, train, test deep learning models\nAbility to conduct machine learning research (e.g. conducting experiments, drawing conclusions, communicating results)\nAbility to develop production-grade code\nGood understanding of the following field: statistics, computer science (esp. data structures & algorithms), and numerical analysis\nShow more\nShow less",
        "details": {
            "JobDetail": [
                "Senior"
            ],
            "TypeContract": "",
            "Salary": "",
            "Level": "",
            "Experience": null
        },
        "title": "machine learning engineer",
        "skills": {
            "ProgLanguage": [
                "R"
            ],
            "DataAnalytics": [
                "R"
            ],
            "Other": [
                "Machine Learning",
                "ML"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "Capgemini",
        "location": "Toulouse, Occitanie, France",
        "link": "https://fr.linkedin.com/jobs/view/data-scientist-toulouse-at-capgemini-3913358664?position=17&pageNum=0&refId=EGCcUYgUshGnwQGGB%2BWgjg%3D%3D&trackingId=D7LWLFbnm7ToTrU28hLx3Q%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Capgemini en quelques mots\nChoisir Capgemini, c'est choisir une entreprise où vous serez en mesure de façonner votre carrière selon vos aspirations, où vous serez soutenu et inspiré par une communauté d’experts dans le monde entier, où vous pourrez réécrire votre futur. Rejoignez-nous pour redéfinir les limites de ce qui est possible, contribuer à libérer la valeur de la technologie pour les plus grandes organisations et participez à la construction d’un monde plus durable et inclusif.\nVos missions\nEn tant que\nLead Technique Data Science\nau sein de la practice Insights & Data, vous serez amener à intervenir sur des projets data pour :\nIdéaliser les cas d’usages et cadrer le projet afin de répondre aux exigences métiers à partir de solutions innovantes d’Intelligence Artificielle\nPromouvoir les bonnes pratiques au sein de l’équipe avec le développement d’une méthodologie de travail et d’amélioration continue appropriés\nParticiper aux propositions commerciales sur la partie Data\nConstruire une relation de confiance avec le client en tant qu’interlocuteur privilégié et assurer la qualité des rendus finaux ainsi que le développement de nouveaux enjeux business\nFaire parti des leaders de la communauté Data Science et influencer sur la stratégie Data d’Insights & Data\nContinuer de vous former sur tous les aspects de votre métier et assurer une veille technologique sur les innovations les plus pertinentes à mettre en place\nVotre profil\nDe formation Bac + 5 en école d’ingénieur ou équivalent universitaire avec une spécialisation Data Science\nA partir de 6 ans d’expériences\nCompréhension fine des enjeux business et pilotage d'une équipe\nConnaissance de plusieurs langages de programmation (Python, Scala, Spark…) et Cloud (AWS, GCP, Azure, OVH)\nLe Machine Learning, le NLP et le Deep Learning n’ont plus de secret pour vous\nBon niveau d'anglais\n3 raisons de nous rejoindre\nQualité de vie au travail :\naccord de télétravail en France et à l’international, accord sur l’égalité\nprofessionnelle, la parentalité, l’équilibre des temps et la mobilité durable.\nApprentissage en continu :\ncertifications et formations en libre accès, accompagnement sur mesure avec\nvotre carreer manager, parcours d’intégration sur 9 mois.\nAvantages groupe & CSE :\nplan actionnariat, activités à tarifs préférentiels, remboursement partiel\nvacances, remboursement de votre abonnement sportif ou culturel\nNos engagements et priorités\nLe groupe Capgemini encourage une\nculture inclusive dans un cadre multiculturel et handi-accueillant.\nEn nous rejoignant, vous intégrez un collectif qui valorise la diversité, développe le potentiel de ses talents, s’engage dans des\ninitiatives solidaires avec ses partenaires, et se mobilise pour réduire son impact environnemental sur tous ses sites et auprès de ses clients.\nCapgemini\nest un\nleader mondial\n, responsable et multiculturel, regroupant près de 350 000 personnes dans plus de 50 pays. Fort de\n55 ans d’expérience\n, nous sommes un partenaire stratégique des entreprises pour la transformation de leurs activités en tirant profit de toute la puissance de la technologie et des innovations dans les domaines en perpétuelle évolution tels que\nle cloud, la data, l’Intelligence Artificielle, la connectivité, les logiciels, l’ingénierie digitale ou les plateformes.\nGet The Future You Want* | www.capgemini.com/fr-fr\n*Capgemini, le futur que vous voulez\nShow more\nShow less",
        "details": {
            "JobDetail": [],
            "TypeContract": "",
            "Salary": "",
            "Level": "",
            "Experience": "6 an(s)"
        },
        "title": "data scientist",
        "skills": {
            "ProgLanguage": [
                "Scala",
                "Python"
            ],
            "BigData": [
                "Spark"
            ],
            "CloudComputing": [
                "GCP",
                "AWS",
                "Azure"
            ],
            "Other": [
                "Machine Learning",
                "Cloud"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "Enzo Tech Group",
        "location": "Île-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/data-scientist-at-enzo-tech-group-3914681877?position=18&pageNum=0&refId=EGCcUYgUshGnwQGGB%2BWgjg%3D%3D&trackingId=ohDkU5k3R423YD8rHWJhyQ%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Role:\nData Scientist\nLocation:\nParis (3 days) / Remote (2 days)\nSearching for a\nData Scientist\npartnering with a global customer who are searching for multiple Data Scientist's as they continue to invest in designing and building high-quality AI solutions.\nResponsibilities\nAnalyze raw data: assessing quality, cleansing, structuring for downstream processing\nDesign accurate and scalable prediction algorithms\nCollaborate with engineering team to bring analytical prototypes to production\nGenerate actionable insights for business improvements\nQualifications\nBachelor's degree or equivalent experience in quantative field (Statistics, Mathematics, Computer Science, Engineering, etc.)\nTech Stack: GenAI, Databricks, Azure\nAt least 1 - 2 years' of experience in quantitative analytics or data modelling\nDeep understanding of predictive modelling, machine-learning, clustering and classification techniques, and algorithms\nFluency in a programming language (Python, C,C++, Java, SQL)\nCVs:\nApply via job post or directly\n@\nk.downs@enzotechgroup.com\nShow more\nShow less",
        "details": {
            "JobDetail": [
                "Remote"
            ],
            "TypeContract": "",
            "Salary": "",
            "Level": "",
            "Experience": null
        },
        "title": "data scientist",
        "skills": {
            "ProgLanguage": [
                "Java",
                "Python"
            ],
            "DataBase": [
                "SQL"
            ],
            "BigData": [
                "Databricks"
            ],
            "CloudComputing": [
                "Azure"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "Sidetrade",
        "location": "Boulogne-Billancourt, Île-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/data-scientist-at-sidetrade-3894699040?position=19&pageNum=0&refId=EGCcUYgUshGnwQGGB%2BWgjg%3D%3D&trackingId=fi4rJXKOGiEroo0rb7FY%2Bw%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Calling all tech enthusiasts! Are you a problem-solving, curious, and strategic Data Scientist ? Join us at Sidetrade, the leading global SaaS provider recognized by Gartner.(https://go.sidetrade.com/GartnerMagicQuadrant22.ht)\nIndulge your passion for high-availability software and performance enhancement as part of our dynamic team. Embrace the challenge, embrace the excitement - become a Data Scientist and thrive! Shape the future of AI-powered Order-to-Cash at Sidetrade today. Join us in creating innovative solutions that redefine the industry!\nAbout Sidetrade and its amazing R&D team\nSidetrade is a fast-growing international software company that is transforming the Order-to-Cash process for global enterprises. Its AI-powered SaaS platform digitizes the financial customer journey, empowering CFOs to secure and accelerate cash flow generation. Recognized as a Leader in Gartner's Magic Quadrant for two consecutive years, Sidetrade fosters a culture of innovation, collaboration, and customer-centricity from its headquarters in Europe and North America.\nThe R&D team comprises experienced tech professionals who share a deep passion for technology. Together, they are dedicated to developing cutting-edge software solutions that drive the transformation of our customers' work processes. We provide comprehensive training, coaching, resources, and mentorship to empower every team member's growth and nurture their success.\nWhat you will love at Sidetrade:\nWe are seeking a passionate and knowledgeable Data Scientist with a multifaceted skill set. Immerse yourself in the exhilarating world of AI and Data Science within our cutting-edge tech environment. Collaborate with like-minded individuals, embracing the latest tools, techniques, and technologies. Fuel your professional growth and innovation within our agile development ecosystem.\nYour missions :\nBuild solutions with AI, GenAI, LLM, Machine learning, Deep learning, Big Data for our products\nDefine the technical and functional orientations of the product in interaction with our Product, Marketing and Sales teams.\nParticipate in developing the architecture (LakeHouse, DataWareHouse, DataLake, ETL, Search Engine, NoSQL, SQL) and designing scalable and smart algorithms\nEnhance your skills through constant discussions with specialists in their fields, and internal hackathons\nParticipate in data science guild projects: Exploratory research, Data mining, Data analysis, POC Machine learning,..\nYou will be involved in the entire development cycle: design, implementation, testing, release and maintenance.\nThrough your expertise, you will reinforce the continuous improvement of development processes.\nTechnical environment :\nLanguages : Python & SQL\nData Storage : Oracle, Postgres, Elasticsearch, Greenplum, MongoDB\nData Science framework : Dataiku, Jupyter Notebook, Metaflow\nDataviz : Tableau Server, PowerBI\nData processing : Talend, Python, DBT, Kafka\nSource control : Git\nDéployment: Bash, Ansible, Docker\nConfluence, Jira, Teams\nRequirements\nMaster degree\n2 to 5 years' experience in a similar position\nProven data science experience with production launch of Machine Learning models\nApplied knowledge of AI, GenAI and LLM\nSolid knowledge of Python and object-oriented programming\nGood knowledge of SQL and NoSQL databases\nFamiliarity with API Rest and Web development issues\nSensitivy to the performance of your algorithms, both in terms of relevance and hardware impact\nA taste for discovery and technology watch\nYou know how to grasp a rich technical stack (Scheduling/Message queuing/Front/API/Data Workflow / Distributed Computing Framework / Machine Learning / SQL & NoSQL databases) and challenge it\nFluent in English (written and spoken) is a must (most of the meeting are in English).\nBenefits\nJoin our Immersive Bootcamp\nReview your onboarding plan with your manager and develop an action plan to achieve your goals\nCollaborate with the team and participate to the roadmap to optimize software performancebuild your internal network across all departments\nExpand your skill set, share your expertise and unlock your full potential\nAt Sidetrade, we cultivate a multicultural environment that fuels innovation. With over 22 nationalities represented, we strongly value diversity, gender equality, inclusivity, and fairness. As an equal opportunity employer, we reject all forms of discrimination and harassment. Your unique contributions are celebrated, driving collective success in our inclusive workplace.\nDiscover more on www.sidetrade.com\nAgencies\nOnly applications from invited agencies through the Workable portal will be accepted. Unsolicited CVs sent directly to managers or HR will not incur any fees.\nApply for this job\nShow more\nShow less",
        "details": {
            "JobDetail": [
                "Full"
            ],
            "TypeContract": "",
            "Salary": "",
            "Level": "",
            "Experience": null
        },
        "title": "data scientist",
        "skills": {
            "ProgLanguage": [
                "R",
                "Bash",
                "Python"
            ],
            "DataBase": [
                "Elasticsearch",
                "SQL",
                "MongoDB",
                "NoSQL"
            ],
            "DataAnalytics": [
                "R"
            ],
            "DataVisualisation": [
                "Tableau"
            ],
            "DevTools": [
                "Git",
                "Docker"
            ],
            "Automation": [
                "Ansible"
            ],
            "Containers": [
                "Docker"
            ],
            "Collaboration": [
                "Confluence",
                "Teams",
                "JIRA"
            ],
            "Other": [
                "Machine Learning",
                "Big Data"
            ],
            "EnSoftSkils": [
                "Collaboration"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "Mirakl",
        "location": "Bordeaux, Nouvelle-Aquitaine, France",
        "link": "https://fr.linkedin.com/jobs/view/machine-learning-engineer-at-mirakl-3879681732?position=20&pageNum=0&refId=EGCcUYgUshGnwQGGB%2BWgjg%3D%3D&trackingId=lqE6h8iVcB0k9FL%2FdMIw1A%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Mirakl, leader et pionnier de l’économie de plateforme, propose aux entreprises une suite unique de solutions leur permettant de transformer significativement leur e-commerce afin d'accélérer de façon durable et rentable leur croissance. Depuis 2012, Mirakl accompagne les entreprises B2C et B2B avec la technologie la plus avancée, sécurisée et évolutive leur permettant de digitaliser leur activité et d'élargir leur offre via la marketplace ou le dropship, faciliter la gestion des catalogues et des paiements de leurs fournisseurs pour plus d'efficacité, offrir une expérience d'achat personnalisée à leurs clients, et augmenter leurs profits grâce au retail media. Basée à Paris et Boston, Mirakl est certifiée Great Place to Work.\nA propos de Mirakl Labs\nNos équipes techniques et produits, nommées Mirakl Labs, sont principalement réparties entre nos 2 hubs situés à Paris et à Bordeaux. Elles collaborent au quotidien afin d'adresser les problématiques de nos clients et utilisateurs en répondant à différents challenges liés aux nouvelles fonctionnalités, à la scalabilité, la sécurité et l’ergonomie…\nElles opèrent en mode agile et s'organisent en Squads composées d'un Squad Lead, de 5 développeurs, d'un Product Manager et d'un QA. Chaque Squad est spécialisée sur un scope fonctionnel afin de concevoir et réaliser de nouvelles features, leurs évolutions et des APIs (avec un découpage en micro-services). Nos équipes Infrastructure, Architecture, Sécurité, Documentation, Product Design, Data et Support opèrent en transverse en apportant leur expertise et de la cohérence sur l’ensemble des produits.\nToutes les équipes sont responsables de leur périmètre et chacun des collaborateurs apporte son expérience et ses idées. Innovation, feedback et implication dans les prises de décision sont au cœur de notre philosophie.\nEt pour favoriser ce partage avec d’autres passionnés, nous sommes sponsors, speakers, et hôtes de différents événements, meetups, et associations de la scène Tech en France. Au cours des dernières années, nous avons participé à des événements tels que Devoxx, ReactEurope, ProductConf et Flupa UX Days.\nA propos du job\nIntégré.e dans notre équipe Data Science, votre principale mission sera de prototyper, itérer, et mettre en production des algorithmes en collaboration avec les équipes Produit, les Data Engineers et les équipes de développement. Les sujets que vous traiterez auront un vrai impact sur nos clients : l’ambition est d’exploiter au maximum nos données riches et variées afin de développer leur chiffre d'affaires, d’optimiser la gestion opérationnelle de leur marketplace et de garantir la sécurité des utilisateurs et des transactions.\nA propos de l’équipe\nGet to Know the Data Science Team That Powers the Mirakl Platform\nCe qu’il y a pour vous dans ce job\nImplémenter, optimiser et déployer des algorithmes qui auront un impact visible sur plus de 500 sites e-commerce/marketplaces dans 40 pays dont certains une volumétrie très importantes (millions de produits, de clients, de commandes par an)\nTraiter des sujets très divers et variés d’un point de vue:\nBusiness\nMachine learning (NLP, Image processing, Time series, LLM, système de recommandation, etc.)\nInfrastructure (spark, model endpoints, etc.)\nUne plateforme Machine Learning et Data Platform state-of-the-art\nConcevoir et déployer des infrastructures à faible latence avec les Data Engineers\nUne vraie autonomie et responsabilité dans les projets dont vous avez l’ownership\nLa possibilité d'avoir un contrat freelance ou CDI\nNotre stack et nos outils\nPython, Tensorflow, Pytorch, Databricks, Spark, Aws, Airflow, MLflow, Delta Lake, SQL\nAu quotidien\n,\nvous allez :\nDesigner, optimiser et mettre en production des modèles de machine learning de façon scalable (apprentissage et inférence)\nRassembler et manipuler les données, prototyper des algorithmes de machine learning\nMettre en place et monitorer des serving endpoints\nParticiper à l’évolution de la plateforme Machine Learning de Mirakl\nContinuer à mettre en place des best practices de programmation mais aussi de déploiement\nEffectuer de la veille technologique sur les modèles state-of-the-art, ainsi que sur les stack machine learning\nPrésenter les résultats au weekly data science et aux sessions de brainstorming de l’équipe\nÉchanger avec les autres équipes pour affiner les cas d’utilisation, l’expérience utilisateur et les modes d’intégration\nVous aimerez ce job si :\nVous avez minimum 3 ans d’expérience en tant que Machine Learning Engineer (le poste est évolutif selon votre séniorité)\nVous avez de solides compétences en développement Python\nVous aimez le software engineering et le machine learning\nVous avez une expérience significative dans la mise en production, le scaling des modèles et des bests practices MLOps\nVous avez l’habitude de chercher, manipuler et analyser des données à forte volumétrie, idéalement avec Spark\nVous avez une bonne connaissance des algorithmes de Deep Learning (texte et/ou image), des architectures State-Of-the-Art - par exemple les Transformers\nVous avez de l’expérience dans l’optimisation de modèles de machine learning et de leur inférence\nVous avez de l’expérience dans la mise en place de serving de modèles\nVous aimez avoir l’ownership de vos sujets et aimez partager votre travail dans le cadre de présentations internes, dans des conférences ou en rédigeant des articles\nPetit plus :\nVous avez une expérience en environnement e-commerce, sur des algorithmes de systèmes de recommandations et/ou retail media*\nVous avez une expérience dans le serving de modèles à faible latence\nVous êtes spécialiste NLP\nOptimisation de LLM\nMirakl est engagée en faveur de la diversité, de l’égalité des chances et de l’inclusion. Nous célébrons nos différences car nous sommes convaincus que les qualités visibles et invisibles de chaque Mirakl Worker sont une source de force et d’innovation. Dans le cadre de cet engagement, nous étudions toutes les candidatures sans distinction de : genre, ethnicité, religion, orientation sexuelle, handicap, âge ou toute autre caractéristique protégée par la loi.\nShow more\nShow less",
        "details": {
            "JobDetail": [],
            "TypeContract": "CDI",
            "Salary": "",
            "Level": "",
            "Experience": "3 an(s)"
        },
        "title": "machine learning engineer",
        "skills": {
            "ProgLanguage": [
                "Python"
            ],
            "DataBase": [
                "SQL"
            ],
            "BigData": [
                "Databricks",
                "Spark"
            ],
            "MachineLearning": [
                "PyTorch",
                "TensorFlow"
            ],
            "CloudComputing": [
                "AWS"
            ],
            "Automation": [
                "Airflow"
            ],
            "Other": [
                "Machine Learning"
            ],
            "EnSoftSkils": [
                "Collaboration"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "Doctolib",
        "location": "Paris, Île-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/senior-data-scientist-deep-learning-x-f-m-ai-teams-at-doctolib-3778200205?position=21&pageNum=0&refId=EGCcUYgUshGnwQGGB%2BWgjg%3D%3D&trackingId=scc4mYT%2BeM%2F%2BUwLPDdTiFg%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "What You’ll Do\nAt Doctolib, we're on a mission to transform the way healthcare is delivered by leveraging the power of AI. As a Data Scientist, you'll play a critical role in developing and implementing cutting-edge AI solutions that will enable us to create an AI medical assistant that will support the Healthcare Professionals in their day to day job.\nIn this role, you'll have the opportunity to work with a team of talented data scientists, software engineers, machine learning engineers and healthcare professionals to develop and deploy AI models that will have a real impact on people's lives.\nDoctolib is looking for a Senior Data Scientist to join our dedicated feature team in charge of shaping the new consultation experience powered by a medical assistant.\nLet’s make a direct impact of your work with easy access to final users (practitioners) or subject matter experts to empower our Clinical Product with AI.\nYour responsibilities include but are not limited to:\nCreate, find or adapt model architecture, annotation or validation strategies to improve our speech recognition, summarization and medical data structuration engines\nImplement your ideas and test them\nDeploy your algorithms in production guided by our ML platform team\nMeasure the uplift and continuously improve your approach\nWho You Are\nIf you don’t meet all the requirements below but believe this opportunity matches your expectations and experience, we still encourage you to apply!\nYou could be our next team mate if you:\nHave analytical skills, are result oriented and user first\nHave 3 years of experience in the domain or shorter but with significant contribution (papers, open source)\nAre proficient in Deep Learning framework: Pytorch or Tensorflow\nHave knowledge of the latest NLP architecture (Transformer, LLM) and methods (fine tuning, distillation…)\nNow, it would be fantastic if you:\nHave already launched large scale model training\nHave experience in collaborating with end users to refine your modeling approach\nWhat We Offer\nEmployee share plan for every Doctoliber (BSPCE)\nFree Health Insurance for you & your family\nQuarterly or monthly bonus (based on your position)\nUp to 14 days of RTT\nTransparent internal mobility opportunities you're welcome to apply for\nParental care program (1 month off in addition to the legal parental leave and 0,5 days off per child when the school starts)\nSolidarity Days (2 days per year to help health charities and create a positive social impact)\nWellbeing program (free mental health and coaching offer with our partner moka.care)\nA flexible workplace policy offering both hybrid and office-based mode\nFlexibility days allowing to work in EU countries and the UK 10 days per year\nLunch voucher with Swile card\nWork Council subsidy to refund part of sport club membership or creative class\nBicycle subsidy\nReimbursement of public transportation\nRelocation support for international mobilities\nSlean voucher for home-office furniture\nThe interview process\nHR Screen\nInterview with 2 members of the Data Science team\nCase Study & Case restitution\nFinal interview with the DS Director\nAt least one reference check\nCriminal background check\nJob details\nPermanent position\nFull Time\nWorkplace : Paris area\nStart date: asap\nRemuneration : fix + bonus on objectives (according to your profile)\nAt Doctolib, we believe in improving access to healthcare for everyone - regardless of where you come from, what you look like. This translates into our recruitment process: Doctolib is an equal opportunity employer. We don't just accept diversity at Doctolib, we respect and celebrate it!\nThe more diverse ideas are heard, the more our product will truly improve healthcare for all. You are welcome to apply to Doctolib, regardless of your gender, religion, age, sexual orientation, ethnicity, disability, or place of origin. If you have a disability, let us know if there's any way we can make the interview process smoother for you!\nAll the information transmitted via this form is processed by Doctolib for the purpose of managing applications. For more information on how Doctolib processes your application data, click\nhere\n.\nIf you wish to exercise your rights or if you have any questions about the processing of your data, you can write to us at\nhr.dataprivacy(at)doctolib.com\n.\nShow more\nShow less",
        "details": {
            "JobDetail": [
                "Full",
                "Senior"
            ],
            "TypeContract": "",
            "Salary": "",
            "Level": "",
            "Experience": null
        },
        "title": "data scientist",
        "skills": {
            "MachineLearning": [
                "PyTorch",
                "TensorFlow"
            ],
            "Other": [
                "Machine Learning",
                "ML"
            ],
            "EnSoftSkils": [
                "Flexibility"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "Manpower",
        "location": "Saint-Étienne",
        "link": "https://fr.linkedin.com/jobs/view/data-scientist-h-f-at-manpower-3909184596?position=22&pageNum=0&refId=EGCcUYgUshGnwQGGB%2BWgjg%3D%3D&trackingId=tDjvqXV9XJ%2FK4RBewZZGUQ%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Vous le saviez ?\n​Le métier de DATA SCIENTIST H/F a été élu le « métier le plus sexy du XXIe siècle », par le Harvard Business Review !\n​\nRejoignez donc une équipe passionnée et dynamique au sein d'une entreprise incontestée des systèmes automatisés et d'énergie, qui repousse constamment les limites de la technologie et en pleine croissance !\nLes missions\nEn tant que Data Scientist H/F, vous êtes sensibilisés aux risques éventuels et vous pouvez envisager de mettre en place des mesures adéquates pour sécuriser les données et les systèmes contre les menaces.\nVos missions seront donc :\nRassemblement, purification et manipulation d'ensembles de données massifs provenant de diverses sources telles que des bases de données internes et externes, des API et des données non structurées.\nConception et implémentation de modèles prédictifs et d'algorithmes d'apprentissage automatique pour résoudre des défis commerciaux complexes.\nRéalisation d'analyses statistiques approfondies afin d'identifier des tendances, des schémas et des insights significatifs.\nCollaboration étroite avec les équipes interfonctionnelles pour comprendre leurs besoins en données et proposer des solutions analytiques.\nCréation de tableaux de bord interactifs, de visualisations de données et de rapports pour une communication efficace des résultats d'analyse aux parties prenantes.\nVeille constante sur les avancées technologiques en science des données et proposition d'améliorations continues pour les processus et méthodologies existants.\nLe profil\nEt si on parlait de vous...\n​Vous disposez de qualifications dans les domaines des sciences des données, de l'informatique, des mathématiques, des statistiques, de l'économie, de l'informatique, de la gestion, de l'ingénierie industrielle ou dans des domaines connexes.\nVous avez une expérience pertinente dans ce domaine.\nVous êtes familier avec les concepts de collecte, d'extraction et d'analyse de données.\nVous possédez des compétences analytiques et êtes capable de travailler en équipe.\nVous êtes capable de présenter des informations complexes de manière claire et compréhensible.\nVous maitrisez les langages de programmation courants tels que Python, R ou SQL ainsi que l'anglais professionnel.\nVous possédez des compétences avancées en analyse statistique et en modélisation prédictive.\nVous êtes doté d'une expérience pratique avec les bibliothèques et les frameworks d'apprentissage automatique tels que TensorFlow, Scikit-Learn ou PyTorch.\nConditions & avantages :\nCDI Temps plein\nDéplacements à prévoir en France et à l'international (EMEA Germany, Italy, Spain, UK) selon besoin de l'activité\nSalaire ouvert fonction de vos prétentions salariales, adaptable au profil !\nStatut cadre forfait jour\nRTT\nTickets restaurant\nParticipation et intéressement\nVous vous reconnaissez ?\nN'hésitez plus, postulez !!\nShow more\nShow less",
        "details": {
            "JobDetail": [
                "Temps plein"
            ],
            "TypeContract": "CDI",
            "Salary": "Salaire",
            "Level": "",
            "Experience": null
        },
        "title": "data scientist",
        "skills": {
            "ProgLanguage": [
                "R",
                "Python"
            ],
            "DataBase": [
                "SQL"
            ],
            "DataAnalytics": [
                "R"
            ],
            "MachineLearning": [
                "Scikit-Learn",
                "TensorFlow",
                "PyTorch"
            ],
            "Other": [
                "Statistiques"
            ],
            "EnSoftSkils": [
                "Communication",
                "Collaboration"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "Harmonie Mutuelle",
        "location": "Rennes, Brittany, France",
        "link": "https://fr.linkedin.com/jobs/view/data-scientist-h-f-at-harmonie-mutuelle-3903667706?position=23&pageNum=0&refId=EGCcUYgUshGnwQGGB%2BWgjg%3D%3D&trackingId=ybUIyKMl%2FSxeIDx9l%2BRdgg%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Vous êtes en quête d'une nouvelle aventure professionnelle collective et porteuse de sens ?\nVous voulez un parcours qui vous ressemble ? Vous avez envie d'évoluer dans un\nenvironnement de travail épanouissant fondé sur la confiance, la diversité et l'égalité des\nchances ?\nVous êtes au bon endroit ! Ensemble, nous pouvons faire la différence.\nLe poste :\nNous opérons notre transformation digitale et renforçons le besoin de pilotage de nos flux et activités au sein de la Direction des Services et de la Satisfaction Clients. Dans ce cadre, nous recherchons un(e) Data Scientist pour renforcer l'équipe Pilotage et Analyse Data Science. Parmi nos sujets : analyser les activités des centres de gestion, mesurer l'efficacité des actions de digitalisation, robotisation et dématérialisation, analyser et détecter les fraudes à la mutuelle, modéliser des dimensionnements de flux et d'équipes...\nVos missions principales :\nVous participez au développement de cette équipe avec pour mission principale la production opérationnelle d'algorithmes data science de détection de fraude :\n- Exécuter des algorithmes existants, monitorer, valider les productions\n- Maintenir ces modèles mathématiques. Suivre leurs performances réelles\n- Collecter l'ensemble des informations (hypothèses, roadmap, projet, nouvelles données) nécessaires à l'amélioration continue des modèles et au développement de nouveaux\n- Explorer et croiser les données, à des fins d'investigation et de détection unitaires de cas de fraudes\n- Interpréter les données collectées, structurer et partager les résultats\nEn complément de cette activité, vous interviendrez sur les missions suivantes :\n- Participer aux analyses de performances et de pilotage de cette activité globale de gestion de la fraude\n- Intervenir sur des projets transverses au sein de l'équipe et d'Harmonie Mutuelle (datalab, analyse d'impact...)\nLe profil recherché :\nIssu(e) d'une formation Bac +5 avec une spécialisation en Statistiques / Econométrie / Analyse de données, vous avez au moins 2 ans d'expérience en data science. Vous maitrisez les techniques de data mining, machine learning, modélisations supervisées ou non et le pragmatisme.\nVous êtes à l'aise sous SAS, SQL, et Python.\nVous savez et aimez développer. Vous avez une appétence et expérience sur les sujets d'investigation de fautes/fraudes à impact directs sur notre société.\nVous êtes curieux(se), rigoureux(se) et doté(e) d'un bon esprit d'analyse et de synthèse. Vous êtes force de proposition, autonome, dynamique, innovant, créatif.\nVous aimez le travail en équipe.\nUne connaissance des métiers de la mutuelle serait un plus.\nInfos complémentaires :\n- 22, 5 jours de RTT par an\n- Des horaires flexibles pour la majorité des postes\n- Jusqu'à 3 jours de télétravail par semaine (à partir de 6 mois d'ancienneté)\n- Carte déjeuner et CSE (enveloppes loisirs, culture, avantages vacances...)\n- Compte Epargne Temps\n- Forfait mobilité durable : jusqu'à 300 € par an (cumulable avec le remboursement de l'abonnement aux transports en commun, dans la limite de 500 Euros au total)\n- Contrat collectif santé et prévoyance\n- PEE et Retraite\n- Prime d'intéressement\nShow more\nShow less",
        "details": {
            "JobDetail": [],
            "TypeContract": "",
            "Salary": "",
            "Level": "",
            "Experience": "2 an(s)"
        },
        "title": "data scientist",
        "skills": {
            "ProgLanguage": [
                "Python"
            ],
            "DataBase": [
                "SQL"
            ],
            "Other": [
                "Statistiques",
                "Machine Learning"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "Withings",
        "location": "Paris, Île-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/data-scientist-at-withings-3888804341?position=24&pageNum=0&refId=EGCcUYgUshGnwQGGB%2BWgjg%3D%3D&trackingId=3YkA1XkINgfX2cdtUbg6sQ%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Vos missions\nL'équipe Machine Learning est responsable du développement de tous les algorithmes de prédiction des produits Withings. Intégré.e en son sein, tu auras les responsabilités suivantes:\nRecherche algorithmique pour analyser les données pertinentes et les partager avec l’équipe\nRéalisation de prototypes par la mise en pratique des méthodes retenues\nImplémentation de services sur la plateforme / produits Withings, en tenant compte des contraintes de ressources et de temps d’exécution\nMise en avant de nouvelles fonctionnalités pour les applications et produits Withings\nMaintien du lien avec les équipes de Recherche Appliquée et de Développement Produit pour comprendre et exploiter les données recueillies\nREQUIREMENTS\nFormation Bac+5 type grande école d’ingénieur ou équivalent\nUn\ndoctorat\ndans un domaine connexe est très apprécié\nUne première expérience réussie dans le domaine du Machine Learning, de l'algorithmie appliqué aux données de santé ou à l'embarqué est fortement appréciée\nFortes compétences informatiques : calculs scientifiques, Python...\nRigueur, autonomie, prise d'initiatives, curiosité...\nConnaissances en traitement de signal, C/C++ appréciées\nMaîtrise parfaite de la communication en français et en anglais, aussi bien à l’écrit qu’à l’oral\nRejoindre l’aventure Withings, c’est :\nIntégrer un des pionniers et leaders mondiaux de la santé connectée, plusieurs fois primé au Consumer Electronic Show\nContribuer à des projets innovants et ambitieux pour la santé de demain dans un environnement agile et en constante évolution\nIntégrer une entreprise internationale, membre de la FrenchTech 120, dont les équipes sont basées à Issy-les-Moulineaux, Boston, Hong-Kong et Shenzhen\nParticiper à l’amélioration continue de nos produits et services en les bêta-testant avant leur sortie, notamment lors de nos nombreuses sessions sportives entre collègues\nBénéficier de nombreux avantages : Stock Options, smartphone et ordinateur de votre choix, réductions pour des activités culturelles et sportives, restaurant d’entreprise, et bien plus encore\nParticiper à la Withings Med Academy en assistant à des conférences de professionnels de santé afin de renforcer ses connaissances dans le domaine médical\nCollaborer avec des collègues passionnés et célébrer ensemble chacune de nos réussites !\nToutes les candidatures reçues sont étudiées indépendamment de l’origine ethnique, des croyances, de la religion, du genre, de l’orientation sexuelle ou de la santé des candidats. Withings aspire à offrir et garantir l’égalité des chances aux candidats et seules les personnes habilitées (RH et Management) auront accès aux informations concernant votre candidature.\nShow more\nShow less",
        "details": {
            "JobDetail": [],
            "TypeContract": "",
            "Salary": "",
            "Level": "Bac+5",
            "Experience": null
        },
        "title": "data scientist",
        "skills": {
            "ProgLanguage": [
                "Python"
            ],
            "Other": [
                "Machine Learning"
            ],
            "EnSoftSkils": [
                "Communication"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "Akademija Oxford",
        "location": "Val-d'Oise, Île-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/apprenti-e-data-scientist-at-akademija-oxford-3917868440?position=25&pageNum=0&refId=EGCcUYgUshGnwQGGB%2BWgjg%3D%3D&trackingId=w%2BFbe%2BY6pBjPKB97PgOBQg%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Un acteur majeur et en pleine croissance de la Biologie Médicale en Ile de France, recrute un.e Apprenti.e Data Scientist en alternance. Ce contrat d’apprentissage d’une durée de 12 mois débute en Octobre 2021.\nShow more\nShow less",
        "details": {
            "JobDetail": [],
            "TypeContract": "",
            "Salary": "",
            "Level": "",
            "Experience": null
        },
        "title": "data scientist",
        "skills": {}
    },
    {
        "source": "LinkedIn",
        "company": "Lincoln France",
        "location": "Île-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/data-scientist-h-f-at-lincoln-france-3892490370?position=26&pageNum=0&refId=EGCcUYgUshGnwQGGB%2BWgjg%3D%3D&trackingId=lb5IaStMsmncOHPm55zGcw%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "CDI\n📊\n4 ans minimum\nChez Lincoln\n, nous formons une communauté d'innovateurs passionnés qui redéfinissent l'analyse de données depuis\nplus de 30 ans\n. En tant que\nPure Player Data\n, notre expertise est reconnue dans les domaines\nde la Modern BI, du Big Data et de la Science des données\n.\nNotre mission ?\nTransformer les données en solutions concrètes pour nos clients grands comptes dans divers secteurs tels que la banque, le retail, les télécoms, l'industrie, la santé, etc.\nDescription du poste\nNous recherchons un\nData Scientist H/F\npour accompagner nos clients dans leurs projets stratégiques.\nVos missions\nCollecter, nettoyer et préparer les données pour l'analyse.\nConcevoir, développer et mettre en œuvre des modèles prédictifs et analytiques en utilisant des techniques avancées d'apprentissage automatique et de science des données.\nAnalyser les résultats des modèles et fournir des insights exploitables aux équipes clients.\nCollaborer avec les équipes interfonctionnelles pour comprendre les besoins commerciaux et recommander des solutions basées sur les données.\nPrérequis :\nSolides compétences en programmation (\nPython, R, SQL, etc.)\net en manipulation de données.\nExpérience pratique avec des frameworks et des bibliothèques d'apprentissage automatique (\nTensorFlow, PyTorch, Scikit-learn\n,\netc\n.).\nMaîtrise des techniques avancées d'analyse de données, y compris l'apprentissage automatique, l'apprentissage profond, la vision par ordinateur, le traitement du langage naturel, etc.\nExpérience de travail en\nméthode Agile\npour la gestion de projet et le développement de solutions.\nCapacité à travailler de manière autonome et en équipe.\nExcellentes compétences en communication et en présentation.\nLes plus du poste\nEnvironnement Collaboratif\n: projets innovants favorisant le partage des connaissances.\nAccompagnement individualisé et de proximité\n: formations certifiantes, attribution d’un Career Manager pour vous orienter dans votre trajectoire professionnelle, opportunités d’évolution de carrière.\nFlexibilité du Travail\n: Télétravail et horaires flexibles pour votre équilibre vie professionnelle-personnelle.\nRémunération Compétitive\n: Salaire compétitif avec des avantages sociaux attrayants.\nMobilité\n: Possibilité de mobilité à Lille, Lyon ou Aix-en-Provence offrant des expériences diversifiées au sein de Lincoln.\nNotre processus de recrutement :\nUn entretien RH (1h) et entretien technique (1h)\nCette annonce n’est pas faite pour vous si :\nVous êtes freelance et vous comptez le rester !\nToujours là ? Postulez et rejoignez nos\n400 experts en Data\n😉.\nShow more\nShow less",
        "details": {
            "JobDetail": [],
            "TypeContract": "CDI",
            "Salary": "400",
            "Level": "",
            "Experience": "4 an(s)"
        },
        "title": "data scientist",
        "skills": {
            "ProgLanguage": [
                "R",
                "Python"
            ],
            "DataBase": [
                "SQL"
            ],
            "DataAnalytics": [
                "R"
            ],
            "MachineLearning": [
                "Scikit-Learn",
                "TensorFlow",
                "PyTorch"
            ],
            "Other": [
                "Big Data"
            ],
            "EnSoftSkils": [
                "Communication"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "MERITIS",
        "location": "Île-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/data-scientist-h-f-at-meritis-3869246366?position=27&pageNum=0&refId=EGCcUYgUshGnwQGGB%2BWgjg%3D%3D&trackingId=d8lTOx6mLHUmX0a4d6rR7A%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Nous recherchons un\nData Scientist\npour intervenir dans le cadre d'un\nprojet de détection de document.\nVos missions :\nSujet de\nfraude documentaire:\nla problématique est de détecter si un document (RIB ou pièce d’identité) a été manipulé (montage, remplacement de la photo d’identité, changement du nom/prénom, ou de l’IBAN etc).\nLes technos connues utilisées:\nPython avec les libs/framework suivants : pytorch, jupyterlab, pandas\nModèles : layoutLM (techno à priori assez récente), yolo, resnet (classique), docTR (ocr)\nConnaitre les transformers\nAutre : Labelstudio\nCe poste est-il fait pour vous\n? :\nVous êtes diplômé d'un\nBac +5\net justifiez d'\nau moins 4 ans d'expérience\nVous êtes\nproactif et autonome ​\nVous aimez travailler\nau contact de plusieurs équipes métiers\nConnaissance du secteur de l'assurance obligatoire\nDescriptif de l’entreprise :\n​\nMeritis est un cabinet de conseil, pilotage et développement IT fondé en 2007 présent à Paris, Sophia-Antipolis, Aix-en-Provence, Montpellier, Toulouse, Nantes... Et bientôt sur de nouveaux territoires ! Notre mission ? Connecter les meilleurs talents aux entreprises pour leur donner un temps d’avance.​\nNous accompagnons nos clients dans l’intégralité de leurs besoins en transformation numérique à travers de nombreux domaines d’expertises : Software Engineering, Finance, Pilotage de projets, Devops, Data, Cloud, Cybersécurité ou encore Agilité.​\nIntervenant aussi bien dans les secteurs de la Banque, de l'Assurance, des Télécommunications que de l'Industrie ou des Transports, aujourd'hui 40% des entreprises du CAC40 sont clientes Meritis.​\nFort de nos valeurs d’exigence, d’humilité, de bienveillance et de proximité, nous comptons aujourd’hui plus de 900 collaborateurs.​\nNous mettons un point d’honneur à être proche de nos collaborateurs et à les accompagner de manière individualisée quelles que soient leurs fonctions dans l’entreprise.\nCertifiée Great Place To Work depuis 2013, notre conception du bien-être au travail va bien au-delà d'un simple label, ce sont nos collaborateurs qui en parlent le mieux : https://www.glassdoor.fr/Avis/Meritis-Avis-E1163008.htm.​\nVos différences sont nos atouts. C’est pourquoi Meritis est engagée en faveur de la diversité et de la non-discrimination. Tous nos métiers sont accessibles aux personnes en situation de handicap. Si vous avez une question ou pensez être victime ou témoin d’une discrimination, vous pouvez contacter ethiquegroup@meritis.fr. »\nShow more\nShow less",
        "details": {
            "JobDetail": [],
            "TypeContract": "",
            "Salary": "",
            "Level": "",
            "Experience": "4 an(s)"
        },
        "title": "data scientist",
        "skills": {
            "ProgLanguage": [
                "Python"
            ],
            "DataAnalytics": [
                "Pandas"
            ],
            "MachineLearning": [
                "PyTorch"
            ],
            "Other": [
                "Cloud",
                "DevOps"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "SoftwareOne",
        "location": "Levallois-Perret, Île-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/data-scientist-flexible-working-at-softwareone-3872563771?position=28&pageNum=0&refId=EGCcUYgUshGnwQGGB%2BWgjg%3D%3D&trackingId=yznFN8w%2FrSMaXZdjwzCkOg%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Why SoftwareOne?\nSoftwareOne is a leading global software and cloud solutions provider that is redefining how companies build, buy and manage everything in the cloud. By helping clients to migrate and modernize their workloads and applications – and in parallel, to navigate and optimize the resulting software and cloud changes – SoftwareOne unlocks the value of technology. The company’s 8,900 employees are driven to deliver a portfolio of 7,500 software brands with sales and delivery capabilities in 90 countries. Headquartered in Switzerland, SoftwareOne is listed on the SIX Swiss Exchange under the ticker symbol SWON. Visit us at https://www.softwareone.com/en\nThe role\nDATA Scientist\nThe primary focus for a candidate will be in applying different techniques (data mining/statistical analysis/build prediction systems/recommendation systems) using large company data sets to find opportunities for services and products and using models to test the effectiveness of different courses of action. The Candidate must have strong experience using a variety of data mining/data analysis methods, using a variety of data tools, building and implementing models, using/creating algorithms and creating/running simulations.\nWork with business cases to identify opportunities for leveraging company data to drive business solutions.\nMine and analyze data from company databases to drive optimization and improvement of product development and sales techniques\nAssess the effectiveness and accuracy of new data sources and data gathering\nExtending company’s data with third party sources of information when needed\nUse predictive modeling to increase revenue generation, ad targeting and other business outcomes.\nWhat We Need To See From You\nCore:\nAnalyze business cases and identify data sources (internal/external) and data mining/analysis methods to use\nDevelop a normalization engine to execute cleansing/deduplication for a raw data through ETL process for data sources\nCreate, train and test predictive models to solve defined business cases\nDevelop algorithms to apply to data sets\nDesign data structure models for collected data\nFacilitate the build of a solution from PoC to production\nWork with business owners to gather additional information about business cases\nJob Specific:\nWork with Google Cloud data and AI tools\nBe ready to work in agile style (daily, sprint planning, sprint review, retrospective)\nWork in an environment that adapts quickly to creative change using agile principles\nActively work with different development groups inside of organization\nBe ready to adapt a new tool/library/technology/platform\nDesirable Skills:\nFluent in French and English\nAt least 4 years experience in Machine learning models creation\nMaster’s in Statistics, Mathematics, Computer Science preferred\nProfessional Machine learning engineering certification\nExperience with common data science toolkits and libraries, such as pandas, keras, scipy, scikit, tensorflow, NumPy etc\nKnowledge and interest in the following:\nprediction models, Vertex AI, Tenserflow, BigQuery ML, Python,\nnatural language processing, deep learning models, dataPROC, Hadoop, SQL\nExperience using statistical computer languages namely Python to manipulate data and draw insights from large data sets\nStrong knowledge and experience using SQL language\nExperience with C++/C# and Java as a plus\nBackground in technology or professional services preferably in one or more of the domains of GCP and Security,\nStrong understanding of consulting business\nStrong structural work methods, multitasking and time management skills\nSelf-driven independent work ethics that drives internal and external accountability\nMay require periodic travel for workshops\nJob Function\nSoftware & Cloud Services\nShow more\nShow less",
        "details": {
            "JobDetail": [],
            "TypeContract": "",
            "Salary": "",
            "Level": "",
            "Experience": null
        },
        "title": "data scientist",
        "skills": {
            "ProgLanguage": [
                "Java",
                "Python"
            ],
            "DataBase": [
                "SQL"
            ],
            "DataAnalytics": [
                "NumPy",
                "Pandas"
            ],
            "BigData": [
                "Hadoop"
            ],
            "MachineLearning": [
                "TensorFlow",
                "Keras"
            ],
            "CloudComputing": [
                "GCP"
            ],
            "DBMS": [
                "BigQuery"
            ],
            "Other": [
                "Machine Learning",
                "Cloud",
                "ML"
            ],
            "EnSoftSkils": [
                "Time Management",
                "Organization"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "Capital Fund Management (CFM)",
        "location": "Paris, Île-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/data-scientist-at-capital-fund-management-cfm-3911800992?position=29&pageNum=0&refId=EGCcUYgUshGnwQGGB%2BWgjg%3D%3D&trackingId=0kAZtI7%2Fd%2Fwy4lWWwJROOg%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "ABOUT CFM\nFounded in 1991, we are a global quantitative and systematic asset management firm applying a scientific approach to finance to develop alternative investment strategies that create value for our clients.\nWe value innovation, dedication, collaboration and the ability to make an impact and together we create an environment for talented and passionate experts in research, technology and business to explore new ideas and challenge assumptions.\nABOUT THE ROLE\nThe context :\nData is the fuel that powers our investment strategies: intraday price dynamics are used to better our investment decisions; buy/sell intents of market participants help to trade at the best available price… Cfm Data team is in charge of preparing the data to make quant research easier and trading more reliable.\nThe position\nAs a Data Scientist and Tick Data Specialist, your involvement will be crucial to the effectiveness of our strategies. You will be tasked with identifying and specifying new input features from tick data to fuel our alpha predictor, constructing data pipelines, and guaranteeing their smooth functioning. This role necessitates strong collaboration with researchers, primarily aimed at furnishing them with essential data and tools to refine our trading strategies.\nKey Responsibilities:\nYou collaborate with the research team to innovate and introduce new predictive features,\nYou provide functional and technical support to quantitative researchers,\nYou design and develop data pipelines,\nYou contribute to the enhancement of our platform tooling.\nSKILLSET REQUIREMENTS/QUALIFICATIONS\nYou boast significant experience in financial markets, with a tenure of 7 years or more.\nYou have a comprehensive expertise in Matching Engines, Orderbooks, and High-Frequency Data,\nYou demonstrate recognized expertise in data science with a thorough mastery of its tools.\nYour familiarity with big data technologies like Spark or Dask, coupled with proficiency in machine learning, would be highly advantageous.\nExperience with C++ is considered an additional asset.\nYou exhibit a strong enthusiasm for technology.\nAs a collaborative team player, you excel in communication, particularly with quant teams.\nProficiency in French is an additional advantage.\nEQUAL OPPORTUNITIES STATEMENT\nWe are continuously striving to be an equal opportunity employer and we prohibit any discrimination based on sex, disability, origin, sexual orientation, gender identity, age, race, or religion. We believe that our diversity, breadth of experience, and multiple points of view are among the leading factors in our success.\nCFM is a signatory of the Women Empowerment Principles\nFOLLOW US\nFollow us on Twitter and LinkedIn or visit our website to find out more about CFM.\nShow more\nShow less",
        "details": {
            "JobDetail": [],
            "TypeContract": "",
            "Salary": "",
            "Level": "",
            "Experience": null
        },
        "title": "data scientist",
        "skills": {
            "BigData": [
                "Spark"
            ],
            "Collaboration": [
                "Teams"
            ],
            "Other": [
                "Machine Learning",
                "Big Data"
            ],
            "EnSoftSkils": [
                "Communication",
                "Collaboration"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "METEOJOB by CleverConnect",
        "location": "Rontignon, Nouvelle-Aquitaine, France",
        "link": "https://fr.linkedin.com/jobs/view/data-scientist-f-h-at-meteojob-by-cleverconnect-3916294538?position=30&pageNum=0&refId=EGCcUYgUshGnwQGGB%2BWgjg%3D%3D&trackingId=yKbrAtaAN4yOVp8j1m8ELA%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Entreprise\nCabinet de recrutement de dimension internationale, bénéficiant de l'expérience d'un grand Groupe RH, S&you est spécialisé dans le recrutement d'Experts, Cadres et Métiers du tertiaire. Nos 50 consultants expérimentés mettent en œuvre tout notre savoir-faire pour vous accompagner au mieux dans vos projets (recrutement, bilan professionnel, coaching, formation…). La relation de confiance que nous créons avec nos candidats et nos clients représente pour nous le facteur-clé de la performance.\nDescription Du Poste\nVotre profil Vous disposez des compétences et aptitudes nécessaires à l'appropriation du périmètre du poste :\nFormation supérieure Bac + 5 (statistiques, mathématiques appliquées …)\nExpérience significative (2 ans alternance incluse) en qualité de data scientist / data analyst incluant idéalement une expérience en secteur assurantiel.\nMaîtrise / connaissance de l'environnement technique : Python, SQL, R, algorithmes et frameworks, machine learning, RPA, datavisualisation (Power BI, Tableau)\nCuriosité, discernement, agilité et esprit d'initiative : appropriation de données complexes, compréhension de problématiques transverses, veille technologique, proposition de solutions\nDescription Du Profil\nNotre client est un acteur clé du secteur assurantiel dont les 250 collaborateurs accompagnent les compagnies et intermédiaires d'assurance sur l'ensemble des sujets intéressant la profession (information, concertation, mise en œuvre) : assurance de biens et responsabilités, assurance de personne, réassurance, co-assurance, évolutions réglementaires et conventionnelles, maîtrise des risques, médiation, intermédiation, référentiels …Notre client recrute un.e Data Scientist dans le cadre d'une création de poste (CDI) en vue d'accompagner le développement de sa stratégie Data.\nShow more\nShow less",
        "details": {
            "JobDetail": [],
            "TypeContract": "CDI",
            "Salary": "",
            "Level": "",
            "Experience": "2 an(s)"
        },
        "title": "data scientist",
        "skills": {
            "ProgLanguage": [
                "R",
                "Python"
            ],
            "DataBase": [
                "SQL"
            ],
            "DataAnalytics": [
                "R"
            ],
            "DataVisualisation": [
                "Power BI",
                "Tableau"
            ],
            "Other": [
                "Statistiques",
                "Machine Learning"
            ],
            "EnSoftSkils": [
                "Initiative"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "HackerPulse",
        "location": "France",
        "link": "https://fr.linkedin.com/jobs/view/machine-learning-engineer-at-hackerpulse-3917868826?position=32&pageNum=0&refId=EGCcUYgUshGnwQGGB%2BWgjg%3D%3D&trackingId=dWrca%2F%2BwO%2B%2FVqKQBY0Zm1A%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Showcase your software engineering talents using ML-powered profiles. Loved by 11k+ engineers! Backed by Antler.\nThe Role\nYou Will Be Responsible For\nDeveloping scripts to process structured and unstructured data.\nRecommending, developing and implementing ways to improve data reliability, efficiency and quality.\nSupporting translation of data business needs into technical system requirements.\nWorking with stakeholders to understand needs in order with respect to data structure, availability, scalability and accessibility.\nDeveloping high-quality code to build and deploy machine learning models.\nIdeal Profile\nYou possess a degree in Computer Science, Applied Mathematics, Engineering or related field.\nYou have at least 1 year experience, ideally within a Data Engineer role.\nDemonstrated experience working with large and complex data sets as well as experience analyzing volumes of data.\nYou are a strong networker & relationship builder\nYou pay strong attention to detail and deliver work that is of a high standard\nYou are a self-starter and demonstrate a high level of resilience\nWhat's on Offer?\nGreat work environment\nExcellent career development opportunities\nLeadership Role\nShow more\nShow less",
        "details": {
            "JobDetail": [],
            "TypeContract": "",
            "Salary": "",
            "Level": "",
            "Experience": null
        },
        "title": "machine learning engineer",
        "skills": {
            "Other": [
                "Machine Learning",
                "ML"
            ],
            "EnSoftSkils": [
                "Leadership"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "MP DATA",
        "location": "Clermont-Ferrand, Auvergne-Rhône-Alpes, France",
        "link": "https://fr.linkedin.com/jobs/view/data-scientist-h-f-at-mp-data-3904074177?position=33&pageNum=0&refId=EGCcUYgUshGnwQGGB%2BWgjg%3D%3D&trackingId=BeR7584K1zkFfnapkD4q4Q%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "MP DATA est une société spécialisée dans l’acquisition, le traitement, et la valorisation des données. Depuis sa création en 2015, MP DATA accompagne ses clients, majoritairement industriels, dans le management de leur performance et l’exploitation de leur donnée.\nLes collaborateurs, tous issus de grandes écoles, incarnent au quotidien les valeurs d’Excellence, de Partage et d’Engagement. Ils associent savoir-faire technique, méthodologie et passion et mettent leurs compétences au service de missions et projets au sein de grands groupes français.\nMP DATA accompagne ses clients sur toute la chaine au travers de 3 pôles d’expertise : Conseil et Stratégie, Infrastructure & CloudOPS, Data Science.\nNous recherchons un(e) Data Scientist passionné(e) pour rejoindre notre équipe dynamique.\nEn tant que membre clé du pôle Data Science de notre client, un grand acteur du secteur automobile, vous serez chargé(e) d'analyser, interpréter et exploiter les données pour fournir des solutions innovantes à nos clients.\nConception et mise en œuvre de modèles prédictifs et d'algorithmes avancés.\nAnalyse approfondie des données pour identifier des tendances et des opportunités.\nCollaboration étroite avec les équipes clients pour comprendre leurs besoins et définir des solutions sur mesure.\nParticipation active à la veille technologique et à l'amélioration continue de nos pratiques en Data Science.\nProfil :\nDiplôme\ningénieur Grande École\nen Data Science, Statistiques, Informatique ou domaine connexe.\nExpérience pratique dans le développement et l'application de modèles prédictifs,\nMaîtrise des langages de programmation tels que Python,\nExcellentes compétences analytiques et capacité à traduire des résultats complexes en recommandations claires,\nForte aptitude à travailler en équipe et à communiquer efficacement.\nShow more\nShow less",
        "details": {
            "JobDetail": [],
            "TypeContract": "",
            "Salary": "",
            "Level": "",
            "Experience": null
        },
        "title": "data scientist",
        "skills": {
            "ProgLanguage": [
                "Python"
            ],
            "Other": [
                "Statistiques"
            ],
            "EnSoftSkils": [
                "Collaboration"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "Pathway",
        "location": "Paris, Île-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/data-scientist-python-mid-senior-senior-at-pathway-3887683294?position=34&pageNum=0&refId=EGCcUYgUshGnwQGGB%2BWgjg%3D%3D&trackingId=1IFamQDNOslLqGqnZhfbtg%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "About Pathway\nDeeptech start-up, founded in March 2020.\nOur primary developer offering is an ultra-performant Data Processing Framework (unified streaming + batch) with a Python API, distributed Rust engine, and capabilities for data source integration & transformation at scale (Kafka, S3, databases/CDC,...)\nThe single-machine version is provided on a free-to-use license (`pip install pathway`)\nMajor data use cases are around event-stream data (including real-world data such as IoT), and graph data that changes over time\nOur enterprise offering is currently used by leaders of the logistics industry, such as DB Schenker or La Poste, and tested across multiple industries. Pathway has been featured in Gartner's market guide for Event Stream Processing\nLearn more at http://pathway.com/ and https://github.com/pathwaycom/\nPathway is VC-funded, with amazing BAs from the AI space and industry. We have operations across Europe and in the US. We are headquartered in Paris, with significant support from the French ecosystem (BPI, Agoranov, WILCO,...).\nThe Team\nPathway is built by and for overachievers. Its co-founders and employees have worked in the best AI labs in the world (Microsoft Research, Google Brain, ETH Zurich), worked at Google, and graduated from top universities (Polytechnique, ENSAE, Sciences Po, HEC Paris, PhD obtained at the age of 20, etc...). Pathway's CTO is a co-author with Goeff Hinton and Yoshua Bengio. The management team also includes the co-founder of Spoj.com (1M+ developer users) and NK.pl (13.5M+ users) and experienced growth leader who has scaled companies with multiple exits.\nThe opportunity\nWe are currently searching for\nData Scientists\nwith\nexperience in the Python stack\n, to help explore and discover the most pertinent insights in datasets on spatio-temporal event streams. In this job, statistical rigor and beauty of visualization meet on equal footing.\nYou Will\nbe working with spatiotemporal data with advanced schemas (time-changing graph models)/\nbe designing data cross-sections, proposing analytics metrics and KPI's in line with clients' objectives, selecting clustering algorithms, and preparing visualizations, to enable fast data exploration and insight discovery - all within our product\nbe designing dashboards in SQL with some Python elements/extensions\nbe directly helping us with Customer Conversion and Adoption within Customer organizations, by contributing to both deployment instances and \"demonstrators\" of our product, performed on client data sets\nwork directly with our Product Owner and CTO to propose and implement extensions to our product, based on repetitive client needs\ndepending on your seniority, implement machine learning algorithms on spatiotemporal event streams and other geospatial data\nThe results of your work will play a crucial role in proving how our technology can help with compelling industry use cases.\nRequirements\nYou Are\nReady for hands-on contribution to the product, helping to ensure the success of demonstrators for clients, and contribution to product codebase\nIntuitive, with good visual taste, and good common sense judgment\nCommitted to beautiful user-centered design: you know that stories are made for people, and you are willing to listen to what they have to say\nCurious at heart and thrilled to work with real-world data, especially spatio-temporal data\nLike trains, trucks, cranes, pythons, pandas, and other things that move\nNot afraid to switch between the roles of data scientist, data-vis magician, statistician, engineer, and detective, at a moment's notice\nHave 2 years+ experience in positions related to Data Science.\nHave a very good working knowledge of Python\nKnow SQL. Are able to work with tables and other data types (arrays, json,...)\nWould be able to implement the Transit Node Routing algorithm in Python just based on reading its Wikipedia article\nHave experience with git, build systems, and CI/CD\nHave at least basic undergrad textbook familiarity with graph algorithms, finite automata, and text (string) search algorithms\nUnderstand statistical concepts, such as correlated random variables, significance, and non-Gaussian noise\nPrepared to be quizzed & grilled by the datasets you encounter, everyday. Here are some questions you should be able to answer off the top of your head: what can \"-273.15\" signify; why \"65535\" is a suspicious integer value; how many months does it take a containership to go around the world; and, roughly what order of g-force is attained by an astronaut in a space rocket at liftoff?\nRespectful of others\nFluent in English\nBonus Points\nShowing a portfolio: code on github, visualization works, a research paper or a PhD thesis with an original statistical / probabilistic analysis or experiment design,..\nSuccessful track-record in Data Science or algorithms contests (Kaggle, Codeforces,...)\nExperience in topics linked to logistics/moving assets\nFamiliarity with some form of GIS software\nFamiliarity with Pandas, SciPy, NetworkX, and similar tools from the Python stack\nExperience in Data Visualization and UX\nSome knowledge of French, Polish, or German\nWhy You Should Apply\nJoin an intellectually stimulating work environment\nBe a pioneer: you get to work with a new type of data processing\nWork in one of the hottest data/AI startups in France\nUncover exciting career prospects\nMake significant contribution to our success\nJoin & co-create an inclusive workplace culture\nBenefits\nType of contract: Permanent employment contract\nPreferable joining date: February 2023. The positions (at least 2) are open until filled\nCompensation: annual salary of €50K-€70K (mid) up to €60K-€90K (senior, upper band negotiable) + Employee stock option plan\nLocation: Remote work from home. Possibility to work or meet with other team members in one of our offices:\nParis Area - Drahi X-Novation Center, Ecole Polytechnique, Palaiseau\nParis - Agoranov (where Doctolib, Alan, and Criteo were born) near Saint-Placide Metro (75006)\nWroclaw - University area\nPermanent residence will be required in France or Poland, exceptional candidates will be considered anywhere in the EU.\nIf you meet our broad requirements but are missing some experience, don't hesitate to reach out to us.\nNote\n: CS & engineering school students with exceptional profiles and/or strong motivation to join Pathway are invited to apply for Data Science internships. (Minimum duration: 5-6 months, remuneration level: €1500 / month.)\nShow more\nShow less",
        "details": {
            "JobDetail": [
                "Remote",
                "Senior"
            ],
            "TypeContract": "",
            "Salary": "50K",
            "Level": "",
            "Experience": null
        },
        "title": "data scientist",
        "skills": {
            "ProgLanguage": [
                "Python"
            ],
            "DataBase": [
                "SQL"
            ],
            "DataAnalytics": [
                "Pandas"
            ],
            "DataSerialization": [
                "Json"
            ],
            "DevTools": [
                "Git"
            ],
            "Other": [
                "Machine Learning",
                "CI/CD"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "OUTSCALE",
        "location": "St.-Cloud, Île-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/data-scientist-f-h-at-outscale-3891855564?position=35&pageNum=0&refId=EGCcUYgUshGnwQGGB%2BWgjg%3D%3D&trackingId=QUIPYOkgbNqnM3Bn12aBPg%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "OUTSCALE, marque de Dassault Systèmes, est un opérateur souverain et durable de l Expérience en tant que Service qui offre à ses clients des environnements technologiques de confiance.\nNous offrons des expériences uniques grâce au savoir-faire de nos équipes passionnées, qui se reflète notamment par la création de solutions de Business Expériences, le développement de notre propre orchestrateur Cloud, TINA OS, ou encore l obtention de la qualification SecNumCloud.\nNotre mission ? Bâtir un monde numérique accessible et meilleur pour tous à travers la création du jumeau virtuel de l organisation.\nNous menons une politique RH engagée et inclusive favorisant le bien-être de nos collaborateur·rices : respect de l équilibre vie privée/vie professionnelle, développement personnel et des compétences professionnelles, onboarding complet\nNous rejoindre, c est partager une passion pour l innovation, des valeurs communes et imaginer ensemble des solutions de confiance pour construire un monde meilleur et durable !\nNous recrutons\nun·e\nData Scientist\nafin de renforcer notre équipe\nBusiness Experience\n.\nVos missions\nAnalyser des problématiques et proposer des solutions.\nModéliser, implémenter et évaluer des algorithmes.\nTraiter des données non structurées.\nOptimiser des modèles ML/DL pour la scalabilité, l'efficacité et les performances.\nIndustrialiser des algorithmes dans les services API.\nDéployer des services sur le cloud.\nParticiper à la rédaction de spécifications et documentations techniques.\nParticiper à des événements et publications scientifiques.\nStack technique\nPython\nFrameworks ML/DL (Pytorch)\nArchitectures de réseaux neuronaux (LLMs)\nImplémentation d’algorithmes ML/DL (apprentissage supervisé/non-supervisé)\nVotre profil:\nDiplômé·e d’un Master en Intelligence Artificielle, Machine Learning.\n3 ans d’expérience minimum post-diplôme dans le domaine de l’IA, Data Science, Machine Learning, NLP, Computer Vision.\nVous maîtrisez l’analyse et la transformation des données.\nIdéalement, vous avez de l’expérience dans le déploiement des modèles ML/DL sur le cloud.\nMotivé·e, organisé·e, curieux·se, vous appréciez travailler en équipe.\nLa Diversité d’OUTSCALE trouve aussi son expression dans notre politique de recrutement qui privilégie l’égalité des chances, la diversité des individus au sein de nos équipes.\nShow more\nShow less",
        "details": {
            "JobDetail": [],
            "TypeContract": "",
            "Salary": "",
            "Level": "",
            "Experience": "3 an(s)"
        },
        "title": "data scientist",
        "skills": {
            "ProgLanguage": [
                "Python"
            ],
            "MachineLearning": [
                "PyTorch"
            ],
            "Other": [
                "Machine Learning",
                "Cloud",
                "ML"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "moOngy Digital Lab",
        "location": "Lille",
        "link": "https://fr.linkedin.com/jobs/view/data-scientist-h-f-at-moongy-digital-lab-3888669115?position=36&pageNum=0&refId=EGCcUYgUshGnwQGGB%2BWgjg%3D%3D&trackingId=suQG0RAsX5dpKp3qJC%2FHBQ%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Web Transition, c’est qui ?\nFondée en 2011,\nWeb transition\nest une entreprise de services numériques opérant sur le marché de l’IT/Digital !\nConstituant une part essentielle de\nMoOngy Digital Lab\n, Web Transition accompagne ses clients grands comptes sur leurs projets de Webmarketing, de Design, Gestion de projet et également en Data !\nNotre objectif : nous implanter comme un acteur principal sur le marché de la Transformation Digitale en accompagnant et valorisant les compétences de nos collaborateurs !\nNous sommes convaincus que le succès de MoOngy Digital Lab réside dans la somme des potentiels de nos équipes 🤝\nTon équipe : La tribu Data\nParce qu’il est indispensable que tu puisses partager tes connaissances mais aussi en acquérir de nouvelles, tu feras partie de l’une de nos tribus : celle de la Data. De plus, cela te permettra d’être acteur dans le développement et la stratégie de Web Transition. Ce système de co-réflexion et co-construction est un fondement essentiel chez nous !\nDans cette aventure, tu :\nRecueilles, analyses et formalises\nles demandes correspondant aux besoins spécifiques de chaque métier/utilisateur,\nContrôles, sélectionnes et valides\nles données pertinentes pour l'analyse & s'assurer de la cohérence et de la structuration de celles-ci avant exploitation,\nConçois, mets en œuvre et déploies\ndes modèles Machine Learning (ML) et Deep Learning (DL) dans un environnement GCP (BigQuery ML/Vertex AI) : qualité, possibilités d'exploitation, suivi de performances et versioning des mis à jour du modèle en production,\nPrésentes\nles résultats des études réalisées auprès de vos différents interlocuteurs et leur donner du sens, en s’appuyant sur des KPIs adaptés, via les outils de visualisation des données et/ou de documentation,\nAméliores\nl'efficacité de livraison des modèles ML/DL en industrialisant le processus de livraison et en automatisant la préparation des données, l’entraînement des modèles et leur déploiement,\nEffectues\nune veille technologique et maintenir une connaissance approfondie des dernières technologies liées au ML/IA.\nRejoins-nous si tu as :\nUne expérience de 5 ans au minimum dans l'analyse de données/data science, et plus globalement dans le développement des modèles ML et DL & de préférence sur l'écosystème GCP,\nUne maîtrise du langage Python et des librairies d’analyse (Pandas, NumPy et Matplotlib) et ML/DL (Scikit-Learn, TensorFlow, PyTorch, XGBoost),\nUne connaissance de l’environnement Retail serait un plus !\nTon savoir-être :\nOuvert d’esprit\nRespectueux des différences de chacun\nCurieux\nProactif\nPar où on commence ?\nUn premier entretien RH d’1h pour comprendre ton parcours et tes aspirations\nUn second entretien de 45 minutes avec l’un de nos Business Manager afin de valider tes compétences et qu’il se projette sur l’une des missions qu’il pourrait te proposer\nUn troisième entretien de quelques minutes avec notre responsable d’agence pour te proposer d’intégrer notre superbe Team Web !\n3 entretiens en peu de temps, si ton profil correspond tu intègreras très vite nos équipes 😉\nPrêt pour embarquer dans notre grande aventure humaine ? Deviens notre futur Weber en postulant à cette offre ! Voici les avantages qui t’attendent en tant que Weber :\n🤩 Des collègues incroyables\n🏆 Certifiée Great Place to Work\n🎮 Des bureaux sympas (où vous serez toujours les bienvenus)\n🎉 Des teambuilding et évents tous les mois\n💻 Des tributs métiers pour échanger entre Weber du même métier\nDes missions chez le client qui sont accompagnées et coachées par ton manager\nUn accompagnement dans ton plan de carrière et tes envies de re skilling\n🤓 Un catalogue de formations certifiantes ouvert à tous les salariés\n🍽️ Une carte tickets restaurant MyEdenred\n❤️ Une mutuelle GrasSavoye\n🚎 Une prise en charge des frais de transport à 100%\nShow more\nShow less",
        "details": {
            "JobDetail": [],
            "TypeContract": "",
            "Salary": "",
            "Level": "",
            "Experience": "5 an(s)"
        },
        "title": "data scientist",
        "skills": {
            "ProgLanguage": [
                "Python"
            ],
            "DataAnalytics": [
                "NumPy",
                "Pandas"
            ],
            "MachineLearning": [
                "Scikit-Learn",
                "TensorFlow",
                "XGBoost",
                "PyTorch"
            ],
            "DataVisualisation": [
                "Matplotlib"
            ],
            "CloudComputing": [
                "GCP"
            ],
            "DBMS": [
                "BigQuery"
            ],
            "Other": [
                "Machine Learning",
                "ML"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "IT&M STATS",
        "location": "Île-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/data-scientist-h-f-at-it-m-stats-3803674187?position=37&pageNum=0&refId=EGCcUYgUshGnwQGGB%2BWgjg%3D%3D&trackingId=sJjMjWlmkfkPy1RECRs2ow%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "IT&M Stats intervient dans le domaine des statistiques, de la programmation et de la data science, principalement dans les secteurs de l’Industrie Pharmaceutique, Cosmétique, dans la Santé et l’Agro-alimentaire et auprès des Banques et Assurances. IT&M Stats est une filiale du Groupe Astek, acteur mondial de l’ingénierie et du conseil en technologies.\nNous basons notre relation sur :\nUn respect des collaborateurs et des clients, de leurs aspirations,\nUn suivi personnalisé des collaborateurs et des clients,\nUne gestion régulière des carrières des collaborateurs,\nDes échanges transparents,\nUne réactivité, une disponibilité et une écoute permanentes.\nNous recherchons un\nData Scientist\npour intervenir dans le secteur\ncosmétique\n.\nCela vous intéresse ? Voici la suite !\n👇\nMaintenance et mise à jour de dashboards de suivi de tests sous PowerBi\nAnalyser les données générées en interne et externe et réaliser des analyses croisées /meta analyse pour une meilleure compréhension de la performance de nos produits/services\nRéaliser des analyses prédictives de la performance cosmétique en fonction de la formulation\nRéaliser des interfaces dynamiques sous R Shiny\nRé-analyser et vérifier les analyses statistiques réalisées par les prestataires externes le cas échéant\nContribuer à la mise en place des études et aider le département à l’amélioration des process (Plan d’expérience, calcul du nombre de sujets nécessaires, etc…)\nVous pensez être la perle rare ?\nVous êtes titulaire d’un diplôme de type Bac+5 (Master 2 ou école d’ingénieur) avec une spécialisation en statistiques, mathématiques ou data science\nVous justifiez d’une expérience professionnelle de 2 à 3 ans\nUne bonne maitrise de R (dont R Shiny) est attendue\nVous maitrisez PowerBI\nVous êtes organisé, rigoureux, autonome, flexible, vous aimez communiquer et travailler en équipe et vous avez un bon esprit de synthèse et d’analyse\nVous avez un bon niveau d’anglais\n🍀\nVoici ce que nous pouvons vous offrir…\nUn poste en CDI à pourvoir dès que possible, de la bonne humeur, des formations, des soirées, de la bienveillance, un suivi personnalisé, une gestion régulière de votre carrière, des échanges transparents et une écoute permanente.\nSi vous êtes convaincu que vous êtes la perle rare, postulez ! Nous sommes impatients de vous rencontrer.\nShow more\nShow less",
        "details": {
            "JobDetail": [],
            "TypeContract": "CDI",
            "Salary": "",
            "Level": "Bac+5",
            "Experience": "3 an(s)"
        },
        "title": "data scientist",
        "skills": {
            "ProgLanguage": [
                "R"
            ],
            "DataAnalytics": [
                "R"
            ],
            "Other": [
                "Statistiques"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "MindPal",
        "location": "Marseille, Provence-Alpes-Côte d'Azur, France",
        "link": "https://fr.linkedin.com/jobs/view/machine-learning-developer-at-mindpal-3911352774?position=38&pageNum=0&refId=EGCcUYgUshGnwQGGB%2BWgjg%3D%3D&trackingId=JTK7oHiJR2xivPc23lsIJw%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "We are looking for\nMachine Learning Developer\nJob Responsibilities\nWorking on machine learning projects\nAnalyzing and processing data to create machine learning models\nImplementing and optimizing machine learning algorithms\nTesting and evaluating models\nCollaborating with the programming team and other departments within the company to develop innovative solutions\nRequirements\nMinimum 2 years of experience in the field of machine learning\nKnowledge of machine learning algorithms and techniques\nAbility to analyze and process data\nFamiliarity with machine learning tools and technologies\nProficient in English communication\nEducation in computer science\nWe Offer\nB2B contract type\nFull-time employment\nRemote and flexible working hours\nShow more\nShow less",
        "details": {
            "JobDetail": [
                "Remote",
                "Full"
            ],
            "TypeContract": "",
            "Salary": "",
            "Level": "",
            "Experience": null
        },
        "title": "Other",
        "skills": {
            "Other": [
                "Machine Learning"
            ],
            "EnSoftSkils": [
                "Communication"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "TotalEnergies",
        "location": "Courbevoie, Île-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/data-scientist-f-h-at-totalenergies-3892558727?position=39&pageNum=0&refId=EGCcUYgUshGnwQGGB%2BWgjg%3D%3D&trackingId=KYg3lXwxzf%2B1aOlCxyzoyg%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "TotalEnergies est une compagnie multi-énergies mondiale de production et de fourniture d'énergies : pétrole et biocarburants, gaz naturel et gaz verts, renouvelables et électricité. Ses 105 000 collaborateurs s'engagent pour une énergie toujours plus abordable, propre, fiable et accessible au plus grand nombre. Présent dans plus de 130 pays, TotalEnergies inscrit le développement durable dans toutes ses dimensions au cœur de ses projets et opérations pour contribuer au bien-être des populations.\nContexte & Environnement :\nEnvironnement de travail international et multiculturel sur l'ensemble des domaines fonctionnels des activités commerciales de la Compagnie.\nParticipation active à la communauté Data de TotalEnergies.\nLarge éventail de métiers utilisateurs (activités historiques, nouvelles énergies, efficacité énergétique, etc.)\nMultiplicité des intervenants en interne et externe\nPoste :\nAu sein de l'équipe Valorisation des Données, le titulaire du poste aura 2 types d'activités :\n1. Data Scientist\n, représentant environ 80% du temps de travail, pour laquelle il/elle :\nest au contact direct des clients internes et participe à l'expression du besoin;\npropose l'approche à mettre en œuvre pour répondre au besoin métier (bibliographie, méthodologie);\nidentifie, sur la base de l'analyse des données et de sa connaissance du métier des cas d'usages améliorant l'expérience utilisateur;\nélabore et entraine des modèles (machine/deep learning) sur-mesure pour répondre aux besoins métier;\nparticipe, au-delà de la création des modèles, à l'ensemble de la chaine de traitement de la donnée (nettoyage, enrichissement …);\nassure une veille technologique en data science et plus généralement en architecture des données, pour être force de proposition sur de nouvelles études à fort impact potentiel pour l'entreprise ou le développement de nouvelles technologies;\nrapporte les résultats des travaux, en s'assurant de leur robustesse, à l'écrit et/ou avec des présentations internes/externes.\n2. Business Analyst\n, représentant environ 20% du temps de travail, pour laquelle il/elle :\nparticipe à la mise en production, en collaboration avec la Tierce Maintenance Applicative (TMA) et les équipes TGITS (TotalEnergies Global Information Technology Services);\naccompagne également les métiers sur le delivery (run et projets) et garantit le « move to run »;\ns'assure du maintien en conditions opérationnelles du parc applicatif;\nmet en place les KPIs appropriés et pilote le planning, le budget, la qualité des livrables et les risques des projets.\nProfil recherché :\nBAC +5 en mathématiques ou statistiques, une thèse de doctorat (PhD) ou une expérience professionnelle dans un domaine lié aux bases de données, BI et Datamining / Analytics\nMinimum 6 ans d'expérience\nCapacité à développer des algorithmes et coder, notamment en Python\nConnaissance Databricks et ML Ops est un plus\nConnaissance des environnements cloud, idéalement AWS sur des sujets data, est un plus\nAnglais courant obligatoire\nShow more\nShow less",
        "details": {
            "JobDetail": [],
            "TypeContract": "",
            "Salary": "",
            "Level": "",
            "Experience": "6 an(s)"
        },
        "title": "data scientist",
        "skills": {
            "ProgLanguage": [
                "Python"
            ],
            "BigData": [
                "Databricks"
            ],
            "CloudComputing": [
                "AWS"
            ],
            "Other": [
                "Statistiques",
                "Cloud",
                "ML"
            ],
            "EnSoftSkils": [
                "Collaboration"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "METEO FRANCE",
        "location": "Toulouse, Occitanie, France",
        "link": "https://fr.linkedin.com/jobs/view/data-scientist-h-f-at-meteo-france-3914118639?position=40&pageNum=0&refId=EGCcUYgUshGnwQGGB%2BWgjg%3D%3D&trackingId=%2BUpA7U%2FYJxdVmVrUn9yGlw%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Cette offre d’emploi est fournie par Pôle emploi\nDescription\nL'offre d'apprentissage concerne un travail autour de la thématique de l'intelligence artificielle pour la prévision numérique du temps avec notamment pour cible principale la partie assimilation. Le travail consistera à voir l'apport de l'intelligence artificielle sur différentes thématiques : émulateur de modèle météorologique, apprentissage d'erreur modèle, ... Ce travail peut aussi inclure une partie sur le traitement initial des données, notamment sous la forme de la création de jeux de données, l'optimisation du chargement en mémoire des données, ou la visualisation de données. Le diplôme préparé doit être un diplôme d'ingénieur ou un master spécialisé dans une filière data. Les compétences de bases attendues sont celles d'un apprentis datascientist. Des compétences en mathématiques, en statistiques et en informatique (de préférence python) sont attendues. Une première expérience en deep learning serait intéressante. La pratique de git est un plus.\nPROFIL SOUHAITÉ\nExpérience\nExpérience exigée de 1 An(s)\nLangue\nFrançais\nSource: Pole emploi (https://www.pole-emploi.fr)\nShow more\nShow less",
        "details": {
            "JobDetail": [],
            "TypeContract": "",
            "Salary": "",
            "Level": "",
            "Experience": null
        },
        "title": "data scientist",
        "skills": {
            "ProgLanguage": [
                "Python"
            ],
            "DevTools": [
                "Git"
            ],
            "Other": [
                "Statistiques"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "Enzo Tech Group",
        "location": "Paris, Île-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/machine-learning-engineer-at-enzo-tech-group-3914687840?position=41&pageNum=0&refId=EGCcUYgUshGnwQGGB%2BWgjg%3D%3D&trackingId=%2BSNJ9hSa5uQxWvE%2BlzQ11g%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Position:\nMachine Learning Engineer / MLOps Engineer / AI Engineer\nLocation:\nParis\nType:\nFreelance, Contract\nDuration:\n6 months\nSearching for a\nMLOps Engineer\nto lead the implementation of\nMLOps\npractices at scale with a focus on\nlarge language models\n(LLM)\n.\nRole:\nLead the implementation of\nMLOps\npractices at scale, focusing on industrialising AI solutions and ensuring their efficient deployment.\nCollaborate with software engineering teams to integrate machine learning models into production environments.\nManage and optimise\nAI infrastructure\non\nAzure\n, including\nDatabricks\nclusters and other relevant technologies.\nDevelop and maintain automation pipelines for model training, testing, monitoring, and retraining.\nRequirements\nProven experience as an MLOps Engineer or similar role, with expertise in large-scale AI deployments.\nDeep understanding of MLOps principles, including model versioning\nExpertise and support to data scientists and engineers working on AI initiatives.\nCVs: s.allenby@enzotechgroup.com\nShow more\nShow less",
        "details": {
            "JobDetail": [],
            "TypeContract": "",
            "Salary": "",
            "Level": "",
            "Experience": null
        },
        "title": "machine learning engineer",
        "skills": {
            "BigData": [
                "Databricks"
            ],
            "CloudComputing": [
                "Azure"
            ],
            "Collaboration": [
                "Teams"
            ],
            "Other": [
                "Machine Learning"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "DxO Labs",
        "location": "Boulogne-Billancourt, Île-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/data-scientist-at-dxo-labs-3915441544?position=42&pageNum=0&refId=EGCcUYgUshGnwQGGB%2BWgjg%3D%3D&trackingId=q32n1S6zIz%2BzzqOidauFiA%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "En 20 ans, DxO Labs s’est affirmée comme l’une des entreprises françaises les plus innovantes du secteur de la photographie numérique et du traitement d’image.\nNous concevons et commercialisons des logiciels d’édition photo avancée pour les photographes, amateurs ou experts. Nos solutions, issues de l’excellence et du savoir-faire incomparable de nos équipes d’experts internationales et multiculturelles, offrent les outils de correction et de traitement les plus performants.\nDxO Labs s’appuie depuis toujours sur l’excellence et le savoir-faire incomparable de ses équipes d’experts internationales et multiculturelles.\nSi vous souhaitez vous projeter et découvrir nos produits; cliquez sur https://www.dxo.com/fr/\nAfin de renforcer notre équipe R&D, nous recrutons, dans le cadre d’un contrat en CDI plein temps un\nData Scientist\nBasé à notre siège social de Boulogne-Billancourt et rapportant au Directeur Traitement Images.\nAu sein de notre équipe R&D Image et en étroite collaboration avec nos équipes UX et produit, votre rôle sera de nous aider à doter nos logiciels fonctionnalités IA innovantes basées sur l’analyse d’une grande quantité de données.\nVos missions :\nAvec nos product managers et nos chercheurs en traitement d’image, définir de nouvelles fonctionnalités utilisateur.\nConstituer les bases d’apprentissage nécessaires.\nConcevoir, implémenter et entrainer des modèles de deep learning.\nEvaluer ces modèles grâce à des prototypes.\nAider nos experts logiciel à intégrer ces nouvelles fonctionnalités utilisateur dans nos produits.\nÊtre au fait des dernières recherches et méthodes au croisement entre la data science, la vision par ordinateur et la retouche photo.\nVotre profil :\nAu moins 5 ans d'expérience en tant que Data Scientist, de préférence dans le secteur technologique ou des logiciels\nDeep learning (connaissances à jour par rapport à l’état de l’art en 2024)\nPython, PyTorch\nAu moins B2 en Anglais et Français\nCapacité à travailler de manière autonome et en équipe, avec un esprit curieux et tourné innovation\nIdéalement\nConnaissance en Traitement d’image (p.ex. analyse sémantique, génération d'images)\nTraitement de la langue (LLM)\nTensorFlow, AWS, WinML, CoreML, C++\nUn vrai + : Passionné de photographie\nSi vous vous retrouvez dans le descriptif candidat : Postulez sans attendre sur recruit@dxo.com\nNous verrons ensemble si vos compétences et votre savoir-être correspondent à notre ADN\nLocalisation :\nBasé à Boulogne-Billancourt (Métro 9 station Billancourt – Tramway T2 station Les Moulineaux),\nTélétravail possible à hauteur de 2j/semaine\nShow more\nShow less",
        "details": {
            "JobDetail": [],
            "TypeContract": "CDI",
            "Salary": "",
            "Level": "",
            "Experience": "20 an(s)"
        },
        "title": "data scientist",
        "skills": {
            "ProgLanguage": [
                "R",
                "Python"
            ],
            "DataAnalytics": [
                "R"
            ],
            "MachineLearning": [
                "PyTorch",
                "TensorFlow"
            ],
            "CloudComputing": [
                "AWS"
            ],
            "EnSoftSkils": [
                "Collaboration"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "Alki",
        "location": "Paris, Île-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/machine-learning-engineer-at-alki-3916860370?position=44&pageNum=0&refId=EGCcUYgUshGnwQGGB%2BWgjg%3D%3D&trackingId=dR6o7LsxIVtvsBdjeTwWXA%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Full Stack Machine Learning Engineer (Time Series Forecasting)\nLocation:\nRemote or Paris\nJob Type\n: Full-Time\nCompany overview\n: At Alki, we’re leveraging cutting edge AI technologies to transform logistics warehouses and drive innovation. Our mission is to bridge the gap between Amazon and other logistics players. We are looking for a skilled full stack ML engineer with a strong focus on time series forecasting to industrialize and streamline our machine learning operations (MLOps) capabilities from R&D to production.\nResponsibilities:\nDesign & build robust data pipelines specifically tailored for time series data, ensuring efficient data ingestion, pre-processing & exploration to support ML models\nDesign, implement, and optimize sophisticated time series forecasting algorithms\nTranslate advanced statistical and machine learning models from R&D into scalable production solutions\nManage the deployment of machine learning systems, including setting up continuous integration and delivery pipelines (CI/CD) for automated model training and deployment\nMonitor and maintain operational ML models (thousands), quickly identifying and addressing performance degradation or shifts in model accuracy/data\nCollaborate with cross-functional teams, including CTO, AI researcher, software engineer, to ensure models effectively address business needs and enhance decision-making\nStay abreast of the latest developments in machine learning, artificial intelligence, and related technologies to continuously improve our MLOps practices and time series models\nQualifications\nMaster’s/PhD degree in Computer Science, Applied Maths, Statistics, or a related field\nStrong experience with a proven track record of deploying ML models to production\nStrong understanding of the challenges associated with deploying, monitoring, and maintaining thousands of ML models in a production environment\nStrong experience with AutoML, HPO, NAS\nProficient in Python, including extensive experience with ML libraries such as TensorFlow or PyTorch, and statistical modeling tools\nKnowledge of AWS cloud services related to machine learning and data processing, including Amazon S3, EC2, RDS, Lambda, and SageMaker\nFamiliarity with data orchestration tools\nExperience in building and maintaining CI/CD pipelines for automated model deployment\nExcellent analytical and problem-solving abilities, with a strong collaborative mindset\nExperience in time series analysis and forecasting is a plus\nBenefits:\nCompetitive salary\nStrong opportunities for professional development and career advancement\nFlexible working hours and remote work options\nDynamic and innovative work environment\nHow to apply:\nPlease submit your resume and any relevant project portfolio to tanguy@alki.io. We are excited to hear how you can contribute to our team at Alki!\nShow more\nShow less",
        "details": {
            "JobDetail": [
                "Remote",
                "Full"
            ],
            "TypeContract": "",
            "Salary": "Salary",
            "Level": "",
            "Experience": null
        },
        "title": "machine learning engineer",
        "skills": {
            "ProgLanguage": [
                "R",
                "Python"
            ],
            "DataAnalytics": [
                "R"
            ],
            "MachineLearning": [
                "PyTorch",
                "TensorFlow"
            ],
            "CloudComputing": [
                "AWS"
            ],
            "Collaboration": [
                "Teams"
            ],
            "Other": [
                "Machine Learning",
                "Cloud",
                "ML",
                "CI/CD"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "Licorne Society",
        "location": "Paris, Île-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/data-scientist-%40-start-up-at-licorne-society-3918084326?position=45&pageNum=0&refId=EGCcUYgUshGnwQGGB%2BWgjg%3D%3D&trackingId=9prKyMo8%2FLV9SMO9p4WfkA%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Licorne Society est à la recherche de Data Scientist pour des startups innovantes, ne laisse pas passer ta chance !\nC’est quoi Licorne Society ?\nLicorne Society est le seul outil qui te met en relation avec plus de 3000 startups recrutant en France, tous secteurs et métiers confondus. Qu’elles soient en création ou en phase d’hypercroissance, toutes les startups t’attendent sur Licorne Society. Ah oui, et c’est gratuit !\nNotre promesse : faire matcher ta recherche avec les meilleures opportunités et mettre en avant ton profil auprès des startups qui recrutent.\n>> www.licornesociety.com <<\nL'inscription Prend Moins De 10 Minutes. Tu Pourras Alors Accéder à L'ensemble Des Offres En Startup Du Marché Et Être Contacté Directement Par Les Recruteurs\n1 - Remplis ton profil et tes attentes.\n2 - Passe en revue les offres que nous te proposons en fonction de tes critères de recherche et reçois une notification à chaque nouvelle offre publiée. Avec notre mode Tinder, tu n’as qu’à swiper les offres. Matcher avec le job de tes rêves n’a jamais été aussi simple !\n3 - Reçois des sollicitations directes pour des postes de Data Scientist au sein de nos startups préférées (pour ne citer que BackMarket, PlayPlay, Payfit, Trustpair ou encore Choco)\nProfil Recherché\nTu as une première expérience de Data Scientist et tu es très motivé pour rejoindre une start-up / scale-up ou tu es prêt à décrocher ton tout premier job\nTu as la fibre entrepreneuriale\nTu as soif de challenge et de nouveaux apprentissages\nTu es prêt à cliquer sur le lien d’inscription : www.licornesociety.com\nLes parcours particulièrement valorisés chez Licorne Society :\ndes exemples de prises d’initiatives ou projets menés avec l’esprit entrepreneurial\ndes expériences dans des environnements particulièrement exigeants\ndes exemples de réalisations édifiants ou résultats chiffrés\nOn se dit à tout de suite sur la plateforme ?\n>> www.licornesociety.com <<\nShow more\nShow less",
        "details": {
            "JobDetail": [],
            "TypeContract": "",
            "Salary": "",
            "Level": "",
            "Experience": null
        },
        "title": "data scientist",
        "skills": {}
    },
    {
        "source": "LinkedIn",
        "company": "Thales",
        "location": "Paris, Île-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/data-scientist-ia-d%C3%A9fense-f-h-at-thales-3880160252?position=46&pageNum=0&refId=EGCcUYgUshGnwQGGB%2BWgjg%3D%3D&trackingId=4crGluEtbgS8C3IScJtzKw%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "QUI SOMMES-NOUS ?\nThales Digital Factory s’inscrit dans le programme de transformation de Thales qui a pour ambition de devenir un acteur incontournable et exemplaire du digital, et ce dans l’ensemble de ses marchés. Notre mission consiste à accélérer la transition numérique du Groupe Thales en s'aventurant dans de nouveaux modes de travail et de décision. Notre stratégie s’articule autour de 6 valeurs : Responsabilisation, Orientée sur la donnée, Centrée sur l’utilisateur, Collaboration, Amélioration continue et Culture de l’échec. Nos bureaux se répartissent de Paris à Singapour en passant par Montréal au cœur d'écosystèmes innovants. Thales Digital Factory se distingue également grâce à son incubateur qui accompagne des start-ups internes et externes, ses plateformes digitales, son centre d’excellence Cloud et le développement de MVP, porteurs d’innovation pour l’offre digitale du Groupe et de nos clients.\nAvec plus de 600 experts IA et une centaine de doctorants en IA chaque année, et disposant d’un réseau de partenaires industriels, start-up et académiques de premier ordre, Thales est, depuis une décennie, un acteur majeur de l’IA de confiance, transparente, explicable et éthique. Le Groupe figure en tête, en Europe, dans le classement des déposants de brevets dans l’IA des systèmes critiques. Il intègre de l’IA dans plus d’une centaine de ses produits et services.\nNous recherchons notre futur\nData Scientist\ndans le cadre du lancement de notre nouvelle entité CortAix :\nCortAIx\nest l’accélérateur IA qui dotera les forces armées, les avionneurs et tous les opérateurs d’infrastructures critiques, de solutions hautement sécurisées leur apportant plus d’efficacité dans l’analyse des données et la prise de décision, tout en tenant compte des contraintes spécifiques, telles que la cybersécurité, l’embarquabilité et la frugalité, liées aux environnements critiques.\nAu sein de cette nouvelle organisation, nous représentons l'axe\n\"\ncortAIx Factory\"\nqui vise à accélérer la qualification et l’industrialisation des outils de développement de l’IA ainsi que les cas d’usage pour les données des systèmes. Thales dote déjà ses systèmes d’IA et continue d’identifier de nouveaux cas d’usages pour accélérer la performance, comme par exemple la planification de missions, la gestion du trafic aérien, le pilotage de drones et de robots.\nQUI ETES-VOUS ?\nVous êtes titulaire d'un Master 2 (BAC +5) d'une école d'Ingénieur ou d'un parcours universitaire et vous avez un minimum de 5 à 7 ans d'expérience pratique en IA, avec une solide expérience dans le déploiement de solutions ML\nVous faites preuve de motivation, d'autonomie et d'initiative\nVous avez une expérience de mise en place de solutions embarquant du machine learning, depuis la collecte de la donnée jusqu’à la mise en production de la solution par des utilisateurs\nVous faites preuve d'une grande disponibilité et d'une très forte réactivité\nVous êtes reconnu pour votre esprit d'équipe et aimez le travail collaboratif\nUne expérience dans des environnements de projet agiles et dynamiques est un plus\nUne expérience dans la conduite d'ateliers clients et de réunions face aux clients\nVous vous reconnaissez ?\nParlons missions !\nCOMPÉTENCES :\nVous comprenez les enjeux business autours de l’exploitation des données et le déploiement des solutions de Machine Learning et/ou de Deep Learning, ainsi que les problématiques inhérentes à la mise en production de telles solutions innovantes.\nVous maitrisez les statistiques, le Machine Learning et de Deep Learning.\nVous avez une écoute développée et une communication fluide et claire, ainsi, vous êtes à l’aise pour vous exprimer et convaincre sur les objectifs, la rentabilité et les étapes de résolution de problèmes associés à vos modèles, permettant de convaincre un interlocuteur peu au fait des techniques ML ou DL.\nMaîtrise du ML/DL, y compris des principaux frameworks (TensorFlow, PyTorch) et des statistiques.\nSolide connaissance de Python (Java, Spark, Scala sont un plus).\nExpérience dans l'utilisation d'outils tels que Gitlab et Docker.\nFamiliarité avec l'ensemble du cycle de vie de développement et de déploiement de modèles d'IA (MLOps).\nEn collaboration avec les autres membres de CortAIx, composés d'experts en intelligence artificielle :\nVous participez activement à l'identification des besoins spécifiques des différentes branches de Thales ou de ses clients, à travers des ateliers d'idéation, et proposez des solutions algorithmiques sur mesure adaptées à chaque situation. Votre rôle ne se limite pas à répondre à une question technique, mais à imaginer et concevoir des solutions innovantes qui répondent aux défis et objectifs spécifiques identifiés lors des discussions avec les parties prenantes\nVous analysez rapidement les données disponibles pour sélectionner les modèles d'IA les plus pertinents face aux défis identifiés, en tenant compte des spécificités de chaque cas d'usage\nVous développez, testez et validez les algorithmes de traitement des données en utilisant des méthodes statistiques, mathématiques et de machine learning, adaptés à une variété d'environnements techniques prenant en compte des besoins précis en termes de sensibilité des données\nVous jouez un rôle clé dans la diffusion de la connaissance au sein de CortAIx, en partageant régulièrement des insights et des innovations issues de vos projets récents, contribuant ainsi à l'enrichissement collectif\nVous communiquez efficacement au sein de Thales et en externe pour mettre en valeur les succès, les avancées réalisées et les leçons apprises des différents projets, renforçant ainsi la réputation de Thales comme leader de l'IA dans les domaines de la défense et au-delà\nNous sommes toujours en phase ?\nRejoignez-nous !\nInnovation, passion, ambition : rejoignez Thales et créez le monde de demain, dès aujourd’hui.\nShow more\nShow less",
        "details": {
            "JobDetail": [],
            "TypeContract": "",
            "Salary": "",
            "Level": "",
            "Experience": "7 an(s)"
        },
        "title": "data scientist",
        "skills": {
            "ProgLanguage": [
                "Java",
                "Scala",
                "Python"
            ],
            "BigData": [
                "Spark"
            ],
            "MachineLearning": [
                "PyTorch",
                "TensorFlow"
            ],
            "DevTools": [
                "Docker"
            ],
            "Containers": [
                "Docker"
            ],
            "Other": [
                "Statistiques",
                "Machine Learning",
                "Cloud",
                "ML"
            ],
            "EnSoftSkils": [
                "Initiative",
                "Communication",
                "Collaboration"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "Orange",
        "location": "France",
        "link": "https://fr.linkedin.com/jobs/view/data-scientist-f-h-at-orange-3905556668?position=47&pageNum=0&refId=EGCcUYgUshGnwQGGB%2BWgjg%3D%3D&trackingId=YU9dsbTlprbPy2%2FDlBUjaw%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Et si Business & Décision et le groupe Orange conjuguaient leurs forces pour devenir l'un des leaders européens de la Data transformation ?\nNous l'avons fait ! Notre alchimie nous positionne comme un acteur unique intervenant sur toutes les étapes du voyage de la donnée.\nBusiness & Décision en croissance sur l'année 2021, continue sur sa lancée avec un nouvel objectif de plus de 500 recrutements de profils #DataSpecialist.\nNous intervenons sur l'ensemble du cycle de vie des projets de clients du CAC40 :\nDès la phase de réflexion d'un projet, en passant par le management consulting, le cadrage, les études métiers, le cadrage de l'architecture, jusqu'au run, et expertises.\nNous formons et certifions régulièrement nos consultants sur les technologies du marché ; la formation étant l'une de nos priorités afin de vous accompagner dans le développement de vos compétences et vos perspectives d'évolutions.\nNous recherchons aujourd'hui, un Data Scientist afin d'intervenir chez nos clients pour les accompagner sur les missions suivantes :\n- Analyse et cadrage des besoins métiers,\n- Préparation des données,\n- Choix des algorithmes à mettre en oeuvre,\n- Programmation et développement,\n- Interprétation des résultats,\n- Mise en production,\n- Veille technologique,\nEn tant que Data Scientist expert, vous êtes capable de manipuler une grande quantité de bases de données et de sources, quels que soit leurs formats, de mettre en oeuvre les algorithmes nécessaires, de prendre de la hauteur par rapport aux résultats obtenus, et d'assurer une interaction avec le client sur les résultats obtenus.\nDe formation Bac +5 en Mathématiques, Statistiques ou IT\nVous maitrisez au moins un des langages de programmation suivants : Python, R, Scala, SQL, ... Vous avez des notions sur les solutions de studios Data Science (KNIME, Dataiku, H2O, Alteryx, SAS, SPSS, ...) et sur les environnements Cloud (Azure, AWS, GCP).\nVous avez déjà travaillé sur des problématiques de type : Machine Learning, Deep Learning, Time Series, Clustering, Anomly detection,\nUn intérêt ou une première expérience sur les sujets d'IA Générative est un plus.\nRef : 20521918\nShow more\nShow less",
        "details": {
            "JobDetail": [],
            "TypeContract": "",
            "Salary": "",
            "Level": "",
            "Experience": null
        },
        "title": "data scientist",
        "skills": {
            "ProgLanguage": [
                "R",
                "Scala",
                "Python"
            ],
            "DataBase": [
                "SQL"
            ],
            "DataAnalytics": [
                "R"
            ],
            "MachineLearning": [
                "Orange"
            ],
            "CloudComputing": [
                "GCP",
                "AWS",
                "Azure"
            ],
            "Other": [
                "Statistiques",
                "Machine Learning",
                "Cloud"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "Saint-Gobain",
        "location": "Courbevoie, Île-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/data-scientist-f-h-at-saint-gobain-3916726404?position=48&pageNum=0&refId=EGCcUYgUshGnwQGGB%2BWgjg%3D%3D&trackingId=W8fLNWP5t8hiE7uv0wrNeA%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Why do we need you ?\nVous rejoindrez l’équipe « AI & Data Analytics », intégrée au département «Data & Analytics» dans l’organisation « Global Digital & IT». «Data & Analytics» regroupe les activités suivantes :\nData Engineering, Data Capture & Delivery, BI & Visualization, Platform & Architecture, Data Governance and Data Engagement.\nAu Sein De L’équipe Data Science, Sous La Responsabilité Du Head Of AI & Data Analytics, Vous Aurez Le Rôle De Data Scientist (H/F). En Tant Que Tel, Vous Aurez Les Responsabilités Suivantes\nConstruire des modèles descriptifs et prédictifs sur des sujets en constante évolution ;\nMener des projets exploratoires faisant appel à des techniques avancées de Data Science (NLP, deep learning, Generative AI, apprentissage par renforcement ou par transfert), de façon autonome ou avec des partenaires externes ;\nAssurer une veille technologique permanente sur ces sujets ;\nParticiper à l’industrialisation des algorithmes en lien avec les équipes engineering basée sur MLOps;\nAccompagner les équipes opérationnelles dans le déploiement des algorithmes, notamment sur le volet analytics ;\nMener des ateliers d’idéation avec les équipes métiers (industrie, marketing, ventes, logistique, e-commerce, finance, RH) pour identifier les opportunités d’exploitation de la donnée et diffuser la culture data au sein de l’entreprise.\nSi vous recherchez des défis passionnants, pouvant impacter des centaines de milliers de clients, et aimez travailler avec des outils à la pointe de la technologie, venez et rejoignez-nous !\nVous participerez donc à la montée en puissance de l’équipe créée récemment, tout en intervenant sur un ou plusieurs cas d’utilisation.\nIs this job for you ?\nEn complément des missions évoquées, une réelle appétence pour la gestion et la facilitation de projet, avec une certaine aisance en termes de communication, seraient fortement appréciées.\nNotre équipe ayant vocation à travailler pour des clients internes pouvant être basés en France comme à l’étranger, la maitrise de l’anglais (écrite et orale) est obligatoire.\nProfil recherché\nIngénieur diplômé d’une école généraliste (Centrale, X, Mines, ENS etc.) ayant au minimum 3 années d'expérience après le diplôme.\nGrande connaissance du Machine Learning, des statistiques et des probabilités.\nSQL et Python, packages de ML: scikit, xgboost, keras\nExpérience de travail sur un cloud provider et savoir construire des data pipelines serait un plus\nGestion de code : Git, Gitlab, CI/CD\nMaitriser la modélisation à la fois prédictive et descriptive\nSavoir implémenter des dashboards et autres outils de data viz\nPosséder de bonnes qualités de communication : vous pouvez expliquer vos modèles clairement à la fois à des data analysts mais aussi à des Directeurs Généraux ou des responsables opérationnels.\nEtre organisé, structuré et motivé par l’innovation\nAimer le travail en équipe et savoir apprendre de chacun.\nUn état d’esprit orienté business et apport de valeur pour les équipes métiers\nA Little More About Us\nSaint-Gobain est une entreprise française spécialisée dans la production, la transformation et distribution de matériaux.\nFondée en 1665 par Jean-Baptiste Colbert sous le nom de Manufacture royale des glaces, l'entreprise est présente dans soixante-sept pays et emploie en 2018 près de 180 000 personnes\nTo make sure nothing is forgotten\nDétails pratiques du rôle\nDébut : Dès que vous êtes prêts\nLocalisation : La Tour Saint-Gobain, La Défense\nContrat: CDI\nSaint-Gobain encourage la diversité des équipes et favorise notamment l’inclusion des personnes en situation de handicap.\nShow more\nShow less",
        "details": {
            "JobDetail": [],
            "TypeContract": "CDI",
            "Salary": "1665",
            "Level": "",
            "Experience": null
        },
        "title": "data scientist",
        "skills": {
            "ProgLanguage": [
                "Python"
            ],
            "DataBase": [
                "SQL"
            ],
            "MachineLearning": [
                "XGBoost",
                "Keras"
            ],
            "DevTools": [
                "Git"
            ],
            "Other": [
                "CI/CD",
                "ML",
                "Statistiques",
                "Machine Learning",
                "Cloud"
            ],
            "EnSoftSkils": [
                "Communication"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "EarthDaily Agro",
        "location": "Balma, Occitanie, France",
        "link": "https://fr.linkedin.com/jobs/view/geospatial-data-scientist-at-earthdaily-agro-3884744208?position=49&pageNum=0&refId=EGCcUYgUshGnwQGGB%2BWgjg%3D%3D&trackingId=jGH3IzxurslYYB7Wsb3Cag%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "STRUCTURE D’ACCUEIL\nEarthDaily Agro fournit des données et des analyses de l'ère spatiale aux organisations et aux personnes qui nourrissent la planète !\nAvec 35 ans d'expérience dans le secteur, EarthDaily Agro fournit à ses clients les données, les analyses et les connaissances dont ils ont besoin pour prendre des décisions plus efficaces. Les services B2B vont de la gestion globale des risques et du suivi des produits agricoles à la commercialisation d'intrants et au conseil en agriculture de précision, en utilisant les dernières recherches en agronomie, en technologies de l'information et en télédétection.\nEarthDaily Agro développe également des solutions commerciales hautement personnalisées pour les prêteurs agricoles, les assureurs, les fournisseurs d'intrants et les entreprises alimentaires, avec des analyses faciles à utiliser, qui aident à réduire les risques quotidiens de l'agriculture.\nEarthDaily Agro, dont le siège social se trouve à Minneapolis, MN, USA, et qui possède des bureaux en France, au Brésil, en Australie et en Suisse, est une division de EarthDaily Analytics Corp.\nEarthDaily Analytics Corp, une société de traitement et d'analyse de données verticalement intégrée, lance une nouvelle constellation de satellites d'observation de la terre. La constellation de satellites EarthDaily améliorera considérablement les capacités d'analyse géospatiale dans les secteurs de l'agriculture, de la sylviculture, de l'environnement, des services financiers et du renseignement, parmi de nombreux autres segments.\nRESPONSABILITÉS\nVous serez en charge de résoudre des challenges liés à l’agriculture en utilisant la télédétection, en particulier les images de la future constellation EarthDaily, et des données météo. Basé à Balma, à proximité de Toulouse, vous intégrerez une équipe internationale avec des collègues au Brésil et aux USA.\nVOS RESPONSABILITÉS INCLURONT :\nL’agriculture fait face à des challenges sans précédent : le changement climatique induit des risques accrus, et les agriculteurs doivent maintenir voire améliorer leur productivité tout en réduisant leur impact environnemental. Avec la future constellation EarthDaily (jusqu’à 5 m de résolution, revisite quotidienne avec 22 bandes spectrales du visible à l’infra-rouge thermique), EarthDaily Agro disposera d’une technologie clef pour répondre à ces problématiques. Rejoignez EarthDaily Agro pour contribuer à minimiser ces risques avec la technologie.\nEarthDaily Agro est à la recherche d’un.e Data Scientist en télédétection pour rejoindre son équipe R&D et construire des analytiques à valeur ajoutée à destination de ses clients dans le monde agricole.\nVous mettez en place des solutions inventives pour répondre aux problématiques des clients, demandant des compétences fortes en analyse de données et en machine learning, dans un contexte de larges volumes de données et d’une base existante de plus de 100 analytiques. Vous développez des POCs et prototypes, définissez / testez / validez et spécifiez les algorithmes appropriés. Vous êtes activement impliqué.e dans le design et la mise en place de la solution opérationnelle sur notre plateforme Cloud.\nVos missions :\nComprendre les problématiques métier et les traduire en solution algorithmique basée sur les données issues de la télédétection.\nCréer et implémenter des modèles basés sur l’état de l’art, pour extraire l’information pertinente d’un large volume de données\nCollaborer au sein d’une équipe Agile pluridisciplinaire et internationale de Data Scientists, Data Engineers et experts métiers dans toutes les phases du projet : de l’idéation à l’industrialisation et déploiement opérationnel\nRédiger des supports de présentation des résultats, conditions d’utilisation, et défendre la solution proposée par une approche pragmatique\nÊtre proactif(ve) pour alimenter le pipeline d’innovation avec des nouvelles idées, contribuer à définir la roadmap R&D\nEDUCATION, CONNAISSANCES ET CAPACITÉS\nMaster ou doctorat en Machine Learning / Mathématiques appliquées, télédétection, ou domaine associé\nAu moins 3 ans d’expérience professionnelle, expérience dans un domaine associé à l’agriculture et en entreprise privée appréciée\nEtat d’esprit orienté résultats et pragmatique pour évoluer dans un contexte de plannings serrés\nMaîtrise de Python, connaissance en SIG (QGIS, GDAL/OGR),\nLa connaissance des bibliothèques de Machine Learning / Deep Learning (Scikit-learn, Pytorch, Tensorflow…), des outils de MLOps (ZenML, MLFlow), des systèmes de gestion de version (git), de Docker, Kubernetes et du fonctionnement des workflows sur AWS (et Azure) est appréciée\nFacilités de communication pour le travail en équipe dans un contexte international\nAnglais courant (oral et écrit) : l’équipe d’accueil est internationale, les réunions internes se déroulent principalement en anglais.\nVous êtes curieux(se) et créatif(ve), collaboratif(ve) et adaptable ? Rejoignez-nous !\nCONDITIONS\nEmploi en CDI, démarrage dès que possible\nPoste basé à Balma, première couronne de Toulouse accessible en transports en commun. Possibilité de télétravail partiel.\nPowered by JazzHR\nm5SHCur65r\nShow more\nShow less",
        "details": {
            "JobDetail": [],
            "TypeContract": "CDI",
            "Salary": "",
            "Level": "",
            "Experience": "35 an(s)"
        },
        "title": "data scientist",
        "skills": {
            "ProgLanguage": [
                "R",
                "Python"
            ],
            "DataAnalytics": [
                "R"
            ],
            "MachineLearning": [
                "Scikit-Learn",
                "TensorFlow",
                "PyTorch"
            ],
            "CloudComputing": [
                "AWS",
                "Azure"
            ],
            "DevTools": [
                "Git",
                "Docker"
            ],
            "Automation": [
                "Kubernetes"
            ],
            "Containers": [
                "Docker",
                "Kubernetes"
            ],
            "Other": [
                "Machine Learning",
                "Cloud"
            ],
            "EnSoftSkils": [
                "Communication"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "Talan",
        "location": "Paris, Île-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/data-scientist-confirm%C3%A9-s%C3%A9nior-h-f-cdi-at-talan-3909648101?position=50&pageNum=0&refId=EGCcUYgUshGnwQGGB%2BWgjg%3D%3D&trackingId=nzq%2BDoQB8i6NwtkUfvASow%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Talan est un groupe international de conseil en transformation et en innovation par la technologie, créé en 2002.\nNos 5000 consultantes et consultants partagent à travers le monde l’audace d’innover, le goût de l’excellence, et l’envie de relever les défis les plus complexes.\nNous accompagnons les entreprises dans des secteurs variés : énergie, industrie, transport, finance, luxe… à travers 3 grandes expertises :\nLe Conseil en Management et Innovation (320 Consultants en France)\nLa valorisation des données, leurs structurations, et leurs usages (Data et Technologies)\nL’intégration de solutions logicielles (Cloud et Applications Services)\nNos valeurs : engagement, respect, partage, esprit d’équipe et optimisme.\nTalan est une entreprise responsable, reconnue par ses collaborateurs et attachée à la diversité. Des aménagements peuvent être proposés si vous êtes en situation de handicap.\nRetrouvez nos engagements RSEiciet nos actions en faveur de la diversitéici\nJob Description\nNous sommes à la recherche d’un Data Scientist capable de participer à des projets techniques Data Science et IA. Vous devrez faire preuve d’un état d’esprit à la fois innovant, méthodique, orienté solution (et non problème!), et communiquant.\nVotre but ultime sera de garantir l’excellence de vos solutions Data Science/IA, pièces maitresses de la réalisation de projets disruptifs pour nos clients.\nVOTRE ROLE SUR NOS PROJETS\n:\nEn mission: analyse des besoins métiers, définition des principes et méthodes de collecte et de traitement des données, choix des modèles de Machine Learning ou de Deep Learning, mise en application des techniques de traitement et de visualisation de la data, restitution des analyses et résultats obtenus auprès des métiers et des sponsors\nPartager techniquement les membres de l’équipe: solutions et code reviews, recommandations, certifications à réaliser, …\nParticipation à des meet-up, coding dogo,…\nCommunication: écriture d’articles, retours d’expérience…\nVOTRE ROLE CHEZ TALAN :\nBenchmark de solutions et conseil auprès de nos clients sur les solutions technologiques à adopter, en lien avec leurs besoins\nRéalisation de POC (Proof Of Concept)\nParticipation à des projets internes et partage de connaissances au sein de nos équipes.\nPartage de connaissances et formations interne\nQualifications\nVOTRE PROFIL:\nIssu d’une formation Grande École d’Ingénieur/Doctorant, spécialisée en Data Science ou Intelligence Artificielle\nVous disposez d’au moins 3 années d’expérience dans le domaine\nMaitrise des techniques d’analyses statistiques, de modélisations prédictives, de Machine Learning, de Deep Learning,...\nMaitrise des techniques de data management et de DataViz\nMaitrise de Python, R, RShiny, SQL…\nMaitrise de l’utilisation des outils DevOps: Git, Docker, Jenkins/Nexus,…\nBonnes connaissances Big Data: pySpark, Spark, NoSQL…\nConnaissance d’outils tels que Dataiku, AWS SageMaker, Azure ML,…\nAutonomie, organisation, sens du partage\nExcellente communication\nOrientation métier\nAdditional Information\nAVANTAGES\n:\nPlan de formation pour accompagner votre carrière (formations éditeurs, certifications) grâce à nos partenariats nous accordant une position de partenaire privilégié, et management de proximité par des experts\nLocaux modernes en centre-ville\nTop 5 du Palmarès Great Place to Work\nTélétravail jusqu’à 5 jours selon les missions, prime d’équipement de 100€\nMobilité en France et à l’étranger\nTop 1% des entreprises évaluées par Ecovadis dans le domaine social, environnemental et éthique\nTickets restaurant, prime vacances, 50% transport (abonnement transport public), mutuelle\nPermanence handicap (consultant dédié aux collaborateurs en situation de handicap et aux proches aidants)\nActionnariat salarié\nPrime de cooptations\nRTT\nPROCESS RECRUTEMENT\n:\nL’équipe recrutement s’engage à vous proposer un processus de recrutement rapide et fluide\n1 entretien RHpar Teams (45min)\n1 test technique\n1 entretien opérationnel avec le responsable de domaine, au siège (1heure)\n1 entretien avec le directeur de pôle, au siège(1heure)\nShow more\nShow less",
        "details": {
            "JobDetail": [],
            "TypeContract": "",
            "Salary": "",
            "Level": "",
            "Experience": null
        },
        "title": "data scientist",
        "skills": {
            "ProgLanguage": [
                "R",
                "Python"
            ],
            "DataBase": [
                "SQL",
                "NoSQL"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [
                "Spark"
            ],
            "CloudComputing": [
                "AWS",
                "Azure"
            ],
            "DevTools": [
                "Git",
                "Docker",
                "Jenkins"
            ],
            "Containers": [
                "Docker"
            ],
            "Collaboration": [
                "Teams"
            ],
            "Other": [
                "ML",
                "Big Data",
                "Statistiques",
                "Machine Learning",
                "Cloud",
                "DevOps"
            ],
            "EnSoftSkils": [
                "Communication"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "Assurances Crédit Mutuel",
        "location": "Strasbourg, Grand Est, France",
        "link": "https://fr.linkedin.com/jobs/view/data-scientist-h-f-at-assurances-cr%C3%A9dit-mutuel-3881495295?position=51&pageNum=0&refId=EGCcUYgUshGnwQGGB%2BWgjg%3D%3D&trackingId=9SvD0xehnXLGFyKBJXpCNg%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Qui sommes nous\nDepuis 1971, nous imaginons, concevons et orientons les offres et services qui contribuent au développement de l’activité assurance de Crédit Mutuel Alliance Fédérale, inventeur du concept de bancassurance.\nLes Assurances du Crédit Mutuel sont présentes sur les marchés des assurances de biens, des assurances de personnes comme de l’assurance-vie. Nous proposons des solutions à tous ceux qui désirent se protéger et anticiper demain, qu’ils soient particuliers, professionnels ou entreprises.\nCe sont nos valeurs mutualistes et notre philosophie innovante qui guident nos actions. Loin de nous contenter de couvrir nos assurés aujourd’hui, nous cherchons à prévenir les risques futurs et à construire une assurance de demain plus juste.\nLes Assurances du Crédit Mutuel, ce sont ainsi environ 3500 talents au service de près de 13 millions d’assurés, générant un chiffre d’affaires de 13,9 milliards d’euros. Nos offres et services sont principalement distribués par les réseaux bancaires Crédit Mutuel, CIC et Cofidis. Nous sommes parmi les acteurs majeurs de l’assurance en France.\nRejoindre les Assurances du Crédit Mutuel, c’est rejoindre un groupe qui porte haut et fort ses valeurs et où l’humain est toujours au centre. C’est rejoindre une entreprise où les innovations sont sources de simplicité et de solidarité et où chacun est engagé pour une société plus juste et plus durable. Intégrer les ACM c’est également intégrer le groupe Crédit Mutuel Alliance Fédérale et ses multiples opportunités de carrières.\nPourquoi nous recrutons\nDans un contexte de recherche constante d'une croissance responsable et durable, Les assurances du Crédit Mutuel continuent d'innover, de se développer et de renforcer leurs équipes dans de nombreux domaines.\nVos missions\nAu sein de la Direction du Développement, de la transformation et de la Communication, vous intégrez l'équipe « Data et connaissance client » pour mener des projets de data science visant à accompagner la transformation de l'entreprise et favoriser le développement via l’analyse des profils clients.\nEn intégrant cette équipe, vous prendrez en main des projets de data science, avec le cadrage des problématiques, le recueil et l’analyse des données nécessaires. Vous testerez et comparerez différents modèles et études de performances.\nVous jouerez un rôle majeur dans la connaissance et l’anticipation des besoins de nos clients et travaillerez ainsi en relation avec les autres services de la direction (marketing, parcours client, projets digitaux, …), avec les différents services métiers des ACM et la direction commerciale du Groupe.\nVous serez aussi amené(e) à mener des études en collaboration avec d’autres Data Scientists du Groupe.\nActivités / Tâches spécifiques du poste\nVos missions seront entre autres les suivantes :\nDétenir, comprendre et exploiter la connaissance client\nProposer et développer des outils statistiques prédictifs et prescriptifs tels que des scores d’appétence ou d’attrition en mettant en œuvre des techniques de type scoring et segmentation via l’utilisation de méthodes classiques (régression logistique …) ou plus innovantes de type machine learning (random forest …).\nAnalyser, interpréter et synthétiser les données pour dégager des tendances et constats qui alimenteront la compréhension et la réflexion au sein de la direction dans le cadre d’études spécifiques (profils clients …).\nIdentifier les données existantes et de nouvelles sources de données pertinentes à collecter pour enrichir la connaissance client et modéliser leur comportement (données internes ou externes, structurées ou non structurées).\nEtablir les suivis de l’activité commerciale et analyser les performances des actions commerciales et marketing pour améliorer leur efficacité.\nParticiper à différentes missions de type veille et partage de connaissance\nAssurer une veille active sur les sujets de type Big Data et modélisation de données.\nAider au partage de bonnes pratiques au sein du groupe en tant qu’expert des données et des méthodes de modélisation.\nContribuer à la diffusion des travaux de l’équipe au sein de l’entreprise\nPouvoir représenter l'activité en intervenant dans des groupes de travail transverses.\nRestituer et communiquer régulièrement les résultats des analyses et les préconisations associées de manière rigoureuse, pédagogique, accessible et exploitable\nCe que vous allez vivre chez nous\nConcrètement, aux Assurances du Crédit Mutuel, nos collaborateurs bénéficient:\nD'une rémunération fixe versée sur 13 mois\nDe l'intéressement, participation et de l'abondement pouvant atteindre plus de deux mois de salaire en fonction des résultats du groupe\nD'un plan épargne entreprise (PEE), d’un plan épargne retraite collectif (PERECOL) et d’un compte épargne temps (CET),\nD'un rythme de travail adapté fort d'un accord QVT groupe qui permet de télétravailler jusqu'à deux jours par semaine\nDe 22 jours de RTT par an selon le rythme de travail défini\nD'une politique de protection sociale renforcée (régimes de remboursement de frais de santé et de prévoyance)\nD'un régime de retraite supplémentaire (PERO) prise en charge à 100% par l’employeur\nDe conditions bancaires et assurances préférentielles\nD'une politique parentale avantageuse\nD'un parcours d'intégration pour tout nouvel arrivant\nD'au moins une action de formation chaque année (95% des salariés)\nD'un accompagnement pour favoriser votre mobilité géographique et fonctionnelle.\nCe que nous allons aimer chez vous\nConnaissances et compétences\nDe formation supérieure Bac+5 minimum orientée statistiques, mathématiques, Data Science.\nUn minimum de six ans d’expérience à un poste équivalent est demandé.\nVous possédez une expertise confirmée en Python (pandas, scikit-learn) ainsi que des connaissances poussées en Data Science (random forest, boosting, classification …).\nVous maîtrisez des langages / outils de traitement et d’analyse de données (SQL, SAS, Excel, …)\nVous possédez des compétences en présentation (PowerPoint) et êtes capable de mettre en valeur votre travail.\nUne expérience en assurance constituerait un plus.\nUne expérience en compétition de Data Science ou programmation (Kaggle, leetcode ...) constituerait un plus.\nSavoir-être - savoir-faire\nVous appréciez le travail en équipe et faîtes preuve d'une bonne aisance relationnelle.\nCurieux, vous possédez un bon esprit d'initiative et vous tenez au courant des dernières nouveautés en terme de Data Science.\nVous possédez un esprit analytique et créatif et êtes en mesure d’imaginer et de proposer des solutions innovantes.\nRigoureux et autonome, vous disposez d'excellentes capacités d'analyse et de synthèse.\nShow more\nShow less",
        "details": {
            "JobDetail": [
                "Confirmé"
            ],
            "TypeContract": "",
            "Salary": "22",
            "Level": "Bac+5",
            "Experience": null
        },
        "title": "data scientist",
        "skills": {
            "ProgLanguage": [
                "Python"
            ],
            "DataBase": [
                "SQL"
            ],
            "DataAnalytics": [
                "Pandas"
            ],
            "MachineLearning": [
                "Scikit-Learn"
            ],
            "Other": [
                "Statistiques",
                "Machine Learning",
                "Big Data"
            ],
            "EnSoftSkils": [
                "Initiative",
                "Communication",
                "Collaboration"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "METEOJOB by CleverConnect",
        "location": "Rennes, Brittany, France",
        "link": "https://fr.linkedin.com/jobs/view/data-scientist-h-f-at-meteojob-by-cleverconnect-3907968677?position=52&pageNum=0&refId=EGCcUYgUshGnwQGGB%2BWgjg%3D%3D&trackingId=m9Xh%2BLq863yfFLMd5eYlaQ%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Entreprise\nQui sommes-nous ?\nNous sommes passionnés par les nouvelles technologies, et vous ?\nRejoindre Amiltone, c'est intégrer des équipes dynamiques et soudées dans le cadre de projets novateurs et ambitieux. Nous relevons les challenges techniques de nos clients et les accompagnons dans leur transformation digitale.\nPourquoi choisir Amiltone ?\nAmiltone, plus qu'une entreprise, un état d'esprit !\nNotre objectif ? Votre épanouissement professionnel !\nNous Avons à Cœur De\nVous accompagner au mieux au travers d'un suivi personnalisé\nVous faire monter en compétences en vous proposant des formations tout au long de votre carrière\nComprendre vos besoins et respecter nos engagements\nVous proposer des missions de qualité avec des technologies innovantes\nCultiver votre potentiel grâce à notre programme de développement personnel Addvise\nVotre bien-être passe aussi par des activités extraprofessionnelles, c'est pourquoi nous vous proposons des séances sportives animées par nos coachs, soirées pour se retrouver et animations (à l'agence ou en visio), Gaming nights...\nDescription Du Poste\nVos missions ?\nIntégré à notre équipe de 10 personnes, vous assurez les missions suivantes :\nRéceptionner et analyser la donnée brute\nTraiter la donnée en streaming ou en statique\nAdapter ou créer des modèles de machine learning\nEvaluer la précision/robustesse d'un modèle\nOutils de monitoring et de visualisation\nDéveloppement des modèles\nMaintenir et documenter les codes et les process\nLa stack Technique :\nOutils : MongoDB, PostgreSQL\nNLP (IA générative)\nQlik Sense\nDocker, Jenkins\nGitlab/Github\nDescription Du Profil\nAlors ? Prêt à devenir Amiltonien ?\nN'hésitez Pas à Postuler Si Vous Vous Reconnaissez\nDiplômé bac+5 (école d'ingénieur ou master), vous avez au moins 2 ans d'expérience en tant que Data Scientist.\nVous aimez découvrir de nouveaux contextes fonctionnels et comprendre les objectifs des applications que vous développez.\nA l'aise dans une organisation agile, vous faites preuve de rigueur et appliquez les standards de qualité Amiltone durant toute la durée des développements.\nOutre vos compétences techniques, nous nous intéressons également à votre potentiel et votre motivation.\nNos postes sont ouverts aux personnes en situation de handicap.\nShow more\nShow less",
        "details": {
            "JobDetail": [],
            "TypeContract": "",
            "Salary": "",
            "Level": "Bac+5",
            "Experience": "2 an(s)"
        },
        "title": "data scientist",
        "skills": {
            "DataBase": [
                "MongoDB"
            ],
            "DevTools": [
                "Jenkins",
                "Docker"
            ],
            "DBMS": [
                "PostgreSQL"
            ],
            "Containers": [
                "Docker"
            ],
            "Other": [
                "Machine Learning"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "Hugging Face",
        "location": "France",
        "link": "https://fr.linkedin.com/jobs/view/machine-learning-engineer-fast-optimized-inference-emea-remote-at-hugging-face-3848456024?position=53&pageNum=0&refId=EGCcUYgUshGnwQGGB%2BWgjg%3D%3D&trackingId=%2FCf3FGESZO5JC2xrY8Rbqg%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Here at Hugging Face, we're on a journey to advance good Machine Learning and make it more accessible. Along the way, we contribute to the development of technology for the better.\nWe have built the fastest-growing, open-source, library of pre-trained models in the world. With more than 1 Million+ models and 320K+ stars on GitHub, over 15.000 companies are using HF technology in production, including leading AI organizations such as Google, Elastic, Salesforce, Algolia, Grammarly and NASA.\nAbout the role:\nAs a Machine learning Engineer, you work mainly on creating great libraries highly focused on real world ML use cases. We're building on top of our open-source to create more specialized code with a focus on industrial level of usage.\nWe are searching for someone who brings fresh ideas, demonstrates a unique and informed viewpoint, and enjoys collaborating with a progressive, nimble and decentralized approach to develop real-world solutions and positive user experiences at every interaction.\nObjectives of this role:\nDevelop specialized software for specific machine learning (ML) use cases that have broad applications, similar to [text-generation-inference](https://github.com/huggingface/text-generation-inference).\nUtilize existing library frameworks to create scalable software solutions for industrial purposes.\nEnhance the reliability, quality, and time-to-market of our software suite. Measure and optimize system performance to stay ahead of customer needs and drive innovation.\nManage the production environment by monitoring availability and ensuring overall system health. We run our own tools\nAbout you:\nIf you are a passionate Machine Learning Engineer with a keen interest in AI and proficient with Python, Rust and specialized Cuda kernels Frameworks (transformers of course + Keras or PyTorch), we would love to hear from you. Join our team and contribute to the advancement of AI technologies while working alongside talented professionals in a collaborative and stimulating environment.\nMore about Hugging Face\nWe are actively working to build a culture that values diversity, equity, and inclusivity\n.\nWe are intentionally building a workplace where people feel respected and supported—regardless of who you are or where you come from. We believe this is foundational to building a great company and community. Hugging Face is an equal opportunity employer and we do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.\nWe value development.\nYou will work with some of the smartest people in our industry. We are an organization that has a bias for impact and is always challenging ourselves to continuously grow. We provide all employees with reimbursement for relevant conferences, training, and education.\nWe care about your well-being\n.\nWe offer flexible working hours and remote options. We offer health, dental, and vision benefits for employees and their dependents. We also offer flexible parental leave and paid time off.\nWe support our employees wherever they are\n.\nWhile we have office spaces in NYC and Paris, we're very distributed and all remote employees have the opportunity to visit our offices. If needed, we'll also outfit your workstation to ensure you succeed.\nWe want our teammates to be shareholders\n.\nAll employees have company equity as part of their compensation package. If we succeed in becoming a category-defining platform in machine learning and artificial intelligence, everyone enjoys the upside.\nWe support the community\n.\nWe believe major scientific advancements are the result of collaboration across the field. Join a community supporting the ML/AI community.\nShow more\nShow less",
        "details": {
            "JobDetail": [
                "Remote"
            ],
            "TypeContract": "",
            "Salary": "Package",
            "Level": "",
            "Experience": null
        },
        "title": "machine learning engineer",
        "skills": {
            "ProgLanguage": [
                "Python"
            ],
            "MachineLearning": [
                "PyTorch",
                "Keras"
            ],
            "Other": [
                "Machine Learning",
                "ML"
            ],
            "EnSoftSkils": [
                "Organization",
                "Collaboration"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "ADHERENCE CONSULTING",
        "location": "Capinghem, Hauts-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/data-scientist-h-f-at-adherence-consulting-3913994542?position=54&pageNum=0&refId=EGCcUYgUshGnwQGGB%2BWgjg%3D%3D&trackingId=txs3CoClQyUwsnwaIctBaQ%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Adherence Consulting : Votre partenaire IT de choix !\nImplantés à Paris, Lille et Marseille, nous sommes au coeur de l'innovation technologique et organisationnelle.\nNotre mission ? Booster votre performance et vous accompagner dans chaque étape de votre transformation digitale.\nSi vous êtes prêt(e) pour une carrière qui dépasse vos attentes, c'est le moment !\nhttps://www.adherence-consulting.fr/\nLes missions du poste\nContexte\nAdhérence Consulting est une ESN implanté à Paris, Lille et Marseille. Nous sommes au coeur de l'innovation technologique et organisationnelle.\nNotre mission ? Booster les performances et accompagner nos clients à chaque étape de leur transformation digitale. Nous cherchons actuellement un Data Scientist (F/H) pour le projet de notre client.\nVous participerez à la construction de nombreux projets tous aussi ambitieux les uns que les autres.\nQuelles sont vos missions au quotidien ?\nApplique des techniques (statistiques, text mining, comportementale, géolocalisation,) d'extraction et d'analyse d'informations, obtenues à partir de gisements de données (Big Data)\nObtient des données adéquates, trouve les sources de données pertinentes, fait des recommandations sur les bases de données à consolider, modifier, rapatrier, externaliser, internaliser, conçoit des datamarts, voire des entrepôts de données (data warehouses).\nÉvalue la qualité et la richesse des données, les analyse et en restitue les résultats pour ensuite les intégrer dans le système d'information cible du Métier.\nAnalyse les données pour traduire une problématique Métier en problème mathématiques/statistiques et réciproquement.\nCompare et évalue différents modèles ou méthodes de calcul et anticipe les avantages et inconvénients dans un environnement Métier.\nIntervenant auprès des Métiers, il exploite, analyse et évalue la richesse, de données structurées ou non, appartenant à l'entreprise ou non, pour établir des scénarios permettant de comprendre et d'anticiper de futurs levier Métiers ou opérationnels pour l'entreprise\nShow more\nShow less",
        "details": {
            "JobDetail": [],
            "TypeContract": "",
            "Salary": "",
            "Level": "",
            "Experience": null
        },
        "title": "data scientist",
        "skills": {
            "Other": [
                "Statistiques",
                "Big Data"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "Astek",
        "location": "Île-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/ing%C3%A9nieur-data-scientist-%E2%80%93intelligence-artificielle-idf-france-h-f-at-astek-3886897805?position=55&pageNum=0&refId=EGCcUYgUshGnwQGGB%2BWgjg%3D%3D&trackingId=YGjzmQWUDVjj3KqtpfRzEw%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Ce que nous allons accomplir ensemble :\nPour l’un de nos projets dans le domaine aéronautique, vous interviendrez en tant\nqu’ingénieur Data scientist / Intelligence artificielle\nsur la mise en place de systèmes experts destinés aux avions civils et militaires.\nVotre future équipe :\nTeam IT de 12 personnes\nData scientist, ingénieurs systèmes, intégrateurs, architectes\nVous travaillerez avec de véritables passionnés !\nVotre mission (...si vous l’acceptez !) :\nVous participerez au développement des fonctions d’analyses multisystèmes. Pour cela vous assurerez l’établissement d’une spécification formelles sur les modèles d’analyses.\nVous assurerez l’analyse des données et la proposition de méthodes pour le traitement des signaux.\nVous développerez les outils capables de traiter de manière automatique les données systèmes.\nVous assurerez la réalisation des scénarios, ainsi que les tests et simulations.\nVous réaliserez également une activité de support.\nVotre stack de jeu :\nData scientist, python, principe de gestion de configuration, et traçabilité, systèmes aéronautiques, intelligence artificielle\nLes petits plus du projet :\nVous évoluerez au sein d’équipes agiles impliquées et réactives.\nVous interviendrez de A à Z sur des projets riches fonctionnellement et ambitieux techniquement :\nforte volumétrie, haut niveau de performance, exigence maximale en termes d’intelligence artificielle et encore bien d'autres sujets captivants.\nVous ?\nDe formation Ingénieur, vous justifiez d’une expérience significative en Data scientist et ou Intelligence artificielle.\nUne connaissance des méthodes d’analyse de données serait un plus.\nIdéalement vous avez une connaissance des systèmes aéronautiques.\nDes postes également ouverts aux débutants si stages significatifs.\nNous ?\nCréé en France en 1988, Astek est un acteur mondial de l’ingénierie et du conseil en technologies, présent sur les 5 continents. Fort de son expertise dans de nombreux secteurs industriels et tertiaires, Astek accompagne ses clients internationaux dans le déploiement intelligent de leurs produits et de leurs services, et dans la mise en œuvre de leur transformation digitale.\nDepuis sa création, le Groupe a fondé son développement sur une forte culture d’entrepreneuriat et d’innovation, et sur l’accompagnement et la montée en compétence de ses 5 200 collaborateurs qui s’engagent chaque jour à promouvoir la complémentarité entre les technologies numériques et l’ingénierie des systèmes complexes.\nRejoignez un Groupe en fort développement en France et à travers le monde grâce à une levée de fonds de 200M€ réalisée en 2021. Ensemble « Let’s move forward! »\n✨ Tous les détails sur le Groupe sur le site\nhttps://astekgroup.fr.\nEt vous pouvez aussi nous suivre sur\nnotre blog : https://blog.groupeastek.com\n.\nRencontrons-nous !\nVous vous êtes reconnu sur l’annonce et Astek vous plaît !\nPour en savoir plus sur vous, Franck , notre Talent Acquisition vous contacte. Puis, vous aurez 3 entretiens max, avec Léonard (votre futur n+1), Léonard notre Directeur !\nNos plus\nAstek est green et fait bénéficier ses salariés d’une indemnité kilométrique vélo\nUn programme CARE sur-mesure déployé par nos équipes RH pour nos collaborateurs : https://astekgroup.fr/engagements\nNotre charte de la Diversité\nBienvenue dans la team ! Allez-y, maintenant c’est à vous de jouer !\nShow more\nShow less",
        "details": {
            "JobDetail": [],
            "TypeContract": "",
            "Salary": "",
            "Level": "",
            "Experience": null
        },
        "title": "data engineer",
        "skills": {
            "ProgLanguage": [
                "Python"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "Saint-Gobain",
        "location": "Courbevoie, Île-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/data-scientist-f-h-at-saint-gobain-3915274420?position=56&pageNum=0&refId=EGCcUYgUshGnwQGGB%2BWgjg%3D%3D&trackingId=iVy%2FgS0TYo2WhSjVAsbIOQ%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Why do we need you ?\nVous rejoindrez l’équipe « AI & Data Analytics », intégrée au département «Data & Analytics» dans l’organisation « Global Digital & IT». «Data & Analytics» regroupe les activités suivantes :\nData Engineering, Data Capture & Delivery, BI & Visualization, Platform & Architecture, Data Governance and Data Engagement.\nAu Sein De L’équipe Data Science, Sous La Responsabilité Du Head Of AI & Data Analytics, Vous Aurez Le Rôle De Data Scientist (H/F). En Tant Que Tel, Vous Aurez Les Responsabilités Suivantes\nConstruire des modèles descriptifs et prédictifs sur des sujets en constante évolution ;\nMener des projets exploratoires faisant appel à des techniques avancées de Data Science (NLP, deep learning, Generative AI, apprentissage par renforcement ou par transfert), de façon autonome ou avec des partenaires externes ;\nAssurer une veille technologique permanente sur ces sujets ;\nParticiper à l’industrialisation des algorithmes en lien avec les équipes engineering basée sur MLOps;\nAccompagner les équipes opérationnelles dans le déploiement des algorithmes, notamment sur le volet analytics ;\nMener des ateliers d’idéation avec les équipes métiers (industrie, marketing, ventes, logistique, e-commerce, finance, RH) pour identifier les opportunités d’exploitation de la donnée et diffuser la culture data au sein de l’entreprise.\nSi vous recherchez des défis passionnants, pouvant impacter des centaines de milliers de clients, et aimez travailler avec des outils à la pointe de la technologie, venez et rejoignez-nous !\nVous participerez donc à la montée en puissance de l’équipe créée récemment, tout en intervenant sur un ou plusieurs cas d’utilisation.\nIs this job for you ?\nEn complément des missions évoquées, une réelle appétence pour la gestion et la facilitation de projet, avec une certaine aisance en termes de communication, seraient fortement appréciées.\nNotre équipe ayant vocation à travailler pour des clients internes pouvant être basés en France comme à l’étranger, la maitrise de l’anglais (écrite et orale) est obligatoire.\nProfil recherché\nIngénieur diplômé d’une école généraliste (Centrale, X, Mines, ENS etc.) ayant au minimum 3 années d'expérience après le diplôme.\nGrande connaissance du Machine Learning, des statistiques et des probabilités.\nSQL et Python, packages de ML: scikit, xgboost, keras\nExpérience de travail sur un cloud provider et savoir construire des data pipelines serait un plus\nGestion de code : Git, Gitlab, CI/CD\nMaitriser la modélisation à la fois prédictive et descriptive\nSavoir implémenter des dashboards et autres outils de data viz\nPosséder de bonnes qualités de communication : vous pouvez expliquer vos modèles clairement à la fois à des data analysts mais aussi à des Directeurs Généraux ou des responsables opérationnels.\nEtre organisé, structuré et motivé par l’innovation\nAimer le travail en équipe et savoir apprendre de chacun.\nUn état d’esprit orienté business et apport de valeur pour les équipes métiers\nA Little More About Us\nSaint-Gobain est une entreprise française spécialisée dans la production, la transformation et distribution de matériaux.\nFondée en 1665 par Jean-Baptiste Colbert sous le nom de Manufacture royale des glaces, l'entreprise est présente dans soixante-sept pays et emploie en 2018 près de 180 000 personnes\nTo make sure nothing is forgotten\nDétails pratiques du rôle\nDébut : Dès que vous êtes prêts\nLocalisation : La Tour Saint-Gobain, La Défense\nContrat: CDI\nSaint-Gobain encourage la diversité des équipes et favorise notamment l’inclusion des personnes en situation de handicap.\nShow more\nShow less",
        "details": {
            "JobDetail": [],
            "TypeContract": "CDI",
            "Salary": "1665",
            "Level": "",
            "Experience": null
        },
        "title": "data scientist",
        "skills": {
            "ProgLanguage": [
                "Python"
            ],
            "DataBase": [
                "SQL"
            ],
            "MachineLearning": [
                "XGBoost",
                "Keras"
            ],
            "DevTools": [
                "Git"
            ],
            "Other": [
                "CI/CD",
                "ML",
                "Statistiques",
                "Machine Learning",
                "Cloud"
            ],
            "EnSoftSkils": [
                "Communication"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "MindPal",
        "location": "Lyon, Auvergne-Rhône-Alpes, France",
        "link": "https://fr.linkedin.com/jobs/view/machine-learning-developer-at-mindpal-3910999113?position=57&pageNum=0&refId=EGCcUYgUshGnwQGGB%2BWgjg%3D%3D&trackingId=uPBqLe0DylWuIDmsP56kxw%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "We are looking for\nMachine Learning Developer\nJob Responsibilities\nWorking on machine learning projects\nAnalyzing and processing data to create machine learning models\nImplementing and optimizing machine learning algorithms\nTesting and evaluating models\nCollaborating with the programming team and other departments within the company to develop innovative solutions\nRequirements\nMinimum 2 years of experience in the field of machine learning\nKnowledge of machine learning algorithms and techniques\nAbility to analyze and process data\nFamiliarity with machine learning tools and technologies\nProficient in English communication\nEducation in computer science\nWe Offer\nB2B contract type\nFull-time employment\nRemote and flexible working hours\nShow more\nShow less",
        "details": {
            "JobDetail": [
                "Remote",
                "Full"
            ],
            "TypeContract": "",
            "Salary": "",
            "Level": "",
            "Experience": null
        },
        "title": "Other",
        "skills": {
            "Other": [
                "Machine Learning"
            ],
            "EnSoftSkils": [
                "Communication"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "GROUPE ALLIANCE",
        "location": "Île-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/datascientist-at-groupe-alliance-3916080098?position=58&pageNum=0&refId=EGCcUYgUshGnwQGGB%2BWgjg%3D%3D&trackingId=eMJBqkidRy5X4xpxKR2WIQ%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "SI LA GESTION DES DONNEES EST TON DADA, TU PEUX GAGNER LA COURSE EN LISANT CETTE ANNONCE …\nCe que tu recherches :\nau sein d’une équipe dynamique\nà des projets innovants d’envergure\ndes défis\nun nouveau souffle à ta carrière\nAlors nous avons la mission idéale pour toi.\nAu sein d’acteurs majeurs du secteur Bancaire, tu participeras des projets d’envergure sur des évolutions majeures à mettre en œuvre dans le SI du client :\ndes besoins, tu feras\ntechniques, tu rédigeras\net/ou socle technique, tu définiras\npratiques, tu instaureras\nnouvelles fonctionnalités, tu développeras\nbug, tu laisseras\néquipe, tu accompagneras\ninstances de pilotage, tu participeras\nQui tu es :\nde la formation qui va bien\nou dôté(e) d’une expérience de 3 ans minimum\nde la Stack technique machine learning et python\navec les Frameworks et Outils : Ttensorflow, pytorch,scikit-learn, numpy, pandas\nAu-delà des compétences techniques, tu es :\n: tu n’aimes pas rester les deux pieds dans le même sabot\n: un guide du Routard te suffira\nde synthèse : tu sais aller à l’essentiel\nd’adaptation : tu es un vrai caméléon\nde la communication : les mots n’ont pas de secret pour toi\nde proposition : tu es l’Aladdin de l’informatique\nd’équipe : un pour tous et tous pour un !\nShow more\nShow less",
        "details": {
            "JobDetail": [],
            "TypeContract": "",
            "Salary": "",
            "Level": "",
            "Experience": "3 an(s)"
        },
        "title": "data scientist",
        "skills": {
            "ProgLanguage": [
                "Python"
            ],
            "DataAnalytics": [
                "NumPy",
                "Pandas"
            ],
            "MachineLearning": [
                "Scikit-Learn",
                "PyTorch"
            ],
            "Other": [
                "Machine Learning"
            ],
            "EnSoftSkils": [
                "Communication"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "CRIT France",
        "location": "Saint-Étienne",
        "link": "https://fr.linkedin.com/jobs/view/data-scientist-at-crit-france-3908277901?position=59&pageNum=0&refId=EGCcUYgUshGnwQGGB%2BWgjg%3D%3D&trackingId=nZJOgHHRNA%2FamPFJynXc5A%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Vous souhaitez rejoindre une entreprise, leader dans les Énergies Renouvelables et travaillant en mode projet ? Le domaine de la Data et de l'ingénierie informatique n'a plus aucun secret pour vous ? 🚀\nNotre\nCabinet CRIT Experts & Cadres\nrecherche pour l’un de nos clients situé à proximité de Saint-Etienne,\nun\nData Scientist H/F\n, en CDI.\n🌐 Qui est notre client ?\nLeader et fleuron de l’énergie électrique, notre client est basé à proximité de Saint-Étienne (42), est une entreprise qui conçoit, produit et installe des systèmes automatisés, de conversion et de stockage d’énergie électrique\n🌎 Les engagements de l’entreprise ?\n#satisfaction client\n#respect de la personne\n#performance\n#solidarité et le travail d’équipe\n#intégrité\n#développement des talents\nPourquoi postuler ?\nBien qu'étant une entreprise avec des projets à l'international, notre client su rester à taille humaine. Le fonctionnement en mode Projet offre la possibilité à leurs collaborateurs de s'impliquer et d'apporter leurs compétences à des projets variés. Leurs projets sont des défis techniques qui offrent la possibilité de travailler sur un cycle complet, de la conception à la mise en service.\n📌 Quel sera votre rôle ?\nCollecter, analyser et interpréter des données pour aider l'entreprise à prendre des décisions stratégiques basées sur des données probantes.\nRattaché hiérarchiquement directement au Président, vos missions seront :\nCollecter, nettoyer et manipuler de grandes quantités de données provenant de diverses sources, y compris des bases de données internes et externes, des API et des données non structurées.\nDévelopper et mettre en œuvre des modèles prédictifs et des algorithmes d'apprentissage automatique pour résoudre des problèmes commerciaux complexes.\nEffectuer des analyses statistiques approfondies pour identifier des tendances, des modèles et des insights significatifs.\nTravailler en étroite collaboration avec les équipes interfonctionnelles pour comprendre leurs besoins en matière de données et fournir des solutions analytiques.\nCréer des tableaux de bord interactifs, des visualisations de données et des rapports pour communiquer efficacement les résultats de l'analyse aux parties prenantes.\nMaintenir une veille technologique constante sur les avancées en matière de science des données et proposer des améliorations continues aux processus et méthodologies existants.\nVos responsabilités et périmètre d’action :\nSous directives et objectifs fixés par votre responsable hiérarchique, le Président :\nÊtre conscient des risques et prendre des mesures appropriées pour protéger les données et les systèmes contre les menaces.\n🎯\nProfil recherché :\nDomaine des sciences de données : informatique, en mathématiques, en statistiques, en économie, en sciences de l'informatique, en gestion, en ingénierie industrielle ou dans un domaine connexe.\nExpérience antérieure dans un rôle similaire.\nMaîtrise de l’anglais.\n💡 Vos cartes secrètes idéales ?\n👉 Connaissance des concepts en collecte, extraction & analyse de données.\n👉 Compétences analytiques.\n👉 Capacité à communiquer des informations complexes de manière claire et compréhensible.\n👉 Capacité à travailler de manière collaborative.\n👉 Maîtrise des langages de programmation courants tels que Python, R ou SQL.\n👉 Solides compétences en analyse statistique et en modélisation prédictive.\n👉 Expérience pratique avec les bibliothèques et les frameworks d'apprentissage automatique tels que TensorFlow, Scikit-Learn ou PyTorch.\nAutres informations :\nContrat\n: CDI\nStatut\n: cadre\nSalaire\n: en fonction du profil – à définir\n📍\nLieu\n: à proximité de Saint-Etienne\nAvantages salariaux : Prime participation salariale, Tickets Restaurants, CSE…\nDéplacements à prévoir :\nFrance – EMEA Germany, Italy, Spain, UK\nFréquence : selon besoin de l’activité\nShow more\nShow less",
        "details": {
            "JobDetail": [],
            "TypeContract": "CDI",
            "Salary": "Salaire",
            "Level": "",
            "Experience": null
        },
        "title": "data scientist",
        "skills": {
            "ProgLanguage": [
                "R",
                "Python"
            ],
            "DataBase": [
                "SQL"
            ],
            "DataAnalytics": [
                "R"
            ],
            "MachineLearning": [
                "Scikit-Learn",
                "TensorFlow",
                "PyTorch"
            ],
            "Other": [
                "Statistiques"
            ],
            "EnSoftSkils": [
                "Collaboration"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "Lincoln France",
        "location": "Île-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/data-scientist-h-f-at-lincoln-france-3892490370?position=1&pageNum=2&refId=EAisFcfNV4WNL6Xe9UKYqQ%3D%3D&trackingId=CNMoLfhdQ3H5Q5uqpxWVcA%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "CDI\n📊\n4 ans minimum\nChez Lincoln\n, nous formons une communauté d'innovateurs passionnés qui redéfinissent l'analyse de données depuis\nplus de 30 ans\n. En tant que\nPure Player Data\n, notre expertise est reconnue dans les domaines\nde la Modern BI, du Big Data et de la Science des données\n.\nNotre mission ?\nTransformer les données en solutions concrètes pour nos clients grands comptes dans divers secteurs tels que la banque, le retail, les télécoms, l'industrie, la santé, etc.\nDescription du poste\nNous recherchons un\nData Scientist H/F\npour accompagner nos clients dans leurs projets stratégiques.\nVos missions\nCollecter, nettoyer et préparer les données pour l'analyse.\nConcevoir, développer et mettre en œuvre des modèles prédictifs et analytiques en utilisant des techniques avancées d'apprentissage automatique et de science des données.\nAnalyser les résultats des modèles et fournir des insights exploitables aux équipes clients.\nCollaborer avec les équipes interfonctionnelles pour comprendre les besoins commerciaux et recommander des solutions basées sur les données.\nPrérequis :\nSolides compétences en programmation (\nPython, R, SQL, etc.)\net en manipulation de données.\nExpérience pratique avec des frameworks et des bibliothèques d'apprentissage automatique (\nTensorFlow, PyTorch, Scikit-learn\n,\netc\n.).\nMaîtrise des techniques avancées d'analyse de données, y compris l'apprentissage automatique, l'apprentissage profond, la vision par ordinateur, le traitement du langage naturel, etc.\nExpérience de travail en\nméthode Agile\npour la gestion de projet et le développement de solutions.\nCapacité à travailler de manière autonome et en équipe.\nExcellentes compétences en communication et en présentation.\nLes plus du poste\nEnvironnement Collaboratif\n: projets innovants favorisant le partage des connaissances.\nAccompagnement individualisé et de proximité\n: formations certifiantes, attribution d’un Career Manager pour vous orienter dans votre trajectoire professionnelle, opportunités d’évolution de carrière.\nFlexibilité du Travail\n: Télétravail et horaires flexibles pour votre équilibre vie professionnelle-personnelle.\nRémunération Compétitive\n: Salaire compétitif avec des avantages sociaux attrayants.\nMobilité\n: Possibilité de mobilité à Lille, Lyon ou Aix-en-Provence offrant des expériences diversifiées au sein de Lincoln.\nNotre processus de recrutement :\nUn entretien RH (1h) et entretien technique (1h)\nCette annonce n’est pas faite pour vous si :\nVous êtes freelance et vous comptez le rester !\nToujours là ? Postulez et rejoignez nos\n400 experts en Data\n😉.\nShow more\nShow less",
        "details": {
            "JobDetail": [],
            "TypeContract": "CDI",
            "Salary": "400",
            "Level": "",
            "Experience": "4 an(s)"
        },
        "title": "data scientist",
        "skills": {
            "ProgLanguage": [
                "R",
                "Python"
            ],
            "DataBase": [
                "SQL"
            ],
            "DataAnalytics": [
                "R"
            ],
            "MachineLearning": [
                "Scikit-Learn",
                "TensorFlow",
                "PyTorch"
            ],
            "Other": [
                "Big Data"
            ],
            "EnSoftSkils": [
                "Communication"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "MERITIS",
        "location": "Île-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/data-scientist-h-f-at-meritis-3869246366?position=2&pageNum=2&refId=EAisFcfNV4WNL6Xe9UKYqQ%3D%3D&trackingId=jUhkq4MU7YKcmyS9Qi7KKQ%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Nous recherchons un\nData Scientist\npour intervenir dans le cadre d'un\nprojet de détection de document.\nVos missions :\nSujet de\nfraude documentaire:\nla problématique est de détecter si un document (RIB ou pièce d’identité) a été manipulé (montage, remplacement de la photo d’identité, changement du nom/prénom, ou de l’IBAN etc).\nLes technos connues utilisées:\nPython avec les libs/framework suivants : pytorch, jupyterlab, pandas\nModèles : layoutLM (techno à priori assez récente), yolo, resnet (classique), docTR (ocr)\nConnaitre les transformers\nAutre : Labelstudio\nCe poste est-il fait pour vous\n? :\nVous êtes diplômé d'un\nBac +5\net justifiez d'\nau moins 4 ans d'expérience\nVous êtes\nproactif et autonome ​\nVous aimez travailler\nau contact de plusieurs équipes métiers\nConnaissance du secteur de l'assurance obligatoire\nDescriptif de l’entreprise :\n​\nMeritis est un cabinet de conseil, pilotage et développement IT fondé en 2007 présent à Paris, Sophia-Antipolis, Aix-en-Provence, Montpellier, Toulouse, Nantes... Et bientôt sur de nouveaux territoires ! Notre mission ? Connecter les meilleurs talents aux entreprises pour leur donner un temps d’avance.​\nNous accompagnons nos clients dans l’intégralité de leurs besoins en transformation numérique à travers de nombreux domaines d’expertises : Software Engineering, Finance, Pilotage de projets, Devops, Data, Cloud, Cybersécurité ou encore Agilité.​\nIntervenant aussi bien dans les secteurs de la Banque, de l'Assurance, des Télécommunications que de l'Industrie ou des Transports, aujourd'hui 40% des entreprises du CAC40 sont clientes Meritis.​\nFort de nos valeurs d’exigence, d’humilité, de bienveillance et de proximité, nous comptons aujourd’hui plus de 900 collaborateurs.​\nNous mettons un point d’honneur à être proche de nos collaborateurs et à les accompagner de manière individualisée quelles que soient leurs fonctions dans l’entreprise.\nCertifiée Great Place To Work depuis 2013, notre conception du bien-être au travail va bien au-delà d'un simple label, ce sont nos collaborateurs qui en parlent le mieux : https://www.glassdoor.fr/Avis/Meritis-Avis-E1163008.htm.​\nVos différences sont nos atouts. C’est pourquoi Meritis est engagée en faveur de la diversité et de la non-discrimination. Tous nos métiers sont accessibles aux personnes en situation de handicap. Si vous avez une question ou pensez être victime ou témoin d’une discrimination, vous pouvez contacter ethiquegroup@meritis.fr. »\nShow more\nShow less",
        "details": {
            "JobDetail": [],
            "TypeContract": "",
            "Salary": "",
            "Level": "",
            "Experience": "4 an(s)"
        },
        "title": "data scientist",
        "skills": {
            "ProgLanguage": [
                "Python"
            ],
            "DataAnalytics": [
                "Pandas"
            ],
            "MachineLearning": [
                "PyTorch"
            ],
            "Other": [
                "Cloud",
                "DevOps"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "SoftwareOne",
        "location": "Levallois-Perret, Île-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/data-scientist-flexible-working-at-softwareone-3872563771?position=3&pageNum=2&refId=EAisFcfNV4WNL6Xe9UKYqQ%3D%3D&trackingId=GH0UFelX%2FcmY9RQT5cwbGA%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Why SoftwareOne?\nSoftwareOne is a leading global software and cloud solutions provider that is redefining how companies build, buy and manage everything in the cloud. By helping clients to migrate and modernize their workloads and applications – and in parallel, to navigate and optimize the resulting software and cloud changes – SoftwareOne unlocks the value of technology. The company’s 8,900 employees are driven to deliver a portfolio of 7,500 software brands with sales and delivery capabilities in 90 countries. Headquartered in Switzerland, SoftwareOne is listed on the SIX Swiss Exchange under the ticker symbol SWON. Visit us at https://www.softwareone.com/en\nThe role\nDATA Scientist\nThe primary focus for a candidate will be in applying different techniques (data mining/statistical analysis/build prediction systems/recommendation systems) using large company data sets to find opportunities for services and products and using models to test the effectiveness of different courses of action. The Candidate must have strong experience using a variety of data mining/data analysis methods, using a variety of data tools, building and implementing models, using/creating algorithms and creating/running simulations.\nWork with business cases to identify opportunities for leveraging company data to drive business solutions.\nMine and analyze data from company databases to drive optimization and improvement of product development and sales techniques\nAssess the effectiveness and accuracy of new data sources and data gathering\nExtending company’s data with third party sources of information when needed\nUse predictive modeling to increase revenue generation, ad targeting and other business outcomes.\nWhat We Need To See From You\nCore:\nAnalyze business cases and identify data sources (internal/external) and data mining/analysis methods to use\nDevelop a normalization engine to execute cleansing/deduplication for a raw data through ETL process for data sources\nCreate, train and test predictive models to solve defined business cases\nDevelop algorithms to apply to data sets\nDesign data structure models for collected data\nFacilitate the build of a solution from PoC to production\nWork with business owners to gather additional information about business cases\nJob Specific:\nWork with Google Cloud data and AI tools\nBe ready to work in agile style (daily, sprint planning, sprint review, retrospective)\nWork in an environment that adapts quickly to creative change using agile principles\nActively work with different development groups inside of organization\nBe ready to adapt a new tool/library/technology/platform\nDesirable Skills:\nFluent in French and English\nAt least 4 years experience in Machine learning models creation\nMaster’s in Statistics, Mathematics, Computer Science preferred\nProfessional Machine learning engineering certification\nExperience with common data science toolkits and libraries, such as pandas, keras, scipy, scikit, tensorflow, NumPy etc\nKnowledge and interest in the following:\nprediction models, Vertex AI, Tenserflow, BigQuery ML, Python,\nnatural language processing, deep learning models, dataPROC, Hadoop, SQL\nExperience using statistical computer languages namely Python to manipulate data and draw insights from large data sets\nStrong knowledge and experience using SQL language\nExperience with C++/C# and Java as a plus\nBackground in technology or professional services preferably in one or more of the domains of GCP and Security,\nStrong understanding of consulting business\nStrong structural work methods, multitasking and time management skills\nSelf-driven independent work ethics that drives internal and external accountability\nMay require periodic travel for workshops\nJob Function\nSoftware & Cloud Services\nShow more\nShow less",
        "details": {
            "JobDetail": [],
            "TypeContract": "",
            "Salary": "",
            "Level": "",
            "Experience": null
        },
        "title": "data scientist",
        "skills": {
            "ProgLanguage": [
                "Java",
                "Python"
            ],
            "DataBase": [
                "SQL"
            ],
            "DataAnalytics": [
                "NumPy",
                "Pandas"
            ],
            "BigData": [
                "Hadoop"
            ],
            "MachineLearning": [
                "TensorFlow",
                "Keras"
            ],
            "CloudComputing": [
                "GCP"
            ],
            "DBMS": [
                "BigQuery"
            ],
            "Other": [
                "Machine Learning",
                "Cloud",
                "ML"
            ],
            "EnSoftSkils": [
                "Time Management",
                "Organization"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "Capital Fund Management (CFM)",
        "location": "Paris, Île-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/data-scientist-at-capital-fund-management-cfm-3911800992?position=4&pageNum=2&refId=EAisFcfNV4WNL6Xe9UKYqQ%3D%3D&trackingId=VcFHLZSmJrY3LMj3cbA0Vw%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "ABOUT CFM\nFounded in 1991, we are a global quantitative and systematic asset management firm applying a scientific approach to finance to develop alternative investment strategies that create value for our clients.\nWe value innovation, dedication, collaboration and the ability to make an impact and together we create an environment for talented and passionate experts in research, technology and business to explore new ideas and challenge assumptions.\nABOUT THE ROLE\nThe context :\nData is the fuel that powers our investment strategies: intraday price dynamics are used to better our investment decisions; buy/sell intents of market participants help to trade at the best available price… Cfm Data team is in charge of preparing the data to make quant research easier and trading more reliable.\nThe position\nAs a Data Scientist and Tick Data Specialist, your involvement will be crucial to the effectiveness of our strategies. You will be tasked with identifying and specifying new input features from tick data to fuel our alpha predictor, constructing data pipelines, and guaranteeing their smooth functioning. This role necessitates strong collaboration with researchers, primarily aimed at furnishing them with essential data and tools to refine our trading strategies.\nKey Responsibilities:\nYou collaborate with the research team to innovate and introduce new predictive features,\nYou provide functional and technical support to quantitative researchers,\nYou design and develop data pipelines,\nYou contribute to the enhancement of our platform tooling.\nSKILLSET REQUIREMENTS/QUALIFICATIONS\nYou boast significant experience in financial markets, with a tenure of 7 years or more.\nYou have a comprehensive expertise in Matching Engines, Orderbooks, and High-Frequency Data,\nYou demonstrate recognized expertise in data science with a thorough mastery of its tools.\nYour familiarity with big data technologies like Spark or Dask, coupled with proficiency in machine learning, would be highly advantageous.\nExperience with C++ is considered an additional asset.\nYou exhibit a strong enthusiasm for technology.\nAs a collaborative team player, you excel in communication, particularly with quant teams.\nProficiency in French is an additional advantage.\nEQUAL OPPORTUNITIES STATEMENT\nWe are continuously striving to be an equal opportunity employer and we prohibit any discrimination based on sex, disability, origin, sexual orientation, gender identity, age, race, or religion. We believe that our diversity, breadth of experience, and multiple points of view are among the leading factors in our success.\nCFM is a signatory of the Women Empowerment Principles\nFOLLOW US\nFollow us on Twitter and LinkedIn or visit our website to find out more about CFM.\nShow more\nShow less",
        "details": {
            "JobDetail": [],
            "TypeContract": "",
            "Salary": "",
            "Level": "",
            "Experience": null
        },
        "title": "data scientist",
        "skills": {
            "BigData": [
                "Spark"
            ],
            "Collaboration": [
                "Teams"
            ],
            "Other": [
                "Machine Learning",
                "Big Data"
            ],
            "EnSoftSkils": [
                "Communication",
                "Collaboration"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "METEOJOB by CleverConnect",
        "location": "Rontignon, Nouvelle-Aquitaine, France",
        "link": "https://fr.linkedin.com/jobs/view/data-scientist-f-h-at-meteojob-by-cleverconnect-3916294538?position=5&pageNum=2&refId=EAisFcfNV4WNL6Xe9UKYqQ%3D%3D&trackingId=j16vTOYQSrY1mtDyF6apzQ%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Entreprise\nCabinet de recrutement de dimension internationale, bénéficiant de l'expérience d'un grand Groupe RH, S&you est spécialisé dans le recrutement d'Experts, Cadres et Métiers du tertiaire. Nos 50 consultants expérimentés mettent en œuvre tout notre savoir-faire pour vous accompagner au mieux dans vos projets (recrutement, bilan professionnel, coaching, formation…). La relation de confiance que nous créons avec nos candidats et nos clients représente pour nous le facteur-clé de la performance.\nDescription Du Poste\nVotre profil Vous disposez des compétences et aptitudes nécessaires à l'appropriation du périmètre du poste :\nFormation supérieure Bac + 5 (statistiques, mathématiques appliquées …)\nExpérience significative (2 ans alternance incluse) en qualité de data scientist / data analyst incluant idéalement une expérience en secteur assurantiel.\nMaîtrise / connaissance de l'environnement technique : Python, SQL, R, algorithmes et frameworks, machine learning, RPA, datavisualisation (Power BI, Tableau)\nCuriosité, discernement, agilité et esprit d'initiative : appropriation de données complexes, compréhension de problématiques transverses, veille technologique, proposition de solutions\nDescription Du Profil\nNotre client est un acteur clé du secteur assurantiel dont les 250 collaborateurs accompagnent les compagnies et intermédiaires d'assurance sur l'ensemble des sujets intéressant la profession (information, concertation, mise en œuvre) : assurance de biens et responsabilités, assurance de personne, réassurance, co-assurance, évolutions réglementaires et conventionnelles, maîtrise des risques, médiation, intermédiation, référentiels …Notre client recrute un.e Data Scientist dans le cadre d'une création de poste (CDI) en vue d'accompagner le développement de sa stratégie Data.\nShow more\nShow less",
        "details": {
            "JobDetail": [],
            "TypeContract": "CDI",
            "Salary": "",
            "Level": "",
            "Experience": "2 an(s)"
        },
        "title": "data scientist",
        "skills": {
            "ProgLanguage": [
                "R",
                "Python"
            ],
            "DataBase": [
                "SQL"
            ],
            "DataAnalytics": [
                "R"
            ],
            "DataVisualisation": [
                "Power BI",
                "Tableau"
            ],
            "Other": [
                "Statistiques",
                "Machine Learning"
            ],
            "EnSoftSkils": [
                "Initiative"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "HackerPulse",
        "location": "France",
        "link": "https://fr.linkedin.com/jobs/view/machine-learning-engineer-at-hackerpulse-3917868826?position=7&pageNum=2&refId=EAisFcfNV4WNL6Xe9UKYqQ%3D%3D&trackingId=ZnU7XW04Z7AJsOBxKX8wOQ%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Showcase your software engineering talents using ML-powered profiles. Loved by 11k+ engineers! Backed by Antler.\nThe Role\nYou Will Be Responsible For\nDeveloping scripts to process structured and unstructured data.\nRecommending, developing and implementing ways to improve data reliability, efficiency and quality.\nSupporting translation of data business needs into technical system requirements.\nWorking with stakeholders to understand needs in order with respect to data structure, availability, scalability and accessibility.\nDeveloping high-quality code to build and deploy machine learning models.\nIdeal Profile\nYou possess a degree in Computer Science, Applied Mathematics, Engineering or related field.\nYou have at least 1 year experience, ideally within a Data Engineer role.\nDemonstrated experience working with large and complex data sets as well as experience analyzing volumes of data.\nYou are a strong networker & relationship builder\nYou pay strong attention to detail and deliver work that is of a high standard\nYou are a self-starter and demonstrate a high level of resilience\nWhat's on Offer?\nGreat work environment\nExcellent career development opportunities\nLeadership Role\nShow more\nShow less",
        "details": {
            "JobDetail": [],
            "TypeContract": "",
            "Salary": "",
            "Level": "",
            "Experience": null
        },
        "title": "machine learning engineer",
        "skills": {
            "Other": [
                "Machine Learning",
                "ML"
            ],
            "EnSoftSkils": [
                "Leadership"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "MP DATA",
        "location": "Clermont-Ferrand, Auvergne-Rhône-Alpes, France",
        "link": "https://fr.linkedin.com/jobs/view/data-scientist-h-f-at-mp-data-3904074177?position=8&pageNum=2&refId=EAisFcfNV4WNL6Xe9UKYqQ%3D%3D&trackingId=chgwalNrt%2BjVYc%2BI5vYZHw%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "MP DATA est une société spécialisée dans l’acquisition, le traitement, et la valorisation des données. Depuis sa création en 2015, MP DATA accompagne ses clients, majoritairement industriels, dans le management de leur performance et l’exploitation de leur donnée.\nLes collaborateurs, tous issus de grandes écoles, incarnent au quotidien les valeurs d’Excellence, de Partage et d’Engagement. Ils associent savoir-faire technique, méthodologie et passion et mettent leurs compétences au service de missions et projets au sein de grands groupes français.\nMP DATA accompagne ses clients sur toute la chaine au travers de 3 pôles d’expertise : Conseil et Stratégie, Infrastructure & CloudOPS, Data Science.\nNous recherchons un(e) Data Scientist passionné(e) pour rejoindre notre équipe dynamique.\nEn tant que membre clé du pôle Data Science de notre client, un grand acteur du secteur automobile, vous serez chargé(e) d'analyser, interpréter et exploiter les données pour fournir des solutions innovantes à nos clients.\nConception et mise en œuvre de modèles prédictifs et d'algorithmes avancés.\nAnalyse approfondie des données pour identifier des tendances et des opportunités.\nCollaboration étroite avec les équipes clients pour comprendre leurs besoins et définir des solutions sur mesure.\nParticipation active à la veille technologique et à l'amélioration continue de nos pratiques en Data Science.\nProfil :\nDiplôme\ningénieur Grande École\nen Data Science, Statistiques, Informatique ou domaine connexe.\nExpérience pratique dans le développement et l'application de modèles prédictifs,\nMaîtrise des langages de programmation tels que Python,\nExcellentes compétences analytiques et capacité à traduire des résultats complexes en recommandations claires,\nForte aptitude à travailler en équipe et à communiquer efficacement.\nShow more\nShow less",
        "details": {
            "JobDetail": [],
            "TypeContract": "",
            "Salary": "",
            "Level": "",
            "Experience": null
        },
        "title": "data scientist",
        "skills": {
            "ProgLanguage": [
                "Python"
            ],
            "Other": [
                "Statistiques"
            ],
            "EnSoftSkils": [
                "Collaboration"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "Pathway",
        "location": "Paris, Île-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/data-scientist-python-mid-senior-senior-at-pathway-3887683294?position=9&pageNum=2&refId=EAisFcfNV4WNL6Xe9UKYqQ%3D%3D&trackingId=AG47%2Fhm4cbgAjP6i4KQGBw%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "About Pathway\nDeeptech start-up, founded in March 2020.\nOur primary developer offering is an ultra-performant Data Processing Framework (unified streaming + batch) with a Python API, distributed Rust engine, and capabilities for data source integration & transformation at scale (Kafka, S3, databases/CDC,...)\nThe single-machine version is provided on a free-to-use license (`pip install pathway`)\nMajor data use cases are around event-stream data (including real-world data such as IoT), and graph data that changes over time\nOur enterprise offering is currently used by leaders of the logistics industry, such as DB Schenker or La Poste, and tested across multiple industries. Pathway has been featured in Gartner's market guide for Event Stream Processing\nLearn more at http://pathway.com/ and https://github.com/pathwaycom/\nPathway is VC-funded, with amazing BAs from the AI space and industry. We have operations across Europe and in the US. We are headquartered in Paris, with significant support from the French ecosystem (BPI, Agoranov, WILCO,...).\nThe Team\nPathway is built by and for overachievers. Its co-founders and employees have worked in the best AI labs in the world (Microsoft Research, Google Brain, ETH Zurich), worked at Google, and graduated from top universities (Polytechnique, ENSAE, Sciences Po, HEC Paris, PhD obtained at the age of 20, etc...). Pathway's CTO is a co-author with Goeff Hinton and Yoshua Bengio. The management team also includes the co-founder of Spoj.com (1M+ developer users) and NK.pl (13.5M+ users) and experienced growth leader who has scaled companies with multiple exits.\nThe opportunity\nWe are currently searching for\nData Scientists\nwith\nexperience in the Python stack\n, to help explore and discover the most pertinent insights in datasets on spatio-temporal event streams. In this job, statistical rigor and beauty of visualization meet on equal footing.\nYou Will\nbe working with spatiotemporal data with advanced schemas (time-changing graph models)/\nbe designing data cross-sections, proposing analytics metrics and KPI's in line with clients' objectives, selecting clustering algorithms, and preparing visualizations, to enable fast data exploration and insight discovery - all within our product\nbe designing dashboards in SQL with some Python elements/extensions\nbe directly helping us with Customer Conversion and Adoption within Customer organizations, by contributing to both deployment instances and \"demonstrators\" of our product, performed on client data sets\nwork directly with our Product Owner and CTO to propose and implement extensions to our product, based on repetitive client needs\ndepending on your seniority, implement machine learning algorithms on spatiotemporal event streams and other geospatial data\nThe results of your work will play a crucial role in proving how our technology can help with compelling industry use cases.\nRequirements\nYou Are\nReady for hands-on contribution to the product, helping to ensure the success of demonstrators for clients, and contribution to product codebase\nIntuitive, with good visual taste, and good common sense judgment\nCommitted to beautiful user-centered design: you know that stories are made for people, and you are willing to listen to what they have to say\nCurious at heart and thrilled to work with real-world data, especially spatio-temporal data\nLike trains, trucks, cranes, pythons, pandas, and other things that move\nNot afraid to switch between the roles of data scientist, data-vis magician, statistician, engineer, and detective, at a moment's notice\nHave 2 years+ experience in positions related to Data Science.\nHave a very good working knowledge of Python\nKnow SQL. Are able to work with tables and other data types (arrays, json,...)\nWould be able to implement the Transit Node Routing algorithm in Python just based on reading its Wikipedia article\nHave experience with git, build systems, and CI/CD\nHave at least basic undergrad textbook familiarity with graph algorithms, finite automata, and text (string) search algorithms\nUnderstand statistical concepts, such as correlated random variables, significance, and non-Gaussian noise\nPrepared to be quizzed & grilled by the datasets you encounter, everyday. Here are some questions you should be able to answer off the top of your head: what can \"-273.15\" signify; why \"65535\" is a suspicious integer value; how many months does it take a containership to go around the world; and, roughly what order of g-force is attained by an astronaut in a space rocket at liftoff?\nRespectful of others\nFluent in English\nBonus Points\nShowing a portfolio: code on github, visualization works, a research paper or a PhD thesis with an original statistical / probabilistic analysis or experiment design,..\nSuccessful track-record in Data Science or algorithms contests (Kaggle, Codeforces,...)\nExperience in topics linked to logistics/moving assets\nFamiliarity with some form of GIS software\nFamiliarity with Pandas, SciPy, NetworkX, and similar tools from the Python stack\nExperience in Data Visualization and UX\nSome knowledge of French, Polish, or German\nWhy You Should Apply\nJoin an intellectually stimulating work environment\nBe a pioneer: you get to work with a new type of data processing\nWork in one of the hottest data/AI startups in France\nUncover exciting career prospects\nMake significant contribution to our success\nJoin & co-create an inclusive workplace culture\nBenefits\nType of contract: Permanent employment contract\nPreferable joining date: February 2023. The positions (at least 2) are open until filled\nCompensation: annual salary of €50K-€70K (mid) up to €60K-€90K (senior, upper band negotiable) + Employee stock option plan\nLocation: Remote work from home. Possibility to work or meet with other team members in one of our offices:\nParis Area - Drahi X-Novation Center, Ecole Polytechnique, Palaiseau\nParis - Agoranov (where Doctolib, Alan, and Criteo were born) near Saint-Placide Metro (75006)\nWroclaw - University area\nPermanent residence will be required in France or Poland, exceptional candidates will be considered anywhere in the EU.\nIf you meet our broad requirements but are missing some experience, don't hesitate to reach out to us.\nNote\n: CS & engineering school students with exceptional profiles and/or strong motivation to join Pathway are invited to apply for Data Science internships. (Minimum duration: 5-6 months, remuneration level: €1500 / month.)\nShow more\nShow less",
        "details": {
            "JobDetail": [
                "Remote",
                "Senior"
            ],
            "TypeContract": "",
            "Salary": "50K",
            "Level": "",
            "Experience": null
        },
        "title": "data scientist",
        "skills": {
            "ProgLanguage": [
                "Python"
            ],
            "DataBase": [
                "SQL"
            ],
            "DataAnalytics": [
                "Pandas"
            ],
            "DataSerialization": [
                "Json"
            ],
            "DevTools": [
                "Git"
            ],
            "Other": [
                "Machine Learning",
                "CI/CD"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "OUTSCALE",
        "location": "St.-Cloud, Île-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/data-scientist-f-h-at-outscale-3891855564?position=10&pageNum=2&refId=EAisFcfNV4WNL6Xe9UKYqQ%3D%3D&trackingId=vwPlZ7yIsbbe4%2FseNig%2F4g%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "OUTSCALE, marque de Dassault Systèmes, est un opérateur souverain et durable de l Expérience en tant que Service qui offre à ses clients des environnements technologiques de confiance.\nNous offrons des expériences uniques grâce au savoir-faire de nos équipes passionnées, qui se reflète notamment par la création de solutions de Business Expériences, le développement de notre propre orchestrateur Cloud, TINA OS, ou encore l obtention de la qualification SecNumCloud.\nNotre mission ? Bâtir un monde numérique accessible et meilleur pour tous à travers la création du jumeau virtuel de l organisation.\nNous menons une politique RH engagée et inclusive favorisant le bien-être de nos collaborateur·rices : respect de l équilibre vie privée/vie professionnelle, développement personnel et des compétences professionnelles, onboarding complet\nNous rejoindre, c est partager une passion pour l innovation, des valeurs communes et imaginer ensemble des solutions de confiance pour construire un monde meilleur et durable !\nNous recrutons\nun·e\nData Scientist\nafin de renforcer notre équipe\nBusiness Experience\n.\nVos missions\nAnalyser des problématiques et proposer des solutions.\nModéliser, implémenter et évaluer des algorithmes.\nTraiter des données non structurées.\nOptimiser des modèles ML/DL pour la scalabilité, l'efficacité et les performances.\nIndustrialiser des algorithmes dans les services API.\nDéployer des services sur le cloud.\nParticiper à la rédaction de spécifications et documentations techniques.\nParticiper à des événements et publications scientifiques.\nStack technique\nPython\nFrameworks ML/DL (Pytorch)\nArchitectures de réseaux neuronaux (LLMs)\nImplémentation d’algorithmes ML/DL (apprentissage supervisé/non-supervisé)\nVotre profil:\nDiplômé·e d’un Master en Intelligence Artificielle, Machine Learning.\n3 ans d’expérience minimum post-diplôme dans le domaine de l’IA, Data Science, Machine Learning, NLP, Computer Vision.\nVous maîtrisez l’analyse et la transformation des données.\nIdéalement, vous avez de l’expérience dans le déploiement des modèles ML/DL sur le cloud.\nMotivé·e, organisé·e, curieux·se, vous appréciez travailler en équipe.\nLa Diversité d’OUTSCALE trouve aussi son expression dans notre politique de recrutement qui privilégie l’égalité des chances, la diversité des individus au sein de nos équipes.\nShow more\nShow less",
        "details": {
            "JobDetail": [],
            "TypeContract": "",
            "Salary": "",
            "Level": "",
            "Experience": "3 an(s)"
        },
        "title": "data scientist",
        "skills": {
            "ProgLanguage": [
                "Python"
            ],
            "MachineLearning": [
                "PyTorch"
            ],
            "Other": [
                "Machine Learning",
                "Cloud",
                "ML"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "Talan",
        "location": "Paris, Île-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/data-scientist-confirm%C3%A9-s%C3%A9nior-h-f-cdi-at-talan-3909648101?position=1&pageNum=5&refId=W%2BmbKJ%2BzlSnYV3NZlNoxRw%3D%3D&trackingId=5E17rP97%2FIQpNuN8X8ff9A%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Talan est un groupe international de conseil en transformation et en innovation par la technologie, créé en 2002.\nNos 5000 consultantes et consultants partagent à travers le monde l’audace d’innover, le goût de l’excellence, et l’envie de relever les défis les plus complexes.\nNous accompagnons les entreprises dans des secteurs variés : énergie, industrie, transport, finance, luxe… à travers 3 grandes expertises :\nLe Conseil en Management et Innovation (320 Consultants en France)\nLa valorisation des données, leurs structurations, et leurs usages (Data et Technologies)\nL’intégration de solutions logicielles (Cloud et Applications Services)\nNos valeurs : engagement, respect, partage, esprit d’équipe et optimisme.\nTalan est une entreprise responsable, reconnue par ses collaborateurs et attachée à la diversité. Des aménagements peuvent être proposés si vous êtes en situation de handicap.\nRetrouvez nos engagements RSEiciet nos actions en faveur de la diversitéici\nJob Description\nNous sommes à la recherche d’un Data Scientist capable de participer à des projets techniques Data Science et IA. Vous devrez faire preuve d’un état d’esprit à la fois innovant, méthodique, orienté solution (et non problème!), et communiquant.\nVotre but ultime sera de garantir l’excellence de vos solutions Data Science/IA, pièces maitresses de la réalisation de projets disruptifs pour nos clients.\nVOTRE ROLE SUR NOS PROJETS\n:\nEn mission: analyse des besoins métiers, définition des principes et méthodes de collecte et de traitement des données, choix des modèles de Machine Learning ou de Deep Learning, mise en application des techniques de traitement et de visualisation de la data, restitution des analyses et résultats obtenus auprès des métiers et des sponsors\nPartager techniquement les membres de l’équipe: solutions et code reviews, recommandations, certifications à réaliser, …\nParticipation à des meet-up, coding dogo,…\nCommunication: écriture d’articles, retours d’expérience…\nVOTRE ROLE CHEZ TALAN :\nBenchmark de solutions et conseil auprès de nos clients sur les solutions technologiques à adopter, en lien avec leurs besoins\nRéalisation de POC (Proof Of Concept)\nParticipation à des projets internes et partage de connaissances au sein de nos équipes.\nPartage de connaissances et formations interne\nQualifications\nVOTRE PROFIL:\nIssu d’une formation Grande École d’Ingénieur/Doctorant, spécialisée en Data Science ou Intelligence Artificielle\nVous disposez d’au moins 3 années d’expérience dans le domaine\nMaitrise des techniques d’analyses statistiques, de modélisations prédictives, de Machine Learning, de Deep Learning,...\nMaitrise des techniques de data management et de DataViz\nMaitrise de Python, R, RShiny, SQL…\nMaitrise de l’utilisation des outils DevOps: Git, Docker, Jenkins/Nexus,…\nBonnes connaissances Big Data: pySpark, Spark, NoSQL…\nConnaissance d’outils tels que Dataiku, AWS SageMaker, Azure ML,…\nAutonomie, organisation, sens du partage\nExcellente communication\nOrientation métier\nAdditional Information\nAVANTAGES\n:\nPlan de formation pour accompagner votre carrière (formations éditeurs, certifications) grâce à nos partenariats nous accordant une position de partenaire privilégié, et management de proximité par des experts\nLocaux modernes en centre-ville\nTop 5 du Palmarès Great Place to Work\nTélétravail jusqu’à 5 jours selon les missions, prime d’équipement de 100€\nMobilité en France et à l’étranger\nTop 1% des entreprises évaluées par Ecovadis dans le domaine social, environnemental et éthique\nTickets restaurant, prime vacances, 50% transport (abonnement transport public), mutuelle\nPermanence handicap (consultant dédié aux collaborateurs en situation de handicap et aux proches aidants)\nActionnariat salarié\nPrime de cooptations\nRTT\nPROCESS RECRUTEMENT\n:\nL’équipe recrutement s’engage à vous proposer un processus de recrutement rapide et fluide\n1 entretien RHpar Teams (45min)\n1 test technique\n1 entretien opérationnel avec le responsable de domaine, au siège (1heure)\n1 entretien avec le directeur de pôle, au siège(1heure)\nShow more\nShow less",
        "details": {
            "JobDetail": [],
            "TypeContract": "",
            "Salary": "",
            "Level": "",
            "Experience": null
        },
        "title": "data scientist",
        "skills": {
            "ProgLanguage": [
                "R",
                "Python"
            ],
            "DataBase": [
                "SQL",
                "NoSQL"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [
                "Spark"
            ],
            "CloudComputing": [
                "AWS",
                "Azure"
            ],
            "DevTools": [
                "Git",
                "Docker",
                "Jenkins"
            ],
            "Containers": [
                "Docker"
            ],
            "Collaboration": [
                "Teams"
            ],
            "Other": [
                "ML",
                "Big Data",
                "Statistiques",
                "Machine Learning",
                "Cloud",
                "DevOps"
            ],
            "EnSoftSkils": [
                "Communication"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "Assurances Crédit Mutuel",
        "location": "Strasbourg, Grand Est, France",
        "link": "https://fr.linkedin.com/jobs/view/data-scientist-h-f-at-assurances-cr%C3%A9dit-mutuel-3881495295?position=2&pageNum=5&refId=W%2BmbKJ%2BzlSnYV3NZlNoxRw%3D%3D&trackingId=J7Bg515clDdz2SFaUDGZYQ%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Qui sommes nous\nDepuis 1971, nous imaginons, concevons et orientons les offres et services qui contribuent au développement de l’activité assurance de Crédit Mutuel Alliance Fédérale, inventeur du concept de bancassurance.\nLes Assurances du Crédit Mutuel sont présentes sur les marchés des assurances de biens, des assurances de personnes comme de l’assurance-vie. Nous proposons des solutions à tous ceux qui désirent se protéger et anticiper demain, qu’ils soient particuliers, professionnels ou entreprises.\nCe sont nos valeurs mutualistes et notre philosophie innovante qui guident nos actions. Loin de nous contenter de couvrir nos assurés aujourd’hui, nous cherchons à prévenir les risques futurs et à construire une assurance de demain plus juste.\nLes Assurances du Crédit Mutuel, ce sont ainsi environ 3500 talents au service de près de 13 millions d’assurés, générant un chiffre d’affaires de 13,9 milliards d’euros. Nos offres et services sont principalement distribués par les réseaux bancaires Crédit Mutuel, CIC et Cofidis. Nous sommes parmi les acteurs majeurs de l’assurance en France.\nRejoindre les Assurances du Crédit Mutuel, c’est rejoindre un groupe qui porte haut et fort ses valeurs et où l’humain est toujours au centre. C’est rejoindre une entreprise où les innovations sont sources de simplicité et de solidarité et où chacun est engagé pour une société plus juste et plus durable. Intégrer les ACM c’est également intégrer le groupe Crédit Mutuel Alliance Fédérale et ses multiples opportunités de carrières.\nPourquoi nous recrutons\nDans un contexte de recherche constante d'une croissance responsable et durable, Les assurances du Crédit Mutuel continuent d'innover, de se développer et de renforcer leurs équipes dans de nombreux domaines.\nVos missions\nAu sein de la Direction du Développement, de la transformation et de la Communication, vous intégrez l'équipe « Data et connaissance client » pour mener des projets de data science visant à accompagner la transformation de l'entreprise et favoriser le développement via l’analyse des profils clients.\nEn intégrant cette équipe, vous prendrez en main des projets de data science, avec le cadrage des problématiques, le recueil et l’analyse des données nécessaires. Vous testerez et comparerez différents modèles et études de performances.\nVous jouerez un rôle majeur dans la connaissance et l’anticipation des besoins de nos clients et travaillerez ainsi en relation avec les autres services de la direction (marketing, parcours client, projets digitaux, …), avec les différents services métiers des ACM et la direction commerciale du Groupe.\nVous serez aussi amené(e) à mener des études en collaboration avec d’autres Data Scientists du Groupe.\nActivités / Tâches spécifiques du poste\nVos missions seront entre autres les suivantes :\nDétenir, comprendre et exploiter la connaissance client\nProposer et développer des outils statistiques prédictifs et prescriptifs tels que des scores d’appétence ou d’attrition en mettant en œuvre des techniques de type scoring et segmentation via l’utilisation de méthodes classiques (régression logistique …) ou plus innovantes de type machine learning (random forest …).\nAnalyser, interpréter et synthétiser les données pour dégager des tendances et constats qui alimenteront la compréhension et la réflexion au sein de la direction dans le cadre d’études spécifiques (profils clients …).\nIdentifier les données existantes et de nouvelles sources de données pertinentes à collecter pour enrichir la connaissance client et modéliser leur comportement (données internes ou externes, structurées ou non structurées).\nEtablir les suivis de l’activité commerciale et analyser les performances des actions commerciales et marketing pour améliorer leur efficacité.\nParticiper à différentes missions de type veille et partage de connaissance\nAssurer une veille active sur les sujets de type Big Data et modélisation de données.\nAider au partage de bonnes pratiques au sein du groupe en tant qu’expert des données et des méthodes de modélisation.\nContribuer à la diffusion des travaux de l’équipe au sein de l’entreprise\nPouvoir représenter l'activité en intervenant dans des groupes de travail transverses.\nRestituer et communiquer régulièrement les résultats des analyses et les préconisations associées de manière rigoureuse, pédagogique, accessible et exploitable\nCe que vous allez vivre chez nous\nConcrètement, aux Assurances du Crédit Mutuel, nos collaborateurs bénéficient:\nD'une rémunération fixe versée sur 13 mois\nDe l'intéressement, participation et de l'abondement pouvant atteindre plus de deux mois de salaire en fonction des résultats du groupe\nD'un plan épargne entreprise (PEE), d’un plan épargne retraite collectif (PERECOL) et d’un compte épargne temps (CET),\nD'un rythme de travail adapté fort d'un accord QVT groupe qui permet de télétravailler jusqu'à deux jours par semaine\nDe 22 jours de RTT par an selon le rythme de travail défini\nD'une politique de protection sociale renforcée (régimes de remboursement de frais de santé et de prévoyance)\nD'un régime de retraite supplémentaire (PERO) prise en charge à 100% par l’employeur\nDe conditions bancaires et assurances préférentielles\nD'une politique parentale avantageuse\nD'un parcours d'intégration pour tout nouvel arrivant\nD'au moins une action de formation chaque année (95% des salariés)\nD'un accompagnement pour favoriser votre mobilité géographique et fonctionnelle.\nCe que nous allons aimer chez vous\nConnaissances et compétences\nDe formation supérieure Bac+5 minimum orientée statistiques, mathématiques, Data Science.\nUn minimum de six ans d’expérience à un poste équivalent est demandé.\nVous possédez une expertise confirmée en Python (pandas, scikit-learn) ainsi que des connaissances poussées en Data Science (random forest, boosting, classification …).\nVous maîtrisez des langages / outils de traitement et d’analyse de données (SQL, SAS, Excel, …)\nVous possédez des compétences en présentation (PowerPoint) et êtes capable de mettre en valeur votre travail.\nUne expérience en assurance constituerait un plus.\nUne expérience en compétition de Data Science ou programmation (Kaggle, leetcode ...) constituerait un plus.\nSavoir-être - savoir-faire\nVous appréciez le travail en équipe et faîtes preuve d'une bonne aisance relationnelle.\nCurieux, vous possédez un bon esprit d'initiative et vous tenez au courant des dernières nouveautés en terme de Data Science.\nVous possédez un esprit analytique et créatif et êtes en mesure d’imaginer et de proposer des solutions innovantes.\nRigoureux et autonome, vous disposez d'excellentes capacités d'analyse et de synthèse.\nShow more\nShow less",
        "details": {
            "JobDetail": [
                "Confirmé"
            ],
            "TypeContract": "",
            "Salary": "22",
            "Level": "Bac+5",
            "Experience": null
        },
        "title": "data scientist",
        "skills": {
            "ProgLanguage": [
                "Python"
            ],
            "DataBase": [
                "SQL"
            ],
            "DataAnalytics": [
                "Pandas"
            ],
            "MachineLearning": [
                "Scikit-Learn"
            ],
            "Other": [
                "Statistiques",
                "Machine Learning",
                "Big Data"
            ],
            "EnSoftSkils": [
                "Initiative",
                "Communication",
                "Collaboration"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "METEOJOB by CleverConnect",
        "location": "Rennes, Brittany, France",
        "link": "https://fr.linkedin.com/jobs/view/data-scientist-h-f-at-meteojob-by-cleverconnect-3907968677?position=3&pageNum=5&refId=W%2BmbKJ%2BzlSnYV3NZlNoxRw%3D%3D&trackingId=92xzcUc%2BQLQedngjK8RfNg%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Entreprise\nQui sommes-nous ?\nNous sommes passionnés par les nouvelles technologies, et vous ?\nRejoindre Amiltone, c'est intégrer des équipes dynamiques et soudées dans le cadre de projets novateurs et ambitieux. Nous relevons les challenges techniques de nos clients et les accompagnons dans leur transformation digitale.\nPourquoi choisir Amiltone ?\nAmiltone, plus qu'une entreprise, un état d'esprit !\nNotre objectif ? Votre épanouissement professionnel !\nNous Avons à Cœur De\nVous accompagner au mieux au travers d'un suivi personnalisé\nVous faire monter en compétences en vous proposant des formations tout au long de votre carrière\nComprendre vos besoins et respecter nos engagements\nVous proposer des missions de qualité avec des technologies innovantes\nCultiver votre potentiel grâce à notre programme de développement personnel Addvise\nVotre bien-être passe aussi par des activités extraprofessionnelles, c'est pourquoi nous vous proposons des séances sportives animées par nos coachs, soirées pour se retrouver et animations (à l'agence ou en visio), Gaming nights...\nDescription Du Poste\nVos missions ?\nIntégré à notre équipe de 10 personnes, vous assurez les missions suivantes :\nRéceptionner et analyser la donnée brute\nTraiter la donnée en streaming ou en statique\nAdapter ou créer des modèles de machine learning\nEvaluer la précision/robustesse d'un modèle\nOutils de monitoring et de visualisation\nDéveloppement des modèles\nMaintenir et documenter les codes et les process\nLa stack Technique :\nOutils : MongoDB, PostgreSQL\nNLP (IA générative)\nQlik Sense\nDocker, Jenkins\nGitlab/Github\nDescription Du Profil\nAlors ? Prêt à devenir Amiltonien ?\nN'hésitez Pas à Postuler Si Vous Vous Reconnaissez\nDiplômé bac+5 (école d'ingénieur ou master), vous avez au moins 2 ans d'expérience en tant que Data Scientist.\nVous aimez découvrir de nouveaux contextes fonctionnels et comprendre les objectifs des applications que vous développez.\nA l'aise dans une organisation agile, vous faites preuve de rigueur et appliquez les standards de qualité Amiltone durant toute la durée des développements.\nOutre vos compétences techniques, nous nous intéressons également à votre potentiel et votre motivation.\nNos postes sont ouverts aux personnes en situation de handicap.\nShow more\nShow less",
        "details": {
            "JobDetail": [],
            "TypeContract": "",
            "Salary": "",
            "Level": "Bac+5",
            "Experience": "2 an(s)"
        },
        "title": "data scientist",
        "skills": {
            "DataBase": [
                "MongoDB"
            ],
            "DevTools": [
                "Jenkins",
                "Docker"
            ],
            "DBMS": [
                "PostgreSQL"
            ],
            "Containers": [
                "Docker"
            ],
            "Other": [
                "Machine Learning"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "Hugging Face",
        "location": "France",
        "link": "https://fr.linkedin.com/jobs/view/machine-learning-engineer-fast-optimized-inference-emea-remote-at-hugging-face-3848456024?position=4&pageNum=5&refId=W%2BmbKJ%2BzlSnYV3NZlNoxRw%3D%3D&trackingId=%2BGu1iJX1H6RIkBl8Ycwdvw%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Here at Hugging Face, we're on a journey to advance good Machine Learning and make it more accessible. Along the way, we contribute to the development of technology for the better.\nWe have built the fastest-growing, open-source, library of pre-trained models in the world. With more than 1 Million+ models and 320K+ stars on GitHub, over 15.000 companies are using HF technology in production, including leading AI organizations such as Google, Elastic, Salesforce, Algolia, Grammarly and NASA.\nAbout the role:\nAs a Machine learning Engineer, you work mainly on creating great libraries highly focused on real world ML use cases. We're building on top of our open-source to create more specialized code with a focus on industrial level of usage.\nWe are searching for someone who brings fresh ideas, demonstrates a unique and informed viewpoint, and enjoys collaborating with a progressive, nimble and decentralized approach to develop real-world solutions and positive user experiences at every interaction.\nObjectives of this role:\nDevelop specialized software for specific machine learning (ML) use cases that have broad applications, similar to [text-generation-inference](https://github.com/huggingface/text-generation-inference).\nUtilize existing library frameworks to create scalable software solutions for industrial purposes.\nEnhance the reliability, quality, and time-to-market of our software suite. Measure and optimize system performance to stay ahead of customer needs and drive innovation.\nManage the production environment by monitoring availability and ensuring overall system health. We run our own tools\nAbout you:\nIf you are a passionate Machine Learning Engineer with a keen interest in AI and proficient with Python, Rust and specialized Cuda kernels Frameworks (transformers of course + Keras or PyTorch), we would love to hear from you. Join our team and contribute to the advancement of AI technologies while working alongside talented professionals in a collaborative and stimulating environment.\nMore about Hugging Face\nWe are actively working to build a culture that values diversity, equity, and inclusivity\n.\nWe are intentionally building a workplace where people feel respected and supported—regardless of who you are or where you come from. We believe this is foundational to building a great company and community. Hugging Face is an equal opportunity employer and we do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.\nWe value development.\nYou will work with some of the smartest people in our industry. We are an organization that has a bias for impact and is always challenging ourselves to continuously grow. We provide all employees with reimbursement for relevant conferences, training, and education.\nWe care about your well-being\n.\nWe offer flexible working hours and remote options. We offer health, dental, and vision benefits for employees and their dependents. We also offer flexible parental leave and paid time off.\nWe support our employees wherever they are\n.\nWhile we have office spaces in NYC and Paris, we're very distributed and all remote employees have the opportunity to visit our offices. If needed, we'll also outfit your workstation to ensure you succeed.\nWe want our teammates to be shareholders\n.\nAll employees have company equity as part of their compensation package. If we succeed in becoming a category-defining platform in machine learning and artificial intelligence, everyone enjoys the upside.\nWe support the community\n.\nWe believe major scientific advancements are the result of collaboration across the field. Join a community supporting the ML/AI community.\nShow more\nShow less",
        "details": {
            "JobDetail": [
                "Remote"
            ],
            "TypeContract": "",
            "Salary": "Package",
            "Level": "",
            "Experience": null
        },
        "title": "machine learning engineer",
        "skills": {
            "ProgLanguage": [
                "Python"
            ],
            "MachineLearning": [
                "PyTorch",
                "Keras"
            ],
            "Other": [
                "Machine Learning",
                "ML"
            ],
            "EnSoftSkils": [
                "Organization",
                "Collaboration"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "ADHERENCE CONSULTING",
        "location": "Capinghem, Hauts-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/data-scientist-h-f-at-adherence-consulting-3913994542?position=5&pageNum=5&refId=W%2BmbKJ%2BzlSnYV3NZlNoxRw%3D%3D&trackingId=nODE9OBg72XqGPojQqUxag%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Adherence Consulting : Votre partenaire IT de choix !\nImplantés à Paris, Lille et Marseille, nous sommes au coeur de l'innovation technologique et organisationnelle.\nNotre mission ? Booster votre performance et vous accompagner dans chaque étape de votre transformation digitale.\nSi vous êtes prêt(e) pour une carrière qui dépasse vos attentes, c'est le moment !\nhttps://www.adherence-consulting.fr/\nLes missions du poste\nContexte\nAdhérence Consulting est une ESN implanté à Paris, Lille et Marseille. Nous sommes au coeur de l'innovation technologique et organisationnelle.\nNotre mission ? Booster les performances et accompagner nos clients à chaque étape de leur transformation digitale. Nous cherchons actuellement un Data Scientist (F/H) pour le projet de notre client.\nVous participerez à la construction de nombreux projets tous aussi ambitieux les uns que les autres.\nQuelles sont vos missions au quotidien ?\nApplique des techniques (statistiques, text mining, comportementale, géolocalisation,) d'extraction et d'analyse d'informations, obtenues à partir de gisements de données (Big Data)\nObtient des données adéquates, trouve les sources de données pertinentes, fait des recommandations sur les bases de données à consolider, modifier, rapatrier, externaliser, internaliser, conçoit des datamarts, voire des entrepôts de données (data warehouses).\nÉvalue la qualité et la richesse des données, les analyse et en restitue les résultats pour ensuite les intégrer dans le système d'information cible du Métier.\nAnalyse les données pour traduire une problématique Métier en problème mathématiques/statistiques et réciproquement.\nCompare et évalue différents modèles ou méthodes de calcul et anticipe les avantages et inconvénients dans un environnement Métier.\nIntervenant auprès des Métiers, il exploite, analyse et évalue la richesse, de données structurées ou non, appartenant à l'entreprise ou non, pour établir des scénarios permettant de comprendre et d'anticiper de futurs levier Métiers ou opérationnels pour l'entreprise\nShow more\nShow less",
        "details": {
            "JobDetail": [],
            "TypeContract": "",
            "Salary": "",
            "Level": "",
            "Experience": null
        },
        "title": "data scientist",
        "skills": {
            "Other": [
                "Statistiques",
                "Big Data"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "Astek",
        "location": "Île-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/ing%C3%A9nieur-data-scientist-%E2%80%93intelligence-artificielle-idf-france-h-f-at-astek-3886897805?position=6&pageNum=5&refId=W%2BmbKJ%2BzlSnYV3NZlNoxRw%3D%3D&trackingId=udgrvdt5xDGV5tEe9Y5h2Q%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Ce que nous allons accomplir ensemble :\nPour l’un de nos projets dans le domaine aéronautique, vous interviendrez en tant\nqu’ingénieur Data scientist / Intelligence artificielle\nsur la mise en place de systèmes experts destinés aux avions civils et militaires.\nVotre future équipe :\nTeam IT de 12 personnes\nData scientist, ingénieurs systèmes, intégrateurs, architectes\nVous travaillerez avec de véritables passionnés !\nVotre mission (...si vous l’acceptez !) :\nVous participerez au développement des fonctions d’analyses multisystèmes. Pour cela vous assurerez l’établissement d’une spécification formelles sur les modèles d’analyses.\nVous assurerez l’analyse des données et la proposition de méthodes pour le traitement des signaux.\nVous développerez les outils capables de traiter de manière automatique les données systèmes.\nVous assurerez la réalisation des scénarios, ainsi que les tests et simulations.\nVous réaliserez également une activité de support.\nVotre stack de jeu :\nData scientist, python, principe de gestion de configuration, et traçabilité, systèmes aéronautiques, intelligence artificielle\nLes petits plus du projet :\nVous évoluerez au sein d’équipes agiles impliquées et réactives.\nVous interviendrez de A à Z sur des projets riches fonctionnellement et ambitieux techniquement :\nforte volumétrie, haut niveau de performance, exigence maximale en termes d’intelligence artificielle et encore bien d'autres sujets captivants.\nVous ?\nDe formation Ingénieur, vous justifiez d’une expérience significative en Data scientist et ou Intelligence artificielle.\nUne connaissance des méthodes d’analyse de données serait un plus.\nIdéalement vous avez une connaissance des systèmes aéronautiques.\nDes postes également ouverts aux débutants si stages significatifs.\nNous ?\nCréé en France en 1988, Astek est un acteur mondial de l’ingénierie et du conseil en technologies, présent sur les 5 continents. Fort de son expertise dans de nombreux secteurs industriels et tertiaires, Astek accompagne ses clients internationaux dans le déploiement intelligent de leurs produits et de leurs services, et dans la mise en œuvre de leur transformation digitale.\nDepuis sa création, le Groupe a fondé son développement sur une forte culture d’entrepreneuriat et d’innovation, et sur l’accompagnement et la montée en compétence de ses 5 200 collaborateurs qui s’engagent chaque jour à promouvoir la complémentarité entre les technologies numériques et l’ingénierie des systèmes complexes.\nRejoignez un Groupe en fort développement en France et à travers le monde grâce à une levée de fonds de 200M€ réalisée en 2021. Ensemble « Let’s move forward! »\n✨ Tous les détails sur le Groupe sur le site\nhttps://astekgroup.fr.\nEt vous pouvez aussi nous suivre sur\nnotre blog : https://blog.groupeastek.com\n.\nRencontrons-nous !\nVous vous êtes reconnu sur l’annonce et Astek vous plaît !\nPour en savoir plus sur vous, Franck , notre Talent Acquisition vous contacte. Puis, vous aurez 3 entretiens max, avec Léonard (votre futur n+1), Léonard notre Directeur !\nNos plus\nAstek est green et fait bénéficier ses salariés d’une indemnité kilométrique vélo\nUn programme CARE sur-mesure déployé par nos équipes RH pour nos collaborateurs : https://astekgroup.fr/engagements\nNotre charte de la Diversité\nBienvenue dans la team ! Allez-y, maintenant c’est à vous de jouer !\nShow more\nShow less",
        "details": {
            "JobDetail": [],
            "TypeContract": "",
            "Salary": "",
            "Level": "",
            "Experience": null
        },
        "title": "data engineer",
        "skills": {
            "ProgLanguage": [
                "Python"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "Saint-Gobain",
        "location": "Courbevoie, Île-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/data-scientist-f-h-at-saint-gobain-3915274420?position=7&pageNum=5&refId=W%2BmbKJ%2BzlSnYV3NZlNoxRw%3D%3D&trackingId=rqMeKkKKTAPrl3%2Fn%2BdCEgA%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Why do we need you ?\nVous rejoindrez l’équipe « AI & Data Analytics », intégrée au département «Data & Analytics» dans l’organisation « Global Digital & IT». «Data & Analytics» regroupe les activités suivantes :\nData Engineering, Data Capture & Delivery, BI & Visualization, Platform & Architecture, Data Governance and Data Engagement.\nAu Sein De L’équipe Data Science, Sous La Responsabilité Du Head Of AI & Data Analytics, Vous Aurez Le Rôle De Data Scientist (H/F). En Tant Que Tel, Vous Aurez Les Responsabilités Suivantes\nConstruire des modèles descriptifs et prédictifs sur des sujets en constante évolution ;\nMener des projets exploratoires faisant appel à des techniques avancées de Data Science (NLP, deep learning, Generative AI, apprentissage par renforcement ou par transfert), de façon autonome ou avec des partenaires externes ;\nAssurer une veille technologique permanente sur ces sujets ;\nParticiper à l’industrialisation des algorithmes en lien avec les équipes engineering basée sur MLOps;\nAccompagner les équipes opérationnelles dans le déploiement des algorithmes, notamment sur le volet analytics ;\nMener des ateliers d’idéation avec les équipes métiers (industrie, marketing, ventes, logistique, e-commerce, finance, RH) pour identifier les opportunités d’exploitation de la donnée et diffuser la culture data au sein de l’entreprise.\nSi vous recherchez des défis passionnants, pouvant impacter des centaines de milliers de clients, et aimez travailler avec des outils à la pointe de la technologie, venez et rejoignez-nous !\nVous participerez donc à la montée en puissance de l’équipe créée récemment, tout en intervenant sur un ou plusieurs cas d’utilisation.\nIs this job for you ?\nEn complément des missions évoquées, une réelle appétence pour la gestion et la facilitation de projet, avec une certaine aisance en termes de communication, seraient fortement appréciées.\nNotre équipe ayant vocation à travailler pour des clients internes pouvant être basés en France comme à l’étranger, la maitrise de l’anglais (écrite et orale) est obligatoire.\nProfil recherché\nIngénieur diplômé d’une école généraliste (Centrale, X, Mines, ENS etc.) ayant au minimum 3 années d'expérience après le diplôme.\nGrande connaissance du Machine Learning, des statistiques et des probabilités.\nSQL et Python, packages de ML: scikit, xgboost, keras\nExpérience de travail sur un cloud provider et savoir construire des data pipelines serait un plus\nGestion de code : Git, Gitlab, CI/CD\nMaitriser la modélisation à la fois prédictive et descriptive\nSavoir implémenter des dashboards et autres outils de data viz\nPosséder de bonnes qualités de communication : vous pouvez expliquer vos modèles clairement à la fois à des data analysts mais aussi à des Directeurs Généraux ou des responsables opérationnels.\nEtre organisé, structuré et motivé par l’innovation\nAimer le travail en équipe et savoir apprendre de chacun.\nUn état d’esprit orienté business et apport de valeur pour les équipes métiers\nA Little More About Us\nSaint-Gobain est une entreprise française spécialisée dans la production, la transformation et distribution de matériaux.\nFondée en 1665 par Jean-Baptiste Colbert sous le nom de Manufacture royale des glaces, l'entreprise est présente dans soixante-sept pays et emploie en 2018 près de 180 000 personnes\nTo make sure nothing is forgotten\nDétails pratiques du rôle\nDébut : Dès que vous êtes prêts\nLocalisation : La Tour Saint-Gobain, La Défense\nContrat: CDI\nSaint-Gobain encourage la diversité des équipes et favorise notamment l’inclusion des personnes en situation de handicap.\nShow more\nShow less",
        "details": {
            "JobDetail": [],
            "TypeContract": "CDI",
            "Salary": "1665",
            "Level": "",
            "Experience": null
        },
        "title": "data scientist",
        "skills": {
            "ProgLanguage": [
                "Python"
            ],
            "DataBase": [
                "SQL"
            ],
            "MachineLearning": [
                "XGBoost",
                "Keras"
            ],
            "DevTools": [
                "Git"
            ],
            "Other": [
                "CI/CD",
                "ML",
                "Statistiques",
                "Machine Learning",
                "Cloud"
            ],
            "EnSoftSkils": [
                "Communication"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "MindPal",
        "location": "Lyon, Auvergne-Rhône-Alpes, France",
        "link": "https://fr.linkedin.com/jobs/view/machine-learning-developer-at-mindpal-3910999113?position=8&pageNum=5&refId=W%2BmbKJ%2BzlSnYV3NZlNoxRw%3D%3D&trackingId=BaQ0Eql2CBVU4gHlkHMYpg%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "We are looking for\nMachine Learning Developer\nJob Responsibilities\nWorking on machine learning projects\nAnalyzing and processing data to create machine learning models\nImplementing and optimizing machine learning algorithms\nTesting and evaluating models\nCollaborating with the programming team and other departments within the company to develop innovative solutions\nRequirements\nMinimum 2 years of experience in the field of machine learning\nKnowledge of machine learning algorithms and techniques\nAbility to analyze and process data\nFamiliarity with machine learning tools and technologies\nProficient in English communication\nEducation in computer science\nWe Offer\nB2B contract type\nFull-time employment\nRemote and flexible working hours\nShow more\nShow less",
        "details": {
            "JobDetail": [
                "Remote",
                "Full"
            ],
            "TypeContract": "",
            "Salary": "",
            "Level": "",
            "Experience": null
        },
        "title": "Other",
        "skills": {
            "Other": [
                "Machine Learning"
            ],
            "EnSoftSkils": [
                "Communication"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "GROUPE ALLIANCE",
        "location": "Île-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/datascientist-at-groupe-alliance-3916080098?position=9&pageNum=5&refId=W%2BmbKJ%2BzlSnYV3NZlNoxRw%3D%3D&trackingId=4oN38rxmbt06vitjIoqESA%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "SI LA GESTION DES DONNEES EST TON DADA, TU PEUX GAGNER LA COURSE EN LISANT CETTE ANNONCE …\nCe que tu recherches :\nau sein d’une équipe dynamique\nà des projets innovants d’envergure\ndes défis\nun nouveau souffle à ta carrière\nAlors nous avons la mission idéale pour toi.\nAu sein d’acteurs majeurs du secteur Bancaire, tu participeras des projets d’envergure sur des évolutions majeures à mettre en œuvre dans le SI du client :\ndes besoins, tu feras\ntechniques, tu rédigeras\net/ou socle technique, tu définiras\npratiques, tu instaureras\nnouvelles fonctionnalités, tu développeras\nbug, tu laisseras\néquipe, tu accompagneras\ninstances de pilotage, tu participeras\nQui tu es :\nde la formation qui va bien\nou dôté(e) d’une expérience de 3 ans minimum\nde la Stack technique machine learning et python\navec les Frameworks et Outils : Ttensorflow, pytorch,scikit-learn, numpy, pandas\nAu-delà des compétences techniques, tu es :\n: tu n’aimes pas rester les deux pieds dans le même sabot\n: un guide du Routard te suffira\nde synthèse : tu sais aller à l’essentiel\nd’adaptation : tu es un vrai caméléon\nde la communication : les mots n’ont pas de secret pour toi\nde proposition : tu es l’Aladdin de l’informatique\nd’équipe : un pour tous et tous pour un !\nShow more\nShow less",
        "details": {
            "JobDetail": [],
            "TypeContract": "",
            "Salary": "",
            "Level": "",
            "Experience": "3 an(s)"
        },
        "title": "data scientist",
        "skills": {
            "ProgLanguage": [
                "Python"
            ],
            "DataAnalytics": [
                "NumPy",
                "Pandas"
            ],
            "MachineLearning": [
                "Scikit-Learn",
                "PyTorch"
            ],
            "Other": [
                "Machine Learning"
            ],
            "EnSoftSkils": [
                "Communication"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "CRIT France",
        "location": "Saint-Étienne",
        "link": "https://fr.linkedin.com/jobs/view/data-scientist-at-crit-france-3908277901?position=10&pageNum=5&refId=W%2BmbKJ%2BzlSnYV3NZlNoxRw%3D%3D&trackingId=u0Bv4piXqeM4zmhZT8ljtw%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Vous souhaitez rejoindre une entreprise, leader dans les Énergies Renouvelables et travaillant en mode projet ? Le domaine de la Data et de l'ingénierie informatique n'a plus aucun secret pour vous ? 🚀\nNotre\nCabinet CRIT Experts & Cadres\nrecherche pour l’un de nos clients situé à proximité de Saint-Etienne,\nun\nData Scientist H/F\n, en CDI.\n🌐 Qui est notre client ?\nLeader et fleuron de l’énergie électrique, notre client est basé à proximité de Saint-Étienne (42), est une entreprise qui conçoit, produit et installe des systèmes automatisés, de conversion et de stockage d’énergie électrique\n🌎 Les engagements de l’entreprise ?\n#satisfaction client\n#respect de la personne\n#performance\n#solidarité et le travail d’équipe\n#intégrité\n#développement des talents\nPourquoi postuler ?\nBien qu'étant une entreprise avec des projets à l'international, notre client su rester à taille humaine. Le fonctionnement en mode Projet offre la possibilité à leurs collaborateurs de s'impliquer et d'apporter leurs compétences à des projets variés. Leurs projets sont des défis techniques qui offrent la possibilité de travailler sur un cycle complet, de la conception à la mise en service.\n📌 Quel sera votre rôle ?\nCollecter, analyser et interpréter des données pour aider l'entreprise à prendre des décisions stratégiques basées sur des données probantes.\nRattaché hiérarchiquement directement au Président, vos missions seront :\nCollecter, nettoyer et manipuler de grandes quantités de données provenant de diverses sources, y compris des bases de données internes et externes, des API et des données non structurées.\nDévelopper et mettre en œuvre des modèles prédictifs et des algorithmes d'apprentissage automatique pour résoudre des problèmes commerciaux complexes.\nEffectuer des analyses statistiques approfondies pour identifier des tendances, des modèles et des insights significatifs.\nTravailler en étroite collaboration avec les équipes interfonctionnelles pour comprendre leurs besoins en matière de données et fournir des solutions analytiques.\nCréer des tableaux de bord interactifs, des visualisations de données et des rapports pour communiquer efficacement les résultats de l'analyse aux parties prenantes.\nMaintenir une veille technologique constante sur les avancées en matière de science des données et proposer des améliorations continues aux processus et méthodologies existants.\nVos responsabilités et périmètre d’action :\nSous directives et objectifs fixés par votre responsable hiérarchique, le Président :\nÊtre conscient des risques et prendre des mesures appropriées pour protéger les données et les systèmes contre les menaces.\n🎯\nProfil recherché :\nDomaine des sciences de données : informatique, en mathématiques, en statistiques, en économie, en sciences de l'informatique, en gestion, en ingénierie industrielle ou dans un domaine connexe.\nExpérience antérieure dans un rôle similaire.\nMaîtrise de l’anglais.\n💡 Vos cartes secrètes idéales ?\n👉 Connaissance des concepts en collecte, extraction & analyse de données.\n👉 Compétences analytiques.\n👉 Capacité à communiquer des informations complexes de manière claire et compréhensible.\n👉 Capacité à travailler de manière collaborative.\n👉 Maîtrise des langages de programmation courants tels que Python, R ou SQL.\n👉 Solides compétences en analyse statistique et en modélisation prédictive.\n👉 Expérience pratique avec les bibliothèques et les frameworks d'apprentissage automatique tels que TensorFlow, Scikit-Learn ou PyTorch.\nAutres informations :\nContrat\n: CDI\nStatut\n: cadre\nSalaire\n: en fonction du profil – à définir\n📍\nLieu\n: à proximité de Saint-Etienne\nAvantages salariaux : Prime participation salariale, Tickets Restaurants, CSE…\nDéplacements à prévoir :\nFrance – EMEA Germany, Italy, Spain, UK\nFréquence : selon besoin de l’activité\nShow more\nShow less",
        "details": {
            "JobDetail": [],
            "TypeContract": "CDI",
            "Salary": "Salaire",
            "Level": "",
            "Experience": null
        },
        "title": "data scientist",
        "skills": {
            "ProgLanguage": [
                "R",
                "Python"
            ],
            "DataBase": [
                "SQL"
            ],
            "DataAnalytics": [
                "R"
            ],
            "MachineLearning": [
                "Scikit-Learn",
                "TensorFlow",
                "PyTorch"
            ],
            "Other": [
                "Statistiques"
            ],
            "EnSoftSkils": [
                "Collaboration"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "Homa",
        "location": "Paris, Île-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/senior-machine-learning-engineer-at-homa-3911467922?position=1&pageNum=7&refId=jSHCf8SJlBfpMeJ3wOWkYQ%3D%3D&trackingId=qpEVx0pIvAU2%2FyI%2Bdv7UgQ%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Welcome to Homa, the gaming technology lab that is taking the industry by storm! Our team of over 200 people, hailing from more than 35 different countries, is dedicated to empowering mobile game creators worldwide to bring their creative ideas to the top charts.\nOur Homa Lab platform offers a comprehensive suite of cutting-edge tools that allow developers to stay on top of the latest trends, test new features in real-time, and easily distribute and monetize their games. Our success speaks for itself - our apps have been downloaded over 1 billion times!\nSince our inception, we have raised $165 million in total from prominent investors, including Headline, Northzone, Eurazeo, Singular, Quadrille Capital, Fabric Ventures, and Bpifrance. We have also received support from renowned business angels, such as the founders of King, Sorare and Spotify founders.\nBut what really makes Homa special is our team. We are a diverse group of artists, business developers, engineers, entrepreneurs, and former strategy consultants who all share the same passion for taking over the gaming industry. When you become part of Homa, you'll be joining a dedicated team that creates innovative and high-performing games that resonate with players worldwide.\nIf you're ready to take your career to the next level and make a real impact in the company, then Homa is the perfect place for you. Join us and let's create the future of gaming together!\nMeet the team\n👩‍👩‍👧‍👧\nYou will join the Data department organized into:\nA Data Platform team with 5 Data Engineers responsible for ingesting large amounts of data from multiple different sources, creating and maintaining a core data model which aims at making data standardized, reliable and easily available\nA Data Science and ML Platform team with 6 Data Scientists / ML Engineer working on ML-driven data products: Autobidder for User Acquisition, N-Testing for experimentation\nAn Advanced Analytics & Data Science team with 6 Data Analysts and Scientists exploiting our data for:\nGame Analytics\nUser Acquisition and Marketing Analytics\nMarket Inteligence Analytics\nOps Analytics\nRole and Missions — What you will do\n🚀\nWe are looking for a Senior Machine Learning Engineer to join the team in order to scale and industrialize Machine Learning & AI at Homa. Under the responsibility of our Associate Director, your responsibilities will be the following:\nLead ML Projects: Spearhead development and implementation of ML models for Marketing Tech (User Acquisition, Monetization) and Game Tech (Bayesian A/B Testing, Segmentation)\nML Industrialization & Democratization: Enhance ML engineering processes, adopt ML Ops tools, and contribute to model interpretability and collaborative efforts\nImplement Scalable ML Solutions: Build Serving APIs for handling millions of requests daily with low latency\nCollaborative Innovation: Work closely with diverse teams, leveraging GenAI tools for productivity and product improvements\nStay Updated: Integrate latest ML technologies and advancements into our tech stack\nCurrent Tech Stack: AWS, Redshift, Databricks, Python, DBT, Spark, Airflow, Kafka, Kubernetes, LightGBM, MLFlow, Metabase\nRequirements\nIf you're creative, ambitious, and up for taking over the industry, we want you on our team! We are also looking for:\nExtensive ML Experience: 5+ years in implementing and deploying ML models to production\nKey Technology Proficiency: Expertise in Neural Networks (TensorFlow / PyTorch), Gradient Boosting libraries (LightGBM / XGBoost), and at least one top Cloud provider (GCP, Azure, AWS)\nMLOps Skills: Experience with ML Ops tools like MLFlow\nAPI Development Expertise: Proven ability in building high-performance Serving APIs\nCollaborative Skills: Excellent communication and teamwork abilities\nInnovative Mindset: Passion for staying ahead in ML trends and technologies\nLanguage Skills: Fluent English is mandatory (interviews will be led in English)\nOur Culture—Who we are\n🪐\nAt Homa, we are building a community of brilliant talents. We believe that true innovation comes from diversity and collaboration, and that's why we prioritize brainpower and determination over formal education. So if you have the talent, energy and motivation, there is no obstacle to your success here.\nAs the creative experts behind the platform, we provide developers with the data they need to bring their ideas to life. Our team lives by three central values that guide everything we do:\n✨\nAmbition\n: we're not afraid to tackle difficult challenges and set our goals extremely high. We're on a mission to revolutionize an industry dominated by well-established companies, and we won't stop until we succeed.\n✨\nHumility\n: we leave our pride & ego aside. We are always ready to lend a helping hand, celebrate each other's successes, and learn from our failures. As Mr. Lamar said, \"Sit down. Be humble.\"\n✨\nCuriosity\n: we keep our minds open and never stop learning. We believe that questioning everything is the best way to stay ahead of the curve, and we encourage all our team members to stay curious and never stop exploring new ideas.\nAt Homa, you'll be challenged, supported, and inspired every day, and we can't wait to see what you bring to the table.\nBenefits\nWhile success is its own reward, here are some of the benefits that come with working at Homa:\nWe offer essential benefits in France and specific locations, including health insurance, meal vouchers, public transport subsidies, childcare benefits, and life insurance\nIf you're interested in working from our newly renovated Paris HQ with a rooftop garden and WeWork amenities, we have a desk waiting for you\nYou will be working in English with our international team of top-tier talents from 35+ countries\nYou will have bi-annual reviews with your manager to reflect on your performance, celebrate wins, and receive constructive feedback\nYou will be able to attend diverse team events and Workations (the famous company-wide Homa trip)\nShow more\nShow less",
        "details": {
            "JobDetail": [
                "Senior"
            ],
            "TypeContract": "",
            "Salary": "",
            "Level": "",
            "Experience": null
        },
        "title": "machine learning engineer",
        "skills": {
            "ProgLanguage": [
                "Python"
            ],
            "BigData": [
                "Databricks",
                "Spark"
            ],
            "MachineLearning": [
                "PyTorch",
                "LightGBM",
                "TensorFlow",
                "XGBoost"
            ],
            "CloudComputing": [
                "GCP",
                "AWS",
                "Azure"
            ],
            "Automation": [
                "Airflow",
                "Kubernetes"
            ],
            "Containers": [
                "Kubernetes"
            ],
            "Collaboration": [
                "Teams"
            ],
            "Other": [
                "Machine Learning",
                "Cloud",
                "ML"
            ],
            "EnSoftSkils": [
                "Teamwork",
                "Communication",
                "Collaboration"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "Dataiku",
        "location": "Paris, Île-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/data-scientist-france-paris-at-dataiku-3834882798?position=2&pageNum=7&refId=jSHCf8SJlBfpMeJ3wOWkYQ%3D%3D&trackingId=23drlgg9Xn%2FF0W%2FrC2Hwbg%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "At Dataiku, we're not just adapting to the AI revolution, we're leading it. Since our beginning in Paris in 2013, we've been pioneering the future of AI with a platform that makes data actionable and accessible. With over 1,000 teammates across 25 countries and backed by a renowned set of investors, we're the architects of Everyday AI, enabling data experts and domain experts to work together to build AI into their daily operations, from advanced analytics to Generative AI.\nHeadquartered in New York City, Dataiku was founded in Paris in 2013 and achieved unicorn status in 2019. Now, more than 1,300 employees work across the globe in our offices and remotely. Backed by a renowned set of investors and partners including CapitalG, Tiger Global, and ICONIQ Growth, we’ve set out to build the future of AI.\nThe role of a Data Scientist at Dataiku is unique. Our Data Scientists not only develop solutions to real-world problems but also participate in client-facing endeavors throughout the customer journey. This includes supporting their discovery of the platform, helping integrate Dataiku with other tools and technologies, providing user training, and co-developing data science projects from design to deployment.\nJust as the non-technical skills are important, so too are the technical. Our Data Scientists work on the Dataiku platform daily. Aside from the visual tools, our team uses mostly Python, with occasional work in other languages (e.g., R, SQL, Pyspark, JavaScript, etc.). An ideal candidate is excited to teach data science and how to use the Dataiku platform to customers, and learn about new technologies.\nHow you'll make an impact\nHelp users discover and master the Dataiku platform, via user training, office hours, demos, and ongoing consultative support.\nAnalyze and investigate various kinds of data and machine learning applications across industries and use cases.\nProvide strategic input to the customer and account teams that help make our customers successful.\nScope and co-develop production-level data science projects with our customers.\nMentor and help educate data scientists and other customer team members to aid in career development and growth.\nWhat you'll need to be successful\nCuriosity and a desire to learn new technical skills.\nEmpathy and an eagerness to share your knowledge with your colleagues, Dataiku’s customers, and the general public.\nAbility to clearly explain complex topics to technical as well as non-technical audiences.\nOver 3 years of experience with coding (Python, R, SQL).\nOver 3 years of experience building ML models.\nUnderstanding of underlying data systems and platform mechanics such as Cloud architectures, K8S, Spark, and SQL.\nWhat will make you stand out\nExperience with Consulting and/or Customer-facing Data Science roles.\nExperience with Data Engineering or MLOps.\nExperience developing WebApps in Javascript, RShiny, or Dash.\nExperience building APIs.\nExperience using enterprise data science tools.\nPassion for teaching or public speaking.\nBenefits\nExposure to a wide range of enterprise customers across industries. Examples of Dataiku’s hundreds of customers include GE, Unilever, Comcast, Ubisoft, OVH, Santander, and Capgemini.\nA wide diversity of projects.\nOpportunity to contribute to the core vision of our company and product: simplify and democratize the way people work with data and use Artificial Intelligence.\nExposure to the latest, open-source technologies that Dataiku integrates. See our release notes for our latest developments: https://doc.dataiku.com/dss/latest/release_notes/index.html\nOpportunity to work with a smart, passionate, and driven team in hypergrowth mode.\nDataiku has a strong culture based on key values: Transparency, Ambition, Excellence, Humility, and Empathy.\nWhat are you waiting for!\nAt Dataiku, you'll be part of a journey to shape the ever-evolving world of AI. We're not just building a product; we're crafting the future of AI. If you're ready to make a significant impact in a company that values innovation, collaboration, and your personal growth, we can't wait to welcome you to Dataiku! And if you’d like to learn even more about working here, you can visit our Dataiku LinkedIn page .\nOur practices are rooted in the idea that everyone should be treated with dignity, decency and fairness. Dataiku also believes that a diverse identity is a source of strength and allows us to optimize across the many dimensions that are needed for our success. Therefore, we are proud to be an equal opportunity employer. All employment practices are based on business needs, without regard to race, ethnicity, gender identity or expression, sexual orientation, religion, age, neurodiversity, disability status, citizenship, veteran status or any other aspect which makes an individual unique or protected by laws and regulations in the locations where we operate. This applies to all policies and procedures related to recruitment and hiring, compensation, benefits, performance, promotion and termination and all other conditions and terms of employment. If you need assistance or an accommodation, please contact us at: reasonable-accommodations@dataiku.com\nShow more\nShow less",
        "details": {
            "JobDetail": [
                "Remote"
            ],
            "TypeContract": "",
            "Salary": "",
            "Level": "",
            "Experience": null
        },
        "title": "data scientist",
        "skills": {
            "ProgLanguage": [
                "R",
                "Python"
            ],
            "DataBase": [
                "SQL"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [
                "Spark"
            ],
            "Collaboration": [
                "Teams"
            ],
            "Other": [
                "Machine Learning",
                "Cloud",
                "ML"
            ],
            "EnSoftSkils": [
                "Empathy",
                "Collaboration"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "METEOJOB by CleverConnect",
        "location": "Nantes, Pays de la Loire, France",
        "link": "https://fr.linkedin.com/jobs/view/data-scientist-h-f-at-meteojob-by-cleverconnect-3913467533?position=3&pageNum=7&refId=jSHCf8SJlBfpMeJ3wOWkYQ%3D%3D&trackingId=f7hRpLcHOxygXRvSayk5Uw%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Entreprise\niziwork est une agence de recrutement d'intérim totalement digitalisée, s'appuyant sur l'innovation technologique pour améliorer radicalement l'accès à l'expérience du travail pour tous. Elle offre aux travailleurs un accès simple et instantané à un grand choix de jobs mais aussi un accompagnement personnalisé au fil des missions qui donne du sens au mérite individuel. En rupture avec les pratiques du marché, iziwork offre une approche « worker centric » pour attirer et valoriser les personnes fiables et compétentes en recherche d'emploi.\nDescription Du Poste\nIziwork est une agence de recrutement digital qui sélectionne les meilleures missions et offres d'emploi pour les centaines de milliers d'intérimaires et candidats qu'elle a déjà séduits. Postulez en quelques minutes, gérez votre contrat en un clin d'oeil depuis notre app et bénéficiez du suivi personnalisé de votre recruteur au quotidien.\nÀ propos de la mission\nOrganiser et conduire les ateliers de construction des modèles de données pour chaque référentiel groupe\nAccompagner les métiers à la définition des règles d'archivage, de gestion et de contrôle qualité\nAssurer les contrôles préliminaires de cohérence des données\nAccompagner l'administrateur des données au transcodage des règles de contrôle qualité dans Talend\nAssurer les contrôles préliminaires de cohérence des données\nParticiper au processus de migration des données dans l'ERP cible en accompagnant les métiers à l'identification des écarts et à la mise en conformité des data dans la/les solutions cible\nIdentifier les incohérences avec l'architecture et participer à la synchronisation de l'intégrité des flux\nAssurer la supervision et l'intégration des données de diverses natures et vérifier la qualité des données qui entrent dans le Data Lake\nStructurer le cycle de vie de la donnée dans le respect des réglementations RGPD & ISO24143\nRémunération & Avantages\nRémunération : 40 000 € - 50 000 € par an\nProfil recherché\nIssu(e) d'une formation en Informatique de niveau BAC+2/+3, vous disposez d'une expérience similaire de 2 à 3 ans idéalement en milieu industriel ou SSI.\nVous possédez une première expérience de gestion de projet informatique, vous savez animer des ateliers.\nTrès organisé(e), rigoureux(se), réactif(ve), vous savez gérer les priorités.\nVotre sens du service et votre aisance relationnelle vous permettent d'instaurer un climat de confiance avec vos différents interlocuteurs.\nVous maitrisez les langages informatiques suivants : Java, Python, SQL. Connaissances souhaitées d'un outil MDM (Talend, Tibco) et d'un ETL.\nVous bénéficiez d'une bonne maîtrise d'Excel.\nNotre environnement international requiert la maîtrise de l'anglais à un niveau B2 minimum (intermédiaire - avancé).\nExpérience : Entre 24 mois et 5 ans\nCertificats requis\nAucun certificat requis\nShow more\nShow less",
        "details": {
            "JobDetail": [],
            "TypeContract": "",
            "Salary": "",
            "Level": "",
            "Experience": "3 an(s)"
        },
        "title": "data scientist",
        "skills": {
            "ProgLanguage": [
                "Java",
                "Python"
            ],
            "DataBase": [
                "SQL"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "STATION F",
        "location": "Paris, Île-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/ai-engineer-at-station-f-3918860437?position=4&pageNum=7&refId=jSHCf8SJlBfpMeJ3wOWkYQ%3D%3D&trackingId=LfYYyiZyzITuvZSu5HbMtQ%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "À propos\nDepuis 30 ans, les contrats n'ont pas changé.\nLeur contenu est simplement passé d'une feuille de papier à un écran d'ordinateur et les entreprises ont dû s'adapter, en utilisant des outils de tous les jours, faute d'équipements adaptés.\nParce qu'ils sont au cœur du business et des relations commerciales, Tomorro réinvente la négociation contractuelle avec une expérience collaborative et intuitive.\nTomorro permet aux entreprises de gérer de manière simple et automatisée le cycle de vie complet d'un contrat, de sa création à son suivi, en passant par sa négociation et sa signature.\nDescriptif du poste\nTa mission\nTu intégreras l'équipe technique de Tomorro, composée de 10 développeurs, 2 product designer et 3 product managers.\nTon but sera alors de contribuer au développement et à l'amélioration continue de notre application SaaS de gestion de contrats grâce aux LLMs au sein d’une squad dédiée.\nTu auras pour objectif de développer de nouvelles fonctionnalités, optimiser les performances et participer à l’architecture de la solution pour pouvoir offrir une expérience utilisateur fluide et fiable autour des technologies de GenAI.\nTes responsabilités\nContribuer au futur de Tomorro tant au niveau technique que produit en implémentant de nouvelles fonctionnalités autour de l’IA générative\nSuperviser l'intégration des modèles d'IA dans nos systèmes existants, en s'assurant qu'ils sont évolutifs, fiables et performants\nMaintenir un niveau maximal de sécurité et de confidentialité dans un contexte juridique\nCollaborer avec les autres membres de l’équipe et cultiver le partage de connaissances.\nPrendre part aux revues de code et veiller à un niveau d’exigence élevé sur la qualité du code\nAssurer une veille permanente sur les sujets IA / ML et proposer des innovations\nParticiper activement aux discussions sur l’architecture et challenger les choix techniques de manière pragmatique\nJouer un rôle essentiel dans la construction de notre équipe technique dans le recrutement et dans la mise en place d'une structure solide\nStack technique\nFront-end: React, Typescript, Apollo, Storybook\nBack-end: Nodejs, Typescript, Nestjs, GraphQL\nInfrastructure: AWS (ECS, S3, SQS, SNS, Lambdas …), IAC with CDK, Docker\nDatabase: Mysql, OpenSearch, Redis\nMonitoring & Observability: Datadog, Sentry\nCI / CD: Github, CircleCI\nGestion de projet: Notion, Linear, Figma\nProfil recherché\nA propos de toi\nTu as 3+ années d’expérience et déjà contribué à un projet GenAI\nTu as une solide expérience technique dans un environnement Typescript et des connaissances sur différentes langages de programmation et technique de conception (SQL, AWS, Docker, Message broker…)\nTu maitrises les API des foundation models (exemple : OpenAI GPT, Titan, LLama, Mistral, Claude…) et l’orchestration sur GenAI (LangChain, Prompt management, MLops...)\nTu as des connaissances en OCR et en traitement de langage naturel (NLP)\nTu es rigoureux·se en matière de tests et de qualité du code\nTu as l’ambition de livrer des applications présentant une haute fiabilité et une disponibilité optimale\nTu es enthousiaste à l'idée de travailler en équipe et tu as autant envie d'apprendre que d'enseigner\nComment nous travaillons\nAmbition: Nous recherchons des personnes extrêmement ambitieuses qui veulent se battre pour changer les choses. Nous vous encouragerons toujours à oser.\nTrust & Ownership: Rejoindre Tomorro c’est vouloir avoir des responsabilités. C’est vouloir grandir et faire grandir l’entreprise vite\nRéunions: Nous n'organisons pas de réunions avant 14 heures et essayons de n’en faire que lorsque c'est nécessaire et non par défaut.\nPrendre du plaisir: Pour finir, on fait tout ça dans la bonne humeur :)\nTomorro c’est aussi\nUne équipe internationale, soudée et ambitieuse partageant des valeurs communes.\nUne rémunération attractive avec plan de BSPCE pour tous les employés.\nUne politique de remote flexible, si tu souhaites travailler depuis Berlin une semaine, pas de problème.\nMacBook, écran, casque et tous les autres accessoires dont tu as besoin pour travailler dans les meilleures conditions.\nDes bureaux centraux et spacieux situés en plein Paris, avec restaurants et autres lieux sympas à proximité.\nUn abonnement sportif Gymlib pour que tu sois au top de ta forme.\nChèques-repas Swile (10€ de valeur faciale), remboursement de la mobilité douce et mutuelle de premier ordre.\nDes afterworks et diners tous les mois, mais aussi deux séminaires par an avec toute l’équipe (Marseille ☀️🇫🇷, Tignes 🎿🇫🇷, Tunisie 🏜️🇹🇳, Megève 🎿🇫🇷).\nProcess de recrutement\nUn appel de 30 minutes pour se présenter, te parler de Tomorro et voir si nos attentes respectives sont compatibles.\n1h30 d’entretien avec un développeur et un membre de l’équipe produit pour discuter en détail du poste, de tes expériences et de tes attentes.\nUn entretien technique avec le Sébastien (CTO). On sait que ton temps est précieux et nous avons conçu un cas qui ne te prendra pas trop de temps.\n30 minutes d’entretien avec Antoine (CEO) pour mieux comprendre ton ambition et tes motivations à rejoindre Tomorro.\nDrink Team🍹: Parce que c'est aussi très agréable de discuter de tout et de rien comme de bons vieux amis, on t’invite à venir boire un verre avec l'équipe.\nInformations complémentaires\nType de contrat : CDI\nLieu : Paris\nNiveau d'études : Bac +5 / Master\nExpérience : > 3 ans\nTélétravail ponctuel autorisé\nShow more\nShow less",
        "details": {
            "JobDetail": [
                "Remote"
            ],
            "TypeContract": "CDI",
            "Salary": "",
            "Level": "",
            "Experience": "30 an(s)"
        },
        "title": "Other",
        "skills": {
            "DataBase": [
                "SQL"
            ],
            "CloudComputing": [
                "AWS"
            ],
            "DevTools": [
                "Docker"
            ],
            "DBMS": [
                "MySQL"
            ],
            "Containers": [
                "Docker"
            ],
            "Other": [
                "CI / CD",
                "ML"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "eXalt",
        "location": "Paris, Île-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/data-scientist-ia-gen-at-exalt-3856618698?position=5&pageNum=7&refId=jSHCf8SJlBfpMeJ3wOWkYQ%3D%3D&trackingId=s4rKX6nYpAJwBil147WL0g%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Descriptif du poste\nNous recherchons un\nData Scientist IA Gen H/F\npour rejoindre notre communauté sur le\npilier Data Science & IA.\nVos missions:\nIdentifier les besoins spécifiques des différentes équipes, à travers des ateliers d’idéation, et proposition de solutions algorithmiques innovantes et adaptées à chaque situation.\nAnalyser les données disponibles pour sélectionner les modèles d’IA les plus pertinents face aux besoins identifiés, en tenant compte des particularités de chaque cas d’usage.\nDévelopper, tester et déployer les algorithmes des modèles d’apprentissage automatique et des algorithmes avancés pour résoudre des problèmes complexes grâce à des méthodes statistiques, mathématiques et de machine learning.\nCollaborer avec les Data Engineer afin d’intégrer les solutions IA dans les produits et les applications existants.\nExploiter les dernières avancées en matière d’IA, notamment le Deep Learning, le Reinforcement Learning, le Traitement du Langage Naturel (NLP), la vision par ordinateur, etc., pour créer des solutions innovantes.\nConseiller les clients tout au long du cycle de vie des projets sur les solutions techniques les plus adaptées à leurs environnements.\nProfil recherché\nCompréhension des enjeux business autours de l’exploitation des données et le déploiement des solutions IA\nMaîtrise du Machine Learning et du Deep Learning, y compris des principaux frameworks (TensorFlow, PyTorch, Scikit-learn, Pandas, NumPy,) et des méthodes statistiques.\nSolide connaissance de Python (Java, Spark, Scala sont un plus).\nExpérience dans l’utilisation d’outils tels que Gitlab et Docker.\nAisance avec l’ensemble du cycle de vie de développement et de déploiement de modèles d’IA (MLOps).\nExpérience de travail en méthode Agile\nCapacité à travailler de manière autonome et en équipe.\nExcellentes compétences en communication et présentation.\nMaîtrise de l’anglais (oral & écrit dans un contexte international professionnel).\nDéroulement des entretiens\nUn entretien RH avec Estelle, à la suite duquel vous saurez tout (ou presque) d’eXalt Value,\nUn entretien technique avec un Manager IA assorti d’un test technique, lors duquel vous aurez l’occasion de démontrer vos talents mais aussi d’apprendre avant même de dire oui,\nUn entretien final avec la Directrice Associée ou le Directeur Opérationnel, pour finir de vous convaincre de nous rejoindre 😊\nVotre environnement eXalté:\nRejoindre\neXalt Value\n, c’est également :\nUn Lab IA au sein duquel vous pourrez expérimenter les divers outils et techniques, autour de use cases internes et externes.\nUn environnement de travail Collaboratif favorisant les initiatives et projets transverses à la Practice Data & IA (Data Hub, etc ;)\nUn collectif de consultants passionnés, s’intéressant aux tendances innovantes du secteur\nUne Practice de proximité, privilégiant la montée en compétence de ses collaborateurs (formations, coachings, mentorats, etc.)\nUn suivi individualisé et de proximité par un.e Data Sales Manager référent du compte client, un.e Chargé.e RH et un.e Practice Manager\nUne équipe sympa et dynamique, qui privilégie des moments de partage (séminaires, eXaltemps, meet-ups, déjeuners d’équipe,etc.)\nQui sont-ils ?\neXalt\nest un cabinet de conseil IT\nPure player Data\n& IA basé à Paris (1er arrondissement).\nNotre offre s’articule autour de 4 piliers réunis au sein d’une même communauté pour un accompagnement à 360° alliant une expertise technique et méthodologique à une approche conseil métier:\nData Gouvernance & Project\nData Engineering & Big Data\nData Performance & Analytics\nData Science & IA\nFiliale du groupe eXalt créé en 2018,\nregroupant plus de\n950 collaborateurs en France\n(Paris, Lyon, Bordeaux, Lille, Nantes, Marseille)\net à l’international\n(Colombie, Etats-Unis, Espagne, Belgique),\neXalt Value\ndémontre une\nexpertise approfondie\ndans le domaine de la Data & IA et conseille les entreprises dans le déploiement de leurs stratégies data-driven.\nBénéficiant de la renommée et des relations client du groupe eXalt\n(1er dans la catégorie Conseil & Audit au classement des Champions de la Croissance 2024), eXalt Value\nest en pleine croissance et regroupe aujourd’hui une communauté d’expertise de plus de 60 collaborateurs en région parisienne.\nNos consultants interviennent sur d\nes projets d’envergure stimulants\ndans divers secteurs d’activité, Banque & Assurance, Médias, Transports, Retail, Tourisme, etc.\nShow more\nShow less",
        "details": {
            "JobDetail": [],
            "TypeContract": "",
            "Salary": "",
            "Level": "",
            "Experience": null
        },
        "title": "data scientist",
        "skills": {
            "ProgLanguage": [
                "Java",
                "Scala",
                "Python"
            ],
            "DataAnalytics": [
                "NumPy",
                "Pandas"
            ],
            "BigData": [
                "Spark"
            ],
            "MachineLearning": [
                "Scikit-Learn",
                "TensorFlow",
                "PyTorch"
            ],
            "DevTools": [
                "Docker"
            ],
            "Containers": [
                "Docker"
            ],
            "Other": [
                "Statistiques",
                "Machine Learning",
                "Big Data"
            ],
            "EnSoftSkils": [
                "Communication"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "Harry Hope.",
        "location": "Nancy, Grand Est, France",
        "link": "https://fr.linkedin.com/jobs/view/data-scientist-h-f-at-harry-hope-3917140355?position=6&pageNum=7&refId=jSHCf8SJlBfpMeJ3wOWkYQ%3D%3D&trackingId=on%2F8v2XMzjUiXrJDWCh9%2Fg%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Jean, consultant spécialisé sur les métiers de l'IT sur la lorraine au sein du cabinet de recrutement Harry Hope accompagne les candidats dans leurs recherches d'une meilleure opportunité professionnelle sur leur secteur géographique privilégié. Nous ne sommes pas une ESN, nous intervenons dans la mise en relation avec des clients finaux sur des postes en CDI. Notre client, une société en pleine croissance dans le secteur de l'IA, recherche un Data Scientist (H/F) pour compléter son équipe dédiée.\nIntégré à une équipe technique composée de Data scientist, de développeurs et de chercheurs, vous aurez l'occasion d'intervenir dans la récupération, l'exploitation, la modélisation, l'évaluation et l'interprétation de données stockées dans les bases de données de la structure permettant de les exploiter selon les besoins. En parallèle de vos missions concernant les données propre à l'activité principale de l'entreprise, vous intervenez également dans l'exploitation et la structuration des datas récupérées sur internet en lien avec l'IA en cours de développement.\nDiplômé en informatique, vous disposez à minima d'une première expérience à un poste similaire (alternance ou premier emploi). Techniquement, vous avez une grande expertise en statistiques et en mathématiques appliquées. Vous maitrisez les domaines du Big Data, du machine learning et de la programmation informatique (Python, Java, R, SQL ...). Humainement, vous êtes reconnu pour votre dynamisme, votre flexibilité et votre engagement. Vous êtes capable de vous impliquer à fond dans les projets qui vous sont confiés et vous appréciez le travail collaboratif. Passionné par la Data, vous assurez une veille constante sur les nouvelles technologies en lien avec votre activité. Enfin, vous maitrisez l'anglais à l'oral comme à l'écrit.\nInformations complémentaires : Salaire selon profil et expériences (38/42kEUR), possibilité d'évoluer rapidement, CDI à pouvoir rapidement à Nancy.\nSi cette opportunité correspond à vos aspirations professionnelles alors faites-moi parvenir votre candidature. J'étudierai cette dernière et reviendrai vers vous dans les meilleurs délais pour un suivi personnalisé de votre profil !\n20624921-55584\nShow more\nShow less",
        "details": {
            "JobDetail": [],
            "TypeContract": "CDI",
            "Salary": "38",
            "Level": "",
            "Experience": null
        },
        "title": "data scientist",
        "skills": {
            "ProgLanguage": [
                "R",
                "Java",
                "Python"
            ],
            "DataBase": [
                "SQL"
            ],
            "DataAnalytics": [
                "R"
            ],
            "Other": [
                "Statistiques",
                "Machine Learning",
                "Big Data"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "MindPal",
        "location": "Paris, Île-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/machine-learning-developer-at-mindpal-3896993704?position=7&pageNum=7&refId=jSHCf8SJlBfpMeJ3wOWkYQ%3D%3D&trackingId=%2BwC5oaYVFwVTsNj2TKJOtg%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "We are looking for\nMachine Learning Developer\nJob Responsibilities\nWorking on machine learning projects\nAnalyzing and processing data to create machine learning models\nImplementing and optimizing machine learning algorithms\nTesting and evaluating models\nCollaborating with the programming team and other departments within the company to develop innovative solutions\nRequirements\nMinimum 2 years of experience in the field of machine learning\nKnowledge of machine learning algorithms and techniques\nAbility to analyze and process data\nFamiliarity with machine learning tools and technologies\nProficient in English communication\nEducation in computer science\nWe Offer\nB2B contract type\nFull-time employment\nRemote and flexible working hours\nShow more\nShow less",
        "details": {
            "JobDetail": [
                "Remote",
                "Full"
            ],
            "TypeContract": "",
            "Salary": "",
            "Level": "",
            "Experience": null
        },
        "title": "Other",
        "skills": {
            "Other": [
                "Machine Learning"
            ],
            "EnSoftSkils": [
                "Communication"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "ITNOVEM.",
        "location": "Paris, Île-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/cdi-data-scientist-ia-confirme-h-f-at-itnovem-3899543583?position=8&pageNum=7&refId=jSHCf8SJlBfpMeJ3wOWkYQ%3D%3D&trackingId=wnSlVnaIhncVBDe2l9rAVA%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "L’ENTREPRISE\nFiliale privée technologique du\nGroupe SNCF\n, ITNOVEM se positionne comme accélérateur des projets Digitaux, numériques et de la transformation des Systèmes d’information du groupe. Porteuse de grands projets de la révolution digitale, notre société est en constante recherche de profils pour rejoindre la grande aventure de l’Internet des objets, de la data science, de la cybersécurité et de l’accompagnement des projets digitaux. Qu’il s’agisse de maintenance prédictive, d’aide à la décision sur la maintenance des infrastructures, de gare 4.0, d’usine du futur, ou de sécurisation des assets, nos équipes font valoir à la fois une expérience métier et une expertise technique sans cesse renouvelée, dans le respect des valeurs du groupe :\nExcellence\n,\nInnovation\n,\nCollectif\n,\nAgile\n,\nEngagement.\nLE POSTE\nAu sein d’ITNOVEM, la « Factory Data & IA » accompagne les différentes entités du Groupe SNCF à répondre à leurs enjeux métiers via l’exploitation des données dont le groupe dispose et en mobilisant des compétences et expertises techniques en data science, data engineering et technologies Big Data & Cloud. Elle conçoit, construit, déploie, et exploite les projets data pour le Groupe SNCF (socles de données, traitements de données massives, transformations complexes, développement d'algorithmes, intelligence artificielle ...).\nAu sein de la « Factory Data & IA », l’équipe « Data Science » intervient auprès des métiers et DSI de SNCF avec une forte ambition en matière d’industrialisation et des technologies Data et IA qui correspondent à l’état de l’art. Les problématiques sont variées et liées aux grands enjeux industriels, opérationnels et stratégiques du groupe SNCF, par exemple :\nMaintenance du matériel roulant ;\nSurveillance et la maintenance de l'infrastructure ferroviaire (voies et caténaires) ;\nMise en œuvre de l’IA Générative pour des applications ferroviaires ;\nConstruction de modèles IA pour améliorer la performance opérationnelle ;\nMise en place de solutions d’IA autour de l’image et la vidéo (computer vision) ;\nAnalyse et valorisation des données de capteurs (par ex., mesures, vidéo).\nL’\nIngénieur Data Scientist\ncontribue au développement de l’activité de l’équipe « Data Science ». Il analyse, valorise et exploite l’ensemble des données mises à sa disposition. Il proposer, en proche collaboration avec les métiers, des solutions pour répondre aux cas d’usage identifiés.\nMISSIONS ET RESPONSABILITÉS\nAu sein de l’équipe « Data Science », le\nData Scientist\nporte les responsabilités suivantes :\nAccompagner, en tant que lead technique, les projets Data Science / IA (cadrages, études, prototypes et industrialisation) de la Factory, à la fois sur les aspects techniques / scientifiques et sur la relation client.\nMener des activités de conseil technique et scientifique sur l’usage et la valorisation de la donnée au sein du Groupe SNCF. Accompagner l’identification et la mise en œuvre de cas d’usage auprès des métiers.\nConstruire des solutions d’IA et de valorisation des données appliquées aux cas d’usage du Groupe SNCF.\nContribuer à la veille scientifique et technique, aux projets R&D internes, et à la construction de produits et de services techniques orientés data. Proposer des axes de développement des activités Data Science.\nÊtre un référent technique de l'équipe sur les questions data science et accompagner les data scientists plus juniors dans leur montée en compétences.\nParticiper et contribuer à la vie de l’équipe Data Science : partage de connaissance, mise en place de bonnes pratiques, communication interne et externe, collaborations externes.\nCOMPETENCES ATTENDUES\nCompétences techniques / métier\nMaitrise des outils mathématiques de la Science des Données (statistiques, recherche opérationnelle, traitement du signal, traitement de l’image …).\nCapacité à aborder et à résoudre des problèmes complexes avec méthode.\nCapacité avérée de modélisation de problématiques métier en termes de données et d’analyse statistique.\nExpérience en développement Python et une bonne capacité à produire du code industriel (modulaire, testé, non redondant, automatisé, robuste, optimisé).\nMaîtrise des algorithmes de Machine Learning et de Deep Learning, ainsi que des outils associés (scikit-learn, TensorFlow, PyTorch, SparkML ...) pour le traitement de données structurées et non structurées.\nMaitrise des outils de NLP et de l’IA générative / LLM / RAG.\nBonne connaissance des principes de la gestion de projet Data. Capacité à piloter, cadrer et chiffrer un projet et gérer des collaborateurs.\nMaitrise de l’anglais technique.\nConnaissance d’un écosystème cloud (Azure ou AWS) et de Databricks est un plus.\nIdéalement, des connaissances du contexte et enjeux liés à l’industrie.\nCompétences personnelles / transverses\nCommunication écrite et orale rigoureuse et claire. Sens de la pédagogie. Capacité à effectuer et synthétiser de la veille scientifique et technique.\nOrienté résolution de problème.\nTransversalité et capacité à travailler avec des équipes pluridisciplinaires.\nOrientation client, qualité et résultats.\nCapacité à piloter une équipe, cadrer et chiffrer un projet, manager des collaborateurs.\nCapacité à mener des activités de conseil technique et scientifique auprès de non spécialistes.\nRigueur, gestion et organisation.\nCuriosité fonctionnelle et technologique.\nAppétence pour le milieu industriel, et particulièrement le domaine ferroviaire.\nEXPÉRIENCES ET FORMATIONS\nVous avec obtenu une diplôme d’une formation scientifique Bac+5 ou supérieur (doctorat, école d’ingénieur), dans un domaine lié à l’usage de la données (par exemple, physique, mécanique, traitement du signal et de l’image, mathématiques appliquées).\nVous disposez d'au moins 4 ans d'expérience professionnelle dans le traitement avancé des données et le développement d'applications en Analyse / Intelligence Artificielle / Science des Données. Sont notamment appréciées les expériences en relation avec un domaine industriel.\nD’autres raisons de rejoindre ITNOVEM !\n🚀 En tant que filiale SNCF, des opportunités de carrières internes vous sont offertes.\n📚 ITNOVEM croit en la formation continue de ses collaborateurs et leur donne l’opportunité de s’inscrire à une formation par an minimum.\n🚊 Vos titres de transport sont pris en charge à hauteur de 75%.\n🍽️ Via la carte titres-restaurant Swile, vous bénéficiez de 9,25 € par jour dont 60% pris en charge par ITNOVEM.\n💻 Chez ITNOVEM, vous bénéficiez jusqu’à 3 jours de télétravail par semaine.\n🏖️ ITNOVEM vous permet de profiter de 28 congés et de 16 RTT pour les cadres et 10 pour les non-cadres. Par ailleurs, 2 des 3 jours de congés pour enfant malade sont rémunérés.\n👫 La mise en œuvre de l’égalité professionnelle femmes/hommes est primordiale chez ITNOVEM. A chaque nouvelle embauche, l'entreprise s'engage à proposer une rémunération équivalente tant aux femmes qu'aux hommes.\n♻️ ITNOVEM incite tous les collaborateurs à trier leurs déchets et les gobelets ont été bannis. Par ailleurs, chaque année, ITNOVEM participe à « La grande collecte », une initiative SNCF qui permet de collecter les PC devenus obsolètes en leur offrant une seconde vie\nShow more\nShow less",
        "details": {
            "JobDetail": [
                "Junior"
            ],
            "TypeContract": "",
            "Salary": "",
            "Level": "Bac+5",
            "Experience": "4 an(s)"
        },
        "title": "data scientist",
        "skills": {
            "ProgLanguage": [
                "R",
                "Python"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [
                "Databricks"
            ],
            "MachineLearning": [
                "Scikit-Learn",
                "TensorFlow",
                "PyTorch"
            ],
            "CloudComputing": [
                "AWS",
                "Azure"
            ],
            "Other": [
                "Statistiques",
                "Machine Learning",
                "Cloud",
                "Big Data"
            ],
            "EnSoftSkils": [
                "Initiative",
                "Communication",
                "Collaboration"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "Klanik",
        "location": "Nice, Provence-Alpes-Côte d'Azur, France",
        "link": "https://fr.linkedin.com/jobs/view/data-scientist-monaco-at-klanik-3912534166?position=9&pageNum=7&refId=jSHCf8SJlBfpMeJ3wOWkYQ%3D%3D&trackingId=ty%2Bj5ikNaHH1trpEsmjAXg%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Le consultant travaillera sur des analyses de données et de participer au développement de modèles prédictifs et d'algorithmes d'apprentissage automatique.\nActivités :\n- Nettoyage / préparation / structuration / normalisation des données pour garantir leur qualité et leur fiabilité ;\n- Exploration de données : utiliser des statistiques descriptives et des visualisations de données pour explorer les jeux de données, identifier des tendances, des anomalies éventuelles ;\n- Modélisations : concevoir, développer et déployer des modèles statistiques et d'apprentissage automatique pour répondre à des questions spécifiques ou résoudre des problèmes métiers ;\n- Développement et optimisation de pipelines de données pour faciliter l'acquisition, le traitement et la mise à disposition des données pour l'analyse ;\n- Communication des résultats des analyses et des modélisations à travers des rapports et des visualisations de données claires et impactantes, permettant aux parties prenantes de prendre des décisions basées sur les données.\nProfil\nÊtre titulaire, d’un diplôme national d’ingénieur sanctionnant cinq années d’études supérieures ou d’un diplôme reconnu équivalent\nEntre 2 et 5 ans d'expérience en tant que Data Scientist\nCompétences Techniques :\nMaîtrise des langages de programmation tels que Python ou R, et des bibliothèques de data science comme pandas, TensorFlow ou PyTorch ;\nExpérience en Modélisation Statistique : Solide compréhension des techniques statistiques et de machine learning, avec une capacité à appliquer ces techniques pour résoudre des problèmes complexes ;\nGestion de Bases de Données : Expérience avec les bases de données SQL, NoSQL, Time Series, ainsi qu'avec les technologies de traitement de données en temps réel ;\nVisualisation de Données : Compétence dans l'utilisation d'outils de visualisation de données tels que Tableau, Power BI, ou des bibliothèques Python de visualisation de données.\nShow more\nShow less",
        "details": {
            "JobDetail": [],
            "TypeContract": "",
            "Salary": "",
            "Level": "",
            "Experience": "5 an(s)"
        },
        "title": "data scientist",
        "skills": {
            "ProgLanguage": [
                "R",
                "Python"
            ],
            "DataBase": [
                "SQL",
                "NoSQL"
            ],
            "DataAnalytics": [
                "R",
                "Pandas"
            ],
            "MachineLearning": [
                "PyTorch",
                "TensorFlow"
            ],
            "DataVisualisation": [
                "Power BI",
                "Tableau"
            ],
            "Statistics": [
                "Statistiques Descriptives"
            ],
            "Other": [
                "Statistiques",
                "Machine Learning"
            ],
            "EnSoftSkils": [
                "Communication"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "MindPal",
        "location": "Toulouse, Occitanie, France",
        "link": "https://fr.linkedin.com/jobs/view/machine-learning-developer-at-mindpal-3896992755?position=10&pageNum=7&refId=jSHCf8SJlBfpMeJ3wOWkYQ%3D%3D&trackingId=U51E83rZ34mXilrhQlk01g%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "We are looking for\nMachine Learning Developer\nJob Responsibilities\nWorking on machine learning projects\nAnalyzing and processing data to create machine learning models\nImplementing and optimizing machine learning algorithms\nTesting and evaluating models\nCollaborating with the programming team and other departments within the company to develop innovative solutions\nRequirements\nMinimum 2 years of experience in the field of machine learning\nKnowledge of machine learning algorithms and techniques\nAbility to analyze and process data\nFamiliarity with machine learning tools and technologies\nProficient in English communication\nEducation in computer science\nWe Offer\nB2B contract type\nFull-time employment\nRemote and flexible working hours\nShow more\nShow less",
        "details": {
            "JobDetail": [
                "Remote",
                "Full"
            ],
            "TypeContract": "",
            "Salary": "",
            "Level": "",
            "Experience": null
        },
        "title": "Other",
        "skills": {
            "Other": [
                "Machine Learning"
            ],
            "EnSoftSkils": [
                "Communication"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "Technology & Strategy",
        "location": "Paris, Île-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/senior-data-scientist-h-f-at-technology-strategy-3873419835?position=1&pageNum=10&refId=lUCpoL4OtWpdXIhZLSJ%2ByQ%3D%3D&trackingId=ecXMVmaYF654bCTCykdAeA%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Découvrez Novencia\n:\nExpert en Data et Intelligence Artificielle, nous aidons nos clients à exploiter et à valoriser leurs données sous toutes ses formes en les accompagnant sur des projets de Data Analyse, Data Gourvernance, Data Architecture, Data Science, et Data Engineering…\nVous avez une solide expérience de minimum 4 ans dans la science des données et vous êtes à la recherche de nouveaux défis ? N'hésitez plus !\nType de contrat : CDI\nDémarrage : Dès que possible\nLieu : Paris\nEn qualité de Senior Data Scientist (H/F), votre rôle sera :\nCadrer et challenger les besoins des utilisateurs, contribuer à la définition des Use Case\nTraiter les données, structurées ou non structurées pour extraire des insights à valeur ajoutée\nContrôler la qualité des données, détecter des patterns, des outliers\nProposer et mettre en pratique les modèles statistiques (régressions…) ou de datascience (machine learning…) pour résoudre les problématiques métier\nMener le projet de la phase de POC à l’industrialisation, le plus souvent intégré au sein d’une Feature team\nRestituer les résultats (rapports, présentations…)\nPré-requis :\nCapacité de comprendre les besoins et enjeux métiers et de les reformuler sous forme d’une problématique Data\nCapacité d’expliquer des idées complexes avec des mots simples, claires et précis\nBonne connaissance et maîtrise des algorithmes de Data Science et de Machine Learning\nTrès bonnes compétences en programmation sur Python avec une maîtrise des librairies python\nBonnes bases des outils de versioning comme git\nUne maîtrise des librairies ou d'outils de data visualisation\nMaîtrise d’autres langages (comme R et SAS) est un plus\nFamilier avec une plateforme cloud (AWS, GCP et Azure)\nCompréhension des enjeux de mise en production\nCompétences dans les technologies Big Data est un plus\nBon niveau d’anglais à l’oral comme à l’écrit\nNotre objectif commun est de co-construire votre carrière en fonction de vos aspirations et de vos compétences.\nContactez-moi en message privé ou par mail à s.ziki@technologyandstrategy.com !\nLet's make it possible #together\n*Nos postes sont ouverts aux personnes bénéficiant d’une Reconnaissance de la Qualité de Travailleur Handicapé (RQTH). T&S Groupe encourage la diversité et l’égalité sur le lieu de travail. Tous les candidats qualifiés H/F/* sont pris en considération pour un emploi sur un même pied d'égalité.\nShow more\nShow less",
        "details": {
            "JobDetail": [
                "Senior"
            ],
            "TypeContract": "CDI",
            "Salary": "",
            "Level": "",
            "Experience": "4 an(s)"
        },
        "title": "data scientist",
        "skills": {
            "ProgLanguage": [
                "R",
                "Python"
            ],
            "DataAnalytics": [
                "R"
            ],
            "CloudComputing": [
                "GCP",
                "AWS",
                "Azure"
            ],
            "DevTools": [
                "Git"
            ],
            "Other": [
                "Statistiques",
                "Machine Learning",
                "Cloud",
                "Big Data"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "Novelis",
        "location": "Paris, Île-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/docteur-en-ia-ml-nlp-%E2%80%93-h-f-at-novelis-3903772419?position=2&pageNum=10&refId=lUCpoL4OtWpdXIhZLSJ%2ByQ%3D%3D&trackingId=sKPdU8FAUJ4onEORMp6Uxg%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Doctor in AI/ML/NLP\nNovelis is a dynamic and agile organization that has chosen to focus on innovation and research. We strongly believe in investment as a tool for progress and a driver of growth; it's part of our DNA. With our Intelligent Automation division and our R&D laboratory, we assist our partners in developing innovative architectures and solutions that combine Data, Artificial Intelligence, and Smart Automation (RPA, OCR, Semantic Analysis).\nWe are looking for a PhD Doctor to strengthen our R&D Lab in the Paris region.\nThe Novelis Lab is our dedicated research and development structure. It is the nerve center of Novelis, whose objective is to implement our Innovation and Research strategy.\nYour missions\nWork on multidisciplinary topics that combine artificial intelligence (machine learning), natural language processing (NLP), and computer vision, reasoning\n,\nplanification\nand\noptimization\ntasks\n,\nprocess\nautomation.\nConduct research and stay up to date with the scientific state of the art related to our research work.\nDesign, develop, test, and document innovative solutions that meet the challenges of our R&D laboratory.\nContribute to the writing of scientific publications.\nRequired Profil\nWe are seeking a highly skilled and motivated individual to join our R&D laboratory as a Doctor of Artificial Intelligence. The successful candidate will have a PhD in artificial intelligence, machine learning, or a related field and will possess knowledge in NLP and/or machine vision and/or machine learning methods. Strong programming skills in Python (Java is a plus) and experience in software modeling, design (UML/Merise), and development are required.\nIn addition, excellent written and verbal communication skills, a creative mindset, scientific curiosity, and a passion for research are essential for this role. Fluency in English is required, and proficiency in French is a plus. If you are looking for an exciting opportunity to be part of a dynamic R&D team and contribute to cutting-edge research in the field of artificial intelligence, we encourage you to apply.\njobs@novelis.io\nAs part of its diversity policy, Novelis studies, with equal skills, all applications including those of people with disabilities.\nShow more\nShow less",
        "details": {
            "JobDetail": [],
            "TypeContract": "",
            "Salary": "",
            "Level": "",
            "Experience": null
        },
        "title": "Other",
        "skills": {
            "ProgLanguage": [
                "R",
                "Java",
                "Python"
            ],
            "DataAnalytics": [
                "R"
            ],
            "Other": [
                "Machine Learning",
                "ML"
            ],
            "EnSoftSkils": [
                "Communication",
                "Organization"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "SMARTIUM Group",
        "location": "Strasbourg, Grand Est, France",
        "link": "https://fr.linkedin.com/jobs/view/data-scientist-at-smartium-group-3835671392?position=3&pageNum=10&refId=lUCpoL4OtWpdXIhZLSJ%2ByQ%3D%3D&trackingId=RcYvV4bgCpIn5jNqakcapg%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "SMARTIUM Group est une jeune startup basée à Starsbourg qui propose des technologies de mesure des rayonnements ionisants dans les domaines de l'industrie, de la santé et de la sécurité. Dans le cadre de notre développement nous recherchons\nun(e) Data Scientist\n.\nNos solutions embarquées à forte valeur ajoutée permettent une analyse avancée des dnnées fournies par les systèmes de mesure et par la modélisation numérique (monte carlo).\nIssue de la valorisation des travaux de recherche, SMARTIUM Group bénéficie d'un lien renforcé avec la recherche (CNRS) et les universités.\nVos missions\nVous êtes titulaire d'un Bac+5 et/ou doctorat en science de préférence, et vous avez pu développer des compétences en simulation Monte Carlo (Genat4, MCNP, ...) et/ou en science des données (analyse statistique, apprentissage automatique, intelligence artificielle). Vous souhaitez valoriser ces compétences dans un environnement professionnel dynamique d'une jeune startup Deeptech en lien direct avec la recherche.\nRattaché directement au CEO vous contriburez au développement de solutions innovantes variées pour des problématiques santés, industrielles et environnementales.\nVotre implication et votre réussite feront de vous un élément clé du développement de l'entreprise. Des prerspectives d'encadrement d'équipe sont envisagées pour les profils faisant preuve de qualités managériales.\nVos compétences\nBac +5 en science/ physique nucléaire ; Intérêt fort pour la science des données ; une expérience/formation en simulation Monte Carlo serait un plus ; une apétence pour l'analyse des données ; des connaissance en Intelligence Artificielle serait un plus ;\nAvantages\nAmbiance startup - Equipe dynamique - Salaire suivant profil + avantages\nShow more\nShow less",
        "details": {
            "JobDetail": [],
            "TypeContract": "",
            "Salary": "Salaire",
            "Level": "Bac+5",
            "Experience": null
        },
        "title": "data scientist",
        "skills": {}
    },
    {
        "source": "LinkedIn",
        "company": "Astek",
        "location": "Paris, Île-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/ing%C3%A9nieur-machine-learning-%E2%80%93-paris-france-h-f-at-astek-3882492554?position=4&pageNum=10&refId=lUCpoL4OtWpdXIhZLSJ%2ByQ%3D%3D&trackingId=gtmDKe%2FvjVPakexFswVVtA%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "CDI\nParis - France\nPubliée il y a 1 mois\nLe Groupe Astek\nCe Que Nous Allons Accomplir Ensemble :\nRejoignez nos équipes et intervenons ensemble sur les projets de nos partenaires autour des enheux d’innovation.\nVotre Mission, Si Vous L’acceptez :\nCadrer techniquement les projets et accompagner les Data Scientists dans la construction des modèles en veillant à respecter les bonnes pratiques d’ingénierie logicielle.\nMettre en place la démarche ML OPS\nDéployer les modèles en production en respectant des contraintes de coûts, précisions et performances techniques.\nImplémenter les outils permettant de monitorer ces modèles en production\nVous ?\nVous êtes issu(e) d’une formation Bac+5 (École d’ingénieur, Université ou équivalent …) en informatique\nVous justifiez d’une expérience significative d’au moins 5 ans au sein d’une équipe dans un environnement Data à l’échelle du SI d’un grand groupe\nVous êtes un bon communiquant et disposez de capacités d’analyse et de synthèse éprouvées\nVous accordez de l’importance à la veille technologique\nCompétences Techniques :\nExpertise en SPARK et PySpark\nConnaissance de Kubernetes\nConnaissance de d’Apache Kafka\nUne expérience sur un cloud provider public comme Azure (idéalement), AWS, ou GCP\nExpertise de développement en Python\nExpertise du ML OPS\nCompétences Transverses :\nCapacité à interagir avec des parties prenantes diverses : Data Scientists, Business analyst, Architectes, Métier\nForte expérience en mode de Delivery Agile (Scrum, Kanban, etc.…)\nEtre expert dans les pratiques du Software Craftsmanship (Test Driven, Development, Behavior Driven Development, Clean Code, Code Reviews, etc.)\nEt :\nDes Connaissances sur Azure DevOps, Azure Pipeline, GIT\nMaitrise des Traitements Big Data en mode Streaming\nMaitrise des Bases de données relationnelles et NoSQL\nUne expérience professionnelle avec des outils comme Azure Databricks, Azure, Machine Learning , Azure Data Lake Storage ou encore Azure Data Factory\nLe Groupe Astek\nCréé en France en 1988, Astek est un acteur mondial de l’ingénierie et du conseil en technologies. Fort de son expertise dans de nombreux secteurs industriels et tertiaires, Astek accompagne ses clients internationaux dans le déploiement intelligent de leurs produits et de leurs services, et dans la mise en œuvre de leur transformation digitale.\nDepuis sa création, le Groupe a fondé son développement sur une forte culture d’entrepreneuriat et d’innovation, et sur l’accompagnement et la montée en compétence de\nses 7800 collaborateurs\nqui s’engagent chaque jour à promouvoir la complémentarité entre les technologies numériques et l’ingénierie des systèmes complexes.\nRejoignez un Groupe en fort développement en France et à travers le monde ayant réalisé un chiffre d’affaires de 600 M€ en 2023.\nTous les détails sur le Groupe sur le site https://astekgroup.fr. Et vous pouvez aussi nous suivre sur notre blog : https://blog.groupeastek.com.\nRencontrons-nous\nNotre projet commun vous plait ?\nPostulez à cette annonce, et soyez transparent !\nNotre Talent Acquisition Officer, vous contactera pour un premier échange téléphonique.\nPuis vous rencontrerez votre futur manager, avec lequel vous échangerez autour d’Astek, de votre parcours, de vos attentes et de votre future mission .\nEnfin, vous rencontrerez notre Directeur de département, avec lequel vous pourrez valider votre intérêt et adéquation pour le poste et finaliser les éléments contractuels.\nNos Plus\nAstek est green et fait bénéficier ses salariés d’une indemnité kilométrique vélo\nUne politique CARE sur-mesure déployée par nos équipes RH pour nos collaborateurs (https://astekgroup.fr/engagements)\nNotre charte de la Diversité\nBienvenue dans la team ! Allez-y, maintenant c’est à vous de jouer !\nMots-clés :\ningénieur – ingénieure – consultant – consultante\nCaractéristiques de l'emploi\nCatégorie Chef de Projet\nJob Industry Aérospatial / Défense / Sécurité, Distribution / Services Internet, Energie / Sciences de la Vie / Autres industries, Finance / Gouvernement, Télécom / Média, Transports Terrestres\nPostuler en ligne\nNom *\nPrénom *\nEmail *\nUn email valide est requis.\nTéléphone *\nUn numéro de téléphone valide est requis.\nJoindre un CV *\nMots-clés :\ningénieur – ingénieure – consultant – consultante\nShow more\nShow less",
        "details": {
            "JobDetail": [],
            "TypeContract": "CDI",
            "Salary": "",
            "Level": "Bac+5",
            "Experience": "5 an(s)"
        },
        "title": "Other",
        "skills": {
            "ProgLanguage": [
                "Python"
            ],
            "DataBase": [
                "NoSQL"
            ],
            "BigData": [
                "Databricks",
                "Spark"
            ],
            "CloudComputing": [
                "GCP",
                "AWS",
                "Azure"
            ],
            "DevTools": [
                "Git"
            ],
            "SoftBigDataProcessing": [
                "Apache Kafka"
            ],
            "Automation": [
                "Chef",
                "Kubernetes"
            ],
            "Containers": [
                "Kubernetes"
            ],
            "Other": [
                "ML",
                "Big Data",
                "Machine Learning",
                "Cloud",
                "DevOps"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "Moët Hennessy",
        "location": "Paris, Île-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/alternance-data-scientist-at-mo%C3%ABt-hennessy-3840470791?position=5&pageNum=10&refId=lUCpoL4OtWpdXIhZLSJ%2ByQ%3D%3D&trackingId=dOIqnzI%2BZWf9tXqV9o%2B%2F0Q%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Moët Hennessy est à la recherche d'une personne motivée pour rejoindre son Centre d'Expertise (CoE) Data & AI en tant qu'alternant.e Data Scientist.\nDans ce rôle, vous aurez l'opportunité de contribuer au développement d'un \"compliance bridge\" visant à valider automatiquement la conformité aux différentes réglementations en vigueur du contenu produit par ou pour Moët Hennessy (texte, image, vidéo, etc.).\nCela nécessitera, notamment, de mettre en œuvre des compétences en Machine Learning (Object Detection, Object Segmentation, NLP, GenAI...).\nEn plus de cette mission principale, vous serez amené.e à travailler sur d'autres sujets selon les besoins (implémentation de démonstrateur IA, acculturation des métiers, veille technologique...).\nLe CoE Data & AI est une équipe au sein du département Data & AI de la DSI de Moët Hennessy. Cette direction a pour mission d'accélérer la transformation de nos différents métiers, de la vigne jusqu'au verre.\nDescriptif du poste\n:\nParticiper au développement de la \"couche de conformité\" afin d'assurer la conformité du contenu avec les réglementations locales (par exemple, la Loi Evin) et les normes internes.\nParticiper aux phases d'idéation, d'étude de faisabilité et de lancement de projets IA\nParticiper pour ces projets aux phases de modélisation mathématique\nEffectuer des analyses exploratoires des données\nContribuer aux activités de préparation des données (nettoyage de donnée, feature engineering, feature selection…)\nSoutenir la conception et la mise en œuvre des modèles\nContribuer au design des pipelines de machine learning incluant notamment la mesure de performance des modèles et à leur monitoring\nContribuer à l'industrialisation des modèles tout en respectant les normes du groupe et les principes MLOps\nDocumenter les projets d'intelligence artificielle\nContribuer à la veille technologique du COE Data & AI\nNous recherchons une personne en alternance inscrite dans un programme master 1 ou master 2 en data science.\nRythme d'alternance souhaité :\n15j / 15j de préférence (autres rythmes possibles).\nDurée de l'alternance souhaitée :\n1 an\nCompétences recherchées :\nMaitrise de Python\nBonne compréhension des bonnes pratiques de développement logiciel\nConnaissance de Dataiku\nConnaissance des services GCP (en particulier Cloud Run, Vertex AI\nAnglais professionnel\nFrançais courant\nAutonomie et pro activité\nEsprit de synthèse\nCapacité de vulgarisation\nQualités relationnelles et rédactionnelles\nInformations complémentaires :\nPériode : rentrée de septembre 2024\nLocalisation géographique de l'offre : PARIS\nDéplacements occasionnels à prévoir en Champagne (Epernay)\nShow more\nShow less",
        "details": {
            "JobDetail": [],
            "TypeContract": "",
            "Salary": "",
            "Level": "",
            "Experience": null
        },
        "title": "data scientist",
        "skills": {
            "ProgLanguage": [
                "Python"
            ],
            "CloudComputing": [
                "GCP"
            ],
            "Other": [
                "Machine Learning",
                "Cloud"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "Pierre Fabre Group",
        "location": "Lavaur, Occitanie, France",
        "link": "https://fr.linkedin.com/jobs/view/data-scientist-cdi-h-f-at-pierre-fabre-group-3908875712?position=6&pageNum=10&refId=lUCpoL4OtWpdXIhZLSJ%2ByQ%3D%3D&trackingId=%2FOn%2F%2FbnWQ8vwdot%2F6DMK1g%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Qui sommes-nous ?\nPierre Fabre est le 2ème laboratoire dermo-cosmétique mondial, le 2ème groupe pharmaceutique privé français et le leader des produits vendus hors prescription dans les pharmacies en France.\nSon portefeuille compte plusieurs franchises médicales et marques internationales dont Pierre Fabre Oncologie, Pierre Fabre Dermatologie, Eau Thermale Avène, Klorane, Ducray, René Furterer, A-Derma, Naturactive et Pierre Fabre Oral Care.\nImplanté depuis toujours en région Occitanie, fabricant plus de 95% de ses produits en France, le groupe emploie près de 10 000 collaborateurs dans le monde et distribue ses produits dans quelque 130 pays. Pierre Fabre est détenu à 86% par la Fondation Pierre Fabre, une fondation reconnue d’utilité publique, et secondairement par ses collaborateurs à travers un plan d’actionnariat salarié.\nEn 2021, Ecocert Environnement a évalué la démarche de responsabilité sociétale et environnementale du Groupe selon la norme ISO 26000 du développement durable et lui a attribué le niveau « Excellence ».\nPierre Fabre est reconnu comme l’un des « Meilleurs Employeurs du Monde 2021 » par Forbes. Notre groupe est classé dans le Top 6 de l’industrie cosmétique et dans le Top 7 de l’industrie pharmaceutique dans le monde. Nous sommes convaincus que notre engagement et notre passion font préserver notre indépendance et vivre notre raison d'être.\nVotre mission :\nLes Laboratoires Pierre Fabre, engagés dans l'excellence et l'innovation, vous offrent la possibilité de mettre votre expertise en data science au service de projets novateurs et stratégiques.\nEn exploitant des techniques avancées d'IA (machine learning, IA Gen...), vous contribuerez à relever des défis commerciaux et opérationnels de prédiction et de prescription par la data.\nPour cela, nous recrutons notre futur(e) :\nDATA SCIENTIST\n– CDI-\nH/F -\nsitué à\nLAVAUR (81)\nAu cœur du Data Office (rattaché à la Direction Générale), vous rejoindrez une équipe pluridisciplinaire de haut niveau. Dans un cadre agile et propice à la synergie, votre rôle sera pivot à chaque phase des projets :\nCollaborer étroitement avec les départements opérationnels et exécutifs pour cerner leurs besoins et envisager des solutions data-driven.\nAssurer l'intégrité des données via leur nettoyage, agrégation et analyse exploratoire.\nConcevoir et déployer des modèles prédictifs en utilisant des algorithmes de pointe.\nPiloter des tests en conditions réelles pour valider les solutions proposées.\nDévelopper des interfaces de visualisation pour une interprétation intuitive des données.\nImplémenter les solutions retenues, en assurer la maintenance et les améliorations continues.\nAssurer une veille et tester les solutions d'IA Générative.\nEncadrer et former les talents émergents en data science.\nCe poste est à pourvoir\nau plus tôt selon votre disponibilité\ndans le cadre d’un CDI.\nLes \"plus\" du poste :\nVotre intégration au sein de notre communauté d'experts en data science et ingénierie informatique (les data champions) vous permettra de participer à des séminaires, des ateliers et des forums de discussion, favorisant l'échange de connaissances et le partage d'expériences.\nQui êtes-vous ?\nVous êtes doté(e) d'une formation supérieure en informatique ou en mathématiques appliquées (Master ou expérience équivalente), vous possédez une solide maîtrise des algorithmes d'apprentissage statistique.\nVous justifiez d'au moins 5 ans d'expérience dans le domaine, avec une compétence reconnue à toutes les étapes du cycle de projet en data science, y compris la gestion de bases de données volumineuses.\nVotre rigueur scientifique et votre capacité à vous adapter à de nouveaux challenges en science des données sont des atouts que vous avez su développer tout au long de votre parcours.\nVous êtes également en mesure de guider des data ingénieurs moins expérimentés et d'échanger efficacement avec des interlocuteurs variés.\nLes enjeux opérationnels concrets, notamment ceux liés au secteur de la pharma et de la dermo- cosmétique, vous motivent.\nVous excellez dans la communication de concepts complexes à des audiences variées, grâce à vos qualités relationnelles et votre aisance à l'oral.\nVotre expérience en développement collaboratif et votre attachement à la qualité et à la clarté du code sont essentiels.\nVous maîtrisez le français et l'anglais technique, et vous avez une expérience significative des\nprojets cloud et du développement agile\n.\nAtouts supplémentaires :\nNous valorisons votre expérience sur les plateformes cloud, en particulier Microsoft, et votre capacité à gérer d'importants volumes de données. Nous sommes attentifs à votre expertise en développement logiciel agile et à tout projet antérieur de mise en œuvre de solutions ML.\nEnvironnement technique :\nNos outils incluent Python, SQL, Tableau, Alteryx, POSIT, Snowflake, JMP entre autres.\nPackage de rémunération :\nVous bénéficiez d’un package de rémunération complet et attractif : intéressement, participation, actionnariat salarié avec abondement, mutuelle, prévoyance, 16 jours de RTT, CE …\nNous sommes convaincus que la diversité est une source d’épanouissement, d’équilibre social et de complémentarité pour nos collaborateurs, nos offres sont donc ouvertes à toutes et tous sans restriction.\nShow more\nShow less",
        "details": {
            "JobDetail": [],
            "TypeContract": "CDI",
            "Salary": "16",
            "Level": "",
            "Experience": "5 an(s)"
        },
        "title": "data scientist",
        "skills": {
            "ProgLanguage": [
                "Python"
            ],
            "DataBase": [
                "SQL"
            ],
            "DataVisualisation": [
                "Tableau"
            ],
            "DBMS": [
                "Snowflake"
            ],
            "Other": [
                "Machine Learning",
                "Cloud",
                "ML"
            ],
            "EnSoftSkils": [
                "Communication"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "Exotec",
        "location": "Lille, Hauts-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/computer-vision-deep-learning-engineer-at-exotec-3918170653?position=7&pageNum=10&refId=lUCpoL4OtWpdXIhZLSJ%2ByQ%3D%3D&trackingId=edYin4dnueh%2FCTr3wpqAMg%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Chez Exotec, nous mettons l'excellence technologique au service de la redéfinition des relations entre humains et robots. A travers le monde, nos solutions révolutionnent la façon dont nos clients délivrent leurs produits aux consommateurs finaux. Nous contribuons au succès des plus grandes marques du commerce et de l'industrie, tout en améliorant les conditions de travail de leurs salariés.\nPar l'alliance de l'intelligence artificielle et d'un hardware performant, nos robots sont désormais déployés dans le monde entier et leur succès a fait de nous la première licorne industrielle française.\nRejoindre Exotec, c'est l'opportunité de donner du sens à vos compétences. Grandissez avec plus de 600 ExoPeople dans le monde entier pour faire de vos idées des réalités.\nLa révolution robotique portée par Exotec ne fait que commencer, vous en êtes ?\nVos missions :\nConnaitre les dernières avancées dans le monde du Deep Learning et de la vision par ordinateur.\nIdentifier les angles d'améliorations des modèles et proposer de nouvelles solutions.\nCollecter et manipuler les données nécessaires à l'entraînement et l'évaluation de modèles.\nImplémenter et entrainer de nouveaux modèles.\nPartager la connaissance avec votre équipe et consolider vos résultats sous la forme de code et de documentation de qualité.\nTester vos algorithmes en conditions réelles.\nContribuer à une intégration complète de vos solutions en collaborant avec les autres équipes.\nConcevoir les méthodes de suivi des performances et d'identification de pistes d'améliorations.\nRequirements\nVous êtes diplômé d'une grande école d'ingénieur ou détenteur d'un doctorat\nVous avez de l'expérience en Deep Learning et en Computer Vision et vous aimez la recherche\nVous aimer coder et vous êtes à l'aise en développement avec Python et utilisez des librairies comme PyTorch, TensorFlow et OpenCV\nVous avez des connaissances en C++ et en Robotique\nVous avez de l'expérience dans le déploiement et l'exploitation de modèles de Machine Learning en production\nVous savez prendre des initiatives et collaborer dans une ambiance décontractée au sein d'une équipe jeune et dynamique\nUn niveau d'Anglais opérationnel, à l'oral comme à l'écrit, est nécessaire\nPoste basé à Croix, à 15mn en métro du centre-ville de Lille, à 30mn de Bruxelles, 1h de Paris et 2h de Londres\nBenefits\nCouverture mutuelle et prévoyance santé compétitive\nPrimes collectives et attribution de BSPCE\nPolitique famille avantageuse\nProgramme de mobilité interne et internationale\nNombreuses opportunités de formation et de développement\nChez Exotec, nous garantissons l'égalité des chances dans notre processus de recrutement. L'ensemble des candidatures reçues sont étudiées indépendamment de l'âge, du genre, de l'origine, de la religion, de la couleur de peau, de la nationalité, du sexe, du handicap, de l'orientation sexuelle ou de toute autre distinction protégée par la loi. Nous mettons en place un environnement de travail inclusif et respectueux de toutes les différences. En rejoignant le Pacte Parité, Exotec s'engage pour un écosystème French Tech plus paritaire.\nShow more\nShow less",
        "details": {
            "JobDetail": [],
            "TypeContract": "",
            "Salary": "",
            "Level": "",
            "Experience": null
        },
        "title": "Other",
        "skills": {
            "ProgLanguage": [
                "Python"
            ],
            "MachineLearning": [
                "PyTorch",
                "TensorFlow"
            ],
            "Other": [
                "Machine Learning"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "Hermès",
        "location": "Paris, Île-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/alternance-data-scientist-h-f-at-herm%C3%A8s-3890172447?position=8&pageNum=10&refId=lUCpoL4OtWpdXIhZLSJ%2ByQ%3D%3D&trackingId=kWxrs7B0%2FKNsohGsLL9Vww%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Contexte\nAlternance de 12 mois à pourvoir à partir de septembre.\nFace au développement de la maison, la Direction des Activités Retail Groupe souhaite renforcer son expertise et développer son équipe Retail Data afin de répondre à de nouvelles ambitions concernant la gestion et l’analyse de la Data pour le Retail.\nMissions\nVos principales missions seront :\nACCELERER LA MONTEE EN PUISSANCE DE LA DATA SCIENCE POUR LE RETAIL\nReprendre et améliorer les sujets IA existants au sein de l’équipe\nDévelopper de nouveaux algorithmes de Machine Learning à destination de la relation client et du Retail\nPromouvoir et animer l’utilisation de l’Intelligence Artificielle pour le retail en recensant et valorisant les cas d’usages de l’IA\nMONITORER LA PERFORMANCE COMMERCIALE\nEtudes Ad Hoc\nAssister l’équipe Retail Data dans la réalisation des études AD HOC à destination des entités de production et de nos filiales de distribution\nReporting\nAccompagner les Data Analysts dans la création de nouveaux reportings et leurs améliorations à destination des filiales de distribution et entités de production\nASSURER UNE VEILLE QUALITATIVE DES INNOVATIONS DATA SCIENCE APPLIQUEES AU RETAIL\nRecenser et centraliser les nouvelles méthodologies d’algorithmie applicables à l’univers du Retail\nMettre à disposition cette veille aux membres de l’équipe\nProfil recherché :\nEtudiant(e) en Bac +4/5 en grande école ou grande université, en spécialité Statistiques/Data Science\nConnaissance des Bases de données et à l’aise avec les langages de programmation (SQL, Python, etc.)\nLa connaissance de l’environnement AWS et ses composants (Sagemaker, etc.) est un plus\nLa connaissance de PowerBI est un plus\nLangues : Anglais courant (écrit et oral)\nCapacité d’analyse et esprit de synthèse\nCuriosité et faculté d’adaptation\nShow more\nShow less",
        "details": {
            "JobDetail": [],
            "TypeContract": "",
            "Salary": "",
            "Level": "",
            "Experience": null
        },
        "title": "data scientist",
        "skills": {
            "ProgLanguage": [
                "Python"
            ],
            "DataBase": [
                "SQL"
            ],
            "CloudComputing": [
                "AWS"
            ],
            "Other": [
                "Statistiques",
                "Machine Learning"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "IRSN",
        "location": "Saint-Paul-lez-Durance, Provence-Alpes-Côte d'Azur, France",
        "link": "https://fr.linkedin.com/jobs/view/data-scientist-pour-la-simulation-de-l-incendie-et-des-explosions-h-f-at-irsn-3909242968?position=9&pageNum=10&refId=lUCpoL4OtWpdXIhZLSJ%2ByQ%3D%3D&trackingId=oHFmObYU7gY4DVwRY3IQcg%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Vous intégrez le Laboratoire de l'Incendie et des Explosions (LIE) du Service des Agressions Internes et risques Industriels (SA2I) rattaché au Pôle Sûreté des installations et des systèmes nucléaires à Cadarache.\nLe SA2I réalise des expertises concernant la maîtrise des risques d'incendies, d'explosions et induits par l'activité humaine et des travaux de R&D dans ces mêmes domaines et plus généralement de la thermique et de la mécanique des fluides réactifs. Il initie, réalise ou suit des études et des recherches propres à répondre aux besoins de l'expertise dans son domaine de compétences.\nAu sein du service, le LIE a pour objectif principal d'améliorer la connaissance sur les risques incendie et explosion en milieu confiné et ventilé et de développer les modélisations physiques associées. Cette connaissance est capitalisée par le développement de logiciels scientifiques à champ et à zones pour simuler les scénarios d'incendie et d'explosion en milieux représentatifs des installations\nnucléaires. Il vient en soutien aux unités qui réalisent des expertises de sûreté et des programmes expérimentaux par l'utilisation de ces logiciels.\nEn tant que spécialiste en science des données, vous aurez quatre missions principales :\nexploiter les informations contenues dans les bases expérimentales disponibles\net/ou générées par des simulations CFD par des méthodes de \" machine learning pour pouvoir extrapoler/interpoler les résultats physiques fournis par les logiciels (vitesses de flamme, température, écoulement...) et conforter leurs applications dans les études de sureté.\ndévelopper des modèles par assimilation de données issues de campagnes\nexpérimentales et de simulations CFD pour conforter leurs applications dans les études de sureté.\ndévelopper des métamodèles rapides en investiguant les solutions les plus\nadaptées pour les problèmes physiques rencontrées en modélisation de l'incendie et des explosions. Ces modèles doivent permettre d'optimiser l'utilisation des logiciels développés au sein du service.\ndévelopper des méthodes d'analyse de sensibilité et de propagation des incertitudes pour l'identification des paramètres les plus influents des modèles numériques, en support à l'expertise et à l'orientation des recherches numériques et expérimentales.\nDans un environnement de travail où la compréhension et l'interprétation physique des phénomènes sont essentielles, vous devrez porter une attention particulière au niveau de confiance pouvant être accordé aux résultats obtenus par les métamodèles, ce qui pourrait notamment passer par le machine-learning informé par la physique, l'intelligence artificielle explicable et interprétable, les\nméthodes de validation et de quantification des incertitudes avancées...\nVous aurez à collaborer avec les data scientists de différentes unités pour élaborer, partager et développer les méthodes à mettre en oeuvre pour les applications propres au SA2I. Vous devrez progressivement vous acculturer aux problématiques métiers du service, concernant les installations expérimentales et les outils de modélisation, afin de proposer des solutions répondant aux besoins des utilisateurs et s'intégrant dans les chaînes de calcul actuelles.\nVous aurez un rôle à jouer dans l'acculturation des ingénieurs-chercheurs au domaine des sciences des données.\nVous êtes titulaire d'un diplôme d'ingénieur ou de 3e cycle universitaire. Vous justifiez de 3 ans ou plus d'expérience professionnelle dans les sciences des données.\nDes connaissances dans le domaine de la simulation numérique (CFD) seraient appréciées.\nVous maitrisez l'anglais.\nVous êtes rigoureux(se), force de proposition et disposez d'un esprit d'analyse et de synthèse ainsi que des capacités rédactionnelles.\nVous disposez de capacités de vulgarisation et d'écoute.\nVous avez un sens avéré du collectif.\n20496836-55584\nShow more\nShow less",
        "details": {
            "JobDetail": [],
            "TypeContract": "",
            "Salary": "",
            "Level": "",
            "Experience": "3 an(s)"
        },
        "title": "data scientist",
        "skills": {
            "ProgLanguage": [
                "R"
            ],
            "DataAnalytics": [
                "R"
            ],
            "Other": [
                "Machine Learning"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "Modjo",
        "location": "Paris, Île-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/ml-engineer-cdi-f-h-at-modjo-3909458542?position=10&pageNum=10&refId=lUCpoL4OtWpdXIhZLSJ%2ByQ%3D%3D&trackingId=0Z5jp0PzvUT51yLEVmvL8Q%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Modjo:\nModjo is the leader European AI Revenue Platform whose mission is to drive revenue teams productivity & performance with AI-extracted knowledge from customers interactions.\nWhile AI is challenging how companies work across the world and all industries, Modjo brings these new capabilities to sales teams thanks to a platform that analyzes all interactions sales people have with their customers to improve sales teams productivity, drive strategy, and increase revenue.\nWe are a growing team of over 65 people, helping over 400 clients like BouyguesTelecom, Doctolib, Spendesk and Payfit in France and abroad. 🌎\nJust like Slack, Zoom or Hubspot, Modjo is a product company. This means that our product is the core of what we are doing and how we are creating value to customers. Therefore, the success of the company relies on the capacity of its Tech & Product teams to deliver together the best product to its users.\nTeam organization :\nThe overall tech department is composed of 10 Software Engineers (2 squads), 2 ML Engineers, a Data Team (1 team lead + 1 analyst) and the CTO. You will be part of the Data Science team alongside the other ML Engineers.\nMission:\nModjo's core capabilities include capturing conversations between sales teams and their customers (video & audio recordings, emails..) and leveraging this data thanks to speech-to-text and various LLM-based processings to extract and structure data out of it.\nAs part of this, your main missions will be:\nCollaborating with Product and Engineering to build features that require machine-learning expertise\nBuild, maintain and optimize our infrastructure for doing production machine learning including our speech-to-text stack (processing thousands of hours of audio every day) and our infrastructure for using LLMs\nDesign and implement processes, tools and pipelines in order to work efficiently with LLMs for our multiple use cases\nStay up to date with latest speech-to-text and LLM technologies in order to include them in the product and build the relevant technological asset for Modjo to differentiate from basic competition. This includes exploring model-finetuning models and RAGs\nYour profile :\nWe think you would be a great fit if :\nYou have 3y+ experience in Machine Learning and Engineering\nYou have experience working with and knowledge about NLP, LLM and speech-to-text\nYou have experience with putting models in production, including monitoring and CI/CD\nYou are interested in solving real world use cases with LLMs and building the proper technology around it\nYou are eager to learn a lot in an autonomous way, both in Science and Engineering fields\nYou are willing to work in English (language of the team)\nYou want to join a company where the product you will be building is core to our strategy\nYou are looking for a challenging job, but also an environment where you can thrive and have fun on a day-to-day basis :)\nWe are looking for someone who will thrive and share our values:\n😃 Pleasure\n“If you Smile, things will work out” - Serena Williams\n✅ Action\n“Done is better than perfect” - Sheryl Sandberg\n📚 Continuous Learning\n“Amateurs call it Genius, masters call it practice” - Thierry Henry\n🤲 Team Spirit\n“Great things in business are never done by one person; they’re done by a team of people” - Steve Jobs\nShow more\nShow less",
        "details": {
            "JobDetail": [],
            "TypeContract": "",
            "Salary": "",
            "Level": "",
            "Experience": null
        },
        "title": "machine learning engineer",
        "skills": {
            "Collaboration": [
                "Slack",
                "Teams"
            ],
            "Other": [
                "Machine Learning",
                "ML",
                "CI/CD"
            ],
            "EnSoftSkils": [
                "Organization"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "Mirakl",
        "location": "France",
        "link": "https://fr.linkedin.com/jobs/view/senior-data-scientist-at-mirakl-3879684286?position=1&pageNum=12&refId=%2BSqq7I81JvLhh66Hu4n2TA%3D%3D&trackingId=mNNdDGXEHdQdszGAfOTmVA%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Mirakl, leader et pionnier de l’économie de plateforme, propose aux entreprises une suite unique de solutions leur permettant de transformer significativement leur e-commerce afin d'accélérer de façon durable et rentable leur croissance. Depuis 2012, Mirakl accompagne les entreprises B2C et B2B avec la technologie la plus avancée, sécurisée et évolutive leur permettant de digitaliser leur activité et d'élargir leur offre via la marketplace ou le dropship, faciliter la gestion des catalogues et des paiements de leurs fournisseurs pour plus d'efficacité, offrir une expérience d'achat personnalisée à leurs clients, et augmenter leurs profits grâce au retail media. Basée à Paris et Boston, Mirakl est certifiée Great Place to Work.\nA propos de Mirakl Labs\nNos équipes techniques et produits, nommées Mirakl Labs, sont principalement réparties entre nos 2 hubs situés à Paris et à Bordeaux. Elles collaborent au quotidien afin d'adresser les problématiques de nos clients et utilisateurs en répondant à différents challenges liés aux nouvelles fonctionnalités, à la scalabilité, la sécurité et l’ergonomie…\nElles opèrent en mode agile et s'organisent en Squads composées d'un Squad Lead, de 5 développeurs, d'un Product Manager et d'un QA. Chaque Squad est spécialisée sur un scope fonctionnel afin de concevoir et réaliser de nouvelles features, leurs évolutions et des APIs (avec un découpage en micro-services). Nos équipes Infrastructure, Architecture, Sécurité, Documentation, Product Design, Data et Support opèrent en transverse en apportant leur expertise et de la cohérence sur l’ensemble des produits.\nToutes les équipes sont responsables de leur périmètre et chacun des collaborateurs apporte son expérience et ses idées. Innovation, feedback et implication dans les prises de décision sont au cœur de notre philosophie.\nEt pour favoriser ce partage avec d’autres passionnés, nous sommes sponsors, speakers, et hôtes de différents événements, meetups, et associations de la scène Tech en France. Au cours des dernières années, nous avons participé à des événements tels que Devoxx, ReactEurope, ProductConf et Flupa UX Days.\nA propos du job\nIntégré(e) dans notre équipe Data Science, votre principale mission sera de prototyper, itérer, et mettre en production des algorithmes en collaboration avec les équipes Produit, les Data Engineers et les équipes de développement. Les sujets que vous traiterez auront un vrai impact sur nos clients : l’ambition est d’exploiter au maximum nos données riches et variées afin de développer leur chiffre d'affaires, d’optimiser la gestion opérationnelle de leur marketplace et de garantir la sécurité des utilisateurs et des transactions.\nA propos de l’équipe\nGet to Know the Data Science Team That Powers the Mirakl Platform\nVoici quelques sujets actuels & futurs :\nCatégorisation de produits\nMappings de données produit\nExtraction de caractéristiques produit à partir du texte et des images\nDétection de comportements frauduleux\nEstimation de la date de livraison d’une commande\nMonitoring de la qualité de service des vendeurs\nRecommandations de produits (upsell, cross-sell, retargeting, …)\nPersonnalisation des résultats de recherche\nPersonnalisation de l’affichage de contenu\nPrédiction de produits tendance\nAide/Suggestion de réponses au customer service\nAffichage de produits sponsorisés ou de publicités maximisant le taux de clic\nCe qu’il y a pour vous dans ce job\nImplémenter des algorithmes qui auront un impact visible sur plus de 500 sites e-commerce/marketplaces dans 40 pays dont certains une volumétrie très importantes (millions de produits, de clients, de commandes par an)\nDes techniques diverses et variées (Heuristiques, Deep Learning, NLP, Image Processing, Time Series, LLM, etc.)\nUne vraie autonomie et responsabilité dans les projets dont vous avez l’ownership\nLa possibilité d'avoir un contrat freelance ou CDI\nNotre stack et nos outils\nPython, Tensorflow, Keras, Pytorch, Databricks, Spark, Aws (Amazon Redshift, s3, etc.), SQL, Airflow, Delta Lake\nAu quotidien\n, vous allez :\nAnalyser, préparer les données, prototyper des algorithmes\nLes mettre en production en collaboration avec les Data Engineers et les équipes de développement\nFaire des dashboards afin d’illustrer la pertinence des algorithmes et de monitorer la production\nPrésenter les résultats au weekly data science\nParticiper aux sessions de brainstorming de l’équipe\nÉchanger avec les autres équipes pour affiner les cas d’utilisation, l’expérience utilisateur et les modes d’intégration\nVous aimerez ce job si :\nVous avez 4 à 5 ans d'expérience minimum en tant que Data Scientist, avec une expérience significative en machine learning appliqué en entreprise\nVous avez déjà mis en production des algorithmes de Machine Learning\nVous avez une bonne connaissance des algorithmes de Deep Learning (image et/ou texte) et des architectures State-Of-the-Art - par exemple les Transformers\nVous maîtrisez Python, Tensorflow ou/et PyTorch\nVous avez une expérience en développement Spark\nVous êtes pragmatique, data-driven et orienté métier\nVous aimez avoir l’ownership de vos sujets\nVous êtes autonome et avez un très bon esprit d’équipe\nVous avez un esprit positif : respect et bienveillance font partie de vos valeurs\nVous aimez partager votre travail dans le cadre de présentations internes, dans des conférences ou en rédigeant des articles\nPetit plus :\nVous avez une expérience en environnement e-commerce et sur des algorithmes de systèmes de recommandations\nMirakl est engagée en faveur de la diversité, de l’égalité des chances et de l’inclusion. Nous célébrons nos différences car nous sommes convaincus que les qualités visibles et invisibles de chaque Mirakl Worker sont une source de force et d’innovation. Dans le cadre de cet engagement, nous étudions toutes les candidatures sans distinction de : genre, ethnicité, religion, orientation sexuelle, handicap, âge ou toute autre caractéristique protégée par la loi.\nShow more\nShow less",
        "details": {
            "JobDetail": [],
            "TypeContract": "CDI",
            "Salary": "",
            "Level": "",
            "Experience": "5 an(s)"
        },
        "title": "data scientist",
        "skills": {
            "ProgLanguage": [
                "Python"
            ],
            "DataBase": [
                "SQL"
            ],
            "BigData": [
                "Databricks",
                "Spark"
            ],
            "MachineLearning": [
                "PyTorch",
                "TensorFlow",
                "Keras"
            ],
            "CloudComputing": [
                "AWS"
            ],
            "Automation": [
                "Airflow"
            ],
            "Other": [
                "Machine Learning"
            ],
            "EnSoftSkils": [
                "Collaboration"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "Sully Group",
        "location": "Grenoble, Auvergne-Rhône-Alpes, France",
        "link": "https://fr.linkedin.com/jobs/view/ing%C3%A9nieur-data-scientist-h-f-%C3%A0-grenoble-at-sully-group-3905268593?position=2&pageNum=12&refId=%2BSqq7I81JvLhh66Hu4n2TA%3D%3D&trackingId=P8Db1QOy4T6bBQS43vSVsw%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Au sein d'une équipe de 6 personnes, vous intervenez en mission chez notre client basé à Grenoble comme Data Ingénieur.\nVous participerez à un nouveau projet orienté Intelligence Artificielle appliquée à la mobilité.\nVos missions\nCollecter, transformer et nettoyer des données extraites\nCréation de tableaux de bord\nContribuer à l’effort d’animation technique, de veille technologique et d’innovation\nParlons de vous\nVous possédez une première expérience comme Data Scientist\nVous maitrisez Python\nVous avez l'esprit d'équipe\nShow more\nShow less",
        "details": {
            "JobDetail": [],
            "TypeContract": "",
            "Salary": "",
            "Level": "",
            "Experience": null
        },
        "title": "data engineer",
        "skills": {
            "ProgLanguage": [
                "Python"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "Davidson consulting",
        "location": "Nantes, Pays de la Loire, France",
        "link": "https://fr.linkedin.com/jobs/view/data-scientist-h-f-at-davidson-consulting-3913989716?position=3&pageNum=12&refId=%2BSqq7I81JvLhh66Hu4n2TA%3D%3D&trackingId=fpEQDidy%2B3idIFLcxMGygQ%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Rejoindre Davidson, ce n'est pas seulement intégrer un groupe de 3000 consultants dans 8 pays et 3 continents, c'est intégrer LA société qui a été élue par ses salariés Great Place To Work France et Europe pendant 4 ans ainsi que la plus grande B Corp de France !\nLes « B Corp » formant une communauté de sociétés qui ont décidé d'être non pas les meilleures du monde mais les meilleures POUR le monde.\nParce que notre développement repose sur des principes forts :\nUn profond respect de l'ensemble de nos parties prenantes : consultants, clients et fournisseurs. Car si le travail ne fait pas le bonheur, il peut cependant faire le malheur. Nous nous engageons donc à écouter, agir avec honnêteté et promouvoir l'équité\nUne empreinte environnementale minimale, et sociétale maximale. C'est pourquoi, au-delà des missions que vous réaliserez, vous pourrez également contribuer à des projets que Davidson soutient : missions de solidarité internationale (avec Planète Urgence), accompagnement d'étudiant(e)s issus de milieux peu favorisés (avec Article 1), investissement dans des startups développant des solutions innovantes !\nUn Management adhocratique basé sur la mise en oeuvre des principes de l'entreprise horizontale et du management tribal.\nSur ce dernier point une précision d'importance : le bien-être au travail est un luxe qu'il faut pouvoir s'offrir en étant une entreprise solide. Ceci induit pour les davidsonien(ne)s d'allier prises d'initiative, engagement et professionnalisme. Car sans travail, le talent n'est qu'une sale manie. Et cela nous incite à chercher à recruter des éléments meilleurs que nous. Dans une organisation classico-hiérarchique, il peut être bénéfique d'avoir une armée de gens qui travaillent pour vous. Dans une adhocratie, ils causent des dégâts.\nDans le cadre de projets Data Science menés par Davidson pour ses clients dans des secteurs variés (Gaming, Luxe, Télécoms, Finance, etc.), tu interviendras en tant que spécialiste ML & DL. Ta mission consistera à accompagner des experts métiers sur des problématiques variées : traitement du langage naturel, reconnaissance d images, détection de la fraude, système de recommandation, agent conversationnel, etc.\nÀ Ces Fins Tes Missions Consisteront à\nAnimer des ateliers d expression de besoins\nIdentifier, intégrer et croiser les sources de données (structurées ou non structurées)\nPréparer et analyser des données\nCréer, implémenter des mod��les\nPrototyper et valider les algorithmes\nMesurer les gains obtenus\nCommuniquer et capitaliser sur les résultats\nRéaliser une veille technologique ainsi que des études d opportunités\nCompétences requises ou à acquérir\nDe formation ingénieur / Bac +5, tu as déjà réussi plusieurs projets dans le domaine de la Data Science. Avec au minimum 2 ans d expérience professionnelle (et c est vraiment un minimum hein)\nDes compétences scripting sont nécessaires. Et mieux vaut être fort en maths !\nAptitudes / Savoir-être\nExcellent relationnel\nCapacité d analyse\nCuriosité\nPédagogie\nAnglais + SQL / Python bilingue\nShow more\nShow less",
        "details": {
            "JobDetail": [],
            "TypeContract": "",
            "Salary": "",
            "Level": "",
            "Experience": "4 an(s)"
        },
        "title": "data scientist",
        "skills": {
            "ProgLanguage": [
                "Python"
            ],
            "DataBase": [
                "SQL"
            ],
            "Other": [
                "ML"
            ],
            "EnSoftSkils": [
                "Initiative"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "Davidson consulting",
        "location": "Rennes, Brittany, France",
        "link": "https://fr.linkedin.com/jobs/view/data-scientist-h-f-at-davidson-consulting-3913988737?position=4&pageNum=12&refId=%2BSqq7I81JvLhh66Hu4n2TA%3D%3D&trackingId=M3VXBM3FYui5MlPlGZtuPQ%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Rejoindre Davidson, ce n'est pas seulement intégrer un groupe de 3000 consultants dans 8 pays et 3 continents, c'est intégrer LA société qui a été élue par ses salariés Great Place To Work France et Europe pendant 4 ans ainsi que la plus grande B Corp de France !\nLes « B Corp » formant une communauté de sociétés qui ont décidé d'être non pas les meilleures du monde mais les meilleures POUR le monde.\nParce que notre développement repose sur des principes forts :\nUn profond respect de l'ensemble de nos parties prenantes : consultants, clients et fournisseurs. Car si le travail ne fait pas le bonheur, il peut cependant faire le malheur. Nous nous engageons donc à écouter, agir avec honnêteté et promouvoir l'équité\nUne empreinte environnementale minimale, et sociétale maximale. C'est pourquoi, au-delà des missions que vous réaliserez, vous pourrez également contribuer à des projets que Davidson soutient : missions de solidarité internationale (avec Planète Urgence), accompagnement d'étudiant(e)s issus de milieux peu favorisés (avec Article 1), investissement dans des startups développant des solutions innovantes !\nUn Management adhocratique basé sur la mise en oeuvre des principes de l'entreprise horizontale et du management tribal.\nSur ce dernier point une précision d'importance : le bien-être au travail est un luxe qu'il faut pouvoir s'offrir en étant une entreprise solide. Ceci induit pour les davidsonien(ne)s d'allier prises d'initiative, engagement et professionnalisme. Car sans travail, le talent n'est qu'une sale manie. Et cela nous incite à chercher à recruter des éléments meilleurs que nous. Dans une organisation classico-hiérarchique, il peut être bénéfique d'avoir une armée de gens qui travaillent pour vous. Dans une adhocratie, ils causent des dégâts.\nDans le cadre de projets Data Science menés par Davidson pour ses clients dans des secteurs variés (Gaming, Luxe, Télécoms, Finance, etc.), tu interviendras en tant que spécialiste ML & DL. Ta mission consistera à accompagner des experts métiers sur des problématiques variées : traitement du langage naturel, reconnaissance d images, détection de la fraude, système de recommandation, agent conversationnel, etc.\nÀ Ces Fins Tes Missions Consisteront à\nAnimer des ateliers d expression de besoins\nIdentifier, intégrer et croiser les sources de données (structurées ou non structurées)\nPréparer et analyser des données\nCréer, implémenter des modèles\nPrototyper et valider les algorithmes\nMesurer les gains obtenus\nCommuniquer et capitaliser sur les résultats\nRéaliser une veille technologique ainsi que des études d opportunités\nCompétences requises ou à acquérir\nDe formation ingénieur / Bac +5, tu as déjà réussi plusieurs projets dans le domaine de la Data Science. Avec au minimum 2 ans d expérience professionnelle (et c est vraiment un minimum hein)\nDes compétences scripting sont nécessaires. Et mieux vaut être fort en maths !\nAptitudes / Savoir-être\nExcellent relationnel\nCapacité d analyse\nCuriosité\nPédagogie\nAnglais + SQL / Python bilingue\nShow more\nShow less",
        "details": {
            "JobDetail": [],
            "TypeContract": "",
            "Salary": "",
            "Level": "",
            "Experience": "4 an(s)"
        },
        "title": "data scientist",
        "skills": {
            "ProgLanguage": [
                "Python"
            ],
            "DataBase": [
                "SQL"
            ],
            "Other": [
                "ML"
            ],
            "EnSoftSkils": [
                "Initiative"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "Pictarine",
        "location": "Labège, Occitanie, France",
        "link": "https://fr.linkedin.com/jobs/view/data-scientist-at-pictarine-3911762881?position=5&pageNum=12&refId=%2BSqq7I81JvLhh66Hu4n2TA%3D%3D&trackingId=heHC6icEiO9RWOdGLC%2Bu1g%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Mission and challenges 🎯\nSi tu es passionné par le développement d’outils en transformant des données brutes en informations claires et exploitables, le tout dans une startup en pleine croissance, c'est l'opportunité parfaite pour toi !\nCe sera l’occasion d’utiliser toute ta créativité pour fournir les bons outils aux équipes de Pictarine dans le but d’optimiser la prise de décisions.\nTu rejoindras l’équipe Engineering, composée des pôles dev et data 🤖 ! Tu travailleras en collaboration avec l’équipe tech (les data analyst, les data engineer, etc.), l’équipe produit (les PM, les user researchers, etc.), et bien d’autres équipes.\nTon Rôle Comprendra Les Aspects Suivants\nUtiliser des techniques avancées d'analyse de données pour comprendre le comportement des clients, y compris l'analyse des feedbacks clients (NLP) et la segmentation des clients (clusterisation/segmentation)\nIdentifier les clients VIP et comprendre les facteurs qui contribuent à leur fidélité à Pictarine (rétention, etc.)\nAnalyser les données transactionnelles et comportementales pour détecter les corrélations entre les variables et identifier les tendances significatives\nDévelopper et mettre en œuvre des modèles prédictifs pour anticiper le comportement d'achat des clients, en distinguant les returning clients des nouveaux clients\nCollaborer avec les équipes marketing pour optimiser les campagnes de fidélisation, les programmes de récompenses et les stratégies de tarification en utilisant des analyses de données approfondies\nCommuniquer efficacement les résultats des analyses complexes aux parties prenantes non techniques et recommander des actions stratégiques basées sur les insights obtenus\nProfil Recherché\nAbout you 💎\nTu as au moins 5 ans d’expérience sur un poste de Data Scientist\nTu maîtrises des techniques d'analyse de données avancées, y compris l'apprentissage automatique, la modélisation statistique, l'analyse prédictive et la segmentation\nTu as d’excellentes compétences en programmation, notamment en Python, ainsi qu'une connaissance pratique des outils d'analyse de données (p. ex. pandas, scikit-learn, TensorFlow etc.)\nTu es familier avec le data warehouse suivant : BigQuery\nTu as des connaissances avec un ou plusieurs outils de data visualisation comme Looker Studio, Tableau, Power BI ou Dataiku\nTu es curieux de tester des nouvelles technologies et packages\nTu es doté d’excellentes qualités relationnelles, de communication et de vulgarisation\nTu es un team player et toujours à l'affût de nouvelles idées\nWork @ Pictarine✨\nUn environnement de travail agile, collaboratif, international et multiculturel\nDes perspectives d’évolution rapides\nDes locaux tout beaux à Labège avec du matériel dernier cri (mais aussi des snacks à profusion et un frigo à boissons toujours bien rempli)\nUn apprentissage permanent : conférence, meet-up, Pictarine Academy, cours d’anglais.\nDes events tous les mois : massage, pilates, TGIF, team building .\nUn environnement de travail flexible : horaires, politique de remote hybride.\nUn package de rémunération attractif : salaire compétitif, RTT, mutuelle& prévoyance 100% prise en charge, intéressement.\nDes petits + : Développement de photos gratuit, subvention sport, 3 jours “entraide familiale”, jours de congés en plus avec l'ancienneté...🤫on ne te dévoile pas tout!\nRecruitment process\n⚙️\nTu souhaites nous rejoindre ? Viens rencontrer les gens avec qui tu vas bosser :\n1er échange pour apprendre à se connaître avec Akram ou Marie (15’)\nEntretien d’équipe RH/Manager avec Marie et des membres de l'équipe data (60-90’)\nTest pratique afin de nous montrer tes talents 🙂 (durée selon test)\nEntretien final avec 2 membres du CODIR (120’)\nWelcome aboard !\nShow more\nShow less",
        "details": {
            "JobDetail": [
                "Hybride",
                "Remote"
            ],
            "TypeContract": "",
            "Salary": "100, 100",
            "Level": "",
            "Experience": "5 an(s)"
        },
        "title": "data scientist",
        "skills": {
            "ProgLanguage": [
                "Python"
            ],
            "DataAnalytics": [
                "Pandas"
            ],
            "MachineLearning": [
                "Scikit-Learn",
                "TensorFlow"
            ],
            "DataVisualisation": [
                "Power BI",
                "Tableau"
            ],
            "DBMS": [
                "BigQuery"
            ],
            "EnSoftSkils": [
                "Communication",
                "Collaboration"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "Liberty Rider",
        "location": "Toulouse, Occitanie, France",
        "link": "https://fr.linkedin.com/jobs/view/data-scientist-qui-sauve-des-vies-at-liberty-rider-3918799919?position=6&pageNum=12&refId=%2BSqq7I81JvLhh66Hu4n2TA%3D%3D&trackingId=EOLgfbCj3r66nVZ3UH4PDA%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Environnement Technique\nDes algorithmes de détection d'accident, de reconnaissance d’activité, de cartographie, ...\nMachine learning (apprentissage supervisé, TensorFlow, ONNX)\nTraitement du signal (filtrage, FFT, ...)\nDes algorithmes temps-réel intégrés à des applications mobiles natives (Kotlin, Swift)\nUn environnement d'expérimentation avec Python et NumPy\nDes datasets riches, à améliorer constamment\nCode reviews, intégration continue, releases automatisées\nTes Missions\nTu rejoindras l’équipe multidisciplinaire en charge des solutions de détection d’accident Liberty Rider.\nTa responsabilité sera l'amélioration de nos algorithmes et de nos datasets : surveillance des performances, investigation des défauts, recherche de solutions et d'innovations, expérimentation itérative, veille sur l'état de l'art, contribution à la stratégie R&D.\nComme nous sommes une petite équipe tu pourras contribuer sur d'autres sujets suivant tes goûts, ton niveau d'expérience, et les priorités du moment : implémentation dans les apps mobiles ou backend, roadmap technique globale, business intelligence...\nProfil Recherché\nPostule chez Liberty si :\ntu as minimum 3 ans d'expérience professionnelle\ntu veux avoir un vrai impact sur la vie des gens\ntu fais du vélo ou de la moto\ntu prends tes décisions en pensant à l’utilisateur final et aux enjeux de ton entreprise\ntu aimes communiquer et travailler en équipe\nCe Que Nous T’offrons\nun contrat en CDI, dès maintenant, et des tickets restaurant\ndes bureaux au coeur de Toulouse, du télétravail jusqu'à 80%\nun salaire correspondant à ton profil (50-65k€)\nContact : jobs@liberty-rider.com\nShow more\nShow less",
        "details": {
            "JobDetail": [],
            "TypeContract": "CDI",
            "Salary": "50",
            "Level": "",
            "Experience": "3 an(s)"
        },
        "title": "data scientist",
        "skills": {
            "ProgLanguage": [
                "R",
                "Kotlin",
                "Python"
            ],
            "DataAnalytics": [
                "R",
                "NumPy"
            ],
            "MachineLearning": [
                "TensorFlow"
            ],
            "Other": [
                "Machine Learning"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "ENGIE Global Energy Management & Sales",
        "location": "Courbevoie, Île-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/data-scientist-at-engie-global-energy-management-sales-3779080378?position=7&pageNum=12&refId=%2BSqq7I81JvLhh66Hu4n2TA%3D%3D&trackingId=PIi2wJGsqM9MOwgNgjgAaA%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "About US (GEMS):\nENGIE Global Energy Management & Sales (GEMS) provides energy supply solutions and risk management services to support its clients through their decarbonization journey, while optimizing ENGIE’s assets and contributing to value creation.\nENGIE is a global reference in low-carbon energy and services with a leading energy management business, piloted by its entity \"Global Energy Management & Sales\" who built its savoir-faire managing the Group’s large and diverse asset portfolio over 20+ years.\n3,300 employees around the world develop our solutions, through +20 international business platforms. We cover the full energy mix: renewable and thermal power, natural gas & LNG, biomass, environmental products. Our experts provide tailor made solutions based on a wide range of savoir-faire in energy management with a strong focus on decarbonation and decentralization.\nOur +120,00 clients span the entire value chain: producers, asset developers, financial players, utilities, distributors and industrials. Our global reach and strong local presence enable us to offer these diverse clients tailor-made services and respond to rapid changes in mature or emerging markets alike.\nOur 4 expertises:\nAsset management\nEnergy transition services\nEnergy supply & global commodities\nRisk management & market access\nAt GEMS we encourage breakthrough results, team spirit, curiosity and innovation while preserving the right work/life balance for you.\nMore info on GEMS Hub ( https://gems.engie.com ) or LinkedIn ( https://www.linkedin.com/company/engie-global-energy-management-solutions ).\nJob Description\nAs Trading Data Scientist, you will be responsible for:\nDesigning and implementing new business use cases, going through rotations in the business divisions.\nActing as Data science expert for GEM (tools, methodology)\nEnsuring Market intelligence on Data Science topics\nLiaising with other Engie Data Science communities and projects\nThe Trading Data Scientist will be based in the transversal Data team located in Paris and will report to the Chief Data Officer.\nSome of the initial use cases may include optimization of trading/hedging strategies, customer flow data and management of full supply contracts\nProfile\nStrong academic background, ideally from Engineering, Mathematics, Physics or Computing\nExperience in a commodity trading environment is a plus\nPower and gas markets fundamentals knowledge is a plus\nTechnical and professional skills\n:\nExcellent research and analytical skills, with the ability to synthesize analysis into concrete value creation\nExcellent quantitative skills\nStrong Programming skills: Python, C# is a plus\nData management skills\nTeam player\nSoft skills and competencies\n:\nAbility to work under pressure in a fast-paced environment\nSelf-motivated and result driven with a high level of initiative and creative problem solving\nTeam player\nShow more\nShow less",
        "details": {
            "JobDetail": [
                "Full"
            ],
            "TypeContract": "",
            "Salary": "",
            "Level": "",
            "Experience": null
        },
        "title": "data scientist",
        "skills": {
            "ProgLanguage": [
                "Python"
            ],
            "EnSoftSkils": [
                "Initiative",
                "Problem Solving"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "Hashlist",
        "location": "Paris",
        "link": "https://fr.linkedin.com/jobs/view/data-scientist-automotive-at-hashlist-3851788714?position=8&pageNum=12&refId=%2BSqq7I81JvLhh66Hu4n2TA%3D%3D&trackingId=0X3HUf%2Fn3KYYGjd1Z%2FNN2Q%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Hashlist is a platform for tech positions & projects within the automotive sector.\nWe work with some of the largest OEMs, Tier1s, and Ecosystem Players developing for the automotive sector to help them fill on-demand tech talent gaps faster.\nAre you ready to be a part of that journey? We are now looking for a Data Scientist in Paris, France.\nResponsibilities:\nCollect, process, and clean data from various automotive systems and sources, including vehicle telemetry, customer usage patterns, manufacturing processes, and external datasets, to prepare it for analysis.\nPerform in-depth data analysis using statistical methods and data analytics tools to identify trends, patterns, and insights that can inform product development, operational improvements, and strategic decision-making.\nDevelop and maintain dashboards, reports, and visualizations to communicate findings and recommendations to both technical and non-technical stakeholders within Hashlist and its automotive partners.\nCollaborate with cross-functional teams to define data analysis requirements and objectives, ensuring that data analysis projects align with business goals and contribute to the enhancement of automotive products and services.\nApply machine learning algorithms and predictive modeling techniques to forecast trends, optimize operations, and enhance vehicle performance and customer experiences.\nEnsure data integrity and compliance with data protection regulations and best practices, managing data securely and ethically.\nProvide analytical support for ad-hoc queries and projects, contributing to the overall data-driven culture within the organization.\nQualifications:\nBachelor’s or Master’s degree in Data Science, Statistics, Computer Science, or a related field, with a strong emphasis on quantitative analysis.\nProven experience in data analysis, with expertise in using statistical software and programming languages such as Python, R, SQL, or similar tools for data manipulation and analysis.\nStrong knowledge of data visualization tools (e.g., Tableau, Power BI, Google Data Studio) and the ability to create impactful reports and dashboards.\nFamiliarity with machine learning techniques and tools, and experience applying these methods to real-world datasets to solve complex problems.\nExcellent analytical and problem-solving skills, with the ability to interpret complex data sets and provide actionable insights.\nNext steps:\nPress \"Apply\"\nWe will review your application\nIf qualified, you will be accepted into the network and can be considered for this and similar positions & projects.\nShow more\nShow less",
        "details": {
            "JobDetail": [],
            "TypeContract": "",
            "Salary": "",
            "Level": "",
            "Experience": null
        },
        "title": "data scientist",
        "skills": {
            "ProgLanguage": [
                "R",
                "Python"
            ],
            "DataBase": [
                "SQL"
            ],
            "DataAnalytics": [
                "R"
            ],
            "DataVisualisation": [
                "Power BI",
                "Tableau"
            ],
            "Collaboration": [
                "Teams"
            ],
            "Other": [
                "Machine Learning"
            ],
            "EnSoftSkils": [
                "Organization"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "VINCI Construction France",
        "location": "Chevilly-Larue, Île-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/data-scientist-f-h-at-vinci-construction-france-3907122405?position=9&pageNum=12&refId=%2BSqq7I81JvLhh66Hu4n2TA%3D%3D&trackingId=c4ss6NnUK7FLuULm%2BXevUA%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Au sein du Groupe VINCI, leader de la construction et des concessions, employant plus de 280 000 salariés à travers plus de 120 pays, l’équipe Synaps’Up spécialisée dans l’intelligence artificielle poursuit son développement.\nL’ambition de cette activité innovante est de décupler la performance de VINCI Construction avec des solutions digitales et IA concrètes. Pour cela Synaps’Up regroupe des profils riches et complémentaires : ingénieurs génie civil, data scientists et développeurs. Tous travaillent ensemble à la création des nouveaux outils de la construction.\nIssue de VINCI Construction en France et du programme d’intrapreneuriat de Léonard, la structure dédiée à l’innovation du Groupe VINCI, Synaps’Up vous permettra d’évoluer dans un environnement de type start-up tout en bénéficiant de l’écosystème d’un grand groupe du CAC40.\nDescription De La Mission\nVous travaillerez sur différents cas d’usage métier en équipe avec des ingénieurs Génie Civil et des développeurs pour mettre en œuvre les outils du futur de l’ingénierie de la construction ! Votre rôle sera de mettre au point et développer les solutions de Machine Learning répondant à des problématiques concrètes.\nPour cela vous travaillerez sur l’ensemble du cycle de vie des solutions :\nEn amont, vous participerez à l’analyse des besoins métiers et les traduirez sous l’aspect Machine Learning et optimisation\nEn développement, vous réaliserez les premiers prototypes jusqu’à la mise en œuvre d’une solution fonctionnelle et efficiente\nVous déploierez le modèle, l’industrialiserez et l’améliorerez\nNos solutions réunissent le meilleur des deux mondes de l’IT et de la Construction en mêlant optimisation et data science avec l’ingénierie de la construction. Les thématiques de travail et les technologies sont passionnantes, vous allez vous plaire chez nous !\nBAC+5 diplômé d’une école d’ingénieur ou d’une Université en Mathématiques ou en Informatique\nCurieux et autonome vous avez déjà une première expérience concluante de développement d’un projet d’optimisation ou de Machine Learning\nSolides connaissances théoriques et pratiques des méthodes statistiques et de Machine Learning\nTrès bonne maîtrise des outils Python de Data-Science (pandas, numpy, scikit-learn, pytorch, tensorflow …)\nMaîtrise des outils de développement collaboratifs (git)\nExpérience en qualité logicielle, tests unitaires, programmation orientée objet\nUne expérience en déploiement de modèles sur un Cloud (Azure ou autre) et en MLOps serait un plus\nPourquoi nous rejoindre ?\nPlan épargne entreprise et prime d’intéressement\nEquipe jeune, dynamique et surtout extrêmement sympathique !\nTélétravail jusqu’à deux jours par semaine\nRestaurant d’entreprise\nSalle de sport d’entreprise dans les locaux + Piscine à moins de 500m\nShow more\nShow less",
        "details": {
            "JobDetail": [],
            "TypeContract": "",
            "Salary": "",
            "Level": "Bac+5",
            "Experience": null
        },
        "title": "data scientist",
        "skills": {
            "ProgLanguage": [
                "Python"
            ],
            "DataAnalytics": [
                "NumPy",
                "Pandas"
            ],
            "MachineLearning": [
                "Scikit-Learn",
                "TensorFlow",
                "PyTorch"
            ],
            "CloudComputing": [
                "Azure"
            ],
            "DevTools": [
                "Git"
            ],
            "Other": [
                "Statistiques",
                "Machine Learning",
                "Cloud"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "Mirakl",
        "location": "Paris, Île-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/senior-data-scientist-at-mirakl-3767995717?position=1&pageNum=15&refId=wJnfW9FfV7ATob%2FRARlIng%3D%3D&trackingId=7%2FpbLUYDf14u2LOJaYegEg%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Mirakl, leader et pionnier de l’économie de plateforme, propose aux entreprises une suite unique de solutions leur permettant de transformer significativement leur e-commerce afin d'accélérer de façon durable et rentable leur croissance. Depuis 2012, Mirakl accompagne les entreprises B2C et B2B avec la technologie la plus avancée, sécurisée et évolutive leur permettant de digitaliser leur activité et d'élargir leur offre via la marketplace ou le dropship, faciliter la gestion des catalogues et des paiements de leurs fournisseurs pour plus d'efficacité, offrir une expérience d'achat personnalisée à leurs clients, et augmenter leurs profits grâce au retail media. Basée à Paris et Boston, Mirakl est certifiée Great Place to Work.\nA propos de Mirakl Labs\nNos équipes techniques et produits, nommées Mirakl Labs, sont principalement réparties entre nos 2 hubs situés à Paris et à Bordeaux. Elles collaborent au quotidien afin d'adresser les problématiques de nos clients et utilisateurs en répondant à différents challenges liés aux nouvelles fonctionnalités, à la scalabilité, la sécurité et l’ergonomie…\nElles opèrent en mode agile et s'organisent en Squads composées d'un Squad Lead, de 5 développeurs, d'un Product Manager et d'un QA. Chaque Squad est spécialisée sur un scope fonctionnel afin de concevoir et réaliser de nouvelles features, leurs évolutions et des APIs (avec un découpage en micro-services). Nos équipes Infrastructure, Architecture, Sécurité, Documentation, Product Design, Data et Support opèrent en transverse en apportant leur expertise et de la cohérence sur l’ensemble des produits.\nToutes les équipes sont responsables de leur périmètre et chacun des collaborateurs apporte son expérience et ses idées. Innovation, feedback et implication dans les prises de décision sont au cœur de notre philosophie.\nEt pour favoriser ce partage avec d’autres passionnés, nous sommes sponsors, speakers, et hôtes de différents événements, meetups, et associations de la scène Tech en France. Au cours des dernières années, nous avons participé à des événements tels que Devoxx, ReactEurope, ProductConf et Flupa UX Days.\nA propos du job\nIntégré(e) dans notre équipe Data Science, votre principale mission sera de prototyper, itérer, et mettre en production des algorithmes en collaboration avec les équipes Produit, les Data Engineers et les équipes de développement. Les sujets que vous traiterez auront un vrai impact sur nos clients : l’ambition est d’exploiter au maximum nos données riches et variées afin de développer leur chiffre d'affaires, d’optimiser la gestion opérationnelle de leur marketplace et de garantir la sécurité des utilisateurs et des transactions.\nA propos de l’équipe\nGet to Know the Data Science Team That Powers the Mirakl Platform\nVoici quelques sujets actuels & futurs :\nCatégorisation de produits\nMappings de données produit\nExtraction de caractéristiques produit à partir du texte et des images\nDétection de comportements frauduleux\nEstimation de la date de livraison d’une commande\nMonitoring de la qualité de service des vendeurs\nRecommandations de produits (upsell, cross-sell, retargeting, …)\nPersonnalisation des résultats de recherche\nPersonnalisation de l’affichage de contenu\nPrédiction de produits tendance\nAide/Suggestion de réponses au customer service\nAffichage de produits sponsorisés ou de publicités maximisant le taux de clic\nCe qu’il y a pour vous dans ce job\nImplémenter des algorithmes qui auront un impact visible sur plus de 500 sites e-commerce/marketplaces dans 40 pays dont certains une volumétrie très importantes (millions de produits, de clients, de commandes par an)\nDes techniques diverses et variées (Heuristiques, Deep Learning, NLP, Image Processing, Time Series, LLM, etc.)\nUne vraie autonomie et responsabilité dans les projets dont vous avez l’ownership\nLa possibilité d'avoir un contrat freelance ou CDI\nNotre stack et nos outils\nPython, Tensorflow, Keras, Pytorch, Databricks, Spark, Aws (Amazon Redshift, s3, etc.), SQL, Airflow, Delta Lake\nAu quotidien\n, vous allez :\nAnalyser, préparer les données, prototyper des algorithmes\nLes mettre en production en collaboration avec les Data Engineers et les équipes de développement\nFaire des dashboards afin d’illustrer la pertinence des algorithmes et de monitorer la production\nPrésenter les résultats au weekly data science\nParticiper aux sessions de brainstorming de l’équipe\nÉchanger avec les autres équipes pour affiner les cas d’utilisation, l’expérience utilisateur et les modes d’intégration\nVous aimerez ce job si :\nVous avez 4 à 5 ans d'expérience minimum en tant que Data Scientist, avec une expérience significative en machine learning appliqué en entreprise\nVous avez déjà mis en production des algorithmes de Machine Learning\nVous avez une bonne connaissance des algorithmes de Deep Learning (image et/ou texte) et des architectures State-Of-the-Art - par exemple les Transformers\nVous maîtrisez Python, Tensorflow ou/et PyTorch\nVous avez une expérience en développement Spark\nVous êtes pragmatique, data-driven et orienté métier\nVous aimez avoir l’ownership de vos sujets\nVous êtes autonome et avez un très bon esprit d’équipe\nVous avez un esprit positif : respect et bienveillance font partie de vos valeurs\nVous aimez partager votre travail dans le cadre de présentations internes, dans des conférences ou en rédigeant des articles\nPetit plus :\nVous avez une expérience en environnement e-commerce et sur des algorithmes de systèmes de recommandations\nMirakl est engagée en faveur de la diversité, de l’égalité des chances et de l’inclusion. Nous célébrons nos différences car nous sommes convaincus que les qualités visibles et invisibles de chaque Mirakl Worker sont une source de force et d’innovation. Dans le cadre de cet engagement, nous étudions toutes les candidatures sans distinction de : genre, ethnicité, religion, orientation sexuelle, handicap, âge ou toute autre caractéristique protégée par la loi.\nShow more\nShow less",
        "details": {
            "JobDetail": [],
            "TypeContract": "CDI",
            "Salary": "",
            "Level": "",
            "Experience": "5 an(s)"
        },
        "title": "data scientist",
        "skills": {
            "ProgLanguage": [
                "Python"
            ],
            "DataBase": [
                "SQL"
            ],
            "BigData": [
                "Databricks",
                "Spark"
            ],
            "MachineLearning": [
                "PyTorch",
                "TensorFlow",
                "Keras"
            ],
            "CloudComputing": [
                "AWS"
            ],
            "Automation": [
                "Airflow"
            ],
            "Other": [
                "Machine Learning"
            ],
            "EnSoftSkils": [
                "Collaboration"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "JCW Group",
        "location": "Paris, Île-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/p-c-data-scientist-at-jcw-group-3916695827?position=2&pageNum=15&refId=wJnfW9FfV7ATob%2FRARlIng%3D%3D&trackingId=aYDJ3zulLJknP7nBXRMY0Q%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "P&C Data Scientist – Paris\n1. Purpose\nJoin a leading insurance company and be at the forefront of innovation as a P&C Data Scientist in Paris. This role combines actuarial expertise with data science to enhance risk assessment and support strategic decision-making through advanced analytics.\n2. Key Result Areas and Deliverables:\nDevelop strong relationships with actuarial teams, underwriters, and stakeholders to drive innovation and leverage data insights.\nUtilize statistical models, machine learning, and AI solutions to develop inference and predictive analytics, enhancing pricing strategies.\nAnalyze and incorporate external data sources to improve data-driven solutions and analytical models.\nEnhance data collection, management, and transformation capabilities to support pricing optimization and product innovation.\nTransform data into actionable insights, empowering business stakeholders to make informed decisions and drive growth.\n3. Key Competencies:\nGeneric:\nGood interpersonal skills\nCreativity and curiosity\nAttention to detail and analytical mindset\nProactive, flexible, and adaptable\nGood communication skills in English and French\nJob Specific:\nSkilled in Python and SQL\nProficient in data analysis techniques\nP&C insurance and Pricing knowledge\nFamiliarity with Large language Models (LLM)\nFamiliarity with Big Data technologies like Hadoop, Spark, or Kafka\nExperience with R, SAS, and VBA is a plus\nShow more\nShow less",
        "details": {
            "JobDetail": [],
            "TypeContract": "",
            "Salary": "",
            "Level": "",
            "Experience": null
        },
        "title": "data scientist",
        "skills": {
            "ProgLanguage": [
                "R",
                "Python"
            ],
            "DataBase": [
                "SQL"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [
                "Hadoop",
                "Spark"
            ],
            "Collaboration": [
                "Teams"
            ],
            "Other": [
                "Machine Learning",
                "Big Data"
            ],
            "EnSoftSkils": [
                "Creativity",
                "Communication",
                "Interpersonal Skills"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "OpenClassrooms",
        "location": "Communay, Auvergne-Rhône-Alpes, France",
        "link": "https://fr.linkedin.com/jobs/view/data-scientist-h-f-en-alternance-at-openclassrooms-3919835926?position=3&pageNum=15&refId=wJnfW9FfV7ATob%2FRARlIng%3D%3D&trackingId=mrCKz5o59QNqdh031pWpNg%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Description Du Poste\nOpenClassrooms recherche un Data Scientist en contrat d’apprentissage pour un de nos partenaires du secteur de l'entreprise, pour préparer une de ses formations diplômantes reconnues par l’État.\nAttention : cette offre ne s’adresse qu’aux candidats à l’alternance qui effectuent leur formation avec OpenClassrooms ou souhaitent s’inscrire chez OpenClassrooms pour leur alternance. Seules les candidatures répondant à ces critères seront étudiées. Apprenez un métier d’avenir en alternance avec OpenClassrooms. OpenClassrooms recherche un Data Scientist en contrat d’apprentissage pour un de nos partenaires du secteur de l'entreprise, pour préparer une de ses formations diplômantes reconnues par l’État.\nAttention : cette offre ne s’adresse qu’aux candidats à l’alternance qui effectuent leur formation avec OpenClassrooms ou souhaitent s’inscrire chez OpenClassrooms pour leur alternance. Seules les candidatures répondant à ces critères seront étudiées.\nAvec OpenClassrooms, vous apprendrez un métier avec une pédagogie mêlant 20% de théorie et 80% de pratique. Résultat : à l’issue de votre formation, vous êtes 100% prêt à l’emploi. Une fois votre diplôme en poche, nos équipes épaulent chaque profil dans la recherche d’un employeur, nous permettant d’afficher un taux d’insertion de nos étudiants en entreprise de plus de 80%. Si votre candidature est retenue, votre scolarité sera entièrement financée par votre employeur.\nVos missions en tant que Data Scientist en alternance :\nParticiper à l'analyse de données dans le but d'identifier des tendances et de formuler des recommandations pour améliorer les performances de l'entreprise\nContribuer à la création et à l'optimisation de modèles prédictifs pour anticiper les comportements des clients\nParticiper au développement d'algorithmes d'apprentissage automatique pour optimiser les campagnes de publicité en ligne\nCollaborer avec les équipes techniques pour mettre en place des solutions basées sur les données\nPoste basé à Paris (Île-de-France). Travail en hybride.\nRythme d’alternance et présence en entreprise Du lundi au vendredi Périodes de travail de 8 heures Repos le week-end Travail en journée\nEn entreprise : 4 jours par semaine (jours au choix) avec présence réduite à 3 jours 1 à 2 fois par mois\nEn formation : 1 jour par semaine + 1 jour supplémentaire 1 à 2 fois par mois\nProfil recherché\nProfil recherché\nFormation en Data Science ou dans un domaine connexe\nMaîtrise des techniques d'analyse de données et de modélisation statistique\nBonnes compétences en programmation (Python, R, etc.)\nCapacité à travailler de manière autonome et en équipe\nBonnes capacités de communication et de présentation\nShow more\nShow less",
        "details": {
            "JobDetail": [
                "Hybride"
            ],
            "TypeContract": "",
            "Salary": "",
            "Level": "",
            "Experience": null
        },
        "title": "data scientist",
        "skills": {
            "ProgLanguage": [
                "R",
                "Python"
            ],
            "DataAnalytics": [
                "R"
            ],
            "EnSoftSkils": [
                "Communication"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "Equancy | Groupe EDG",
        "location": "Paris, Île-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/stage-data-scientist-h-f-at-equancy-%C2%A0groupe-edg-3911741622?position=4&pageNum=15&refId=wJnfW9FfV7ATob%2FRARlIng%3D%3D&trackingId=onzFsT3EFkGmF%2BdRl37eMA%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Equancy\nest un cabinet de conseil international, basé à Paris et Dubaï, spécialisé dans la transformation data des entreprises.\nNous planifions, concevons et mettons en œuvre des solutions Big Data, Data Science et Intelligence Artificielle pour nos clients. Nos projets vont de la mise en œuvre d’infrastructures spécialisées dans le traitement de la donnée de nos clients, de lacs de données jusqu’au développement de systèmes opérationnels intégrant des algorithmes de\nmachine learning\nou de\ndeep learning\n. Nous sommes experts dans l’industrialisation de ces plates-formes, en appliquant les principes du devops à nos infrastructures data.\nNos clients sont de grands groupes français et internationaux (LVMH, Picard, Chanel VINCI, Volkswagen). Ils nous font confiance autant dans l’accompagnement au cadrage de leurs besoins que dans la réalisation des solutions data innovantes\nAfin d’accompagner la croissance de son activité, Equancy recherche un Stagiaire Data Scientist Junior (H/F) pour intégrer sa Practice data.\nDans ce cadre :\nVous participez à la compréhension du besoin métier et à la définition de l’approche de data science, encadré par un data scientist senior ou expert : données à utiliser, préparations nécessaires, approche algorithmique et de modélisation, évaluation des performances, optimisation des paramètres, itérations pour améliorer;\nVous réalisez les analyses nécessaires à une bonne prise en charge des données à disposition, contrôlez la cohérence, validez leur lecture;\nVous développez les traitements en Python (essentiellement) pour préparer les données, entraîner et optimiser les modèles de data science (statistiques, machine learning, deep learning), évaluer et valider leur performance;\nLe cas échéant, en cas de fortes volumétries, vous travaillez en pyspark;\nVous pourriez avoir à développer des interfaces de visualisation et d’interaction avec les modèles développés (dash);\nVous participez à l’industrialisation (MLOps) des modèles qui sont mis en production et interagissez avec l’équipe de data engineering ; Vous évoluez dans des équipes fonctionnant en méthode Agile;\nVous documentez vos travaux et vos analyses;\nVous participez à la rédaction des restitutions et présentations des travaux réalisés auprès des commanditaires (internes ou clients).\nProfil recherché:\nDe formation Bac+4/5 type Ecole d’ingénieur ou université en Informatique;\nVous maitrisez Python et ses modules de data science (pandas, sklearn, seaborn, dash);\nVous connaissez les techniques de préparation de données, création de features;\nVous connaissez les algorithmes de statistiques, machine learning et deep learning;\nVous vous intéressez particulièrement à l’industrialisation, au passage à l’échelle de modèles de data science, au-delà d’une approche expérimentale de la data science;\nVous avez envie de connaître les environnements cloud (Google Cloud, Amazon Web Services, MS Azure);\nVous aimez travailler en équipe;\nVous êtes réactif, avec le sens du service, vous justifiez de bonnes capacités d’écoute, d’un bon relationnel et d’une bonne gestion du stress;\nVous êtes curieux, autonome et proactif.\nEquancy c'est aussi :\nUn cadre de travail :\n· Superbes locaux au cœur de Paris : Espace WeWork Jules Lefebvre, à coté de Saint Lazare, au sein d’un bâtiment historique, avec de grands espaces et vue panoramique sur tout Paris;\n· Equilibre vie pro / vie perso;\n· Une politique de télétravail de deux jours par semaine;\n· Équipement pour travailler en remote + participation aux frais du télétravail (allocation mensuelle);\n· Engagement environnemental;\n· Des activités sportives proposées\n· Une conciergerie proposée par We Work.\nEnvironnement de travail stimulant, proximité forte avec les directeurs et les associés ;\nÉquipe dynamique, passionnée et internationale.\nL’aventure vous tente ? Écrivez-nous !\nShow more\nShow less",
        "details": {
            "JobDetail": [
                "Remote",
                "Junior",
                "Senior"
            ],
            "TypeContract": "",
            "Salary": "",
            "Level": "",
            "Experience": null
        },
        "title": "data scientist",
        "skills": {
            "ProgLanguage": [
                "Python"
            ],
            "DataAnalytics": [
                "Pandas"
            ],
            "DataVisualisation": [
                "Seaborn"
            ],
            "CloudComputing": [
                "Azure"
            ],
            "Other": [
                "Big Data",
                "Statistiques",
                "Machine Learning",
                "Cloud",
                "DevOps"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "Assystem",
        "location": "Courbevoie, Île-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/data-scientist-h-f-at-assystem-3902418016?position=5&pageNum=15&refId=wJnfW9FfV7ATob%2FRARlIng%3D%3D&trackingId=x5Iy%2BU0dhO1MrRGqlnQGDw%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Trouver des solutions au dérèglement climatique est la priorité du 21ème siècle, et implique de switcher à\nl’énergie bas-carbone\n. Chez Assystem, on s’est donc donné pour mission\nd’accélérer la transition énergétique\npartout dans le monde. Et pour y parvenir,\nnos 7000 Switchers\ncouplent leur expertise historique en\ningénierie et en management de projet\naux\ntechnologies digitales\n.\nPrésent dans 12 pays (Europe, Moyen-Orient, Asie), nous travaillons sur la\nproduction et la distribution d'électricité bas-carbone\n, à travers le\ndéveloppement des énergies nucléaires\net\nrenouvelables\n. Nous participons également à la\nmodernisation des réseaux électriques\net\nl'électrification des usages\n, à travers\nl'hydrogène\npour décarboner les secteurs des transports et de l'industrie.\nDescription du poste\nVotre Futur Equipe\nRejoignez l'équipe d'Alexandre et apportez votre expertise en tant que\nData Scientist (H/F)\npour contribuer activement à nos projets innovants dans le domaine du réseau électrique. Nous recherchons un(e) professionnel(le) passionné(e) et expérimenté(e) capable de créer et d'implémenter des algorithmes avancés pour optimiser nos opérations.\nMission :\nEn tant que Data Scientist (H/F), votre rôle sera crucial dans\nle développement et l'optimisation de nos solutions data pour le réseau électrique.\nVous serez responsable de la\ncréation d'algorithmes, de l'analyse de données et de la modélisation mathématique pour améliorer nos processus et nos décisions\n.\nResponsabilités principales :\nConception et développement d'algorithmes\navancés pour optimiser la conception et la régulation\ndu réseau électrique\n.\nCréation d'une ontologie universelle\npour faciliter la recherche rapide des exigences de conception spécifiques aux différents pays.\nÉlaboration d'un cadre réglementaire de référence\npour identifier les régulations applicables dans les pays étrangers.\nAnalyse de conformité des designs originaux ou adaptés aux normes locales ou internationales du réseau électrique\n.\nDéveloppement et mise en œuvre d'une application de sélection de sites pour les énergies renouvelables basée sur des facteurs géographiques et une cartographie binaire avec GIS.\nOptimisation de la sélection des sites pour établir des installations hybrides à coût réduit en utilisant la modélisation déterministe et l'analyse du réseau.\nAutomatisation de l'analyse du réseau en utilisant Digsilent Powerfactory\net des scripts\nPython\npour l'exécution parallèle des fonctions de calcul et les évaluations d'impact.\nPourquoi rejoindre la communauté des Switchers ?\nRejoignez la\ncommunauté des Switchers\net faites partie d'une aventure digitale passionnante au cœur de\nl'industrie nucléaire\n!\n💪 Plus de 55 ans d’expérience dans le nucléaire et positionné dans le top 3 des plus grandes entreprises d’ingénierie nucléaire.\n🚀 Participer à des projets stimulants avec un véritableimpactsociétal.\n📈 De nombreuses opportunités de carrière avec 70% de nos managers issus de la promotion interne.\nQualifications\nExpérience significative de minimum 4 ansen tant que\nData Scientist,\nidéalement dans le\ndomaine du réseau électrique ou secteur similaire\n.\nMaîtrise des modèles mathématiques\net capacité à les appliquer aux problématiques du réseau électrique.\nConnaissance approfondie des entrepôts de données et maîtrise du requêtage.\nSensibilisation aux enjeux de la transition énergétique\net intérêt pour les énergies renouvelables.\nNotions avancées en électrotechnique et connaissance des réseaux électriques.\nCompétences en programmation avec Python\net\nfamiliarité avec Digsilent Powerfactory.\nCapacité à travailler en équipe, autonomie et rigueur.\nInformations supplémentaires\nNous nous engageons au respect de l’égalité de traitement entre les candidats, et célébrons toutes les formes de diversité. Chez Assystem, seules les compétences comptent!Si vous souhaitez porter à la connaissance d’Assystem une quelconque situation ou des besoins spécifiques, n’hésitez pas vous serez accompagné(e)!\nShow more\nShow less",
        "details": {
            "JobDetail": [
                "Hybride"
            ],
            "TypeContract": "",
            "Salary": "",
            "Level": "",
            "Experience": "55 an(s)"
        },
        "title": "data scientist",
        "skills": {
            "ProgLanguage": [
                "Python"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "METEOJOB by CleverConnect",
        "location": "Aubervilliers, Île-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/alternance-%E2%80%93-data-scientist-at-meteojob-by-cleverconnect-3898720601?position=6&pageNum=15&refId=wJnfW9FfV7ATob%2FRARlIng%3D%3D&trackingId=vVffsTO1ZpX5Qw24My8nQw%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Entreprise\nMAKING THE WORLD A BETTER HOME\n, faire du monde une maison commune, c'est la raison pour laquelle nous existons et c'est notre cap commun.\nPrésent dans 75 pays, Saint-Gobain est le leader mondial de la construction durable.\nNotre métier ?\nNous concevons, produisons et distribuons des matériaux et des services pour les marchés de l'habitat et de l'industrie.\nNos solutions ?\nElles se trouvent partout dans notre vie quotidienne - bâtiments, transports, infrastructures - et apportent confort et durabilité.\nNotre ambition ?\nOù que vous soyez, laissez votre personnalité briller et nos valeurs vous guider chaque jour pour inventer un monde plus durable.\nSaint-Gobain Glass conçoit, produit et distribue des matériaux et services pour les marchés de l'habitat et de l'industrie. Mus par une volonté permanente d'adapter nos produits verriers aux besoins et aux réalités actuels, nous innovons sans cesse. Nous développons ainsi des solutions intégrées pour la rénovation des bâtiments publics et privés, la construction légère. Par l'innovation, nous avons également à cœur de participer à la décarbonation du monde de la construction et de l'industrie avec des produits apportant durabilité et performance.\nEn France, Saint-Gobain Glass produit, transforme le verre plat et distribue des solutions verrières répondant à un large spectre d'applications pour l'habitat résidentiel et tertiaire.\nEn intégrant Saint-Gobain Glass France, vous rejoindrez la Direction Technologie et Performance Industrielle (DTI) établie à Aubervilliers, où vous serez au cœur des initiatives stratégiques pour optimiser les performances industrielles et environnementales.\nLes missions principales de la DTI sont d'assurer un accompagnement des pays et métiers du Groupe sur les activités suivantes: feuilles de route industrielles (standards, benchmark, performance, énergie, CO2, savings, …), programmes R&D pour les métiers de la Construction, Investissements et Achats stratégiques, Allocation de capacité entre les pays et Programmes d'excellence opérationnelle avec les savings associés (World Class Manufacturing, World Class Supply Chain, 4.0, Applications digitales pour l'Industrie, …).\nDescription Du Poste\nLa Direction Technique Internationale est à la recherche d'un(e) alternant(e) - Data science.\nNotre futur(e) alternant(e) collaborera avec les experts de divers domaines pour répondre à leurs besoins d'analyse et contribuera activement au développement du pôle \"Data Science\" chez Saint-Gobain Glass.\nIl ou elle sera rattaché(e) à notre Ingénieurs Data Scientist\nLes Missions Principales Incluront\nEffectuer des analyses descriptives des données, telles que le Datamining, les Corrélations et les Segmentations.\nIdentifier et collecter les différentes données provenant des sources internes ou externes nécessaires aux études.\nManipuler et nettoyer de grandes quantités de données.\nMettre en place des algorithmes de prédiction, tels que la Régression, la Classification ou le Deep Learning.\nCollaborer étroitement avec des experts techniques et des professionnels du domaine pour interpréter les résultats obtenus.\nCréer des rapports et des tableaux de bord présentant divers indicateurs de performance, en utilisant des outils de business intelligence.\nFormation\nDescription du profil :\nNous recherchons des candidat(e)s ayant un niveau d'expérience correspondant à un Master 1-2, issu(e)s d'une école d'ingénieur.\nCompétences Techniques\nUne maîtrise de Miscrosoft 365 est indispensable.\nCapacité à effectuer des analyses de données sur R et/ou Python.\nLa maîtrise d'un outil de Business Intelligence est un atout.\nMaîtrise du Français et de l'Anglais.\nCompétences Relationnelles Et Qualités Requises\nUn fort intérêt pour l'analyse de données.\nDynamisme et sens du service client.\nCapacité à travailler de manière autonome et avec rigueur.\nOuverture d'esprit et curiosité.\nUn intérêt marqué pour le secteur industriel et les nouvelles technologies.\nExigences Du Poste\nEnvironnement multinational et multilingue.\nLocalisation à Aubervilliers\nCette offre est accessible à tous les talents ! Saint-Gobain s'engage quotidiennement pour l'égalité des chances. Nous apportons une attention particulière à l'inclusion et la diversité, https://www.saint-gobain.com/fr/news/agir-durablement\nLa culture Trust Empowerment and Collaboration (TEC) est le socle sur lequel se structure nos actions diversité et inclusion.\nShow more\nShow less",
        "details": {
            "JobDetail": [],
            "TypeContract": "",
            "Salary": "",
            "Level": "",
            "Experience": null
        },
        "title": "data scientist",
        "skills": {
            "ProgLanguage": [
                "R",
                "Python"
            ],
            "DataAnalytics": [
                "R"
            ],
            "EnSoftSkils": [
                "Collaboration"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "CHANEL",
        "location": "Paris, Île-de-France, France",
        "link": "https://fr.linkedin.com/jobs/view/stage-data-scientist-h-f-at-chanel-3904548050?position=7&pageNum=15&refId=wJnfW9FfV7ATob%2FRARlIng%3D%3D&trackingId=Od8%2FZJ%2FBc19WHuPR%2BV2XhA%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "A propos du poste\nLa « Business Services Platform » se positionne en conseil interne, partenaire de tous nos départements fonctionnels, aux différents niveaux de l’organisation européenne : corporate, région, marchés et boutiques.\nElle se décompose en trois finalités opérationnelles complémentaires\nNotre mission D&A, « Data Science & Advanced Analytics » est de définir et réaliser des cas d’usage pragmatiques et concrets via une approche projet itérative et courte.\nEn très forte collaboration avec les acteurs opérationnels, doté d’une expertise mathématique adaptée à nos besoins spécifiques, nous produisons du business consulting, des modèles mathématiques et algorithmiques performants et opérants.\nEn très forte collaboration avec les acteurs IT, nous construisons au fil des cas d’usage, nos plateformes européennes de donnée et d’algorithme, normalisées, industrialisées, orientées business et services.\nStage de 6 mois à pourvoir dès que possible.\nVotre impact chez CHANEL\nDans une approche itérative, progressive et coconstruite avec l’expert opérationnel et les acteurs IT data-ops / dev-ops. Avec un temps de production court : 1 à 3 mois par cas d’usage, depuis la définition détaillée du besoin réel jusqu’au modèle opérant en production.\nDans une élaboration progressive, fonctionnelle et cohérente de la plateforme cible de données et d’algorithmes « as a service », vous serez un appui au service sur les sujets suivants :\nPréparer et participer aux ateliers de définition détaillée, dans une approche produit / process cible, et couplée consulting métier / analyse exploratoire statistique de la donnée.\nProduire les livrables formels et synthétiques de conception détaillée.\nAligner et modéliser la solution mathématique et algorithmique, dans le respect de nos normes internes (scripts, framework de packages, performance, exposition / -visualisation) et de la contrainte itérative.\nTester avec l’expert opérationnel : former et valider la solution de calcul avancé, sa restitution et son monitoring opérationnel.\nTransmettre à l’IT les éléments et le support nécessaires d’industrialisation (mode batch - pipeline ou modèle conteneurisé).\nDocumenter et garantir l’auditabilité des modèles produits.\nContribuer au pilotage du projet : tenue des échéances, anticipation des risques, mise en production\nExemples de cas d’usage potentiels pendant le stage : optimisation de la distribution et de la répartition des stocks dans le réseau retail, optimisation de la planification des boutiques, prévisions commerciales, financières, des effectifs…\nCe que vous apporterez\nDiplômé d’une école d’ingénieur, option mathématiques appliquées / data science\nExpérience accomplie, avec des cas d’usage opérationnels et en production, sur des sujets de :\nSéries temporelles\nModèles d’optimisation\nModèles de régression et de classification (machine & deep learning)\nMaîtrise des frameworks classiques d’analyse statistique et de modélisation ; e.g. en Python :\nnumpy, pandas, matplotlib, statsmodel…\npmdarima, scikit-learn, scipy, tensorflow / keras, pytorch…\nMaitrise du langage Python\nPremier stage accompli de définition / validation du besoin métier, en approche couplée « business consulting » & analyse exploratoire et statistique des données. Si possible dans les fonctions finance et opérations.\nCulture et savoir-faire en mode projet piloté de bout en bout, en double interface métier et IT\nCuriosité, vivacité et agilité d’esprit\nInfluenceur, prescripteur et fort esprit de collaboration\nSens du résultat et du service au client, pédagogie opérationnelle\nAnglais\nCe que CHANEL peut vous offrir\nChez CHANEL, nous nous attachons à créer une culture inclusive qui favorise l'épanouissement et le développement personnel tout en contribuant à la performance collective. Nous avons la conviction que la singularité de chaque personne contribue à renforcer la diversité, la complémentarité et l'efficacité de nos équipes. Nous encourageons vivement votre candidature, car nous accordons une grande importance à l'expérience et au potentiel que vous pourriez apporter à la Maison CHANEL.\nShow more\nShow less",
        "details": {
            "JobDetail": [],
            "TypeContract": "",
            "Salary": "Package",
            "Level": "",
            "Experience": null
        },
        "title": "data scientist",
        "skills": {
            "ProgLanguage": [
                "Python"
            ],
            "DataAnalytics": [
                "NumPy",
                "Pandas"
            ],
            "MachineLearning": [
                "Scikit-Learn",
                "PyTorch",
                "TensorFlow",
                "Keras"
            ],
            "DataVisualisation": [
                "Matplotlib"
            ],
            "EnSoftSkils": [
                "Collaboration"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "Acelys Services Numériques",
        "location": "Montpellier, Occitanie, France",
        "link": "https://fr.linkedin.com/jobs/view/data-scientist-traitement-du-langage-naturel-f-h-syst%C3%A8me-r%C3%A9seaux-donn%C3%A9es-h-f-at-acelys-services-num%C3%A9riques-3908665280?position=8&pageNum=15&refId=wJnfW9FfV7ATob%2FRARlIng%3D%3D&trackingId=T%2Fzawx6R49aHcZgK3juWmg%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Cette offre d’emploi est fournie par Pôle emploi\nDescription\nDescriptif du poste: Acelys recherche un.e Data Scientist expérimenté en IA et NLP pour rejoindre notre équipe dynamique au sein du pôle de R&D/IA d'une quinzaine de talents. Notre pôle R&D, expert dans le traitement du langage naturel (pôle Edition) mène depuis 10 ans des travaux en étroite collaboration avec des laboratoires de recherche sur des problématiques technologiques. Vous travaillerez en lien avec les chercheurs, ingénieurs et autres experts en utilisant des techniques d'apprentissage automatique et de traitement du langage naturel pour résoudre des problèmes complexes, tels que la recherche documentaire, la similarité sémantique, la classification... Profil recherché: - Vous êtes diplômé.e en informatique, en sciences des données ou dans un domaine connexe - Vous disposez de solides compétences en programmation (Python, TensorFlow, PyTorch, etc.) - Vous avez connaissance des techniques d'apprentissage automatique et du traitement automatique du langage naturel - Vous êtes expérimenté.e sur les pratiques CI/CD (intégration continue et déploiement continu) - Une expérience sur les Frameworks Python est appréciée : Langchain, Django/Flask,Transformers\nPROFIL SOUHAITÉ\nExpérience\nExpérience exigée de 2 An(s)\nSource: Pole emploi (https://www.pole-emploi.fr)\nShow more\nShow less",
        "details": {
            "JobDetail": [],
            "TypeContract": "",
            "Salary": "",
            "Level": "",
            "Experience": "10 an(s)"
        },
        "title": "data scientist",
        "skills": {
            "ProgLanguage": [
                "R",
                "Python"
            ],
            "DataAnalytics": [
                "R"
            ],
            "MachineLearning": [
                "PyTorch",
                "TensorFlow"
            ],
            "Other": [
                "CI/CD"
            ],
            "EnSoftSkils": [
                "Collaboration"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "Astek",
        "location": "Bordeaux, Nouvelle-Aquitaine, France",
        "link": "https://fr.linkedin.com/jobs/view/lead-data-scientist-%E2%80%93-bordeaux-france-h-f-at-astek-3882495203?position=9&pageNum=15&refId=wJnfW9FfV7ATob%2FRARlIng%3D%3D&trackingId=pL7LwHO8%2FzWbGzzjk%2BP3iw%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "CDI\nBordeaux - France\nPubliée il y a 1 mois\nLe Groupe Astek\nCe Que Nous Allons Accomplir Ensemble :\nAfin d’accélérer la transformation IA de nos clients, la Division Consulting IA Astek vous propose d’integrer ses équipe en qualité de data scientist senior pour travailler sur le prototypage et la construction de solutions d’IA en étroite collaboration avec nos partenaires.\nLa Division Consulting IA a pour mission d’accélérer le développement de modèles et d’applications d’IA en itérant en étroite collaboration nos\néquipes R&D internes et nos clients. Le projet nécessite à la fois des compétences techniques avancées, des aptitudes d’analyse et des compétences en communication.\nVous etes intéressé par l’innovation en IA et disposez d’une forte compétence technique et appréciez de travailler avec des équipes de\ndifférentes fonctions? N’attendez plus, rejoignez nous.\nVotre Mission, Si Vous L’acceptez :\nPiloter les projets d’IA, proposer des solutions stratégiques et exposer les résultats aux dirigeants et aux partenaires commerciaux, tout en encadrant les scientifiques des données pour garantir la qualité de la livraison.\nParticiper à la transformation de l’IA dans l’entreprise, avec pour objectif de créer une valeur réelle et mesurable pour le Groupe.\nFaciliter les projets en apportant des modèles, des pipelines de traitement de données, des analyses ou des modélisations de problèmes.\nContribuer aux activités de R&D en IA, notamment dans le cadre de nos partenariats avec Microsoft.\nAccompagner nos clients dans la définition de leurs priorité et schémas directeurs.\nVous ?\nFormation : Bac+5 ou doctorat issu d’une grande école d’ingénieurs ou d’université ; spécialisation en mathématiques, statistiques ou informatique.\nExpérience : Entre 2 et 8 ans en tant que data scientist ou dans un poste comparable.\nCompétences : Excellentes compétences en modélisation mathématique et en résolution de problèmes, avec une bonne maîtrise des statistiques, du machine learning et du deep learning ; La NLP est un atout.\nAutonomie et adaptabilité ; Capacité à synthétiser et à communiquer efficacement.\nStack technique : Maîtrise de Python, SQL, Spark, avec une compétence supplémentaire dans le déploiement de modèles (Airflow, Gitlab, Docker) et/ou le deep learning (pyTorch, cuda).\nLe Groupe Astek\nCréé en France en 1988, Astek est un acteur mondial de l’ingénierie et du conseil en technologies. Fort de son expertise dans de nombreux secteurs industriels et tertiaires, Astek accompagne ses clients internationaux dans le déploiement intelligent de leurs produits et de leurs services, et dans la mise en œuvre de leur transformation digitale.\nDepuis sa création, le Groupe a fondé son développement sur une forte culture d’entrepreneuriat et d’innovation, et sur l’accompagnement et la montée en compétence de\nses 7800 collaborateurs\nqui s’engagent chaque jour à promouvoir la complémentarité entre les technologies numériques et l’ingénierie des systèmes complexes.\nRejoignez un Groupe en fort développement en France et à travers le monde ayant réalisé un chiffre d’affaires de 600 M€ en 2023.\nTous les détails sur le Groupe sur le site https://astekgroup.fr. Et vous pouvez aussi nous suivre sur notre blog : https://blog.groupeastek.com.\nRencontrons-nous\nNotre projet commun vous plait ?\nPostulez à cette annonce, et soyez transparent !\nNotre Talent Acquisition Officer, vous contactera pour un premier échange téléphonique.\nPuis vous rencontrerez votre futur manager, avec lequel vous échangerez autour d’Astek, de votre parcours, de vos attentes et de votre future mission .\nEnfin, vous rencontrerez notre Directeur de département, avec lequel vous pourrez valider votre intérêt et adéquation pour le poste et finaliser les éléments contractuels.\nNos Plus\nAstek est green et fait bénéficier ses salariés d’une indemnité kilométrique vélo\nUne politique CARE sur-mesure déployée par nos équipes RH pour nos collaborateurs (https://astekgroup.fr/engagements)\nNotre charte de la Diversité\nBienvenue dans la team ! Allez-y, maintenant c’est à vous de jouer !\nCaractéristiques de l'emploi\nCatégorie Ingénieur\nJob Industry Aérospatial / Défense / Sécurité, Distribution / Services Internet, Energie / Sciences de la Vie / Autres industries, Finance / Gouvernement, Télécom / Média, Transports Terrestres\nPostuler en ligne\nNom *\nPrénom *\nEmail *\nUn email valide est requis.\nTéléphone *\nUn numéro de téléphone valide est requis.\nJoindre un CV *\nVotre Mission, Si Vous L’acceptez :\nPiloter les projets d’IA, proposer des solutions stratégiques et exposer les résultats aux dirigeants et aux partenaires commerciaux, tout en encadrant les scientifiques des données pour garantir la qualité de la livraison.\nParticiper à la transformation de l’IA dans l’entreprise, avec pour objectif de créer une valeur réelle et mesurable pour le Groupe.\nFaciliter les projets en apportant des modèles, des pipelines de traitement de données, des analyses ou des modélisations de problèmes.\nContribuer aux activités de R&D en IA, notamment dans le cadre de nos partenariats avec Microsoft.\nAccompagner nos clients dans la définition de leurs priorité et schémas directeurs.\nVous ?\nFormation : Bac+5 ou doctorat issu d’une grande école d’ingénieurs ou d’université ; spécialisation en mathématiques, statistiques ou informatique.\nExpérience : Entre 2 et 8 ans en tant que data scientist ou dans un poste comparable.\nCompétences : Excellentes compétences en modélisation mathématique et en résolution de problèmes, avec une bonne maîtrise des statistiques, du machine learning et du deep learning ; La NLP est un atout.\nAutonomie et adaptabilité ; Capacité à synthétiser et à communiquer efficacement.\nStack technique : Maîtrise de Python, SQL, Spark, avec une compétence supplémentaire dans le déploiement de modèles (Airflow, Gitlab, Docker) et/ou le deep learning (pyTorch, cuda).\nLe Groupe Astek\nCréé en France en 1988, Astek est un acteur mondial de l’ingénierie et du conseil en technologies. Fort de son expertise dans de nombreux secteurs industriels et tertiaires, Astek accompagne ses clients internationaux dans le déploiement intelligent de leurs produits et de leurs services, et dans la mise en œuvre de leur transformation digitale.\nDepuis sa création, le Groupe a fondé son développement sur une forte culture d’entrepreneuriat et d’innovation, et sur l’accompagnement et la montée en compétence de\nses 7800 collaborateurs\nqui s’engagent chaque jour à promouvoir la complémentarité entre les technologies numériques et l’ingénierie des systèmes complexes.\nRejoignez un Groupe en fort développement en France et à travers le monde ayant réalisé un chiffre d’affaires de 600 M€ en 2023.\nTous les détails sur le Groupe sur le site https://astekgroup.fr. Et vous pouvez aussi nous suivre sur notre blog : https://blog.groupeastek.com.\nRencontrons-nous\nNotre projet commun vous plait ?\nPostulez à cette annonce, et soyez transparent !\nNotre Talent Acquisition Officer, vous contactera pour un premier échange téléphonique.\nPuis vous rencontrerez votre futur manager, avec lequel vous échangerez autour d’Astek, de votre parcours, de vos attentes et de votre future mission .\nEnfin, vous rencontrerez notre Directeur de département, avec lequel vous pourrez valider votre intérêt et adéquation pour le poste et finaliser les éléments contractuels.\nNos Plus\nAstek est green et fait bénéficier ses salariés d’une indemnité kilométrique vélo\nUne politique CARE sur-mesure déployée par nos équipes RH pour nos collaborateurs (https://astekgroup.fr/engagements)\nNotre charte de la Diversité\nBienvenue dans la team ! Allez-y, maintenant c’est à vous de jouer !\nShow more\nShow less",
        "details": {
            "JobDetail": [
                "Senior"
            ],
            "TypeContract": "CDI",
            "Salary": "",
            "Level": "Bac+5",
            "Experience": "8 an(s)"
        },
        "title": "data scientist",
        "skills": {
            "ProgLanguage": [
                "R",
                "Python"
            ],
            "DataBase": [
                "SQL"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [
                "Spark"
            ],
            "MachineLearning": [
                "PyTorch"
            ],
            "DevTools": [
                "Docker"
            ],
            "Automation": [
                "Airflow"
            ],
            "Containers": [
                "Docker"
            ],
            "Other": [
                "Statistiques",
                "Machine Learning"
            ],
            "EnSoftSkils": [
                "Communication",
                "Collaboration"
            ]
        }
    },
    {
        "source": "LinkedIn",
        "company": "LesJeudis",
        "location": "Le Havre, Normandy, France",
        "link": "https://fr.linkedin.com/jobs/view/data-scientist-cdi-at-lesjeudis-3909984113?position=10&pageNum=15&refId=wJnfW9FfV7ATob%2FRARlIng%3D%3D&trackingId=mj1%2F5hu2Z0sN3fqfzwLf9A%3D%3D&trk=public_jobs_jserp-result_search-card",
        "description": "Data Scientist H/F (CDI).\nMode de travail : hybride, 2 à 3 jours de présentiel.\nLocalisation : le Havre (76).\nProfil : intermédiaire à confirmé.\nFourchette de salaire : 35k€ à 55k€ en fonction du profil et de l’expérience.\nDate de démarrage : à partir de mai, si vous avez un préavis nous pouvons vous attendre.\nL’\nIT\nchez ARTEMYS AGIL-IT combine\nla technologie\net\nl’humain\n! Nous sommes convaincus que les compétences, le savoir-être et l’épanouissement de nos Talents sont les\nclés de notre réussite\n. Avant tout, nous recherchons chez\nARTEMYS AGIL-IT\ndes\npersonnalITés passionnées.\nAlors, vous nous rejoignez ?!\nNous recherchons un.e Data Scientist talentueux.se pour rejoindre l’équipe dynamique de notre client. Dans ce rôle hybride, vous aurez l’opportunité de travailler sur un projet vitrine passionnant, impliquant la mise en place d’un kiosque data.\nLes Missions\nConcevoir, développer et mettre en œuvre des modèles de machine learning et des algorithmes d'analyse de données pour répondre aux besoins du projet.\nAnalyser et interpréter les données pour fournir des insights pertinents et des recommandations stratégiques.\nParticiper activement à l'amélioration continue des processus et des méthodologies liés à l'analyse de données.\nVous êtes titulaire d’un diplôme universitaire en informatique, statistiques, mathématiques appliquées ou domaine connexe.\nVous avez une\nexpérience\ndémontrée dans le développement et le déploiement de modèles de machine learning.\nVous\nmaîtrisez\ndes outils et des langages de programmation couramment utilisés en Data Science (Python, SQL…).\nVotre esprit analytique et votre capacité à communiquer efficacement avec les parties prenantes ne sont plus à prouver.\nLes Attendus Concernant Le Savoir-être\nAutonomie, créativité et capacité à travailler dans un environnement collaboratif.\nVous avez un\nsuper\nétat d’esprit\net êtes\nultra motivé.e\n…\nVous vous reconnaissez ?\nAlors, vous êtes fait.e pour nous rejoindre !\nVous êtes toujours là ? Top ! Voici ce qui vous attend :\nUn premier échangepour faire connaissance\nUn entretien RH avec Mathilde\nUn entretien techniqueavec votre futur manager\nUne proposition salariale\nAlors, ça vous tente ?\nC’est parti !\nBienvenue dans l’aventure ARTEMYS AGIL-IT\nShow more\nShow less",
        "details": {
            "JobDetail": [
                "Hybride",
                "Confirmé"
            ],
            "TypeContract": "CDI",
            "Salary": "35k",
            "Level": "",
            "Experience": null
        },
        "title": "data scientist",
        "skills": {
            "ProgLanguage": [
                "Python"
            ],
            "DataBase": [
                "SQL"
            ],
            "Other": [
                "Statistiques",
                "Machine Learning"
            ]
        }
    }
]